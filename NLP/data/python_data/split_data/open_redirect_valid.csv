,Unnamed: 0,id,code,label
64,64,0e771d89d1c8b20b5eedb1c2596570b6f3aaa488,"database_setup.py/n/nfrom sqlalchemy import Column, ForeignKey, Integer, String
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from sqlalchemy import create_engine

Base = declarative_base()

class User(Base):
    __tablename__ = 'User'

    id = Column(Integer, primary_key=True)
    name = Column(String(250), nullable=False)
    email = Column(String(250), nullable=False)
    picture = Column(String(250))

class Grudget(Base):
    __tablename__ = 'Grudget'

    id = Column(Integer, primary_key=True)
    name = Column(String(250), nullable=False)
    user_id = Column(Integer, ForeignKey('User.id'))
    user = relationship(User)

    @property
    def serialize(self):
        """"""Return object data in easily serializeable format""""""
        return {
            'name': self.name,
            'id': self.id,
        }


class Grudge(Base):
    __tablename__ = 'Grudge'

    id = Column(Integer, primary_key=True)
    name = Column(String(80), nullable=False)
    description = Column(String(450),nullable=False)
    processed = Column(String(15))
    takeaway = Column(String(250))
    grudget_id = Column(Integer, ForeignKey('Grudget.id'))
    grudget = relationship(Grudget)
    user_id = Column(Integer, ForeignKey('User.id'))
    user = relationship(User)

    @property
    def serialize(self):
        """"""Return object data in easily serializeable format""""""
        return {
            'id': self.id,
            'name': self.name,
            'description': self.description,
            'processed': self.processed,
            'takeaway': self.takeaway,
        }


engine = create_engine('sqlite:///grudgebucketwithusers.db', connect_args={'check_same_thread': False})


Base.metadata.create_all(engine)
/n/n/nfinalproject.py/n/nfrom flask import Flask, render_template, request, redirect, jsonify, url_for, flash
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from database_setup import Grudget, Base, Grudge, User
from flask import session as login_session
import random
import string
from oauth2client.client import flow_from_clientsecrets
from oauth2client.client import FlowExchangeError
import httplib2
import json
from flask import make_response
import requests

app = Flask(__name__)

#Reminder to change application name one day
CLIENT_ID = json.loads(
    open('client_secrets.json', 'r').read())['web']['client_id']
APPLICATION_NAME = ""Grudget Catalog""

#Connect to database and create db session
engine = create_engine('sqlite:///grudgebucketwithusers.db', connect_args={'check_same_thread': False})
Base.metadata.bind = engine
DBSession = sessionmaker(bind=engine)
session = DBSession()


# Create anti-forgery state token
@app.route('/login')
def showLogin():
    state = ''.join(random.choice(string.ascii_uppercase + string.digits)
                    for x in xrange(32))
    login_session['state'] = state
    # return ""The current session state is %s"" % login_session['state']
    return render_template('login.html', STATE=state)


@app.route('/gconnect', methods=['POST','GET'])
def gconnect():
    # Validate state token
    if request.args.get('state') != login_session['state']:
        response = make_response(json.dumps('Invalid state parameter.'), 401)
        response.headers['Content-Type'] = 'application/json'
        return response
    # Obtain authorization code
    request.get_data()
    code = request.data.decode('utf-8')
    #code = request.data

    try:
        # Upgrade the authorization code into a credentials object
        oauth_flow = flow_from_clientsecrets('client_secrets.json', scope='')
        oauth_flow.redirect_uri = 'postmessage'
        credentials = oauth_flow.step2_exchange(code)
    except FlowExchangeError:
        response = make_response(
            json.dumps('Failed to upgrade the authorization code.'), 401)
        response.headers['Content-Type'] = 'application/json'
        return response

    # Check that the access token is valid.
    access_token = credentials.access_token
    url = ('https://www.googleapis.com/oauth2/v1/tokeninfo?access_token=%s'
           % access_token)
    h = httplib2.Http()
    result = json.loads(h.request(url, 'GET')[1])
  

    # If there was an error in the access token info, abort.
    if result.get('error') is not None:
        response = make_response(json.dumps(result.get('error')), 500)
        response.headers['Content-Type'] = 'application/json'
        return response

    # Verify that the access token is used for the intended user.
    gplus_id = credentials.id_token['sub']
    if result['user_id'] != gplus_id:
        response = make_response(
            json.dumps(""Token's user ID doesn't match given user ID.""), 401)
        response.headers['Content-Type'] = 'application/json'
        return response

    # Verify that the access token is valid for this app.
    if result['issued_to'] != CLIENT_ID:
        response = make_response(
            json.dumps(""Token's client ID does not match app's.""), 401)
        print ""Token's client ID does not match app's.""
        response.headers['Content-Type'] = 'application/json'
        return response
        #Chcek if user is alkready logged in
    stored_access_token = login_session.get('access_token')
    stored_gplus_id = login_session.get('gplus_id')
    if stored_access_token is not None and gplus_id == stored_gplus_id:
        response = make_response(json.dumps('Current user is already connected.'),
                                 200)
        response.headers['Content-Type'] = 'application/json'
        return response

    # Store the access token in the session for later use.
    login_session['access_token'] = credentials.access_token
    login_session['gplus_id'] = gplus_id

    # Get user info
    userinfo_url = ""https://www.googleapis.com/oauth2/v1/userinfo""
    params = {'access_token': credentials.access_token, 'alt': 'json'}
    answer = requests.get(userinfo_url, params=params)
    data = answer.json()
    login_session['username'] = data['name']
    login_session['picture'] = data['picture']
    login_session['email'] = data['email']
    login_session['provider'] = 'google'

    # see if user exists, if it doesn't make a new one
    user_id = getUserID(data[""email""])
    if not user_id:
        user_id = createUser(login_session)
    login_session['user_id'] = user_id
    output = ''
    output += '<h1>Welcome, '
    output += login_session['username']
    output += login_session['user_id']
    output += '!</h1>'
    output += '<img src=""'
    output += login_session['picture']
    output += ' "" style = ""width: 300px; height: 300px;border-radius: 150px;-webkit-border-radius: 150px;-moz-border-radius: 150px;""> '
    flash(""you are now logged in as %s"" % login_session['username'])
    return output

# User Helper Functions
def createUser(login_session):
    newUser = User(
        name=login_session['username'], 
        email=login_session['email'], 
        picture=login_session['picture'])
    session.add(newUser)
    session.commit()
    user = session.query(User).filter_by(email=login_session['email']).one()
    return user.id


def getUserInfo(user_id):
    user = session.query(User).filter_by(id=user_id).one()
    return user


def getUserID(email):
    try:
        user = session.query(User).filter_by(email=email).one()
        return user.id
    except:
        return None


# Disconnect based on provider
@app.route('/logout')
def disconnect():
    if 'provider' in login_session:
        if login_session['provider'] == 'google':
            gdisconnect()
            del login_session['gplus_id']
            del login_session['access_token']
        if login_session['provider'] == 'facebook':
            fbdisconnect()
            del login_session['facebook_id']
        del login_session['username']
        del login_session['email']
        del login_session['picture']
        del login_session['user_id']
        del login_session['provider']
        flash(""You have successfully been logged out."")
        return redirect(url_for('showGrudgets'))
    else:
        flash(""You were not logged in"")
        return redirect(url_for('showGrudgets'))

# DISCONNECT - Revoke a current user's token and reset their login_session
@app.route('/gdisconnect')
def gdisconnect():
        # Only disconnect a connected user.
    access_token = login_session.get('access_token')
    if access_token is None:
        response = make_response(
            json.dumps('Current user not connected.'), 401)
        response.headers['Content-Type'] = 'application/json'
        return response
    url = 'https://accounts.google.com/o/oauth2/revoke?token=%s' % access_token
    h = httplib2.Http()
    result = h.request(url, 'GET')[0]
    if result['status'] == '200':
        # Reset the user's sesson.
        del login_session['access_token']
        del login_session['gplus_id']
        del login_session['username']
        del login_session['email']
        del login_session['picture']

        # response = make_response(json.dumps('Successfully disconnected.'), 200)
        # response.headers['Content-Type'] = 'application/json'
        response = redirect(url_for('showGrudgets'))
        flash(""You are now logged out."")
        return response
    else:
        # For whatever reason, the given token was invalid.
        response = make_response(
            json.dumps('Failed to revoke token for given user.', 400))
        response.headers['Content-Type'] = 'application/json'
        return response



#JSON APIs to view the Grudge Buckets aka Grudgets and Grudges
@app.route('/grudget/<int:grudget_id>/grudge/JSON')
def grudgetGrudgeJSON(grudget_id):
    grudget = session.query(Grudget).filter_by(id=grudget_id).one()
    grudges = session.query(Grudge).filter_by(grudget_id=grudget.id).all()
    return jsonify(Grudge=[i.serialize for i in grudges])


@app.route('/grudget/<int:grudget_id>/grudge/<int:grudge_id>/JSON')
def grudgeJSON(grudget_id, grudge_id):
    grudge = session.query(Grudge).filter_by(id=grudge_id).one()
    return jsonify(grudge=Grudge.serialize)


@app.route('/grudget/JSON')
def grudgetsJSON():
    grudgets = session.query(Grudget).all()
    return jsonify(grudget=[g.serialize for g in grudgets])


# Show all grudgets/grudge buckets
@app.route('/')
@app.route('/grudget/')
def showGrudgets():
    grudgets = session.query(Grudget).all()
    if 'username' not in login_session:
        return render_template('publicgrudgets.html', grudgets=grudgets)
    else:
        return render_template('grudgets.html', grudgets=grudgets)
    

# Create a new grudge bucket aka grudget
@app.route('/grudget/new/', methods=['GET', 'POST'])
def newGrudget():
    if 'username' not in login_session:
        return redirect('/login')
    if request.method == 'POST':
        newGrudget = Grudget(name=request.form['name'])
        print newGrudget
        session.add(newGrudget)
        session.commit()
        return redirect(url_for('showGrudgets'))
    else:
        return render_template('newGrudget.html')


# # Edit a grudge bucket - should be protected, street cred
@app.route('/grudget/<int:grudget_id>/edit/', methods=['GET', 'POST'])
def editGrudget(grudget_id):
    editedGrudget = session.query(Grudget).filter_by(id=grudget_id).one()
    user = session.query(User).filter_by(id=user_id).one()
    creator = getUserInfo(grudget.user_id)
    if 'username' not in login_session:
        return redirect('/login')
    if user != login_session['user_id']:
        return ""<script>function myFunction() {alert('As juicy as this is, you are not authorized to edit this grudget. Please create your own grudget in oder to edit.');}</script><body onload='myFunction()'>""
    if request.method == 'POST':
        if request.form['name']:
            editedGrudget.name = request.form['name']
            return redirect(url_for('showGrudgets'))
    else:
        return render_template('editGrudget.html', grudget=editedGrudget)


# # Delete a grudge bucket - Protected
@app.route('/grudget/<int:grudget_id>/delete/', methods=['GET', 'POST'])
def deleteGrudget(grudget_id):
    grudgetToDelete = session.query(Grudget).filter_by(id=grudget_id).one()
    if 'username' not in login_session:
        return redirect('/login')
    if user_id != login_session['user_id']:
        return ""<script>function myFunction() {alert('As juicy as this is, you are not authorized to delete this grudget. Please create your own grudget in order to edit.');}</script><body onload='myFunction()'>""
    if request.method == 'POST':
        session.delete(grudgetToDelete)
        session.commit()
        return redirect(
            url_for('showGrudgets', grudget_id=grudget_id))
    else:
        return render_template('deleteGrudget.html', grudget=grudgetToDelete)
 


# Show a grudge
@app.route('/grudget/<int:grudget_id>/')
@app.route('/grudget/<int:grudget_id>/grudge/')
def showGrudge(grudget_id):
    grudget = session.query(Grudget).filter_by(id=grudget_id).first()
    creator = getUserInfo(grudget.user_id)
    grudges = session.query(Grudge).filter_by(grudget_id=grudget_id).all()
    if 'username' not in login_session:
        return render_template('publicgrudges.html', grudges=grudges, id=grudget_id,grudget=grudget, creator=creator)
    else:
        return render_template('showgrudge.html', grudges=grudges, id=grudget_id, grudget=grudget, creator=creator)
 

# # Create a new grudge
@app.route('/grudget/<int:grudget_id>/grudge/new/', methods=['GET', 'POST'])
def newGrudge(grudget_id):
    if 'username' not in login_session:
        return redirect('/login')
    grudget = session.query(Grudget).filter_by(id=grudget_id).one()
    user_id=login_session['user_id']
    print user_id
    creator = getUserInfo(grudget.user_id)
    # if login_session['user_id'] != grudget.user_id:
    #     return ""<script>function myFunction() {alert('You are not authorized to add a grudge to this grudget.');}</script><body onload='myFunction()'>""
    if request.method == 'POST':
            newGrudge = Grudge(
                name=request.form['name'], 
                description=request.form['description'], 
                processed=request.form['processed'], 
                takeaway=request.form['takeaway'], 
                id=grudget_id, 
                user_id=user_id)
            session.add(newGrudge)
            session.commit()
            return redirect(url_for('showGrudge', grudget_id=grudget_id,creator=creator))
    else:
        return render_template('newgrudge.html', grudget_id=grudget_id)


# # Edit a grudge - Protected
@app.route('/grudget/<int:grudget_id>/grudge/<int:grudge_id>/edit', methods=['GET', 'POST'])
def editGrudge(grudget_id, grudge_id):
    if 'username' not in login_session:
        return redirect('/login')
    editgrudge = session.query(Grudge).filter_by(id=grudge_id).one()
    grudget = session.query(Grudget).filter_by(id=grudget_id).one()
    if login_session['user_id'] != id.user_id:
        return ""<script>function myFunction() {alert('You are not authorized to edit this grudge.');}</script><body onload='myFunction()'>""
    if request.method == 'POST':
        if request.form['name']:
            editgrudge.name = request.form['name']
        if request.form['description']:
            editgrudge.description = request.form['description']
        if request.form['processed']:
            editgrudge.processed = request.form['processed']
        if request.form['takeaway']:
           editgrudge.takeaway = request.form['takeaway']
        session.add(editgrudge)
        session.commit()
        return redirect(url_for('showGrudge', grudget_id=grudget_id))
    else:
        return render_template('editgrudge.html', grudget_id=grudget_id, grudge_id=grudge_id, grudge=editgrudge)


# # Delete a grudge - Protected -
@app.route('/grudget/<int:grudget_id>/grudge/<int:grudge_id>/delete', methods=['GET', 'POST'])
def deleteGrudge(grudget_id, grudge_id):
    if 'username' not in login_session:
        return redirect('/login')
    grudgeToDelete = session.query(Grudge).filter_by(id=grudge_id).one()
    if login_session['user_id'] != grudget.user_id:
        return ""<script>function myFunction() {alert('You are not authorized to delete any grudges not created by yourself. Please create your own grudges.');}</script><body onload='myFunction()'>""
    if request.method == 'POST':
        session.delete(grudgeToDelete)
        session.commit()
        return redirect(url_for('showGrudge', grudget_id=grudget_id))
    else:
        return render_template('deletegrudge.html', grudget_id=grudget_id, grudge=grudgeToDelete)



if __name__ == '__main__':
    app.secret_key = 'super_secret_key'
    app.debug = True
    app.run(host='0.0.0.0', port=5000)
/n/n/nlotsofgrudges.py/n/nfrom sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from database_setup import Grudget, Base, Grudge, User

engine = create_engine('sqlite:///grudgebucketwithusers.db')
# Bind the engine to the metadata of the Base class so that the
# declaratives can be accessed through a DBSession instance
Base.metadata.bind = engine

DBSession = sessionmaker(bind=engine)
# A DBSession() instance establishes all conversations with the database
# and represents a ""staging zone"" for all the objects loaded into the
# database session object. Any change made against the objects in the
# session won't be persisted into the database until you call
# session.commit(). If you're not happy about the changes, you can
# revert all of them back to the last commit by calling
# session.rollback()
session = DBSession()

#DumbDebby user
User1 = User(name=""Lorena Bobbett"", email=""lbobbett@hotmail.com"",
             picture='https://randomuser.me/api/portraits/women/71.jpg')
session.add(User1)
session.commit()

# Grudge Bucket for Strangers

grudget1 = Grudget(user_id=1,name=""Husbands Like John"")
session.add(grudget1)
session.commit()

grudge1 = Grudge(user_id=1,name=""Jerks who drink"", description=""These jerks use alcohol to escape their issues and then use their power over you"",
                     processed=""True"" , takeaway=""Avoid dating alcholics"", grudget=grudget1)

session.add(grudge1)
session.commit()


grudge2 = Grudge(user_id=1,name=""Whenever I want"", description=""Jerk who think women are at their mercy"",
                     processed=""True"", takeaway=""That mofo will never hurt another women again."", grudget=grudget1)

session.add(grudge2)
session.commit()


grudge3 = Grudge(user_id=1,name=""Creepy neighbor"", description=""While in college on a late night a neighbor flashed his schlong at me as I was putting my key in the door to my apt"",
                     processed=""False"",takeaway=""Unprocessed, I still hate that guy for doing that to me."", grudget=grudget1)

session.add(grudge3)
session.commit()



# Grudge Bucket for Bosses
grudget2 = Grudget(user_id=1,name=""Bosses"")

session.add(grudget2)
session.commit()


grudge4 = Grudge(user_id=1,name=""The non solicited editor"", description=""I once had a boss, who would spend hours editing my powerpoint presentations, because he didn't think I knew proper english"",
                     processed=""True"" ,takeaway=""Never be like him, always assume the best of people"", grudget=grudget2)

session.add(grudge4)
session.commit()


grudge5 = Grudge(user_id=1,name=""The AssHole"", description=""I had this boss that loved belitting people to the point of tears. Even when we attempted to warn him when he was going off the deep end he always ended up hurting his team to the point of tears."",
                     processed=""True"" ,takeaway=""Life is too short to put up with that type of bullshit"", grudget=grudget2)

session.add(grudge5)
session.commit()

# Grudge Bucket for Coworkers
grudget3 = Grudget(user_id=1,name=""CoWorkers"")

session.add(grudget3)
session.commit()


grudge6 = Grudge(user_id=1,name=""Take Credit for your work"", description=""I like to have treats in the office, chocolate, mints, etc. This was a new tradition I wanted to establish at the office. I heard an exec inquire about what an excellent idea that was and a coworker take credit for a treat jar that was at my desk, funded with chocolate of my own money"",
                     processed=""True"", takeaway=""low blow, let them have it. Truth will come to light"", grudget=grudget3)

session.add(grudge6)
session.commit()


grudge7 = Grudge(user_id=1,name=""BrownNoser"", description=""This person has no idea what they are doing professionally, but are very effective at establishing strong political relationships and talking about sports"",
                     processed=""True"", takeaway=""Always carry Poopari, to spray it on said coworker, and step up your sports game!"", grudget=grudget3)

session.add(grudge7)
session.commit()


print ""all grudges loaded, woot woot""
# print ""----> grudges_by(user.id):""
# query = session.query(Grudge)
# for _row in query.all():
#     print(_row.name, _row.description, _row.processed,_row.takeaway)
/n/n/n",0
65,65,0e771d89d1c8b20b5eedb1c2596570b6f3aaa488,"/database_setup.py/n/nfrom sqlalchemy import Column, ForeignKey, Integer, String
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from sqlalchemy import create_engine

Base = declarative_base()

class User(Base):
    __tablename__ = 'user'

    id = Column(Integer, primary_key=True)
    name = Column(String(250), nullable=False)
    email = Column(String(250), nullable=False)
    picture = Column(String(250))

class Grudget(Base):
    __tablename__ = 'Grudget'

    id = Column(Integer, primary_key=True)
    name = Column(String(250), nullable=False)
    user_id = Column(Integer, ForeignKey('user.id'))
    user = relationship(User)

    @property
    def serialize(self):
        """"""Return object data in easily serializeable format""""""
        return {
            'name': self.name,
            'id': self.id,
        }


class Grudge(Base):
    __tablename__ = 'Grudge'

    id = Column(Integer, primary_key=True)
    name = Column(String(80), nullable=False)
    description = Column(String(450),nullable=False)
    processed = Column(String(5))
    takeaway = Column(String(250))
    grudget_id = Column(Integer, ForeignKey('Grudget.id'))
    grudget = relationship(Grudget)
    user_id = Column(Integer, ForeignKey('user.id'))
    user = relationship(User)

    @property
    def serialize(self):
        """"""Return object data in easily serializeable format""""""
        return {
            'id': self.id,
            'name': self.name,
            'description': self.description,
            'processed': self.processed,
            'takeaway': self.takeaway,
        }


engine = create_engine('sqlite:///grudgebucketwithusers.db', connect_args={'check_same_thread': False})


Base.metadata.create_all(engine)
/n/n/n/finalproject.py/n/nfrom flask import Flask, render_template, request, redirect, jsonify, url_for, flash
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from database_setup import Grudget, Base, Grudge, User
from flask import session as login_session
import random
import string
from oauth2client.client import flow_from_clientsecrets
from oauth2client.client import FlowExchangeError
import httplib2
import json
from flask import make_response
import requests

app = Flask(__name__)

#Reminder to change application name one day
CLIENT_ID = json.loads(
    open('client_secrets.json', 'r').read())['web']['client_id']
APPLICATION_NAME = ""Grudget Catalog""

#Connect to database and create db session
engine = create_engine('sqlite:///grudgebucketwithusers.db', connect_args={'check_same_thread': False})
Base.metadata.bind = engine
DBSession = sessionmaker(bind=engine)
session = DBSession()

#Create anti-forgery state token

# Create anti-forgery state token
@app.route('/login')
def showLogin():
    state = ''.join(random.choice(string.ascii_uppercase + string.digits)
                    for x in xrange(32))
    login_session['state'] = state
    # return ""The current session state is %s"" % login_session['state']
    return render_template('login.html', STATE=state)


@app.route('/gconnect', methods=['POST'])
def gconnect():
    # Validate state token
    if request.args.get('state') != login_session['state']:
        response = make_response(json.dumps('Invalid state parameter.'), 401)
        response.headers['Content-Type'] = 'application/json'
        return response
    # Obtain authorization code
    code = request.data

    try:
        # Upgrade the authorization code into a credentials object
        oauth_flow = flow_from_clientsecrets('client_secrets.json', scope='')
        oauth_flow.redirect_uri = 'postmessage'
        credentials = oauth_flow.step2_exchange(code)
    except FlowExchangeError:
        response = make_response(
            json.dumps('Failed to upgrade the authorization code.'), 401)
        response.headers['Content-Type'] = 'application/json'
        return response

    # Check that the access token is valid.
    access_token = credentials.access_token
    url = ('https://www.googleapis.com/oauth2/v1/tokeninfo?access_token=%s'
           % access_token)
    h = httplib2.Http()
    result = json.loads(h.request(url, 'GET')[1])
    # If there was an error in the access token info, abort.
    if result.get('error') is not None:
        response = make_response(json.dumps(result.get('error')), 500)
        response.headers['Content-Type'] = 'application/json'
        return response

    # Verify that the access token is used for the intended user.
    gplus_id = credentials.id_token['sub']
    if result['user_id'] != gplus_id:
        response = make_response(
            json.dumps(""Token's user ID doesn't match given user ID.""), 401)
        response.headers['Content-Type'] = 'application/json'
        return response

    # Verify that the access token is valid for this app.
    if result['issued_to'] != CLIENT_ID:
        response = make_response(
            json.dumps(""Token's client ID does not match app's.""), 401)
        print ""Token's client ID does not match app's.""
        response.headers['Content-Type'] = 'application/json'
        return response

    stored_access_token = login_session.get('access_token')
    stored_gplus_id = login_session.get('gplus_id')
    if stored_access_token is not None and gplus_id == stored_gplus_id:
        response = make_response(json.dumps('Current user is already connected.'),
                                 200)
        response.headers['Content-Type'] = 'application/json'
        return response

    # Store the access token in the session for later use.
    login_session['access_token'] = credentials.access_token
    login_session['gplus_id'] = gplus_id

    # Get user info
    userinfo_url = ""https://www.googleapis.com/oauth2/v1/userinfo""
    params = {'access_token': credentials.access_token, 'alt': 'json'}
    answer = requests.get(userinfo_url, params=params)

    data = answer.json()

    login_session['username'] = data['name']
    login_session['picture'] = data['picture']
    login_session['email'] = data['email']

    output = ''
    output += '<h1>Welcome, '
    output += login_session['username']
    output += '!</h1>'
    output += '<img src=""'
    output += login_session['picture']
    output += ' "" style = ""width: 300px; height: 300px;border-radius: 150px;-webkit-border-radius: 150px;-moz-border-radius: 150px;""> '
    flash(""you are now logged in as %s"" % login_session['username'])
    print ""done!""
    return output


# Disconnect based on provider
@app.route('/logout')
def disconnect():
    if 'provider' in login_session:
        if login_session['provider'] == 'google':
            gdisconnect()
            del login_session['gplus_id']
            del login_session['access_token']
        if login_session['provider'] == 'facebook':
            fbdisconnect()
            del login_session['facebook_id']
        del login_session['username']
        del login_session['email']
        del login_session['picture']
        del login_session['user_id']
        del login_session['provider']
        flash(""You have successfully been logged out."")
        return redirect(url_for('showGrudgets'))
    else:
        flash(""You were not logged in"")
        return redirect(url_for('showGrudgets'))
# User Helper Functions


def createUser(login_session):
    newUser = User(name=login_session['username'], email=login_session[
                   'email'], picture=login_session['picture'])
    session.add(newUser)
    session.commit()
    user = session.query(User).filter_by(email=login_session['email']).one()
    return user.id


def getUserInfo(user_id):
    user = session.query(User).filter_by(id=user_id).one()
    return user


def getUserID(email):
    try:
        user = session.query(User).filter_by(email=email).one()
        return user.id
    except:
        return None

# DISCONNECT - Revoke a current user's token and reset their login_session




#JSON APIs to view the Grudge Buckets aka Grudgets and Grudges
@app.route('/grudget/<int:grudget_id>/grudge/JSON')
def grudgetGrudgeJSON(grudget_id):
    grudget = session.query(Grudget).filter_by(id=grudget_id).one()
    grudges = session.query(Grudge).filter_by(grudget_id=grudget.id).all()
    return jsonify(Grudge=[i.serialize for i in grudges])


@app.route('/grudget/<int:grudget_id>/grudge/<int:grudge_id>/JSON')
def grudgeJSON(grudget_id, grudge_id):
    grudge = session.query(Grudge).filter_by(id=grudge_id).one()
    return jsonify(grudge=Grudge.serialize)


@app.route('/grudget/JSON')
def grudgetsJSON():
    grudgets = session.query(Grudget).all()
    return jsonify(grudget=[g.serialize for g in grudgets])


# Show all grudgets/grudge buckets
@app.route('/')
@app.route('/grudget/')
def showGrudgets():
    grudgets = session.query(Grudget).all()
    if 'username' not in login_session:
        return render_template('publicgrudgets.html', grudgets=grudgets)
    else:
        return render_template('grudgets.html', grudgets=grudgets)
    

# Create a new grudge bucket aka grudget
@app.route('/grudget/new/', methods=['GET', 'POST'])
def newGrudget():
    if 'username' not in login_session:
        return redirect('/login')
    if request.method == 'POST':
        newGrudget = Grudget(name=request.form['name'])
        session.add(newGrudget)
        session.commit()
        return redirect(url_for('showGrudgets'))
    else:
        return render_template('newGrudget.html')


# # Edit a grudge bucket - should be protected, street cred
@app.route('/grudget/<int:grudget_id>/edit/', methods=['GET', 'POST'])
def editGrudget(grudget_id):
    editedGrudget = session.query(
        Grudget).filter_by(id=grudget_id).one()
    if 'username' not in login_session:
        return redirect('/login')
    if editGrudget.user_id != login_session['user_id']:
        return ""<script>function myFunction() {alert('As juicy as this is, you are not authorized to edit this grudget. Please create your own grudget in order to edit.');}</script><body onload='myFunction()'>""
    if request.method == 'POST':
        if request.form['name']:
            editedGrudget.name = request.form['name']
            return redirect(url_for('showGrudgets'))
    else:
        return render_template('editGrudget.html', grudget=editedGrudget)


# # Delete a grudge bucket - Protected
@app.route('/grudget/<int:grudget_id>/delete/', methods=['GET', 'POST'])
def deleteGrudget(grudget_id):
    grudgetToDelete = session.query(Grudget).filter_by(id=grudget_id).one()
    if 'username' not in login_session:
        return redirect('/login')
    if grudgetToDelete.user_id != login_session['user_id']:
        return ""<script>function myFunction() {alert('As juicy as this is, you are not authorized to delete this grudget. Please create your own grudget in order to edit.');}</script><body onload='myFunction()'>""
    if request.method == 'POST':
        session.delete(grudgetToDelete)
        session.commit()
        return redirect(
            url_for('showGrudgets', grudget_id=grudget_id))
    else:
        return render_template('deleteGrudget.html', grudget=grudgetToDelete)
 


# Show a grudge
@app.route('/grudget/<int:grudget_id>/')
@app.route('/grudget/<int:grudget_id>/grudge/')
def showGrudge(grudget_id):
    grudget = session.query(Grudget).filter_by(id=grudget_id).one()
    creator = getUserInfo(grudget.user_id)
    grudges = session.query(Grudge).filter_by(grudget_id=grudget_id).all()
    if 'username' not in login_session:
        return render_template('publicgrudges.html', grudges=grudges, id=grudget_id,grudget=grudget,creator=creator )
    else:
        return render_template('showgrudge.html', grudges=grudges, id=grudget_id, grudget=grudget, creator=creator)
 

# # Create a new grudge, SHOULD NOT BE PROTECTED
@app.route('/grudget/<int:grudget_id>/grudge/new/', methods=['GET', 'POST'])
def newGrudge(grudget_id):
    if 'username' not in login_session:
        return redirect('/login')
    grudget = session.query(Grudget).filter_by(id=grudget_id).one()
    # if login_session['user_id'] != grudget.user_id:
    #     return ""<script>function myFunction() {alert('You are not authorized to add a grudge to this grudget.');}</script><body onload='myFunction()'>""
    if request.method == 'POST':
            newGrudge = Grudge(name=request.form['name'], description=request.form[
                           'description'], processed=request.form['processed'], takeaway=request.form['takeaway'], grudget_id=grudget_id, user_id=login_session['user_id'])
            session.add(newGrudge)
            session.commit()
            return redirect(url_for('showGrudge', grudget_id=grudget_id))
    else:
        return render_template('newgrudge.html', grudget_id=grudget_id)


# # Edit a grudge - Protected
@app.route('/grudget/<int:grudget_id>/grudge/<int:grudge_id>/edit', methods=['GET', 'POST'])
def editGrudge(grudget_id, grudge_id):
    if 'username' not in login_session:
        return redirect('/login')
    editgrudge = session.query(Grudge).filter_by(id=grudge_id).one()
    grudget = session.query(Grudget).filter_by(id=grudget_id).one()
    if login_session['user_id'] != grudget.user_id:
        return ""<script>function myFunction() {alert('You are not authorized to edit this grudge.');}</script><body onload='myFunction()'>""
    if request.method == 'POST':
        if request.form['name']:
            editgrudge.name = request.form['name']
        if request.form['description']:
            editgrudge.description = request.form['description']
        if request.form['processed']:
            editgrudge.processed = request.form['processed']
        if request.form['takeaway']:
           editgrudge.takeaway = request.form['takeaway']
        session.add(editgrudge)
        session.commit()
        return redirect(url_for('showGrudge', grudget_id=grudget_id))
    else:
        return render_template('editgrudge.html', grudget_id=grudget_id, grudge_id=grudge_id, grudge=editgrudge)


# # Delete a grudge - Protected - do I need thsi before grudgetoDeletequery
@app.route('/grudget/<int:grudget_id>/grudge/<int:grudge_id>/delete', methods=['GET', 'POST'])
def deleteGrudge(grudget_id, grudge_id):
    if 'username' not in login_session:
        return redirect('/login')
    grudgeToDelete = session.query(Grudge).filter_by(id=grudge_id).one()
    if login_session['user_id'] != grudget.user_id:
        return ""<script>function myFunction() {alert('You are not authorized to delete any grudges not created by yourself. Please create your own grudges.');}</script><body onload='myFunction()'>""
    if request.method == 'POST':
        session.delete(grudgeToDelete)
        session.commit()
        return redirect(url_for('showGrudge', grudget_id=grudget_id))
    else:
        return render_template('deletegrudge.html', grudget_id=grudget_id, grudge=grudgeToDelete)



if __name__ == '__main__':
    app.secret_key = 'super_secret_key'
    app.debug = True
    app.run(host='0.0.0.0', port=5000)
/n/n/n",1
6,6,a1f948b468b6621083a03b0d53432341b7a4d753,"django/views/static.py/n/n""""""
Views and functions for serving static files. These are only to be used
during development, and SHOULD NOT be used in a production setting.
""""""
import mimetypes
import os
import posixpath
import re
import stat

from django.http import (
    FileResponse, Http404, HttpResponse, HttpResponseNotModified,
)
from django.template import Context, Engine, TemplateDoesNotExist, loader
from django.utils._os import safe_join
from django.utils.http import http_date, parse_http_date
from django.utils.translation import gettext as _, gettext_lazy


def serve(request, path, document_root=None, show_indexes=False):
    """"""
    Serve static files below a given point in the directory structure.

    To use, put a URL pattern such as::

        from django.views.static import serve

        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})

    in your URLconf. You must provide the ``document_root`` param. You may
    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index
    of the directory.  This index view will use the template hardcoded below,
    but if you'd like to override it, you can create a template called
    ``static/directory_index.html``.
    """"""
    path = posixpath.normpath(path).lstrip('/')
    fullpath = safe_join(document_root, path)
    if os.path.isdir(fullpath):
        if show_indexes:
            return directory_index(path, fullpath)
        raise Http404(_(""Directory indexes are not allowed here.""))
    if not os.path.exists(fullpath):
        raise Http404(_('""%(path)s"" does not exist') % {'path': fullpath})
    # Respect the If-Modified-Since header.
    statobj = os.stat(fullpath)
    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),
                              statobj.st_mtime, statobj.st_size):
        return HttpResponseNotModified()
    content_type, encoding = mimetypes.guess_type(fullpath)
    content_type = content_type or 'application/octet-stream'
    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)
    response[""Last-Modified""] = http_date(statobj.st_mtime)
    if stat.S_ISREG(statobj.st_mode):
        response[""Content-Length""] = statobj.st_size
    if encoding:
        response[""Content-Encoding""] = encoding
    return response


DEFAULT_DIRECTORY_INDEX_TEMPLATE = """"""
{% load i18n %}
<!DOCTYPE html>
<html lang=""en"">
  <head>
    <meta http-equiv=""Content-type"" content=""text/html; charset=utf-8"" />
    <meta http-equiv=""Content-Language"" content=""en-us"" />
    <meta name=""robots"" content=""NONE,NOARCHIVE"" />
    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>
  </head>
  <body>
    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>
    <ul>
      {% if directory != ""/"" %}
      <li><a href=""../"">../</a></li>
      {% endif %}
      {% for f in file_list %}
      <li><a href=""{{ f|urlencode }}"">{{ f }}</a></li>
      {% endfor %}
    </ul>
  </body>
</html>
""""""
template_translatable = gettext_lazy(""Index of %(directory)s"")


def directory_index(path, fullpath):
    try:
        t = loader.select_template([
            'static/directory_index.html',
            'static/directory_index',
        ])
    except TemplateDoesNotExist:
        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)
    files = []
    for f in os.listdir(fullpath):
        if not f.startswith('.'):
            if os.path.isdir(os.path.join(fullpath, f)):
                f += '/'
            files.append(f)
    c = Context({
        'directory': path + '/',
        'file_list': files,
    })
    return HttpResponse(t.render(c))


def was_modified_since(header=None, mtime=0, size=0):
    """"""
    Was something modified since the user last downloaded it?

    header
      This is the value of the If-Modified-Since header.  If this is None,
      I'll just return True.

    mtime
      This is the modification time of the item we're talking about.

    size
      This is the size of the item we're talking about.
    """"""
    try:
        if header is None:
            raise ValueError
        matches = re.match(r""^([^;]+)(; length=([0-9]+))?$"", header,
                           re.IGNORECASE)
        header_mtime = parse_http_date(matches.group(1))
        header_len = matches.group(3)
        if header_len and int(header_len) != size:
            raise ValueError
        if int(mtime) > header_mtime:
            raise ValueError
    except (AttributeError, ValueError, OverflowError):
        return True
    return False
/n/n/ntests/view_tests/tests/test_static.py/n/nimport mimetypes
import unittest
from os import path
from urllib.parse import quote

from django.conf.urls.static import static
from django.core.exceptions import ImproperlyConfigured
from django.http import FileResponse, HttpResponseNotModified
from django.test import SimpleTestCase, override_settings
from django.utils.http import http_date
from django.views.static import was_modified_since

from .. import urls
from ..urls import media_dir


@override_settings(DEBUG=True, ROOT_URLCONF='view_tests.urls')
class StaticTests(SimpleTestCase):
    """"""Tests django views in django/views/static.py""""""

    prefix = 'site_media'

    def test_serve(self):
        ""The static view can serve static media""
        media_files = ['file.txt', 'file.txt.gz', '%2F.txt']
        for filename in media_files:
            response = self.client.get('/%s/%s' % (self.prefix, quote(filename)))
            response_content = b''.join(response)
            file_path = path.join(media_dir, filename)
            with open(file_path, 'rb') as fp:
                self.assertEqual(fp.read(), response_content)
            self.assertEqual(len(response_content), int(response['Content-Length']))
            self.assertEqual(mimetypes.guess_type(file_path)[1], response.get('Content-Encoding', None))

    def test_chunked(self):
        ""The static view should stream files in chunks to avoid large memory usage""
        response = self.client.get('/%s/%s' % (self.prefix, 'long-line.txt'))
        first_chunk = next(response.streaming_content)
        self.assertEqual(len(first_chunk), FileResponse.block_size)
        second_chunk = next(response.streaming_content)
        response.close()
        # strip() to prevent OS line endings from causing differences
        self.assertEqual(len(second_chunk.strip()), 1449)

    def test_unknown_mime_type(self):
        response = self.client.get('/%s/file.unknown' % self.prefix)
        self.assertEqual('application/octet-stream', response['Content-Type'])
        response.close()

    def test_copes_with_empty_path_component(self):
        file_name = 'file.txt'
        response = self.client.get('/%s//%s' % (self.prefix, file_name))
        response_content = b''.join(response)
        with open(path.join(media_dir, file_name), 'rb') as fp:
            self.assertEqual(fp.read(), response_content)

    def test_is_modified_since(self):
        file_name = 'file.txt'
        response = self.client.get(
            '/%s/%s' % (self.prefix, file_name),
            HTTP_IF_MODIFIED_SINCE='Thu, 1 Jan 1970 00:00:00 GMT'
        )
        response_content = b''.join(response)
        with open(path.join(media_dir, file_name), 'rb') as fp:
            self.assertEqual(fp.read(), response_content)

    def test_not_modified_since(self):
        file_name = 'file.txt'
        response = self.client.get(
            '/%s/%s' % (self.prefix, file_name),
            HTTP_IF_MODIFIED_SINCE='Mon, 18 Jan 2038 05:14:07 GMT'
            # This is 24h before max Unix time. Remember to fix Django and
            # update this test well before 2038 :)
        )
        self.assertIsInstance(response, HttpResponseNotModified)

    def test_invalid_if_modified_since(self):
        """"""Handle bogus If-Modified-Since values gracefully

        Assume that a file is modified since an invalid timestamp as per RFC
        2616, section 14.25.
        """"""
        file_name = 'file.txt'
        invalid_date = 'Mon, 28 May 999999999999 28:25:26 GMT'
        response = self.client.get('/%s/%s' % (self.prefix, file_name),
                                   HTTP_IF_MODIFIED_SINCE=invalid_date)
        response_content = b''.join(response)
        with open(path.join(media_dir, file_name), 'rb') as fp:
            self.assertEqual(fp.read(), response_content)
        self.assertEqual(len(response_content), int(response['Content-Length']))

    def test_invalid_if_modified_since2(self):
        """"""Handle even more bogus If-Modified-Since values gracefully

        Assume that a file is modified since an invalid timestamp as per RFC
        2616, section 14.25.
        """"""
        file_name = 'file.txt'
        invalid_date = ': 1291108438, Wed, 20 Oct 2010 14:05:00 GMT'
        response = self.client.get('/%s/%s' % (self.prefix, file_name),
                                   HTTP_IF_MODIFIED_SINCE=invalid_date)
        response_content = b''.join(response)
        with open(path.join(media_dir, file_name), 'rb') as fp:
            self.assertEqual(fp.read(), response_content)
        self.assertEqual(len(response_content), int(response['Content-Length']))

    def test_404(self):
        response = self.client.get('/%s/nonexistent_resource' % self.prefix)
        self.assertEqual(404, response.status_code)

    def test_index(self):
        response = self.client.get('/%s/' % self.prefix)
        self.assertContains(response, 'Index of ./')


class StaticHelperTest(StaticTests):
    """"""
    Test case to make sure the static URL pattern helper works as expected
    """"""
    def setUp(self):
        super().setUp()
        self._old_views_urlpatterns = urls.urlpatterns[:]
        urls.urlpatterns += static('/media/', document_root=media_dir)

    def tearDown(self):
        super().tearDown()
        urls.urlpatterns = self._old_views_urlpatterns

    def test_prefix(self):
        self.assertEqual(static('test')[0].regex.pattern, '^test(?P<path>.*)$')

    @override_settings(DEBUG=False)
    def test_debug_off(self):
        """"""No URLs are served if DEBUG=False.""""""
        self.assertEqual(static('test'), [])

    def test_empty_prefix(self):
        with self.assertRaisesMessage(ImproperlyConfigured, 'Empty static prefix not permitted'):
            static('')

    def test_special_prefix(self):
        """"""No URLs are served if prefix contains '://'.""""""
        self.assertEqual(static('http://'), [])


class StaticUtilsTests(unittest.TestCase):
    def test_was_modified_since_fp(self):
        """"""
        A floating point mtime does not disturb was_modified_since (#18675).
        """"""
        mtime = 1343416141.107817
        header = http_date(mtime)
        self.assertFalse(was_modified_since(header, mtime))
/n/n/n",0
7,7,a1f948b468b6621083a03b0d53432341b7a4d753,"/django/views/static.py/n/n""""""
Views and functions for serving static files. These are only to be used
during development, and SHOULD NOT be used in a production setting.
""""""
import mimetypes
import os
import posixpath
import re
import stat

from django.http import (
    FileResponse, Http404, HttpResponse, HttpResponseNotModified,
    HttpResponseRedirect,
)
from django.template import Context, Engine, TemplateDoesNotExist, loader
from django.utils.http import http_date, parse_http_date
from django.utils.translation import gettext as _, gettext_lazy


def serve(request, path, document_root=None, show_indexes=False):
    """"""
    Serve static files below a given point in the directory structure.

    To use, put a URL pattern such as::

        from django.views.static import serve

        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})

    in your URLconf. You must provide the ``document_root`` param. You may
    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index
    of the directory.  This index view will use the template hardcoded below,
    but if you'd like to override it, you can create a template called
    ``static/directory_index.html``.
    """"""
    path = posixpath.normpath(path)
    path = path.lstrip('/')
    newpath = ''
    for part in path.split('/'):
        if not part:
            # Strip empty path components.
            continue
        drive, part = os.path.splitdrive(part)
        head, part = os.path.split(part)
        if part in (os.curdir, os.pardir):
            # Strip '.' and '..' in path.
            continue
        newpath = os.path.join(newpath, part).replace('\\', '/')
    if newpath and path != newpath:
        return HttpResponseRedirect(newpath)
    fullpath = os.path.join(document_root, newpath)
    if os.path.isdir(fullpath):
        if show_indexes:
            return directory_index(newpath, fullpath)
        raise Http404(_(""Directory indexes are not allowed here.""))
    if not os.path.exists(fullpath):
        raise Http404(_('""%(path)s"" does not exist') % {'path': fullpath})
    # Respect the If-Modified-Since header.
    statobj = os.stat(fullpath)
    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),
                              statobj.st_mtime, statobj.st_size):
        return HttpResponseNotModified()
    content_type, encoding = mimetypes.guess_type(fullpath)
    content_type = content_type or 'application/octet-stream'
    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)
    response[""Last-Modified""] = http_date(statobj.st_mtime)
    if stat.S_ISREG(statobj.st_mode):
        response[""Content-Length""] = statobj.st_size
    if encoding:
        response[""Content-Encoding""] = encoding
    return response


DEFAULT_DIRECTORY_INDEX_TEMPLATE = """"""
{% load i18n %}
<!DOCTYPE html>
<html lang=""en"">
  <head>
    <meta http-equiv=""Content-type"" content=""text/html; charset=utf-8"" />
    <meta http-equiv=""Content-Language"" content=""en-us"" />
    <meta name=""robots"" content=""NONE,NOARCHIVE"" />
    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>
  </head>
  <body>
    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>
    <ul>
      {% if directory != ""/"" %}
      <li><a href=""../"">../</a></li>
      {% endif %}
      {% for f in file_list %}
      <li><a href=""{{ f|urlencode }}"">{{ f }}</a></li>
      {% endfor %}
    </ul>
  </body>
</html>
""""""
template_translatable = gettext_lazy(""Index of %(directory)s"")


def directory_index(path, fullpath):
    try:
        t = loader.select_template([
            'static/directory_index.html',
            'static/directory_index',
        ])
    except TemplateDoesNotExist:
        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)
    files = []
    for f in os.listdir(fullpath):
        if not f.startswith('.'):
            if os.path.isdir(os.path.join(fullpath, f)):
                f += '/'
            files.append(f)
    c = Context({
        'directory': path + '/',
        'file_list': files,
    })
    return HttpResponse(t.render(c))


def was_modified_since(header=None, mtime=0, size=0):
    """"""
    Was something modified since the user last downloaded it?

    header
      This is the value of the If-Modified-Since header.  If this is None,
      I'll just return True.

    mtime
      This is the modification time of the item we're talking about.

    size
      This is the size of the item we're talking about.
    """"""
    try:
        if header is None:
            raise ValueError
        matches = re.match(r""^([^;]+)(; length=([0-9]+))?$"", header,
                           re.IGNORECASE)
        header_mtime = parse_http_date(matches.group(1))
        header_len = matches.group(3)
        if header_len and int(header_len) != size:
            raise ValueError
        if int(mtime) > header_mtime:
            raise ValueError
    except (AttributeError, ValueError, OverflowError):
        return True
    return False
/n/n/n",1
12,12,22b6ecb953bbf40f0394a8bfd41d71a3f16e3465,"mozilla_django_oidc/views.py/n/nimport time
try:
    from urllib.parse import urlencode
except ImportError:
    # Python < 3
    from urllib import urlencode

import django
from django.core.exceptions import SuspiciousOperation
from django.core.urlresolvers import reverse
from django.contrib import auth
from django.http import HttpResponseRedirect
from django.utils.crypto import get_random_string
from django.utils.http import is_safe_url
from django.utils.module_loading import import_string
from django.views.generic import View

from mozilla_django_oidc.utils import (
    absolutify,
    import_from_settings,
    is_authenticated,
)


class OIDCAuthenticationCallbackView(View):
    """"""OIDC client authentication callback HTTP endpoint""""""

    http_method_names = ['get']

    @property
    def failure_url(self):
        return import_from_settings('LOGIN_REDIRECT_URL_FAILURE', '/')

    @property
    def success_url(self):
        # Pull the next url from the session or settings--we don't need to
        # sanitize here because it should already have been sanitized.
        next_url = self.request.session.get('oidc_login_next', None)
        return next_url or import_from_settings('LOGIN_REDIRECT_URL', '/')

    def login_failure(self):
        return HttpResponseRedirect(self.failure_url)

    def login_success(self):
        auth.login(self.request, self.user)

        # Figure out when this id_token will expire. This is ignored unless you're
        # using the RenewIDToken middleware.
        expiration_interval = import_from_settings('OIDC_RENEW_ID_TOKEN_EXPIRY_SECONDS', 60 * 15)
        self.request.session['oidc_id_token_expiration'] = time.time() + expiration_interval

        return HttpResponseRedirect(self.success_url)

    def get(self, request):
        """"""Callback handler for OIDC authorization code flow""""""

        nonce = request.session.get('oidc_nonce')
        if nonce:
            # Make sure that nonce is not used twice
            del request.session['oidc_nonce']

        if 'code' in request.GET and 'state' in request.GET:
            kwargs = {
                'request': request,
                'nonce': nonce,
            }

            if 'oidc_state' not in request.session:
                return self.login_failure()

            if request.GET['state'] != request.session['oidc_state']:
                msg = 'Session `oidc_state` does not match the OIDC callback state'
                raise SuspiciousOperation(msg)

            self.user = auth.authenticate(**kwargs)

            if self.user and self.user.is_active:
                return self.login_success()
        return self.login_failure()


def get_next_url(request, redirect_field_name):
    """"""Retrieves next url from request

    Note: This verifies that the url is safe before returning it. If the url
    is not safe, this returns None.

    :arg HttpRequest request: the http request
    :arg str redirect_field_name: the name of the field holding the next url

    :returns: safe url or None

    """"""
    next_url = request.GET.get(redirect_field_name)
    if next_url:
        kwargs = {
            'url': next_url,
            'host': request.get_host()
        }
        # NOTE(willkg): Django 1.11+ allows us to require https, too.
        if django.VERSION >= (1, 11):
            kwargs['require_https'] = request.is_secure()
        is_safe = is_safe_url(**kwargs)
        if is_safe:
            return next_url
    return None


class OIDCAuthenticationRequestView(View):
    """"""OIDC client authentication HTTP endpoint""""""

    http_method_names = ['get']

    def __init__(self, *args, **kwargs):
        super(OIDCAuthenticationRequestView, self).__init__(*args, **kwargs)

        self.OIDC_OP_AUTH_ENDPOINT = import_from_settings('OIDC_OP_AUTHORIZATION_ENDPOINT')
        self.OIDC_RP_CLIENT_ID = import_from_settings('OIDC_RP_CLIENT_ID')

    def get(self, request):
        """"""OIDC client authentication initialization HTTP endpoint""""""
        state = get_random_string(import_from_settings('OIDC_STATE_SIZE', 32))
        redirect_field_name = import_from_settings('OIDC_REDIRECT_FIELD_NAME', 'next')

        params = {
            'response_type': 'code',
            'scope': 'openid',
            'client_id': self.OIDC_RP_CLIENT_ID,
            'redirect_uri': absolutify(
                request,
                reverse('oidc_authentication_callback')
            ),
            'state': state,
        }

        if import_from_settings('OIDC_USE_NONCE', True):
            nonce = get_random_string(import_from_settings('OIDC_NONCE_SIZE', 32))
            params.update({
                'nonce': nonce
            })
            request.session['oidc_nonce'] = nonce

        request.session['oidc_state'] = state
        request.session['oidc_login_next'] = get_next_url(request, redirect_field_name)

        query = urlencode(params)
        redirect_url = '{url}?{query}'.format(url=self.OIDC_OP_AUTH_ENDPOINT, query=query)
        return HttpResponseRedirect(redirect_url)


class OIDCLogoutView(View):
    """"""Logout helper view""""""

    http_method_names = ['get', 'post']

    @property
    def redirect_url(self):
        """"""Return the logout url defined in settings.""""""
        return import_from_settings('LOGOUT_REDIRECT_URL', '/')

    def post(self, request):
        """"""Log out the user.""""""
        logout_url = self.redirect_url

        if is_authenticated(request.user):
            # Check if a method exists to build the URL to log out the user
            # from the OP.
            logout_from_op = import_from_settings('OIDC_OP_LOGOUT_URL_METHOD', '')
            if logout_from_op:
                logout_url = import_string(logout_from_op)()

            # Log out the Django user, only if she was actually logged in.
            auth.logout(request)

        return HttpResponseRedirect(logout_url)
/n/n/ntests/test_views.py/n/ntry:
    from urllib.parse import parse_qs, urlparse
except ImportError:
    # Python < 3
    from urlparse import parse_qs, urlparse

from mock import patch

import django
from django.core.exceptions import SuspiciousOperation
from django.contrib.auth import get_user_model
from django.contrib.auth.models import AnonymousUser
from django.core.urlresolvers import reverse
from django.test import RequestFactory, TestCase, override_settings

from mozilla_django_oidc import views


User = get_user_model()


def my_custom_op_logout(*args, **kwargs):
    return 'http://example.com/logged/out'


class OIDCAuthorizationCallbackViewTestCase(TestCase):
    def setUp(self):
        self.factory = RequestFactory()

    @override_settings(LOGIN_REDIRECT_URL='/success')
    def test_get_auth_success(self):
        """"""Test successful callback request to RP.""""""
        user = User.objects.create_user('example_username')

        get_data = {
            'code': 'example_code',
            'state': 'example_state'
        }
        url = reverse('oidc_authentication_callback')
        request = self.factory.get(url, get_data)
        request.session = {
            'oidc_state': 'example_state'
        }
        callback_view = views.OIDCAuthenticationCallbackView.as_view()

        with patch('mozilla_django_oidc.views.auth.authenticate') as mock_auth:
            with patch('mozilla_django_oidc.views.auth.login') as mock_login:
                mock_auth.return_value = user
                response = callback_view(request)

                mock_auth.assert_called_once_with(nonce=None,
                                                  request=request)
                mock_login.assert_called_once_with(request, user)

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response.url, '/success')

    @override_settings(LOGIN_REDIRECT_URL='/success')
    def test_get_auth_success_next_url(self):
        """"""Test successful callback request to RP with custom `next` url.""""""
        user = User.objects.create_user('example_username')

        get_data = {
            'code': 'example_code',
            'state': 'example_state'
        }
        url = reverse('oidc_authentication_callback')
        request = self.factory.get(url, get_data)
        request.session = {
            'oidc_state': 'example_state',
            'oidc_login_next': '/foobar'
        }
        callback_view = views.OIDCAuthenticationCallbackView.as_view()

        with patch('mozilla_django_oidc.views.auth.authenticate') as mock_auth:
            with patch('mozilla_django_oidc.views.auth.login') as mock_login:
                mock_auth.return_value = user
                response = callback_view(request)

                mock_auth.assert_called_once_with(nonce=None,
                                                  request=request)
                mock_login.assert_called_once_with(request, user)

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response.url, '/foobar')

    @override_settings(LOGIN_REDIRECT_URL_FAILURE='/failure')
    def test_get_auth_failure_nonexisting_user(self):
        """"""Test unsuccessful authentication and redirect url.""""""
        get_data = {
            'code': 'example_code',
            'state': 'example_state'
        }

        url = reverse('oidc_authentication_callback')
        request = self.factory.get(url, get_data)
        request.session = {
            'oidc_state': 'example_state'
        }
        callback_view = views.OIDCAuthenticationCallbackView.as_view()

        with patch('mozilla_django_oidc.views.auth.authenticate') as mock_auth:
            mock_auth.return_value = None
            response = callback_view(request)

            mock_auth.assert_called_once_with(nonce=None,
                                              request=request)

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response.url, '/failure')

    @override_settings(LOGIN_REDIRECT_URL_FAILURE='/failure')
    def test_get_auth_failure_inactive_user(self):
        """"""Test authentication failure attempt for an inactive user.""""""
        user = User.objects.create_user('example_username')
        user.is_active = False
        user.save()

        get_data = {
            'code': 'example_code',
            'state': 'example_state'
        }

        url = reverse('oidc_authentication_callback')
        request = self.factory.get(url, get_data)
        request.session = {
            'oidc_state': 'example_state'
        }
        callback_view = views.OIDCAuthenticationCallbackView.as_view()

        with patch('mozilla_django_oidc.views.auth.authenticate') as mock_auth:
            mock_auth.return_value = user
            response = callback_view(request)

            mock_auth.assert_called_once_with(request=request,
                                              nonce=None)

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response.url, '/failure')

    @override_settings(OIDC_USE_NONCE=False)
    @override_settings(LOGIN_REDIRECT_URL_FAILURE='/failure')
    def test_get_auth_dirty_data(self):
        """"""Test authentication attempt with wrong get data.""""""
        get_data = {
            'foo': 'bar',
        }

        url = reverse('oidc_authentication_callback')
        request = self.factory.get(url, get_data)
        request.session = {}
        callback_view = views.OIDCAuthenticationCallbackView.as_view()
        response = callback_view(request)
        self.assertEqual(response.status_code, 302)
        self.assertEqual(response.url, '/failure')

    @override_settings(LOGIN_REDIRECT_URL_FAILURE='/failure')
    def test_get_auth_failure_missing_session_state(self):
        """"""Test authentication failure attempt for an inactive user.""""""
        user = User.objects.create_user('example_username')
        user.is_active = False
        user.save()

        get_data = {
            'code': 'example_code',
            'state': 'example_state'
        }

        url = reverse('oidc_authentication_callback')
        request = self.factory.get(url, get_data)
        request.session = {
        }
        callback_view = views.OIDCAuthenticationCallbackView.as_view()

        response = callback_view(request)

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response.url, '/failure')

    @override_settings(LOGIN_REDIRECT_URL_FAILURE='/failure')
    def test_get_auth_failure_tampered_session_state(self):
        """"""Test authentication failure attempt for an inactive user.""""""
        user = User.objects.create_user('example_username')
        user.is_active = False
        user.save()

        get_data = {
            'code': 'example_code',
            'state': 'example_state'
        }

        url = reverse('oidc_authentication_callback')
        request = self.factory.get(url, get_data)
        request.session = {
            'oidc_state': 'tampered_state'
        }
        callback_view = views.OIDCAuthenticationCallbackView.as_view()

        with self.assertRaises(SuspiciousOperation) as context:
            callback_view(request)

        expected_error_message = 'Session `oidc_state` does not match the OIDC callback state'
        self.assertEqual(context.exception.args, (expected_error_message,))

    @override_settings(LOGIN_REDIRECT_URL='/success')
    def test_nonce_is_deleted(self):
        """"""Test Nonce is not in session.""""""
        user = User.objects.create_user('example_username')

        get_data = {
            'code': 'example_code',
            'state': 'example_state'
        }
        url = reverse('oidc_authentication_callback')
        request = self.factory.get(url, get_data)
        request.session = {
            'oidc_state': 'example_state',
            'oidc_nonce': 'example_nonce'
        }
        callback_view = views.OIDCAuthenticationCallbackView.as_view()

        with patch('mozilla_django_oidc.views.auth.authenticate') as mock_auth:
            with patch('mozilla_django_oidc.views.auth.login') as mock_login:
                mock_auth.return_value = user
                response = callback_view(request)

                mock_auth.assert_called_once_with(nonce='example_nonce',
                                                  request=request)
                mock_login.assert_called_once_with(request, user)

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response.url, '/success')
        self.assertTrue('oidc_nonce' not in request.session)


class GetNextURLTestCase(TestCase):
    def setUp(self):
        self.factory = RequestFactory()

    def build_request(self, next_url):
        return self.factory.get('/', data={'next': next_url})

    def test_no_param(self):
        req = self.factory.get('/')
        next_url = views.get_next_url(req, 'next')
        self.assertEqual(next_url, None)

    def test_non_next_param(self):
        req = self.factory.get('/', data={'redirectto': '/foo'})
        next_url = views.get_next_url(req, 'redirectto')
        self.assertEqual(next_url, '/foo')

    def test_good_urls(self):
        urls = [
            '/',
            '/foo',
            '/foo?bar=baz',
            'http://testserver/foo',
        ]
        for url in urls:
            req = self.build_request(next_url=url)
            next_url = views.get_next_url(req, 'next')

            self.assertEqual(next_url, url)

    def test_bad_urls(self):
        urls = [
            '',
            # NOTE(willkg): Test data taken from the Django is_safe_url tests.
            'http://example.com',
            'http:///example.com',
            'https://example.com',
            'ftp://example.com',
            r'\\example.com',
            r'\\\example.com',
            r'/\\/example.com',
            r'\\\example.com',
            r'\\example.com',
            r'\\//example.com',
            r'/\/example.com',
            r'\/example.com',
            r'/\example.com',
            'http:///example.com',
            r'http:/\//example.com',
            r'http:\/example.com',
            r'http:/\example.com',
            'javascript:alert(""XSS"")',
            '\njavascript:alert(x)',
            '\x08//example.com',
            r'http://otherserver\@example.com',
            r'http:\\testserver\@example.com',
            r'http://testserver\me:pass@example.com',
            r'http://testserver\@example.com',
            r'http:\\testserver\confirm\me@example.com',
            'http:999999999',
            'ftp:9999999999',
            '\n',
        ]
        for url in urls:
            req = self.build_request(next_url=url)
            next_url = views.get_next_url(req, 'next')

            self.assertEqual(next_url, None)

    def test_https(self):
        # If the request is for HTTPS and the next url is HTTPS, then that
        # works with all Djangos.
        req = self.factory.get(
            '/',
            data={'next': 'https://testserver/foo'},
            secure=True,
        )
        self.assertEquals(req.is_secure(), True)
        next_url = views.get_next_url(req, 'next')
        self.assertEqual(next_url, 'https://testserver/foo')

        # For Django 1.11+, if the request is for HTTPS and the next url is
        # HTTP, then that fails.
        if django.VERSION >= (1, 11):
            req = self.factory.get(
                '/',
                data={'next': 'http://testserver/foo'},
                secure=True,
            )
            self.assertEquals(req.is_secure(), True)
            next_url = views.get_next_url(req, 'next')
            self.assertEqual(next_url, None)


class OIDCAuthorizationRequestViewTestCase(TestCase):
    def setUp(self):
        self.factory = RequestFactory()

    @override_settings(OIDC_OP_AUTHORIZATION_ENDPOINT='https://server.example.com/auth')
    @override_settings(OIDC_RP_CLIENT_ID='example_id')
    @patch('mozilla_django_oidc.views.get_random_string')
    def test_get(self, mock_random_string):
        """"""Test initiation of a successful OIDC attempt.""""""
        mock_random_string.return_value = 'examplestring'
        url = reverse('oidc_authentication_init')
        request = self.factory.get(url)
        request.session = dict()
        login_view = views.OIDCAuthenticationRequestView.as_view()
        response = login_view(request)
        self.assertEqual(response.status_code, 302)

        o = urlparse(response.url)
        expected_query = {
            'response_type': ['code'],
            'scope': ['openid'],
            'client_id': ['example_id'],
            'redirect_uri': ['http://testserver/callback/'],
            'state': ['examplestring'],
            'nonce': ['examplestring']
        }
        self.assertDictEqual(parse_qs(o.query), expected_query)
        self.assertEqual(o.hostname, 'server.example.com')
        self.assertEqual(o.path, '/auth')

    @override_settings(OIDC_OP_AUTHORIZATION_ENDPOINT='https://server.example.com/auth')
    @override_settings(OIDC_RP_CLIENT_ID='example_id')
    def test_next_url(self):
        """"""Test that `next` url gets stored to user session.""""""
        url = reverse('oidc_authentication_init')
        request = self.factory.get('{url}?{params}'.format(url=url, params='next=/foo'))
        request.session = dict()
        login_view = views.OIDCAuthenticationRequestView.as_view()
        login_view(request)
        self.assertTrue('oidc_login_next' in request.session)
        self.assertEqual(request.session['oidc_login_next'], '/foo')

    @override_settings(OIDC_OP_AUTHORIZATION_ENDPOINT='https://server.example.com/auth')
    @override_settings(OIDC_RP_CLIENT_ID='example_id')
    def test_missing_next_url(self):
        """"""Test that `next` url gets invalidated in user session.""""""
        url = reverse('oidc_authentication_init')
        request = self.factory.get(url)
        request.session = {
            'oidc_login_next': 'foobar'
        }
        login_view = views.OIDCAuthenticationRequestView.as_view()
        login_view(request)
        self.assertTrue('oidc_login_next' in request.session)
        self.assertTrue(request.session['oidc_login_next'] is None)


class OIDCLogoutViewTestCase(TestCase):
    def setUp(self):
        self.factory = RequestFactory()

    @override_settings(LOGOUT_REDIRECT_URL='/example-logout')
    def test_get_anonymous_user(self):
        url = reverse('oidc_logout')
        request = self.factory.post(url)
        request.user = AnonymousUser()
        logout_view = views.OIDCLogoutView.as_view()

        response = logout_view(request)
        self.assertEqual(response.status_code, 302)
        self.assertEqual(response.url, '/example-logout')

    @override_settings(LOGOUT_REDIRECT_URL='/example-logout')
    def test_post(self):
        user = User.objects.create_user('example_username')
        url = reverse('oidc_logout')
        request = self.factory.post(url)
        request.user = user
        logout_view = views.OIDCLogoutView.as_view()

        with patch('mozilla_django_oidc.views.auth.logout') as mock_logout:
            response = logout_view(request)
            mock_logout.assert_called_once_with(request)

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response.url, '/example-logout')

    @override_settings(LOGOUT_REDIRECT_URL='/example-logout')
    @override_settings(OIDC_OP_LOGOUT_URL_METHOD='tests.test_views.my_custom_op_logout')
    def test_post_with_OIDC_OP_LOGOUT_URL_METHOD(self):
        user = User.objects.create_user('example_username')
        url = reverse('oidc_logout')
        request = self.factory.post(url)
        request.user = user
        logout_view = views.OIDCLogoutView.as_view()

        with patch('mozilla_django_oidc.views.auth.logout') as mock_logout:
            response = logout_view(request)
            mock_logout.assert_called_once_with(request)

        self.assertEqual(response.status_code, 302)
        self.assertEqual(response.url, 'http://example.com/logged/out')
/n/n/n",0
13,13,22b6ecb953bbf40f0394a8bfd41d71a3f16e3465,"/mozilla_django_oidc/views.py/n/nimport time
try:
    from urllib.parse import urlencode
except ImportError:
    # Python < 3
    from urllib import urlencode

from django.core.exceptions import SuspiciousOperation
from django.core.urlresolvers import reverse
from django.contrib import auth
from django.http import HttpResponseRedirect
from django.utils.crypto import get_random_string
from django.utils.module_loading import import_string
from django.views.generic import View

from mozilla_django_oidc.utils import (
    absolutify,
    import_from_settings,
    is_authenticated,
)


class OIDCAuthenticationCallbackView(View):
    """"""OIDC client authentication callback HTTP endpoint""""""

    http_method_names = ['get']

    @property
    def failure_url(self):
        return import_from_settings('LOGIN_REDIRECT_URL_FAILURE', '/')

    @property
    def success_url(self):
        next_url = self.request.session.get('oidc_login_next', None)
        return next_url or import_from_settings('LOGIN_REDIRECT_URL', '/')

    def login_failure(self):
        return HttpResponseRedirect(self.failure_url)

    def login_success(self):
        auth.login(self.request, self.user)

        # Figure out when this id_token will expire. This is ignored unless you're
        # using the RenewIDToken middleware.
        expiration_interval = import_from_settings('OIDC_RENEW_ID_TOKEN_EXPIRY_SECONDS', 60 * 15)
        self.request.session['oidc_id_token_expiration'] = time.time() + expiration_interval

        return HttpResponseRedirect(self.success_url)

    def get(self, request):
        """"""Callback handler for OIDC authorization code flow""""""

        nonce = request.session.get('oidc_nonce')
        if nonce:
            # Make sure that nonce is not used twice
            del request.session['oidc_nonce']

        if 'code' in request.GET and 'state' in request.GET:
            kwargs = {
                'request': request,
                'nonce': nonce,
            }

            if 'oidc_state' not in request.session:
                return self.login_failure()

            if request.GET['state'] != request.session['oidc_state']:
                msg = 'Session `oidc_state` does not match the OIDC callback state'
                raise SuspiciousOperation(msg)

            self.user = auth.authenticate(**kwargs)

            if self.user and self.user.is_active:
                return self.login_success()
        return self.login_failure()


class OIDCAuthenticationRequestView(View):
    """"""OIDC client authentication HTTP endpoint""""""

    http_method_names = ['get']

    def __init__(self, *args, **kwargs):
        super(OIDCAuthenticationRequestView, self).__init__(*args, **kwargs)

        self.OIDC_OP_AUTH_ENDPOINT = import_from_settings('OIDC_OP_AUTHORIZATION_ENDPOINT')
        self.OIDC_RP_CLIENT_ID = import_from_settings('OIDC_RP_CLIENT_ID')

    def get(self, request):
        """"""OIDC client authentication initialization HTTP endpoint""""""
        state = get_random_string(import_from_settings('OIDC_STATE_SIZE', 32))
        redirect_field_name = import_from_settings('OIDC_REDIRECT_FIELD_NAME', 'next')

        params = {
            'response_type': 'code',
            'scope': 'openid',
            'client_id': self.OIDC_RP_CLIENT_ID,
            'redirect_uri': absolutify(
                request,
                reverse('oidc_authentication_callback')
            ),
            'state': state,
        }

        if import_from_settings('OIDC_USE_NONCE', True):
            nonce = get_random_string(import_from_settings('OIDC_NONCE_SIZE', 32))
            params.update({
                'nonce': nonce
            })
            request.session['oidc_nonce'] = nonce

        request.session['oidc_state'] = state
        request.session['oidc_login_next'] = request.GET.get(redirect_field_name)

        query = urlencode(params)
        redirect_url = '{url}?{query}'.format(url=self.OIDC_OP_AUTH_ENDPOINT, query=query)
        return HttpResponseRedirect(redirect_url)


class OIDCLogoutView(View):
    """"""Logout helper view""""""

    http_method_names = ['get', 'post']

    @property
    def redirect_url(self):
        """"""Return the logout url defined in settings.""""""
        return import_from_settings('LOGOUT_REDIRECT_URL', '/')

    def post(self, request):
        """"""Log out the user.""""""
        logout_url = self.redirect_url

        if is_authenticated(request.user):
            # Check if a method exists to build the URL to log out the user
            # from the OP.
            logout_from_op = import_from_settings('OIDC_OP_LOGOUT_URL_METHOD', '')
            if logout_from_op:
                logout_url = import_string(logout_from_op)()

            # Log out the Django user, only if she was actually logged in.
            auth.logout(request)

        return HttpResponseRedirect(logout_url)
/n/n/n",1
142,142,824726393b185b8e5a8f17e66487dfde9f3c8b5c,"qa/tasks/mgr/dashboard/test_ganesha.py/n/n# -*- coding: utf-8 -*-
# pylint: disable=too-many-public-methods

from __future__ import absolute_import

import time

from .helper import DashboardTestCase, JObj, JLeaf, JList


class GaneshaTest(DashboardTestCase):
    CEPHFS = True
    AUTH_ROLES = ['pool-manager', 'ganesha-manager']

    @classmethod
    def create_pool(cls, name, pg_num, pool_type, application='rbd'):
        data = {
            'pool': name,
            'pg_num': pg_num,
            'pool_type': pool_type,
            'application_metadata': [application]
        }
        if pool_type == 'erasure':
            data['flags'] = ['ec_overwrites']
        cls._task_post(""/api/pool"", data)

    @classmethod
    def setUpClass(cls):
        super(GaneshaTest, cls).setUpClass()
        cls.create_pool('ganesha', 3, 'replicated')
        cls._rados_cmd(['-p', 'ganesha', '-N', 'ganesha1', 'create', 'conf-node1'])
        cls._rados_cmd(['-p', 'ganesha', '-N', 'ganesha1', 'create', 'conf-node2'])
        cls._rados_cmd(['-p', 'ganesha', '-N', 'ganesha1', 'create', 'conf-node3'])
        cls._rados_cmd(['-p', 'ganesha', '-N', 'ganesha2', 'create', 'conf-node1'])
        cls._rados_cmd(['-p', 'ganesha', '-N', 'ganesha2', 'create', 'conf-node2'])
        cls._rados_cmd(['-p', 'ganesha', '-N', 'ganesha2', 'create', 'conf-node3'])
        cls._ceph_cmd(['dashboard', 'set-ganesha-clusters-rados-pool-namespace', 'cluster1:ganesha/ganesha1,cluster2:ganesha/ganesha2'])

        # RGW setup
        cls._radosgw_admin_cmd([
            'user', 'create', '--uid', 'admin', '--display-name', 'admin',
            '--system', '--access-key', 'admin', '--secret', 'admin'
        ])
        cls._ceph_cmd(['dashboard', 'set-rgw-api-secret-key', 'admin'])
        cls._ceph_cmd(['dashboard', 'set-rgw-api-access-key', 'admin'])

    @classmethod
    def tearDownClass(cls):
        super(GaneshaTest, cls).tearDownClass()
        cls._radosgw_admin_cmd(['user', 'rm', '--uid', 'admin', '--purge-data'])
        cls._ceph_cmd(['osd', 'pool', 'delete', 'ganesha', 'ganesha', '--yes-i-really-really-mean-it'])

    @DashboardTestCase.RunAs('test', 'test', [{'rbd-image': ['create', 'update', 'delete']}])
    def test_read_access_permissions(self):
        self._get('/api/nfs-ganesha/export')
        self.assertStatus(403)

    def test_list_daemons(self):
        daemons = self._get(""/api/nfs-ganesha/daemon"")
        self.assertEqual(len(daemons), 6)
        daemons = [(d['daemon_id'], d['cluster_id']) for d in daemons]
        self.assertIn(('node1', 'cluster1'), daemons)
        self.assertIn(('node2', 'cluster1'), daemons)
        self.assertIn(('node3', 'cluster1'), daemons)
        self.assertIn(('node1', 'cluster2'), daemons)
        self.assertIn(('node2', 'cluster2'), daemons)
        self.assertIn(('node3', 'cluster2'), daemons)

    @classmethod
    def create_export(cls, path, cluster_id, daemons, fsal, sec_label_xattr=None):
        if fsal == 'CEPH':
            fsal = {""name"": ""CEPH"", ""user_id"":""admin"", ""fs_name"": None, ""sec_label_xattr"": sec_label_xattr}
            pseudo = ""/cephfs{}"".format(path)
        else:
            fsal = {""name"": ""RGW"", ""rgw_user_id"": ""admin""}
            pseudo = ""/rgw/{}"".format(path if path[0] != '/' else """")
        ex_json = {
            ""path"": path,
            ""fsal"": fsal,
            ""cluster_id"": cluster_id,
            ""daemons"": [""node1"", ""node3""],
            ""pseudo"": pseudo,
            ""tag"": None,
            ""access_type"": ""RW"",
            ""squash"": ""no_root_squash"",
            ""security_label"": sec_label_xattr is not None,
            ""protocols"": [4],
            ""transports"": [""TCP""],
            ""clients"": [{
                ""addresses"":[""10.0.0.0/8""],
                ""access_type"": ""RO"",
                ""squash"": ""root""
            }]
        }
        return cls._task_post('/api/nfs-ganesha/export', ex_json)

    def tearDown(self):
        super(GaneshaTest, self).tearDown()
        exports = self._get(""/api/nfs-ganesha/export"")
        if self._resp.status_code != 200:
            return
        self.assertIsInstance(exports, list)
        for exp in exports:
            self._task_delete(""/api/nfs-ganesha/export/{}/{}""
                              .format(exp['cluster_id'], exp['export_id']))

    def test_create_export(self):
        exports = self._get(""/api/nfs-ganesha/export"")
        self.assertEqual(len(exports), 0)

        data = self.create_export(""/foo"", 'cluster1', ['node1', 'node2'], 'CEPH', ""security.selinux"")

        exports = self._get(""/api/nfs-ganesha/export"")
        self.assertEqual(len(exports), 1)
        self.assertDictEqual(exports[0], data)
        return data

    def test_update_export(self):
        export = self.test_create_export()
        export['access_type'] = 'RO'
        export['daemons'] = ['node1', 'node3']
        export['security_label'] = True
        data = self._task_put('/api/nfs-ganesha/export/{}/{}'
                              .format(export['cluster_id'], export['export_id']),
                              export)
        exports = self._get(""/api/nfs-ganesha/export"")
        self.assertEqual(len(exports), 1)
        self.assertDictEqual(exports[0], data)
        self.assertEqual(exports[0]['daemons'], ['node1', 'node3'])
        self.assertEqual(exports[0]['security_label'], True)

    def test_delete_export(self):
        export = self.test_create_export()
        self._task_delete(""/api/nfs-ganesha/export/{}/{}""
                          .format(export['cluster_id'], export['export_id']))
        self.assertStatus(204)

    def test_get_export(self):
        exports = self._get(""/api/nfs-ganesha/export"")
        self.assertEqual(len(exports), 0)

        data1 = self.create_export(""/foo"", 'cluster2', ['node1', 'node2'], 'CEPH')
        data2 = self.create_export(""mybucket"", 'cluster2', ['node2', 'node3'], 'RGW')

        export1 = self._get(""/api/nfs-ganesha/export/cluster2/1"")
        self.assertDictEqual(export1, data1)

        export2 = self._get(""/api/nfs-ganesha/export/cluster2/2"")
        self.assertDictEqual(export2, data2)

    def test_invalid_status(self):
        self._ceph_cmd(['dashboard', 'set-ganesha-clusters-rados-pool-namespace', ''])

        data = self._get('/api/nfs-ganesha/status')
        self.assertStatus(200)
        self.assertIn('available', data)
        self.assertIn('message', data)
        self.assertFalse(data['available'])
        self.assertIn('Ganesha config location is not configured. Please set the GANESHA_RADOS_POOL_NAMESPACE setting.',
                      data['message'])

        self._ceph_cmd(['dashboard', 'set-ganesha-clusters-rados-pool-namespace', 'cluster1:ganesha/ganesha1,cluster2:ganesha/ganesha2'])

    def test_valid_status(self):
        data = self._get('/api/nfs-ganesha/status')
        self.assertStatus(200)
        self.assertIn('available', data)
        self.assertIn('message', data)
        self.assertTrue(data['available'])
/n/n/nsrc/pybind/mgr/dashboard/controllers/nfsganesha.py/n/n# -*- coding: utf-8 -*-
from __future__ import absolute_import

from functools import partial

import cherrypy
import cephfs

from . import ApiController, RESTController, UiApiController, BaseController, \
              Endpoint, Task, ReadPermission
from .. import logger
from ..security import Scope
from ..services.cephfs import CephFS
from ..services.cephx import CephX
from ..services.exception import serialize_dashboard_exception
from ..services.ganesha import Ganesha, GaneshaConf, NFSException
from ..services.rgw_client import RgwClient


# pylint: disable=not-callable
def NfsTask(name, metadata, wait_for):
    def composed_decorator(func):
        return Task(""nfs/{}"".format(name), metadata, wait_for,
                    partial(serialize_dashboard_exception,
                            include_http_status=True))(func)
    return composed_decorator


@ApiController('/nfs-ganesha', Scope.NFS_GANESHA)
class NFSGanesha(RESTController):

    @Endpoint()
    @ReadPermission
    def status(self):
        status = {'available': True, 'message': None}
        try:
            Ganesha.get_ganesha_clusters()
        except NFSException as e:
            status['message'] = str(e)
            status['available'] = False

        return status


@ApiController('/nfs-ganesha/export', Scope.NFS_GANESHA)
class NFSGaneshaExports(RESTController):
    RESOURCE_ID = ""cluster_id/export_id""

    def list(self):
        result = []
        for cluster_id in Ganesha.get_ganesha_clusters():
            result.extend(
                [export.to_dict()
                 for export in GaneshaConf.instance(cluster_id).list_exports()])
        return result

    @NfsTask('create', {'path': '{path}', 'fsal': '{fsal.name}',
                        'cluster_id': '{cluster_id}'}, 2.0)
    def create(self, path, cluster_id, daemons, pseudo, tag, access_type,
               squash, security_label, protocols, transports, fsal, clients,
               reload_daemons=True):
        if fsal['name'] not in Ganesha.fsals_available():
            raise NFSException(""Cannot create this export. ""
                               ""FSAL '{}' cannot be managed by the dashboard.""
                               .format(fsal['name']))

        ganesha_conf = GaneshaConf.instance(cluster_id)
        ex_id = ganesha_conf.create_export({
            'path': path,
            'pseudo': pseudo,
            'cluster_id': cluster_id,
            'daemons': daemons,
            'tag': tag,
            'access_type': access_type,
            'squash': squash,
            'security_label': security_label,
            'protocols': protocols,
            'transports': transports,
            'fsal': fsal,
            'clients': clients
        })
        if reload_daemons:
            ganesha_conf.reload_daemons(daemons)
        return ganesha_conf.get_export(ex_id).to_dict()

    def get(self, cluster_id, export_id):
        export_id = int(export_id)
        ganesha_conf = GaneshaConf.instance(cluster_id)
        if not ganesha_conf.has_export(export_id):
            raise cherrypy.HTTPError(404)
        return ganesha_conf.get_export(export_id).to_dict()

    @NfsTask('edit', {'cluster_id': '{cluster_id}', 'export_id': '{export_id}'},
             2.0)
    def set(self, cluster_id, export_id, path, daemons, pseudo, tag, access_type,
            squash, security_label, protocols, transports, fsal, clients,
            reload_daemons=True):
        export_id = int(export_id)
        ganesha_conf = GaneshaConf.instance(cluster_id)

        if not ganesha_conf.has_export(export_id):
            raise cherrypy.HTTPError(404)

        if fsal['name'] not in Ganesha.fsals_available():
            raise NFSException(""Cannot make modifications to this export. ""
                               ""FSAL '{}' cannot be managed by the dashboard.""
                               .format(fsal['name']))

        old_export = ganesha_conf.update_export({
            'export_id': export_id,
            'path': path,
            'cluster_id': cluster_id,
            'daemons': daemons,
            'pseudo': pseudo,
            'tag': tag,
            'access_type': access_type,
            'squash': squash,
            'security_label': security_label,
            'protocols': protocols,
            'transports': transports,
            'fsal': fsal,
            'clients': clients
        })
        daemons = list(daemons)
        for d_id in old_export.daemons:
            if d_id not in daemons:
                daemons.append(d_id)
        if reload_daemons:
            ganesha_conf.reload_daemons(daemons)
        return ganesha_conf.get_export(export_id).to_dict()

    @NfsTask('delete', {'cluster_id': '{cluster_id}',
                        'export_id': '{export_id}'}, 2.0)
    def delete(self, cluster_id, export_id, reload_daemons=True):
        export_id = int(export_id)
        ganesha_conf = GaneshaConf.instance(cluster_id)

        if not ganesha_conf.has_export(export_id):
            raise cherrypy.HTTPError(404)

        export = ganesha_conf.remove_export(export_id)
        if reload_daemons:
            ganesha_conf.reload_daemons(export.daemons)


@ApiController('/nfs-ganesha/daemon')
class NFSGaneshaService(RESTController):

    def list(self):
        status_dict = Ganesha.get_daemons_status()
        if status_dict:
            return [
                {
                    'daemon_id': daemon_id,
                    'cluster_id': cluster_id,
                    'status': status_dict[cluster_id][daemon_id]['status'],
                    'desc': status_dict[cluster_id][daemon_id]['desc']
                }
                for daemon_id in status_dict[cluster_id]
                for cluster_id in status_dict
            ]

        result = []
        for cluster_id in Ganesha.get_ganesha_clusters():
            result.extend(
                [{'daemon_id': daemon_id, 'cluster_id': cluster_id}
                 for daemon_id in GaneshaConf.instance(cluster_id).list_daemons()])
        return result


@UiApiController('/nfs-ganesha')
class NFSGaneshaUi(BaseController):
    @Endpoint('GET', '/cephx/clients')
    def cephx_clients(self):
        return [client for client in CephX.list_clients()]

    @Endpoint('GET', '/fsals')
    def fsals(self):
        return Ganesha.fsals_available()

    @Endpoint('GET', '/lsdir')
    def lsdir(self, root_dir=None, depth=1):
        if root_dir is None:
            root_dir = ""/""
        depth = int(depth)
        if depth > 5:
            logger.warning(""[NFS] Limiting depth to maximum value of 5: ""
                           ""input depth=%s"", depth)
            depth = 5
        root_dir = '{}/'.format(root_dir) \
                   if not root_dir.endswith('/') else root_dir

        try:
            cfs = CephFS()
            paths = cfs.get_dir_list(root_dir, depth)
            paths = [p[:-1] for p in paths if p != root_dir]
            return {'paths': paths}
        except (cephfs.ObjectNotFound, cephfs.PermissionError):
            return {'paths': []}

    @Endpoint('GET', '/cephfs/filesystems')
    def filesystems(self):
        return CephFS.list_filesystems()

    @Endpoint('GET', '/rgw/buckets')
    def buckets(self, user_id=None):
        return RgwClient.instance(user_id).get_buckets()

    @Endpoint('GET', '/clusters')
    def clusters(self):
        return Ganesha.get_ganesha_clusters()
/n/n/n",0
143,143,824726393b185b8e5a8f17e66487dfde9f3c8b5c,"/src/pybind/mgr/dashboard/controllers/nfsganesha.py/n/n# -*- coding: utf-8 -*-
from __future__ import absolute_import

from functools import partial

import cherrypy
import cephfs

from . import ApiController, RESTController, UiApiController, BaseController, \
              Endpoint, Task
from .. import logger
from ..security import Scope
from ..services.cephfs import CephFS
from ..services.cephx import CephX
from ..services.exception import serialize_dashboard_exception
from ..services.ganesha import Ganesha, GaneshaConf, NFSException
from ..services.rgw_client import RgwClient


# pylint: disable=not-callable
def NfsTask(name, metadata, wait_for):
    def composed_decorator(func):
        return Task(""nfs/{}"".format(name), metadata, wait_for,
                    partial(serialize_dashboard_exception,
                            include_http_status=True))(func)
    return composed_decorator


@ApiController('/nfs-ganesha/export', Scope.NFS_GANESHA)
class NFSGaneshaExports(RESTController):
    RESOURCE_ID = ""cluster_id/export_id""

    def list(self):
        result = []
        for cluster_id in Ganesha.get_ganesha_clusters():
            result.extend(
                [export.to_dict()
                 for export in GaneshaConf.instance(cluster_id).list_exports()])
        return result

    @NfsTask('create', {'path': '{path}', 'fsal': '{fsal.name}',
                        'cluster_id': '{cluster_id}'}, 2.0)
    def create(self, path, cluster_id, daemons, pseudo, tag, access_type,
               squash, security_label, protocols, transports, fsal, clients,
               reload_daemons=True):
        if fsal['name'] not in Ganesha.fsals_available():
            raise NFSException(""Cannot create this export. ""
                               ""FSAL '{}' cannot be managed by the dashboard.""
                               .format(fsal['name']))

        ganesha_conf = GaneshaConf.instance(cluster_id)
        ex_id = ganesha_conf.create_export({
            'path': path,
            'pseudo': pseudo,
            'cluster_id': cluster_id,
            'daemons': daemons,
            'tag': tag,
            'access_type': access_type,
            'squash': squash,
            'security_label': security_label,
            'protocols': protocols,
            'transports': transports,
            'fsal': fsal,
            'clients': clients
        })
        if reload_daemons:
            ganesha_conf.reload_daemons(daemons)
        return ganesha_conf.get_export(ex_id).to_dict()

    def get(self, cluster_id, export_id):
        export_id = int(export_id)
        ganesha_conf = GaneshaConf.instance(cluster_id)
        if not ganesha_conf.has_export(export_id):
            raise cherrypy.HTTPError(404)
        return ganesha_conf.get_export(export_id).to_dict()

    @NfsTask('edit', {'cluster_id': '{cluster_id}', 'export_id': '{export_id}'},
             2.0)
    def set(self, cluster_id, export_id, path, daemons, pseudo, tag, access_type,
            squash, security_label, protocols, transports, fsal, clients,
            reload_daemons=True):
        export_id = int(export_id)
        ganesha_conf = GaneshaConf.instance(cluster_id)

        if not ganesha_conf.has_export(export_id):
            raise cherrypy.HTTPError(404)

        if fsal['name'] not in Ganesha.fsals_available():
            raise NFSException(""Cannot make modifications to this export. ""
                               ""FSAL '{}' cannot be managed by the dashboard.""
                               .format(fsal['name']))

        old_export = ganesha_conf.update_export({
            'export_id': export_id,
            'path': path,
            'cluster_id': cluster_id,
            'daemons': daemons,
            'pseudo': pseudo,
            'tag': tag,
            'access_type': access_type,
            'squash': squash,
            'security_label': security_label,
            'protocols': protocols,
            'transports': transports,
            'fsal': fsal,
            'clients': clients
        })
        daemons = list(daemons)
        for d_id in old_export.daemons:
            if d_id not in daemons:
                daemons.append(d_id)
        if reload_daemons:
            ganesha_conf.reload_daemons(daemons)
        return ganesha_conf.get_export(export_id).to_dict()

    @NfsTask('delete', {'cluster_id': '{cluster_id}',
                        'export_id': '{export_id}'}, 2.0)
    def delete(self, cluster_id, export_id, reload_daemons=True):
        export_id = int(export_id)
        ganesha_conf = GaneshaConf.instance(cluster_id)

        if not ganesha_conf.has_export(export_id):
            raise cherrypy.HTTPError(404)

        export = ganesha_conf.remove_export(export_id)
        if reload_daemons:
            ganesha_conf.reload_daemons(export.daemons)


@ApiController('/nfs-ganesha/daemon')
class NFSGaneshaService(RESTController):

    def list(self):
        status_dict = Ganesha.get_daemons_status()
        if status_dict:
            return [
                {
                    'daemon_id': daemon_id,
                    'cluster_id': cluster_id,
                    'status': status_dict[cluster_id][daemon_id]['status'],
                    'desc': status_dict[cluster_id][daemon_id]['desc']
                }
                for daemon_id in status_dict[cluster_id]
                for cluster_id in status_dict
            ]

        result = []
        for cluster_id in Ganesha.get_ganesha_clusters():
            result.extend(
                [{'daemon_id': daemon_id, 'cluster_id': cluster_id}
                 for daemon_id in GaneshaConf.instance(cluster_id).list_daemons()])
        return result


@UiApiController('/nfs-ganesha')
class NFSGaneshaUi(BaseController):
    @Endpoint('GET', '/cephx/clients')
    def cephx_clients(self):
        return [client for client in CephX.list_clients()]

    @Endpoint('GET', '/fsals')
    def fsals(self):
        return Ganesha.fsals_available()

    @Endpoint('GET', '/lsdir')
    def lsdir(self, root_dir=None, depth=1):
        if root_dir is None:
            root_dir = ""/""
        depth = int(depth)
        if depth > 5:
            logger.warning(""[NFS] Limiting depth to maximum value of 5: ""
                           ""input depth=%s"", depth)
            depth = 5
        root_dir = '{}/'.format(root_dir) \
                   if not root_dir.endswith('/') else root_dir

        try:
            cfs = CephFS()
            paths = cfs.get_dir_list(root_dir, depth)
            paths = [p[:-1] for p in paths if p != root_dir]
            return {'paths': paths}
        except (cephfs.ObjectNotFound, cephfs.PermissionError):
            return {'paths': []}

    @Endpoint('GET', '/cephfs/filesystems')
    def filesystems(self):
        return CephFS.list_filesystems()

    @Endpoint('GET', '/rgw/buckets')
    def buckets(self, user_id=None):
        return RgwClient.instance(user_id).get_buckets()

    @Endpoint('GET', '/clusters')
    def clusters(self):
        return Ganesha.get_ganesha_clusters()
/n/n/n",1
152,152,2559b932cbd1b55a2750afae054a02753c1df7a9,"etd_app/views.py/n/nimport logging
import os
import urllib
import requests
from django.contrib.auth.decorators import login_required, permission_required
from django.contrib import messages
from django.conf import settings
from django.core.exceptions import PermissionDenied
from django.core.urlresolvers import reverse
from django.http import HttpResponse, HttpResponseRedirect, HttpResponsePermanentRedirect, HttpResponseForbidden, JsonResponse, FileResponse, HttpResponseServerError
from django.shortcuts import render, get_object_or_404
from django.utils.http import is_safe_url
from django.views.decorators.http import require_http_methods
from .models import Person, Candidate, Keyword, CommitteeMember
from .widgets import ID_VAL_SEPARATOR


BDR_EMAIL = 'bdr@brown.edu'
logger = logging.getLogger('etd')


def login(request):
    if request.user.is_authenticated():
        next_url = request.GET.get('next', '')
        if not is_safe_url(next_url):
            next_url = reverse('home')
        return HttpResponseRedirect(next_url)
    else:
        logger.error('login() - got anonymous user: %s' % request.META)
        return HttpResponseServerError('Internet Server error. Please contact %s for assistance.' % BDR_EMAIL)


def redirect_to_home(request):
    return HttpResponsePermanentRedirect(reverse('home'))


def home(request):
    return render(request, 'etd_app/home.html')


def overview(request):
    return render(request, 'etd_app/overview.html')


def faq(request):
    return render(request, 'etd_app/faq.html')


def copyright(request):
    return render(request, 'etd_app/copyright.html')


def get_person_instance(request):
    person_instance = None
    try:
        person_instance = Person.objects.get(netid=request.user.username)
    except Person.DoesNotExist:
        if 'orcid' in request.POST:
            try:
                person_instance = Person.objects.get(orcid=request.POST['orcid'])
            except Person.DoesNotExist:
                pass
    return person_instance


def get_shib_info_from_request(request):
    info = {}
    info['last_name'] = request.META.get('Shibboleth-sn', '')
    info['first_name'] = request.META.get('Shibboleth-givenName', '')
    info['email'] = request.META.get('Shibboleth-mail', '')
    return info


def _get_candidate(candidate_id, request):
    candidate = Candidate.objects.get(id=candidate_id)
    if candidate.person.netid != request.user.username:
        raise PermissionDenied
    return candidate


@login_required
def register(request):
    from .forms import PersonForm, CandidateForm
    if request.method == 'POST':
        post_data = request.POST.copy()
        post_data['netid'] = request.user.username
        person_form = PersonForm(post_data, instance=get_person_instance(request))
        candidate_form = CandidateForm(post_data)
        if person_form.is_valid() and candidate_form.is_valid():
            person = person_form.save()
            banner_id = request.META.get('Shibboleth-brownBannerID', '')
            if banner_id:
                person.bannerid = banner_id
                person.save()
            candidate = candidate_form.save(commit=False)
            candidate.person = person
            candidate.save()
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        shib_info = get_shib_info_from_request(request)
        person_instance = get_person_instance(request)
        degree_type = request.GET.get('type', '')
        if person_instance:
            person_form = PersonForm(instance=person_instance, degree_type=degree_type)
        else:
            person_form = PersonForm(initial=shib_info, degree_type=degree_type)
        candidate_form = CandidateForm(degree_type=degree_type)
    return render(request, 'etd_app/register.html', {'person_form': person_form, 'candidate_form': candidate_form, 'register': True})


@login_required
def candidate_profile(request, candidate_id):
    from .forms import PersonForm, CandidateForm
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    if candidate.thesis.is_locked():
        return HttpResponseForbidden('Thesis has already been submitted and is locked.')
    if request.method == 'POST':
        post_data = request.POST.copy()
        post_data['netid'] = request.user.username
        person_form = PersonForm(post_data, instance=candidate.person)
        candidate_form = CandidateForm(post_data, instance=candidate)
        if person_form.is_valid() and candidate_form.is_valid():
            person = person_form.save()
            banner_id = request.META.get('Shibboleth-brownBannerID', '')
            if banner_id:
                person.bannerid = banner_id
                person.save()
            candidate = candidate_form.save(commit=False)
            candidate.person = person
            candidate.save()
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        shib_info = get_shib_info_from_request(request)
        degree_type = request.GET.get('type', '')
        person_form = PersonForm(instance=candidate.person, degree_type=degree_type)
        candidate_form = CandidateForm(instance=candidate, degree_type=degree_type)
    return render(request, 'etd_app/register.html', {'person_form': person_form, 'candidate_form': candidate_form})


@login_required
def candidate_home(request, candidate_id=None):
    try:
        if candidate_id:
            candidate = _get_candidate(candidate_id=candidate_id, request=request)
        else:
            candidate = Candidate.objects.get(person__netid=request.user.username)
    except Candidate.DoesNotExist:
        type_ = request.GET.get('type', '')
        if type_:
            url = '%s?type=%s' % (reverse('register'), type_)
        else:
            url = reverse('register')
        return HttpResponseRedirect(url)
    except Candidate.MultipleObjectsReturned:
        candidate = Candidate.objects.filter(person__netid=request.user.username)[0]
    context_data = {'candidate': candidate}
    other_candidacies = Candidate.objects.filter(person__netid=request.user.username).exclude(id=candidate.id)
    if other_candidacies:
        context_data['other_candidacies'] = other_candidacies
    return render(request, 'etd_app/candidate.html', context_data)


@login_required
def candidate_upload(request, candidate_id):
    from .forms import UploadForm
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    if candidate.thesis.is_locked():
        return HttpResponseForbidden('Thesis has already been submitted and is locked.')
    if request.method == 'POST':
        form = UploadForm(request.POST, request.FILES)
        if form.is_valid():
            form.save_upload(candidate)
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        form = UploadForm()
    return render(request, 'etd_app/candidate_upload.html', {'candidate': candidate, 'form': form})


def _user_keywords_changed(thesis, user_request_keywords):
    db_keywords_info = {}
    for kw in thesis.keywords.all():
        db_keywords_info[str(kw.id)] = kw
    unsorted_user_keywords = []
    for kw in user_request_keywords:
        if kw in db_keywords_info:
            unsorted_user_keywords.append(db_keywords_info[kw].text)
        else:
            unsorted_user_keywords.append(kw)
    db_keywords = sorted([kw.text for kw in db_keywords_info.values()])
    user_keywords = sorted([kw.split(ID_VAL_SEPARATOR)[-1] for kw in unsorted_user_keywords])
    if user_keywords and (user_keywords != db_keywords):
        return True
    return False


@login_required
def candidate_metadata(request, candidate_id):
    from .forms import MetadataForm
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    if candidate.thesis.is_locked():
        return HttpResponseForbidden('Thesis has already been submitted and is locked.')
    if request.method == 'POST':
        post_data = request.POST.copy()
        post_data['candidate'] = candidate.id
        form = MetadataForm(post_data, instance=candidate.thesis)
        if form.is_valid():
            thesis = form.save()
            if thesis.abstract != form.cleaned_data['abstract']:
                messages.info(request, 'Your abstract contained invisible characters that we\'ve removed. Please make sure your abstract is correct in the information section below.')
            if thesis.title != form.cleaned_data['title']:
                messages.info(request, 'Your title contained invisible characters that we\'ve removed. Please make sure your title is correct in the information section below.')
            if _user_keywords_changed(thesis, request.POST.getlist('keywords', [])):
                messages.info(request, 'Your keywords contained invisible characters that we\'ve removed. Please make sure your keywords are correct in the information section below.')
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        form = MetadataForm(instance=candidate.thesis)
    context = {'candidate': candidate, 'form': form, 'ID_VAL_SEPARATOR': ID_VAL_SEPARATOR}
    return render(request, 'etd_app/candidate_metadata.html', context)


@login_required
def candidate_committee(request, candidate_id):
    from .forms import CommitteeMemberPersonForm, CommitteeMemberForm
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    if candidate.thesis.is_locked():
        return HttpResponseForbidden('Thesis has already been submitted and is locked.')
    if request.method == 'POST':
        person_form = CommitteeMemberPersonForm(request.POST)
        committee_member_form = CommitteeMemberForm(request.POST)
        if person_form.is_valid() and committee_member_form.is_valid():
            person = person_form.save()
            committee_member = committee_member_form.save(commit=False)
            committee_member.person = person
            committee_member.save()
            candidate.committee_members.add(committee_member)
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        person_form = CommitteeMemberPersonForm()
        committee_member_form = CommitteeMemberForm()
    context = {'candidate': candidate, 'person_form': person_form,
               'committee_member_form': committee_member_form}
    return render(request, 'etd_app/candidate_committee.html', context)


@login_required
@require_http_methods(['POST'])
def candidate_committee_remove(request, candidate_id, cm_id):
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    cm = CommitteeMember.objects.get(id=cm_id)
    candidate.committee_members.remove(cm)
    return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))


@login_required
def candidate_preview_submission(request, candidate_id):
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    return render(request, 'etd_app/candidate_preview.html', {'candidate': candidate})


@login_required
@require_http_methods(['POST'])
def candidate_submit(request, candidate_id):
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    candidate.thesis.submit()
    return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
def staff_home(request):
    return HttpResponseRedirect(reverse('review_candidates', kwargs={'status': 'all'}))


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
def staff_view_candidates(request, status):
    if 'sort_by' in request.GET:
        candidates = Candidate.get_candidates_by_status(status, sort_param=request.GET['sort_by'])
    else:
        candidates = Candidate.get_candidates_by_status(status)
    return render(request, 'etd_app/staff_view_candidates.html', {'candidates': candidates, 'status': status})


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
def staff_approve(request, candidate_id):
    from .forms import GradschoolChecklistForm, FormatChecklistForm
    candidate = get_object_or_404(Candidate, id=candidate_id)
    if request.method == 'POST':
        form = GradschoolChecklistForm(request.POST)
        if form.is_valid():
            form.save_data(candidate)
            return HttpResponseRedirect(reverse('staff_home'))
    else:
        format_form = FormatChecklistForm(instance=candidate.thesis.format_checklist)
    context = {'candidate': candidate, 'format_form': format_form}
    return render(request, 'etd_app/staff_approve_candidate.html', context)


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
def view_abstract(request, candidate_id):
    candidate = get_object_or_404(Candidate, id=candidate_id)
    return render(request, 'etd_app/staff_view_abstract.html', {'candidate': candidate})


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
@require_http_methods(['POST'])
def staff_format_post(request, candidate_id):
    from .forms import FormatChecklistForm
    candidate = get_object_or_404(Candidate, id=candidate_id)
    format_form = FormatChecklistForm(request.POST, instance=candidate.thesis.format_checklist)
    if format_form.is_valid():
        format_form.handle_post(request.POST, candidate)
        return HttpResponseRedirect(reverse('approve', kwargs={'candidate_id': candidate_id}))


@login_required
def view_file(request, candidate_id):
    candidate = get_object_or_404(Candidate, id=candidate_id)
    if candidate.person.netid != request.user.username:
        if not request.user.has_perm('etd_app.change_candidate'):
            return HttpResponseForbidden('You don\'t have permission to view this candidate\'s thesis.')
    if not candidate.thesis.current_file_name:
        return HttpResponse('Couldn\'t find a file: please email %s if there should be one.' % BDR_EMAIL)
    file_path = os.path.join(settings.MEDIA_ROOT, candidate.thesis.current_file_name)
    response = FileResponse(open(file_path, 'rb'), content_type='application/pdf')
    response['Content-Disposition'] = 'attachment; filename=""%s""' % candidate.thesis.original_file_name
    return response


def _select2_list(search_results):
    select2_results = []
    for r in search_results:
        select2_results.append({'id': r.id, 'text': r.text})
    return select2_results


def _get_previously_used(model, term):
    keywords = Keyword.search(term=term, order='text')
    if len(keywords) > 0:
        return [{'text': 'Previously Used', 'children': _select2_list(keywords)}]
    else:
        return []


def _build_fast_url(term, index):
    url = '%s?query=%s&queryIndex=%s' % (settings.FAST_LOOKUP_BASE_URL, urllib.parse.quote(term), index)
    url = '%s&queryReturn=%s&suggest=autoSubject' % (url, urllib.parse.quote('idroot,auth,type,%s' % index))
    return url


def _fast_results_to_select2_list(fast_results, index):
    results = []
    fast_ids = []
    for item in fast_results:
        text = item['auth']
        if item['type'] != 'auth':
            text = '%s (%s)' % (text, item[index][0])
        if item['idroot'] not in fast_ids:
            results.append({'id': '%s%s%s' % (item['idroot'], ID_VAL_SEPARATOR, item['auth']), 'text': text})
            fast_ids.append(item['idroot'])
    return results


def _get_fast_results(term, index='suggestall'):
    error_response = [{'text': 'FAST results', 'children': [{'id': '', 'text': 'Error retrieving FAST results.'}]}]
    url = _build_fast_url(term, index)
    try:
        r = requests.get(url, timeout=2)
    except requests.exceptions.Timeout:
        logger.error('fast lookup timed out')
        return error_response
    except Exception:
        import traceback
        logger.error('fast lookup exception: %s' % traceback.format_exc())
        return error_response
    try:
        select2_results = _fast_results_to_select2_list(r.json()['response']['docs'], index)
        if select2_results:
            return [{'text': 'FAST results', 'children': select2_results}]
        else:
            return []
    except Exception as e:
        logger.error('fast data exception: %s' % e)
        logger.error('fast response: %s - %s' % (r.status_code, r.text))
        return error_response


@login_required
def autocomplete_keywords(request):
    term = request.GET['term']
    results = _get_previously_used(Keyword, term)
    results.extend(_get_fast_results(term))
    return JsonResponse({'err': 'nil', 'results': results})
/n/n/ntests/test_views.py/n/nimport json
import os
from django.contrib.auth.models import User, Permission
from django.core.files import File
from django.core.urlresolvers import reverse
from django.conf import settings
from django.http import HttpRequest
from django.test import SimpleTestCase, TestCase
from django.test.client import Client, MULTIPART_CONTENT, BOUNDARY
from django.utils import timezone
from django.utils.encoding import force_bytes
import responses
from tests import responses_data
from tests.test_models import TEST_PDF_FILENAME, LAST_NAME, FIRST_NAME, CURRENT_YEAR, add_file_to_thesis, add_metadata_to_thesis
from etd_app.models import Person, Candidate, CommitteeMember, Department, Degree, Thesis, Keyword
from etd_app.views import get_shib_info_from_request, _get_previously_used, _get_fast_results, candidate_metadata
from etd_app.widgets import ID_VAL_SEPARATOR


def get_auth_client(username='tjones@brown.edu'):
    user = User.objects.create_user(username, 'pw')
    auth_client = Client()
    auth_client.force_login(user)
    return auth_client


def get_staff_client():
    user = User.objects.create_user('staff@brown.edu', 'pw')
    change_candidate_perm = Permission.objects.get(codename='change_candidate')
    user.user_permissions.add(change_candidate_perm)
    staff_client = Client()
    staff_client.force_login(user)
    return staff_client


class TestLogin(TestCase):

    def test_open_redirect(self):
        url = '%s?next=https://www.brown.edu' % reverse('login')
        r = self.client.get(url, **{'REMOTE_USER': 'x@brown.edu', 'Shibboleth-eppn': 'x@brown.edu'})
        self.assertRedirects(r, reverse('home'))


class TestStaticViews(SimpleTestCase):

    def test_redirect(self):
        response = self.client.get('/index.php')
        self.assertRedirects(response, reverse('home'), status_code=301)

    def test_home_page(self):
        response = self.client.get(reverse('home'))
        self.assertContains(response, '<title>Electronic Theses &amp; Dissertations at Brown University')
        self.assertContains(response, 'Ph.D. candidates at Brown must file their dissertations electronically.')
        self.assertContains(response, 'Deposit My Dissertation')
        self.assertContains(response, 'Admin')

    def test_overview(self):
        response = self.client.get(reverse('overview'))
        self.assertContains(response, 'Submission Overview')

    def test_faq(self):
        response = self.client.get(reverse('faq'))
        self.assertContains(response, 'Where are Browns ETDs available?')

    def test_copyright(self):
        response = self.client.get(reverse('copyright'))
        self.assertContains(response, 'You own the copyright to your dissertation')


class CandidateCreator:
    '''mixin object for creating PhD candidates'''

    @property
    def cur_dir(self):
        return os.path.dirname(os.path.abspath(__file__))

    def _create_person(self, netid, email, last_name='', first_name=''):
        return Person.objects.create(netid=netid, last_name=last_name, first_name=first_name, email=email)

    def _create_candidate(self, degree_type=Degree.TYPES.doctorate):
        self.dept = Department.objects.create(name='Department of Engineering')
        self.degree = Degree.objects.create(abbreviation='Ph.D.', name='Doctorate', degree_type=Degree.TYPES.doctorate)
        self.masters_degree = Degree.objects.create(abbreviation='AM', name='Masters', degree_type=Degree.TYPES.masters)
        self.person = self._create_person(netid='tjones@brown.edu', last_name=LAST_NAME, first_name=FIRST_NAME,
                email='tom_jones@brown.edu')
        cm_person = Person.objects.create(last_name='Smith')
        self.committee_member = CommitteeMember.objects.create(person=cm_person, department=self.dept)
        self.committee_member2 = CommitteeMember.objects.create(person=cm_person, department=self.dept, role='advisor')
        self.candidate = Candidate.objects.create(person=self.person, year=CURRENT_YEAR, department=self.dept,
                degree=Degree.objects.get(degree_type=degree_type))

    def _create_additional_candidate(self, degree_type=Degree.TYPES.doctorate, person=None, thesis_title=None):
        if not person:
            person = Person.objects.create(netid='msmith@brown.edu', last_name='Smith', first_name='Mary',
                email='mary_smith@brown.edu')
        candidate = Candidate.objects.create(person=person, year=CURRENT_YEAR, department=self.dept, degree=self.degree)
        if thesis_title:
            candidate.thesis.title = thesis_title
            candidate.thesis.save()
        return candidate


class TestRegister(TestCase, CandidateCreator):

    def setUp(self):
        #set an incorrect netid here, to make sure it's read from the username instead of
        #   the passed in value - we don't want someone to be able to register for a different user.
        self.person_data = {'netid': 'wrongid@brown.edu', 'orcid': '1234567890',
                'last_name': LAST_NAME, 'first_name': FIRST_NAME,
                'email': 'tomjones@brown.edu', 'phone': '401-123-1234'}

    def test_register_auth(self):
        response = self.client.get(reverse('register'))
        self.assertRedirects(response, '%s?next=/register/' % reverse('login'), fetch_redirect_response=False)

    def test_get_shib_info_from_request(self):
        request = HttpRequest()
        request.META.update({'Shibboleth-sn': 'Jones', 'Shibboleth-givenName': 'Tom',
                             'Shibboleth-mail': 'tom_jones@school.edu'})
        shib_info = get_shib_info_from_request(request)
        self.assertEqual(shib_info['last_name'], 'Jones')
        self.assertEqual(shib_info['first_name'], 'Tom')
        self.assertEqual(shib_info['email'], 'tom_jones@school.edu')

    def test_register_get(self):
        auth_client = get_auth_client()
        degree = Degree.objects.create(abbreviation='Ph.D.', name='Doctorate')
        degree2 = Degree.objects.create(abbreviation='M.S.', name='Masters', degree_type=Degree.TYPES.masters)
        response = auth_client.get(reverse('register'), **{'Shibboleth-sn': 'Jones'})
        self.assertContains(response, 'Registration:')
        response_text = response.content.decode('utf8')
        last_name_input = '<input type=""text"" name=""last_name"" value=""Jones"" maxlength=""190"" class=""textinput textInput"" required id=""id_last_name"" />'
        self.assertInHTML(last_name_input, response_text)
        self.assertContains(response, 'Must match name on thesis or dissertation')
        self.assertContains(response, 'Department')
        self.assertContains(response, 'input type=""radio"" name=""degree""')
        self.assertContains(response, 'Ph.D.')
        self.assertContains(response, 'M.S.')
        self.assertContains(response, 'submit')
        self.assertContains(response, 'Restrict access')
        self.assertNotContains(response, 'Netid')
        #test degree choices limited appropriately
        response = auth_client.get('%s?type=dissertation' % reverse('register'))
        self.assertContains(response, 'Must match name on dissertation</p>')
        self.assertContains(response, 'Ph.D.')
        self.assertNotContains(response, 'M.S.')
        self.assertContains(response, 'Restrict access to my dissertation for 2 years')
        response = auth_client.get('%s?type=thesis' % reverse('register'))
        self.assertContains(response, 'Must match name on thesis</p>')
        self.assertNotContains(response, 'Ph.D.')
        self.assertContains(response, 'M.S.')
        self.assertContains(response, 'Restrict access to my thesis for 2 years')

    def _create_candidate_foreign_keys(self):
        self.dept = Department.objects.create(name='Engineering')
        self.degree = Degree.objects.create(abbreviation='Ph.D', name='Doctor')
        self.masters_degree = Degree.objects.create(abbreviation='AM', name='Masters')

    def test_email_field_required(self):
        auth_client = get_auth_client()
        self._create_candidate_foreign_keys()
        data = self.person_data.copy()
        del data['email']
        data.update({'year': CURRENT_YEAR, 'department': self.dept.id, 'degree': self.degree.id})
        response = auth_client.post(reverse('register'), data, follow=True)
        email_required_msg = u'<span id=""error_1_id_email"" class=""help-inline""><strong>This field is required.</strong></span>'
        self.assertInHTML(email_required_msg, response.content.decode('utf8'))

    def test_new_person_and_candidate_created_with_embargo(self):
        '''verify that new data for Person & Candidate gets saved properly (& redirected to candidate_home)'''
        auth_client = get_auth_client()
        self._create_candidate_foreign_keys()
        data = self.person_data.copy()
        data.update({'year': CURRENT_YEAR, 'department': self.dept.id, 'degree': self.degree.id,
                     'set_embargo': 'on'})
        response = auth_client.post(reverse('register'), data, follow=True, **{'Shibboleth-brownBannerID': '12345'})
        person = Person.objects.all()[0]
        self.assertEqual(person.netid, 'tjones@brown.edu') #make sure logged-in user netid was used, not the invalid parameter netid
        self.assertEqual(person.bannerid, '12345')
        self.assertEqual(person.last_name, LAST_NAME)
        candidate = Candidate.objects.all()[0]
        self.assertEqual(candidate.year, CURRENT_YEAR)
        self.assertEqual(candidate.degree.abbreviation, 'Ph.D')
        self.assertEqual(candidate.embargo_end_year, CURRENT_YEAR + 2)
        self.assertRedirects(response, reverse('candidate_home', kwargs={'candidate_id': candidate.id}))

    def test_invalid_year(self):
        auth_client = get_auth_client()
        self._create_candidate_foreign_keys()
        data = self.person_data.copy()
        data.update({'year': 1816, 'department': self.dept.id, 'degree': self.degree.id,
                     'set_embargo': 'on'})
        response = auth_client.post(reverse('register'), data, follow=True)
        self.assertEqual(len(Candidate.objects.all()), 0)
        self.assertContains(response, '1816 is not one of the available choices.')

    def test_no_embargo(self):
        auth_client = get_auth_client()
        self._create_candidate_foreign_keys()
        data = self.person_data.copy()
        data.update({'year': CURRENT_YEAR, 'department': self.dept.id, 'degree': self.degree.id})
        response = auth_client.post(reverse('register'), data, follow=True)
        candidate = Candidate.objects.all()[0]
        self.assertEqual(candidate.embargo_end_year, None)

    def test_register_and_edit_existing_person_by_netid(self):
        person = Person.objects.create(netid='tjones@brown.edu', last_name=LAST_NAME)
        auth_client = get_auth_client()
        self._create_candidate_foreign_keys()
        data = self.person_data.copy()
        data['last_name'] = 'new last name'
        data.update({'year': CURRENT_YEAR, 'department': self.dept.id, 'degree': self.degree.id})
        response = auth_client.post(reverse('register'), data, follow=True)
        self.assertEqual(len(Person.objects.all()), 1)
        person = Person.objects.all()[0]
        self.assertEqual(person.last_name, 'new last name')
        self.assertEqual(len(Candidate.objects.all()), 1)
        candidate = Candidate.objects.get(person=person)
        self.assertEqual(candidate.year, CURRENT_YEAR)

    def test_register_and_edit_existing_person_by_orcid(self):
        person = Person.objects.create(orcid='1234567890', last_name=LAST_NAME)
        auth_client = get_auth_client()
        self._create_candidate_foreign_keys()
        data = self.person_data.copy()
        data['last_name'] = 'new last name'
        data.update({'year': CURRENT_YEAR, 'department': self.dept.id, 'degree': self.degree.id})
        response = auth_client.post(reverse('register'), data, follow=True)
        self.assertEqual(len(Person.objects.all()), 1)
        person = Person.objects.all()[0]
        self.assertEqual(person.last_name, 'new last name')
        self.assertEqual(len(Candidate.objects.all()), 1)
        candidate = Candidate.objects.get(person=person)
        self.assertEqual(candidate.year, CURRENT_YEAR)

    def test_register_new_candidacy(self):
        auth_client = get_auth_client()
        self._create_candidate_foreign_keys()
        data = self.person_data.copy()
        data.update({'year': CURRENT_YEAR, 'department': self.dept.id, 'degree': self.degree.id})
        response = auth_client.post(reverse('register'), data, follow=True)
        self.assertEqual(len(Candidate.objects.all()), 1)
        self.assertEqual(Candidate.objects.all()[0].degree.abbreviation, 'Ph.D')
        data.update({'year': CURRENT_YEAR, 'department': self.dept.id, 'degree': self.masters_degree.id})
        response = auth_client.post(reverse('register'), data, follow=True)
        self.assertEqual(len(Candidate.objects.all()), 2)
        abbreviations = [c.degree.abbreviation for c in Candidate.objects.all()]
        self.assertEqual(sorted(abbreviations), ['AM', 'Ph.D'])

    def test_register_get_two_candidacies(self):
        self._create_candidate()
        self._create_additional_candidate(person=self.person)
        auth_client = get_auth_client()
        response = auth_client.get(reverse('register'))
        self.assertEqual(response.status_code, 200)


class TestCandidateProfile(TestCase, CandidateCreator):

    def setUp(self):
        self._create_candidate()
        self.url = reverse('candidate_profile', kwargs={'candidate_id': self.candidate.id})
        self.person_data = {'netid': 'tjones@brown.edu', 'orcid': '1234567890',
                'last_name': LAST_NAME, 'first_name': FIRST_NAME,
                'email': 'tomjones@brown.edu', 'phone': '401-123-1234'}

    def test_auth(self):
        response = self.client.get(self.url)
        self.assertRedirects(response, '%s?next=%s' % (reverse('login'), self.url), fetch_redirect_response=False)

    def test_candidate_profile_person_checking(self):
        #verify that person matches the request info, when candidate_id is passed in
        auth_client = get_auth_client(username='malicious@school.edu')
        response = auth_client.get(self.url)
        self.assertEqual(response.status_code, 403)

    def test_get_candidate_exists(self):
        embargo_unchecked = '<input type=""checkbox"" name=""set_embargo"" class=""checkboxinput"" id=""id_set_embargo"" />'
        embargo_checked = '<input type=""checkbox"" name=""set_embargo"" checked class=""checkboxinput"" id=""id_set_embargo"" />'
        auth_client = get_auth_client()
        response = auth_client.get(self.url)
        self.assertContains(response, 'value=""%s""' % LAST_NAME)
        self.assertContains(response, 'selected>%s</option>' % CURRENT_YEAR)
        self.assertInHTML(embargo_unchecked, response.content.decode('utf8'))
        self.candidate.embargo_end_year = CURRENT_YEAR + 2
        self.candidate.save()
        response = auth_client.get(self.url)
        self.assertInHTML(embargo_checked, response.content.decode('utf8'))

    def test_edit_candidate_data(self):
        auth_client = get_auth_client()
        data = self.person_data.copy()
        #change the last name - everything else stays the same
        data['last_name'] = 'new last name'
        data.update({'year': CURRENT_YEAR, 'department': self.dept.id, 'degree': self.degree.id})
        response = auth_client.post(self.url, data, follow=True)
        self.assertEqual(len(Candidate.objects.all()), 1)
        candidate = Candidate.objects.get(person__id=self.person.id)
        self.assertEqual(candidate.person.last_name, 'new last name')
        self.assertEqual(candidate.year, CURRENT_YEAR)

    def test_edit_profile_locked(self):
        add_file_to_thesis(self.candidate.thesis)
        add_metadata_to_thesis(self.candidate.thesis)
        self.candidate.committee_members.add(self.committee_member)
        self.candidate.thesis.submit()
        auth_client = get_auth_client()
        data = self.person_data.copy()
        response = auth_client.post(self.url, data, follow=True)
        self.assertEqual(response.status_code, 403)

    def test_edit_candidate_remove_embargo(self):
        auth_client = get_auth_client()
        candidate = Candidate.objects.all()[0]
        candidate.embargo_end_year = CURRENT_YEAR + 2
        candidate.save()
        candidate = Candidate.objects.all()[0]
        self.assertEqual(candidate.embargo_end_year, CURRENT_YEAR + 2)
        data = self.person_data.copy()
        data.update({'year': CURRENT_YEAR, 'department': self.dept.id, 'degree': self.degree.id})
        response = auth_client.post(self.url, data, follow=True)
        candidate = Candidate.objects.all()[0]
        self.assertEqual(len(Candidate.objects.all()), 1)
        self.assertEqual(candidate.embargo_end_year, None)


class TestCandidateHome(TestCase, CandidateCreator):

    def test_candidate_home_auth(self):
        response = self.client.get(reverse('candidate_home'))
        self.assertRedirects(response, '%s?next=/candidate/' % reverse('login'), fetch_redirect_response=False)

    def test_candidate_not_registered(self):
        auth_client = get_auth_client()
        response = auth_client.get(reverse('candidate_home'))
        self.assertRedirects(response, reverse('register'))

    def test_candidate(self):
        self._create_candidate()
        auth_client = get_auth_client()
        response = auth_client.get(reverse('candidate_home'))
        self.assertContains(response, '%s %s - Ph.D. - Engineering' % (FIRST_NAME, LAST_NAME))
        self.assertContains(response, 'Edit Degree Profile</a>')
        self.assertContains(response, reverse('candidate_metadata', kwargs={'candidate_id': self.candidate.id}))
        self.assertContains(response, reverse('candidate_upload', kwargs={'candidate_id': self.candidate.id}))
        self.assertContains(response, 'Submit Cashier&#39;s Office receipt for dissertation fee')
        self.assertNotContains(response, 'Completed on ')

    def test_candidate_person_checking(self):
        #verify that person matches the request info, when candidate_id is passed in
        self._create_candidate()
        auth_client = get_auth_client(username='malicious@school.edu')
        response = auth_client.get(reverse('candidate_home', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(response.status_code, 403)

    def test_two_candidacies(self):
        self._create_candidate(degree_type=Degree.TYPES.masters)
        self._create_additional_candidate(degree_type=Degree.TYPES.doctorate, person=self.person)
        auth_client = get_auth_client()
        response = auth_client.get(reverse('candidate_home', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(response.status_code, 200)
        self.assertContains(response, 'Switch to Dissertation (Engineering)')

    def test_candidate_thesis_uploaded(self):
        self._create_candidate()
        add_file_to_thesis(self.candidate.thesis)
        auth_client = get_auth_client()
        response = auth_client.get(reverse('candidate_home'))
        self.assertContains(response, TEST_PDF_FILENAME)
        self.assertContains(response, reverse('candidate_upload', kwargs={'candidate_id': self.candidate.id}))

    def test_candidate_show_committee_members(self):
        self._create_candidate()
        advisor_person = Person.objects.create(last_name='johnson', first_name='bob')
        advisor = CommitteeMember.objects.create(person=advisor_person, role='advisor', department=self.dept)
        self.candidate.committee_members.add(advisor)
        auth_client = get_auth_client()
        response = auth_client.get(reverse('candidate_home'))
        self.assertContains(response, 'Advisor')

    def test_candidate_ready_to_submit(self):
        self._create_candidate()
        self.candidate.degree = self.masters_degree
        self.candidate.save()
        add_file_to_thesis(self.candidate.thesis)
        add_metadata_to_thesis(self.candidate.thesis)
        self.candidate.committee_members.add(self.committee_member)
        auth_client = get_auth_client()
        response = auth_client.get(reverse('candidate_home'))
        self.assertContains(response, 'Preview and Submit Thesis')

    def test_candidate_thesis_locked(self):
        #don't show links for changing information once the dissertation is locked
        self._create_candidate()
        add_file_to_thesis(self.candidate.thesis)
        add_metadata_to_thesis(self.candidate.thesis)
        self.candidate.committee_members.add(self.committee_member)
        self.candidate.thesis.submit()
        self.candidate.thesis.accept()
        auth_client = get_auth_client()
        response = auth_client.get(reverse('candidate_home'))
        self.assertNotContains(response, reverse('candidate_profile', kwargs={'candidate_id': self.candidate.id}))
        self.assertNotContains(response, reverse('candidate_metadata', kwargs={'candidate_id': self.candidate.id}))
        self.assertNotContains(response, reverse('candidate_upload', kwargs={'candidate_id': self.candidate.id}))
        self.assertNotContains(response, reverse('candidate_committee', kwargs={'candidate_id': self.candidate.id}))
        self.assertNotContains(response, reverse('candidate_committee_remove', kwargs={'candidate_id': self.candidate.id, 'cm_id': self.committee_member.id}))

    def test_candidate_get_checklist_complete(self):
        self._create_candidate()
        self.candidate.gradschool_checklist.dissertation_fee = timezone.now()
        self.candidate.gradschool_checklist.bursar_receipt = timezone.now()
        self.candidate.gradschool_checklist.gradschool_exit_survey = timezone.now()
        self.candidate.gradschool_checklist.earned_docs_survey = timezone.now()
        self.candidate.gradschool_checklist.pages_submitted_to_gradschool = timezone.now()
        self.candidate.gradschool_checklist.save()
        auth_client = get_auth_client()
        response = auth_client.get(reverse('candidate_home'))
        self.assertContains(response, 'Completed on ')


class TestCandidatePreviewSubmit(TestCase, CandidateCreator):

    def setUp(self):
        self._create_candidate()
        self.preview_url = reverse('candidate_preview_submission', kwargs={'candidate_id': self.candidate.id})
        self.submit_url = reverse('candidate_submit', kwargs={'candidate_id': self.candidate.id})

    def test_candidate_preview_auth(self):
        response = self.client.get(self.preview_url)
        self.assertRedirects(response, '%s?next=%s' % (reverse('login'), self.preview_url), fetch_redirect_response=False)

    def test_candidate_preview_person_checking(self):
        #verify that person matches the request info, when candidate_id is passed in
        auth_client = get_auth_client(username='malicious@school.edu')
        response = auth_client.get(self.preview_url)
        self.assertEqual(response.status_code, 403)

    def test_candidate_preview(self):
        self.candidate.committee_members.add(self.committee_member)
        thesis = self.candidate.thesis
        add_file_to_thesis(thesis)
        add_metadata_to_thesis(thesis)
        auth_client = get_auth_client()
        response = auth_client.post(self.preview_url)
        self.assertContains(response, 'Preview Your Dissertation')
        self.assertContains(response, 'Name:')
        self.assertContains(response, 'Title:')
        self.assertContains(response, 'Submit Your Dissertation')
        self.assertNotContains(response, 'Embargoed until %s' % (CURRENT_YEAR + 2))
        self.candidate.embargo_end_year = CURRENT_YEAR + 2
        self.candidate.save()
        response = auth_client.post(self.preview_url)
        self.assertContains(response, 'Embargoed until %s' % (CURRENT_YEAR + 2))

    def test_candidate_submit_auth(self):
        response = self.client.get(self.submit_url)
        self.assertRedirects(response, '%s?next=%s' % (reverse('login'), self.submit_url), fetch_redirect_response=False)

    def test_candidate_submit(self):
        self.candidate.committee_members.add(self.committee_member)
        thesis = self.candidate.thesis
        add_file_to_thesis(thesis)
        add_metadata_to_thesis(thesis)
        auth_client = get_auth_client()
        response = auth_client.post(self.submit_url)
        self.assertRedirects(response, reverse('candidate_home', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(Candidate.objects.all()[0].thesis.status, 'pending')


class TestCandidateUpload(TestCase, CandidateCreator):

    def test_upload_auth(self):
        self._create_candidate()
        url = reverse('candidate_upload', kwargs={'candidate_id': self.candidate.id})
        response = self.client.get(url)
        self.assertRedirects(response, '%s?next=%s' % (reverse('login'), url), fetch_redirect_response=False)

    def test_upload_get(self):
        self._create_candidate()
        url = reverse('candidate_upload', kwargs={'candidate_id': self.candidate.id})
        auth_client = get_auth_client()
        response = auth_client.get(url)
        self.assertContains(response, '%s %s' % (FIRST_NAME, LAST_NAME))
        self.assertContains(response, 'Upload Your Dissertation')

    def test_upload_thesis_locked(self):
        self._create_candidate()
        add_file_to_thesis(self.candidate.thesis)
        add_metadata_to_thesis(self.candidate.thesis)
        self.candidate.committee_members.add(self.committee_member)
        self.candidate.thesis.submit()
        self.candidate.thesis.accept()
        auth_client = get_auth_client()
        url = reverse('candidate_upload', kwargs={'candidate_id': self.candidate.id})
        response = auth_client.get(url)
        self.assertEqual(response.status_code, 403)
        response = auth_client.post(url)
        self.assertEqual(response.status_code, 403)

    def test_upload_post(self):
        self._create_candidate()
        url = reverse('candidate_upload', kwargs={'candidate_id': self.candidate.id})
        auth_client = get_auth_client()
        self.assertEqual(len(Thesis.objects.all()), 1)
        with open(os.path.join(self.cur_dir, 'test_files', TEST_PDF_FILENAME), 'rb') as f:
            response = auth_client.post(url, {'thesis_file': f})
        self.assertEqual(len(Thesis.objects.all()), 1)
        self.assertEqual(Candidate.objects.all()[0].thesis.original_file_name, TEST_PDF_FILENAME)
        self.assertRedirects(response, reverse('candidate_home', kwargs={'candidate_id': self.candidate.id}))
        full_path = os.path.join(settings.MEDIA_ROOT, Candidate.objects.all()[0].thesis.current_file_name)
        self.assertTrue(os.path.exists(full_path), '%s doesn\'t exist' % full_path)

    def test_upload_bad_file(self):
        self._create_candidate()
        url = reverse('candidate_upload', kwargs={'candidate_id': self.candidate.id})
        auth_client = get_auth_client()
        self.assertEqual(len(Thesis.objects.all()), 1)
        with open(os.path.join(self.cur_dir, 'test_files', 'test_obj'), 'rb') as f:
            response = auth_client.post(url, {'thesis_file': f})
            self.assertContains(response, 'Upload Your Dissertation')
            self.assertContains(response, 'file must be a PDF')
            self.assertFalse(Candidate.objects.all()[0].thesis.document)
            self.assertEqual(len(Thesis.objects.all()), 1)

    def test_upload_new_thesis_file(self):
        self._create_candidate()
        url = reverse('candidate_upload', kwargs={'candidate_id': self.candidate.id})
        auth_client = get_auth_client()
        add_file_to_thesis(self.candidate.thesis)
        self.assertEqual(len(Thesis.objects.all()), 1)
        thesis = Candidate.objects.all()[0].thesis
        self.assertEqual(thesis.original_file_name, TEST_PDF_FILENAME)
        self.assertEqual(thesis.checksum, 'b1938fc5549d1b5b42c0b695baa76d5df5f81ac3')
        with open(os.path.join(self.cur_dir, 'test_files', 'test2.pdf'), 'rb') as f:
            response = auth_client.post(url, {'thesis_file': f})
            self.assertEqual(len(Thesis.objects.all()), 1)
            thesis = Candidate.objects.all()[0].thesis
            self.assertEqual(thesis.original_file_name, 'test2.pdf')
            self.assertEqual(thesis.checksum, '2ce252ec827258837e53b2b0bfb94141ba951f2e')


class TestCandidateMetadata(TestCase, CandidateCreator):

    def setUp(self):
        self._create_candidate()
        self.url = reverse('candidate_metadata', kwargs={'candidate_id': self.candidate.id})

    def test_metadata_auth(self):
        response = self.client.get(self.url)
        self.assertRedirects(response, '%s?next=%s' % (reverse('login'), self.url), fetch_redirect_response=False)

    def test_metadata_get(self):
        auth_client = get_auth_client()
        response = auth_client.get(self.url)
        self.assertContains(response, '%s %s' % (FIRST_NAME, LAST_NAME))
        self.assertContains(response, 'About Your Dissertation')
        self.assertContains(response, 'Title')

    def test_metadata_thesis_locked(self):
        add_file_to_thesis(self.candidate.thesis)
        add_metadata_to_thesis(self.candidate.thesis)
        self.candidate.committee_members.add(self.committee_member)
        self.candidate.thesis.submit()
        self.candidate.thesis.accept()
        auth_client = get_auth_client()
        response = auth_client.get(self.url)
        self.assertEqual(response.status_code, 403)
        response = auth_client.post(self.url)
        self.assertEqual(response.status_code, 403)

    def test_metadata_post_incomplete_data(self):
        auth_client = get_auth_client()
        self.assertEqual(len(Thesis.objects.all()), 1)
        data = {'title':'test', 'abstract': 'test abstract'}
        response = auth_client.post(self.url, data)
        self.assertContains(response, '<span id=""error_1_id_keywords"" class=""help-inline""><strong>This field is required.')

    def test_metadata_post(self):
        auth_client = get_auth_client()
        self.assertEqual(len(Thesis.objects.all()), 1)
        k = Keyword.objects.create(text='test')
        data = {'title':'test', 'abstract': 'test abstract', 'keywords': [k.id, 'dog', 'fst12345%sSomething' % ID_VAL_SEPARATOR]}
        response = auth_client.post(self.url, data, follow=True)
        self.assertEqual(len(Thesis.objects.all()), 1)
        self.assertEqual(Candidate.objects.all()[0].thesis.title, 'test')
        keywords = sorted([kw.text for kw in Candidate.objects.all()[0].thesis.keywords.all()])
        self.assertEqual(keywords, ['Something', 'dog', 'test'])
        self.assertNotContains(response, 'invisible characters')
        self.assertRedirects(response, reverse('candidate_home', kwargs={'candidate_id': self.candidate.id}))

    def _encode_multipart(self, data):
        #custom encoding method that handles bytes that way we want - django sees bytes input as a list of values
        lines = []
        def to_bytes(s):
            return force_bytes(s, settings.DEFAULT_CHARSET)
        for (key, value) in data.items():
            lines.extend(to_bytes(val) for val in [
                       '--%s' % BOUNDARY,
                       'Content-Disposition: form-data; name=""%s""' % key,
                       '',
                       value
                   ])
        lines.extend([
            to_bytes('--%s--' % BOUNDARY),
            b'',
        ])
        return b'\r\n'.join(lines)

    def test_metadata_post_bad_encoding(self):
        #Try passing non-utf8 bytes and see what happens. Gets saved to the db, but it's mangled.
        auth_client = get_auth_client()
        self.assertEqual(len(Thesis.objects.all()), 1)
        k = Keyword.objects.create(text='tst')
        abstract_utf16_bytes = 'tst abstract'.encode('utf16')
        data = {'title': 'tst', 'abstract': abstract_utf16_bytes, 'keywords': k.id}
        multipart_data = self._encode_multipart(data)
        self.assertTrue(abstract_utf16_bytes in multipart_data)
        #use generic(), because we can bypass the encoding step that post() does on the data
        response = auth_client.generic('POST', self.url, multipart_data, MULTIPART_CONTENT)
        self.assertEqual(len(Thesis.objects.all()), 1)
        thesis = Candidate.objects.all()[0].thesis
        self.assertEqual(Candidate.objects.all()[0].thesis.title, 'tst')
        abstract = Candidate.objects.all()[0].thesis.abstract
        self.assertTrue(isinstance(abstract, str))
        mangled_abstract = 't\x00\x00s\x00t\x00 \x00a\x00b\x00s\x00t\x00r\x00a\x00c\x00t\x00'
        self.assertEqual(abstract, mangled_abstract)
        self.assertNotEqual(abstract.encode('utf16'), abstract_utf16_bytes)

    def test_user_message_for_invalid_control_characters(self):
        auth_client = get_auth_client()
        k = Keyword.objects.create(text='tst')
        data = {'title': 'tst', 'abstract': 'tst \x0cabstract', 'keywords': k.id}
        response = auth_client.post(self.url, data, follow=True)
        self.assertContains(response, 'Your abstract contained invisible characters that we\'ve removed. Please make sure your abstract is correct in the information section below.')
        data = {'title': 'tst \x0ctitle', 'abstract': 'tst', 'keywords': k.id}
        response = auth_client.post(self.url, data, follow=True)
        self.assertContains(response, 'Your title contained invisible characters that we\'ve removed. Please make sure your title is correct in the information section below.')

    def test_user_message_for_invalid_control_chars_in_keyword(self):
        auth_client = get_auth_client()
        data = {'title': 'title', 'abstract': 'tst', 'keywords': 'tst \x0ckeyword'}
        response = auth_client.post(self.url, data, follow=True)
        self.assertContains(response, 'Your keywords contained invisible characters that we\'ve removed. Please make sure your keywords are correct in the information section below.')

    def test_user_message_for_invalid_control_chars_in_fast_keyword(self):
        auth_client = get_auth_client()
        data = {'title': 'title', 'abstract': 'tst', 'keywords': 'fst12345\tSom\x0cething'}
        response = auth_client.post(self.url, data, follow=True)
        self.assertContains(response, 'Your keywords contained invisible characters that we\'ve removed. Please make sure your keywords are correct in the information section below.')

    def test_metadata_post_thesis_already_exists(self):
        auth_client = get_auth_client()
        add_file_to_thesis(self.candidate.thesis)
        self.assertEqual(len(Thesis.objects.all()), 1)
        k = Keyword.objects.create(text='tst')
        data = {'title': 'tst', 'abstract': 'tst abstract', 'keywords': k.id}
        response = auth_client.post(self.url, data)
        self.assertEqual(len(Thesis.objects.all()), 1)
        thesis = Candidate.objects.all()[0].thesis
        self.assertEqual(thesis.title, 'tst')
        self.assertEqual(thesis.original_file_name, TEST_PDF_FILENAME)


class TestCommitteeMembers(TestCase, CandidateCreator):

    def test_committee_members_auth(self):
        self._create_candidate()
        url = reverse('candidate_committee', kwargs={'candidate_id': self.candidate.id})
        response = self.client.get(url)
        self.assertRedirects(response, '%s?next=%s' % (reverse('login'), url), fetch_redirect_response=False)

    def test_committee_members_get(self):
        self._create_candidate()
        auth_client = get_auth_client()
        response = auth_client.get(reverse('candidate_committee', kwargs={'candidate_id': self.candidate.id}))
        self.assertContains(response, 'About Your Committee')
        self.assertContains(response, 'Last Name')
        self.assertContains(response, 'Brown Department')

    def test_committee_members_thesis_locked(self):
        self._create_candidate()
        add_file_to_thesis(self.candidate.thesis)
        add_metadata_to_thesis(self.candidate.thesis)
        self.candidate.committee_members.add(self.committee_member)
        self.candidate.thesis.submit()
        self.candidate.thesis.accept()
        auth_client = get_auth_client()
        response = auth_client.get(reverse('candidate_committee', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(response.status_code, 403)
        response = auth_client.post(reverse('candidate_committee', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(response.status_code, 403)

    def test_add_committee_member(self):
        self._create_candidate()
        auth_client = get_auth_client()
        post_data = {'last_name': 'smith', 'first_name': 'bob', 'role': 'reader', 'department': self.dept.id}
        response = auth_client.post(reverse('candidate_committee', kwargs={'candidate_id': self.candidate.id}), post_data)
        self.assertEqual(Candidate.objects.all()[0].committee_members.all()[0].person.last_name, 'smith')
        self.assertEqual(Candidate.objects.all()[0].committee_members.all()[0].role, 'reader')

    def test_committee_member_remove_auth(self):
        self._create_candidate()
        cm = CommitteeMember.objects.create(person=self.person, department=self.dept)
        url = reverse('candidate_committee_remove', kwargs={'candidate_id': self.candidate.id, 'cm_id': cm.id})
        response = self.client.get(url)
        self.assertRedirects(response, '%s?next=%s' % (reverse('login'), url), fetch_redirect_response=False)

    def test_remove_committee_member(self):
        self._create_candidate()
        self.candidate.committee_members.add(self.committee_member)
        self.assertEqual(len(self.candidate.committee_members.all()), 1)
        auth_client = get_auth_client()
        response = auth_client.post(reverse('candidate_committee_remove', kwargs={'candidate_id': self.candidate.id, 'cm_id': self.committee_member.id}))
        self.assertEqual(len(self.candidate.committee_members.all()), 0)


class TestStaffReview(TestCase, CandidateCreator):

    def test_login_required(self):
        response = self.client.get(reverse('staff_home'))
        self.assertRedirects(response, '%s?next=/review/' % reverse('login'), fetch_redirect_response=False)

    def test_permission_required(self):
        auth_client = get_auth_client()
        response = auth_client.get(reverse('staff_home'))
        self.assertEqual(response.status_code, 403)

    def test_staff_home_get(self):
        staff_client = get_staff_client()
        response = staff_client.get(reverse('staff_home'))
        self.assertRedirects(response, reverse('review_candidates', kwargs={'status': 'all'}))

    def test_view_candidates_permission_required(self):
        auth_client = get_auth_client()
        response = auth_client.get(reverse('review_candidates', kwargs={'status': 'all'}))
        self.assertEqual(response.status_code, 403)

    def test_view_candidates_all(self):
        self._create_candidate()
        thesis = Thesis.objects.all()[0]
        add_file_to_thesis(thesis)
        add_metadata_to_thesis(thesis)
        self.candidate.committee_members.add(self.committee_member)
        thesis.submit()
        staff_client = get_staff_client()
        response = staff_client.get(reverse('review_candidates', kwargs={'status': 'all'}))
        self.assertContains(response, '>Status</a>')
        self.assertContains(response, '%s, %s' % (LAST_NAME, FIRST_NAME))
        self.assertContains(response, 'Awaiting ')

    def test_view_candidates_in_progress(self):
        self._create_candidate()
        self.candidate.thesis.title = 'tst'
        self.candidate.thesis.save()
        staff_client = get_staff_client()
        response = staff_client.get(reverse('review_candidates', kwargs={'status': 'in_progress'}))
        self.assertContains(response, '>Dissertation Title</a>')
        self.assertContains(response, 'tst')

    def test_view_candidates_other_statuses(self):
        staff_client = get_staff_client()
        response = staff_client.get(reverse('review_candidates', kwargs={'status': 'awaiting_gradschool'}))
        self.assertEqual(response.status_code, 200)
        response = staff_client.get(reverse('review_candidates', kwargs={'status': 'dissertation_rejected'}))
        self.assertEqual(response.status_code, 200)
        response = staff_client.get(reverse('review_candidates', kwargs={'status': 'paperwork_incomplete'}))
        self.assertEqual(response.status_code, 200)
        response = staff_client.get(reverse('review_candidates', kwargs={'status': 'complete'}))
        self.assertEqual(response.status_code, 200)

    def test_view_candidates_sorted(self):
        self._create_candidate()
        p = Person.objects.create(netid='rsmith@brown.edu', last_name='smith', email='r_smith@brown.edu')
        c = Candidate.objects.create(person=p, department=Department.objects.create(name='Anthropology', bdr_collection_id='2'),
                year=CURRENT_YEAR, degree=self.degree)
        staff_client = get_staff_client()
        response = staff_client.get('%s?sort_by=department' % reverse('review_candidates', kwargs={'status': 'all'}))
        self.assertEqual(response.status_code, 200)
        #tests passing in the sort_by param, but not really sure how to completely verify result


class TestStaffApproveThesis(TestCase, CandidateCreator):

    def test_permission_required(self):
        self._create_candidate()
        auth_client = get_auth_client()
        response = auth_client.get(reverse('approve', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(response.status_code, 403)

    def test_approve_get(self):
        self._create_candidate()
        staff_client = get_staff_client()
        response = staff_client.get(reverse('approve', kwargs={'candidate_id': self.candidate.id}))
        self.assertContains(response, '%s %s' % (FIRST_NAME, LAST_NAME))
        self.assertContains(response, '<input type=""checkbox"" name=""dissertation_fee"" />Received')
        self.assertContains(response, 'View Dissertation')
        self.assertContains(response, 'View Abstract')
        self.assertNotContains(response, 'Title page issue')
        self.assertNotContains(response, 'Received on ')
        now = timezone.now()
        self.candidate.gradschool_checklist.dissertation_fee = now
        self.candidate.gradschool_checklist.save()
        response = staff_client.get(reverse('approve', kwargs={'candidate_id': self.candidate.id}))
        self.assertNotContains(response, '<input type=""checkbox"" name=""dissertation_fee"" />Received')
        self.assertContains(response, 'Received on ')

    def test_approve_post(self):
        staff_client = get_staff_client()
        self._create_candidate()
        self.candidate.gradschool_checklist.earned_docs_survey = timezone.now()
        self.candidate.gradschool_checklist.save()
        post_data = {'dissertation_fee': True, 'bursar_receipt': True, 'pages_submitted_to_gradschool': True}
        response = staff_client.post(reverse('approve', kwargs={'candidate_id': self.candidate.id}), post_data)
        self.assertEqual(Candidate.objects.all()[0].gradschool_checklist.dissertation_fee.date(), timezone.now().date())
        self.assertEqual(Candidate.objects.all()[0].gradschool_checklist.bursar_receipt.date(), timezone.now().date())
        self.assertEqual(Candidate.objects.all()[0].gradschool_checklist.earned_docs_survey.date(), timezone.now().date())
        self.assertEqual(Candidate.objects.all()[0].gradschool_checklist.pages_submitted_to_gradschool.date(), timezone.now().date())
        self.assertRedirects(response, reverse('staff_home'), fetch_redirect_response=False)

    def test_format_post_perms(self):
        self._create_candidate()
        auth_client = get_auth_client()
        response = auth_client.post(reverse('format_post', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(response.status_code, 403)

    def test_format_post(self):
        self._create_candidate()
        thesis = self.candidate.thesis
        add_file_to_thesis(thesis)
        add_metadata_to_thesis(thesis)
        self.candidate.committee_members.add(self.committee_member)
        self.candidate.thesis.submit()
        staff_client = get_staff_client()
        post_data = {'title_page_issue': True, 'signature_page_issue': True, 'signature_page_comment': 'Test comment',
                'accept_diss': 'Approve'}
        url = reverse('format_post', kwargs={'candidate_id': self.candidate.id})
        response = staff_client.post(url, post_data)
        self.assertRedirects(response, reverse('approve', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(Candidate.objects.all()[0].thesis.format_checklist.title_page_issue, True)
        self.assertEqual(Candidate.objects.all()[0].thesis.status, Thesis.STATUS_CHOICES.accepted)

    def test_format_post_reject(self):
        self._create_candidate()
        thesis = self.candidate.thesis
        add_file_to_thesis(thesis)
        add_metadata_to_thesis(thesis)
        self.candidate.committee_members.add(self.committee_member)
        self.candidate.thesis.submit()
        staff_client = get_staff_client()
        post_data = {'title_page_issue': True, 'signature_page_issue': True, 'signature_page_comment': 'Test comment',
                'reject_diss': 'Reject'}
        url = reverse('format_post', kwargs={'candidate_id': self.candidate.id})
        response = staff_client.post(url, post_data)
        self.assertEqual(Candidate.objects.all()[0].thesis.status, Thesis.STATUS_CHOICES.rejected)


class TestViewInfo(TestCase, CandidateCreator):

    def test_view_abstract_perm_required(self):
        self._create_candidate()
        auth_client = get_auth_client()
        response = auth_client.get(reverse('abstract', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(response.status_code, 403)

    def test_view_abstract(self):
        self._create_candidate()
        add_metadata_to_thesis(self.candidate.thesis)
        staff_client = get_staff_client()
        response = staff_client.get(reverse('abstract', kwargs={'candidate_id': self.candidate.id}))
        self.assertContains(response, 'test abstract')

    def test_view_file_login_required(self):
        self._create_candidate()
        url = reverse('view_file', kwargs={'candidate_id': self.candidate.id})
        response = self.client.get(url)
        self.assertRedirects(response, '%s?next=%s' % (reverse('login'), url), fetch_redirect_response=False)

    def test_view_file(self):
        self._create_candidate()
        add_file_to_thesis(self.candidate.thesis)
        auth_client = get_auth_client()
        response = auth_client.get(reverse('view_file', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(response.status_code, 200)

    def test_view_file_no_file(self):
        self._create_candidate()
        auth_client = get_auth_client()
        response = auth_client.get(reverse('view_file', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(response.status_code, 200)

    def test_view_file_wrong_user(self):
        self._create_candidate()
        add_file_to_thesis(self.candidate.thesis)
        auth_client = get_auth_client(username='wrong_user@brown.edu')
        response = auth_client.get(reverse('view_file', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(response.status_code, 403)

    def test_view_file_staff(self):
        self._create_candidate()
        add_file_to_thesis(self.candidate.thesis)
        staff_client = get_staff_client()
        response = staff_client.get(reverse('view_file', kwargs={'candidate_id': self.candidate.id}))
        self.assertEqual(response.status_code, 200)


class TestAutocompleteKeywords(TestCase):

    def test_login(self):
        response = self.client.get(reverse('autocomplete_keywords'))
        self.assertRedirects(response, '%s?next=/autocomplete/keywords/' % reverse('login'), fetch_redirect_response=False)

    def test_previously_used(self):
        #test empty
        results = _get_previously_used(Keyword, 'test')
        self.assertEqual(results, [])
        #now test with a result
        k = Keyword.objects.create(text='tst')
        results = _get_previously_used(Keyword, 'test')
        self.assertEqual(len(results), 1)
        self.assertEqual(results[0]['text'], 'Previously Used')
        self.assertEqual(results[0]['children'][0]['id'], k.id)
        self.assertEqual(results[0]['children'][0]['text'], k.text)

    @responses.activate
    def test_fast_lookup(self):
        responses.add(responses.GET,  'http://fast.oclc.org/searchfast/fastsuggest',
                 body=json.dumps(responses_data.FAST_PYTHON_DATA),
                 status=200,
                 content_type='application/json'
             )
        fast_results = _get_fast_results('python')
        self.assertEqual(fast_results[0]['text'], 'FAST results')
        self.assertEqual(fast_results[0]['children'][0]['id'], 'fst01084736%sPython (Computer program language)' % ID_VAL_SEPARATOR)
        self.assertEqual(fast_results[0]['children'][0]['text'], 'Python (Computer program language)')

    @responses.activate
    def test_no_fast_results(self):
        responses.add(responses.GET,  'http://fast.oclc.org/searchfast/fastsuggest',
                body=json.dumps(responses_data.FAST_NO_RESULTS_DATA),
                status=200,
                content_type='application/json'
            )
        fast_results = _get_fast_results('python01234')
        self.assertEqual(fast_results, [])

    @responses.activate
    def test_fast_timeout(self):
        from requests.exceptions import Timeout
        timeout_exc = Timeout()
        responses.add(responses.GET,  'http://fast.oclc.org/searchfast/fastsuggest',
                body=timeout_exc,
            )
        fast_results = _get_fast_results('python')
        self.assertEqual(fast_results[0]['text'], 'FAST results')
        self.assertEqual(fast_results[0]['children'][0]['id'], '')
        self.assertEqual(fast_results[0]['children'][0]['text'], 'Error retrieving FAST results.')

    def test_fast_error(self):
        with self.settings(FAST_LOOKUP_BASE_URL='http://localhost/fast'):
            fast_results = _get_fast_results('python')
            self.assertEqual(fast_results[0]['text'], 'FAST results')
            self.assertEqual(fast_results[0]['children'][0]['id'], '')
            self.assertEqual(fast_results[0]['children'][0]['text'], 'Error retrieving FAST results.')


    def test_autocomplete_keywords(self):
        k = Keyword.objects.create(text='tst')
        auth_client = get_auth_client()
        response = auth_client.get('%s?term=test' % reverse('autocomplete_keywords'))
        response_data = json.loads(response.content.decode('utf8'))
        self.assertEqual(response_data['err'], 'nil')
        self.assertEqual(response_data['results'][0]['text'], 'Previously Used')
        self.assertEqual(response_data['results'][0]['children'][0]['text'], k.text)
        self.assertEqual(response_data['results'][1]['text'], 'FAST results')

/n/n/n",0
153,153,2559b932cbd1b55a2750afae054a02753c1df7a9,"/etd_app/views.py/n/nimport logging
import os
import urllib
import requests
from django.contrib.auth.decorators import login_required, permission_required
from django.contrib import messages
from django.conf import settings
from django.core.exceptions import PermissionDenied
from django.core.urlresolvers import reverse
from django.http import HttpResponse, HttpResponseRedirect, HttpResponsePermanentRedirect, HttpResponseForbidden, JsonResponse, FileResponse, HttpResponseServerError
from django.shortcuts import render, get_object_or_404
from django.views.decorators.http import require_http_methods
from .models import Person, Candidate, Keyword, CommitteeMember
from .widgets import ID_VAL_SEPARATOR


BDR_EMAIL = 'bdr@brown.edu'
logger = logging.getLogger('etd')


def login(request):
    if request.user.is_authenticated():
        next_url = request.GET.get('next', reverse('home'))
        return HttpResponseRedirect(next_url)
    else:
        logger.error('login() - got anonymous user: %s' % request.META)
        return HttpResponseServerError('Internet Server error. Please contact %s for assistance.' % BDR_EMAIL)


def redirect_to_home(request):
    return HttpResponsePermanentRedirect(reverse('home'))


def home(request):
    return render(request, 'etd_app/home.html')


def overview(request):
    return render(request, 'etd_app/overview.html')


def faq(request):
    return render(request, 'etd_app/faq.html')


def copyright(request):
    return render(request, 'etd_app/copyright.html')


def get_person_instance(request):
    person_instance = None
    try:
        person_instance = Person.objects.get(netid=request.user.username)
    except Person.DoesNotExist:
        if 'orcid' in request.POST:
            try:
                person_instance = Person.objects.get(orcid=request.POST['orcid'])
            except Person.DoesNotExist:
                pass
    return person_instance


def get_shib_info_from_request(request):
    info = {}
    info['last_name'] = request.META.get('Shibboleth-sn', '')
    info['first_name'] = request.META.get('Shibboleth-givenName', '')
    info['email'] = request.META.get('Shibboleth-mail', '')
    return info


def _get_candidate(candidate_id, request):
    candidate = Candidate.objects.get(id=candidate_id)
    if candidate.person.netid != request.user.username:
        raise PermissionDenied
    return candidate


@login_required
def register(request):
    from .forms import PersonForm, CandidateForm
    if request.method == 'POST':
        post_data = request.POST.copy()
        post_data['netid'] = request.user.username
        person_form = PersonForm(post_data, instance=get_person_instance(request))
        candidate_form = CandidateForm(post_data)
        if person_form.is_valid() and candidate_form.is_valid():
            person = person_form.save()
            banner_id = request.META.get('Shibboleth-brownBannerID', '')
            if banner_id:
                person.bannerid = banner_id
                person.save()
            candidate = candidate_form.save(commit=False)
            candidate.person = person
            candidate.save()
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        shib_info = get_shib_info_from_request(request)
        person_instance = get_person_instance(request)
        degree_type = request.GET.get('type', '')
        if person_instance:
            person_form = PersonForm(instance=person_instance, degree_type=degree_type)
        else:
            person_form = PersonForm(initial=shib_info, degree_type=degree_type)
        candidate_form = CandidateForm(degree_type=degree_type)
    return render(request, 'etd_app/register.html', {'person_form': person_form, 'candidate_form': candidate_form, 'register': True})


@login_required
def candidate_profile(request, candidate_id):
    from .forms import PersonForm, CandidateForm
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    if candidate.thesis.is_locked():
        return HttpResponseForbidden('Thesis has already been submitted and is locked.')
    if request.method == 'POST':
        post_data = request.POST.copy()
        post_data['netid'] = request.user.username
        person_form = PersonForm(post_data, instance=candidate.person)
        candidate_form = CandidateForm(post_data, instance=candidate)
        if person_form.is_valid() and candidate_form.is_valid():
            person = person_form.save()
            banner_id = request.META.get('Shibboleth-brownBannerID', '')
            if banner_id:
                person.bannerid = banner_id
                person.save()
            candidate = candidate_form.save(commit=False)
            candidate.person = person
            candidate.save()
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        shib_info = get_shib_info_from_request(request)
        degree_type = request.GET.get('type', '')
        person_form = PersonForm(instance=candidate.person, degree_type=degree_type)
        candidate_form = CandidateForm(instance=candidate, degree_type=degree_type)
    return render(request, 'etd_app/register.html', {'person_form': person_form, 'candidate_form': candidate_form})


@login_required
def candidate_home(request, candidate_id=None):
    try:
        if candidate_id:
            candidate = _get_candidate(candidate_id=candidate_id, request=request)
        else:
            candidate = Candidate.objects.get(person__netid=request.user.username)
    except Candidate.DoesNotExist:
        type_ = request.GET.get('type', '')
        if type_:
            url = '%s?type=%s' % (reverse('register'), type_)
        else:
            url = reverse('register')
        return HttpResponseRedirect(url)
    except Candidate.MultipleObjectsReturned:
        candidate = Candidate.objects.filter(person__netid=request.user.username)[0]
    context_data = {'candidate': candidate}
    other_candidacies = Candidate.objects.filter(person__netid=request.user.username).exclude(id=candidate.id)
    if other_candidacies:
        context_data['other_candidacies'] = other_candidacies
    return render(request, 'etd_app/candidate.html', context_data)


@login_required
def candidate_upload(request, candidate_id):
    from .forms import UploadForm
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    if candidate.thesis.is_locked():
        return HttpResponseForbidden('Thesis has already been submitted and is locked.')
    if request.method == 'POST':
        form = UploadForm(request.POST, request.FILES)
        if form.is_valid():
            form.save_upload(candidate)
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        form = UploadForm()
    return render(request, 'etd_app/candidate_upload.html', {'candidate': candidate, 'form': form})


def _user_keywords_changed(thesis, user_request_keywords):
    db_keywords_info = {}
    for kw in thesis.keywords.all():
        db_keywords_info[str(kw.id)] = kw
    unsorted_user_keywords = []
    for kw in user_request_keywords:
        if kw in db_keywords_info:
            unsorted_user_keywords.append(db_keywords_info[kw].text)
        else:
            unsorted_user_keywords.append(kw)
    db_keywords = sorted([kw.text for kw in db_keywords_info.values()])
    user_keywords = sorted([kw.split(ID_VAL_SEPARATOR)[-1] for kw in unsorted_user_keywords])
    if user_keywords and (user_keywords != db_keywords):
        return True
    return False


@login_required
def candidate_metadata(request, candidate_id):
    from .forms import MetadataForm
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    if candidate.thesis.is_locked():
        return HttpResponseForbidden('Thesis has already been submitted and is locked.')
    if request.method == 'POST':
        post_data = request.POST.copy()
        post_data['candidate'] = candidate.id
        form = MetadataForm(post_data, instance=candidate.thesis)
        if form.is_valid():
            thesis = form.save()
            if thesis.abstract != form.cleaned_data['abstract']:
                messages.info(request, 'Your abstract contained invisible characters that we\'ve removed. Please make sure your abstract is correct in the information section below.')
            if thesis.title != form.cleaned_data['title']:
                messages.info(request, 'Your title contained invisible characters that we\'ve removed. Please make sure your title is correct in the information section below.')
            if _user_keywords_changed(thesis, request.POST.getlist('keywords', [])):
                messages.info(request, 'Your keywords contained invisible characters that we\'ve removed. Please make sure your keywords are correct in the information section below.')
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        form = MetadataForm(instance=candidate.thesis)
    context = {'candidate': candidate, 'form': form, 'ID_VAL_SEPARATOR': ID_VAL_SEPARATOR}
    return render(request, 'etd_app/candidate_metadata.html', context)


@login_required
def candidate_committee(request, candidate_id):
    from .forms import CommitteeMemberPersonForm, CommitteeMemberForm
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    if candidate.thesis.is_locked():
        return HttpResponseForbidden('Thesis has already been submitted and is locked.')
    if request.method == 'POST':
        person_form = CommitteeMemberPersonForm(request.POST)
        committee_member_form = CommitteeMemberForm(request.POST)
        if person_form.is_valid() and committee_member_form.is_valid():
            person = person_form.save()
            committee_member = committee_member_form.save(commit=False)
            committee_member.person = person
            committee_member.save()
            candidate.committee_members.add(committee_member)
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        person_form = CommitteeMemberPersonForm()
        committee_member_form = CommitteeMemberForm()
    context = {'candidate': candidate, 'person_form': person_form,
               'committee_member_form': committee_member_form}
    return render(request, 'etd_app/candidate_committee.html', context)


@login_required
@require_http_methods(['POST'])
def candidate_committee_remove(request, candidate_id, cm_id):
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    cm = CommitteeMember.objects.get(id=cm_id)
    candidate.committee_members.remove(cm)
    return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))


@login_required
def candidate_preview_submission(request, candidate_id):
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    return render(request, 'etd_app/candidate_preview.html', {'candidate': candidate})


@login_required
@require_http_methods(['POST'])
def candidate_submit(request, candidate_id):
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    candidate.thesis.submit()
    return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
def staff_home(request):
    return HttpResponseRedirect(reverse('review_candidates', kwargs={'status': 'all'}))


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
def staff_view_candidates(request, status):
    if 'sort_by' in request.GET:
        candidates = Candidate.get_candidates_by_status(status, sort_param=request.GET['sort_by'])
    else:
        candidates = Candidate.get_candidates_by_status(status)
    return render(request, 'etd_app/staff_view_candidates.html', {'candidates': candidates, 'status': status})


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
def staff_approve(request, candidate_id):
    from .forms import GradschoolChecklistForm, FormatChecklistForm
    candidate = get_object_or_404(Candidate, id=candidate_id)
    if request.method == 'POST':
        form = GradschoolChecklistForm(request.POST)
        if form.is_valid():
            form.save_data(candidate)
            return HttpResponseRedirect(reverse('staff_home'))
    else:
        format_form = FormatChecklistForm(instance=candidate.thesis.format_checklist)
    context = {'candidate': candidate, 'format_form': format_form}
    return render(request, 'etd_app/staff_approve_candidate.html', context)


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
def view_abstract(request, candidate_id):
    candidate = get_object_or_404(Candidate, id=candidate_id)
    return render(request, 'etd_app/staff_view_abstract.html', {'candidate': candidate})


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
@require_http_methods(['POST'])
def staff_format_post(request, candidate_id):
    from .forms import FormatChecklistForm
    candidate = get_object_or_404(Candidate, id=candidate_id)
    format_form = FormatChecklistForm(request.POST, instance=candidate.thesis.format_checklist)
    if format_form.is_valid():
        format_form.handle_post(request.POST, candidate)
        return HttpResponseRedirect(reverse('approve', kwargs={'candidate_id': candidate_id}))


@login_required
def view_file(request, candidate_id):
    candidate = get_object_or_404(Candidate, id=candidate_id)
    if candidate.person.netid != request.user.username:
        if not request.user.has_perm('etd_app.change_candidate'):
            return HttpResponseForbidden('You don\'t have permission to view this candidate\'s thesis.')
    if not candidate.thesis.current_file_name:
        return HttpResponse('Couldn\'t find a file: please email %s if there should be one.' % BDR_EMAIL)
    file_path = os.path.join(settings.MEDIA_ROOT, candidate.thesis.current_file_name)
    response = FileResponse(open(file_path, 'rb'), content_type='application/pdf')
    response['Content-Disposition'] = 'attachment; filename=""%s""' % candidate.thesis.original_file_name
    return response


def _select2_list(search_results):
    select2_results = []
    for r in search_results:
        select2_results.append({'id': r.id, 'text': r.text})
    return select2_results


def _get_previously_used(model, term):
    keywords = Keyword.search(term=term, order='text')
    if len(keywords) > 0:
        return [{'text': 'Previously Used', 'children': _select2_list(keywords)}]
    else:
        return []


def _build_fast_url(term, index):
    url = '%s?query=%s&queryIndex=%s' % (settings.FAST_LOOKUP_BASE_URL, urllib.parse.quote(term), index)
    url = '%s&queryReturn=%s&suggest=autoSubject' % (url, urllib.parse.quote('idroot,auth,type,%s' % index))
    return url


def _fast_results_to_select2_list(fast_results, index):
    results = []
    fast_ids = []
    for item in fast_results:
        text = item['auth']
        if item['type'] != 'auth':
            text = '%s (%s)' % (text, item[index][0])
        if item['idroot'] not in fast_ids:
            results.append({'id': '%s%s%s' % (item['idroot'], ID_VAL_SEPARATOR, item['auth']), 'text': text})
            fast_ids.append(item['idroot'])
    return results


def _get_fast_results(term, index='suggestall'):
    error_response = [{'text': 'FAST results', 'children': [{'id': '', 'text': 'Error retrieving FAST results.'}]}]
    url = _build_fast_url(term, index)
    try:
        r = requests.get(url, timeout=2)
    except requests.exceptions.Timeout:
        logger.error('fast lookup timed out')
        return error_response
    except Exception:
        import traceback
        logger.error('fast lookup exception: %s' % traceback.format_exc())
        return error_response
    try:
        select2_results = _fast_results_to_select2_list(r.json()['response']['docs'], index)
        if select2_results:
            return [{'text': 'FAST results', 'children': select2_results}]
        else:
            return []
    except Exception as e:
        logger.error('fast data exception: %s' % e)
        logger.error('fast response: %s - %s' % (r.status_code, r.text))
        return error_response


@login_required
def autocomplete_keywords(request):
    term = request.GET['term']
    results = _get_previously_used(Keyword, term)
    results.extend(_get_fast_results(term))
    return JsonResponse({'err': 'nil', 'results': results})
/n/n/n",1
156,156,f2ff5ba9d250b8d34c5b48429ba5f632cb2040b1,"earth_enterprise/src/server/wsgi/wms/ogc/common/configs.py/n/n#!/usr/bin/env python
#
# Copyright 2017 Google Inc.
# Copyright 2019 Open GEE Contributors
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


""""""Utilities for getting config parameters.""""""


class Configs(object):
  """"""Class for loading and provide configuration parameters.""""""

  def __init__(self, config_file, default_values=None):
    """"""Load config key/value pairs from the config file.""""""
    if default_values:
      self._config_values = default_values
    else:
      self._config_values = {}
    try:
      fp = open(config_file)
      for line in fp:
        line = line.strip()
        if line and line[0] != ""#"":
          (key, value) = line.split("" "")
          self._config_values[key] = value
      fp.close()
    except IOError:
      pass
    except:
      pass

  def GetStr(self, key):
    """"""Returns the value for the given key from the config file.""""""
    try:
      return self._config_values[key]
    except KeyError:
      return """"

  def GetInt(self, key):
    """"""Returns the integer value for the given key from the config file.""""""
    try:
      return int(self._config_values[key])
    except KeyError:
      return 0

  def GetBool(self, key):
    """"""Returns the boolean value for the given key from the config file.""""""
    try:
      return ""t"" == self._config_values[key].lower()[0]
    except KeyError:
      return False
    except IndexError:
      return False
/n/n/nearth_enterprise/src/server/wsgi/wms/ogc/common/tiles.py/n/n#!/usr/bin/python
#
# Copyright 2017 Google Inc.
# Copyright 2019 Open GEE Contributors
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


""""""Deals with fetching tiles and composing them for the final image.""""""

import logging
import os
import StringIO
import tempfile
import wms_connection

import geom
import images
import PIL.Image as Image
import tilecalcs

logger = logging.getLogger(""wms_maps"")
_TILE_PIXEL_SIZE = 256
_NO_DATA_PIXELS = (0, 0, 0)
_OPAQUE_ALPHA = (255,)
_TRANSPARENT_ALPHA = (0,)
_ALPHA_THRESHOLD = 128
ALL_WHITE_PIXELS = (255, 255, 255)


def ProduceImage(layer_properties, user_log_rect, user_width, user_height):
  """"""High-level production of the image.

  Args:
      layer_properties: Object with details about the layer.
      user_log_rect: The user-requested projected, ie map coordinates,
        not lat/lon, limits of the desired region. Ie BBOX, pretty much.
      user_width: The user-requested width of the image.
      user_height: The user-requested height of the image.

  Returns:
      The image to be presented to the user.
  """"""
  proj = layer_properties.projection

  zoom_level = tilecalcs.CalcZoomLevel(user_log_rect.Extent(),
                                       proj.InternalLogOuterBounds().Extent(),
                                       geom.Pair(user_width, user_height))

  tilepixel_rect, rect_of_tiles = tilecalcs.CalcTileRects(
      proj, user_log_rect, zoom_level)

  logger.info(""Done tile calcs"")

  tiles_array = _FetchTiles(rect_of_tiles, zoom_level, layer_properties)

  im_whole_tiles_extent = geom.Pair(rect_of_tiles.Width() * _TILE_PIXEL_SIZE,
                                    rect_of_tiles.Height() * _TILE_PIXEL_SIZE)

  # Process transparency for map.
  # Presently ""image/png"" is the only picture format
  # which supports transparency.
  # If the picture format is ""image/jpeg"", then send
  # the image as it is, without processing it
  # for any transparency requirements.

  set_pixel_to_bgcolor = (layer_properties.image_format == ""image/png"" and
                          layer_properties.is_transparent == ""FALSE"")

  bgcolor = (layer_properties.bgcolor if set_pixel_to_bgcolor
             else _NO_DATA_PIXELS)
  alpha = _OPAQUE_ALPHA if set_pixel_to_bgcolor else _TRANSPARENT_ALPHA

  # Alpha channel is not required for jpeg formats.
  if layer_properties.image_format == ""image/jpeg"":
    mode = ""RGB""
    color = bgcolor
  else:
    mode = ""RGBA""
    color = bgcolor + alpha

  # If TRANSPARENT = TRUE, image format is ""image/png"",
  # then create a transparent image (alpha = 0) with a black background.

  # If TRANSPARENT = FALSE, image format is ""image/png"",
  # then create an opaque image (alpha = 255) with bgcolor background.

  # Will have unwanted margin but we'll crop it off later.
  im_whole_tiles = Image.new(mode, im_whole_tiles_extent.AsTuple(), color)

  logger.debug(""Tiles rect (in tiles): %s %s"",
               str(rect_of_tiles), str(rect_of_tiles.Extent()))
  logger.debug(""im_whole_tiles pixel extent: %s"",
               str(im_whole_tiles_extent))

  for row in range(rect_of_tiles.Height()):
    for column in range(rect_of_tiles.Width()):
      pos = (
          int(column * _TILE_PIXEL_SIZE),
          int(row * _TILE_PIXEL_SIZE),
          int((column + 1) * _TILE_PIXEL_SIZE),
          int((row + 1) * _TILE_PIXEL_SIZE)
          )
      im_tile = tiles_array.ImageAt(column, row)

      if set_pixel_to_bgcolor:
        im_tile = _SetTransPixelToBgcolor(im_tile, bgcolor)

      # It may be None.
      if im_tile:
        _PasteTile(im_whole_tiles, im_tile, pos)

  logger.debug(""tilepixel_rect: %s"", str(tilepixel_rect))

  # Relative to / within im_whole_tiles.
  # Round down to nearest 256.
  offset_within_tiled_image = geom.Pair(
      tilepixel_rect.x0 % _TILE_PIXEL_SIZE,
      tilepixel_rect.y0 % _TILE_PIXEL_SIZE
      )

  logger.debug(""Offset within: %s"", str(offset_within_tiled_image))

  within_tiled_image = geom.Rect.FromLowerLeftAndExtent(
      offset_within_tiled_image, tilepixel_rect.Extent())

  logger.debug(""Cropping to: %s"", str(within_tiled_image.AsTuple()))

  im_true = im_whole_tiles.crop(within_tiled_image.AsTuple())

  logger.debug(""Stretching to requested: %s"", str(
      (user_width, user_height)))

  # Stretch the final pixels to match the aspect ratio of WIDTH /
  # HEIGHT. This is per the spec; doing this lets the client compensate
  # for non-square pixels.
  im_user = im_true.resize((user_width, user_height), Image.ANTIALIAS)

  return im_user


def _FetchTiles(rect_of_tiles, zoom_level, layer_properties):
  """"""Fetches all the tiles for a given image.

  Args:
      rect_of_tiles: is ul - lr (lr is exclusive!) addresses of tiles at a given
        zoom_level.
      zoom_level: self-explanatory.
      layer_properties: Object with details about the layer.

  Returns:
      ImageArray of the tiles.

  FWIW fetching isn't a big part of the total time for our WMS (~0.3s),
  so we don't bother with threads.
  For 8 tiles, unthreaded was faster - ~0.017s vs ~0.029s;
    http://localhost/wms?LAYERS=1002&
    SERVICE=WMS&VERSION=1.3.0&REQUEST=GetMap&STYLES=&FORMAT=image%2Fjpeg&
    CRS=EPSG:3857&BBOX=-30000000.0,-30000000.0,30000000.0,30000000.0&
    WIDTH=400&HEIGHT=400
  For 16, threaded is faster:  0.108545780182s vs 0.0410861968994s
    http://localhost/wms?LAYERS=1002&SERVICE=WMS&
    VERSION=1.3.0&REQUEST=GetMap&STYLES=&FORMAT=image%2Fjpg&CRS=EPSG:3857&
    BBOX=-400000.0,-400000.0,400000.0,400000.0&WIDTH=800&HEIGHT=800
  """"""
  # <world_extent_in_tiles> is the total tiles vertically and
  # horizontally, so that we know to either wrap around east-west, or
  # fill in with black tiles (per the WMS spec) for north-south
  # out-of-bounds requests.

  logger.info(""Fetching tiles"")
  logger.debug(""rect_of_tiles: %s"", rect_of_tiles)

  world_extent_in_tiles = 2 ** zoom_level
  tiles_array = images.ImagesArray(
      rect_of_tiles.Width(), rect_of_tiles.Height())

  logger.debug(""World extent in tiles: %s"", str(world_extent_in_tiles))

  base_url = layer_properties.GetMapBaseUrl()

  # We don't fetch 'black', empty tiles. They are always whole tiles.
  for abs_tile_row in range(rect_of_tiles.y0, rect_of_tiles.y1):
    # rel_tile_row is the row it will appear in, in the tile image.
    # Ie, [0 - n-1]; top-down.
    # Tile pixel space and tiles are both 'graphics space', ie 0,0 is
    # upper-left corner, down to lower-right.

    rel_tile_row = abs_tile_row - rect_of_tiles.y0
    logger.debug(""Row - abs: %d; rel:%d"", abs_tile_row, rel_tile_row)

    if rel_tile_row < 0:
      logger.error(""Tile row %d - must never be < 0"", rel_tile_row)

    for abs_tile_col in range(rect_of_tiles.x0, rect_of_tiles.x1):
      rel_tile_col = (abs_tile_col - rect_of_tiles.x0)

      if abs_tile_row < 0 or world_extent_in_tiles <= abs_tile_row:
        logger.debug(""[%d] %d, %d is black"",
                     world_extent_in_tiles,
                     abs_tile_col,
                     abs_tile_row)

        # Python Imaging Library (PIL)'s pixels are black by default;
        # we just don't set them.
        tiles_array.AddImage(rel_tile_col, rel_tile_row, None)
      else:
        # If more than 360-worth, could wrap back onto an
        # already-written part of the image array. Though if it did
        # it'd write the same thing so, it's only inefficient, not an
        # error.
        world_wrapped_tile_col = abs_tile_col % world_extent_in_tiles
        tile_args = layer_properties.GetTileArgs(world_wrapped_tile_col,
                                                 abs_tile_row, zoom_level)
        tile_url = base_url + tile_args
        im_tile = _FetchMapTile(tile_url)
        if im_tile:
          if im_tile.size == (1, 1):
            # 1x1 tiles come (probably mostly) from vector layers. They
            # mean that the whole 256x256 tile should be filled with the
            # color & opacity of this pixel.
            im_tile = im_tile.resize((_TILE_PIXEL_SIZE, _TILE_PIXEL_SIZE))
          tiles_array.AddImage(rel_tile_col, rel_tile_row, im_tile)

  return tiles_array


def _SetTransPixelToBgcolor(tile, bgcolor):
  """"""Set the transparent pixels to bgcolor.

  Args:
     tile: Tile as sent from the server.
     bgcolor: BGCOLOR parameter as sent by the GIS client's.
     Default is 0xFFFFFF(white).
  Returns:
     The source tile with transparent pixels fill w/ BGCOLOR and made opaque.
  """"""
  logger.debug(""Processing the transparency for tile"")

  if not tile:
    # Server returned a 404 Error.
    # _FetchmapTile() would return tile = None, in such cases.
    return tile

  # Palette or (1, 1) size tiles have mode ""P"".
  if tile.getbands() == (""P"",):
    # convert the P mode to RGBA mode
    rgba_tile = Image.new(""RGBA"", tile.size)
    rgba_tile.paste(tile)

    # transparent tiles need not be processed, as the grid image is
    # already filled with bgcolor and made opaque.

    # Non-transparent tiles should be returned as it is to be inserted
    # into the grid image.

    tile = (tile if rgba_tile.getpixel((0, 0))[-1] != _TRANSPARENT_ALPHA[0]
            else None)
    return tile

  # RGB mode for PNG tiles.
  # Return the tile as is.
  # This tile will have opaque alpha in the grid image.
  if tile.getbands() == (""R"", ""G"", ""B""):
    return tile

  pixdata = tile.load()
  for row in xrange(tile.size[0]):
    for col in xrange(tile.size[1]):
      # If pixel alpha < threshold, make it opaque and fill it with bgcolor.
      if pixdata[row, col][3] <= _ALPHA_THRESHOLD:
        pixdata[row, col] = bgcolor + _OPAQUE_ALPHA
      else:
        (red, green, blue, alpha) = pixdata[row, col]
        if alpha < _OPAQUE_ALPHA[0]:
          pixdata[row, col] = (red, green, blue) + _OPAQUE_ALPHA

  return tile


def _FetchMapTile(url):
  """"""Fetches and returns a tile, given an url.

  Args:
      url: the exact url of the tile to fetch.

  Returns:
      The tile bitmap.
  """"""
  try:
    f = StringIO.StringIO(wms_connection.HandleConnection(url))
    im_tile = Image.open(f)
    im_tile.load()
  except IOError, e:
    im_tile = None
    logger.error(""Failed to fetch tile:%s"", e)

  return im_tile


def _SaveImage(image, fname, image_spec):
  """"""For debugging; saves the named tile to /tmp.

  Args:
      image: the PIL tile image.
      fname: the name to give the image.
      image_spec: all details about type, extension etc.
  """"""
  try:
    _, t_path = tempfile.mkstemp(suffix=""."" + image_spec.file_extension,
                                 prefix=fname + ""-"")
    # image.info is necessary to get transparency.
    image.save(t_path, image_spec.pil_format, **image.info)
    os.chmod(t_path, 777)
  except IOError, e:
    logger.error(""Failed to save:%s"", str(e.args[0]))
    raise


def _PasteTile(im_dest, im_src, box):
  """"""Copy the image.

  Args:
      im_dest: Destination of the image to be copied.
      im_src: Source image to be copied.
      box: the dimentions of the image.
  """"""
  try:
    im_dest.paste(im_src, box)
  except ValueError, e:
    logger.error(""Failed to paste:%s"", str(e.args[0]))
    logger.debug(""Size %s vs %s"", str(im_src.size), str(im_dest.size))
    logger.debug(""Mode %s vs %s"", str(im_src.mode), str(im_dest.mode))
    raise


def main():
  map_url = (""http://localhost/ca_maps/query?request=ImageryMaps&""
             ""channel=1002&version=1&x=1&y=0&z=1"")
  im = _FetchMapTile(map_url)
  print im

if __name__ == ""__main__"":
  main()
/n/n/nearth_enterprise/src/server/wsgi/wms/ogc/common/wms_connection.py/n/n#!/usr/bin/python
#
# Copyright 2019 Open GEE Contributors
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

""""""Handle connections to WMS API""""""

import ssl
import urllib2
import urlparse
import logging
import configs

CONFIG_FILE = ""/opt/google/gehttpd/wsgi-bin/wms/ogc/wms.cfg""
CONFIGS = configs.Configs(CONFIG_FILE)

logger = logging.getLogger(""wms_maps"")

def HandleConnection(url):
  logger.debug(""Opening url: [%s]"", url)

  if CONFIGS.GetStr(""DATABASE_HOST"") != """":
    url = CONFIGS.GetStr(""DATABASE_HOST"") + urlparse.urlsplit(url)[2:]

  fp = None
  try:
    # Set the context based on cert requirements
    if CONFIGS.GetBool(""VALIDATE_CERTIFICATE""):
      cert_file = CONFIGS.GetStr(""CERTIFICATE_CHAIN_PATH"")
      key_file = CONFIGS.GetStr(""CERTIFICATE_KEY_PATH"")
      context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
      context.load_cert_chain(cert_file, keyfile=key_file)
    else:
      context = ssl.create_default_context()
      context.check_hostname = False
      context.verify_mode = ssl.CERT_NONE

    fp = urllib2.urlopen(url, context=context)
    response = fp.read()
  except urllib2.HTTPError, e:
    logger.warning(""Server definitions didn't return any results %s."", e)
    return {}
  finally:
    if fp:
      fp.close()

  return response
/n/n/nearth_enterprise/src/server/wsgi/wms/ogc/gee/maps_server_handler.py/n/n#!/usr/bin/python
#
# Copyright 2017 Google Inc.
# Copyright 2019 Open GEE Contributors
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

""""""Code and objects that know about the servers.""""""

import json
import logging
import re
import ssl
from socket import gethostname
import urlparse

import wms.ogc.common.wms_connection as wms_connection
import wms.ogc.common.projections as projections

# Example 'serverDefs' from Maps/Portable. The parts we use are the same
# for GEMap server.

# var geeServerDefs = {
# isAuthenticated : false,
# layers :
# [
# {
# icon : ""icons/773_l.png"",
# id : 1004,
# initialState : true,
# isPng : false,
# label : ""Imagery"",
# lookAt : ""none"",
# opacity : 1,
# requestType : ""ImageryMaps"",
# version : 8
# }
# ,
# {
# icon : ""icons/773_l.png"",
# id : 1002,
# initialState : true,
# isPng : true,
# label : ""SF info"",
# lookAt : ""none"",
# opacity : 1,
# requestType : ""VectorMapsRaster"",
# version : 4
# }
# ]
# ,
# projection : ""mercator"",
# ...
# url : ""http://localhost:9335/SearchServlet/MapsAdapter?\
#        service=GEPlacesPlugin&DbId=42""
# ...


_LAYER_ARG_NAMES = {
    ""ImageryMaps"": {
        ""x"": ""x"",
        ""y"": ""y"",
        ""z"": ""z""},
    ""VectorMapsRaster"": {
        ""x"": ""col"",
        ""y"": ""row"",
        ""z"": ""level""},
    ""ImageryMapsMercator"": {
        ""x"": ""x"",
        ""y"": ""y"",
        ""z"": ""z""}
    }

_SERVER_DEF_URL = ""query?request=Json&var=geeServerDefs&is2d=t""
_TILE_BASE_URL = ""%s/query?request=%s""
_IMAGE_FMT = ""&format=%s""
_CHANNEL_VERSION = ""&channel=%s&version=%s""
_TILE_ARGS = ""&%s=%d&%s=%d&%s=%d""

# TODO: Support for ""glc"" type database should be added.
_SUPPORTED_DB_TYPES = (""gemap"", ""gedb"", ""glm"", ""glb"")

# Get logger
logger = logging.getLogger(""wms_maps"")


class WmsLayer(object):
  """"""Represents everything a client needs to deal with a server layer.""""""

  def __init__(
      self,
      target_url,
      name,
      layer_id,
      label,
      projection,
      request_type,
      db_type,
      version,
      tile_arg_names):
    self.target_url = target_url
    self.name = name
    self.layer_id = layer_id
    self.label = label
    self.projection = projection
    self.request_type = request_type
    self.db_type = db_type
    self.version = str(version)
    self.tile_arg_names = tile_arg_names

    # Add a variable to store the requested
    # image format for an image.
    # This would be of type ""jpeg"" or ""png"".
    # Make ""jpeg"" as default value.
    # This variable will be updated with the
    # user request format at a later stage.
    self.image_format = ""image/jpeg""

  @staticmethod
  def Make(target_url, server_layer_def):
    """"""Make a WmsLayer object from a serverDefs layer.

    Args:
      target_url: The server's target url, after which we'll append '?query...'
      server_layer_def: JSON layer spec.
    Returns:
        A WmsLayer object.
    """"""

    # 'layer_ns' is namespace to distinguish layers of the same target path.
    target_path = urlparse.urlsplit(target_url).path[1:]
    layer_ns = ""[%s]:%s"" %(target_path, str(server_layer_def[""id""]))

    if server_layer_def[""projection""] == ""mercator"":
      projection = projections.Mercator()
    else:
      projection = projections.Flat()

    # Note: By default, the requestType is set to 'ImageryMaps' since the
    # requestType-property doesn't present in 3D Fusion Database.
    request_type = server_layer_def.get(""requestType"", ""ImageryMaps"")

    tile_arg_names = _LAYER_ARG_NAMES[request_type]

    # TODO: support multi-layered maps (contain glm_id in json).
    version_info = server_layer_def.get(""version"", None)

    layer = WmsLayer(
        target_url=target_url,
        name=layer_ns,
        layer_id=str(server_layer_def[""id""]),
        label=server_layer_def[""label""],
        projection=projection,
        request_type=request_type,
        db_type=server_layer_def[""db_type""],
        version=version_info,
        tile_arg_names=tile_arg_names
        )

    return layer

  def GetMapBaseUrl(self):
    """"""Prepares the base URL for fetching tiles.""""""

    # Add 'requestType' parameter to the URL.
    base_url = _TILE_BASE_URL % (self.target_url, self.request_type)

    # Add 'format' parameter to the URL.
    base_url += _IMAGE_FMT % self.image_format

    if self.db_type == ""gemap"":
      # 'channel' and 'version' information is
      # required only for 'gemap' database types.
      base_url += _CHANNEL_VERSION % (self.layer_id, self.version)

    return base_url

  def GetTileArgs(self, x, y, z):
    """"""Prepares the URL for fetching tiles.""""""
    tile_args = _TILE_ARGS % (
        self.tile_arg_names[""x""], x,
        self.tile_arg_names[""y""], y,
        self.tile_arg_names[""z""], z
        )

    return tile_args


def _GetServerVars(target_url):
  """"""Fetches the server definitions from the Maps server.

  Args:
      target_url: The url of the server with target path.
  Returns:
      The server definitions for specified target.
  """"""

  if target_url[-1] != ""/"":
    target_url += ""/""

  logger.debug(""Fetching server definitions over http"")

  target_url = urlparse.urljoin(target_url, _SERVER_DEF_URL)

  result = wms_connection.HandleConnection(target_url)

  logger.debug(""Server definitions data read, start regex"")
  logger.debug(""JSON vars: %s"", result)

  # Clean up the JS -> JSON
  # leading line
  p = re.compile(r""var geeServerDefs ="")
  result = p.sub("""", result)

  # final line
  p = re.compile(r"";\s*$"")
  result = p.sub("""", result)

  # Adds quotes to bare keywords, changing from JavaScript to
  # actual JSON. (\s* absorbs newlines, & all keys are on their own lines.)
  p = re.compile(r""([\[\{,])\s*(\w+)\s*:"")
  result = p.sub(r'\g<1>""\g<2>"":', result)

  return json.loads(result)


def _LayersFromServerVars(target_url):
  """"""Fetch layer information from ServerVars.

  Args:
    target_url: Server URL hosting the target database.
  Returns:
    layers_by_name: A dict of all the layers in a database.
  """"""
  layers_by_name = {}

  server_vars = _GetServerVars(target_url)

  # ""server_vars"" would be empty({}) if the target doesn't exist.
  # This kind of error would be handled even before reaching this point.
  # A check for server_vars being empty ({}) is not required here
  # for the same reason.

  if not server_vars.has_key(""dbType""):
    # Old databases do not have the ""dbType"" parameter in geeServerDefs.
    # Detect type of db based on the projection field for old databases.
    # gedb has no projection specified,
    if server_vars.has_key(""projection""):
      server_vars[""dbType""] = ""gemap""
    else:
      server_vars[""dbType""] = ""gedb""

  # No explicit projection, then it is gedb, default to 'flat'.
  if not server_vars.has_key(""projection""):
    server_vars[""projection""] = ""flat""

  logger.debug(""Servers projection: %s"", server_vars[""projection""])
  logger.debug(""Server database type: %s"", server_vars[""dbType""])

  # Error out when db_type is not supported.
  if server_vars[""dbType""] not in _SUPPORTED_DB_TYPES:
    logger.error(""GEE WMS implementation doesn't support database""
                 ""type '%s'"", server_vars[""dbType""])
    # In this scenario, return an empty({}) layers_by_name.
    return layers_by_name

  for server_layer_def in server_vars[""layers""]:

    # TODO: Use layer projection for GetCapabilities.
    # This will allow the service to serve flat imagery as both 'flat'
    # and 'mercator' based projections.

    # propagate server's 'global' projection name to each layer.
    server_layer_def[""projection""] = server_vars[""projection""]

    # propagate server's 'global' database type to each layer.
    server_layer_def[""db_type""] = server_vars[""dbType""]

    layer = WmsLayer.Make(target_url, server_layer_def)
    layers_by_name[layer.name] = layer

    logger.debug(""Found server layer: %s"", layer.name)

  logger.debug(""Layers processing done"")

  return layers_by_name


class GEELayer(object):
  """"""Represents a Google Earth Enterprise Layer server.""""""

  def __init__(self):
    logger.debug(""Initializing GEELayer"")

  def GetLayers(self, server_url, target_path):
    """"""Returns WmsLayer representations of the server's layers.

    These contain metainfo, and the ability to fetch tiles -
    everything a code client needs to know about and use, to get
    tiles from a server.


    Args:
     server_url: URL of the server on which command to be executed.
     target_path: Target published point.
    Returns:
        The layers from the server definitions.
    """"""
    target_url = urlparse.urljoin(server_url, target_path)
    logger.debug(""Fetching layer information for target url '%s'"", target_url)

    layers_by_name = _LayersFromServerVars(target_url)

    for layer_name in layers_by_name.keys():
      # Ignore Vector layers  from 3d types.
      if layers_by_name[layer_name].db_type in (""gedb"", ""glb""):
        if layers_by_name[layer_name].label != ""Imagery"":
          # Delete the non-Imagery layer.
          layers_by_name.pop(layer_name)

    return layers_by_name


def main():
  obj = GEELayer()

  hostname = gethostname()
  target_path = ""merc""

  server_url = ""http://%s.xxx.xxx.com"" % hostname
  results = obj.GetLayers(server_url, target_path)

  print results

if __name__ == ""__main__"":
  main()
/n/n/n",0
157,157,f2ff5ba9d250b8d34c5b48429ba5f632cb2040b1,"/earth_enterprise/src/server/wsgi/wms/ogc/common/tiles.py/n/n#!/usr/bin/python
#
# Copyright 2017 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


""""""Deals with fetching tiles and composing them for the final image.""""""

import logging
import os
import StringIO
import tempfile
import urllib

import geom
import images
import PIL.Image as Image
import tilecalcs

logger = logging.getLogger(""wms_maps"")
_TILE_PIXEL_SIZE = 256
_NO_DATA_PIXELS = (0, 0, 0)
_OPAQUE_ALPHA = (255,)
_TRANSPARENT_ALPHA = (0,)
_ALPHA_THRESHOLD = 128
ALL_WHITE_PIXELS = (255, 255, 255)


def ProduceImage(layer_properties, user_log_rect, user_width, user_height):
  """"""High-level production of the image.

  Args:
      layer_properties: Object with details about the layer.
      user_log_rect: The user-requested projected, ie map coordinates,
        not lat/lon, limits of the desired region. Ie BBOX, pretty much.
      user_width: The user-requested width of the image.
      user_height: The user-requested height of the image.

  Returns:
      The image to be presented to the user.
  """"""
  proj = layer_properties.projection

  zoom_level = tilecalcs.CalcZoomLevel(user_log_rect.Extent(),
                                       proj.InternalLogOuterBounds().Extent(),
                                       geom.Pair(user_width, user_height))

  tilepixel_rect, rect_of_tiles = tilecalcs.CalcTileRects(
      proj, user_log_rect, zoom_level)

  logger.info(""Done tile calcs"")

  tiles_array = _FetchTiles(rect_of_tiles, zoom_level, layer_properties)

  im_whole_tiles_extent = geom.Pair(rect_of_tiles.Width() * _TILE_PIXEL_SIZE,
                                    rect_of_tiles.Height() * _TILE_PIXEL_SIZE)

  # Process transparency for map.
  # Presently ""image/png"" is the only picture format
  # which supports transparency.
  # If the picture format is ""image/jpeg"", then send
  # the image as it is, without processing it
  # for any transparency requirements.

  set_pixel_to_bgcolor = (layer_properties.image_format == ""image/png"" and
                          layer_properties.is_transparent == ""FALSE"")

  bgcolor = (layer_properties.bgcolor if set_pixel_to_bgcolor
             else _NO_DATA_PIXELS)
  alpha = _OPAQUE_ALPHA if set_pixel_to_bgcolor else _TRANSPARENT_ALPHA

  # Alpha channel is not required for jpeg formats.
  if layer_properties.image_format == ""image/jpeg"":
    mode = ""RGB""
    color = bgcolor
  else:
    mode = ""RGBA""
    color = bgcolor + alpha

  # If TRANSPARENT = TRUE, image format is ""image/png"",
  # then create a transparent image (alpha = 0) with a black background.

  # If TRANSPARENT = FALSE, image format is ""image/png"",
  # then create an opaque image (alpha = 255) with bgcolor background.

  # Will have unwanted margin but we'll crop it off later.
  im_whole_tiles = Image.new(mode, im_whole_tiles_extent.AsTuple(), color)

  logger.debug(""Tiles rect (in tiles): %s %s"",
               str(rect_of_tiles), str(rect_of_tiles.Extent()))
  logger.debug(""im_whole_tiles pixel extent: %s"",
               str(im_whole_tiles_extent))

  for row in range(rect_of_tiles.Height()):
    for column in range(rect_of_tiles.Width()):
      pos = (
          int(column * _TILE_PIXEL_SIZE),
          int(row * _TILE_PIXEL_SIZE),
          int((column + 1) * _TILE_PIXEL_SIZE),
          int((row + 1) * _TILE_PIXEL_SIZE)
          )
      im_tile = tiles_array.ImageAt(column, row)

      if set_pixel_to_bgcolor:
        im_tile = _SetTransPixelToBgcolor(im_tile, bgcolor)

      # It may be None.
      if im_tile:
        _PasteTile(im_whole_tiles, im_tile, pos)

  logger.debug(""tilepixel_rect: %s"", str(tilepixel_rect))

  # Relative to / within im_whole_tiles.
  # Round down to nearest 256.
  offset_within_tiled_image = geom.Pair(
      tilepixel_rect.x0 % _TILE_PIXEL_SIZE,
      tilepixel_rect.y0 % _TILE_PIXEL_SIZE
      )

  logger.debug(""Offset within: %s"", str(offset_within_tiled_image))

  within_tiled_image = geom.Rect.FromLowerLeftAndExtent(
      offset_within_tiled_image, tilepixel_rect.Extent())

  logger.debug(""Cropping to: %s"", str(within_tiled_image.AsTuple()))

  im_true = im_whole_tiles.crop(within_tiled_image.AsTuple())

  logger.debug(""Stretching to requested: %s"", str(
      (user_width, user_height)))

  # Stretch the final pixels to match the aspect ratio of WIDTH /
  # HEIGHT. This is per the spec; doing this lets the client compensate
  # for non-square pixels.
  im_user = im_true.resize((user_width, user_height), Image.ANTIALIAS)

  return im_user


def _FetchTiles(rect_of_tiles, zoom_level, layer_properties):
  """"""Fetches all the tiles for a given image.

  Args:
      rect_of_tiles: is ul - lr (lr is exclusive!) addresses of tiles at a given
        zoom_level.
      zoom_level: self-explanatory.
      layer_properties: Object with details about the layer.

  Returns:
      ImageArray of the tiles.

  FWIW fetching isn't a big part of the total time for our WMS (~0.3s),
  so we don't bother with threads.
  For 8 tiles, unthreaded was faster - ~0.017s vs ~0.029s;
    http://localhost/wms?LAYERS=1002&
    SERVICE=WMS&VERSION=1.3.0&REQUEST=GetMap&STYLES=&FORMAT=image%2Fjpeg&
    CRS=EPSG:3857&BBOX=-30000000.0,-30000000.0,30000000.0,30000000.0&
    WIDTH=400&HEIGHT=400
  For 16, threaded is faster:  0.108545780182s vs 0.0410861968994s
    http://localhost/wms?LAYERS=1002&SERVICE=WMS&
    VERSION=1.3.0&REQUEST=GetMap&STYLES=&FORMAT=image%2Fjpg&CRS=EPSG:3857&
    BBOX=-400000.0,-400000.0,400000.0,400000.0&WIDTH=800&HEIGHT=800
  """"""
  # <world_extent_in_tiles> is the total tiles vertically and
  # horizontally, so that we know to either wrap around east-west, or
  # fill in with black tiles (per the WMS spec) for north-south
  # out-of-bounds requests.

  logger.info(""Fetching tiles"")
  logger.debug(""rect_of_tiles: %s"", rect_of_tiles)

  world_extent_in_tiles = 2 ** zoom_level
  tiles_array = images.ImagesArray(
      rect_of_tiles.Width(), rect_of_tiles.Height())

  logger.debug(""World extent in tiles: %s"", str(world_extent_in_tiles))

  base_url = layer_properties.GetMapBaseUrl()

  # We don't fetch 'black', empty tiles. They are always whole tiles.
  for abs_tile_row in range(rect_of_tiles.y0, rect_of_tiles.y1):
    # rel_tile_row is the row it will appear in, in the tile image.
    # Ie, [0 - n-1]; top-down.
    # Tile pixel space and tiles are both 'graphics space', ie 0,0 is
    # upper-left corner, down to lower-right.

    rel_tile_row = abs_tile_row - rect_of_tiles.y0
    logger.debug(""Row - abs: %d; rel:%d"", abs_tile_row, rel_tile_row)

    if rel_tile_row < 0:
      logger.error(""Tile row %d - must never be < 0"", rel_tile_row)

    for abs_tile_col in range(rect_of_tiles.x0, rect_of_tiles.x1):
      rel_tile_col = (abs_tile_col - rect_of_tiles.x0)

      if abs_tile_row < 0 or world_extent_in_tiles <= abs_tile_row:
        logger.debug(""[%d] %d, %d is black"",
                     world_extent_in_tiles,
                     abs_tile_col,
                     abs_tile_row)

        # Python Imaging Library (PIL)'s pixels are black by default;
        # we just don't set them.
        tiles_array.AddImage(rel_tile_col, rel_tile_row, None)
      else:
        # If more than 360-worth, could wrap back onto an
        # already-written part of the image array. Though if it did
        # it'd write the same thing so, it's only inefficient, not an
        # error.
        world_wrapped_tile_col = abs_tile_col % world_extent_in_tiles
        tile_args = layer_properties.GetTileArgs(world_wrapped_tile_col,
                                                 abs_tile_row, zoom_level)
        tile_url = base_url + tile_args
        im_tile = _FetchMapTile(tile_url)
        if im_tile:
          if im_tile.size == (1, 1):
            # 1x1 tiles come (probably mostly) from vector layers. They
            # mean that the whole 256x256 tile should be filled with the
            # color & opacity of this pixel.
            im_tile = im_tile.resize((_TILE_PIXEL_SIZE, _TILE_PIXEL_SIZE))
          tiles_array.AddImage(rel_tile_col, rel_tile_row, im_tile)

  return tiles_array


def _SetTransPixelToBgcolor(tile, bgcolor):
  """"""Set the transparent pixels to bgcolor.

  Args:
     tile: Tile as sent from the server.
     bgcolor: BGCOLOR parameter as sent by the GIS client's.
     Default is 0xFFFFFF(white).
  Returns:
     The source tile with transparent pixels fill w/ BGCOLOR and made opaque.
  """"""
  logger.debug(""Processing the transparency for tile"")

  if not tile:
    # Server returned a 404 Error.
    # _FetchmapTile() would return tile = None, in such cases.
    return tile

  # Palette or (1, 1) size tiles have mode ""P"".
  if tile.getbands() == (""P"",):
    # convert the P mode to RGBA mode
    rgba_tile = Image.new(""RGBA"", tile.size)
    rgba_tile.paste(tile)

    # transparent tiles need not be processed, as the grid image is
    # already filled with bgcolor and made opaque.

    # Non-transparent tiles should be returned as it is to be inserted
    # into the grid image.

    tile = (tile if rgba_tile.getpixel((0, 0))[-1] != _TRANSPARENT_ALPHA[0]
            else None)
    return tile

  # RGB mode for PNG tiles.
  # Return the tile as is.
  # This tile will have opaque alpha in the grid image.
  if tile.getbands() == (""R"", ""G"", ""B""):
    return tile

  pixdata = tile.load()
  for row in xrange(tile.size[0]):
    for col in xrange(tile.size[1]):
      # If pixel alpha < threshold, make it opaque and fill it with bgcolor.
      if pixdata[row, col][3] <= _ALPHA_THRESHOLD:
        pixdata[row, col] = bgcolor + _OPAQUE_ALPHA
      else:
        (red, green, blue, alpha) = pixdata[row, col]
        if alpha < _OPAQUE_ALPHA[0]:
          pixdata[row, col] = (red, green, blue) + _OPAQUE_ALPHA

  return tile


def _FetchMapTile(url):
  """"""Fetches and returns a tile, given an url.

  Args:
      url: the exact url of the tile to fetch.

  Returns:
      The tile bitmap.
  """"""
  try:
    fp = urllib.urlopen(url)
    f = StringIO.StringIO(fp.read())
    im_tile = Image.open(f)
    im_tile.load()
  except IOError, e:
    im_tile = None
    logger.error(""Failed to fetch tile:%s"", e)
  finally:
    if fp:
      fp.close()

  return im_tile


def _SaveImage(image, fname, image_spec):
  """"""For debugging; saves the named tile to /tmp.

  Args:
      image: the PIL tile image.
      fname: the name to give the image.
      image_spec: all details about type, extension etc.
  """"""
  try:
    _, t_path = tempfile.mkstemp(suffix=""."" + image_spec.file_extension,
                                 prefix=fname + ""-"")
    # image.info is necessary to get transparency.
    image.save(t_path, image_spec.pil_format, **image.info)
    os.chmod(t_path, 777)
  except IOError, e:
    logger.error(""Failed to save:%s"", str(e.args[0]))
    raise


def _PasteTile(im_dest, im_src, box):
  """"""Copy the image.

  Args:
      im_dest: Destination of the image to be copied.
      im_src: Source image to be copied.
      box: the dimentions of the image.
  """"""
  try:
    im_dest.paste(im_src, box)
  except ValueError, e:
    logger.error(""Failed to paste:%s"", str(e.args[0]))
    logger.debug(""Size %s vs %s"", str(im_src.size), str(im_dest.size))
    logger.debug(""Mode %s vs %s"", str(im_src.mode), str(im_dest.mode))
    raise


def main():
  map_url = (""http://localhost/ca_maps/query?request=ImageryMaps&""
             ""channel=1002&version=1&x=1&y=0&z=1"")
  im = _FetchMapTile(map_url)
  print im

if __name__ == ""__main__"":
  main()
/n/n/n/earth_enterprise/src/server/wsgi/wms/ogc/gee/maps_server_handler.py/n/n#!/usr/bin/python
#
# Copyright 2017 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

""""""Code and objects that know about the servers.""""""

import json
import logging
import re
from socket import gethostname
import urllib2
import urlparse

import wms.ogc.common.projections as projections

# Example 'serverDefs' from Maps/Portable. The parts we use are the same
# for GEMap server.

# var geeServerDefs = {
# isAuthenticated : false,
# layers :
# [
# {
# icon : ""icons/773_l.png"",
# id : 1004,
# initialState : true,
# isPng : false,
# label : ""Imagery"",
# lookAt : ""none"",
# opacity : 1,
# requestType : ""ImageryMaps"",
# version : 8
# }
# ,
# {
# icon : ""icons/773_l.png"",
# id : 1002,
# initialState : true,
# isPng : true,
# label : ""SF info"",
# lookAt : ""none"",
# opacity : 1,
# requestType : ""VectorMapsRaster"",
# version : 4
# }
# ]
# ,
# projection : ""mercator"",
# ...
# url : ""http://localhost:9335/SearchServlet/MapsAdapter?\
#        service=GEPlacesPlugin&DbId=42""
# ...


_LAYER_ARG_NAMES = {
    ""ImageryMaps"": {
        ""x"": ""x"",
        ""y"": ""y"",
        ""z"": ""z""},
    ""VectorMapsRaster"": {
        ""x"": ""col"",
        ""y"": ""row"",
        ""z"": ""level""},
    ""ImageryMapsMercator"": {
        ""x"": ""x"",
        ""y"": ""y"",
        ""z"": ""z""}
    }

_SERVER_DEF_URL = ""query?request=Json&var=geeServerDefs&is2d=t""
_TILE_BASE_URL = ""%s/query?request=%s""
_IMAGE_FMT = ""&format=%s""
_CHANNEL_VERSION = ""&channel=%s&version=%s""
_TILE_ARGS = ""&%s=%d&%s=%d&%s=%d""

# TODO: Support for ""glc"" type database should be added.
_SUPPORTED_DB_TYPES = (""gemap"", ""gedb"", ""glm"", ""glb"")

# Get logger
logger = logging.getLogger(""wms_maps"")


class WmsLayer(object):
  """"""Represents everything a client needs to deal with a server layer.""""""

  def __init__(
      self,
      target_url,
      name,
      layer_id,
      label,
      projection,
      request_type,
      db_type,
      version,
      tile_arg_names):
    self.target_url = target_url
    self.name = name
    self.layer_id = layer_id
    self.label = label
    self.projection = projection
    self.request_type = request_type
    self.db_type = db_type
    self.version = str(version)
    self.tile_arg_names = tile_arg_names

    # Add a variable to store the requested
    # image format for an image.
    # This would be of type ""jpeg"" or ""png"".
    # Make ""jpeg"" as default value.
    # This variable will be updated with the
    # user request format at a later stage.
    self.image_format = ""image/jpeg""

  @staticmethod
  def Make(target_url, server_layer_def):
    """"""Make a WmsLayer object from a serverDefs layer.

    Args:
      target_url: The server's target url, after which we'll append '?query...'
      server_layer_def: JSON layer spec.
    Returns:
        A WmsLayer object.
    """"""

    # 'layer_ns' is namespace to distinguish layers of the same target path.
    target_path = urlparse.urlsplit(target_url).path[1:]
    layer_ns = ""[%s]:%s"" %(target_path, str(server_layer_def[""id""]))

    if server_layer_def[""projection""] == ""mercator"":
      projection = projections.Mercator()
    else:
      projection = projections.Flat()

    # Note: By default, the requestType is set to 'ImageryMaps' since the
    # requestType-property doesn't present in 3D Fusion Database.
    request_type = server_layer_def.get(""requestType"", ""ImageryMaps"")

    tile_arg_names = _LAYER_ARG_NAMES[request_type]

    # TODO: support multi-layered maps (contain glm_id in json).
    version_info = server_layer_def.get(""version"", None)

    layer = WmsLayer(
        target_url=target_url,
        name=layer_ns,
        layer_id=str(server_layer_def[""id""]),
        label=server_layer_def[""label""],
        projection=projection,
        request_type=request_type,
        db_type=server_layer_def[""db_type""],
        version=version_info,
        tile_arg_names=tile_arg_names
        )

    return layer

  def GetMapBaseUrl(self):
    """"""Prepares the base URL for fetching tiles.""""""

    # Add 'requestType' parameter to the URL.
    base_url = _TILE_BASE_URL % (self.target_url, self.request_type)

    # Add 'format' parameter to the URL.
    base_url += _IMAGE_FMT % self.image_format

    if self.db_type == ""gemap"":
      # 'channel' and 'version' information is
      # required only for 'gemap' database types.
      base_url += _CHANNEL_VERSION % (self.layer_id, self.version)

    return base_url

  def GetTileArgs(self, x, y, z):
    """"""Prepares the URL for fetching tiles.""""""
    tile_args = _TILE_ARGS % (
        self.tile_arg_names[""x""], x,
        self.tile_arg_names[""y""], y,
        self.tile_arg_names[""z""], z
        )

    return tile_args


def _GetServerVars(target_url):
  """"""Fetches the server definitions from the Maps server.

  Args:
      target_url: The url of the server with target path.
  Returns:
      The server definitions for specified target.
  """"""

  if target_url[-1] != ""/"":
    target_url += ""/""

  logger.debug(""Fetching server definitions over http"")

  target_url = urlparse.urljoin(target_url, _SERVER_DEF_URL)

  logger.debug(""Opening url: [%s]"", target_url)

  try:
    fp = urllib2.urlopen(target_url)
    result = fp.read()
  except urllib2.HTTPError, e:
    logger.warning(""Server definitions didn't return any results %s."", e)
    return {}

  fp.close()

  logger.debug(""Server definitions data read, start regex"")
  logger.debug(""JSON vars: %s"", result)

  # Clean up the JS -> JSON
  # leading line
  p = re.compile(r""var geeServerDefs ="")
  result = p.sub("""", result)

  # final line
  p = re.compile(r"";\s*$"")
  result = p.sub("""", result)

  # Adds quotes to bare keywords, changing from JavaScript to
  # actual JSON. (\s* absorbs newlines, & all keys are on their own lines.)
  p = re.compile(r""([\[\{,])\s*(\w+)\s*:"")
  result = p.sub(r'\g<1>""\g<2>"":', result)

  return json.loads(result)


def _LayersFromServerVars(target_url):
  """"""Fetch layer information from ServerVars.

  Args:
    target_url: Server URL hosting the target database.
  Returns:
    layers_by_name: A dict of all the layers in a database.
  """"""
  layers_by_name = {}

  server_vars = _GetServerVars(target_url)

  # ""server_vars"" would be empty({}) if the target doesn't exist.
  # This kind of error would be handled even before reaching this point.
  # A check for server_vars being empty ({}) is not required here
  # for the same reason.

  if not server_vars.has_key(""dbType""):
    # Old databases do not have the ""dbType"" parameter in geeServerDefs.
    # Detect type of db based on the projection field for old databases.
    # gedb has no projection specified,
    if server_vars.has_key(""projection""):
      server_vars[""dbType""] = ""gemap""
    else:
      server_vars[""dbType""] = ""gedb""

  # No explicit projection, then it is gedb, default to 'flat'.
  if not server_vars.has_key(""projection""):
    server_vars[""projection""] = ""flat""

  logger.debug(""Servers projection: %s"", server_vars[""projection""])
  logger.debug(""Server database type: %s"", server_vars[""dbType""])

  # Error out when db_type is not supported.
  if server_vars[""dbType""] not in _SUPPORTED_DB_TYPES:
    logger.error(""GEE WMS implementation doesn't support database""
                 ""type '%s'"", server_vars[""dbType""])
    # In this scenario, return an empty({}) layers_by_name.
    return layers_by_name

  for server_layer_def in server_vars[""layers""]:

    # TODO: Use layer projection for GetCapabilities.
    # This will allow the service to serve flat imagery as both 'flat'
    # and 'mercator' based projections.

    # propagate server's 'global' projection name to each layer.
    server_layer_def[""projection""] = server_vars[""projection""]

    # propagate server's 'global' database type to each layer.
    server_layer_def[""db_type""] = server_vars[""dbType""]

    layer = WmsLayer.Make(target_url, server_layer_def)
    layers_by_name[layer.name] = layer

    logger.debug(""Found server layer: %s"", layer.name)

  logger.debug(""Layers processing done"")

  return layers_by_name


class GEELayer(object):
  """"""Represents a Google Earth Enterprise Layer server.""""""

  def __init__(self):
    logger.debug(""Initializing GEELayer"")

  def GetLayers(self, server_url, target_path):
    """"""Returns WmsLayer representations of the server's layers.

    These contain metainfo, and the ability to fetch tiles -
    everything a code client needs to know about and use, to get
    tiles from a server.


    Args:
     server_url: URL of the server on which command to be executed.
     target_path: Target published point.
    Returns:
        The layers from the server definitions.
    """"""
    target_url = urlparse.urljoin(server_url, target_path)
    logger.debug(""Fetching layer information for target url '%s'"", target_url)

    layers_by_name = _LayersFromServerVars(target_url)

    for layer_name in layers_by_name.keys():
      # Ignore Vector layers  from 3d types.
      if layers_by_name[layer_name].db_type in (""gedb"", ""glb""):
        if layers_by_name[layer_name].label != ""Imagery"":
          # Delete the non-Imagery layer.
          layers_by_name.pop(layer_name)

    return layers_by_name


def main():
  obj = GEELayer()

  hostname = gethostname()
  target_path = ""merc""

  server_url = ""http://%s.xxx.xxx.com"" % hostname
  results = obj.GetLayers(server_url, target_path)

  print results

if __name__ == ""__main__"":
  main()
/n/n/n",1
34,34,43b55308a6467a5b8880bb40b71ec0821cb76398,"common/djangoapps/student/helpers.py/n/n""""""Helpers for the student app. """"""
import logging
import mimetypes
import urllib
import urlparse
from datetime import datetime

from django.conf import settings
from django.core.urlresolvers import NoReverseMatch, reverse
from django.utils import http
from oauth2_provider.models import AccessToken as dot_access_token
from oauth2_provider.models import RefreshToken as dot_refresh_token
from provider.oauth2.models import AccessToken as dop_access_token
from provider.oauth2.models import RefreshToken as dop_refresh_token
from pytz import UTC

import third_party_auth
from course_modes.models import CourseMode
from lms.djangoapps.verify_student.models import SoftwareSecurePhotoVerification, VerificationDeadline
from openedx.core.djangoapps.site_configuration import helpers as configuration_helpers
from openedx.core.djangoapps.theming.helpers import get_themes

# Enumeration of per-course verification statuses
# we display on the student dashboard.
VERIFY_STATUS_NEED_TO_VERIFY = ""verify_need_to_verify""
VERIFY_STATUS_SUBMITTED = ""verify_submitted""
VERIFY_STATUS_RESUBMITTED = ""re_verify_submitted""
VERIFY_STATUS_APPROVED = ""verify_approved""
VERIFY_STATUS_MISSED_DEADLINE = ""verify_missed_deadline""
VERIFY_STATUS_NEED_TO_REVERIFY = ""verify_need_to_reverify""

DISABLE_UNENROLL_CERT_STATES = [
    'generating',
    'ready',
]


log = logging.getLogger(__name__)


def check_verify_status_by_course(user, course_enrollments):
    """"""
    Determine the per-course verification statuses for a given user.

    The possible statuses are:
        * VERIFY_STATUS_NEED_TO_VERIFY: The student has not yet submitted photos for verification.
        * VERIFY_STATUS_SUBMITTED: The student has submitted photos for verification,
          but has have not yet been approved.
        * VERIFY_STATUS_RESUBMITTED: The student has re-submitted photos for re-verification while
          they still have an active but expiring ID verification
        * VERIFY_STATUS_APPROVED: The student has been successfully verified.
        * VERIFY_STATUS_MISSED_DEADLINE: The student did not submit photos within the course's deadline.
        * VERIFY_STATUS_NEED_TO_REVERIFY: The student has an active verification, but it is
            set to expire before the verification deadline for the course.

    It is is also possible that a course does NOT have a verification status if:
        * The user is not enrolled in a verified mode, meaning that the user didn't pay.
        * The course does not offer a verified mode.
        * The user submitted photos but an error occurred while verifying them.
        * The user submitted photos but the verification was denied.

    In the last two cases, we rely on messages in the sidebar rather than displaying
    messages for each course.

    Arguments:
        user (User): The currently logged-in user.
        course_enrollments (list[CourseEnrollment]): The courses the user is enrolled in.

    Returns:
        dict: Mapping of course keys verification status dictionaries.
            If no verification status is applicable to a course, it will not
            be included in the dictionary.
            The dictionaries have these keys:
                * status (str): One of the enumerated status codes.
                * days_until_deadline (int): Number of days until the verification deadline.
                * verification_good_until (str): Date string for the verification expiration date.

    """"""
    status_by_course = {}

    # Retrieve all verifications for the user, sorted in descending
    # order by submission datetime
    verifications = SoftwareSecurePhotoVerification.objects.filter(user=user)

    # Check whether the user has an active or pending verification attempt
    # To avoid another database hit, we re-use the queryset we have already retrieved.
    has_active_or_pending = SoftwareSecurePhotoVerification.user_has_valid_or_pending(
        user, queryset=verifications
    )

    # Retrieve expiration_datetime of most recent approved verification
    # To avoid another database hit, we re-use the queryset we have already retrieved.
    expiration_datetime = SoftwareSecurePhotoVerification.get_expiration_datetime(user, verifications)
    verification_expiring_soon = SoftwareSecurePhotoVerification.is_verification_expiring_soon(expiration_datetime)

    # Retrieve verification deadlines for the enrolled courses
    enrolled_course_keys = [enrollment.course_id for enrollment in course_enrollments]
    course_deadlines = VerificationDeadline.deadlines_for_courses(enrolled_course_keys)

    recent_verification_datetime = None

    for enrollment in course_enrollments:

        # If the user hasn't enrolled as verified, then the course
        # won't display state related to its verification status.
        if enrollment.mode in CourseMode.VERIFIED_MODES:

            # Retrieve the verification deadline associated with the course.
            # This could be None if the course doesn't have a deadline.
            deadline = course_deadlines.get(enrollment.course_id)

            relevant_verification = SoftwareSecurePhotoVerification.verification_for_datetime(deadline, verifications)

            # Picking the max verification datetime on each iteration only with approved status
            if relevant_verification is not None and relevant_verification.status == ""approved"":
                recent_verification_datetime = max(
                    recent_verification_datetime if recent_verification_datetime is not None
                    else relevant_verification.expiration_datetime,
                    relevant_verification.expiration_datetime
                )

            # By default, don't show any status related to verification
            status = None

            # Check whether the user was approved or is awaiting approval
            if relevant_verification is not None:
                if relevant_verification.status == ""approved"":
                    if verification_expiring_soon:
                        status = VERIFY_STATUS_NEED_TO_REVERIFY
                    else:
                        status = VERIFY_STATUS_APPROVED
                elif relevant_verification.status == ""submitted"":
                    if verification_expiring_soon:
                        status = VERIFY_STATUS_RESUBMITTED
                    else:
                        status = VERIFY_STATUS_SUBMITTED

            # If the user didn't submit at all, then tell them they need to verify
            # If the deadline has already passed, then tell them they missed it.
            # If they submitted but something went wrong (error or denied),
            # then don't show any messaging next to the course, since we already
            # show messages related to this on the left sidebar.
            submitted = (
                relevant_verification is not None and
                relevant_verification.status not in [""created"", ""ready""]
            )
            if status is None and not submitted:
                if deadline is None or deadline > datetime.now(UTC):
                    if SoftwareSecurePhotoVerification.user_is_verified(user):
                        if verification_expiring_soon:
                            # The user has an active verification, but the verification
                            # is set to expire within ""EXPIRING_SOON_WINDOW"" days (default is 4 weeks).
                            # Tell the student to reverify.
                            status = VERIFY_STATUS_NEED_TO_REVERIFY
                    else:
                        status = VERIFY_STATUS_NEED_TO_VERIFY
                else:
                    # If a user currently has an active or pending verification,
                    # then they may have submitted an additional attempt after
                    # the verification deadline passed.  This can occur,
                    # for example, when the support team asks a student
                    # to reverify after the deadline so they can receive
                    # a verified certificate.
                    # In this case, we still want to show them as ""verified""
                    # on the dashboard.
                    if has_active_or_pending:
                        status = VERIFY_STATUS_APPROVED

                    # Otherwise, the student missed the deadline, so show
                    # them as ""honor"" (the kind of certificate they will receive).
                    else:
                        status = VERIFY_STATUS_MISSED_DEADLINE

            # Set the status for the course only if we're displaying some kind of message
            # Otherwise, leave the course out of the dictionary.
            if status is not None:
                days_until_deadline = None

                now = datetime.now(UTC)
                if deadline is not None and deadline > now:
                    days_until_deadline = (deadline - now).days

                status_by_course[enrollment.course_id] = {
                    'status': status,
                    'days_until_deadline': days_until_deadline
                }

    if recent_verification_datetime:
        for key, value in status_by_course.iteritems():  # pylint: disable=unused-variable
            status_by_course[key]['verification_good_until'] = recent_verification_datetime.strftime(""%m/%d/%Y"")

    return status_by_course


def auth_pipeline_urls(auth_entry, redirect_url=None):
    """"""Retrieve URLs for each enabled third-party auth provider.

    These URLs are used on the ""sign up"" and ""sign in"" buttons
    on the login/registration forms to allow users to begin
    authentication with a third-party provider.

    Optionally, we can redirect the user to an arbitrary
    url after auth completes successfully.  We use this
    to redirect the user to a page that required login,
    or to send users to the payment flow when enrolling
    in a course.

    Args:
        auth_entry (string): Either `pipeline.AUTH_ENTRY_LOGIN` or `pipeline.AUTH_ENTRY_REGISTER`

    Keyword Args:
        redirect_url (unicode): If provided, send users to this URL
            after they successfully authenticate.

    Returns:
        dict mapping provider IDs to URLs

    """"""
    if not third_party_auth.is_enabled():
        return {}

    return {
        provider.provider_id: third_party_auth.pipeline.get_login_url(
            provider.provider_id, auth_entry, redirect_url=redirect_url
        ) for provider in third_party_auth.provider.Registry.displayed_for_login()
    }


# Query string parameters that can be passed to the ""finish_auth"" view to manage
# things like auto-enrollment.
POST_AUTH_PARAMS = ('course_id', 'enrollment_action', 'course_mode', 'email_opt_in', 'purchase_workflow')


def get_next_url_for_login_page(request):
    """"""
    Determine the URL to redirect to following login/registration/third_party_auth

    The user is currently on a login or registration page.
    If 'course_id' is set, or other POST_AUTH_PARAMS, we will need to send the user to the
    /account/finish_auth/ view following login, which will take care of auto-enrollment in
    the specified course.

    Otherwise, we go to the ?next= query param or to the dashboard if nothing else is
    specified.

    If THIRD_PARTY_AUTH_HINT is set, then `tpa_hint=<hint>` is added as a query parameter.
    """"""
    redirect_to = get_redirect_to(request)
    if not redirect_to:
        try:
            redirect_to = reverse('dashboard')
        except NoReverseMatch:
            redirect_to = reverse('home')

    if any(param in request.GET for param in POST_AUTH_PARAMS):
        # Before we redirect to next/dashboard, we need to handle auto-enrollment:
        params = [(param, request.GET[param]) for param in POST_AUTH_PARAMS if param in request.GET]
        params.append(('next', redirect_to))  # After auto-enrollment, user will be sent to payment page or to this URL
        redirect_to = '{}?{}'.format(reverse('finish_auth'), urllib.urlencode(params))
        # Note: if we are resuming a third party auth pipeline, then the next URL will already
        # be saved in the session as part of the pipeline state. That URL will take priority
        # over this one.

    # Append a tpa_hint query parameter, if one is configured
    tpa_hint = configuration_helpers.get_value(
        ""THIRD_PARTY_AUTH_HINT"",
        settings.FEATURES.get(""THIRD_PARTY_AUTH_HINT"", '')
    )
    if tpa_hint:
        # Don't add tpa_hint if we're already in the TPA pipeline (prevent infinite loop),
        # and don't overwrite any existing tpa_hint params (allow tpa_hint override).
        running_pipeline = third_party_auth.pipeline.get(request)
        (scheme, netloc, path, query, fragment) = list(urlparse.urlsplit(redirect_to))
        if not running_pipeline and 'tpa_hint' not in query:
            params = urlparse.parse_qs(query)
            params['tpa_hint'] = [tpa_hint]
            query = urllib.urlencode(params, doseq=True)
            redirect_to = urlparse.urlunsplit((scheme, netloc, path, query, fragment))

    return redirect_to


def get_redirect_to(request):
    """"""
    Determine the redirect url and return if safe
    :argument
        request: request object

    :returns: redirect url if safe else None
    """"""
    redirect_to = request.GET.get('next')
    header_accept = request.META.get('HTTP_ACCEPT', '')

    # If we get a redirect parameter, make sure it's safe i.e. not redirecting outside our domain.
    # Also make sure that it is not redirecting to a static asset and redirected page is web page
    # not a static file. As allowing assets to be pointed to by ""next"" allows 3rd party sites to
    # get information about a user on edx.org. In any such case drop the parameter.
    if redirect_to:
        mime_type, _ = mimetypes.guess_type(redirect_to, strict=False)
        if not http.is_safe_url(redirect_to):
            log.warning(
                u'Unsafe redirect parameter detected after login page: %(redirect_to)r',
                {""redirect_to"": redirect_to}
            )
            redirect_to = None
        elif 'text/html' not in header_accept:
            log.warning(
                u'Redirect to non html content %(content_type)r detected from %(user_agent)r'
                u' after login page: %(redirect_to)r',
                {
                    ""redirect_to"": redirect_to, ""content_type"": header_accept,
                    ""user_agent"": request.META.get('HTTP_USER_AGENT', '')
                }
            )
            redirect_to = None
        elif mime_type:
            log.warning(
                u'Redirect to url path with specified filed type %(mime_type)r not allowed: %(redirect_to)r',
                {""redirect_to"": redirect_to, ""mime_type"": mime_type}
            )
            redirect_to = None
        elif settings.STATIC_URL in redirect_to:
            log.warning(
                u'Redirect to static content detected after login page: %(redirect_to)r',
                {""redirect_to"": redirect_to}
            )
            redirect_to = None
        else:
            themes = get_themes()
            for theme in themes:
                if theme.theme_dir_name in redirect_to:
                    log.warning(
                        u'Redirect to theme content detected after login page: %(redirect_to)r',
                        {""redirect_to"": redirect_to}
                    )
                    redirect_to = None
                    break

    return redirect_to


def destroy_oauth_tokens(user):
    """"""
    Destroys ALL OAuth access and refresh tokens for the given user.
    """"""
    dop_access_token.objects.filter(user=user.id).delete()
    dop_refresh_token.objects.filter(user=user.id).delete()
    dot_access_token.objects.filter(user=user.id).delete()
    dot_refresh_token.objects.filter(user=user.id).delete()
/n/n/ncommon/djangoapps/student/tests/test_helpers.py/n/n"""""" Test Student helpers """"""

import logging

import ddt
from django.conf import settings
from django.contrib.sessions.middleware import SessionMiddleware
from django.core.urlresolvers import reverse
from django.test import TestCase
from django.test.client import RequestFactory
from django.test.utils import override_settings
from mock import patch
from testfixtures import LogCapture

from student.helpers import get_next_url_for_login_page
from openedx.core.djangoapps.site_configuration.tests.test_util import with_site_configuration_context

LOGGER_NAME = ""student.helpers""


@ddt.ddt
class TestLoginHelper(TestCase):
    """"""Test login helper methods.""""""
    static_url = settings.STATIC_URL

    def setUp(self):
        super(TestLoginHelper, self).setUp()
        self.request = RequestFactory()

    @staticmethod
    def _add_session(request):
        """"""Annotate the request object with a session""""""
        middleware = SessionMiddleware()
        middleware.process_request(request)
        request.session.save()

    @ddt.data(
        (""https://www.amazon.com"", ""text/html"", None,
         ""Unsafe redirect parameter detected after login page: u'https://www.amazon.com'""),
        (""favicon.ico"", ""image/*"", ""test/agent"",
         ""Redirect to non html content 'image/*' detected from 'test/agent' after login page: u'favicon.ico'""),
        (""https://www.test.com/test.jpg"", ""image/*"", None,
         ""Unsafe redirect parameter detected after login page: u'https://www.test.com/test.jpg'""),
        (static_url + ""dummy.png"", ""image/*"", ""test/agent"",
         ""Redirect to non html content 'image/*' detected from 'test/agent' after login page: u'"" + static_url +
         ""dummy.png"" + ""'""),
        (""test.png"", ""text/html"", None,
         ""Redirect to url path with specified filed type 'image/png' not allowed: u'test.png'""),
        (static_url + ""dummy.png"", ""text/html"", None,
         ""Redirect to url path with specified filed type 'image/png' not allowed: u'"" + static_url + ""dummy.png"" + ""'""),
    )
    @ddt.unpack
    def test_unsafe_next(self, unsafe_url, http_accept, user_agent, expected_log):
        """""" Test unsafe next parameter """"""
        with LogCapture(LOGGER_NAME, level=logging.WARNING) as logger:
            req = self.request.get(reverse(""login"") + ""?next={url}"".format(url=unsafe_url))
            req.META[""HTTP_ACCEPT""] = http_accept  # pylint: disable=no-member
            req.META[""HTTP_USER_AGENT""] = user_agent  # pylint: disable=no-member
            get_next_url_for_login_page(req)
            logger.check(
                (LOGGER_NAME, ""WARNING"", expected_log)
            )

    def test_safe_next(self):
        """""" Test safe next parameter """"""
        req = self.request.get(reverse(""login"") + ""?next={url}"".format(url=""/dashboard""))
        req.META[""HTTP_ACCEPT""] = ""text/html""  # pylint: disable=no-member
        next_page = get_next_url_for_login_page(req)
        self.assertEqual(next_page, u'/dashboard')

    @patch('student.helpers.third_party_auth.pipeline.get')
    @ddt.data(
        # Test requests outside the TPA pipeline - tpa_hint should be added.
        (None, '/dashboard', '/dashboard', False),
        ('', '/dashboard', '/dashboard', False),
        ('', '/dashboard?tpa_hint=oa2-google-oauth2', '/dashboard?tpa_hint=oa2-google-oauth2', False),
        ('saml-idp', '/dashboard', '/dashboard?tpa_hint=saml-idp', False),
        # THIRD_PARTY_AUTH_HINT can be overridden via the query string
        ('saml-idp', '/dashboard?tpa_hint=oa2-google-oauth2', '/dashboard?tpa_hint=oa2-google-oauth2', False),

        # Test requests inside the TPA pipeline - tpa_hint should not be added, preventing infinite loop.
        (None, '/dashboard', '/dashboard', True),
        ('', '/dashboard', '/dashboard', True),
        ('', '/dashboard?tpa_hint=oa2-google-oauth2', '/dashboard?tpa_hint=oa2-google-oauth2', True),
        ('saml-idp', '/dashboard', '/dashboard', True),
        # OK to leave tpa_hint overrides in place.
        ('saml-idp', '/dashboard?tpa_hint=oa2-google-oauth2', '/dashboard?tpa_hint=oa2-google-oauth2', True),
    )
    @ddt.unpack
    def test_third_party_auth_hint(self, tpa_hint, next_url, expected_url, running_pipeline, mock_running_pipeline):
        mock_running_pipeline.return_value = running_pipeline

        def validate_login():
            req = self.request.get(reverse(""login"") + ""?next={url}"".format(url=next_url))
            req.META[""HTTP_ACCEPT""] = ""text/html""  # pylint: disable=no-member
            self._add_session(req)
            next_page = get_next_url_for_login_page(req)
            self.assertEqual(next_page, expected_url)

        with override_settings(FEATURES=dict(settings.FEATURES, THIRD_PARTY_AUTH_HINT=tpa_hint)):
            validate_login()

        with with_site_configuration_context(configuration=dict(THIRD_PARTY_AUTH_HINT=tpa_hint)):
            validate_login()
/n/n/nlms/djangoapps/student_account/test/test_views.py/n/n# -*- coding: utf-8 -*-
"""""" Tests for student account views. """"""

import logging
import re
from unittest import skipUnless
from urllib import urlencode

import ddt
import mock
from django.conf import settings
from django.contrib import messages
from django.contrib.auth import get_user_model
from django.contrib.messages.middleware import MessageMiddleware
from django.core import mail
from django.core.files.uploadedfile import SimpleUploadedFile
from django.core.urlresolvers import reverse
from django.http import HttpRequest
from django.test import TestCase
from django.test.utils import override_settings
from edx_oauth2_provider.tests.factories import AccessTokenFactory, ClientFactory, RefreshTokenFactory
from edx_rest_api_client import exceptions
from nose.plugins.attrib import attr
from oauth2_provider.models import AccessToken as dot_access_token
from oauth2_provider.models import RefreshToken as dot_refresh_token
from provider.oauth2.models import AccessToken as dop_access_token
from provider.oauth2.models import RefreshToken as dop_refresh_token
from testfixtures import LogCapture

from commerce.models import CommerceConfiguration
from commerce.tests import factories
from commerce.tests.mocks import mock_get_orders
from course_modes.models import CourseMode
from edxmako.shortcuts import render_to_response
from openedx.core.djangoapps.oauth_dispatch.tests import factories as dot_factories
from openedx.core.djangoapps.programs.tests.mixins import ProgramsApiConfigMixin
from openedx.core.djangoapps.site_configuration.tests.mixins import SiteMixin
from openedx.core.djangoapps.theming.tests.test_util import with_comprehensive_theme_context
from openedx.core.djangoapps.user_api.accounts import EMAIL_MAX_LENGTH
from openedx.core.djangoapps.user_api.accounts.api import activate_account, create_account
from openedx.core.djangolib.js_utils import dump_js_escaped_json
from openedx.core.djangolib.testing.utils import CacheIsolationTestCase
from student.tests.factories import UserFactory
from student_account.views import account_settings_context, get_user_orders
from third_party_auth.tests.testutil import ThirdPartyAuthTestMixin, simulate_running_pipeline
from util.testing import UrlResetMixin
from xmodule.modulestore.tests.django_utils import ModuleStoreTestCase

LOGGER_NAME = 'audit'
User = get_user_model()  # pylint:disable=invalid-name


@ddt.ddt
class StudentAccountUpdateTest(CacheIsolationTestCase, UrlResetMixin):
    """""" Tests for the student account views that update the user's account information. """"""

    USERNAME = u""heisenberg""
    ALTERNATE_USERNAME = u""walt""
    OLD_PASSWORD = u""""
    NEW_PASSWORD = u""""
    OLD_EMAIL = u""walter@graymattertech.com""
    NEW_EMAIL = u""walt@savewalterwhite.com""

    INVALID_ATTEMPTS = 100

    INVALID_EMAILS = [
        None,
        u"""",
        u""a"",
        ""no_domain"",
        ""no+domain"",
        ""@"",
        ""@domain.com"",
        ""test@no_extension"",

        # Long email -- subtract the length of the @domain
        # except for one character (so we exceed the max length limit)
        u""{user}@example.com"".format(
            user=(u'e' * (EMAIL_MAX_LENGTH - 11))
        )
    ]

    INVALID_KEY = u""123abc""

    URLCONF_MODULES = ['student_accounts.urls']

    ENABLED_CACHES = ['default']

    def setUp(self):
        super(StudentAccountUpdateTest, self).setUp()

        # Create/activate a new account
        activation_key = create_account(self.USERNAME, self.OLD_PASSWORD, self.OLD_EMAIL)
        activate_account(activation_key)

        # Login
        result = self.client.login(username=self.USERNAME, password=self.OLD_PASSWORD)
        self.assertTrue(result)

    @skipUnless(settings.ROOT_URLCONF == 'lms.urls', 'Test only valid in LMS')
    def test_password_change(self):
        # Request a password change while logged in, simulating
        # use of the password reset link from the account page
        response = self._change_password()
        self.assertEqual(response.status_code, 200)

        # Check that an email was sent
        self.assertEqual(len(mail.outbox), 1)

        # Retrieve the activation link from the email body
        email_body = mail.outbox[0].body
        result = re.search(r'(?P<url>https?://[^\s]+)', email_body)
        self.assertIsNot(result, None)
        activation_link = result.group('url')

        # Visit the activation link
        response = self.client.get(activation_link)
        self.assertEqual(response.status_code, 200)

        # Submit a new password and follow the redirect to the success page
        response = self.client.post(
            activation_link,
            # These keys are from the form on the current password reset confirmation page.
            {'new_password1': self.NEW_PASSWORD, 'new_password2': self.NEW_PASSWORD},
            follow=True
        )
        self.assertEqual(response.status_code, 200)
        self.assertContains(response, ""Your password has been reset."")

        # Log the user out to clear session data
        self.client.logout()

        # Verify that the new password can be used to log in
        result = self.client.login(username=self.USERNAME, password=self.NEW_PASSWORD)
        self.assertTrue(result)

        # Try reusing the activation link to change the password again
        # Visit the activation link again.
        response = self.client.get(activation_link)
        self.assertEqual(response.status_code, 200)
        self.assertContains(response, ""This password reset link is invalid. It may have been used already."")

        self.client.logout()

        # Verify that the old password cannot be used to log in
        result = self.client.login(username=self.USERNAME, password=self.OLD_PASSWORD)
        self.assertFalse(result)

        # Verify that the new password continues to be valid
        result = self.client.login(username=self.USERNAME, password=self.NEW_PASSWORD)
        self.assertTrue(result)

    @ddt.data(True, False)
    def test_password_change_logged_out(self, send_email):
        # Log the user out
        self.client.logout()

        # Request a password change while logged out, simulating
        # use of the password reset link from the login page
        if send_email:
            response = self._change_password(email=self.OLD_EMAIL)
            self.assertEqual(response.status_code, 200)
        else:
            # Don't send an email in the POST data, simulating
            # its (potentially accidental) omission in the POST
            # data sent from the login page
            response = self._change_password()
            self.assertEqual(response.status_code, 400)

    def test_access_token_invalidation_logged_out(self):
        self.client.logout()
        user = User.objects.get(email=self.OLD_EMAIL)
        self._create_dop_tokens(user)
        self._create_dot_tokens(user)
        response = self._change_password(email=self.OLD_EMAIL)
        self.assertEqual(response.status_code, 200)
        self.assert_access_token_destroyed(user)

    def test_access_token_invalidation_logged_in(self):
        user = User.objects.get(email=self.OLD_EMAIL)
        self._create_dop_tokens(user)
        self._create_dot_tokens(user)
        response = self._change_password()
        self.assertEqual(response.status_code, 200)
        self.assert_access_token_destroyed(user)

    def test_password_change_inactive_user(self):
        # Log out the user created during test setup
        self.client.logout()

        # Create a second user, but do not activate it
        create_account(self.ALTERNATE_USERNAME, self.OLD_PASSWORD, self.NEW_EMAIL)

        # Send the view the email address tied to the inactive user
        response = self._change_password(email=self.NEW_EMAIL)

        # Expect that the activation email is still sent,
        # since the user may have lost the original activation email.
        self.assertEqual(response.status_code, 200)
        self.assertEqual(len(mail.outbox), 1)

    def test_password_change_no_user(self):
        # Log out the user created during test setup
        self.client.logout()

        with LogCapture(LOGGER_NAME, level=logging.INFO) as logger:
            # Send the view an email address not tied to any user
            response = self._change_password(email=self.NEW_EMAIL)
            self.assertEqual(response.status_code, 200)
            logger.check((LOGGER_NAME, 'INFO', 'Invalid password reset attempt'))

    def test_password_change_rate_limited(self):
        # Log out the user created during test setup, to prevent the view from
        # selecting the logged-in user's email address over the email provided
        # in the POST data
        self.client.logout()

        # Make many consecutive bad requests in an attempt to trigger the rate limiter
        for __ in xrange(self.INVALID_ATTEMPTS):
            self._change_password(email=self.NEW_EMAIL)

        response = self._change_password(email=self.NEW_EMAIL)
        self.assertEqual(response.status_code, 403)

    @ddt.data(
        ('post', 'password_change_request', []),
    )
    @ddt.unpack
    def test_require_http_method(self, correct_method, url_name, args):
        wrong_methods = {'get', 'put', 'post', 'head', 'options', 'delete'} - {correct_method}
        url = reverse(url_name, args=args)

        for method in wrong_methods:
            response = getattr(self.client, method)(url)
            self.assertEqual(response.status_code, 405)

    def _change_password(self, email=None):
        """"""Request to change the user's password. """"""
        data = {}

        if email:
            data['email'] = email

        return self.client.post(path=reverse('password_change_request'), data=data)

    def _create_dop_tokens(self, user=None):
        """"""Create dop access token for given user if user provided else for default user.""""""
        if not user:
            user = User.objects.get(email=self.OLD_EMAIL)

        client = ClientFactory()
        access_token = AccessTokenFactory(user=user, client=client)
        RefreshTokenFactory(user=user, client=client, access_token=access_token)

    def _create_dot_tokens(self, user=None):
        """"""Create dop access token for given user if user provided else for default user.""""""
        if not user:
            user = User.objects.get(email=self.OLD_EMAIL)

        application = dot_factories.ApplicationFactory(user=user)
        access_token = dot_factories.AccessTokenFactory(user=user, application=application)
        dot_factories.RefreshTokenFactory(user=user, application=application, access_token=access_token)

    def assert_access_token_destroyed(self, user):
        """"""Assert all access tokens are destroyed.""""""
        self.assertFalse(dot_access_token.objects.filter(user=user).exists())
        self.assertFalse(dot_refresh_token.objects.filter(user=user).exists())
        self.assertFalse(dop_access_token.objects.filter(user=user).exists())
        self.assertFalse(dop_refresh_token.objects.filter(user=user).exists())


@attr(shard=3)
@ddt.ddt
class StudentAccountLoginAndRegistrationTest(ThirdPartyAuthTestMixin, UrlResetMixin, ModuleStoreTestCase):
    """""" Tests for the student account views that update the user's account information. """"""

    USERNAME = ""bob""
    EMAIL = ""bob@example.com""
    PASSWORD = ""password""

    URLCONF_MODULES = ['openedx.core.djangoapps.embargo']

    @mock.patch.dict(settings.FEATURES, {'EMBARGO': True})
    def setUp(self):
        super(StudentAccountLoginAndRegistrationTest, self).setUp()

        # Several third party auth providers are created for these tests:
        self.google_provider = self.configure_google_provider(enabled=True, visible=True)
        self.configure_facebook_provider(enabled=True, visible=True)
        self.configure_dummy_provider(
            visible=True,
            enabled=True,
            icon_class='',
            icon_image=SimpleUploadedFile('icon.svg', '<svg><rect width=""50"" height=""100""/></svg>'),
        )
        self.hidden_enabled_provider = self.configure_linkedin_provider(
            visible=False,
            enabled=True,
        )
        self.hidden_disabled_provider = self.configure_azure_ad_provider()

    @ddt.data(
        (""signin_user"", ""login""),
        (""register_user"", ""register""),
    )
    @ddt.unpack
    def test_login_and_registration_form(self, url_name, initial_mode):
        response = self.client.get(reverse(url_name))
        expected_data = '""initial_mode"": ""{mode}""'.format(mode=initial_mode)
        self.assertContains(response, expected_data)

    @ddt.data(""signin_user"", ""register_user"")
    def test_login_and_registration_form_already_authenticated(self, url_name):
        # Create/activate a new account and log in
        activation_key = create_account(self.USERNAME, self.PASSWORD, self.EMAIL)
        activate_account(activation_key)
        result = self.client.login(username=self.USERNAME, password=self.PASSWORD)
        self.assertTrue(result)

        # Verify that we're redirected to the dashboard
        response = self.client.get(reverse(url_name))
        self.assertRedirects(response, reverse(""dashboard""))

    @ddt.data(
        (None, ""signin_user""),
        (None, ""register_user""),
        (""edx.org"", ""signin_user""),
        (""edx.org"", ""register_user""),
    )
    @ddt.unpack
    def test_login_and_registration_form_signin_not_preserves_params(self, theme, url_name):
        params = [
            ('course_id', 'edX/DemoX/Demo_Course'),
            ('enrollment_action', 'enroll'),
        ]

        # The response should not have a ""Sign In"" button with the URL
        # that preserves the querystring params
        with with_comprehensive_theme_context(theme):
            response = self.client.get(reverse(url_name), params, HTTP_ACCEPT=""text/html"")

        expected_url = '/login?{}'.format(self._finish_auth_url_param(params + [('next', '/dashboard')]))
        self.assertNotContains(response, expected_url)

        # Add additional parameters:
        params = [
            ('course_id', 'edX/DemoX/Demo_Course'),
            ('enrollment_action', 'enroll'),
            ('course_mode', CourseMode.DEFAULT_MODE_SLUG),
            ('email_opt_in', 'true'),
            ('next', '/custom/final/destination')
        ]

        # Verify that this parameter is also preserved
        with with_comprehensive_theme_context(theme):
            response = self.client.get(reverse(url_name), params, HTTP_ACCEPT=""text/html"")

        expected_url = '/login?{}'.format(self._finish_auth_url_param(params))
        self.assertNotContains(response, expected_url)

    @mock.patch.dict(settings.FEATURES, {""ENABLE_THIRD_PARTY_AUTH"": False})
    @ddt.data(""signin_user"", ""register_user"")
    def test_third_party_auth_disabled(self, url_name):
        response = self.client.get(reverse(url_name))
        self._assert_third_party_auth_data(response, None, None, [], None)

    @mock.patch('student_account.views.enterprise_customer_for_request')
    @ddt.data(
        (""signin_user"", None, None, None),
        (""register_user"", None, None, None),
        (""signin_user"", ""google-oauth2"", ""Google"", None),
        (""register_user"", ""google-oauth2"", ""Google"", None),
        (""signin_user"", ""facebook"", ""Facebook"", None),
        (""register_user"", ""facebook"", ""Facebook"", None),
        (""signin_user"", ""dummy"", ""Dummy"", None),
        (""register_user"", ""dummy"", ""Dummy"", None),
        (
            ""signin_user"",
            ""google-oauth2"",
            ""Google"",
            {
                'name': 'FakeName',
                'logo': 'https://host.com/logo.jpg',
                'welcome_msg': 'No message'
            }
        )
    )
    @ddt.unpack
    def test_third_party_auth(
            self,
            url_name,
            current_backend,
            current_provider,
            expected_enterprise_customer_mock_attrs,
            enterprise_customer_mock
    ):
        params = [
            ('course_id', 'course-v1:Org+Course+Run'),
            ('enrollment_action', 'enroll'),
            ('course_mode', CourseMode.DEFAULT_MODE_SLUG),
            ('email_opt_in', 'true'),
            ('next', '/custom/final/destination'),
        ]

        if expected_enterprise_customer_mock_attrs:
            expected_ec = mock.MagicMock(
                branding_configuration=mock.MagicMock(
                    logo=mock.MagicMock(
                        url=expected_enterprise_customer_mock_attrs['logo']
                    ),
                    welcome_message=expected_enterprise_customer_mock_attrs['welcome_msg']
                )
            )
            expected_ec.name = expected_enterprise_customer_mock_attrs['name']
        else:
            expected_ec = None

        enterprise_customer_mock.return_value = expected_ec

        # Simulate a running pipeline
        if current_backend is not None:
            pipeline_target = ""student_account.views.third_party_auth.pipeline""
            with simulate_running_pipeline(pipeline_target, current_backend):
                response = self.client.get(reverse(url_name), params, HTTP_ACCEPT=""text/html"")

        # Do NOT simulate a running pipeline
        else:
            response = self.client.get(reverse(url_name), params, HTTP_ACCEPT=""text/html"")

        # This relies on the THIRD_PARTY_AUTH configuration in the test settings
        expected_providers = [
            {
                ""id"": ""oa2-dummy"",
                ""name"": ""Dummy"",
                ""iconClass"": None,
                ""iconImage"": settings.MEDIA_URL + ""icon.svg"",
                ""loginUrl"": self._third_party_login_url(""dummy"", ""login"", params),
                ""registerUrl"": self._third_party_login_url(""dummy"", ""register"", params)
            },
            {
                ""id"": ""oa2-facebook"",
                ""name"": ""Facebook"",
                ""iconClass"": ""fa-facebook"",
                ""iconImage"": None,
                ""loginUrl"": self._third_party_login_url(""facebook"", ""login"", params),
                ""registerUrl"": self._third_party_login_url(""facebook"", ""register"", params)
            },
            {
                ""id"": ""oa2-google-oauth2"",
                ""name"": ""Google"",
                ""iconClass"": ""fa-google-plus"",
                ""iconImage"": None,
                ""loginUrl"": self._third_party_login_url(""google-oauth2"", ""login"", params),
                ""registerUrl"": self._third_party_login_url(""google-oauth2"", ""register"", params)
            },
        ]
        self._assert_third_party_auth_data(
            response,
            current_backend,
            current_provider,
            expected_providers,
            expected_ec
        )

    def test_hinted_login(self):
        params = [(""next"", ""/courses/something/?tpa_hint=oa2-google-oauth2"")]
        response = self.client.get(reverse('signin_user'), params, HTTP_ACCEPT=""text/html"")
        self.assertContains(response, '""third_party_auth_hint"": ""oa2-google-oauth2""')

        tpa_hint = self.hidden_enabled_provider.provider_id
        params = [(""next"", ""/courses/something/?tpa_hint={0}"".format(tpa_hint))]
        response = self.client.get(reverse('signin_user'), params, HTTP_ACCEPT=""text/html"")
        self.assertContains(response, '""third_party_auth_hint"": ""{0}""'.format(tpa_hint))

        tpa_hint = self.hidden_disabled_provider.provider_id
        params = [(""next"", ""/courses/something/?tpa_hint={0}"".format(tpa_hint))]
        response = self.client.get(reverse('signin_user'), params, HTTP_ACCEPT=""text/html"")
        self.assertNotIn(response.content, tpa_hint)

    @ddt.data(
        ('signin_user', 'login'),
        ('register_user', 'register'),
    )
    @ddt.unpack
    def test_hinted_login_dialog_disabled(self, url_name, auth_entry):
        """"""Test that the dialog doesn't show up for hinted logins when disabled. """"""
        self.google_provider.skip_hinted_login_dialog = True
        self.google_provider.save()
        params = [(""next"", ""/courses/something/?tpa_hint=oa2-google-oauth2"")]
        response = self.client.get(reverse(url_name), params, HTTP_ACCEPT=""text/html"")
        self.assertRedirects(
            response,
            'auth/login/google-oauth2/?auth_entry={}&next=%2Fcourses%2Fsomething%2F%3Ftpa_hint%3Doa2-google-oauth2'.format(auth_entry),
            target_status_code=302
        )

    @override_settings(FEATURES=dict(settings.FEATURES, THIRD_PARTY_AUTH_HINT='oa2-google-oauth2'))
    @ddt.data(
        'signin_user',
        'register_user',
    )
    def test_settings_tpa_hinted_login(self, url_name):
        """"""
        Ensure that settings.FEATURES['THIRD_PARTY_AUTH_HINT'] can set third_party_auth_hint.
        """"""
        params = [(""next"", ""/courses/something/"")]
        response = self.client.get(reverse(url_name), params, HTTP_ACCEPT=""text/html"")
        self.assertContains(response, '""third_party_auth_hint"": ""oa2-google-oauth2""')

        # THIRD_PARTY_AUTH_HINT can be overridden via the query string
        tpa_hint = self.hidden_enabled_provider.provider_id
        params = [(""next"", ""/courses/something/?tpa_hint={0}"".format(tpa_hint))]
        response = self.client.get(reverse(url_name), params, HTTP_ACCEPT=""text/html"")
        self.assertContains(response, '""third_party_auth_hint"": ""{0}""'.format(tpa_hint))

        # Even disabled providers in the query string will override THIRD_PARTY_AUTH_HINT
        tpa_hint = self.hidden_disabled_provider.provider_id
        params = [(""next"", ""/courses/something/?tpa_hint={0}"".format(tpa_hint))]
        response = self.client.get(reverse(url_name), params, HTTP_ACCEPT=""text/html"")
        self.assertNotIn(response.content, tpa_hint)

    @override_settings(FEATURES=dict(settings.FEATURES, THIRD_PARTY_AUTH_HINT='oa2-google-oauth2'))
    @ddt.data(
        ('signin_user', 'login'),
        ('register_user', 'register'),
    )
    @ddt.unpack
    def test_settings_tpa_hinted_login_dialog_disabled(self, url_name, auth_entry):
        """"""Test that the dialog doesn't show up for hinted logins when disabled via settings.THIRD_PARTY_AUTH_HINT. """"""
        self.google_provider.skip_hinted_login_dialog = True
        self.google_provider.save()
        params = [(""next"", ""/courses/something/"")]
        response = self.client.get(reverse(url_name), params, HTTP_ACCEPT=""text/html"")
        self.assertRedirects(
            response,
            'auth/login/google-oauth2/?auth_entry={}&next=%2Fcourses%2Fsomething%2F%3Ftpa_hint%3Doa2-google-oauth2'.format(auth_entry),
            target_status_code=302
        )

    @mock.patch('student_account.views.enterprise_customer_for_request')
    @ddt.data(
        ('signin_user', False, None, None, None),
        ('register_user', False, None, None, None),
        ('signin_user', True, 'Fake EC', 'http://logo.com/logo.jpg', u'{enterprise_name} - {platform_name}'),
        ('register_user', True, 'Fake EC', 'http://logo.com/logo.jpg', u'{enterprise_name} - {platform_name}'),
        ('signin_user', True, 'Fake EC', None, u'{enterprise_name} - {platform_name}'),
        ('register_user', True, 'Fake EC', None, u'{enterprise_name} - {platform_name}'),
        ('signin_user', True, 'Fake EC', 'http://logo.com/logo.jpg', None),
        ('register_user', True, 'Fake EC', 'http://logo.com/logo.jpg', None),
        ('signin_user', True, 'Fake EC', None, None),
        ('register_user', True, 'Fake EC', None, None),
    )
    @ddt.unpack
    def test_enterprise_register(self, url_name, ec_present, ec_name, logo_url, welcome_message, mock_get_ec):
        """"""
        Verify that when an EnterpriseCustomer is received on the login and register views,
        the appropriate sidebar is rendered.
        """"""
        if ec_present:
            mock_ec = mock_get_ec.return_value
            mock_ec.name = ec_name
            if logo_url:
                mock_ec.branding_configuration.logo.url = logo_url
            else:
                mock_ec.branding_configuration.logo = None
            if welcome_message:
                mock_ec.branding_configuration.welcome_message = welcome_message
            else:
                del mock_ec.branding_configuration.welcome_message
        else:
            mock_get_ec.return_value = None

        response = self.client.get(reverse(url_name), HTTP_ACCEPT=""text/html"")

        enterprise_sidebar_div_id = u'enterprise-content-container'

        if not ec_present:
            self.assertNotContains(response, text=enterprise_sidebar_div_id)
        else:
            self.assertContains(response, text=enterprise_sidebar_div_id)
            if not welcome_message:
                welcome_message = settings.ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE
            expected_message = welcome_message.format(
                start_bold=u'<b>',
                end_bold=u'</b>',
                enterprise_name=ec_name,
                platform_name=settings.PLATFORM_NAME
            )
            self.assertContains(response, expected_message)
            if logo_url:
                self.assertContains(response, logo_url)

    @override_settings(SITE_NAME=settings.MICROSITE_TEST_HOSTNAME)
    def test_microsite_uses_old_login_page(self):
        # Retrieve the login page from a microsite domain
        # and verify that we're served the old page.
        resp = self.client.get(
            reverse(""signin_user""),
            HTTP_HOST=settings.MICROSITE_TEST_HOSTNAME
        )
        self.assertContains(resp, ""Log into your Test Site Account"")
        self.assertContains(resp, ""login-form"")

    def test_microsite_uses_old_register_page(self):
        # Retrieve the register page from a microsite domain
        # and verify that we're served the old page.
        resp = self.client.get(
            reverse(""register_user""),
            HTTP_HOST=settings.MICROSITE_TEST_HOSTNAME
        )
        self.assertContains(resp, ""Register for Test Site"")
        self.assertContains(resp, ""register-form"")

    def test_login_registration_xframe_protected(self):
        resp = self.client.get(
            reverse(""register_user""),
            {},
            HTTP_REFERER=""http://localhost/iframe""
        )

        self.assertEqual(resp['X-Frame-Options'], 'DENY')

        self.configure_lti_provider(name='Test', lti_hostname='localhost', lti_consumer_key='test_key', enabled=True)

        resp = self.client.get(
            reverse(""register_user""),
            HTTP_REFERER=""http://localhost/iframe""
        )

        self.assertEqual(resp['X-Frame-Options'], 'ALLOW')

    def _assert_third_party_auth_data(self, response, current_backend, current_provider, providers, expected_ec):
        """"""Verify that third party auth info is rendered correctly in a DOM data attribute. """"""
        finish_auth_url = None
        if current_backend:
            finish_auth_url = reverse(""social:complete"", kwargs={""backend"": current_backend}) + ""?""

        auth_info = {
            ""currentProvider"": current_provider,
            ""providers"": providers,
            ""secondaryProviders"": [],
            ""finishAuthUrl"": finish_auth_url,
            ""errorMessage"": None,
        }
        if expected_ec is not None:
            # If we set an EnterpriseCustomer, third-party auth providers ought to be hidden.
            auth_info['providers'] = []
        auth_info = dump_js_escaped_json(auth_info)

        expected_data = '""third_party_auth"": {auth_info}'.format(
            auth_info=auth_info
        )

        self.assertContains(response, expected_data)

    def _third_party_login_url(self, backend_name, auth_entry, login_params):
        """"""Construct the login URL to start third party authentication. """"""
        return u""{url}?auth_entry={auth_entry}&{param_str}"".format(
            url=reverse(""social:begin"", kwargs={""backend"": backend_name}),
            auth_entry=auth_entry,
            param_str=self._finish_auth_url_param(login_params),
        )

    def _finish_auth_url_param(self, params):
        """"""
        Make the next=... URL parameter that indicates where the user should go next.

        >>> _finish_auth_url_param([('next', '/dashboard')])
        '/account/finish_auth?next=%2Fdashboard'
        """"""
        return urlencode({
            'next': '/account/finish_auth?{}'.format(urlencode(params))
        })

    def test_english_by_default(self):
        response = self.client.get(reverse('signin_user'), [], HTTP_ACCEPT=""text/html"")

        self.assertEqual(response['Content-Language'], 'en')

    def test_unsupported_language(self):
        response = self.client.get(reverse('signin_user'), [], HTTP_ACCEPT=""text/html"", HTTP_ACCEPT_LANGUAGE=""ts-zx"")

        self.assertEqual(response['Content-Language'], 'en')

    def test_browser_language(self):
        response = self.client.get(reverse('signin_user'), [], HTTP_ACCEPT=""text/html"", HTTP_ACCEPT_LANGUAGE=""es"")

        self.assertEqual(response['Content-Language'], 'es-419')

    def test_browser_language_dialent(self):
        response = self.client.get(reverse('signin_user'), [], HTTP_ACCEPT=""text/html"", HTTP_ACCEPT_LANGUAGE=""es-es"")

        self.assertEqual(response['Content-Language'], 'es-es')


class AccountSettingsViewTest(ThirdPartyAuthTestMixin, TestCase, ProgramsApiConfigMixin):
    """""" Tests for the account settings view. """"""

    USERNAME = 'student'
    PASSWORD = 'password'
    FIELDS = [
        'country',
        'gender',
        'language',
        'level_of_education',
        'password',
        'year_of_birth',
        'preferred_language',
        'time_zone',
    ]

    @mock.patch(""django.conf.settings.MESSAGE_STORAGE"", 'django.contrib.messages.storage.cookie.CookieStorage')
    def setUp(self):
        super(AccountSettingsViewTest, self).setUp()
        self.user = UserFactory.create(username=self.USERNAME, password=self.PASSWORD)
        CommerceConfiguration.objects.create(cache_ttl=10, enabled=True)
        self.client.login(username=self.USERNAME, password=self.PASSWORD)

        self.request = HttpRequest()
        self.request.user = self.user

        # For these tests, two third party auth providers are enabled by default:
        self.configure_google_provider(enabled=True, visible=True)
        self.configure_facebook_provider(enabled=True, visible=True)

        # Python-social saves auth failure notifcations in Django messages.
        # See pipeline.get_duplicate_provider() for details.
        self.request.COOKIES = {}
        MessageMiddleware().process_request(self.request)
        messages.error(self.request, 'Facebook is already in use.', extra_tags='Auth facebook')

    def test_context(self):

        context = account_settings_context(self.request)

        user_accounts_api_url = reverse(""accounts_api"", kwargs={'username': self.user.username})
        self.assertEqual(context['user_accounts_api_url'], user_accounts_api_url)

        user_preferences_api_url = reverse('preferences_api', kwargs={'username': self.user.username})
        self.assertEqual(context['user_preferences_api_url'], user_preferences_api_url)

        for attribute in self.FIELDS:
            self.assertIn(attribute, context['fields'])

        self.assertEqual(
            context['user_accounts_api_url'], reverse(""accounts_api"", kwargs={'username': self.user.username})
        )
        self.assertEqual(
            context['user_preferences_api_url'], reverse('preferences_api', kwargs={'username': self.user.username})
        )

        self.assertEqual(context['duplicate_provider'], 'facebook')
        self.assertEqual(context['auth']['providers'][0]['name'], 'Facebook')
        self.assertEqual(context['auth']['providers'][1]['name'], 'Google')

    def test_view(self):
        """"""
        Test that all fields are  visible
        """"""
        view_path = reverse('account_settings')
        response = self.client.get(path=view_path)

        for attribute in self.FIELDS:
            self.assertIn(attribute, response.content)

    def test_header_with_programs_listing_enabled(self):
        """"""
        Verify that tabs header will be shown while program listing is enabled.
        """"""
        self.create_programs_config()
        view_path = reverse('account_settings')
        response = self.client.get(path=view_path)

        self.assertContains(response, '<li class=""tab-nav-item"">')

    def test_header_with_programs_listing_disabled(self):
        """"""
        Verify that nav header will be shown while program listing is disabled.
        """"""
        self.create_programs_config(enabled=False)
        view_path = reverse('account_settings')
        response = self.client.get(path=view_path)

        self.assertContains(response, '<li class=""item nav-global-01"">')

    def test_commerce_order_detail(self):
        """"""
        Verify that get_user_orders returns the correct order data.
        """"""
        with mock_get_orders():
            order_detail = get_user_orders(self.user)

        for i, order in enumerate(mock_get_orders.default_response['results']):
            expected = {
                'number': order['number'],
                'price': order['total_excl_tax'],
                'order_date': 'Jan 01, 2016',
                'receipt_url': '/checkout/receipt/?order_number=' + order['number'],
                'lines': order['lines'],
            }
            self.assertEqual(order_detail[i], expected)

    def test_commerce_order_detail_exception(self):
        with mock_get_orders(exception=exceptions.HttpNotFoundError):
            order_detail = get_user_orders(self.user)

        self.assertEqual(order_detail, [])

    def test_incomplete_order_detail(self):
        response = {
            'results': [
                factories.OrderFactory(
                    status='Incomplete',
                    lines=[
                        factories.OrderLineFactory(
                            product=factories.ProductFactory(attribute_values=[factories.ProductAttributeFactory()])
                        )
                    ]
                )
            ]
        }
        with mock_get_orders(response=response):
            order_detail = get_user_orders(self.user)

        self.assertEqual(order_detail, [])

    def test_order_history_with_no_product(self):
        response = {
            'results': [
                factories.OrderFactory(
                    lines=[
                        factories.OrderLineFactory(
                            product=None
                        ),
                        factories.OrderLineFactory(
                            product=factories.ProductFactory(attribute_values=[factories.ProductAttributeFactory(
                                name='certificate_type',
                                value='verified'
                            )])
                        )
                    ]
                )
            ]
        }
        with mock_get_orders(response=response):
            order_detail = get_user_orders(self.user)

        self.assertEqual(len(order_detail), 1)


@override_settings(SITE_NAME=settings.MICROSITE_LOGISTRATION_HOSTNAME)
class MicrositeLogistrationTests(TestCase):
    """"""
    Test to validate that microsites can display the logistration page
    """"""

    def test_login_page(self):
        """"""
        Make sure that we get the expected logistration page on our specialized
        microsite
        """"""

        resp = self.client.get(
            reverse('signin_user'),
            HTTP_HOST=settings.MICROSITE_LOGISTRATION_HOSTNAME
        )
        self.assertEqual(resp.status_code, 200)

        self.assertIn('<div id=""login-and-registration-container""', resp.content)

    def test_registration_page(self):
        """"""
        Make sure that we get the expected logistration page on our specialized
        microsite
        """"""

        resp = self.client.get(
            reverse('register_user'),
            HTTP_HOST=settings.MICROSITE_LOGISTRATION_HOSTNAME
        )
        self.assertEqual(resp.status_code, 200)

        self.assertIn('<div id=""login-and-registration-container""', resp.content)

    @override_settings(SITE_NAME=settings.MICROSITE_TEST_HOSTNAME)
    def test_no_override(self):
        """"""
        Make sure we get the old style login/registration if we don't override
        """"""

        resp = self.client.get(
            reverse('signin_user'),
            HTTP_HOST=settings.MICROSITE_TEST_HOSTNAME
        )
        self.assertEqual(resp.status_code, 200)

        self.assertNotIn('<div id=""login-and-registration-container""', resp.content)

        resp = self.client.get(
            reverse('register_user'),
            HTTP_HOST=settings.MICROSITE_TEST_HOSTNAME
        )
        self.assertEqual(resp.status_code, 200)

        self.assertNotIn('<div id=""login-and-registration-container""', resp.content)


class AccountCreationTestCaseWithSiteOverrides(SiteMixin, TestCase):
    """"""
    Test cases for Feature flag ALLOW_PUBLIC_ACCOUNT_CREATION which when
    turned off disables the account creation options in lms
    """"""

    def setUp(self):
        """"""Set up the tests""""""
        super(AccountCreationTestCaseWithSiteOverrides, self).setUp()

        # Set the feature flag ALLOW_PUBLIC_ACCOUNT_CREATION to False
        self.site_configuration_values = {
            'ALLOW_PUBLIC_ACCOUNT_CREATION': False
        }
        self.site_domain = 'testserver1.com'
        self.set_up_site(self.site_domain, self.site_configuration_values)

    def test_register_option_login_page(self):
        """"""
        Navigate to the login page and check the Register option is hidden when
        ALLOW_PUBLIC_ACCOUNT_CREATION flag is turned off
        """"""
        response = self.client.get(reverse('signin_user'))
        self.assertNotIn('<a class=""btn-neutral"" href=""/register?next=%2Fdashboard"">Register</a>',
                         response.content)
/n/n/nlms/djangoapps/student_account/views.py/n/n"""""" Views for a student's account information. """"""

import json
import logging
import urlparse
from datetime import datetime

import pytz
from django.conf import settings
from django.contrib import messages
from django.contrib.auth import get_user_model
from django.contrib.auth.decorators import login_required
from django.core.urlresolvers import resolve, reverse
from django.http import HttpRequest, HttpResponse, HttpResponseBadRequest, HttpResponseForbidden
from django.shortcuts import redirect
from django.utils.translation import ugettext as _
from django.views.decorators.csrf import ensure_csrf_cookie
from django.views.decorators.http import require_http_methods
from django_countries import countries

import third_party_auth
from commerce.models import CommerceConfiguration
from edxmako.shortcuts import render_to_response, render_to_string
from lms.djangoapps.commerce.utils import EcommerceService
from openedx.core.djangoapps.commerce.utils import ecommerce_api_client
from openedx.core.djangoapps.external_auth.login_and_register import login as external_auth_login
from openedx.core.djangoapps.external_auth.login_and_register import register as external_auth_register
from openedx.core.djangoapps.lang_pref.api import all_languages, released_languages
from openedx.core.djangoapps.programs.models import ProgramsApiConfig
from openedx.core.djangoapps.site_configuration import helpers as configuration_helpers
from openedx.core.djangoapps.theming.helpers import is_request_in_themed_site
from openedx.core.djangoapps.user_api.accounts.api import request_password_change
from openedx.core.djangoapps.user_api.errors import UserNotFound
from openedx.core.lib.edx_api_utils import get_edx_api_data
from openedx.core.lib.time_zone_utils import TIME_ZONE_CHOICES
from openedx.features.enterprise_support.api import enterprise_customer_for_request
from student.helpers import destroy_oauth_tokens, get_next_url_for_login_page
from student.models import UserProfile
from student.views import register_user as old_register_view
from student.views import signin_user as old_login_view
from third_party_auth import pipeline
from third_party_auth.decorators import xframe_allow_whitelisted
from util.bad_request_rate_limiter import BadRequestRateLimiter
from util.date_utils import strftime_localized

AUDIT_LOG = logging.getLogger(""audit"")
log = logging.getLogger(__name__)
User = get_user_model()  # pylint:disable=invalid-name


@require_http_methods(['GET'])
@ensure_csrf_cookie
@xframe_allow_whitelisted
def login_and_registration_form(request, initial_mode=""login""):
    """"""Render the combined login/registration form, defaulting to login

    This relies on the JS to asynchronously load the actual form from
    the user_api.

    Keyword Args:
        initial_mode (string): Either ""login"" or ""register"".

    """"""
    # Determine the URL to redirect to following login/registration/third_party_auth
    redirect_to = get_next_url_for_login_page(request)
    # If we're already logged in, redirect to the dashboard
    if request.user.is_authenticated():
        return redirect(redirect_to)

    # Retrieve the form descriptions from the user API
    form_descriptions = _get_form_descriptions(request)

    # Our ?next= URL may itself contain a parameter 'tpa_hint=x' that we need to check.
    # If present, we display a login page focused on third-party auth with that provider.
    third_party_auth_hint = None
    if '?' in redirect_to:
        try:
            next_args = urlparse.parse_qs(urlparse.urlparse(redirect_to).query)
            provider_id = next_args['tpa_hint'][0]
            tpa_hint_provider = third_party_auth.provider.Registry.get(provider_id=provider_id)
            if tpa_hint_provider:
                if tpa_hint_provider.skip_hinted_login_dialog:
                    # Forward the user directly to the provider's login URL when the provider is configured
                    # to skip the dialog.
                    if initial_mode == ""register"":
                        auth_entry = pipeline.AUTH_ENTRY_REGISTER
                    else:
                        auth_entry = pipeline.AUTH_ENTRY_LOGIN
                    return redirect(
                        pipeline.get_login_url(provider_id, auth_entry, redirect_url=redirect_to)
                    )
                third_party_auth_hint = provider_id
                initial_mode = ""hinted_login""
        except (KeyError, ValueError, IndexError) as ex:
            log.error(""Unknown tpa_hint provider: %s"", ex)

    # If this is a themed site, revert to the old login/registration pages.
    # We need to do this for now to support existing themes.
    # Themed sites can use the new logistration page by setting
    # 'ENABLE_COMBINED_LOGIN_REGISTRATION' in their
    # configuration settings.
    if is_request_in_themed_site() and not configuration_helpers.get_value('ENABLE_COMBINED_LOGIN_REGISTRATION', False):
        if initial_mode == ""login"":
            return old_login_view(request)
        elif initial_mode == ""register"":
            return old_register_view(request)

    # Allow external auth to intercept and handle the request
    ext_auth_response = _external_auth_intercept(request, initial_mode)
    if ext_auth_response is not None:
        return ext_auth_response

    # Account activation message
    account_activation_messages = [
        {
            'message': message.message, 'tags': message.tags
        } for message in messages.get_messages(request) if 'account-activation' in message.tags
    ]

    # Otherwise, render the combined login/registration page
    context = {
        'data': {
            'login_redirect_url': redirect_to,
            'initial_mode': initial_mode,
            'third_party_auth': _third_party_auth_context(request, redirect_to, third_party_auth_hint),
            'third_party_auth_hint': third_party_auth_hint or '',
            'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
            'support_link': configuration_helpers.get_value('SUPPORT_SITE_LINK', settings.SUPPORT_SITE_LINK),
            'password_reset_support_link': configuration_helpers.get_value(
                'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
            ) or settings.SUPPORT_SITE_LINK,
            'account_activation_messages': account_activation_messages,

            # Include form descriptions retrieved from the user API.
            # We could have the JS client make these requests directly,
            # but we include them in the initial page load to avoid
            # the additional round-trip to the server.
            'login_form_desc': json.loads(form_descriptions['login']),
            'registration_form_desc': json.loads(form_descriptions['registration']),
            'password_reset_form_desc': json.loads(form_descriptions['password_reset']),
            'account_creation_allowed': configuration_helpers.get_value(
                'ALLOW_PUBLIC_ACCOUNT_CREATION', settings.FEATURES.get('ALLOW_PUBLIC_ACCOUNT_CREATION', True))
        },
        'login_redirect_url': redirect_to,  # This gets added to the query string of the ""Sign In"" button in header
        'responsive': True,
        'allow_iframing': True,
        'disable_courseware_js': True,
        'combined_login_and_register': True,
        'disable_footer': not configuration_helpers.get_value(
            'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER',
            settings.FEATURES['ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER']
        ),
    }

    context = update_context_for_enterprise(request, context)

    return render_to_response('student_account/login_and_register.html', context)


@require_http_methods(['POST'])
def password_change_request_handler(request):
    """"""Handle password change requests originating from the account page.

    Uses the Account API to email the user a link to the password reset page.

    Note:
        The next step in the password reset process (confirmation) is currently handled
        by student.views.password_reset_confirm_wrapper, a custom wrapper around Django's
        password reset confirmation view.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the email was sent successfully
        HttpResponse: 400 if there is no 'email' POST parameter
        HttpResponse: 403 if the client has been rate limited
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        POST /account/password

    """"""

    limiter = BadRequestRateLimiter()
    if limiter.is_rate_limit_exceeded(request):
        AUDIT_LOG.warning(""Password reset rate limit exceeded"")
        return HttpResponseForbidden()

    user = request.user
    # Prefer logged-in user's email
    email = user.email if user.is_authenticated() else request.POST.get('email')

    if email:
        try:
            request_password_change(email, request.is_secure())
            user = user if user.is_authenticated() else User.objects.get(email=email)
            destroy_oauth_tokens(user)
        except UserNotFound:
            AUDIT_LOG.info(""Invalid password reset attempt"")
            # Increment the rate limit counter
            limiter.tick_bad_request_counter(request)

        return HttpResponse(status=200)
    else:
        return HttpResponseBadRequest(_(""No email address provided.""))


def update_context_for_enterprise(request, context):
    """"""
    Take the processed context produced by the view, determine if it's relevant
    to a particular Enterprise Customer, and update it to include that customer's
    enterprise metadata.
    """"""

    context = context.copy()

    sidebar_context = enterprise_sidebar_context(request)

    if sidebar_context:
        context['data']['registration_form_desc']['fields'] = enterprise_fields_only(
            context['data']['registration_form_desc']
        )
        context.update(sidebar_context)
        context['enable_enterprise_sidebar'] = True
        context['data']['hide_auth_warnings'] = True
    else:
        context['enable_enterprise_sidebar'] = False

    return context


def enterprise_fields_only(fields):
    """"""
    Take the received field definition, and exclude those fields that we don't want
    to require if the user is going to be a member of an Enterprise Customer.
    """"""
    enterprise_exclusions = configuration_helpers.get_value(
        'ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS',
        settings.ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS
    )
    return [field for field in fields['fields'] if field['name'] not in enterprise_exclusions]


def enterprise_sidebar_context(request):
    """"""
    Given the current request, render the HTML of a sidebar for the current
    logistration view that depicts Enterprise-related information.
    """"""
    enterprise_customer = enterprise_customer_for_request(request)

    if not enterprise_customer:
        return {}

    platform_name = configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME)

    if enterprise_customer.branding_configuration.logo:
        enterprise_logo_url = enterprise_customer.branding_configuration.logo.url
    else:
        enterprise_logo_url = ''

    if getattr(enterprise_customer.branding_configuration, 'welcome_message', None):
        branded_welcome_template = enterprise_customer.branding_configuration.welcome_message
    else:
        branded_welcome_template = configuration_helpers.get_value(
            'ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE',
            settings.ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE
        )

    branded_welcome_string = branded_welcome_template.format(
        start_bold=u'<b>',
        end_bold=u'</b>',
        enterprise_name=enterprise_customer.name,
        platform_name=platform_name
    )

    platform_welcome_template = configuration_helpers.get_value(
        'ENTERPRISE_PLATFORM_WELCOME_TEMPLATE',
        settings.ENTERPRISE_PLATFORM_WELCOME_TEMPLATE
    )
    platform_welcome_string = platform_welcome_template.format(platform_name=platform_name)

    context = {
        'enterprise_name': enterprise_customer.name,
        'enterprise_logo_url': enterprise_logo_url,
        'enterprise_branded_welcome_string': branded_welcome_string,
        'platform_welcome_string': platform_welcome_string,
    }

    return context


def _third_party_auth_context(request, redirect_to, tpa_hint=None):
    """"""Context for third party auth providers and the currently running pipeline.

    Arguments:
        request (HttpRequest): The request, used to determine if a pipeline
            is currently running.
        redirect_to: The URL to send the user to following successful
            authentication.
        tpa_hint (string): An override flag that will return a matching provider
            as long as its configuration has been enabled

    Returns:
        dict

    """"""
    context = {
        ""currentProvider"": None,
        ""providers"": [],
        ""secondaryProviders"": [],
        ""finishAuthUrl"": None,
        ""errorMessage"": None,
    }

    if third_party_auth.is_enabled():
        if not enterprise_customer_for_request(request):
            for enabled in third_party_auth.provider.Registry.displayed_for_login(tpa_hint=tpa_hint):
                info = {
                    ""id"": enabled.provider_id,
                    ""name"": enabled.name,
                    ""iconClass"": enabled.icon_class or None,
                    ""iconImage"": enabled.icon_image.url if enabled.icon_image else None,
                    ""loginUrl"": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_LOGIN,
                        redirect_url=redirect_to,
                    ),
                    ""registerUrl"": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_REGISTER,
                        redirect_url=redirect_to,
                    ),
                }
                context[""providers"" if not enabled.secondary else ""secondaryProviders""].append(info)

        running_pipeline = pipeline.get(request)
        if running_pipeline is not None:
            current_provider = third_party_auth.provider.Registry.get_from_pipeline(running_pipeline)

            if current_provider is not None:
                context[""currentProvider""] = current_provider.name
                context[""finishAuthUrl""] = pipeline.get_complete_url(current_provider.backend_name)

                if current_provider.skip_registration_form:
                    # As a reliable way of ""skipping"" the registration form, we just submit it automatically
                    context[""autoSubmitRegForm""] = True

        # Check for any error messages we may want to display:
        for msg in messages.get_messages(request):
            if msg.extra_tags.split()[0] == ""social-auth"":
                # msg may or may not be translated. Try translating [again] in case we are able to:
                context['errorMessage'] = _(unicode(msg))  # pylint: disable=translation-of-non-string
                break

    return context


def _get_form_descriptions(request):
    """"""Retrieve form descriptions from the user API.

    Arguments:
        request (HttpRequest): The original request, used to retrieve session info.

    Returns:
        dict: Keys are 'login', 'registration', and 'password_reset';
            values are the JSON-serialized form descriptions.

    """"""
    return {
        'login': _local_server_get('/user_api/v1/account/login_session/', request.session),
        'registration': _local_server_get('/user_api/v1/account/registration/', request.session),
        'password_reset': _local_server_get('/user_api/v1/account/password_reset/', request.session)
    }


def _local_server_get(url, session):
    """"""Simulate a server-server GET request for an in-process API.

    Arguments:
        url (str): The URL of the request (excluding the protocol and domain)
        session (SessionStore): The session of the original request,
            used to get past the CSRF checks.

    Returns:
        str: The content of the response

    """"""
    # Since the user API is currently run in-process,
    # we simulate the server-server API call by constructing
    # our own request object.  We don't need to include much
    # information in the request except for the session
    # (to get past through CSRF validation)
    request = HttpRequest()
    request.method = ""GET""
    request.session = session

    # Call the Django view function, simulating
    # the server-server API call
    view, args, kwargs = resolve(url)
    response = view(request, *args, **kwargs)

    # Return the content of the response
    return response.content


def _external_auth_intercept(request, mode):
    """"""Allow external auth to intercept a login/registration request.

    Arguments:
        request (Request): The original request.
        mode (str): Either ""login"" or ""register""

    Returns:
        Response or None

    """"""
    if mode == ""login"":
        return external_auth_login(request)
    elif mode == ""register"":
        return external_auth_register(request)


def get_user_orders(user):
    """"""Given a user, get the detail of all the orders from the Ecommerce service.

    Args:
        user (User): The user to authenticate as when requesting ecommerce.

    Returns:
        list of dict, representing orders returned by the Ecommerce service.
    """"""
    no_data = []
    user_orders = []
    commerce_configuration = CommerceConfiguration.current()
    user_query = {'username': user.username}

    use_cache = commerce_configuration.is_cache_enabled
    cache_key = commerce_configuration.CACHE_KEY + '.' + str(user.id) if use_cache else None
    api = ecommerce_api_client(user)
    commerce_user_orders = get_edx_api_data(
        commerce_configuration, 'orders', api=api, querystring=user_query, cache_key=cache_key
    )

    for order in commerce_user_orders:
        if order['status'].lower() == 'complete':
            date_placed = datetime.strptime(order['date_placed'], ""%Y-%m-%dT%H:%M:%SZ"")
            order_data = {
                'number': order['number'],
                'price': order['total_excl_tax'],
                'order_date': strftime_localized(date_placed, 'SHORT_DATE'),
                'receipt_url': EcommerceService().get_receipt_page_url(order['number']),
                'lines': order['lines'],
            }
            user_orders.append(order_data)

    return user_orders


@login_required
@require_http_methods(['GET'])
def account_settings(request):
    """"""Render the current user's account settings page.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/settings

    """"""
    return render_to_response('student_account/account_settings.html', account_settings_context(request))


@login_required
@require_http_methods(['GET'])
def finish_auth(request):  # pylint: disable=unused-argument
    """""" Following logistration (1st or 3rd party), handle any special query string params.

    See FinishAuthView.js for details on the query string params.

    e.g. auto-enroll the user in a course, set email opt-in preference.

    This view just displays a ""Please wait"" message while AJAX calls are made to enroll the
    user in the course etc. This view is only used if a parameter like ""course_id"" is present
    during login/registration/third_party_auth. Otherwise, there is no need for it.

    Ideally this view will finish and redirect to the next step before the user even sees it.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/finish_auth/?course_id=course-v1:blah&enrollment_action=enroll

    """"""
    return render_to_response('student_account/finish_auth.html', {
        'disable_courseware_js': True,
        'disable_footer': True,
    })


def account_settings_context(request):
    """""" Context for the account settings page.

    Args:
        request: The request object.

    Returns:
        dict

    """"""
    user = request.user

    year_of_birth_options = [(unicode(year), unicode(year)) for year in UserProfile.VALID_YEARS]
    try:
        user_orders = get_user_orders(user)
    except:  # pylint: disable=bare-except
        log.exception('Error fetching order history from Otto.')
        # Return empty order list as account settings page expect a list and
        # it will be broken if exception raised
        user_orders = []

    context = {
        'auth': {},
        'duplicate_provider': None,
        'nav_hidden': True,
        'fields': {
            'country': {
                'options': list(countries),
            }, 'gender': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.GENDER_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'language': {
                'options': released_languages(),
            }, 'level_of_education': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.LEVEL_OF_EDUCATION_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'password': {
                'url': reverse('password_reset'),
            }, 'year_of_birth': {
                'options': year_of_birth_options,
            }, 'preferred_language': {
                'options': all_languages(),
            }, 'time_zone': {
                'options': TIME_ZONE_CHOICES,
            }
        },
        'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
        'password_reset_support_link': configuration_helpers.get_value(
            'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
        ) or settings.SUPPORT_SITE_LINK,
        'user_accounts_api_url': reverse(""accounts_api"", kwargs={'username': user.username}),
        'user_preferences_api_url': reverse('preferences_api', kwargs={'username': user.username}),
        'disable_courseware_js': True,
        'show_program_listing': ProgramsApiConfig.is_enabled(),
        'order_history': user_orders
    }

    if third_party_auth.is_enabled():
        # If the account on the third party provider is already connected with another edX account,
        # we display a message to the user.
        context['duplicate_provider'] = pipeline.get_duplicate_provider(messages.get_messages(request))

        auth_states = pipeline.get_provider_user_states(user)

        context['auth']['providers'] = [{
            'id': state.provider.provider_id,
            'name': state.provider.name,  # The name of the provider e.g. Facebook
            'connected': state.has_account,  # Whether the user's edX account is connected with the provider.
            # If the user is not connected, they should be directed to this page to authenticate
            # with the particular provider, as long as the provider supports initiating a login.
            'connect_url': pipeline.get_login_url(
                state.provider.provider_id,
                pipeline.AUTH_ENTRY_ACCOUNT_SETTINGS,
                # The url the user should be directed to after the auth process has completed.
                redirect_url=reverse('account_settings'),
            ),
            'accepts_logins': state.provider.accepts_logins,
            # If the user is connected, sending a POST request to this url removes the connection
            # information for this provider from their edX account.
            'disconnect_url': pipeline.get_disconnect_url(state.provider.provider_id, state.association_id),
            # We only want to include providers if they are either currently available to be logged
            # in with, or if the user is already authenticated with them.
        } for state in auth_states if state.provider.display_for_login or state.has_account]

    return context
/n/n/n",0
35,35,43b55308a6467a5b8880bb40b71ec0821cb76398,"/lms/djangoapps/student_account/views.py/n/n"""""" Views for a student's account information. """"""

import json
import logging
import urlparse
from datetime import datetime

import pytz
from django.conf import settings
from django.contrib import messages
from django.contrib.auth import get_user_model
from django.contrib.auth.decorators import login_required
from django.core.urlresolvers import resolve, reverse
from django.http import HttpRequest, HttpResponse, HttpResponseBadRequest, HttpResponseForbidden
from django.shortcuts import redirect
from django.utils.translation import ugettext as _
from django.views.decorators.csrf import ensure_csrf_cookie
from django.views.decorators.http import require_http_methods
from django_countries import countries

import third_party_auth
from commerce.models import CommerceConfiguration
from edxmako.shortcuts import render_to_response, render_to_string
from lms.djangoapps.commerce.utils import EcommerceService
from openedx.core.djangoapps.commerce.utils import ecommerce_api_client
from openedx.core.djangoapps.external_auth.login_and_register import login as external_auth_login
from openedx.core.djangoapps.external_auth.login_and_register import register as external_auth_register
from openedx.core.djangoapps.lang_pref.api import all_languages, released_languages
from openedx.core.djangoapps.programs.models import ProgramsApiConfig
from openedx.core.djangoapps.site_configuration import helpers as configuration_helpers
from openedx.core.djangoapps.theming.helpers import is_request_in_themed_site
from openedx.core.djangoapps.user_api.accounts.api import request_password_change
from openedx.core.djangoapps.user_api.errors import UserNotFound
from openedx.core.lib.edx_api_utils import get_edx_api_data
from openedx.core.lib.time_zone_utils import TIME_ZONE_CHOICES
from openedx.features.enterprise_support.api import enterprise_customer_for_request
from student.helpers import destroy_oauth_tokens, get_next_url_for_login_page
from student.models import UserProfile
from student.views import register_user as old_register_view
from student.views import signin_user as old_login_view
from third_party_auth import pipeline
from third_party_auth.decorators import xframe_allow_whitelisted
from util.bad_request_rate_limiter import BadRequestRateLimiter
from util.date_utils import strftime_localized

AUDIT_LOG = logging.getLogger(""audit"")
log = logging.getLogger(__name__)
User = get_user_model()  # pylint:disable=invalid-name


@require_http_methods(['GET'])
@ensure_csrf_cookie
@xframe_allow_whitelisted
def login_and_registration_form(request, initial_mode=""login""):
    """"""Render the combined login/registration form, defaulting to login

    This relies on the JS to asynchronously load the actual form from
    the user_api.

    Keyword Args:
        initial_mode (string): Either ""login"" or ""register"".

    """"""
    # Determine the URL to redirect to following login/registration/third_party_auth
    redirect_to = get_next_url_for_login_page(request)
    # If we're already logged in, redirect to the dashboard
    if request.user.is_authenticated():
        return redirect(redirect_to)

    # Retrieve the form descriptions from the user API
    form_descriptions = _get_form_descriptions(request)

    # Our ?next= URL may itself contain a parameter 'tpa_hint=x' that we need to check.
    # If present, we display a login page focused on third-party auth with that provider.
    third_party_auth_hint = None
    if '?' in redirect_to:
        try:
            next_args = urlparse.parse_qs(urlparse.urlparse(redirect_to).query)
            provider_id = next_args['tpa_hint'][0]
            tpa_hint_provider = third_party_auth.provider.Registry.get(provider_id=provider_id)
            if tpa_hint_provider:
                if tpa_hint_provider.skip_hinted_login_dialog:
                    # Forward the user directly to the provider's login URL when the provider is configured
                    # to skip the dialog.
                    return redirect(
                        pipeline.get_login_url(provider_id, pipeline.AUTH_ENTRY_LOGIN, redirect_url=redirect_to)
                    )
                third_party_auth_hint = provider_id
                initial_mode = ""hinted_login""
        except (KeyError, ValueError, IndexError):
            pass

    # If this is a themed site, revert to the old login/registration pages.
    # We need to do this for now to support existing themes.
    # Themed sites can use the new logistration page by setting
    # 'ENABLE_COMBINED_LOGIN_REGISTRATION' in their
    # configuration settings.
    if is_request_in_themed_site() and not configuration_helpers.get_value('ENABLE_COMBINED_LOGIN_REGISTRATION', False):
        if initial_mode == ""login"":
            return old_login_view(request)
        elif initial_mode == ""register"":
            return old_register_view(request)

    # Allow external auth to intercept and handle the request
    ext_auth_response = _external_auth_intercept(request, initial_mode)
    if ext_auth_response is not None:
        return ext_auth_response

    # Account activation message
    account_activation_messages = [
        {
            'message': message.message, 'tags': message.tags
        } for message in messages.get_messages(request) if 'account-activation' in message.tags
    ]

    # Otherwise, render the combined login/registration page
    context = {
        'data': {
            'login_redirect_url': redirect_to,
            'initial_mode': initial_mode,
            'third_party_auth': _third_party_auth_context(request, redirect_to, third_party_auth_hint),
            'third_party_auth_hint': third_party_auth_hint or '',
            'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
            'support_link': configuration_helpers.get_value('SUPPORT_SITE_LINK', settings.SUPPORT_SITE_LINK),
            'password_reset_support_link': configuration_helpers.get_value(
                'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
            ) or settings.SUPPORT_SITE_LINK,
            'account_activation_messages': account_activation_messages,

            # Include form descriptions retrieved from the user API.
            # We could have the JS client make these requests directly,
            # but we include them in the initial page load to avoid
            # the additional round-trip to the server.
            'login_form_desc': json.loads(form_descriptions['login']),
            'registration_form_desc': json.loads(form_descriptions['registration']),
            'password_reset_form_desc': json.loads(form_descriptions['password_reset']),
            'account_creation_allowed': configuration_helpers.get_value(
                'ALLOW_PUBLIC_ACCOUNT_CREATION', settings.FEATURES.get('ALLOW_PUBLIC_ACCOUNT_CREATION', True))
        },
        'login_redirect_url': redirect_to,  # This gets added to the query string of the ""Sign In"" button in header
        'responsive': True,
        'allow_iframing': True,
        'disable_courseware_js': True,
        'combined_login_and_register': True,
        'disable_footer': not configuration_helpers.get_value(
            'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER',
            settings.FEATURES['ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER']
        ),
    }

    context = update_context_for_enterprise(request, context)

    return render_to_response('student_account/login_and_register.html', context)


@require_http_methods(['POST'])
def password_change_request_handler(request):
    """"""Handle password change requests originating from the account page.

    Uses the Account API to email the user a link to the password reset page.

    Note:
        The next step in the password reset process (confirmation) is currently handled
        by student.views.password_reset_confirm_wrapper, a custom wrapper around Django's
        password reset confirmation view.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the email was sent successfully
        HttpResponse: 400 if there is no 'email' POST parameter
        HttpResponse: 403 if the client has been rate limited
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        POST /account/password

    """"""

    limiter = BadRequestRateLimiter()
    if limiter.is_rate_limit_exceeded(request):
        AUDIT_LOG.warning(""Password reset rate limit exceeded"")
        return HttpResponseForbidden()

    user = request.user
    # Prefer logged-in user's email
    email = user.email if user.is_authenticated() else request.POST.get('email')

    if email:
        try:
            request_password_change(email, request.is_secure())
            user = user if user.is_authenticated() else User.objects.get(email=email)
            destroy_oauth_tokens(user)
        except UserNotFound:
            AUDIT_LOG.info(""Invalid password reset attempt"")
            # Increment the rate limit counter
            limiter.tick_bad_request_counter(request)

        return HttpResponse(status=200)
    else:
        return HttpResponseBadRequest(_(""No email address provided.""))


def update_context_for_enterprise(request, context):
    """"""
    Take the processed context produced by the view, determine if it's relevant
    to a particular Enterprise Customer, and update it to include that customer's
    enterprise metadata.
    """"""

    context = context.copy()

    sidebar_context = enterprise_sidebar_context(request)

    if sidebar_context:
        context['data']['registration_form_desc']['fields'] = enterprise_fields_only(
            context['data']['registration_form_desc']
        )
        context.update(sidebar_context)
        context['enable_enterprise_sidebar'] = True
        context['data']['hide_auth_warnings'] = True
    else:
        context['enable_enterprise_sidebar'] = False

    return context


def enterprise_fields_only(fields):
    """"""
    Take the received field definition, and exclude those fields that we don't want
    to require if the user is going to be a member of an Enterprise Customer.
    """"""
    enterprise_exclusions = configuration_helpers.get_value(
        'ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS',
        settings.ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS
    )
    return [field for field in fields['fields'] if field['name'] not in enterprise_exclusions]


def enterprise_sidebar_context(request):
    """"""
    Given the current request, render the HTML of a sidebar for the current
    logistration view that depicts Enterprise-related information.
    """"""
    enterprise_customer = enterprise_customer_for_request(request)

    if not enterprise_customer:
        return {}

    platform_name = configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME)

    if enterprise_customer.branding_configuration.logo:
        enterprise_logo_url = enterprise_customer.branding_configuration.logo.url
    else:
        enterprise_logo_url = ''

    if getattr(enterprise_customer.branding_configuration, 'welcome_message', None):
        branded_welcome_template = enterprise_customer.branding_configuration.welcome_message
    else:
        branded_welcome_template = configuration_helpers.get_value(
            'ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE',
            settings.ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE
        )

    branded_welcome_string = branded_welcome_template.format(
        start_bold=u'<b>',
        end_bold=u'</b>',
        enterprise_name=enterprise_customer.name,
        platform_name=platform_name
    )

    platform_welcome_template = configuration_helpers.get_value(
        'ENTERPRISE_PLATFORM_WELCOME_TEMPLATE',
        settings.ENTERPRISE_PLATFORM_WELCOME_TEMPLATE
    )
    platform_welcome_string = platform_welcome_template.format(platform_name=platform_name)

    context = {
        'enterprise_name': enterprise_customer.name,
        'enterprise_logo_url': enterprise_logo_url,
        'enterprise_branded_welcome_string': branded_welcome_string,
        'platform_welcome_string': platform_welcome_string,
    }

    return context


def _third_party_auth_context(request, redirect_to, tpa_hint=None):
    """"""Context for third party auth providers and the currently running pipeline.

    Arguments:
        request (HttpRequest): The request, used to determine if a pipeline
            is currently running.
        redirect_to: The URL to send the user to following successful
            authentication.
        tpa_hint (string): An override flag that will return a matching provider
            as long as its configuration has been enabled

    Returns:
        dict

    """"""
    context = {
        ""currentProvider"": None,
        ""providers"": [],
        ""secondaryProviders"": [],
        ""finishAuthUrl"": None,
        ""errorMessage"": None,
    }

    if third_party_auth.is_enabled():
        if not enterprise_customer_for_request(request):
            for enabled in third_party_auth.provider.Registry.displayed_for_login(tpa_hint=tpa_hint):
                info = {
                    ""id"": enabled.provider_id,
                    ""name"": enabled.name,
                    ""iconClass"": enabled.icon_class or None,
                    ""iconImage"": enabled.icon_image.url if enabled.icon_image else None,
                    ""loginUrl"": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_LOGIN,
                        redirect_url=redirect_to,
                    ),
                    ""registerUrl"": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_REGISTER,
                        redirect_url=redirect_to,
                    ),
                }
                context[""providers"" if not enabled.secondary else ""secondaryProviders""].append(info)

        running_pipeline = pipeline.get(request)
        if running_pipeline is not None:
            current_provider = third_party_auth.provider.Registry.get_from_pipeline(running_pipeline)

            if current_provider is not None:
                context[""currentProvider""] = current_provider.name
                context[""finishAuthUrl""] = pipeline.get_complete_url(current_provider.backend_name)

                if current_provider.skip_registration_form:
                    # As a reliable way of ""skipping"" the registration form, we just submit it automatically
                    context[""autoSubmitRegForm""] = True

        # Check for any error messages we may want to display:
        for msg in messages.get_messages(request):
            if msg.extra_tags.split()[0] == ""social-auth"":
                # msg may or may not be translated. Try translating [again] in case we are able to:
                context['errorMessage'] = _(unicode(msg))  # pylint: disable=translation-of-non-string
                break

    return context


def _get_form_descriptions(request):
    """"""Retrieve form descriptions from the user API.

    Arguments:
        request (HttpRequest): The original request, used to retrieve session info.

    Returns:
        dict: Keys are 'login', 'registration', and 'password_reset';
            values are the JSON-serialized form descriptions.

    """"""
    return {
        'login': _local_server_get('/user_api/v1/account/login_session/', request.session),
        'registration': _local_server_get('/user_api/v1/account/registration/', request.session),
        'password_reset': _local_server_get('/user_api/v1/account/password_reset/', request.session)
    }


def _local_server_get(url, session):
    """"""Simulate a server-server GET request for an in-process API.

    Arguments:
        url (str): The URL of the request (excluding the protocol and domain)
        session (SessionStore): The session of the original request,
            used to get past the CSRF checks.

    Returns:
        str: The content of the response

    """"""
    # Since the user API is currently run in-process,
    # we simulate the server-server API call by constructing
    # our own request object.  We don't need to include much
    # information in the request except for the session
    # (to get past through CSRF validation)
    request = HttpRequest()
    request.method = ""GET""
    request.session = session

    # Call the Django view function, simulating
    # the server-server API call
    view, args, kwargs = resolve(url)
    response = view(request, *args, **kwargs)

    # Return the content of the response
    return response.content


def _external_auth_intercept(request, mode):
    """"""Allow external auth to intercept a login/registration request.

    Arguments:
        request (Request): The original request.
        mode (str): Either ""login"" or ""register""

    Returns:
        Response or None

    """"""
    if mode == ""login"":
        return external_auth_login(request)
    elif mode == ""register"":
        return external_auth_register(request)


def get_user_orders(user):
    """"""Given a user, get the detail of all the orders from the Ecommerce service.

    Args:
        user (User): The user to authenticate as when requesting ecommerce.

    Returns:
        list of dict, representing orders returned by the Ecommerce service.
    """"""
    no_data = []
    user_orders = []
    commerce_configuration = CommerceConfiguration.current()
    user_query = {'username': user.username}

    use_cache = commerce_configuration.is_cache_enabled
    cache_key = commerce_configuration.CACHE_KEY + '.' + str(user.id) if use_cache else None
    api = ecommerce_api_client(user)
    commerce_user_orders = get_edx_api_data(
        commerce_configuration, 'orders', api=api, querystring=user_query, cache_key=cache_key
    )

    for order in commerce_user_orders:
        if order['status'].lower() == 'complete':
            date_placed = datetime.strptime(order['date_placed'], ""%Y-%m-%dT%H:%M:%SZ"")
            order_data = {
                'number': order['number'],
                'price': order['total_excl_tax'],
                'order_date': strftime_localized(date_placed, 'SHORT_DATE'),
                'receipt_url': EcommerceService().get_receipt_page_url(order['number']),
                'lines': order['lines'],
            }
            user_orders.append(order_data)

    return user_orders


@login_required
@require_http_methods(['GET'])
def account_settings(request):
    """"""Render the current user's account settings page.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/settings

    """"""
    return render_to_response('student_account/account_settings.html', account_settings_context(request))


@login_required
@require_http_methods(['GET'])
def finish_auth(request):  # pylint: disable=unused-argument
    """""" Following logistration (1st or 3rd party), handle any special query string params.

    See FinishAuthView.js for details on the query string params.

    e.g. auto-enroll the user in a course, set email opt-in preference.

    This view just displays a ""Please wait"" message while AJAX calls are made to enroll the
    user in the course etc. This view is only used if a parameter like ""course_id"" is present
    during login/registration/third_party_auth. Otherwise, there is no need for it.

    Ideally this view will finish and redirect to the next step before the user even sees it.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/finish_auth/?course_id=course-v1:blah&enrollment_action=enroll

    """"""
    return render_to_response('student_account/finish_auth.html', {
        'disable_courseware_js': True,
        'disable_footer': True,
    })


def account_settings_context(request):
    """""" Context for the account settings page.

    Args:
        request: The request object.

    Returns:
        dict

    """"""
    user = request.user

    year_of_birth_options = [(unicode(year), unicode(year)) for year in UserProfile.VALID_YEARS]
    try:
        user_orders = get_user_orders(user)
    except:  # pylint: disable=bare-except
        log.exception('Error fetching order history from Otto.')
        # Return empty order list as account settings page expect a list and
        # it will be broken if exception raised
        user_orders = []

    context = {
        'auth': {},
        'duplicate_provider': None,
        'nav_hidden': True,
        'fields': {
            'country': {
                'options': list(countries),
            }, 'gender': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.GENDER_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'language': {
                'options': released_languages(),
            }, 'level_of_education': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.LEVEL_OF_EDUCATION_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'password': {
                'url': reverse('password_reset'),
            }, 'year_of_birth': {
                'options': year_of_birth_options,
            }, 'preferred_language': {
                'options': all_languages(),
            }, 'time_zone': {
                'options': TIME_ZONE_CHOICES,
            }
        },
        'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
        'password_reset_support_link': configuration_helpers.get_value(
            'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
        ) or settings.SUPPORT_SITE_LINK,
        'user_accounts_api_url': reverse(""accounts_api"", kwargs={'username': user.username}),
        'user_preferences_api_url': reverse('preferences_api', kwargs={'username': user.username}),
        'disable_courseware_js': True,
        'show_program_listing': ProgramsApiConfig.is_enabled(),
        'order_history': user_orders
    }

    if third_party_auth.is_enabled():
        # If the account on the third party provider is already connected with another edX account,
        # we display a message to the user.
        context['duplicate_provider'] = pipeline.get_duplicate_provider(messages.get_messages(request))

        auth_states = pipeline.get_provider_user_states(user)

        context['auth']['providers'] = [{
            'id': state.provider.provider_id,
            'name': state.provider.name,  # The name of the provider e.g. Facebook
            'connected': state.has_account,  # Whether the user's edX account is connected with the provider.
            # If the user is not connected, they should be directed to this page to authenticate
            # with the particular provider, as long as the provider supports initiating a login.
            'connect_url': pipeline.get_login_url(
                state.provider.provider_id,
                pipeline.AUTH_ENTRY_ACCOUNT_SETTINGS,
                # The url the user should be directed to after the auth process has completed.
                redirect_url=reverse('account_settings'),
            ),
            'accepts_logins': state.provider.accepts_logins,
            # If the user is connected, sending a POST request to this url removes the connection
            # information for this provider from their edX account.
            'disconnect_url': pipeline.get_disconnect_url(state.provider.provider_id, state.association_id),
            # We only want to include providers if they are either currently available to be logged
            # in with, or if the user is already authenticated with them.
        } for state in auth_states if state.provider.display_for_login or state.has_account]

    return context
/n/n/n",1
164,164,a9dbf69051d4875875fbe7ed22f7bed6578befc1,"ckanext/data_qld/actions.py/n/nimport ckan.lib.base as base
import ckan.lib.helpers as helpers
import ckan.lib.mailer as mailer
import ckan.model as model
import ckan.plugins as plugins
import ckanext.datarequests.db as db
import ckanext.datarequests.validator as validator
import datetime
import logging
from pylons import config

import constants

c = plugins.toolkit.c
log = logging.getLogger(__name__)
tk = plugins.toolkit

# Avoid user_show lag
USERS_CACHE = {}


def _get_user(user_id):
    try:
        if user_id in USERS_CACHE:
            return USERS_CACHE[user_id]
        else:
            user = tk.get_action('user_show')({'ignore_auth': True}, {'id': user_id})
            USERS_CACHE[user_id] = user
            return user
    except Exception as e:
        log.warn(e)


def _get_organization(organization_id):
    try:
        organization_show = tk.get_action('organization_show')
        return organization_show({'ignore_auth': True}, {'id': organization_id})
    except Exception as e:
        log.warn(e)


def _get_package(package_id):
    try:
        package_show = tk.get_action('package_show')
        return package_show({'ignore_auth': True}, {'id': package_id})
    except Exception as e:
        log.warn(e)


def _dictize_datarequest(datarequest):
    # Transform time
    open_time = str(datarequest.open_time)
    # Close time can be None and the transformation is only needed when the
    # fields contains a valid date
    close_time = datarequest.close_time
    close_time = str(close_time) if close_time else close_time

    # Convert the data request into a dict
    data_dict = {
        'id': datarequest.id,
        'user_id': datarequest.user_id,
        'title': datarequest.title,
        'description': datarequest.description,
        'organization_id': datarequest.organization_id,
        'open_time': open_time,
        'accepted_dataset_id': datarequest.accepted_dataset_id,
        'close_time': close_time,
        'closed': datarequest.closed,
        'user': _get_user(datarequest.user_id),
        'organization': None,
        'accepted_dataset': None,
        'followers': 0,
        'dataset_url': helpers.url_for(controller='ckanext.datarequests.controllers.ui_controller:DataRequestsUI',
                                       action='show', id=datarequest.id, qualified=True)
    }

    if datarequest.organization_id:
        data_dict['organization'] = _get_organization(datarequest.organization_id)

    if datarequest.accepted_dataset_id:
        data_dict['accepted_dataset'] = _get_package(datarequest.accepted_dataset_id)

    data_dict['followers'] = db.DataRequestFollower.get_datarequest_followers_number(
        datarequest_id=datarequest.id)

    return data_dict


def _undictize_datarequest_basic(data_request, data_dict):
    data_request.title = data_dict['title']
    data_request.description = data_dict['description']
    organization = data_dict['organization_id']
    data_request.organization_id = organization if organization else None


def _send_mail(user_ids, action_type, datarequest, job_title):
    for user_id in user_ids:
        try:
            user_data = model.User.get(user_id)
            extra_vars = {
                'datarequest': datarequest,
                'user': user_data,
                'site_title': config.get('ckan.site_title'),
                'site_url': config.get('ckan.site_url')
            }
            subject = base.render_jinja2('emails/subjects/{0}.txt'.format(action_type), extra_vars)
            body = base.render_jinja2('emails/bodies/{0}.txt'.format(action_type), extra_vars)
            tk.enqueue_job(mailer.mail_user, [user_data, subject, body], title=job_title)
        except Exception:
            logging.exception(""Error sending notification to {0}"".format(user_id))


def _get_admin_users_from_organasition(datarequest_dict):
    # Data QLD modification.
    users = set([user['id'] for user in datarequest_dict['organization']['users'] if user.get('capacity') == 'admin'])
    return users


# Copied from ckanext.datarequests.actions. Please keep up to date with any extension updates
@tk.chained_action
def create_datarequest(original_action, context, data_dict):
    """"""
    Action to create a new data request. The function checks the access rights
    of the user before creating the data request. If the user is not allowed
    a NotAuthorized exception will be risen.

    In addition, you should note that the parameters will be checked and an
    exception (ValidationError) will be risen if some of these parameters are
    not valid.

    Data QLD modification
    Will send email notification to users of assigned organisation with admin access

    :param title: The title of the data request
    :type title: string

    :param description: A brief description for your data request
    :type description: string

    :param organiztion_id: The ID of the organization you want to asign the
        data request (optional).
    :type organization_id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict
    """"""

    model = context['model']
    session = context['session']

    # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.CREATE_DATAREQUEST, context, data_dict)

    # Validate data
    validator.validate_datarequest(context, data_dict)

    # Store the data
    data_req = db.DataRequest()
    _undictize_datarequest_basic(data_req, data_dict)
    data_req.user_id = context['auth_user_obj'].id
    data_req.open_time = datetime.datetime.now()

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    if datarequest_dict['organization']:
        # Data QLD modification
        users = _get_admin_users_from_organasition(datarequest_dict)
        users.discard(context['auth_user_obj'].id)
        _send_mail(users, 'new_datarequest_organisation', datarequest_dict, 'Data Request Created Email')

    return datarequest_dict


#  Copied from ckanext.datarequests.actions. Please keep up to date with any action updates
@tk.chained_action
def update_datarequest(original_action, context, data_dict):
    """"""
    Action to update a data request. The function checks the access rights of
    the user before updating the data request. If the user is not allowed
    a NotAuthorized exception will be risen.

    In addition, you should note that the parameters will be checked and an
    exception (ValidationError) will be risen if some of these parameters are
    invalid.

    Data QLD modification
    Will send email notification if organisation was changed to users of assigned organisation with admin access

    :param id: The ID of the data request to be updated
    :type id: string

    :param title: The title of the data request
    :type title: string

    :param description: A brief description for your data request
    :type description: string

    :param organiztion_id: The ID of the organization you want to asign the
        data request.
    :type organization_id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict
    """"""

    model = context['model']
    session = context['session']
    datarequest_id = data_dict.get('id', '')

    if not datarequest_id:
        raise tk.ValidationError(tk._('Data Request ID has not been included'))

    # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.UPDATE_DATAREQUEST, context, data_dict)

    # Get the initial data
    result = db.DataRequest.get(id=datarequest_id)
    if not result:
        raise tk.ObjectNotFound(tk._('Data Request %s not found in the data base') % datarequest_id)

    data_req = result[0]

    # Avoid the validator to return an error when the user does not change the title
    context['avoid_existing_title_check'] = data_req.title == data_dict['title']

    # Validate data
    validator.validate_datarequest(context, data_dict)

    # Data QLD modification
    organisation_updated = data_req.organization_id != data_dict['organization_id']
    if organisation_updated:
        unassigned_organisation_id = data_req.organization_id

    # Set the data provided by the user in the data_red
    _undictize_datarequest_basic(data_req, data_dict)

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    if datarequest_dict['organization'] and organisation_updated:
        # Data QLD modification
        # Email Admin users of the assigned organisation
        users = _get_admin_users_from_organasition(datarequest_dict)
        users.discard(context['auth_user_obj'].id)
        _send_mail(users, 'new_datarequest_organisation', datarequest_dict, 'Data Request Assigned Email')
        # Email Admin users of unassigned organisation
        org_dict = {
            'organization': _get_organization(unassigned_organisation_id)
        }
        users = _get_admin_users_from_organasition(org_dict)
        users.discard(context['auth_user_obj'].id)
        _send_mail(users, 'unassigned_datarequest_organisation', datarequest_dict, 'Data Request Unassigned Email')

    return datarequest_dict


#  Copied from ckanext.datarequests.actions. Please keep up to date with any action updates
@tk.chained_action
def close_datarequest(original_action, context, data_dict):
    """"""
    Action to close a data request. Access rights will be checked before
    closing the data request. If the user is not allowed, a NotAuthorized
    exception will be risen.

    Data QLD modification
    Will send email notification to the data request creator

    :param id: The ID of the data request to be closed
    :type id: string

    :param accepted_dataset_id: The ID of the dataset accepted as solution
        for this data request
    :type accepted_dataset_id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict

    """"""

    model = context['model']
    session = context['session']
    datarequest_id = data_dict.get('id', '')

    # Check id
    if not datarequest_id:
        raise tk.ValidationError(tk._('Data Request ID has not been included'))

    # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.CLOSE_DATAREQUEST, context, data_dict)

    # Get the data request
    result = db.DataRequest.get(id=datarequest_id)
    if not result:
        raise tk.ObjectNotFound(tk._('Data Request %s not found in the data base') % datarequest_id)

    # Validate data
    validator.validate_datarequest_closing(context, data_dict)

    data_req = result[0]

    # Was the data request previously closed?
    if data_req.closed:
        raise tk.ValidationError([tk._('This Data Request is already closed')])

    data_req.closed = True
    data_req.accepted_dataset_id = data_dict.get('accepted_dataset_id', None)
    data_req.close_time = datetime.datetime.now()

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    # Mailing
    users = [data_req.user_id]
    _send_mail(users, 'close_datarequest_creator', datarequest_dict, 'Data Request Closed Send Email')

    return datarequest_dict


def open_datarequest(context, data_dict):
    """"""
    Action to open a data request. Access rights will be checked before
    opening the data request. If the user is not allowed, a NotAuthorized
    exception will be risen.

    :param id: The ID of the data request to be closed
    :type id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict

    """"""

    model = context['model']
    session = context['session']
    datarequest_id = data_dict.get('id', '')

    # Check id
    if not datarequest_id:
        raise tk.ValidationError(tk._('Data Request ID has not been included'))

        # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.OPEN_DATAREQUEST, context, data_dict)

    # Get the data request
    result = db.DataRequest.get(id=datarequest_id)

    if not result:
        raise tk.ObjectNotFound(tk._('Data Request %s not found in the data base') % datarequest_id)

    data_req = result[0]
    data_req.closed = False
    data_req.accepted_dataset_id = None
    data_req.close_time = None

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    # Mailing
    users = [data_req.user_id]
    # Creator email
    _send_mail(users, 'open_datarequest_creator', datarequest_dict, 'Data Request Opened Creator Email')
    if datarequest_dict['organization']:
        users = _get_admin_users_from_organasition(datarequest_dict)
        # Admins of organisation email
        _send_mail(users, 'open_datarequest_organisation', datarequest_dict, 'Data Request Opened Admins Email')

    return datarequest_dict
/n/n/n",0
165,165,a9dbf69051d4875875fbe7ed22f7bed6578befc1,"/ckanext/data_qld/actions.py/n/nimport ckan.lib.base as base
import ckan.lib.helpers as helpers
import ckan.lib.mailer as mailer
import ckan.model as model
import ckan.plugins as plugins
import ckanext.datarequests.db as db
import ckanext.datarequests.validator as validator
import datetime
import logging
from pylons import config

import constants

c = plugins.toolkit.c
log = logging.getLogger(__name__)
tk = plugins.toolkit

# Avoid user_show lag
USERS_CACHE = {}


def _get_user(user_id):
    try:
        if user_id in USERS_CACHE:
            return USERS_CACHE[user_id]
        else:
            user = tk.get_action('user_show')({'ignore_auth': True}, {'id': user_id})
            USERS_CACHE[user_id] = user
            return user
    except Exception as e:
        log.warn(e)


def _get_organization(organization_id):
    try:
        organization_show = tk.get_action('organization_show')
        return organization_show({'ignore_auth': True}, {'id': organization_id})
    except Exception as e:
        log.warn(e)


def _get_package(package_id):
    try:
        package_show = tk.get_action('package_show')
        return package_show({'ignore_auth': True}, {'id': package_id})
    except Exception as e:
        log.warn(e)


def _dictize_datarequest(datarequest):
    # Transform time
    open_time = str(datarequest.open_time)
    # Close time can be None and the transformation is only needed when the
    # fields contains a valid date
    close_time = datarequest.close_time
    close_time = str(close_time) if close_time else close_time

    # Convert the data request into a dict
    data_dict = {
        'id': datarequest.id,
        'user_id': datarequest.user_id,
        'title': datarequest.title,
        'description': datarequest.description,
        'organization_id': datarequest.organization_id,
        'open_time': open_time,
        'accepted_dataset_id': datarequest.accepted_dataset_id,
        'close_time': close_time,
        'closed': datarequest.closed,
        'user': _get_user(datarequest.user_id),
        'organization': None,
        'accepted_dataset': None,
        'followers': 0,
        'dataset_url': helpers.url_for(controller='ckanext.datarequests.controllers.ui_controller:DataRequestsUI',
                                       action='show', id=datarequest.id, qualified=True)
    }

    if datarequest.organization_id:
        data_dict['organization'] = _get_organization(datarequest.organization_id)

    if datarequest.accepted_dataset_id:
        data_dict['accepted_dataset'] = _get_package(datarequest.accepted_dataset_id)

    data_dict['followers'] = db.DataRequestFollower.get_datarequest_followers_number(
        datarequest_id=datarequest.id)

    return data_dict


def _undictize_datarequest_basic(data_request, data_dict):
    data_request.title = data_dict['title']
    data_request.description = data_dict['description']
    organization = data_dict['organization_id']
    data_request.organization_id = organization if organization else None


def _send_mail(user_ids, action_type, datarequest):
    for user_id in user_ids:
        try:
            user_data = model.User.get(user_id)
            extra_vars = {
                'datarequest': datarequest,
                'user': user_data,
                'site_title': config.get('ckan.site_title'),
                'site_url': config.get('ckan.site_url')
            }

            subject = base.render_jinja2('emails/subjects/{0}.txt'.format(action_type), extra_vars)
            body = base.render_jinja2('emails/bodies/{0}.txt'.format(action_type), extra_vars)

            mailer.mail_user(user_data, subject, body)

        except Exception:
            logging.exception(""Error sending notification to {0}"".format(user_id))


def _get_admin_users_from_organasition(datarequest_dict):
    # Data QLD modification.
    users = set([user['id'] for user in datarequest_dict['organization']['users'] if user.get('capacity') == 'admin'])
    return users


# Copied from ckanext.datarequests.actions. Please keep up to date with any extension updates
@tk.chained_action
def create_datarequest(original_action, context, data_dict):
    """"""
    Action to create a new data request. The function checks the access rights
    of the user before creating the data request. If the user is not allowed
    a NotAuthorized exception will be risen.

    In addition, you should note that the parameters will be checked and an
    exception (ValidationError) will be risen if some of these parameters are
    not valid.

    Data QLD modification
    Will send email notification to users of assigned organisation with admin access

    :param title: The title of the data request
    :type title: string

    :param description: A brief description for your data request
    :type description: string

    :param organiztion_id: The ID of the organization you want to asign the
        data request (optional).
    :type organization_id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict
    """"""

    model = context['model']
    session = context['session']

    # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.CREATE_DATAREQUEST, context, data_dict)

    # Validate data
    validator.validate_datarequest(context, data_dict)

    # Store the data
    data_req = db.DataRequest()
    _undictize_datarequest_basic(data_req, data_dict)
    data_req.user_id = context['auth_user_obj'].id
    data_req.open_time = datetime.datetime.now()

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    if datarequest_dict['organization']:
        # Data QLD modification
        users = _get_admin_users_from_organasition(datarequest_dict)
        users.discard(context['auth_user_obj'].id)
        tk.enqueue_job(_send_mail, [users, 'new_datarequest_organisation', datarequest_dict], title=u'Data Request Created Email')

    return datarequest_dict


#  Copied from ckanext.datarequests.actions. Please keep up to date with any action updates
@tk.chained_action
def update_datarequest(original_action, context, data_dict):
    """"""
    Action to update a data request. The function checks the access rights of
    the user before updating the data request. If the user is not allowed
    a NotAuthorized exception will be risen.

    In addition, you should note that the parameters will be checked and an
    exception (ValidationError) will be risen if some of these parameters are
    invalid.

    Data QLD modification
    Will send email notification if organisation was changed to users of assigned organisation with admin access

    :param id: The ID of the data request to be updated
    :type id: string

    :param title: The title of the data request
    :type title: string

    :param description: A brief description for your data request
    :type description: string

    :param organiztion_id: The ID of the organization you want to asign the
        data request.
    :type organization_id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict
    """"""

    model = context['model']
    session = context['session']
    datarequest_id = data_dict.get('id', '')

    if not datarequest_id:
        raise tk.ValidationError(tk._('Data Request ID has not been included'))

    # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.UPDATE_DATAREQUEST, context, data_dict)

    # Get the initial data
    result = db.DataRequest.get(id=datarequest_id)
    if not result:
        raise tk.ObjectNotFound(tk._('Data Request %s not found in the data base') % datarequest_id)

    data_req = result[0]

    # Avoid the validator to return an error when the user does not change the title
    context['avoid_existing_title_check'] = data_req.title == data_dict['title']

    # Validate data
    validator.validate_datarequest(context, data_dict)

    # Data QLD modification
    organisation_updated = data_req.organization_id != data_dict['organization_id']
    if organisation_updated:
        unassigned_organisation_id = data_req.organization_id

    # Set the data provided by the user in the data_red
    _undictize_datarequest_basic(data_req, data_dict)

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    if datarequest_dict['organization'] and organisation_updated:
        # Data QLD modification
        # Email Admin users of the assigned organisation
        users = _get_admin_users_from_organasition(datarequest_dict)
        users.discard(context['auth_user_obj'].id)
        tk.enqueue_job(_send_mail, [users, 'new_datarequest_organisation', datarequest_dict], title=u'Data Request Assigned Email')
        # Email Admin users of unassigned organisation
        org_dict = {
            'organization': _get_organization(unassigned_organisation_id)
        }
        users = _get_admin_users_from_organasition(org_dict)
        users.discard(context['auth_user_obj'].id)
        tk.enqueue_job(_send_mail, [users, 'unassigned_datarequest_organisation', datarequest_dict], title=u'Data Request Unassigned Email')

    return datarequest_dict


#  Copied from ckanext.datarequests.actions. Please keep up to date with any action updates
@tk.chained_action
def close_datarequest(original_action, context, data_dict):
    """"""
    Action to close a data request. Access rights will be checked before
    closing the data request. If the user is not allowed, a NotAuthorized
    exception will be risen.

    Data QLD modification
    Will send email notification to the data request creator

    :param id: The ID of the data request to be closed
    :type id: string

    :param accepted_dataset_id: The ID of the dataset accepted as solution
        for this data request
    :type accepted_dataset_id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict

    """"""

    model = context['model']
    session = context['session']
    datarequest_id = data_dict.get('id', '')

    # Check id
    if not datarequest_id:
        raise tk.ValidationError(tk._('Data Request ID has not been included'))

    # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.CLOSE_DATAREQUEST, context, data_dict)

    # Get the data request
    result = db.DataRequest.get(id=datarequest_id)
    if not result:
        raise tk.ObjectNotFound(tk._('Data Request %s not found in the data base') % datarequest_id)

    # Validate data
    validator.validate_datarequest_closing(context, data_dict)

    data_req = result[0]

    # Was the data request previously closed?
    if data_req.closed:
        raise tk.ValidationError([tk._('This Data Request is already closed')])

    data_req.closed = True
    data_req.accepted_dataset_id = data_dict.get('accepted_dataset_id', None)
    data_req.close_time = datetime.datetime.now()

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    # Mailing
    users = [data_req.user_id]
    tk.enqueue_job(_send_mail, [users, 'close_datarequest_creator', datarequest_dict], title=u'Data Request Closed Send Email')

    return datarequest_dict


def open_datarequest(context, data_dict):
    """"""
    Action to open a data request. Access rights will be checked before
    opening the data request. If the user is not allowed, a NotAuthorized
    exception will be risen.

    :param id: The ID of the data request to be closed
    :type id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict

    """"""

    model = context['model']
    session = context['session']
    datarequest_id = data_dict.get('id', '')

    # Check id
    if not datarequest_id:
        raise tk.ValidationError(tk._('Data Request ID has not been included'))

        # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.OPEN_DATAREQUEST, context, data_dict)

    # Get the data request
    result = db.DataRequest.get(id=datarequest_id)

    if not result:
        raise tk.ObjectNotFound(tk._('Data Request %s not found in the data base') % datarequest_id)

    data_req = result[0]
    data_req.closed = False
    data_req.accepted_dataset_id = None
    data_req.close_time = None

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    # Mailing
    users = [data_req.user_id]
    # Creator email
    tk.enqueue_job(_send_mail, [users, 'open_datarequest_creator', datarequest_dict], title=u'Data Request Opened Creator Email')
    if datarequest_dict['organization']:
        users = _get_admin_users_from_organasition(datarequest_dict)
        # Admins of organisation email
        tk.enqueue_job(_send_mail, [users, 'open_datarequest_organisation', datarequest_dict], title=u'Data Request Opened Admins Email')

    return datarequest_dict
/n/n/n",1
44,44,9e0b9183681627af52832bcc7f23aeee0275e261,"app.py/n/nfrom flask import Flask, render_template, request, redirect, url_for
from flask_bootstrap import Bootstrap
from flask_wtf import FlaskForm
from flask_wtf.file import FileField, FileRequired, FileAllowed
from flask_login import LoginManager, current_user, login_required, login_user, logout_user, UserMixin
from werkzeug.security import generate_password_hash, check_password_hash
from werkzeug.utils import secure_filename
from wtforms import IntegerField, FloatField, DateField, SelectField, \
    SelectMultipleField, FieldList, FormField, StringField, PasswordField, validators
from datetime import datetime
from urlparse import urlparse, urljoin
import os.path
import json
import redis
import re
import pprint
import uuid

pp = pprint.PrettyPrinter(indent=4)

app = Flask(__name__)
app.config['SECRET_KEY'] = 'secret'
app.config['UPLOAD_FOLDER'] = '/static/upload'
app.jinja_env.filters['json_pretty'] = lambda value: json.dumps(value, sort_keys=True, indent=4)
Bootstrap(app)

db = redis.Redis('localhost')


class User(UserMixin):
    user_id = ''
    email = ''
    password_hash = ''

    def get_id(self):
        return self.user_id


def db_init():
    db.flushdb()
    auth_init()
    auth_add_user('gleb.kondratenko@skybonds.com', 'pwd')


def auth_init():
    db.set('user:ids', '0')


def auth_add_user(email, password):
    user_id = db.incr('user:ids')
    db.hset('user:emails', email, user_id)
    db.hmset('user:%s' % user_id, {
        'user_id': user_id,
        'email': email,
        'password_hash': password
    })
    return auth_get_user_by_id(user_id)


def auth_get_user_by_email(email):
    user_id = db.hget('user:emails', email)
    if not user_id:
        return None
    return auth_get_user_by_id(user_id)


def auth_get_user_by_id(user_id):
    key = 'user:%s' % user_id
    if db.hlen(key) == 0:
        return None
    user_data = db.hgetall(key)
    user = User()
    user.user_id = user_data['user_id']
    user.email = user_data['email']
    user.password_hash = generate_password_hash(user_data['password_hash'])
    return user


def auth_check_password(user, password):
    return check_password_hash(user.password_hash, password)


db_init()

login_manager = LoginManager(app)
login_manager.login_view = 'view_login'


@login_manager.user_loader
def load_user(user_id):
    return auth_get_user_by_id(user_id)


def load_json(name):
    filename = os.path.join(app.static_folder, name)
    return json.load(open(filename))


@app.route('/')
def view_home():
    return render_template('home.html')


@app.route('/models')
def view_models():
    models = load_json('models.json')
    return render_template('models.html', models=models)


@app.route('/models/add', methods=['GET', 'POST'])
@login_required
def view_models_add():
    model_add_form = ModelAddForm()
    if model_add_form.validate_on_submit():
        def get_path(form_file):
            safe_filename = secure_filename(form_file.filename)
            unique_filename = '%s_%s' % (str(uuid.uuid4()), safe_filename)
            return os.path.join(app.static_folder, 'upload', unique_filename)

        form_file = model_add_form.original_file_name.data
        path = get_path(form_file)
        form_file.save(path)
        return redirect(url_for('view_models'))
    return render_template('models_add.html', form=model_add_form)


@app.route('/results')
def view_results():
    results = load_json('results.json')
    time_series = []
    for name, values in results.items():
        ts = {
            'id': name,
            'values': {
                'x': [],
                'y': []
            }
        }
        dates = [key for key in values]
        dates.sort()
        for date in dates:
            ts['values']['x'].append(date)
            ts['values']['y'].append(values[date])

        # Input time series. Examples:
        # G & A_Exxon_sovcombank: macbook:timeseries
        # oil_Brent: macbook:timeseries
        # Income_tax_rate: macbook:timeseries
        if re.search(':timeseries$', name):
            attrs = name.split(':')
            (ts_name, ts_author), rest = attrs[:2], attrs[2:]
            ts['result_type'] = 'Input time series'
            ts['ts_name'] = ts_name
            ts['ts_author'] = ts_author

        # Output time series. Examples:
        # incomePerDay_exxon, macbook, (output, Exxon_4)
        # incomePerDay_goodyear, macbook, (output, Goodyear)
        # gasoline_exxon, macbook, (output, Exxon_4)
        if re.search('\(output,.*\)$', name):
            name_wo_braces = re.sub(r'[()]', '', name)
            attrs = name_wo_braces.split(',')
            (ts_name, ts_author, _, model_name), rest = attrs[:4], attrs[4:]
            ts['result_type'] = 'Output time series'
            ts['ts_name'] = ts_name
            ts['ts_author'] = ts_author
            ts['model_name'] = model_name

        # Intermediate input time series. Examples:
        # gasoline_exxon, Goodyear, macbook, input, source_type: output, Exxon_4, gasoline_exxon, macbook
        # Income_tax_rate, Exxon_4, macbook, input, source_type: timeseries, Income_tax_rate, macbook
        # G & A_Exxon, Exxon_4, macbook, input, source_type: timeseries, G & A_Exxon, macbook
        # oil, Goodyear, macbook, input, source_type: timeseries, oil, macbook
        # oil, Exxon_4, macbook, input, source_type: timeseries, oil, macbook
        if re.search('input,source_type:', name):
            attrs = name.split(',')
            (ts_name, model_name, ts_author, _), source = attrs[:4], attrs[4:]
            ts['result_type'] = 'Intermediate input time series'
            ts['ts_name'] = ts_name
            ts['ts_author'] = ts_author
            ts['model_name'] = model_name
            if re.search('input,source_type:output', name):
                source_model_name, rest = source[1], source[2:]
                ts['source_model_name'] = source_model_name
                ts['source_type'] = 'model'
            else:
                ts['source_type'] = 'timeseries'

        time_series.append(ts)

    time_series.sort(key=lambda ts_item: ts_item['result_type'], reverse=False)

    return render_template('results.html', results=results, time_series=time_series)


# TODO: figure out proper validation
class NoValidationSelectField(SelectField):
    def pre_validate(self, form):
        """"""per_validation is disabled""""""


class ChangeOneModelForm(FlaskForm):
    def __init__(self, csrf_enabled=False, *args, **kwargs):
        super(ChangeOneModelForm, self).__init__(csrf_enabled=csrf_enabled, *args, **kwargs)

    model_system_name = NoValidationSelectField('Model', [validators.required()], choices=[])
    input_source_initial = NoValidationSelectField('Initial input', [validators.required()], choices=[])
    input_source_final = NoValidationSelectField('Final input', [validators.required()], choices=[])


class ChangeAllModelsForm(FlaskForm):
    def __init__(self, csrf_enabled=False, *args, **kwargs):
        super(ChangeAllModelsForm, self).__init__(csrf_enabled=csrf_enabled, *args, **kwargs)

    input_source_initial = NoValidationSelectField('Initial input', [validators.required()], choices=[])
    input_source_final = NoValidationSelectField('Final input', [validators.required()], choices=[])


class ChangeInputNewValue(FlaskForm):
    def __init__(self, csrf_enabled=False, *args, **kwargs):
        super(ChangeInputNewValue, self).__init__(csrf_enabled=csrf_enabled, *args, **kwargs)

    input_source_initial = NoValidationSelectField('Initial input', [validators.required()], choices=[])
    start_day = DateField('Start day', [validators.required()], '%Y-%m-%d', default=datetime.today())
    number_of_days = IntegerField('Number of days', [validators.required()])
    new_value = FloatField('Delta', [validators.required()])


class ChangeInputAddDelta(FlaskForm):
    def __init__(self, csrf_enabled=False, *args, **kwargs):
        super(ChangeInputAddDelta, self).__init__(csrf_enabled=csrf_enabled, *args, **kwargs)

    input_source_initial = NoValidationSelectField('Initial input', [validators.required()], choices=[])
    start_day = DateField('Start day', [validators.required()], '%Y-%m-%d', default=datetime.today())
    number_of_days = IntegerField('Number of days', [validators.required()])
    delta = FloatField('New Value', [validators.required()])


class RunForm(FlaskForm):
    start_day = DateField('Start day', [validators.required()], '%Y-%m-%d', default=datetime.today())
    number_of_days = IntegerField('Number of days', [validators.required()])
    exe_models = SelectMultipleField('Execute models', [validators.required()])
    change_input_series_one_model = FieldList(FormField(ChangeOneModelForm), min_entries=0)
    change_input_series_all_models = FieldList(FormField(ChangeAllModelsForm), min_entries=0)
    change_timeseries_value_several_days = FieldList(FormField(ChangeInputNewValue), min_entries=0)
    change_timeseries_value_several_days_add_delta = FieldList(FormField(ChangeInputAddDelta), min_entries=0)


class ModelAddForm(FlaskForm):
    model_user_name = StringField('Model name', [validators.required()])
    original_file_name = FileField(""Model input"", validators=[
        FileRequired(),
        FileAllowed(['xlsx'], 'Only .xlsx files are allowed as model input')
    ])


def get_models_choices():
    models = load_json('models.json')
    return [
        (model['model_system_name'], model['model_name_user'] + ':' + model['author'])
        for model in models
    ]


def get_inputs_choices_by_model(name):
    models = load_json('models.json')
    model = next(item for item in models if item['model_system_name'] == name)
    return [(
        value['series_name_system'],
        value['series_name_system'] + ':' + value['series_name_user']
    ) for key, value in model['inputs'].iteritems()]


def get_inputs_choices():
    models = load_json('models.json')
    inputs_by_models = [get_inputs_choices_by_model(model['model_system_name']) for model in models]
    return [item for inputs in inputs_by_models for item in inputs]


# returns list of commands of form data
def get_commands(form):
    result = []
    for field in form:
        if field.name == 'start_day':
            result.append({'command': field.name, 'start_day': str(field.data)})
        elif field.name == 'number_of_days':
            result.append({'command': field.name, 'number_of_days': field.data})
        elif field.name == 'exe_models':
            result.append({'command': field.name, 'include': field.data})
        elif field.name == 'change_input_series_one_model':
            for entry in field.entries:
                result.append({
                    'command': field.name,
                    'model_system_name': entry.model_system_name.data,
                    'input_source_initial': entry.input_source_initial.data,
                    'input_source_final': entry.input_source_final.data
                })
        elif field.name == 'change_input_series_all_models':
            for entry in field.entries:
                result.append({
                    'command': field.name,
                    'input_source_initial': entry.input_source_initial.data,
                    'input_source_final': entry.input_source_final.data
                })
        elif field.name == 'change_timeseries_value_several_days':
            for entry in field.entries:
                result.append({
                    'command': field.name,
                    'input_source_initial': entry.input_source_initial.data,
                    'start_day': str(entry.start_day.data),
                    'number_of_days': entry.number_of_days.data,
                    'new_value': entry.new_value.data
                })
        elif field.name == 'change_timeseries_value_several_days_add_delta':
            for entry in field.entries:
                result.append({
                    'command': field.name,
                    'input_source_initial': entry.input_source_initial.data,
                    'start_day': str(entry.start_day.data),
                    'number_of_days': entry.number_of_days.data,
                    'delta': entry.delta.data
                })

    return result


# creates flask form using data from request.data if any
def get_run_form():
    run_form = RunForm()
    # dynamically fill list or select options for available models
    run_form.exe_models.choices = get_models_choices()
    return run_form


# updates form with defaults from given commands
def set_form_defaults(form, commands):
    def get_command(command_name):
        return [item for item in commands if item['command'] == command_name]

    def str_to_datetime(str):
        if not str or str == 'None':
            str = datetime.today().strftime('%Y-%m-%d')
        str = str[:10]
        return datetime.strptime(str, '%Y-%m-%d')

    # set default values for single fields
    if get_command('start_day'):
        form.start_day.data = str_to_datetime(get_command('start_day')[0]['start_day'])
    if get_command('number_of_days'):
        form.number_of_days.data = get_command('number_of_days')[0]['number_of_days']
    if get_command('exe_models'):
        form.exe_models.data = get_command('exe_models')[0]['include']

    # set default values for compound fields
    # TODO: avoid ifs, use if request.get instead
    if not form.change_input_series_one_model:
        for command in get_command('change_input_series_one_model'):
            form.change_input_series_one_model.append_entry()
    if not form.change_input_series_all_models:
        for command in get_command('change_input_series_all_models'):
            form.change_input_series_all_models.append_entry()
    if not form.change_timeseries_value_several_days:
        for command in get_command('change_timeseries_value_several_days'):
            form.change_timeseries_value_several_days.append_entry()
    if not form.change_timeseries_value_several_days_add_delta:
        for command in get_command('change_timeseries_value_several_days_add_delta'):
            form.change_timeseries_value_several_days_add_delta.append_entry()

    for index, command in enumerate(get_command('change_input_series_one_model')):
        sub_form = form.change_input_series_one_model[index]
        sub_form.model_system_name.choices = get_models_choices()
        sub_form.model_system_name.data = command.get('model_system_name', '')
        sub_form.input_source_initial.choices = get_inputs_choices()
        sub_form.input_source_initial.data = command.get('input_source_initial', '')
        sub_form.input_source_final.choices = get_inputs_choices()
        sub_form.input_source_final.data = command.get('input_source_final', '')
    for index, command in enumerate(get_command('change_input_series_all_models')):
        sub_form = form.change_input_series_all_models[index]
        sub_form.input_source_initial.choices = get_inputs_choices()
        sub_form.input_source_initial.data = command.get('input_source_initial', '')
        sub_form.input_source_final.choices = get_inputs_choices()
        sub_form.input_source_final.data = command.get('input_source_final', '')
    for index, command in enumerate(get_command('change_timeseries_value_several_days')):
        sub_form = form.change_timeseries_value_several_days[index]
        sub_form.input_source_initial.choices = get_inputs_choices()
        sub_form.input_source_initial.data = command.get('input_source_initial', '')
        sub_form.start_day.data = str_to_datetime(command.get('start_day', ''))
        sub_form.number_of_days.data = command.get('number_of_days', '')
        sub_form.new_value.data = command.get('new_value', '')
    for index, command in enumerate(get_command('change_timeseries_value_several_days_add_delta')):
        sub_form = form.change_timeseries_value_several_days_add_delta[index]
        sub_form.input_source_initial.choices = get_inputs_choices()
        sub_form.input_source_initial.data = command.get('input_source_initial', '')
        sub_form.start_day.data = str_to_datetime(command.get('start_day', ''))
        sub_form.number_of_days.data = command.get('number_of_days', '')
        sub_form.delta.data = command.get('delta', '')


@app.route('/run')
def view_run():
    return render_template('run.html')


@app.route('/run/form/init', methods=['POST'])
def view_run_init():
    run_form = get_run_form()
    commands = json.loads(request.data)['commands']
    set_form_defaults(run_form, commands)

    return json.dumps({
        'commands': commands,
        'html': render_template('run_form.html', form=run_form)
    })


@app.route('/run/form/submit', methods=['POST'])
def view_run_submit():
    run_form = get_run_form()
    commands = get_commands(run_form)

    # submitted and valid
    if run_form.validate_on_submit():
        # TODO: run modeling with commands
        return json.dumps({
            'commands': commands,
            'html': render_template('run_success.html', commands=commands)
        })

    return json.dumps({
        'commands': commands,
        'html': render_template('run_form.html', form=run_form)
    }), 400


@app.route('/run/form/add/<field>', methods=['POST'])
def view_run_add(field):
    run_form = get_run_form()
    run_form[field].append_entry()
    commands = get_commands(run_form)
    set_form_defaults(run_form, commands)

    return json.dumps({
        'commands': commands,
        'html': render_template('run_form.html', form=run_form)
    })


@app.route('/run/form/remove/<field>', methods=['POST'])
def view_run_remove(field):
    run_form = get_run_form()
    run_form[field].pop_entry()
    commands = get_commands(run_form)
    set_form_defaults(run_form, commands)

    return json.dumps({
        'commands': commands,
        'html': render_template('run_form.html', form=run_form)
    })


@app.route('/run/form/history', methods=['POST'])
def view_run_history():
    history = json.loads(request.data)
    history = [
        {
            'id': item['id'],
            'date': datetime.fromtimestamp(item['date'] / 1000),
            'commands': item['commands']
        } for item in history
    ]
    return render_template('run_history.html', history=history)


class RegisterForm(FlaskForm):
    email = StringField('Email', [validators.required()])
    password = PasswordField('Password', [validators.required()])

    def __init__(self, *args, **kwargs):
        FlaskForm.__init__(self, *args, **kwargs)
        self.user = None

    def validate(self):
        rv = FlaskForm.validate(self)
        if not rv:
            return False

        user = auth_get_user_by_email(self.email.data)
        if user:
            self.password.errors.append('Email already registered')
            return False

        if len(self.password.data) < 8:
            self.password.errors.append('Password should be at least 8 characters long')
            return False

        self.user = auth_add_user(self.email.data, self.password.data)
        return True


class LoginForm(FlaskForm):
    email = StringField('Email', [validators.required()])
    password = PasswordField('Password', [validators.required()])

    def __init__(self, *args, **kwargs):
        FlaskForm.__init__(self, *args, **kwargs)
        self.user = None

    def validate(self):
        rv = FlaskForm.validate(self)
        if not rv:
            return False

        user = auth_get_user_by_email(self.email.data)
        if not user or not auth_check_password(user, self.password.data):
            self.password.errors.append('Invalid email or password')
            return False

        self.user = user
        return True


@app.route('/register', methods=['GET', 'POST'])
def view_register():
    if current_user.is_authenticated:
        return redirect(url_for('view_home'))
    register_form = RegisterForm()
    if register_form.validate_on_submit():
        login_user(register_form.user, remember=True)
        return redirect(url_for('view_home'))
    return render_template('register.html', form=register_form)


def get_safe_redirect_url():
    def is_safe_url(url):
        ref_url = urlparse(request.host_url)
        test_url = urlparse(urljoin(request.host_url, url))
        return test_url.scheme in ('http', 'https') and ref_url.netloc == test_url.netloc

    for url in request.values.get('next'), request.referrer:
        if url and is_safe_url(url):
            return url


@app.route('/login', methods=['GET', 'POST'])
def view_login():
    if current_user.is_authenticated:
        return redirect(url_for('view_home'))
    login_form = LoginForm()
    if login_form.validate_on_submit():
        login_user(login_form.user, remember=True)
        next_url = get_safe_redirect_url()
        return redirect(next_url or url_for('view_home'))
    return render_template('login.html', form=login_form)


@app.route('/logout')
@login_required
def view_logout():
    logout_user()
    return redirect(url_for('view_home'))


if __name__ == '__main__':
    app.run()
/n/n/n",0
45,45,9e0b9183681627af52832bcc7f23aeee0275e261,"/app.py/n/nfrom flask import Flask, render_template, request, redirect, url_for, session
from flask_bootstrap import Bootstrap
from flask_wtf import FlaskForm
from flask_login import LoginManager, current_user, login_user, logout_user, UserMixin
from werkzeug.security import generate_password_hash, check_password_hash
from wtforms import IntegerField, FloatField, DateField, SelectField, \
    SelectMultipleField, FieldList, FormField, StringField, PasswordField, validators
from datetime import datetime
import os.path
import json
import redis
import re
import pprint

pp = pprint.PrettyPrinter(indent=4)

app = Flask(__name__)
app.config['SECRET_KEY'] = 'secret'
app.jinja_env.filters['json_pretty'] = lambda value: json.dumps(value, sort_keys=True, indent=4)
Bootstrap(app)

db = redis.Redis('localhost')


class User(UserMixin):
    user_id = ''
    email = ''
    password_hash = ''

    def get_id(self):
        return self.user_id


def db_init():
    db.flushdb()
    auth_init()
    auth_add_user('gleb.kondratenko@skybonds.com', 'pwd')


def auth_init():
    db.set('user:ids', '0')


def auth_add_user(email, password):
    user_id = db.incr('user:ids')
    db.hset('user:emails', email, user_id)
    db.hmset('user:%s' % user_id, {
        'user_id': user_id,
        'email': email,
        'password_hash': password
    })
    return auth_get_user_by_id(user_id)


def auth_get_user_by_email(email):
    user_id = db.hget('user:emails', email)
    if not user_id:
        return None
    return auth_get_user_by_id(user_id)


def auth_get_user_by_id(user_id):
    key = 'user:%s' % user_id
    if db.hlen(key) == 0:
        return None
    user_data = db.hgetall(key)
    user = User()
    user.user_id = user_data['user_id']
    user.email = user_data['email']
    user.password_hash = generate_password_hash(user_data['password_hash'])
    return user


def auth_check_password(user, password):
    print('auth_check_password', user.password_hash, password)
    return check_password_hash(user.password_hash, password)


db_init()

login_manager = LoginManager(app)
login_manager.login_view = 'view_login'


@login_manager.user_loader
def load_user(user_id):
    return auth_get_user_by_id(user_id)


def load_json(name):
    filename = os.path.join(app.static_folder, name)
    return json.load(open(filename))


@app.route('/')
def view_home():
    return render_template('home.html')


@app.route('/models')
def view_models():
    models = load_json('models.json')
    return render_template('models.html', models=models)


@app.route('/results')
def view_results():
    results = load_json('results.json')
    time_series = []
    for name, values in results.items():
        ts = {
            'id': name,
            'values': {
                'x': [],
                'y': []
            }
        }
        dates = [key for key in values]
        dates.sort()
        for date in dates:
            ts['values']['x'].append(date)
            ts['values']['y'].append(values[date])

        # Input time series. Examples:
        # G & A_Exxon_sovcombank: macbook:timeseries
        # oil_Brent: macbook:timeseries
        # Income_tax_rate: macbook:timeseries
        if re.search(':timeseries$', name):
            attrs = name.split(':')
            (ts_name, ts_author), rest = attrs[:2], attrs[2:]
            ts['result_type'] = 'Input time series'
            ts['ts_name'] = ts_name
            ts['ts_author'] = ts_author

        # Output time series. Examples:
        # incomePerDay_exxon, macbook, (output, Exxon_4)
        # incomePerDay_goodyear, macbook, (output, Goodyear)
        # gasoline_exxon, macbook, (output, Exxon_4)
        if re.search('\(output,.*\)$', name):
            name_wo_braces = re.sub(r'[()]', '', name)
            attrs = name_wo_braces.split(',')
            (ts_name, ts_author, _, model_name), rest = attrs[:4], attrs[4:]
            ts['result_type'] = 'Output time series'
            ts['ts_name'] = ts_name
            ts['ts_author'] = ts_author
            ts['model_name'] = model_name

        # Intermediate input time series. Examples:
        # gasoline_exxon, Goodyear, macbook, input, source_type: output, Exxon_4, gasoline_exxon, macbook
        # Income_tax_rate, Exxon_4, macbook, input, source_type: timeseries, Income_tax_rate, macbook
        # G & A_Exxon, Exxon_4, macbook, input, source_type: timeseries, G & A_Exxon, macbook
        # oil, Goodyear, macbook, input, source_type: timeseries, oil, macbook
        # oil, Exxon_4, macbook, input, source_type: timeseries, oil, macbook
        if re.search('input,source_type:', name):
            attrs = name.split(',')
            (ts_name, model_name, ts_author, _), source = attrs[:4], attrs[4:]
            ts['result_type'] = 'Intermediate input time series'
            ts['ts_name'] = ts_name
            ts['ts_author'] = ts_author
            ts['model_name'] = model_name
            if re.search('input,source_type:output', name):
                source_model_name, rest = source[1], source[2:]
                ts['source_model_name'] = source_model_name
                ts['source_type'] = 'model'
            else:
                ts['source_type'] = 'timeseries'

        time_series.append(ts)

    time_series.sort(key=lambda ts_item: ts_item['result_type'], reverse=False)

    return render_template('results.html', results=results, time_series=time_series)


# TODO: figure out proper validation
class NoValidationSelectField(SelectField):
    def pre_validate(self, form):
        """"""per_validation is disabled""""""


class ChangeOneModelForm(FlaskForm):
    def __init__(self, csrf_enabled=False, *args, **kwargs):
        super(ChangeOneModelForm, self).__init__(csrf_enabled=csrf_enabled, *args, **kwargs)

    model_system_name = NoValidationSelectField('Model', [validators.required()], choices=[])
    input_source_initial = NoValidationSelectField('Initial input', [validators.required()], choices=[])
    input_source_final = NoValidationSelectField('Final input', [validators.required()], choices=[])


class ChangeAllModelsForm(FlaskForm):
    def __init__(self, csrf_enabled=False, *args, **kwargs):
        super(ChangeAllModelsForm, self).__init__(csrf_enabled=csrf_enabled, *args, **kwargs)

    input_source_initial = NoValidationSelectField('Initial input', [validators.required()], choices=[])
    input_source_final = NoValidationSelectField('Final input', [validators.required()], choices=[])


class ChangeInputNewValue(FlaskForm):
    def __init__(self, csrf_enabled=False, *args, **kwargs):
        super(ChangeInputNewValue, self).__init__(csrf_enabled=csrf_enabled, *args, **kwargs)

    input_source_initial = NoValidationSelectField('Initial input', [validators.required()], choices=[])
    start_day = DateField('Start day', [validators.required()], '%Y-%m-%d', default=datetime.today())
    number_of_days = IntegerField('Number of days', [validators.required()])
    new_value = FloatField('Delta', [validators.required()])


class ChangeInputAddDelta(FlaskForm):
    def __init__(self, csrf_enabled=False, *args, **kwargs):
        super(ChangeInputAddDelta, self).__init__(csrf_enabled=csrf_enabled, *args, **kwargs)

    input_source_initial = NoValidationSelectField('Initial input', [validators.required()], choices=[])
    start_day = DateField('Start day', [validators.required()], '%Y-%m-%d', default=datetime.today())
    number_of_days = IntegerField('Number of days', [validators.required()])
    delta = FloatField('New Value', [validators.required()])


class RunForm(FlaskForm):
    start_day = DateField('Start day', [validators.required()], '%Y-%m-%d', default=datetime.today())
    number_of_days = IntegerField('Number of days', [validators.required()])
    exe_models = SelectMultipleField('Execute models', [validators.required()])
    change_input_series_one_model = FieldList(FormField(ChangeOneModelForm), min_entries=0)
    change_input_series_all_models = FieldList(FormField(ChangeAllModelsForm), min_entries=0)
    change_timeseries_value_several_days = FieldList(FormField(ChangeInputNewValue), min_entries=0)
    change_timeseries_value_several_days_add_delta = FieldList(FormField(ChangeInputAddDelta), min_entries=0)


def get_models_choices():
    models = load_json('models.json')
    return [
        (model['model_system_name'], model['model_name_user'] + ':' + model['author'])
        for model in models
    ]


def get_inputs_choices_by_model(name):
    models = load_json('models.json')
    model = next(item for item in models if item['model_system_name'] == name)
    return [(
        value['series_name_system'],
        value['series_name_system'] + ':' + value['series_name_user']
    ) for key, value in model['inputs'].iteritems()]


def get_inputs_choices():
    models = load_json('models.json')
    inputs_by_models = [get_inputs_choices_by_model(model['model_system_name']) for model in models]
    return [item for inputs in inputs_by_models for item in inputs]


# returns list of commands of form data
def get_commands(form):
    result = []
    for field in form:
        if field.name == 'start_day':
            result.append({'command': field.name, 'start_day': str(field.data)})
        elif field.name == 'number_of_days':
            result.append({'command': field.name, 'number_of_days': field.data})
        elif field.name == 'exe_models':
            result.append({'command': field.name, 'include': field.data})
        elif field.name == 'change_input_series_one_model':
            for entry in field.entries:
                result.append({
                    'command': field.name,
                    'model_system_name': entry.model_system_name.data,
                    'input_source_initial': entry.input_source_initial.data,
                    'input_source_final': entry.input_source_final.data
                })
        elif field.name == 'change_input_series_all_models':
            for entry in field.entries:
                result.append({
                    'command': field.name,
                    'input_source_initial': entry.input_source_initial.data,
                    'input_source_final': entry.input_source_final.data
                })
        elif field.name == 'change_timeseries_value_several_days':
            for entry in field.entries:
                result.append({
                    'command': field.name,
                    'input_source_initial': entry.input_source_initial.data,
                    'start_day': str(entry.start_day.data),
                    'number_of_days': entry.number_of_days.data,
                    'new_value': entry.new_value.data
                })
        elif field.name == 'change_timeseries_value_several_days_add_delta':
            for entry in field.entries:
                result.append({
                    'command': field.name,
                    'input_source_initial': entry.input_source_initial.data,
                    'start_day': str(entry.start_day.data),
                    'number_of_days': entry.number_of_days.data,
                    'delta': entry.delta.data
                })

    return result


# creates flask form using data from request.data if any
def get_run_form():
    run_form = RunForm()
    # dynamically fill list or select options for available models
    run_form.exe_models.choices = get_models_choices()
    return run_form


# updates form with defaults from given commands
def set_form_defaults(form, commands):
    def get_command(command_name):
        return [item for item in commands if item['command'] == command_name]

    def str_to_datetime(str):
        if not str or str == 'None':
            str = datetime.today().strftime('%Y-%m-%d')
        str = str[:10]
        return datetime.strptime(str, '%Y-%m-%d')

    # set default values for single fields
    if get_command('start_day'):
        form.start_day.data = str_to_datetime(get_command('start_day')[0]['start_day'])
    if get_command('number_of_days'):
        form.number_of_days.data = get_command('number_of_days')[0]['number_of_days']
    if get_command('exe_models'):
        form.exe_models.data = get_command('exe_models')[0]['include']

    # set default values for compound fields
    # TODO: avoid ifs, use if request.get instead
    if not form.change_input_series_one_model:
        for command in get_command('change_input_series_one_model'):
            form.change_input_series_one_model.append_entry()
    if not form.change_input_series_all_models:
        for command in get_command('change_input_series_all_models'):
            form.change_input_series_all_models.append_entry()
    if not form.change_timeseries_value_several_days:
        for command in get_command('change_timeseries_value_several_days'):
            form.change_timeseries_value_several_days.append_entry()
    if not form.change_timeseries_value_several_days_add_delta:
        for command in get_command('change_timeseries_value_several_days_add_delta'):
            form.change_timeseries_value_several_days_add_delta.append_entry()

    for index, command in enumerate(get_command('change_input_series_one_model')):
        sub_form = form.change_input_series_one_model[index]
        sub_form.model_system_name.choices = get_models_choices()
        sub_form.model_system_name.data = command.get('model_system_name', '')
        sub_form.input_source_initial.choices = get_inputs_choices()
        sub_form.input_source_initial.data = command.get('input_source_initial', '')
        sub_form.input_source_final.choices = get_inputs_choices()
        sub_form.input_source_final.data = command.get('input_source_final', '')
    for index, command in enumerate(get_command('change_input_series_all_models')):
        sub_form = form.change_input_series_all_models[index]
        sub_form.input_source_initial.choices = get_inputs_choices()
        sub_form.input_source_initial.data = command.get('input_source_initial', '')
        sub_form.input_source_final.choices = get_inputs_choices()
        sub_form.input_source_final.data = command.get('input_source_final', '')
    for index, command in enumerate(get_command('change_timeseries_value_several_days')):
        sub_form = form.change_timeseries_value_several_days[index]
        sub_form.input_source_initial.choices = get_inputs_choices()
        sub_form.input_source_initial.data = command.get('input_source_initial', '')
        sub_form.start_day.data = str_to_datetime(command.get('start_day', ''))
        sub_form.number_of_days.data = command.get('number_of_days', '')
        sub_form.new_value.data = command.get('new_value', '')
    for index, command in enumerate(get_command('change_timeseries_value_several_days_add_delta')):
        sub_form = form.change_timeseries_value_several_days_add_delta[index]
        sub_form.input_source_initial.choices = get_inputs_choices()
        sub_form.input_source_initial.data = command.get('input_source_initial', '')
        sub_form.start_day.data = str_to_datetime(command.get('start_day', ''))
        sub_form.number_of_days.data = command.get('number_of_days', '')
        sub_form.delta.data = command.get('delta', '')


@app.route('/run')
def view_run():
    return render_template('run.html')


@app.route('/run/form/init', methods=['POST'])
def view_run_init():
    run_form = get_run_form()
    commands = json.loads(request.data)['commands']
    set_form_defaults(run_form, commands)

    return json.dumps({
        'commands': commands,
        'html': render_template('run_form.html', form=run_form)
    })


@app.route('/run/form/submit', methods=['POST'])
def view_run_submit():
    run_form = get_run_form()
    commands = get_commands(run_form)

    # submitted and valid
    if run_form.validate_on_submit():
        # TODO: run modeling with commands
        return json.dumps({
            'commands': commands,
            'html': render_template('run_success.html', commands=commands)
        })

    return json.dumps({
        'commands': commands,
        'html': render_template('run_form.html', form=run_form)
    }), 400


@app.route('/run/form/add/<field>', methods=['POST'])
def view_run_add(field):
    run_form = get_run_form()
    run_form[field].append_entry()
    commands = get_commands(run_form)
    set_form_defaults(run_form, commands)

    return json.dumps({
        'commands': commands,
        'html': render_template('run_form.html', form=run_form)
    })


@app.route('/run/form/remove/<field>', methods=['POST'])
def view_run_remove(field):
    run_form = get_run_form()
    run_form[field].pop_entry()
    commands = get_commands(run_form)
    set_form_defaults(run_form, commands)

    return json.dumps({
        'commands': commands,
        'html': render_template('run_form.html', form=run_form)
    })


@app.route('/run/form/history', methods=['POST'])
def view_run_history():
    history = json.loads(request.data)
    history = [
        {
            'id': item['id'],
            'date': datetime.fromtimestamp(item['date'] / 1000),
            'commands': item['commands']
        } for item in history
    ]
    return render_template('run_history.html', history=history)


class RegisterForm(FlaskForm):
    email = StringField('Email', [validators.required()])
    password = PasswordField('Password', [validators.required()])

    def __init__(self, *args, **kwargs):
        FlaskForm.__init__(self, *args, **kwargs)
        self.user = None

    def validate(self):
        rv = FlaskForm.validate(self)
        if not rv:
            return False

        user = auth_get_user_by_email(self.email.data)
        if user:
            self.password.errors.append('Email already registered')
            return False

        if len(self.password.data) < 8:
            self.password.errors.append('Password should be at least 8 characters long')
            return False

        self.user = auth_add_user(self.email.data, self.password.data)
        return True


class LoginForm(FlaskForm):
    email = StringField('Email', [validators.required()])
    password = PasswordField('Password', [validators.required()])

    def __init__(self, *args, **kwargs):
        FlaskForm.__init__(self, *args, **kwargs)
        self.user = None

    def validate(self):
        rv = FlaskForm.validate(self)
        if not rv:
            return False

        user = auth_get_user_by_email(self.email.data)
        if not user or not auth_check_password(user, self.password.data):
            self.password.errors.append('Invalid email or password')
            return False

        self.user = user
        return True


@app.route('/register', methods=['GET', 'POST'])
def view_register():
    if current_user.is_authenticated:
        return redirect(url_for('view_home'))
    register_form = RegisterForm()
    if register_form.validate_on_submit():
        login_user(register_form.user, remember=True)
        return redirect(url_for('view_home'))
    return render_template('register.html', form=register_form)


@app.route('/login', methods=['GET', 'POST'])
def view_login():
    if current_user.is_authenticated:
        return redirect(url_for('view_home'))
    login_form = LoginForm()
    if login_form.validate_on_submit():
        login_user(login_form.user, remember=True)
        return redirect(url_for('view_home'))
    return render_template('login.html', form=login_form)


@app.route('/logout')
def view_logout():
    logout_user()
    return redirect(url_for('view_home'))


if __name__ == '__main__':
    app.run()
/n/n/n",1
50,50,fa05c3c41f03c7ec1d689e0a6329811aab272fab,"tools/open_redirect.py/n/n#!/usr/bin/python
import requests,sys

def start():
    input_file = sys.argv[1]
    output_file = sys.argv[2]
    payload_file = sys.argv[3]

    print(""\n-- Testing open redirects on domains in ""+input_file+"" with output file, ""+output_file+"" --"")

    is_closed = True

    payloads = open(payload_file,'r').read().split('\n')

    #First loop trough the payloads to prevent 429 (rate limit)
    for payload in payloads: 
        domains = open(input_file,'r').read().split('\n')   
        print ""\n - Trying payload ""+payload+"" - ""
        for domain in domains:
            if domain != """":

                url = ""https://"" + domain + payload
                url = url.strip()
            
                try:
                    r = requests.head(url, allow_redirects=True, timeout=5)

                    if r.history:  
                        if r.url == ""https://example.com"":
                            print ""[+]""+url
                            if is_closed:
                                file = open(output_file,""w+"")
                            is_closed = False
                            file.write(url + ""\n"")
                        else:
                            print ""[-]""+url
                    else:
                        print ""[-]""+url
                except:
                    print ""[-]Error on "" + url
            else:
                print ""[-]Domain is invalid""

    if is_closed == False:
        file.close()
    print(""\n-- Done --"")

start()

/n/n/n",0
51,51,fa05c3c41f03c7ec1d689e0a6329811aab272fab,"/tools/open_redirect.py/n/n#!/usr/bin/python
import requests,sys

def start():
    input_file = sys.argv[1]
    output_file = sys.argv[2]
    payload_file = sys.argv[3]

    print(""\n-- Testing open redirects on domains in ""+input_file+"" with output file, ""+output_file+"" --"")

    is_closed = True

    payloads = open(payload_file,'r').read().split('\n')

    #First loop trough the payloads to prevent 429 (rate limit)
    for payload in payloads: 
        domains = open(input_file,'r').read().split('\n')   
        print ""\n - Trying payload ""+payload+"" - ""
        for domain in domains:
            if domain != """":

                url = ""https://"" + domain + payload
                url = url.strip()
            
                try:
                    r = requests.head(url, allow_redirects=True, timeout=5)
                except:
                    print ""[-]Error on "" + url

                if r.history:  
                    if r.url == ""https://example.com"":
                        print ""[+]""+url
                        if is_closed:
                            file = open(output_file,""w+"")
                        is_closed = False
                        file.write(url + ""\n"")
                    else:
                        print ""[-]""+url
                else:
                    print ""[-]""+url
        else:
            print ""[-]Domain is invalid""

    if is_closed == False:
        file.close()
    print(""\n-- Done --"")

start()

/n/n/n",1
116,116,6f6d0ff2b41f1cacaf42287b1b230b646bcba9ee,"datasette/app.py/n/nimport asyncio
import click
import collections
import hashlib
import os
import sys
import threading
import traceback
import urllib.parse
from concurrent import futures
from pathlib import Path

from markupsafe import Markup
from jinja2 import ChoiceLoader, Environment, FileSystemLoader, PrefixLoader
from sanic import Sanic, response
from sanic.exceptions import InvalidUsage, NotFound

from .views.base import (
    DatasetteError,
    ureg
)
from .views.database import DatabaseDownload, DatabaseView
from .views.index import IndexView
from .views.special import JsonDataView
from .views.table import RowView, TableView

from .utils import (
    InterruptedError,
    Results,
    escape_css_string,
    escape_sqlite,
    get_plugins,
    module_from_path,
    sqlite3,
    sqlite_timelimit,
    to_css_class
)
from .inspect import inspect_hash, inspect_views, inspect_tables
from .plugins import pm, DEFAULT_PLUGINS
from .version import __version__

app_root = Path(__file__).parent.parent

connections = threading.local()
MEMORY = object()

ConfigOption = collections.namedtuple(
    ""ConfigOption"", (""name"", ""default"", ""help"")
)
CONFIG_OPTIONS = (
    ConfigOption(""default_page_size"", 100, """"""
        Default page size for the table view
    """""".strip()),
    ConfigOption(""max_returned_rows"", 1000, """"""
        Maximum rows that can be returned from a table or custom query
    """""".strip()),
    ConfigOption(""num_sql_threads"", 3, """"""
        Number of threads in the thread pool for executing SQLite queries
    """""".strip()),
    ConfigOption(""sql_time_limit_ms"", 1000, """"""
        Time limit for a SQL query in milliseconds
    """""".strip()),
    ConfigOption(""default_facet_size"", 30, """"""
        Number of values to return for requested facets
    """""".strip()),
    ConfigOption(""facet_time_limit_ms"", 200, """"""
        Time limit for calculating a requested facet
    """""".strip()),
    ConfigOption(""facet_suggest_time_limit_ms"", 50, """"""
        Time limit for calculating a suggested facet
    """""".strip()),
    ConfigOption(""hash_urls"", False, """"""
        Include DB file contents hash in URLs, for far-future caching
    """""".strip()),
    ConfigOption(""allow_facet"", True, """"""
        Allow users to specify columns to facet using ?_facet= parameter
    """""".strip()),
    ConfigOption(""allow_download"", True, """"""
        Allow users to download the original SQLite database files
    """""".strip()),
    ConfigOption(""suggest_facets"", True, """"""
        Calculate and display suggested facets
    """""".strip()),
    ConfigOption(""allow_sql"", True, """"""
        Allow arbitrary SQL queries via ?sql= parameter
    """""".strip()),
    ConfigOption(""default_cache_ttl"", 5, """"""
        Default HTTP cache TTL (used in Cache-Control: max-age= header)
    """""".strip()),
    ConfigOption(""default_cache_ttl_hashed"", 365 * 24 * 60 * 60, """"""
        Default HTTP cache TTL for hashed URL pages
    """""".strip()),
    ConfigOption(""cache_size_kb"", 0, """"""
        SQLite cache size in KB (0 == use SQLite default)
    """""".strip()),
    ConfigOption(""allow_csv_stream"", True, """"""
        Allow .csv?_stream=1 to download all rows (ignoring max_returned_rows)
    """""".strip()),
    ConfigOption(""max_csv_mb"", 100, """"""
        Maximum size allowed for CSV export in MB - set 0 to disable this limit
    """""".strip()),
    ConfigOption(""truncate_cells_html"", 2048, """"""
        Truncate cells longer than this in HTML table view - set 0 to disable
    """""".strip()),
    ConfigOption(""force_https_urls"", False, """"""
        Force URLs in API output to always use https:// protocol
    """""".strip()),
)
DEFAULT_CONFIG = {
    option.name: option.default
    for option in CONFIG_OPTIONS
}


async def favicon(request):
    return response.text("""")


class Datasette:

    def __init__(
        self,
        files,
        cache_headers=True,
        cors=False,
        inspect_data=None,
        metadata=None,
        sqlite_extensions=None,
        template_dir=None,
        plugins_dir=None,
        static_mounts=None,
        memory=False,
        config=None,
        version_note=None,
    ):
        self.files = files
        if not self.files:
            self.files = [MEMORY]
        elif memory:
            self.files = (MEMORY,) + self.files
        self.cache_headers = cache_headers
        self.cors = cors
        self._inspect = inspect_data
        self._metadata = metadata or {}
        self.sqlite_functions = []
        self.sqlite_extensions = sqlite_extensions or []
        self.template_dir = template_dir
        self.plugins_dir = plugins_dir
        self.static_mounts = static_mounts or []
        self._config = dict(DEFAULT_CONFIG, **(config or {}))
        self.version_note = version_note
        self.executor = futures.ThreadPoolExecutor(
            max_workers=self.config(""num_sql_threads"")
        )
        self.max_returned_rows = self.config(""max_returned_rows"")
        self.sql_time_limit_ms = self.config(""sql_time_limit_ms"")
        self.page_size = self.config(""default_page_size"")
        # Execute plugins in constructor, to ensure they are available
        # when the rest of `datasette inspect` executes
        if self.plugins_dir:
            for filename in os.listdir(self.plugins_dir):
                filepath = os.path.join(self.plugins_dir, filename)
                mod = module_from_path(filepath, name=filename)
                try:
                    pm.register(mod)
                except ValueError:
                    # Plugin already registered
                    pass

    def config(self, key):
        return self._config.get(key, None)

    def config_dict(self):
        # Returns a fully resolved config dictionary, useful for templates
        return {
            option.name: self.config(option.name)
            for option in CONFIG_OPTIONS
        }

    def metadata(self, key=None, database=None, table=None, fallback=True):
        """"""
        Looks up metadata, cascading backwards from specified level.
        Returns None if metadata value is not found.
        """"""
        assert not (database is None and table is not None), \
            ""Cannot call metadata() with table= specified but not database=""
        databases = self._metadata.get(""databases"") or {}
        search_list = []
        if database is not None:
            search_list.append(databases.get(database) or {})
        if table is not None:
            table_metadata = (
                (databases.get(database) or {}).get(""tables"") or {}
            ).get(table) or {}
            search_list.insert(0, table_metadata)
        search_list.append(self._metadata)
        if not fallback:
            # No fallback allowed, so just use the first one in the list
            search_list = search_list[:1]
        if key is not None:
            for item in search_list:
                if key in item:
                    return item[key]
            return None
        else:
            # Return the merged list
            m = {}
            for item in search_list:
                m.update(item)
            return m

    def plugin_config(
        self, plugin_name, database=None, table=None, fallback=True
    ):
        ""Return config for plugin, falling back from specified database/table""
        plugins = self.metadata(
            ""plugins"", database=database, table=table, fallback=fallback
        )
        if plugins is None:
            return None
        return plugins.get(plugin_name)

    def app_css_hash(self):
        if not hasattr(self, ""_app_css_hash""):
            self._app_css_hash = hashlib.sha1(
                open(
                    os.path.join(str(app_root), ""datasette/static/app.css"")
                ).read().encode(
                    ""utf8""
                )
            ).hexdigest()[
                :6
            ]
        return self._app_css_hash

    def get_canned_queries(self, database_name):
        queries = self.metadata(
            ""queries"", database=database_name, fallback=False
        ) or {}
        names = queries.keys()
        return [
            self.get_canned_query(database_name, name) for name in names
        ]

    def get_canned_query(self, database_name, query_name):
        queries = self.metadata(
            ""queries"", database=database_name, fallback=False
        ) or {}
        query = queries.get(query_name)
        if query:
            if not isinstance(query, dict):
                query = {""sql"": query}
            query[""name""] = query_name
            return query

    async def get_table_definition(self, database_name, table, type_=""table""):
        table_definition_rows = list(
            await self.execute(
                database_name,
                'select sql from sqlite_master where name = :n and type=:t',
                {""n"": table, ""t"": type_},
            )
        )
        if not table_definition_rows:
            return None
        return table_definition_rows[0][0]

    def get_view_definition(self, database_name, view):
        return self.get_table_definition(database_name, view, 'view')

    def update_with_inherited_metadata(self, metadata):
        # Fills in source/license with defaults, if available
        metadata.update(
            {
                ""source"": metadata.get(""source"") or self.metadata(""source""),
                ""source_url"": metadata.get(""source_url"")
                or self.metadata(""source_url""),
                ""license"": metadata.get(""license"") or self.metadata(""license""),
                ""license_url"": metadata.get(""license_url"")
                or self.metadata(""license_url""),
                ""about"": metadata.get(""about"") or self.metadata(""about""),
                ""about_url"": metadata.get(""about_url"")
                or self.metadata(""about_url""),
            }
        )

    def prepare_connection(self, conn):
        conn.row_factory = sqlite3.Row
        conn.text_factory = lambda x: str(x, ""utf-8"", ""replace"")
        for name, num_args, func in self.sqlite_functions:
            conn.create_function(name, num_args, func)
        if self.sqlite_extensions:
            conn.enable_load_extension(True)
            for extension in self.sqlite_extensions:
                conn.execute(""SELECT load_extension('{}')"".format(extension))
        if self.config(""cache_size_kb""):
            conn.execute('PRAGMA cache_size=-{}'.format(self.config(""cache_size_kb"")))
        pm.hook.prepare_connection(conn=conn)

    def table_exists(self, database, table):
        return table in self.inspect().get(database, {}).get(""tables"")

    def inspect(self):
        "" Inspect the database and return a dictionary of table metadata ""
        if self._inspect:
            return self._inspect

        self._inspect = {}
        for filename in self.files:
            if filename is MEMORY:
                self._inspect["":memory:""] = {
                    ""hash"": ""000"",
                    ""file"": "":memory:"",
                    ""size"": 0,
                    ""views"": {},
                    ""tables"": {},
                }
            else:
                path = Path(filename)
                name = path.stem
                if name in self._inspect:
                    raise Exception(""Multiple files with same stem %s"" % name)
                try:
                    with sqlite3.connect(
                        ""file:{}?immutable=1"".format(path), uri=True
                    ) as conn:
                        self.prepare_connection(conn)
                        self._inspect[name] = {
                            ""hash"": inspect_hash(path),
                            ""file"": str(path),
                            ""size"": path.stat().st_size,
                            ""views"": inspect_views(conn),
                            ""tables"": inspect_tables(conn, (self.metadata(""databases"") or {}).get(name, {}))
                        }
                except sqlite3.OperationalError as e:
                    if (e.args[0] == 'no such module: VirtualSpatialIndex'):
                        raise click.UsageError(
                            ""It looks like you're trying to load a SpatiaLite""
                            "" database without first loading the SpatiaLite module.""
                            ""\n\nRead more: https://datasette.readthedocs.io/en/latest/spatialite.html""
                        )
                    else:
                        raise
        return self._inspect

    def register_custom_units(self):
        ""Register any custom units defined in the metadata.json with Pint""
        for unit in self.metadata(""custom_units"") or []:
            ureg.define(unit)

    def versions(self):
        conn = sqlite3.connect("":memory:"")
        self.prepare_connection(conn)
        sqlite_version = conn.execute(""select sqlite_version()"").fetchone()[0]
        sqlite_extensions = {}
        for extension, testsql, hasversion in (
            (""json1"", ""SELECT json('{}')"", False),
            (""spatialite"", ""SELECT spatialite_version()"", True),
        ):
            try:
                result = conn.execute(testsql)
                if hasversion:
                    sqlite_extensions[extension] = result.fetchone()[0]
                else:
                    sqlite_extensions[extension] = None
            except Exception as e:
                pass
        # Figure out supported FTS versions
        fts_versions = []
        for fts in (""FTS5"", ""FTS4"", ""FTS3""):
            try:
                conn.execute(
                    ""CREATE VIRTUAL TABLE v{fts} USING {fts} (data)"".format(fts=fts)
                )
                fts_versions.append(fts)
            except sqlite3.OperationalError:
                continue
        datasette_version = {""version"": __version__}
        if self.version_note:
            datasette_version[""note""] = self.version_note
        return {
            ""python"": {
                ""version"": ""."".join(map(str, sys.version_info[:3])), ""full"": sys.version
            },
            ""datasette"": datasette_version,
            ""sqlite"": {
                ""version"": sqlite_version,
                ""fts_versions"": fts_versions,
                ""extensions"": sqlite_extensions,
                ""compile_options"": [
                    r[0] for r in conn.execute(""pragma compile_options;"").fetchall()
                ],
            },
        }

    def plugins(self, show_all=False):
        ps = list(get_plugins(pm))
        if not show_all:
            ps = [p for p in ps if p[""name""] not in DEFAULT_PLUGINS]
        return [
            {
                ""name"": p[""name""],
                ""static"": p[""static_path""] is not None,
                ""templates"": p[""templates_path""] is not None,
                ""version"": p.get(""version""),
            }
            for p in ps
        ]

    async def execute(
        self,
        db_name,
        sql,
        params=None,
        truncate=False,
        custom_time_limit=None,
        page_size=None,
    ):
        """"""Executes sql against db_name in a thread""""""
        page_size = page_size or self.page_size

        def sql_operation_in_thread():
            conn = getattr(connections, db_name, None)
            if not conn:
                info = self.inspect()[db_name]
                if info[""file""] == "":memory:"":
                    conn = sqlite3.connect("":memory:"")
                else:
                    conn = sqlite3.connect(
                        ""file:{}?immutable=1"".format(info[""file""]),
                        uri=True,
                        check_same_thread=False,
                    )
                self.prepare_connection(conn)
                setattr(connections, db_name, conn)

            time_limit_ms = self.sql_time_limit_ms
            if custom_time_limit and custom_time_limit < time_limit_ms:
                time_limit_ms = custom_time_limit

            with sqlite_timelimit(conn, time_limit_ms):
                try:
                    cursor = conn.cursor()
                    cursor.execute(sql, params or {})
                    max_returned_rows = self.max_returned_rows
                    if max_returned_rows == page_size:
                        max_returned_rows += 1
                    if max_returned_rows and truncate:
                        rows = cursor.fetchmany(max_returned_rows + 1)
                        truncated = len(rows) > max_returned_rows
                        rows = rows[:max_returned_rows]
                    else:
                        rows = cursor.fetchall()
                        truncated = False
                except sqlite3.OperationalError as e:
                    if e.args == ('interrupted',):
                        raise InterruptedError(e)
                    print(
                        ""ERROR: conn={}, sql = {}, params = {}: {}"".format(
                            conn, repr(sql), params, e
                        )
                    )
                    raise

            if truncate:
                return Results(rows, truncated, cursor.description)

            else:
                return Results(rows, False, cursor.description)

        return await asyncio.get_event_loop().run_in_executor(
            self.executor, sql_operation_in_thread
        )

    def app(self):
        app = Sanic(__name__)
        default_templates = str(app_root / ""datasette"" / ""templates"")
        template_paths = []
        if self.template_dir:
            template_paths.append(self.template_dir)
        template_paths.extend(
            [
                plugin[""templates_path""]
                for plugin in get_plugins(pm)
                if plugin[""templates_path""]
            ]
        )
        template_paths.append(default_templates)
        template_loader = ChoiceLoader(
            [
                FileSystemLoader(template_paths),
                # Support {% extends ""default:table.html"" %}:
                PrefixLoader(
                    {""default"": FileSystemLoader(default_templates)}, delimiter="":""
                ),
            ]
        )
        self.jinja_env = Environment(loader=template_loader, autoescape=True)
        self.jinja_env.filters[""escape_css_string""] = escape_css_string
        self.jinja_env.filters[""quote_plus""] = lambda u: urllib.parse.quote_plus(u)
        self.jinja_env.filters[""escape_sqlite""] = escape_sqlite
        self.jinja_env.filters[""to_css_class""] = to_css_class
        pm.hook.prepare_jinja2_environment(env=self.jinja_env)
        app.add_route(IndexView.as_view(self), r""/<as_format:(\.jsono?)?$>"")
        # TODO: /favicon.ico and /-/static/ deserve far-future cache expires
        app.add_route(favicon, ""/favicon.ico"")
        app.static(""/-/static/"", str(app_root / ""datasette"" / ""static""))
        for path, dirname in self.static_mounts:
            app.static(path, dirname)
        # Mount any plugin static/ directories
        for plugin in get_plugins(pm):
            if plugin[""static_path""]:
                modpath = ""/-/static-plugins/{}/"".format(plugin[""name""])
                app.static(modpath, plugin[""static_path""])
        app.add_route(
            JsonDataView.as_view(self, ""inspect.json"", self.inspect),
            r""/-/inspect<as_format:(\.json)?$>"",
        )
        app.add_route(
            JsonDataView.as_view(self, ""metadata.json"", lambda: self._metadata),
            r""/-/metadata<as_format:(\.json)?$>"",
        )
        app.add_route(
            JsonDataView.as_view(self, ""versions.json"", self.versions),
            r""/-/versions<as_format:(\.json)?$>"",
        )
        app.add_route(
            JsonDataView.as_view(self, ""plugins.json"", self.plugins),
            r""/-/plugins<as_format:(\.json)?$>"",
        )
        app.add_route(
            JsonDataView.as_view(self, ""config.json"", lambda: self._config),
            r""/-/config<as_format:(\.json)?$>"",
        )
        app.add_route(
            DatabaseDownload.as_view(self), r""/<db_name:[^/]+?><as_db:(\.db)$>""
        )
        app.add_route(
            DatabaseView.as_view(self), r""/<db_name:[^/]+?><as_format:(\.jsono?|\.csv)?$>""
        )
        app.add_route(
            TableView.as_view(self),
            r""/<db_name:[^/]+>/<table_and_format:[^/]+?$>"",
        )
        app.add_route(
            RowView.as_view(self),
            r""/<db_name:[^/]+>/<table:[^/]+?>/<pk_path:[^/]+?><as_format:(\.jsono?)?$>"",
        )
        self.register_custom_units()
        # On 404 with a trailing slash redirect to path without that slash:
        @app.middleware(""response"")
        def redirect_on_404_with_trailing_slash(request, original_response):
            if original_response.status == 404 and request.path.endswith(""/""):
                path = request.path.rstrip(""/"")
                if request.query_string:
                    path = ""{}?{}"".format(path, request.query_string)
                return response.redirect(path)

        @app.exception(Exception)
        def on_exception(request, exception):
            title = None
            help = None
            if isinstance(exception, NotFound):
                status = 404
                info = {}
                message = exception.args[0]
            elif isinstance(exception, InvalidUsage):
                status = 405
                info = {}
                message = exception.args[0]
            elif isinstance(exception, DatasetteError):
                status = exception.status
                info = exception.error_dict
                message = exception.message
                if exception.messagge_is_html:
                    message = Markup(message)
                title = exception.title
            else:
                status = 500
                info = {}
                message = str(exception)
                traceback.print_exc()
            templates = [""500.html""]
            if status != 500:
                templates = [""{}.html"".format(status)] + templates
            info.update(
                {""ok"": False, ""error"": message, ""status"": status, ""title"": title}
            )
            if request is not None and request.path.split(""?"")[0].endswith("".json""):
                return response.json(info, status=status)

            else:
                template = self.jinja_env.select_template(templates)
                return response.html(template.render(info), status=status)

        return app
/n/n/ndatasette/utils.py/n/nfrom contextlib import contextmanager
from collections import OrderedDict
import base64
import click
import hashlib
import imp
import json
import os
import pkg_resources
import re
import shlex
import tempfile
import time
import shutil
import urllib
import numbers

try:
    import pysqlite3 as sqlite3
except ImportError:
    import sqlite3

# From https://www.sqlite.org/lang_keywords.html
reserved_words = set((
    'abort action add after all alter analyze and as asc attach autoincrement '
    'before begin between by cascade case cast check collate column commit '
    'conflict constraint create cross current_date current_time '
    'current_timestamp database default deferrable deferred delete desc detach '
    'distinct drop each else end escape except exclusive exists explain fail '
    'for foreign from full glob group having if ignore immediate in index '
    'indexed initially inner insert instead intersect into is isnull join key '
    'left like limit match natural no not notnull null of offset on or order '
    'outer plan pragma primary query raise recursive references regexp reindex '
    'release rename replace restrict right rollback row savepoint select set '
    'table temp temporary then to transaction trigger union unique update using '
    'vacuum values view virtual when where with without'
).split())

SPATIALITE_DOCKERFILE_EXTRAS = r'''
RUN apt-get update && \
    apt-get install -y python3-dev gcc libsqlite3-mod-spatialite && \
    rm -rf /var/lib/apt/lists/*
ENV SQLITE_EXTENSIONS /usr/lib/x86_64-linux-gnu/mod_spatialite.so
'''


class InterruptedError(Exception):
    pass


class Results:
    def __init__(self, rows, truncated, description):
        self.rows = rows
        self.truncated = truncated
        self.description = description

    @property
    def columns(self):
        return [d[0] for d in self.description]

    def __iter__(self):
        return iter(self.rows)

    def __len__(self):
        return len(self.rows)


def urlsafe_components(token):
    ""Splits token on commas and URL decodes each component""
    return [
        urllib.parse.unquote_plus(b) for b in token.split(',')
    ]


def path_from_row_pks(row, pks, use_rowid, quote=True):
    """""" Generate an optionally URL-quoted unique identifier
        for a row from its primary keys.""""""
    if use_rowid:
        bits = [row['rowid']]
    else:
        bits = [
            row[pk][""value""] if isinstance(row[pk], dict) else row[pk]
            for pk in pks
        ]
    if quote:
        bits = [urllib.parse.quote_plus(str(bit)) for bit in bits]
    else:
        bits = [str(bit) for bit in bits]

    return ','.join(bits)


def compound_keys_after_sql(pks, start_index=0):
    # Implementation of keyset pagination
    # See https://github.com/simonw/datasette/issues/190
    # For pk1/pk2/pk3 returns:
    #
    # ([pk1] > :p0)
    #   or
    # ([pk1] = :p0 and [pk2] > :p1)
    #   or
    # ([pk1] = :p0 and [pk2] = :p1 and [pk3] > :p2)
    or_clauses = []
    pks_left = pks[:]
    while pks_left:
        and_clauses = []
        last = pks_left[-1]
        rest = pks_left[:-1]
        and_clauses = ['{} = :p{}'.format(
            escape_sqlite(pk), (i + start_index)
        ) for i, pk in enumerate(rest)]
        and_clauses.append('{} > :p{}'.format(
            escape_sqlite(last), (len(rest) + start_index)
        ))
        or_clauses.append('({})'.format(' and '.join(and_clauses)))
        pks_left.pop()
    or_clauses.reverse()
    return '({})'.format('\n  or\n'.join(or_clauses))


class CustomJSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, sqlite3.Row):
            return tuple(obj)
        if isinstance(obj, sqlite3.Cursor):
            return list(obj)
        if isinstance(obj, bytes):
            # Does it encode to utf8?
            try:
                return obj.decode('utf8')
            except UnicodeDecodeError:
                return {
                    '$base64': True,
                    'encoded': base64.b64encode(obj).decode('latin1'),
                }
        return json.JSONEncoder.default(self, obj)


@contextmanager
def sqlite_timelimit(conn, ms):
    deadline = time.time() + (ms / 1000)
    # n is the number of SQLite virtual machine instructions that will be
    # executed between each check. It's hard to know what to pick here.
    # After some experimentation, I've decided to go with 1000 by default and
    # 1 for time limits that are less than 50ms
    n = 1000
    if ms < 50:
        n = 1

    def handler():
        if time.time() >= deadline:
            return 1

    conn.set_progress_handler(handler, n)
    yield
    conn.set_progress_handler(None, n)


class InvalidSql(Exception):
    pass


allowed_sql_res = [
    re.compile(r'^select\b'),
    re.compile(r'^explain select\b'),
    re.compile(r'^explain query plan select\b'),
    re.compile(r'^with\b'),
]
disallawed_sql_res = [
    (re.compile('pragma'), 'Statement may not contain PRAGMA'),
]


def validate_sql_select(sql):
    sql = sql.strip().lower()
    if not any(r.match(sql) for r in allowed_sql_res):
        raise InvalidSql('Statement must be a SELECT')
    for r, msg in disallawed_sql_res:
        if r.search(sql):
            raise InvalidSql(msg)


def append_querystring(url, querystring):
    op = ""&"" if (""?"" in url) else ""?""
    return ""{}{}{}"".format(
        url, op, querystring
    )


def path_with_added_args(request, args, path=None):
    path = path or request.path
    if isinstance(args, dict):
        args = args.items()
    args_to_remove = {k for k, v in args if v is None}
    current = []
    for key, value in urllib.parse.parse_qsl(request.query_string):
        if key not in args_to_remove:
            current.append((key, value))
    current.extend([
        (key, value)
        for key, value in args
        if value is not None
    ])
    query_string = urllib.parse.urlencode(current)
    if query_string:
        query_string = '?{}'.format(query_string)
    return path + query_string


def path_with_removed_args(request, args, path=None):
    query_string = request.query_string
    if path is None:
        path = request.path
    else:
        if ""?"" in path:
            bits = path.split(""?"", 1)
            path, query_string = bits
    # args can be a dict or a set
    current = []
    if isinstance(args, set):
        def should_remove(key, value):
            return key in args
    elif isinstance(args, dict):
        # Must match key AND value
        def should_remove(key, value):
            return args.get(key) == value
    for key, value in urllib.parse.parse_qsl(query_string):
        if not should_remove(key, value):
            current.append((key, value))
    query_string = urllib.parse.urlencode(current)
    if query_string:
        query_string = '?{}'.format(query_string)
    return path + query_string


def path_with_replaced_args(request, args, path=None):
    path = path or request.path
    if isinstance(args, dict):
        args = args.items()
    keys_to_replace = {p[0] for p in args}
    current = []
    for key, value in urllib.parse.parse_qsl(request.query_string):
        if key not in keys_to_replace:
            current.append((key, value))
    current.extend([p for p in args if p[1] is not None])
    query_string = urllib.parse.urlencode(current)
    if query_string:
        query_string = '?{}'.format(query_string)
    return path + query_string


_css_re = re.compile(r'''['""\n\\]''')
_boring_keyword_re = re.compile(r'^[a-zA-Z_][a-zA-Z0-9_]*$')


def escape_css_string(s):
    return _css_re.sub(lambda m: '\\{:X}'.format(ord(m.group())), s)


def escape_sqlite(s):
    if _boring_keyword_re.match(s) and (s.lower() not in reserved_words):
        return s
    else:
        return '[{}]'.format(s)


def make_dockerfile(files, metadata_file, extra_options, branch, template_dir, plugins_dir, static, install, spatialite, version_note):
    cmd = ['""datasette""', '""serve""', '""--host""', '""0.0.0.0""']
    cmd.append('""' + '"", ""'.join(files) + '""')
    cmd.extend(['""--cors""', '""--port""', '""8001""', '""--inspect-file""', '""inspect-data.json""'])
    if metadata_file:
        cmd.extend(['""--metadata""', '""{}""'.format(metadata_file)])
    if template_dir:
        cmd.extend(['""--template-dir""', '""templates/""'])
    if plugins_dir:
        cmd.extend(['""--plugins-dir""', '""plugins/""'])
    if version_note:
        cmd.extend(['""--version-note""', '""{}""'.format(version_note)])
    if static:
        for mount_point, _ in static:
            cmd.extend(['""--static""', '""{}:{}""'.format(mount_point, mount_point)])
    if extra_options:
        for opt in extra_options.split():
            cmd.append('""{}""'.format(opt))

    if branch:
        install = ['https://github.com/simonw/datasette/archive/{}.zip'.format(
            branch
        )] + list(install)
    else:
        install = ['datasette'] + list(install)

    return '''
FROM python:3.6
COPY . /app
WORKDIR /app
{spatialite_extras}
RUN pip install -U {install_from}
RUN datasette inspect {files} --inspect-file inspect-data.json
EXPOSE 8001
CMD [{cmd}]'''.format(
        files=' '.join(files),
        cmd=', '.join(cmd),
        install_from=' '.join(install),
        spatialite_extras=SPATIALITE_DOCKERFILE_EXTRAS if spatialite else '',
    ).strip()


@contextmanager
def temporary_docker_directory(
    files,
    name,
    metadata,
    extra_options,
    branch,
    template_dir,
    plugins_dir,
    static,
    install,
    spatialite,
    version_note,
    extra_metadata=None
):
    extra_metadata = extra_metadata or {}
    tmp = tempfile.TemporaryDirectory()
    # We create a datasette folder in there to get a nicer now deploy name
    datasette_dir = os.path.join(tmp.name, name)
    os.mkdir(datasette_dir)
    saved_cwd = os.getcwd()
    file_paths = [
        os.path.join(saved_cwd, file_path)
        for file_path in files
    ]
    file_names = [os.path.split(f)[-1] for f in files]
    if metadata:
        metadata_content = json.load(metadata)
    else:
        metadata_content = {}
    for key, value in extra_metadata.items():
        if value:
            metadata_content[key] = value
    try:
        dockerfile = make_dockerfile(
            file_names,
            metadata_content and 'metadata.json',
            extra_options,
            branch,
            template_dir,
            plugins_dir,
            static,
            install,
            spatialite,
            version_note,
        )
        os.chdir(datasette_dir)
        if metadata_content:
            open('metadata.json', 'w').write(json.dumps(metadata_content, indent=2))
        open('Dockerfile', 'w').write(dockerfile)
        for path, filename in zip(file_paths, file_names):
            link_or_copy(path, os.path.join(datasette_dir, filename))
        if template_dir:
            link_or_copy_directory(
                os.path.join(saved_cwd, template_dir),
                os.path.join(datasette_dir, 'templates')
            )
        if plugins_dir:
            link_or_copy_directory(
                os.path.join(saved_cwd, plugins_dir),
                os.path.join(datasette_dir, 'plugins')
            )
        for mount_point, path in static:
            link_or_copy_directory(
                os.path.join(saved_cwd, path),
                os.path.join(datasette_dir, mount_point)
            )
        yield datasette_dir
    finally:
        tmp.cleanup()
        os.chdir(saved_cwd)


@contextmanager
def temporary_heroku_directory(
    files,
    name,
    metadata,
    extra_options,
    branch,
    template_dir,
    plugins_dir,
    static,
    install,
    version_note,
    extra_metadata=None
):
    # FIXME: lots of duplicated code from above

    extra_metadata = extra_metadata or {}
    tmp = tempfile.TemporaryDirectory()
    saved_cwd = os.getcwd()

    file_paths = [
        os.path.join(saved_cwd, file_path)
        for file_path in files
    ]
    file_names = [os.path.split(f)[-1] for f in files]

    if metadata:
        metadata_content = json.load(metadata)
    else:
        metadata_content = {}
    for key, value in extra_metadata.items():
        if value:
            metadata_content[key] = value

    try:
        os.chdir(tmp.name)

        if metadata_content:
            open('metadata.json', 'w').write(json.dumps(metadata_content, indent=2))

        open('runtime.txt', 'w').write('python-3.6.7')

        if branch:
            install = ['https://github.com/simonw/datasette/archive/{branch}.zip'.format(
                branch=branch
            )] + list(install)
        else:
            install = ['datasette'] + list(install)

        open('requirements.txt', 'w').write('\n'.join(install))
        os.mkdir('bin')
        open('bin/post_compile', 'w').write('datasette inspect --inspect-file inspect-data.json')

        extras = []
        if template_dir:
            link_or_copy_directory(
                os.path.join(saved_cwd, template_dir),
                os.path.join(tmp.name, 'templates')
            )
            extras.extend(['--template-dir', 'templates/'])
        if plugins_dir:
            link_or_copy_directory(
                os.path.join(saved_cwd, plugins_dir),
                os.path.join(tmp.name, 'plugins')
            )
            extras.extend(['--plugins-dir', 'plugins/'])
        if version_note:
            extras.extend(['--version-note', version_note])
        if metadata_content:
            extras.extend(['--metadata', 'metadata.json'])
        if extra_options:
            extras.extend(extra_options.split())
        for mount_point, path in static:
            link_or_copy_directory(
                os.path.join(saved_cwd, path),
                os.path.join(tmp.name, mount_point)
            )
            extras.extend(['--static', '{}:{}'.format(mount_point, mount_point)])

        quoted_files = "" "".join(map(shlex.quote, file_names))
        procfile_cmd = 'web: datasette serve --host 0.0.0.0 {quoted_files} --cors --port $PORT --inspect-file inspect-data.json {extras}'.format(
            quoted_files=quoted_files,
            extras=' '.join(extras),
        )
        open('Procfile', 'w').write(procfile_cmd)

        for path, filename in zip(file_paths, file_names):
            link_or_copy(path, os.path.join(tmp.name, filename))

        yield

    finally:
        tmp.cleanup()
        os.chdir(saved_cwd)


def get_all_foreign_keys(conn):
    tables = [r[0] for r in conn.execute('select name from sqlite_master where type=""table""')]
    table_to_foreign_keys = {}
    for table in tables:
        table_to_foreign_keys[table] = {
            'incoming': [],
            'outgoing': [],
        }
    for table in tables:
        infos = conn.execute(
            'PRAGMA foreign_key_list([{}])'.format(table)
        ).fetchall()
        for info in infos:
            if info is not None:
                id, seq, table_name, from_, to_, on_update, on_delete, match = info
                if table_name not in table_to_foreign_keys:
                    # Weird edge case where something refers to a table that does
                    # not actually exist
                    continue
                table_to_foreign_keys[table_name]['incoming'].append({
                    'other_table': table,
                    'column': to_,
                    'other_column': from_
                })
                table_to_foreign_keys[table]['outgoing'].append({
                    'other_table': table_name,
                    'column': from_,
                    'other_column': to_
                })

    return table_to_foreign_keys


def detect_spatialite(conn):
    rows = conn.execute('select 1 from sqlite_master where tbl_name = ""geometry_columns""').fetchall()
    return len(rows) > 0


def detect_fts(conn, table):
    ""Detect if table has a corresponding FTS virtual table and return it""
    rows = conn.execute(detect_fts_sql(table)).fetchall()
    if len(rows) == 0:
        return None
    else:
        return rows[0][0]


def detect_fts_sql(table):
    return r'''
        select name from sqlite_master
            where rootpage = 0
            and (
                sql like '%VIRTUAL TABLE%USING FTS%content=""{table}""%'
                or (
                    tbl_name = ""{table}""
                    and sql like '%VIRTUAL TABLE%USING FTS%'
                )
            )
    '''.format(table=table)


class Filter:
    def __init__(self, key, display, sql_template, human_template, format='{}', numeric=False, no_argument=False):
        self.key = key
        self.display = display
        self.sql_template = sql_template
        self.human_template = human_template
        self.format = format
        self.numeric = numeric
        self.no_argument = no_argument

    def where_clause(self, column, value, param_counter):
        converted = self.format.format(value)
        if self.numeric and converted.isdigit():
            converted = int(converted)
        if self.no_argument:
            kwargs = {
                'c': column,
            }
            converted = None
        else:
            kwargs = {
                'c': column,
                'p': 'p{}'.format(param_counter),
            }
        return self.sql_template.format(**kwargs), converted

    def human_clause(self, column, value):
        if callable(self.human_template):
            template = self.human_template(column, value)
        else:
            template = self.human_template
        if self.no_argument:
            return template.format(c=column)
        else:
            return template.format(c=column, v=value)


class Filters:
    _filters = [
        Filter('exact', '=', '""{c}"" = :{p}', lambda c, v: '{c} = {v}' if v.isdigit() else '{c} = ""{v}""'),
        Filter('not', '!=', '""{c}"" != :{p}', lambda c, v: '{c} != {v}' if v.isdigit() else '{c} != ""{v}""'),
        Filter('contains', 'contains', '""{c}"" like :{p}', '{c} contains ""{v}""', format='%{}%'),
        Filter('endswith', 'ends with', '""{c}"" like :{p}', '{c} ends with ""{v}""', format='%{}'),
        Filter('startswith', 'starts with', '""{c}"" like :{p}', '{c} starts with ""{v}""', format='{}%'),
        Filter('gt', '>', '""{c}"" > :{p}', '{c} > {v}', numeric=True),
        Filter('gte', '\u2265', '""{c}"" >= :{p}', '{c} \u2265 {v}', numeric=True),
        Filter('lt', '<', '""{c}"" < :{p}', '{c} < {v}', numeric=True),
        Filter('lte', '\u2264', '""{c}"" <= :{p}', '{c} \u2264 {v}', numeric=True),
        Filter('glob', 'glob', '""{c}"" glob :{p}', '{c} glob ""{v}""'),
        Filter('like', 'like', '""{c}"" like :{p}', '{c} like ""{v}""'),
        Filter('isnull', 'is null', '""{c}"" is null', '{c} is null', no_argument=True),
        Filter('notnull', 'is not null', '""{c}"" is not null', '{c} is not null', no_argument=True),
        Filter('isblank', 'is blank', '(""{c}"" is null or ""{c}"" = """")', '{c} is blank', no_argument=True),
        Filter('notblank', 'is not blank', '(""{c}"" is not null and ""{c}"" != """")', '{c} is not blank', no_argument=True),
    ]
    _filters_by_key = {
        f.key: f for f in _filters
    }

    def __init__(self, pairs, units={}, ureg=None):
        self.pairs = pairs
        self.units = units
        self.ureg = ureg

    def lookups(self):
        ""Yields (lookup, display, no_argument) pairs""
        for filter in self._filters:
            yield filter.key, filter.display, filter.no_argument

    def human_description_en(self, extra=None):
        bits = []
        if extra:
            bits.extend(extra)
        for column, lookup, value in self.selections():
            filter = self._filters_by_key.get(lookup, None)
            if filter:
                bits.append(filter.human_clause(column, value))
        # Comma separated, with an ' and ' at the end
        and_bits = []
        commas, tail = bits[:-1], bits[-1:]
        if commas:
            and_bits.append(', '.join(commas))
        if tail:
            and_bits.append(tail[0])
        s = ' and '.join(and_bits)
        if not s:
            return ''
        return 'where {}'.format(s)

    def selections(self):
        ""Yields (column, lookup, value) tuples""
        for key, value in self.pairs:
            if '__' in key:
                column, lookup = key.rsplit('__', 1)
            else:
                column = key
                lookup = 'exact'
            yield column, lookup, value

    def has_selections(self):
        return bool(self.pairs)

    def convert_unit(self, column, value):
        ""If the user has provided a unit in the quey, convert it into the column unit, if present.""
        if column not in self.units:
            return value

        # Try to interpret the value as a unit
        value = self.ureg(value)
        if isinstance(value, numbers.Number):
            # It's just a bare number, assume it's the column unit
            return value

        column_unit = self.ureg(self.units[column])
        return value.to(column_unit).magnitude

    def build_where_clauses(self):
        sql_bits = []
        params = {}
        for i, (column, lookup, value) in enumerate(self.selections()):
            filter = self._filters_by_key.get(lookup, None)
            if filter:
                sql_bit, param = filter.where_clause(column, self.convert_unit(column, value), i)
                sql_bits.append(sql_bit)
                if param is not None:
                    param_id = 'p{}'.format(i)
                    params[param_id] = param
        return sql_bits, params


filter_column_re = re.compile(r'^_filter_column_\d+$')


def filters_should_redirect(special_args):
    redirect_params = []
    # Handle _filter_column=foo&_filter_op=exact&_filter_value=...
    filter_column = special_args.get('_filter_column')
    filter_op = special_args.get('_filter_op') or ''
    filter_value = special_args.get('_filter_value') or ''
    if '__' in filter_op:
        filter_op, filter_value = filter_op.split('__', 1)
    if filter_column:
        redirect_params.append(
            ('{}__{}'.format(filter_column, filter_op), filter_value)
        )
    for key in ('_filter_column', '_filter_op', '_filter_value'):
        if key in special_args:
            redirect_params.append((key, None))
    # Now handle _filter_column_1=name&_filter_op_1=contains&_filter_value_1=hello
    column_keys = [k for k in special_args if filter_column_re.match(k)]
    for column_key in column_keys:
        number = column_key.split('_')[-1]
        column = special_args[column_key]
        op = special_args.get('_filter_op_{}'.format(number)) or 'exact'
        value = special_args.get('_filter_value_{}'.format(number)) or ''
        if '__' in op:
            op, value = op.split('__', 1)
        if column:
            redirect_params.append(('{}__{}'.format(column, op), value))
        redirect_params.extend([
            ('_filter_column_{}'.format(number), None),
            ('_filter_op_{}'.format(number), None),
            ('_filter_value_{}'.format(number), None),
        ])
    return redirect_params


whitespace_re = re.compile(r'\s')


def is_url(value):
    ""Must start with http:// or https:// and contain JUST a URL""
    if not isinstance(value, str):
        return False
    if not value.startswith('http://') and not value.startswith('https://'):
        return False
    # Any whitespace at all is invalid
    if whitespace_re.search(value):
        return False
    return True


css_class_re = re.compile(r'^[a-zA-Z]+[_a-zA-Z0-9-]*$')
css_invalid_chars_re = re.compile(r'[^a-zA-Z0-9_\-]')


def to_css_class(s):
    """"""
    Given a string (e.g. a table name) returns a valid unique CSS class.
    For simple cases, just returns the string again. If the string is not a
    valid CSS class (we disallow - and _ prefixes even though they are valid
    as they may be confused with browser prefixes) we strip invalid characters
    and add a 6 char md5 sum suffix, to make sure two tables with identical
    names after stripping characters don't end up with the same CSS class.
    """"""
    if css_class_re.match(s):
        return s
    md5_suffix = hashlib.md5(s.encode('utf8')).hexdigest()[:6]
    # Strip leading _, -
    s = s.lstrip('_').lstrip('-')
    # Replace any whitespace with hyphens
    s = '-'.join(s.split())
    # Remove any remaining invalid characters
    s = css_invalid_chars_re.sub('', s)
    # Attach the md5 suffix
    bits = [b for b in (s, md5_suffix) if b]
    return '-'.join(bits)


def link_or_copy(src, dst):
    # Intended for use in populating a temp directory. We link if possible,
    # but fall back to copying if the temp directory is on a different device
    # https://github.com/simonw/datasette/issues/141
    try:
        os.link(src, dst)
    except OSError:
        shutil.copyfile(src, dst)


def link_or_copy_directory(src, dst):
    try:
        shutil.copytree(src, dst, copy_function=os.link)
    except OSError:
        shutil.copytree(src, dst)


def module_from_path(path, name):
    # Adapted from http://sayspy.blogspot.com/2011/07/how-to-import-module-from-just-file.html
    mod = imp.new_module(name)
    mod.__file__ = path
    with open(path, 'r') as file:
        code = compile(file.read(), path, 'exec', dont_inherit=True)
    exec(code, mod.__dict__)
    return mod


def get_plugins(pm):
    plugins = []
    plugin_to_distinfo = dict(pm.list_plugin_distinfo())
    for plugin in pm.get_plugins():
        static_path = None
        templates_path = None
        try:
            if pkg_resources.resource_isdir(plugin.__name__, 'static'):
                static_path = pkg_resources.resource_filename(plugin.__name__, 'static')
            if pkg_resources.resource_isdir(plugin.__name__, 'templates'):
                templates_path = pkg_resources.resource_filename(plugin.__name__, 'templates')
        except (KeyError, ImportError):
            # Caused by --plugins_dir= plugins - KeyError/ImportError thrown in Py3.5
            pass
        plugin_info = {
            'name': plugin.__name__,
            'static_path': static_path,
            'templates_path': templates_path,
        }
        distinfo = plugin_to_distinfo.get(plugin)
        if distinfo:
            plugin_info['version'] = distinfo.version
        plugins.append(plugin_info)
    return plugins


FORMATS = ('csv', 'json', 'jsono')


def resolve_table_and_format(table_and_format, table_exists):
    if '.' in table_and_format:
        # Check if a table exists with this exact name
        if table_exists(table_and_format):
            return table_and_format, None
    # Check if table ends with a known format
    for _format in FORMATS:
        if table_and_format.endswith("".{}"".format(_format)):
            table = table_and_format[:-(len(_format) + 1)]
            return table, _format
    return table_and_format, None


def path_with_format(request, format, extra_qs=None):
    qs = extra_qs or {}
    path = request.path
    if ""."" in request.path:
        qs[""_format""] = format
    else:
        path = ""{}.{}"".format(path, format)
    if qs:
        extra = urllib.parse.urlencode(sorted(qs.items()))
        if request.query_string:
            path = ""{}?{}&{}"".format(
                path, request.query_string, extra
            )
        else:
            path = ""{}?{}"".format(path, extra)
    elif request.query_string:
        path = ""{}?{}"".format(path, request.query_string)
    return path


class CustomRow(OrderedDict):
    # Loose imitation of sqlite3.Row which offers
    # both index-based AND key-based lookups
    def __init__(self, columns, values=None):
        self.columns = columns
        if values:
            self.update(values)

    def __getitem__(self, key):
        if isinstance(key, int):
            return super().__getitem__(self.columns[key])
        else:
            return super().__getitem__(key)

    def __iter__(self):
        for column in self.columns:
            yield self[column]


def value_as_boolean(value):
    if value.lower() not in ('on', 'off', 'true', 'false', '1', '0'):
        raise ValueAsBooleanError
    return value.lower() in ('on', 'true', '1')


class ValueAsBooleanError(ValueError):
    pass


class WriteLimitExceeded(Exception):
    pass


class LimitedWriter:
    def __init__(self, writer, limit_mb):
        self.writer = writer
        self.limit_bytes = limit_mb * 1024 * 1024
        self.bytes_count = 0

    def write(self, bytes):
        self.bytes_count += len(bytes)
        if self.limit_bytes and (self.bytes_count > self.limit_bytes):
            raise WriteLimitExceeded(""CSV contains more than {} bytes"".format(
                self.limit_bytes
            ))
        self.writer.write(bytes)


_infinities = {float(""inf""), float(""-inf"")}


def remove_infinites(row):
    if any((c in _infinities) if isinstance(c, float) else 0 for c in row):
        return [
            None if (isinstance(c, float) and c in _infinities) else c
            for c in row
        ]
    return row


class StaticMount(click.ParamType):
    name = ""static mount""

    def convert(self, value, param, ctx):
        if "":"" not in value:
            self.fail(
                '""{}"" should be of format mountpoint:directory'.format(value),
                param, ctx
            )
        path, dirpath = value.split("":"")
        if not os.path.exists(dirpath) or not os.path.isdir(dirpath):
            self.fail(""%s is not a valid directory path"" % value, param, ctx)
        return path, dirpath


def format_bytes(bytes):
    current = float(bytes)
    for unit in (""bytes"", ""KB"", ""MB"", ""GB"", ""TB""):
        if current < 1024:
            break
        current = current / 1024
    if unit == ""bytes"":
        return ""{} {}"".format(int(current), unit)
    else:
        return ""{:.1f} {}"".format(current, unit)
/n/n/ndatasette/views/base.py/n/nimport asyncio
import csv
import itertools
import json
import re
import time
import urllib

import jinja2
import pint
from sanic import response
from sanic.exceptions import NotFound
from sanic.views import HTTPMethodView

from datasette import __version__
from datasette.plugins import pm
from datasette.utils import (
    CustomJSONEncoder,
    InterruptedError,
    InvalidSql,
    LimitedWriter,
    format_bytes,
    is_url,
    path_from_row_pks,
    path_with_added_args,
    path_with_removed_args,
    path_with_format,
    remove_infinites,
    resolve_table_and_format,
    sqlite3,
    to_css_class,
    value_as_boolean,
)

ureg = pint.UnitRegistry()

HASH_LENGTH = 7


class DatasetteError(Exception):

    def __init__(self, message, title=None, error_dict=None, status=500, template=None, messagge_is_html=False):
        self.message = message
        self.title = title
        self.error_dict = error_dict or {}
        self.status = status
        self.messagge_is_html = messagge_is_html


class RenderMixin(HTTPMethodView):

    def _asset_urls(self, key, template, context):
        # Flatten list-of-lists from plugins:
        seen_urls = set()
        for url_or_dict in itertools.chain(
            itertools.chain.from_iterable(getattr(pm.hook, key)(
                template=template.name,
                database=context.get(""database""),
                table=context.get(""table""),
                datasette=self.ds
            )),
            (self.ds.metadata(key) or [])
        ):
            if isinstance(url_or_dict, dict):
                url = url_or_dict[""url""]
                sri = url_or_dict.get(""sri"")
            else:
                url = url_or_dict
                sri = None
            if url in seen_urls:
                continue
            seen_urls.add(url)
            if sri:
                yield {""url"": url, ""sri"": sri}
            else:
                yield {""url"": url}

    def database_url(self, database):
        if not self.ds.config(""hash_urls""):
            return ""/{}"".format(database)
        else:
            return ""/{}-{}"".format(
                database, self.ds.inspect()[database][""hash""][:HASH_LENGTH]
            )

    def database_color(self, database):
        return 'ff0000'

    def render(self, templates, **context):
        template = self.ds.jinja_env.select_template(templates)
        select_templates = [
            ""{}{}"".format(""*"" if template_name == template.name else """", template_name)
            for template_name in templates
        ]
        body_scripts = []
        for script in pm.hook.extra_body_script(
            template=template.name,
            database=context.get(""database""),
            table=context.get(""table""),
            datasette=self.ds
        ):
            body_scripts.append(jinja2.Markup(script))
        return response.html(
            template.render(
                {
                    **context,
                    **{
                        ""app_css_hash"": self.ds.app_css_hash(),
                        ""select_templates"": select_templates,
                        ""zip"": zip,
                        ""body_scripts"": body_scripts,
                        ""extra_css_urls"": self._asset_urls(
                            ""extra_css_urls"", template, context
                        ),
                        ""extra_js_urls"": self._asset_urls(
                            ""extra_js_urls"", template, context
                        ),
                        ""format_bytes"": format_bytes,
                        ""database_url"": self.database_url,
                        ""database_color"": self.database_color,
                    }
                }
            )
        )


class BaseView(RenderMixin):
    re_named_parameter = re.compile("":([a-zA-Z0-9_]+)"")

    def __init__(self, datasette):
        self.ds = datasette

    def table_metadata(self, database, table):
        ""Fetch table-specific metadata.""
        return (self.ds.metadata(""databases"") or {}).get(database, {}).get(
            ""tables"", {}
        ).get(
            table, {}
        )

    def options(self, request, *args, **kwargs):
        r = response.text(""ok"")
        if self.ds.cors:
            r.headers[""Access-Control-Allow-Origin""] = ""*""
        return r

    def redirect(self, request, path, forward_querystring=True, remove_args=None):
        if request.query_string and ""?"" not in path and forward_querystring:
            path = ""{}?{}"".format(path, request.query_string)
        if remove_args:
            path = path_with_removed_args(request, remove_args, path=path)
        r = response.redirect(path)
        r.headers[""Link""] = ""<{}>; rel=preload"".format(path)
        if self.ds.cors:
            r.headers[""Access-Control-Allow-Origin""] = ""*""
        return r

    def resolve_db_name(self, request, db_name, **kwargs):
        databases = self.ds.inspect()
        hash = None
        name = None
        if ""-"" in db_name:
            # Might be name-and-hash, or might just be
            # a name with a hyphen in it
            name, hash = db_name.rsplit(""-"", 1)
            if name not in databases:
                # Try the whole name
                name = db_name
                hash = None
        else:
            name = db_name
        # Verify the hash
        try:
            info = databases[name]
        except KeyError:
            raise NotFound(""Database not found: {}"".format(name))

        expected = info[""hash""][:HASH_LENGTH]
        correct_hash_provided = (expected == hash)

        if not correct_hash_provided:
            if ""table_and_format"" in kwargs:
                table, _format = resolve_table_and_format(
                    table_and_format=urllib.parse.unquote_plus(
                        kwargs[""table_and_format""]
                    ),
                    table_exists=lambda t: self.ds.table_exists(name, t)
                )
                kwargs[""table""] = table
                if _format:
                    kwargs[""as_format""] = "".{}"".format(_format)
            elif ""table"" in kwargs:
                kwargs[""table""] = urllib.parse.unquote_plus(
                    kwargs[""table""]
                )

            should_redirect = ""/{}-{}"".format(name, expected)
            if ""table"" in kwargs:
                should_redirect += ""/"" + urllib.parse.quote_plus(
                    kwargs[""table""]
                )
            if ""pk_path"" in kwargs:
                should_redirect += ""/"" + kwargs[""pk_path""]
            if ""as_format"" in kwargs:
                should_redirect += kwargs[""as_format""]
            if ""as_db"" in kwargs:
                should_redirect += kwargs[""as_db""]

            if self.ds.config(""hash_urls"") or ""_hash"" in request.args:
                return name, expected, correct_hash_provided, should_redirect

        return name, expected, correct_hash_provided, None

    def absolute_url(self, request, path):
        url = urllib.parse.urljoin(request.url, path)
        if url.startswith(""http://"") and self.ds.config(""force_https_urls""):
            url = ""https://"" + url[len(""http://""):]
        return url

    def get_templates(self, database, table=None):
        assert NotImplemented

    async def get(self, request, db_name, **kwargs):
        database, hash, correct_hash_provided, should_redirect = self.resolve_db_name(
            request, db_name, **kwargs
        )
        if should_redirect:
            return self.redirect(request, should_redirect, remove_args={""_hash""})

        return await self.view_get(request, database, hash, correct_hash_provided, **kwargs)

    async def as_csv(self, request, database, hash, **kwargs):
        stream = request.args.get(""_stream"")
        if stream:
            # Some quick sanity checks
            if not self.ds.config(""allow_csv_stream""):
                raise DatasetteError(""CSV streaming is disabled"", status=400)
            if request.args.get(""_next""):
                raise DatasetteError(
                    ""_next not allowed for CSV streaming"", status=400
                )
            kwargs[""_size""] = ""max""
        # Fetch the first page
        try:
            response_or_template_contexts = await self.data(
                request, database, hash, **kwargs
            )
            if isinstance(response_or_template_contexts, response.HTTPResponse):
                return response_or_template_contexts
            else:
                data, extra_template_data, templates = response_or_template_contexts
        except (sqlite3.OperationalError, InvalidSql) as e:
            raise DatasetteError(str(e), title=""Invalid SQL"", status=400)

        except (sqlite3.OperationalError) as e:
            raise DatasetteError(str(e))

        except DatasetteError:
            raise

        # Convert rows and columns to CSV
        headings = data[""columns""]
        # if there are expanded_columns we need to add additional headings
        expanded_columns = set(data.get(""expanded_columns"") or [])
        if expanded_columns:
            headings = []
            for column in data[""columns""]:
                headings.append(column)
                if column in expanded_columns:
                    headings.append(""{}_label"".format(column))

        async def stream_fn(r):
            nonlocal data
            writer = csv.writer(LimitedWriter(r, self.ds.config(""max_csv_mb"")))
            first = True
            next = None
            while first or (next and stream):
                try:
                    if next:
                        kwargs[""_next""] = next
                    if not first:
                        data, extra_template_data, templates = await self.data(
                            request, database, hash, **kwargs
                        )
                    if first:
                        writer.writerow(headings)
                        first = False
                    next = data.get(""next"")
                    for row in data[""rows""]:
                        if not expanded_columns:
                            # Simple path
                            writer.writerow(row)
                        else:
                            # Look for {""value"": ""label"": } dicts and expand
                            new_row = []
                            for cell in row:
                                if isinstance(cell, dict):
                                    new_row.append(cell[""value""])
                                    new_row.append(cell[""label""])
                                else:
                                    new_row.append(cell)
                            writer.writerow(new_row)
                except Exception as e:
                    print('caught this', e)
                    r.write(str(e))
                    return

        content_type = ""text/plain; charset=utf-8""
        headers = {}
        if self.ds.cors:
            headers[""Access-Control-Allow-Origin""] = ""*""
        if request.args.get(""_dl"", None):
            content_type = ""text/csv; charset=utf-8""
            disposition = 'attachment; filename=""{}.csv""'.format(
                kwargs.get('table', database)
            )
            headers[""Content-Disposition""] = disposition

        return response.stream(
            stream_fn,
            headers=headers,
            content_type=content_type
        )

    async def view_get(self, request, database, hash, correct_hash_provided, **kwargs):
        # If ?_format= is provided, use that as the format
        _format = request.args.get(""_format"", None)
        if not _format:
            _format = (kwargs.pop(""as_format"", None) or """").lstrip(""."")
        if ""table_and_format"" in kwargs:
            table, _ext_format = resolve_table_and_format(
                table_and_format=urllib.parse.unquote_plus(
                    kwargs[""table_and_format""]
                ),
                table_exists=lambda t: self.ds.table_exists(database, t)
            )
            _format = _format or _ext_format
            kwargs[""table""] = table
            del kwargs[""table_and_format""]
        elif ""table"" in kwargs:
            kwargs[""table""] = urllib.parse.unquote_plus(
                kwargs[""table""]
            )

        if _format == ""csv"":
            return await self.as_csv(request, database, hash, **kwargs)

        if _format is None:
            # HTML views default to expanding all forign key labels
            kwargs['default_labels'] = True

        extra_template_data = {}
        start = time.time()
        status_code = 200
        templates = []
        try:
            response_or_template_contexts = await self.data(
                request, database, hash, **kwargs
            )
            if isinstance(response_or_template_contexts, response.HTTPResponse):
                return response_or_template_contexts

            else:
                data, extra_template_data, templates = response_or_template_contexts
        except InterruptedError as e:
            raise DatasetteError(""""""
                SQL query took too long. The time limit is controlled by the
                <a href=""https://datasette.readthedocs.io/en/stable/config.html#sql-time-limit-ms"">sql_time_limit_ms</a>
                configuration option.
            """""", title=""SQL Interrupted"", status=400, messagge_is_html=True)
        except (sqlite3.OperationalError, InvalidSql) as e:
            raise DatasetteError(str(e), title=""Invalid SQL"", status=400)

        except (sqlite3.OperationalError) as e:
            raise DatasetteError(str(e))

        except DatasetteError:
            raise

        end = time.time()
        data[""query_ms""] = (end - start) * 1000
        for key in (""source"", ""source_url"", ""license"", ""license_url""):
            value = self.ds.metadata(key)
            if value:
                data[key] = value
        if _format in (""json"", ""jsono""):
            # Special case for .jsono extension - redirect to _shape=objects
            if _format == ""jsono"":
                return self.redirect(
                    request,
                    path_with_added_args(
                        request,
                        {""_shape"": ""objects""},
                        path=request.path.rsplit("".jsono"", 1)[0] + "".json"",
                    ),
                    forward_querystring=False,
                )

            # Handle the _json= parameter which may modify data[""rows""]
            json_cols = []
            if ""_json"" in request.args:
                json_cols = request.args[""_json""]
            if json_cols and ""rows"" in data and ""columns"" in data:
                data[""rows""] = convert_specific_columns_to_json(
                    data[""rows""], data[""columns""], json_cols,
                )

            # unless _json_infinity=1 requested, replace infinity with None
            if ""rows"" in data and not value_as_boolean(
                request.args.get(""_json_infinity"", ""0"")
            ):
                data[""rows""] = [remove_infinites(row) for row in data[""rows""]]

            # Deal with the _shape option
            shape = request.args.get(""_shape"", ""arrays"")
            if shape == ""arrayfirst"":
                data = [row[0] for row in data[""rows""]]
            elif shape in (""objects"", ""object"", ""array""):
                columns = data.get(""columns"")
                rows = data.get(""rows"")
                if rows and columns:
                    data[""rows""] = [dict(zip(columns, row)) for row in rows]
                if shape == ""object"":
                    error = None
                    if ""primary_keys"" not in data:
                        error = ""_shape=object is only available on tables""
                    else:
                        pks = data[""primary_keys""]
                        if not pks:
                            error = ""_shape=object not available for tables with no primary keys""
                        else:
                            object_rows = {}
                            for row in data[""rows""]:
                                pk_string = path_from_row_pks(row, pks, not pks)
                                object_rows[pk_string] = row
                            data = object_rows
                    if error:
                        data = {
                            ""ok"": False,
                            ""error"": error,
                            ""database"": database,
                        }
                elif shape == ""array"":
                    data = data[""rows""]
            elif shape == ""arrays"":
                pass
            else:
                status_code = 400
                data = {
                    ""ok"": False,
                    ""error"": ""Invalid _shape: {}"".format(shape),
                    ""status"": 400,
                    ""title"": None,
                }
            headers = {}
            if self.ds.cors:
                headers[""Access-Control-Allow-Origin""] = ""*""
            # Handle _nl option for _shape=array
            nl = request.args.get(""_nl"", """")
            if nl and shape == ""array"":
                body = ""\n"".join(json.dumps(item) for item in data)
                content_type = ""text/plain""
            else:
                body = json.dumps(data, cls=CustomJSONEncoder)
                content_type = ""application/json""
            r = response.HTTPResponse(
                body,
                status=status_code,
                content_type=content_type,
                headers=headers,
            )
        else:
            extras = {}
            if callable(extra_template_data):
                extras = extra_template_data()
                if asyncio.iscoroutine(extras):
                    extras = await extras
            else:
                extras = extra_template_data
            url_labels_extra = {}
            if data.get(""expandable_columns""):
                url_labels_extra = {""_labels"": ""on""}
            url_csv_args = {
                ""_size"": ""max"",
                **url_labels_extra
            }
            url_csv = path_with_format(request, ""csv"", url_csv_args)
            url_csv_path = url_csv.split('?')[0]
            context = {
                **data,
                **extras,
                **{
                    ""url_json"": path_with_format(request, ""json"", {
                        **url_labels_extra,
                    }),
                    ""url_csv"": url_csv,
                    ""url_csv_path"": url_csv_path,
                    ""url_csv_hidden_args"": [
                        (key, value)
                        for key, value in urllib.parse.parse_qsl(request.query_string)
                        if key not in (""_labels"", ""_facet"", ""_size"")
                    ] + [(""_size"", ""max"")],
                    ""datasette_version"": __version__,
                    ""config"": self.ds.config_dict(),
                }
            }
            if ""metadata"" not in context:
                context[""metadata""] = self.ds.metadata
            r = self.render(templates, **context)
            r.status = status_code
        # Set far-future cache expiry
        if self.ds.cache_headers and r.status == 200:
            ttl = request.args.get(""_ttl"", None)
            if ttl is None or not ttl.isdigit():
                if correct_hash_provided:
                    ttl = self.ds.config(""default_cache_ttl_hashed"")
                else:
                    ttl = self.ds.config(""default_cache_ttl"")
            else:
                ttl = int(ttl)
            if ttl == 0:
                ttl_header = 'no-cache'
            else:
                ttl_header = 'max-age={}'.format(ttl)
            r.headers[""Cache-Control""] = ttl_header
        r.headers[""Referrer-Policy""] = ""no-referrer""
        return r

    async def custom_sql(
        self, request, database, hash, sql, editable=True, canned_query=None,
        metadata=None, _size=None
    ):
        params = request.raw_args
        if ""sql"" in params:
            params.pop(""sql"")
        if ""_shape"" in params:
            params.pop(""_shape"")
        # Extract any :named parameters
        named_parameters = self.re_named_parameter.findall(sql)
        named_parameter_values = {
            named_parameter: params.get(named_parameter) or """"
            for named_parameter in named_parameters
        }

        # Set to blank string if missing from params
        for named_parameter in named_parameters:
            if named_parameter not in params:
                params[named_parameter] = """"

        extra_args = {}
        if params.get(""_timelimit""):
            extra_args[""custom_time_limit""] = int(params[""_timelimit""])
        if _size:
            extra_args[""page_size""] = _size
        results = await self.ds.execute(
            database, sql, params, truncate=True, **extra_args
        )
        columns = [r[0] for r in results.description]

        templates = [""query-{}.html"".format(to_css_class(database)), ""query.html""]
        if canned_query:
            templates.insert(
                0,
                ""query-{}-{}.html"".format(
                    to_css_class(database), to_css_class(canned_query)
                ),
            )

        async def extra_template():
            display_rows = []
            for row in results.rows:
                display_row = []
                for column, value in zip(results.columns, row):
                    display_value = value
                    # Let the plugins have a go
                    plugin_value = pm.hook.render_cell(
                        value=value,
                        column=column,
                        table=None,
                        database=database,
                        datasette=self.ds,
                    )
                    if plugin_value is not None:
                        display_value = plugin_value
                    else:
                        if value in ("""", None):
                            display_value = jinja2.Markup(""&nbsp;"")
                        elif is_url(str(display_value).strip()):
                            display_value = jinja2.Markup(
                                '<a href=""{url}"">{url}</a>'.format(
                                    url=jinja2.escape(value.strip())
                                )
                            )
                    display_row.append(display_value)
                display_rows.append(display_row)
            return {
                ""display_rows"": display_rows,
                ""custom_sql"": True,
                ""named_parameter_values"": named_parameter_values,
                ""editable"": editable,
                ""canned_query"": canned_query,
                ""metadata"": metadata,
                ""config"": self.ds.config_dict(),
                ""request"": request,
                ""path_with_added_args"": path_with_added_args,
                ""path_with_removed_args"": path_with_removed_args,
                ""hide_sql"": ""_hide_sql"" in params,
            }

        return {
            ""database"": database,
            ""rows"": results.rows,
            ""truncated"": results.truncated,
            ""columns"": columns,
            ""query"": {""sql"": sql, ""params"": params},
        }, extra_template, templates


def convert_specific_columns_to_json(rows, columns, json_cols):
    json_cols = set(json_cols)
    if not json_cols.intersection(columns):
        return rows
    new_rows = []
    for row in rows:
        new_row = []
        for value, column in zip(row, columns):
            if column in json_cols:
                try:
                    value = json.loads(value)
                except (TypeError, ValueError) as e:
                    print(e)
                    pass
            new_row.append(value)
        new_rows.append(new_row)
    return new_rows
/n/n/ndatasette/views/database.py/n/nimport os

from sanic import response

from datasette.utils import to_css_class, validate_sql_select

from .base import BaseView, DatasetteError


class DatabaseView(BaseView):

    async def data(self, request, database, hash, default_labels=False, _size=None):
        if request.args.get(""sql""):
            if not self.ds.config(""allow_sql""):
                raise DatasetteError(""sql= is not allowed"", status=400)
            sql = request.raw_args.pop(""sql"")
            validate_sql_select(sql)
            return await self.custom_sql(request, database, hash, sql, _size=_size)

        info = self.ds.inspect()[database]
        metadata = (self.ds.metadata(""databases"") or {}).get(database, {})
        self.ds.update_with_inherited_metadata(metadata)
        tables = list(info[""tables""].values())
        tables.sort(key=lambda t: (t[""hidden""], t[""name""]))
        return {
            ""database"": database,
            ""size"": info[""size""],
            ""tables"": tables,
            ""hidden_count"": len([t for t in tables if t[""hidden""]]),
            ""views"": info[""views""],
            ""queries"": self.ds.get_canned_queries(database),
        }, {
            ""show_hidden"": request.args.get(""_show_hidden""),
            ""editable"": True,
            ""metadata"": metadata,
        }, (
            ""database-{}.html"".format(to_css_class(database)), ""database.html""
        )


class DatabaseDownload(BaseView):

    async def view_get(self, request, database, hash, correct_hash_present, **kwargs):
        if not self.ds.config(""allow_download""):
            raise DatasetteError(""Database download is forbidden"", status=403)
        filepath = self.ds.inspect()[database][""file""]
        return await response.file_stream(
            filepath,
            filename=os.path.basename(filepath),
            mime_type=""application/octet-stream"",
        )
/n/n/ndatasette/views/index.py/n/nimport json

from sanic import response

from datasette.utils import CustomJSONEncoder
from datasette.version import __version__

from .base import HASH_LENGTH, RenderMixin


class IndexView(RenderMixin):

    def __init__(self, datasette):
        self.ds = datasette

    async def get(self, request, as_format):
        databases = []
        for key, info in sorted(self.ds.inspect().items()):
            tables = [t for t in info[""tables""].values() if not t[""hidden""]]
            hidden_tables = [t for t in info[""tables""].values() if t[""hidden""]]
            database = {
                ""name"": key,
                ""hash"": info[""hash""],
                ""path"": self.database_url(key),
                ""tables_truncated"": sorted(
                    tables, key=lambda t: t[""count""], reverse=True
                )[
                    :5
                ],
                ""tables_count"": len(tables),
                ""tables_more"": len(tables) > 5,
                ""table_rows_sum"": sum(t[""count""] for t in tables),
                ""hidden_table_rows_sum"": sum(t[""count""] for t in hidden_tables),
                ""hidden_tables_count"": len(hidden_tables),
                ""views_count"": len(info[""views""]),
            }
            databases.append(database)
        if as_format:
            headers = {}
            if self.ds.cors:
                headers[""Access-Control-Allow-Origin""] = ""*""
            return response.HTTPResponse(
                json.dumps({db[""name""]: db for db in databases}, cls=CustomJSONEncoder),
                content_type=""application/json"",
                headers=headers,
            )

        else:
            return self.render(
                [""index.html""],
                databases=databases,
                metadata=self.ds.metadata(),
                datasette_version=__version__,
            )
/n/n/ndatasette/views/table.py/n/nimport urllib

import jinja2
from sanic.exceptions import NotFound
from sanic.request import RequestParameters

from datasette.plugins import pm
from datasette.utils import (
    CustomRow,
    Filters,
    InterruptedError,
    append_querystring,
    compound_keys_after_sql,
    escape_sqlite,
    filters_should_redirect,
    is_url,
    path_from_row_pks,
    path_with_added_args,
    path_with_removed_args,
    path_with_replaced_args,
    sqlite3,
    to_css_class,
    urlsafe_components,
    value_as_boolean,
)
from .base import BaseView, DatasetteError, ureg

LINK_WITH_LABEL = '<a href=""/{database}/{table}/{link_id}"">{label}</a>&nbsp;<em>{id}</em>'
LINK_WITH_VALUE = '<a href=""/{database}/{table}/{link_id}"">{id}</a>'


class RowTableShared(BaseView):

    def sortable_columns_for_table(self, database, table, use_rowid):
        table_metadata = self.table_metadata(database, table)
        if ""sortable_columns"" in table_metadata:
            sortable_columns = set(table_metadata[""sortable_columns""])
        else:
            table_info = self.ds.inspect()[database][""tables""].get(table) or {}
            sortable_columns = set(table_info.get(""columns"", []))
        if use_rowid:
            sortable_columns.add(""rowid"")
        return sortable_columns

    def expandable_columns(self, database, table):
        # Returns list of (fk_dict, label_column-or-None) pairs for that table
        tables = self.ds.inspect()[database].get(""tables"", {})
        table_info = tables.get(table)
        if not table_info:
            return []
        expandables = []
        for fk in table_info[""foreign_keys""][""outgoing""]:
            label_column = (
                self.table_metadata(
                    database, fk[""other_table""]
                ).get(""label_column"")
                or tables.get(fk[""other_table""], {}).get(""label_column"")
            ) or None
            expandables.append((fk, label_column))
        return expandables

    async def expand_foreign_keys(self, database, table, column, values):
        ""Returns dict mapping (column, value) -> label""
        labeled_fks = {}
        tables_info = self.ds.inspect()[database][""tables""]
        table_info = tables_info.get(table) or {}
        if not table_info:
            return {}
        foreign_keys = table_info[""foreign_keys""][""outgoing""]
        # Find the foreign_key for this column
        try:
            fk = [
                foreign_key for foreign_key in foreign_keys
                if foreign_key[""column""] == column
            ][0]
        except IndexError:
            return {}
        label_column = (
            # First look in metadata.json for this foreign key table:
            self.table_metadata(
                database, fk[""other_table""]
            ).get(""label_column"")
            or tables_info.get(fk[""other_table""], {}).get(""label_column"")
        )
        if not label_column:
            return {
                (fk[""column""], value): str(value)
                for value in values
            }
        labeled_fks = {}
        sql = '''
            select {other_column}, {label_column}
            from {other_table}
            where {other_column} in ({placeholders})
        '''.format(
            other_column=escape_sqlite(fk[""other_column""]),
            label_column=escape_sqlite(label_column),
            other_table=escape_sqlite(fk[""other_table""]),
            placeholders="", "".join([""?""] * len(set(values))),
        )
        try:
            results = await self.ds.execute(
                database, sql, list(set(values))
            )
        except InterruptedError:
            pass
        else:
            for id, value in results:
                labeled_fks[(fk[""column""], id)] = value
        return labeled_fks

    async def display_columns_and_rows(
        self,
        database,
        table,
        description,
        rows,
        link_column=False,
        truncate_cells=0,
    ):
        ""Returns columns, rows for specified table - including fancy foreign key treatment""
        table_metadata = self.table_metadata(database, table)
        info = self.ds.inspect()[database]
        sortable_columns = self.sortable_columns_for_table(database, table, True)
        columns = [
            {""name"": r[0], ""sortable"": r[0] in sortable_columns} for r in description
        ]
        tables = info[""tables""]
        table_info = tables.get(table) or {}
        pks = table_info.get(""primary_keys"") or []
        column_to_foreign_key_table = {
            fk[""column""]: fk[""other_table""]
            for fk in table_info.get(
                ""foreign_keys"", {}
            ).get(""outgoing"", None) or []
        }

        cell_rows = []
        for row in rows:
            cells = []
            # Unless we are a view, the first column is a link - either to the rowid
            # or to the simple or compound primary key
            if link_column:
                cells.append(
                    {
                        ""column"": pks[0] if len(pks) == 1 else ""Link"",
                        ""value"": jinja2.Markup(
                            '<a href=""/{database}/{table}/{flat_pks_quoted}"">{flat_pks}</a>'.format(
                                database=database,
                                table=urllib.parse.quote_plus(table),
                                flat_pks=str(
                                    jinja2.escape(
                                        path_from_row_pks(row, pks, not pks, False)
                                    )
                                ),
                                flat_pks_quoted=path_from_row_pks(row, pks, not pks),
                            )
                        ),
                    }
                )

            for value, column_dict in zip(row, columns):
                column = column_dict[""name""]
                if link_column and len(pks) == 1 and column == pks[0]:
                    # If there's a simple primary key, don't repeat the value as it's
                    # already shown in the link column.
                    continue

                # First let the plugins have a go
                plugin_display_value = pm.hook.render_cell(
                    value=value,
                    column=column,
                    table=table,
                    database=database,
                    datasette=self.ds,
                )
                if plugin_display_value is not None:
                    display_value = plugin_display_value
                elif isinstance(value, dict):
                    # It's an expanded foreign key - display link to other row
                    label = value[""label""]
                    value = value[""value""]
                    # The table we link to depends on the column
                    other_table = column_to_foreign_key_table[column]
                    link_template = (
                        LINK_WITH_LABEL if (label != value) else LINK_WITH_VALUE
                    )
                    display_value = jinja2.Markup(link_template.format(
                        database=database,
                        table=urllib.parse.quote_plus(other_table),
                        link_id=urllib.parse.quote_plus(str(value)),
                        id=str(jinja2.escape(value)),
                        label=str(jinja2.escape(label)),
                    ))
                elif value in ("""", None):
                    display_value = jinja2.Markup(""&nbsp;"")
                elif is_url(str(value).strip()):
                    display_value = jinja2.Markup(
                        '<a href=""{url}"">{url}</a>'.format(
                            url=jinja2.escape(value.strip())
                        )
                    )
                elif column in table_metadata.get(""units"", {}) and value != """":
                    # Interpret units using pint
                    value = value * ureg(table_metadata[""units""][column])
                    # Pint uses floating point which sometimes introduces errors in the compact
                    # representation, which we have to round off to avoid ugliness. In the vast
                    # majority of cases this rounding will be inconsequential. I hope.
                    value = round(value.to_compact(), 6)
                    display_value = jinja2.Markup(
                        ""{:~P}"".format(value).replace("" "", ""&nbsp;"")
                    )
                else:
                    display_value = str(value)
                    if truncate_cells and len(display_value) > truncate_cells:
                        display_value = display_value[:truncate_cells] + u""\u2026""

                cells.append({""column"": column, ""value"": display_value})
            cell_rows.append(cells)

        if link_column:
            # Add the link column header.
            # If it's a simple primary key, we have to remove and re-add that column name at
            # the beginning of the header row.
            if len(pks) == 1:
                columns = [col for col in columns if col[""name""] != pks[0]]

            columns = [
                {""name"": pks[0] if len(pks) == 1 else ""Link"", ""sortable"": len(pks) == 1}
            ] + columns
        return columns, cell_rows


class TableView(RowTableShared):

    async def data(self, request, database, hash, table, default_labels=False,  _next=None, _size=None):
        canned_query = self.ds.get_canned_query(database, table)
        if canned_query is not None:
            return await self.custom_sql(
                request,
                database,
                hash,
                canned_query[""sql""],
                metadata=canned_query,
                editable=False,
                canned_query=table,
            )

        is_view = bool(await self.ds.get_view_definition(database, table))
        info = self.ds.inspect()
        table_info = info[database][""tables""].get(table) or {}
        if not is_view and not table_info:
            raise NotFound(""Table not found: {}"".format(table))

        pks = table_info.get(""primary_keys"") or []
        use_rowid = not pks and not is_view
        if use_rowid:
            select = ""rowid, *""
            order_by = ""rowid""
            order_by_pks = ""rowid""
        else:
            select = ""*""
            order_by_pks = "", "".join([escape_sqlite(pk) for pk in pks])
            order_by = order_by_pks

        if is_view:
            order_by = """"

        # We roll our own query_string decoder because by default Sanic
        # drops anything with an empty value e.g. ?name__exact=
        args = RequestParameters(
            urllib.parse.parse_qs(request.query_string, keep_blank_values=True)
        )

        # Special args start with _ and do not contain a __
        # That's so if there is a column that starts with _
        # it can still be queried using ?_col__exact=blah
        special_args = {}
        special_args_lists = {}
        other_args = {}
        for key, value in args.items():
            if key.startswith(""_"") and ""__"" not in key:
                special_args[key] = value[0]
                special_args_lists[key] = value
            else:
                other_args[key] = value[0]

        # Handle ?_filter_column and redirect, if present
        redirect_params = filters_should_redirect(special_args)
        if redirect_params:
            return self.redirect(
                request,
                path_with_added_args(request, redirect_params),
                forward_querystring=False,
            )

        # Spot ?_sort_by_desc and redirect to _sort_desc=(_sort)
        if ""_sort_by_desc"" in special_args:
            return self.redirect(
                request,
                path_with_added_args(
                    request,
                    {
                        ""_sort_desc"": special_args.get(""_sort""),
                        ""_sort_by_desc"": None,
                        ""_sort"": None,
                    },
                ),
                forward_querystring=False,
            )

        table_metadata = self.table_metadata(database, table)
        units = table_metadata.get(""units"", {})
        filters = Filters(sorted(other_args.items()), units, ureg)
        where_clauses, params = filters.build_where_clauses()

        # _search support:
        fts_table = table_metadata.get(
            ""fts_table"", info[database][""tables""].get(table, {}).get(""fts_table"")
        )
        fts_pk = table_metadata.get(""fts_pk"", ""rowid"")
        search_args = dict(
            pair for pair in special_args.items() if pair[0].startswith(""_search"")
        )
        search_descriptions = []
        search = """"
        if fts_table and search_args:
            if ""_search"" in search_args:
                # Simple ?_search=xxx
                search = search_args[""_search""]
                where_clauses.append(
                    ""{fts_pk} in (select rowid from {fts_table} where {fts_table} match :search)"".format(
                        fts_table=escape_sqlite(fts_table),
                        fts_pk=escape_sqlite(fts_pk)
                    )
                )
                search_descriptions.append('search matches ""{}""'.format(search))
                params[""search""] = search
            else:
                # More complex: search against specific columns
                valid_columns = set(info[database][""tables""][fts_table][""columns""])
                for i, (key, search_text) in enumerate(search_args.items()):
                    search_col = key.split(""_search_"", 1)[1]
                    if search_col not in valid_columns:
                        raise DatasetteError(""Cannot search by that column"", status=400)

                    where_clauses.append(
                        ""rowid in (select rowid from {fts_table} where {search_col} match :search_{i})"".format(
                            fts_table=escape_sqlite(fts_table),
                            search_col=escape_sqlite(search_col),
                            i=i
                        )
                    )
                    search_descriptions.append(
                        'search column ""{}"" matches ""{}""'.format(
                            search_col, search_text
                        )
                    )
                    params[""search_{}"".format(i)] = search_text

        table_rows_count = None
        sortable_columns = set()
        if not is_view:
            table_rows_count = table_info[""count""]

        sortable_columns = self.sortable_columns_for_table(database, table, use_rowid)

        # Allow for custom sort order
        sort = special_args.get(""_sort"")
        if sort:
            if sort not in sortable_columns:
                raise DatasetteError(""Cannot sort table by {}"".format(sort))

            order_by = escape_sqlite(sort)
        sort_desc = special_args.get(""_sort_desc"")
        if sort_desc:
            if sort_desc not in sortable_columns:
                raise DatasetteError(""Cannot sort table by {}"".format(sort_desc))

            if sort:
                raise DatasetteError(""Cannot use _sort and _sort_desc at the same time"")

            order_by = ""{} desc"".format(escape_sqlite(sort_desc))

        from_sql = ""from {table_name} {where}"".format(
            table_name=escape_sqlite(table),
            where=(
                ""where {} "".format("" and "".join(where_clauses))
            ) if where_clauses else """",
        )
        # Store current params and where_clauses for later:
        from_sql_params = dict(**params)
        from_sql_where_clauses = where_clauses[:]

        count_sql = ""select count(*) {}"".format(from_sql)

        _next = _next or special_args.get(""_next"")
        offset = """"
        if _next:
            if is_view:
                # _next is an offset
                offset = "" offset {}"".format(int(_next))
            else:
                components = urlsafe_components(_next)
                # If a sort order is applied, the first of these is the sort value
                if sort or sort_desc:
                    sort_value = components[0]
                    # Special case for if non-urlencoded first token was $null
                    if _next.split("","")[0] == ""$null"":
                        sort_value = None
                    components = components[1:]

                # Figure out the SQL for next-based-on-primary-key first
                next_by_pk_clauses = []
                if use_rowid:
                    next_by_pk_clauses.append(""rowid > :p{}"".format(len(params)))
                    params[""p{}"".format(len(params))] = components[0]
                else:
                    # Apply the tie-breaker based on primary keys
                    if len(components) == len(pks):
                        param_len = len(params)
                        next_by_pk_clauses.append(
                            compound_keys_after_sql(pks, param_len)
                        )
                        for i, pk_value in enumerate(components):
                            params[""p{}"".format(param_len + i)] = pk_value

                # Now add the sort SQL, which may incorporate next_by_pk_clauses
                if sort or sort_desc:
                    if sort_value is None:
                        if sort_desc:
                            # Just items where column is null ordered by pk
                            where_clauses.append(
                                ""({column} is null and {next_clauses})"".format(
                                    column=escape_sqlite(sort_desc),
                                    next_clauses="" and "".join(next_by_pk_clauses),
                                )
                            )
                        else:
                            where_clauses.append(
                                ""({column} is not null or ({column} is null and {next_clauses}))"".format(
                                    column=escape_sqlite(sort),
                                    next_clauses="" and "".join(next_by_pk_clauses),
                                )
                            )
                    else:
                        where_clauses.append(
                            ""({column} {op} :p{p}{extra_desc_only} or ({column} = :p{p} and {next_clauses}))"".format(
                                column=escape_sqlite(sort or sort_desc),
                                op="">"" if sort else ""<"",
                                p=len(params),
                                extra_desc_only="""" if sort else "" or {column2} is null"".format(
                                    column2=escape_sqlite(sort or sort_desc)
                                ),
                                next_clauses="" and "".join(next_by_pk_clauses),
                            )
                        )
                        params[""p{}"".format(len(params))] = sort_value
                    order_by = ""{}, {}"".format(order_by, order_by_pks)
                else:
                    where_clauses.extend(next_by_pk_clauses)

        where_clause = """"
        if where_clauses:
            where_clause = ""where {} "".format("" and "".join(where_clauses))

        if order_by:
            order_by = ""order by {} "".format(order_by)

        # _group_count=col1&_group_count=col2
        group_count = special_args_lists.get(""_group_count"") or []
        if group_count:
            sql = 'select {group_cols}, count(*) as ""count"" from {table_name} {where} group by {group_cols} order by ""count"" desc limit 100'.format(
                group_cols="", "".join(
                    '""{}""'.format(group_count_col) for group_count_col in group_count
                ),
                table_name=escape_sqlite(table),
                where=where_clause,
            )
            return await self.custom_sql(request, database, hash, sql, editable=True)

        extra_args = {}
        # Handle ?_size=500
        page_size = _size or request.raw_args.get(""_size"")
        if page_size:
            if page_size == ""max"":
                page_size = self.ds.max_returned_rows
            try:
                page_size = int(page_size)
                if page_size < 0:
                    raise ValueError

            except ValueError:
                raise DatasetteError(""_size must be a positive integer"", status=400)

            if page_size > self.ds.max_returned_rows:
                raise DatasetteError(
                    ""_size must be <= {}"".format(self.ds.max_returned_rows), status=400
                )

            extra_args[""page_size""] = page_size
        else:
            page_size = self.ds.page_size

        sql = ""select {select} from {table_name} {where}{order_by}limit {limit}{offset}"".format(
            select=select,
            table_name=escape_sqlite(table),
            where=where_clause,
            order_by=order_by,
            limit=page_size + 1,
            offset=offset,
        )

        if request.raw_args.get(""_timelimit""):
            extra_args[""custom_time_limit""] = int(request.raw_args[""_timelimit""])

        results = await self.ds.execute(
            database, sql, params, truncate=True, **extra_args
        )

        # facets support
        facet_size = self.ds.config(""default_facet_size"")
        metadata_facets = table_metadata.get(""facets"", [])
        facets = metadata_facets[:]
        if request.args.get(""_facet"") and not self.ds.config(""allow_facet""):
            raise DatasetteError(""_facet= is not allowed"", status=400)
        try:
            facets.extend(request.args[""_facet""])
        except KeyError:
            pass
        facet_results = {}
        facets_timed_out = []
        for column in facets:
            if _next:
                continue
            facet_sql = """"""
                select {col} as value, count(*) as count
                {from_sql} {and_or_where} {col} is not null
                group by {col} order by count desc limit {limit}
            """""".format(
                col=escape_sqlite(column),
                from_sql=from_sql,
                and_or_where='and' if from_sql_where_clauses else 'where',
                limit=facet_size+1,
            )
            try:
                facet_rows_results = await self.ds.execute(
                    database, facet_sql, params,
                    truncate=False,
                    custom_time_limit=self.ds.config(""facet_time_limit_ms""),
                )
                facet_results_values = []
                facet_results[column] = {
                    ""name"": column,
                    ""results"": facet_results_values,
                    ""truncated"": len(facet_rows_results) > facet_size,
                }
                facet_rows = facet_rows_results.rows[:facet_size]
                # Attempt to expand foreign keys into labels
                values = [row[""value""] for row in facet_rows]
                expanded = (await self.expand_foreign_keys(
                    database, table, column, values
                ))
                for row in facet_rows:
                    selected = str(other_args.get(column)) == str(row[""value""])
                    if selected:
                        toggle_path = path_with_removed_args(
                            request, {column: str(row[""value""])}
                        )
                    else:
                        toggle_path = path_with_added_args(
                            request, {column: row[""value""]}
                        )
                    facet_results_values.append({
                        ""value"": row[""value""],
                        ""label"": expanded.get(
                            (column, row[""value""]),
                            row[""value""]
                        ),
                        ""count"": row[""count""],
                        ""toggle_url"": self.absolute_url(request, toggle_path),
                        ""selected"": selected,
                    })
            except InterruptedError:
                facets_timed_out.append(column)

        columns = [r[0] for r in results.description]
        rows = list(results.rows)

        filter_columns = columns[:]
        if use_rowid and filter_columns[0] == ""rowid"":
            filter_columns = filter_columns[1:]

        # Expand labeled columns if requested
        expanded_columns = []
        expandable_columns = self.expandable_columns(database, table)
        columns_to_expand = None
        try:
            all_labels = value_as_boolean(special_args.get(""_labels"", """"))
        except ValueError:
            all_labels = default_labels
        # Check for explicit _label=
        if ""_label"" in request.args:
            columns_to_expand = request.args[""_label""]
        if columns_to_expand is None and all_labels:
            # expand all columns with foreign keys
            columns_to_expand = [
                fk[""column""] for fk, _ in expandable_columns
            ]

        if columns_to_expand:
            expanded_labels = {}
            for fk, label_column in expandable_columns:
                column = fk[""column""]
                if column not in columns_to_expand:
                    continue
                expanded_columns.append(column)
                # Gather the values
                column_index = columns.index(column)
                values = [row[column_index] for row in rows]
                # Expand them
                expanded_labels.update(await self.expand_foreign_keys(
                    database, table, column, values
                ))
            if expanded_labels:
                # Rewrite the rows
                new_rows = []
                for row in rows:
                    new_row = CustomRow(columns)
                    for column in row.keys():
                        value = row[column]
                        if (column, value) in expanded_labels:
                            new_row[column] = {
                                'value': value,
                                'label': expanded_labels[(column, value)]
                            }
                        else:
                            new_row[column] = value
                    new_rows.append(new_row)
                rows = new_rows

        # Pagination next link
        next_value = None
        next_url = None
        if len(rows) > page_size and page_size > 0:
            if is_view:
                next_value = int(_next or 0) + page_size
            else:
                next_value = path_from_row_pks(rows[-2], pks, use_rowid)
            # If there's a sort or sort_desc, add that value as a prefix
            if (sort or sort_desc) and not is_view:
                prefix = rows[-2][sort or sort_desc]
                if prefix is None:
                    prefix = ""$null""
                else:
                    prefix = urllib.parse.quote_plus(str(prefix))
                next_value = ""{},{}"".format(prefix, next_value)
                added_args = {""_next"": next_value}
                if sort:
                    added_args[""_sort""] = sort
                else:
                    added_args[""_sort_desc""] = sort_desc
            else:
                added_args = {""_next"": next_value}
            next_url = self.absolute_url(
                request, path_with_replaced_args(request, added_args)
            )
            rows = rows[:page_size]

        # Number of filtered rows in whole set:
        filtered_table_rows_count = None
        if count_sql:
            try:
                count_rows = list(await self.ds.execute(
                    database, count_sql, from_sql_params
                ))
                filtered_table_rows_count = count_rows[0][0]
            except InterruptedError:
                pass

            # Detect suggested facets
            suggested_facets = []
            if self.ds.config(""suggest_facets"") and self.ds.config(""allow_facet""):
                for facet_column in columns:
                    if facet_column in facets:
                        continue
                    if _next:
                        continue
                    if not self.ds.config(""suggest_facets""):
                        continue
                    suggested_facet_sql = '''
                        select distinct {column} {from_sql}
                        {and_or_where} {column} is not null
                        limit {limit}
                    '''.format(
                        column=escape_sqlite(facet_column),
                        from_sql=from_sql,
                        and_or_where='and' if from_sql_where_clauses else 'where',
                        limit=facet_size+1
                    )
                    distinct_values = None
                    try:
                        distinct_values = await self.ds.execute(
                            database, suggested_facet_sql, from_sql_params,
                            truncate=False,
                            custom_time_limit=self.ds.config(""facet_suggest_time_limit_ms""),
                        )
                        num_distinct_values = len(distinct_values)
                        if (
                            num_distinct_values and
                            num_distinct_values > 1 and
                            num_distinct_values <= facet_size and
                            num_distinct_values < filtered_table_rows_count
                        ):
                            suggested_facets.append({
                                'name': facet_column,
                                'toggle_url': self.absolute_url(
                                    request, path_with_added_args(
                                        request, {""_facet"": facet_column}
                                    )
                                ),
                            })
                    except InterruptedError:
                        pass

        # human_description_en combines filters AND search, if provided
        human_description_en = filters.human_description_en(extra=search_descriptions)

        if sort or sort_desc:
            sorted_by = ""sorted by {}{}"".format(
                (sort or sort_desc), "" descending"" if sort_desc else """"
            )
            human_description_en = "" "".join(
                [b for b in [human_description_en, sorted_by] if b]
            )

        async def extra_template():
            display_columns, display_rows = await self.display_columns_and_rows(
                database,
                table,
                results.description,
                rows,
                link_column=not is_view,
                truncate_cells=self.ds.config(""truncate_cells_html""),
            )
            metadata = (self.ds.metadata(""databases"") or {}).get(database, {}).get(
                ""tables"", {}
            ).get(
                table, {}
            )
            self.ds.update_with_inherited_metadata(metadata)
            return {
                ""supports_search"": bool(fts_table),
                ""search"": search or """",
                ""use_rowid"": use_rowid,
                ""filters"": filters,
                ""display_columns"": display_columns,
                ""filter_columns"": filter_columns,
                ""display_rows"": display_rows,
                ""facets_timed_out"": facets_timed_out,
                ""sorted_facet_results"": sorted(
                    facet_results.values(),
                    key=lambda f: (len(f[""results""]), f[""name""]),
                    reverse=True
                ),
                ""facet_hideable"": lambda facet: facet not in metadata_facets,
                ""is_sortable"": any(c[""sortable""] for c in display_columns),
                ""path_with_replaced_args"": path_with_replaced_args,
                ""path_with_removed_args"": path_with_removed_args,
                ""append_querystring"": append_querystring,
                ""request"": request,
                ""sort"": sort,
                ""sort_desc"": sort_desc,
                ""disable_sort"": is_view,
                ""custom_rows_and_columns_templates"": [
                    ""_rows_and_columns-{}-{}.html"".format(
                        to_css_class(database), to_css_class(table)
                    ),
                    ""_rows_and_columns-table-{}-{}.html"".format(
                        to_css_class(database), to_css_class(table)
                    ),
                    ""_rows_and_columns.html"",
                ],
                ""metadata"": metadata,
                ""view_definition"": await self.ds.get_view_definition(database, table),
                ""table_definition"": await self.ds.get_table_definition(database, table),
            }

        return {
            ""database"": database,
            ""table"": table,
            ""is_view"": is_view,
            ""human_description_en"": human_description_en,
            ""rows"": rows[:page_size],
            ""truncated"": results.truncated,
            ""table_rows_count"": table_rows_count,
            ""filtered_table_rows_count"": filtered_table_rows_count,
            ""expanded_columns"": expanded_columns,
            ""expandable_columns"": expandable_columns,
            ""columns"": columns,
            ""primary_keys"": pks,
            ""units"": units,
            ""query"": {""sql"": sql, ""params"": params},
            ""facet_results"": facet_results,
            ""suggested_facets"": suggested_facets,
            ""next"": next_value and str(next_value) or None,
            ""next_url"": next_url,
        }, extra_template, (
            ""table-{}-{}.html"".format(to_css_class(database), to_css_class(table)),
            ""table.html"",
        )


class RowView(RowTableShared):

    async def data(self, request, database, hash, table, pk_path, default_labels=False):
        pk_values = urlsafe_components(pk_path)
        info = self.ds.inspect()[database]
        table_info = info[""tables""].get(table) or {}
        pks = table_info.get(""primary_keys"") or []
        use_rowid = not pks
        select = ""*""
        if use_rowid:
            select = ""rowid, *""
            pks = [""rowid""]
        wheres = ['""{}""=:p{}'.format(pk, i) for i, pk in enumerate(pks)]
        sql = 'select {} from {} where {}'.format(
            select, escape_sqlite(table), "" AND "".join(wheres)
        )
        params = {}
        for i, pk_value in enumerate(pk_values):
            params[""p{}"".format(i)] = pk_value
        results = await self.ds.execute(
            database, sql, params, truncate=True
        )
        columns = [r[0] for r in results.description]
        rows = list(results.rows)
        if not rows:
            raise NotFound(""Record not found: {}"".format(pk_values))

        async def template_data():
            display_columns, display_rows = await self.display_columns_and_rows(
                database,
                table,
                results.description,
                rows,
                link_column=False,
                truncate_cells=0,
            )
            for column in display_columns:
                column[""sortable""] = False
            return {
                ""foreign_key_tables"": await self.foreign_key_tables(
                    database, table, pk_values
                ),
                ""display_columns"": display_columns,
                ""display_rows"": display_rows,
                ""custom_rows_and_columns_templates"": [
                    ""_rows_and_columns-{}-{}.html"".format(
                        to_css_class(database), to_css_class(table)
                    ),
                    ""_rows_and_columns-row-{}-{}.html"".format(
                        to_css_class(database), to_css_class(table)
                    ),
                    ""_rows_and_columns.html"",
                ],
                ""metadata"": (
                    self.ds.metadata(""databases"") or {}
                ).get(database, {}).get(
                    ""tables"", {}
                ).get(
                    table, {}
                ),
            }

        data = {
            ""database"": database,
            ""table"": table,
            ""rows"": rows,
            ""columns"": columns,
            ""primary_keys"": pks,
            ""primary_key_values"": pk_values,
            ""units"": self.table_metadata(database, table).get(""units"", {}),
        }

        if ""foreign_key_tables"" in (request.raw_args.get(""_extras"") or """").split("",""):
            data[""foreign_key_tables""] = await self.foreign_key_tables(
                database, table, pk_values
            )

        return data, template_data, (
            ""row-{}-{}.html"".format(to_css_class(database), to_css_class(table)), ""row.html""
        )

    async def foreign_key_tables(self, database, table, pk_values):
        if len(pk_values) != 1:
            return []

        table_info = self.ds.inspect()[database][""tables""].get(table)
        if not table_info:
            return []

        foreign_keys = table_info[""foreign_keys""][""incoming""]
        if len(foreign_keys) == 0:
            return []

        sql = ""select "" + "", "".join(
            [
                '(select count(*) from {table} where {column}=:id)'.format(
                    table=escape_sqlite(fk[""other_table""]),
                    column=escape_sqlite(fk[""other_column""]),
                )
                for fk in foreign_keys
            ]
        )
        try:
            rows = list(await self.ds.execute(database, sql, {""id"": pk_values[0]}))
        except sqlite3.OperationalError:
            # Almost certainly hit the timeout
            return []

        foreign_table_counts = dict(
            zip(
                [(fk[""other_table""], fk[""other_column""]) for fk in foreign_keys],
                list(rows[0]),
            )
        )
        foreign_key_tables = []
        for fk in foreign_keys:
            count = foreign_table_counts.get(
                (fk[""other_table""], fk[""other_column""])
            ) or 0
            foreign_key_tables.append({**fk, **{""count"": count}})
        return foreign_key_tables
/n/n/ntests/fixtures.py/n/nfrom datasette.app import Datasette
from datasette.utils import sqlite3
import itertools
import json
import os
import pytest
import random
import sys
import string
import tempfile
import time


class TestClient:
    def __init__(self, sanic_test_client):
        self.sanic_test_client = sanic_test_client

    def get(self, path, allow_redirects=True):
        return self.sanic_test_client.get(
            path,
            allow_redirects=allow_redirects,
            gather_request=False
        )


def make_app_client(
    sql_time_limit_ms=None,
    max_returned_rows=None,
    cors=False,
    config=None,
    filename=""fixtures.db"",
):
    with tempfile.TemporaryDirectory() as tmpdir:
        filepath = os.path.join(tmpdir, filename)
        conn = sqlite3.connect(filepath)
        conn.executescript(TABLES)
        os.chdir(os.path.dirname(filepath))
        plugins_dir = os.path.join(tmpdir, ""plugins"")
        os.mkdir(plugins_dir)
        open(os.path.join(plugins_dir, ""my_plugin.py""), ""w"").write(PLUGIN1)
        open(os.path.join(plugins_dir, ""my_plugin_2.py""), ""w"").write(PLUGIN2)
        config = config or {}
        config.update(
            {
                ""default_page_size"": 50,
                ""max_returned_rows"": max_returned_rows or 100,
                ""sql_time_limit_ms"": sql_time_limit_ms or 200,
            }
        )
        ds = Datasette(
            [filepath],
            cors=cors,
            metadata=METADATA,
            plugins_dir=plugins_dir,
            config=config,
        )
        ds.sqlite_functions.append((""sleep"", 1, lambda n: time.sleep(float(n))))
        client = TestClient(ds.app().test_client)
        client.ds = ds
        yield client


@pytest.fixture(scope=""session"")
def app_client():
    yield from make_app_client()


@pytest.fixture(scope=""session"")
def app_client_no_files():
    ds = Datasette([])
    client = TestClient(ds.app().test_client)
    client.ds = ds
    yield client


@pytest.fixture(scope=""session"")
def app_client_with_hash():
    yield from make_app_client(config={
        'hash_urls': True
    })


@pytest.fixture(scope='session')
def app_client_shorter_time_limit():
    yield from make_app_client(20)


@pytest.fixture(scope='session')
def app_client_returned_rows_matches_page_size():
    yield from make_app_client(max_returned_rows=50)


@pytest.fixture(scope='session')
def app_client_larger_cache_size():
    yield from make_app_client(config={
        'cache_size_kb': 2500,
    })


@pytest.fixture(scope='session')
def app_client_csv_max_mb_one():
    yield from make_app_client(config={
        'max_csv_mb': 1,
    })


@pytest.fixture(scope=""session"")
def app_client_with_dot():
    yield from make_app_client(filename=""fixtures.dot.db"")


@pytest.fixture(scope='session')
def app_client_with_cors():
    yield from make_app_client(cors=True)


def generate_compound_rows(num):
    for a, b, c in itertools.islice(
        itertools.product(string.ascii_lowercase, repeat=3), num
    ):
        yield a, b, c, '{}-{}-{}'.format(a, b, c)


def generate_sortable_rows(num):
    rand = random.Random(42)
    for a, b in itertools.islice(
        itertools.product(string.ascii_lowercase, repeat=2), num
    ):
        yield {
            'pk1': a,
            'pk2': b,
            'content': '{}-{}'.format(a, b),
            'sortable': rand.randint(-100, 100),
            'sortable_with_nulls': rand.choice([
                None, rand.random(), rand.random()
            ]),
            'sortable_with_nulls_2': rand.choice([
                None, rand.random(), rand.random()
            ]),
            'text': rand.choice(['$null', '$blah']),
        }


METADATA = {
    'title': 'Datasette Fixtures',
    'description': 'An example SQLite database demonstrating Datasette',
    'license': 'Apache License 2.0',
    'license_url': 'https://github.com/simonw/datasette/blob/master/LICENSE',
    'source': 'tests/fixtures.py',
    'source_url': 'https://github.com/simonw/datasette/blob/master/tests/fixtures.py',
    'about': 'About Datasette',
    'about_url': 'https://github.com/simonw/datasette',
    ""plugins"": {
        ""name-of-plugin"": {
            ""depth"": ""root""
        }
    },
    'databases': {
        'fixtures': {
            'description': 'Test tables description',
            ""plugins"": {
                ""name-of-plugin"": {
                    ""depth"": ""database""
                }
            },
            'tables': {
                'simple_primary_key': {
                    'description_html': 'Simple <em>primary</em> key',
                    'title': 'This <em>HTML</em> is escaped',
                    ""plugins"": {
                        ""name-of-plugin"": {
                            ""depth"": ""table"",
                            ""special"": ""this-is-simple_primary_key""
                        }
                    }
                },
                'sortable': {
                    'sortable_columns': [
                        'sortable',
                        'sortable_with_nulls',
                        'sortable_with_nulls_2',
                        'text',
                    ],
                    ""plugins"": {
                        ""name-of-plugin"": {
                            ""depth"": ""table""
                        }
                    }
                },
                'no_primary_key': {
                    'sortable_columns': [],
                    'hidden': True,
                },
                'units': {
                    'units': {
                        'distance': 'm',
                        'frequency': 'Hz'
                    }
                },
                'primary_key_multiple_columns_explicit_label': {
                    'label_column': 'content2',
                },
                'simple_view': {
                    'sortable_columns': ['content'],
                }
            },
            'queries': {
                'pragma_cache_size': 'PRAGMA cache_size;',
                'neighborhood_search': {
                    'sql': '''
                        select neighborhood, facet_cities.name, state
                        from facetable
                            join facet_cities
                                on facetable.city_id = facet_cities.id
                        where neighborhood like '%' || :text || '%'
                        order by neighborhood;
                    ''',
                    'title': 'Search neighborhoods',
                    'description_html': '<b>Demonstrating</b> simple like search',
                },
            }
        },
    }
}

PLUGIN1 = '''
from datasette import hookimpl
import base64
import pint
import json

ureg = pint.UnitRegistry()


@hookimpl
def prepare_connection(conn):
    def convert_units(amount, from_, to_):
        ""select convert_units(100, 'm', 'ft');""
        return (amount * ureg(from_)).to(to_).to_tuple()[0]
    conn.create_function('convert_units', 3, convert_units)


@hookimpl
def extra_css_urls(template, database, table, datasette):
    return ['https://example.com/{}/extra-css-urls-demo.css'.format(
        base64.b64encode(json.dumps({
            ""template"": template,
            ""database"": database,
            ""table"": table,
        }).encode(""utf8"")).decode(""utf8"")
    )]


@hookimpl
def extra_js_urls():
    return [{
        'url': 'https://example.com/jquery.js',
        'sri': 'SRIHASH',
    }, 'https://example.com/plugin1.js']


@hookimpl
def extra_body_script(template, database, table, datasette):
    return 'var extra_body_script = {};'.format(
        json.dumps({
            ""template"": template,
            ""database"": database,
            ""table"": table,
            ""config"": datasette.plugin_config(
                ""name-of-plugin"",
                database=database,
                table=table,
            )
        })
    )


@hookimpl
def render_cell(value, column, table, database, datasette):
    # Render some debug output in cell with value RENDER_CELL_DEMO
    if value != ""RENDER_CELL_DEMO"":
        return None
    return json.dumps({
        ""column"": column,
        ""table"": table,
        ""database"": database,
        ""config"": datasette.plugin_config(
            ""name-of-plugin"",
            database=database,
            table=table,
        )
    })
'''

PLUGIN2 = '''
from datasette import hookimpl
import jinja2
import json


@hookimpl
def extra_js_urls():
    return [{
        'url': 'https://example.com/jquery.js',
        'sri': 'SRIHASH',
    }, 'https://example.com/plugin2.js']


@hookimpl
def render_cell(value, database):
    # Render {""href"": ""..."", ""label"": ""...""} as link
    if not isinstance(value, str):
        return None
    stripped = value.strip()
    if not stripped.startswith(""{"") and stripped.endswith(""}""):
        return None
    try:
        data = json.loads(value)
    except ValueError:
        return None
    if not isinstance(data, dict):
        return None
    if set(data.keys()) != {""href"", ""label""}:
        return None
    href = data[""href""]
    if not (
        href.startswith(""/"") or href.startswith(""http://"")
        or href.startswith(""https://"")
    ):
        return None
    return jinja2.Markup(
        '<a data-database=""{database}"" href=""{href}"">{label}</a>'.format(
            database=database,
            href=jinja2.escape(data[""href""]),
            label=jinja2.escape(data[""label""] or """") or ""&nbsp;""
        )
    )
'''

TABLES = '''
CREATE TABLE simple_primary_key (
  id varchar(30) primary key,
  content text
);

CREATE TABLE primary_key_multiple_columns (
  id varchar(30) primary key,
  content text,
  content2 text
);

CREATE TABLE primary_key_multiple_columns_explicit_label (
  id varchar(30) primary key,
  content text,
  content2 text
);

CREATE TABLE compound_primary_key (
  pk1 varchar(30),
  pk2 varchar(30),
  content text,
  PRIMARY KEY (pk1, pk2)
);

INSERT INTO compound_primary_key VALUES ('a', 'b', 'c');

CREATE TABLE compound_three_primary_keys (
  pk1 varchar(30),
  pk2 varchar(30),
  pk3 varchar(30),
  content text,
  PRIMARY KEY (pk1, pk2, pk3)
);

CREATE TABLE foreign_key_references (
  pk varchar(30) primary key,
  foreign_key_with_label varchar(30),
  foreign_key_with_no_label varchar(30),
  FOREIGN KEY (foreign_key_with_label) REFERENCES simple_primary_key(id),
  FOREIGN KEY (foreign_key_with_no_label) REFERENCES primary_key_multiple_columns(id)
);

CREATE TABLE sortable (
  pk1 varchar(30),
  pk2 varchar(30),
  content text,
  sortable integer,
  sortable_with_nulls real,
  sortable_with_nulls_2 real,
  text text,
  PRIMARY KEY (pk1, pk2)
);

CREATE TABLE no_primary_key (
  content text,
  a text,
  b text,
  c text
);

CREATE TABLE [123_starts_with_digits] (
  content text
);

CREATE VIEW paginated_view AS
    SELECT
        content,
        '- ' || content || ' -' AS content_extra
    FROM no_primary_key;

CREATE TABLE ""Table With Space In Name"" (
  pk varchar(30) primary key,
  content text
);

CREATE TABLE ""table/with/slashes.csv"" (
  pk varchar(30) primary key,
  content text
);

CREATE TABLE ""complex_foreign_keys"" (
  pk varchar(30) primary key,
  f1 text,
  f2 text,
  f3 text,
  FOREIGN KEY (""f1"") REFERENCES [simple_primary_key](id),
  FOREIGN KEY (""f2"") REFERENCES [simple_primary_key](id),
  FOREIGN KEY (""f3"") REFERENCES [simple_primary_key](id)
);

CREATE TABLE ""custom_foreign_key_label"" (
  pk varchar(30) primary key,
  foreign_key_with_custom_label text,
  FOREIGN KEY (""foreign_key_with_custom_label"") REFERENCES [primary_key_multiple_columns_explicit_label](id)
);

CREATE TABLE units (
  pk integer primary key,
  distance int,
  frequency int
);

INSERT INTO units VALUES (1, 1, 100);
INSERT INTO units VALUES (2, 5000, 2500);
INSERT INTO units VALUES (3, 100000, 75000);

CREATE TABLE tags (
    tag TEXT PRIMARY KEY
);

CREATE TABLE searchable (
  pk integer primary key,
  text1 text,
  text2 text,
  [name with . and spaces] text
);

CREATE TABLE searchable_tags (
    searchable_id integer,
    tag text,
    PRIMARY KEY (searchable_id, tag),
    FOREIGN KEY (searchable_id) REFERENCES searchable(pk),
    FOREIGN KEY (tag) REFERENCES tags(tag)
);

INSERT INTO searchable VALUES (1, 'barry cat', 'terry dog', 'panther');
INSERT INTO searchable VALUES (2, 'terry dog', 'sara weasel', 'puma');

INSERT INTO tags VALUES (""canine"");
INSERT INTO tags VALUES (""feline"");

INSERT INTO searchable_tags (searchable_id, tag) VALUES
    (1, ""feline""),
    (2, ""canine"")
;

CREATE VIRTUAL TABLE ""searchable_fts""
    USING FTS3 (text1, text2, [name with . and spaces], content=""searchable"");
INSERT INTO ""searchable_fts"" (rowid, text1, text2, [name with . and spaces])
    SELECT rowid, text1, text2, [name with . and spaces] FROM searchable;

CREATE TABLE [select] (
  [group] text,
  [having] text,
  [and] text,
  [json] text
);
INSERT INTO [select] VALUES ('group', 'having', 'and',
    '{""href"": ""http://example.com/"", ""label"":""Example""}'
);

CREATE TABLE infinity (
    value REAL
);
INSERT INTO infinity VALUES
    (1e999),
    (-1e999),
    (1.5)
;

CREATE TABLE facet_cities (
    id integer primary key,
    name text
);
INSERT INTO facet_cities (id, name) VALUES
    (1, 'San Francisco'),
    (2, 'Los Angeles'),
    (3, 'Detroit'),
    (4, 'Memnonia')
;

CREATE TABLE facetable (
    pk integer primary key,
    planet_int integer,
    on_earth integer,
    state text,
    city_id integer,
    neighborhood text,
    FOREIGN KEY (""city_id"") REFERENCES [facet_cities](id)
);
INSERT INTO facetable
    (planet_int, on_earth, state, city_id, neighborhood)
VALUES
    (1, 1, 'CA', 1, 'Mission'),
    (1, 1, 'CA', 1, 'Dogpatch'),
    (1, 1, 'CA', 1, 'SOMA'),
    (1, 1, 'CA', 1, 'Tenderloin'),
    (1, 1, 'CA', 1, 'Bernal Heights'),
    (1, 1, 'CA', 1, 'Hayes Valley'),
    (1, 1, 'CA', 2, 'Hollywood'),
    (1, 1, 'CA', 2, 'Downtown'),
    (1, 1, 'CA', 2, 'Los Feliz'),
    (1, 1, 'CA', 2, 'Koreatown'),
    (1, 1, 'MI', 3, 'Downtown'),
    (1, 1, 'MI', 3, 'Greektown'),
    (1, 1, 'MI', 3, 'Corktown'),
    (1, 1, 'MI', 3, 'Mexicantown'),
    (2, 0, 'MC', 4, 'Arcadia Planitia')
;

INSERT INTO simple_primary_key VALUES (1, 'hello');
INSERT INTO simple_primary_key VALUES (2, 'world');
INSERT INTO simple_primary_key VALUES (3, '');
INSERT INTO simple_primary_key VALUES (4, 'RENDER_CELL_DEMO');

INSERT INTO primary_key_multiple_columns VALUES (1, 'hey', 'world');
INSERT INTO primary_key_multiple_columns_explicit_label VALUES (1, 'hey', 'world2');

INSERT INTO foreign_key_references VALUES (1, 1, 1);

INSERT INTO complex_foreign_keys VALUES (1, 1, 2, 1);
INSERT INTO custom_foreign_key_label VALUES (1, 1);

INSERT INTO [table/with/slashes.csv] VALUES (3, 'hey');

CREATE VIEW simple_view AS
    SELECT content, upper(content) AS upper_content FROM simple_primary_key;

''' + '\n'.join([
    'INSERT INTO no_primary_key VALUES ({i}, ""a{i}"", ""b{i}"", ""c{i}"");'.format(i=i + 1)
    for i in range(201)
]) + '\n'.join([
    'INSERT INTO compound_three_primary_keys VALUES (""{a}"", ""{b}"", ""{c}"", ""{content}"");'.format(
        a=a, b=b, c=c, content=content
    ) for a, b, c, content in generate_compound_rows(1001)
]) + '\n'.join([
    '''INSERT INTO sortable VALUES (
        ""{pk1}"", ""{pk2}"", ""{content}"", {sortable},
        {sortable_with_nulls}, {sortable_with_nulls_2}, ""{text}"");
    '''.format(
        **row
    ).replace('None', 'null') for row in generate_sortable_rows(201)
])

if __name__ == '__main__':
    # Can be called with data.db OR data.db metadata.json
    db_filename = sys.argv[-1]
    metadata_filename = None
    if db_filename.endswith("".json""):
        metadata_filename = db_filename
        db_filename = sys.argv[-2]
    if db_filename.endswith("".db""):
        conn = sqlite3.connect(db_filename)
        conn.executescript(TABLES)
        print(""Test tables written to {}"".format(db_filename))
        if metadata_filename:
            open(metadata_filename, 'w').write(json.dumps(METADATA))
            print(""- metadata written to {}"".format(metadata_filename))
    else:
        print(""Usage: {} db_to_write.db [metadata_to_write.json]"".format(
            sys.argv[0]
        ))
/n/n/ntests/test_api.py/n/nfrom .fixtures import ( # noqa
    app_client,
    app_client_no_files,
    app_client_with_hash,
    app_client_shorter_time_limit,
    app_client_larger_cache_size,
    app_client_returned_rows_matches_page_size,
    app_client_with_dot,
    generate_compound_rows,
    generate_sortable_rows,
    make_app_client,
    METADATA,
)
import json
import pytest
import urllib


def test_homepage(app_client):
    response = app_client.get('/.json')
    assert response.status == 200
    assert response.json.keys() == {'fixtures': 0}.keys()
    d = response.json['fixtures']
    assert d['name'] == 'fixtures'
    assert d['tables_count'] == 20


def test_database_page(app_client):
    response = app_client.get('/fixtures.json')
    data = response.json
    assert 'fixtures' == data['database']
    assert [{
        'columns': ['content'],
        'name': '123_starts_with_digits',
        'count': 0,
        'hidden': False,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'label_column': None,
        'fts_table': None,
        'primary_keys': [],
    }, {
        'columns': ['pk', 'content'],
        'name': 'Table With Space In Name',
        'count': 0,
        'hidden': False,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'label_column': None,
        'fts_table': None,
        'primary_keys': ['pk'],
    }, {
        'columns': ['pk', 'f1', 'f2', 'f3'],
        'name': 'complex_foreign_keys',
        'count': 1,
        'foreign_keys': {
            'incoming': [],
            'outgoing': [{
                'column': 'f3',
                'other_column': 'id',
                'other_table': 'simple_primary_key'
            }, {
                'column': 'f2',
                'other_column': 'id',
                'other_table': 'simple_primary_key'
            }, {
                'column': 'f1',
                'other_column': 'id',
                'other_table': 'simple_primary_key'
            }],
        },
        'hidden': False,
        'label_column': None,
        'fts_table': None,
        'primary_keys': ['pk'],
    }, {
        'columns': ['pk1', 'pk2', 'content'],
        'name': 'compound_primary_key',
        'count': 1,
        'hidden': False,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'label_column': None,
        'fts_table': None,
        'primary_keys': ['pk1', 'pk2'],
    }, {
        'columns': ['pk1', 'pk2', 'pk3', 'content'],
        'name': 'compound_three_primary_keys',
        'count': 1001,
        'hidden': False,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'label_column': None,
        'fts_table': None,
        'primary_keys': ['pk1', 'pk2', 'pk3'],
    }, {
        'columns': ['pk', 'foreign_key_with_custom_label'],
        'name': 'custom_foreign_key_label',
        'count': 1,
        'hidden': False,
        'foreign_keys': {
            'incoming': [],
            'outgoing':  [{
                'column': 'foreign_key_with_custom_label',
                'other_column': 'id',
                'other_table': 'primary_key_multiple_columns_explicit_label'
            }],
        },
        'label_column': None,
        'fts_table': None,
        'primary_keys': ['pk'],
    }, {
        'columns': ['id', 'name'],
        'name': 'facet_cities',
        'count': 4,
        'foreign_keys': {
            'incoming': [{
                'column': 'id',
                'other_column': 'city_id',
                'other_table': 'facetable',
            }],
            'outgoing': []
        },
        'fts_table': None,
        'hidden': False,
        'label_column': 'name',
        'primary_keys': ['id'],
    }, {
        'columns': ['pk', 'planet_int', 'on_earth', 'state', 'city_id', 'neighborhood'],
        'name': 'facetable',
        'count': 15,
        'foreign_keys': {
            'incoming': [],
            'outgoing': [{
                'column': 'city_id',
                'other_column': 'id',
                'other_table': 'facet_cities'
            }],
        },
        'fts_table': None,
        'hidden': False,
        'label_column': None,
        'primary_keys': ['pk'],
    }, {
        'columns': ['pk', 'foreign_key_with_label', 'foreign_key_with_no_label'],
        'name': 'foreign_key_references',
        'count': 1,
        'hidden': False,
        'foreign_keys': {
            'incoming': [],
            'outgoing':  [{
                'column': 'foreign_key_with_no_label',
                'other_column': 'id',
                'other_table': 'primary_key_multiple_columns'
            }, {
                'column': 'foreign_key_with_label',
                'other_column': 'id',
                'other_table': 'simple_primary_key',
            }],
        },
        'label_column': None,
        'fts_table': None,
        'primary_keys': ['pk'],
    }, {
        ""name"": ""infinity"",
        ""columns"": [""value""],
        ""count"": 3,
        ""primary_keys"": [],
        ""label_column"": None,
        ""hidden"": False,
        ""fts_table"": None,
        ""foreign_keys"": {""incoming"": [], ""outgoing"": []}
    }, {
        'columns': ['id', 'content', 'content2'],
        'name': 'primary_key_multiple_columns',
        'count': 1,
        'foreign_keys': {
            'incoming': [{
                'column': 'id',
                'other_column': 'foreign_key_with_no_label',
                'other_table': 'foreign_key_references'
            }],
            'outgoing': []
        },
        'hidden': False,
        'label_column': None,
        'fts_table': None,
        'primary_keys': ['id']
    }, {
        'columns': ['id', 'content', 'content2'],
        'name': 'primary_key_multiple_columns_explicit_label',
        'count': 1,
        'foreign_keys': {
            'incoming': [{
                'column': 'id',
                'other_column': 'foreign_key_with_custom_label',
                'other_table': 'custom_foreign_key_label'
            }],
            'outgoing': []
        },
        'hidden': False,
        'label_column': None,
        'fts_table': None,
        'primary_keys': ['id']
    },  {
        'columns': ['pk', 'text1', 'text2', 'name with . and spaces'],
        'name': 'searchable',
        'count': 2,
        'foreign_keys': {'incoming': [{
            ""other_table"": ""searchable_tags"",
            ""column"": ""pk"",
            ""other_column"": ""searchable_id""
        }], 'outgoing': []},
        'fts_table': 'searchable_fts',
        'hidden': False,
        'label_column': None,
        'primary_keys': ['pk'],
    }, {
        ""name"": ""searchable_tags"",
        ""columns"": [""searchable_id"", ""tag""],
        ""primary_keys"": [""searchable_id"", ""tag""],
        ""count"": 2,
        ""label_column"": None,
        ""hidden"": False,
        ""fts_table"": None,
        ""foreign_keys"": {
            ""incoming"": [],
            ""outgoing"": [
                {
                    ""other_table"": ""tags"",
                    ""column"": ""tag"",
                    ""other_column"": ""tag"",
                },
                {
                    ""other_table"": ""searchable"",
                    ""column"": ""searchable_id"",
                    ""other_column"": ""pk"",
                },
            ],
        },
    }, {
        'columns': ['group', 'having', 'and', 'json'],
        'name': 'select',
        'count': 1,
        'hidden': False,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'label_column': None,
        'fts_table': None,
        'primary_keys': [],
    }, {
        'columns': ['id', 'content'],
        'name': 'simple_primary_key',
        'count': 4,
        'hidden': False,
        'foreign_keys': {
            'incoming': [{
                'column': 'id',
                'other_column': 'foreign_key_with_label',
                'other_table': 'foreign_key_references'
            }, {
                'column': 'id',
                'other_column': 'f3',
                'other_table': 'complex_foreign_keys'
            }, {
                'column': 'id',
                'other_column': 'f2',
                'other_table': 'complex_foreign_keys'
            }, {
                'column': 'id',
                'other_column': 'f1',
                'other_table': 'complex_foreign_keys'
            }],
            'outgoing': [],
        },
        'label_column': 'content',
        'fts_table': None,
        'primary_keys': ['id'],
    }, {
        'columns': [
            'pk1', 'pk2', 'content', 'sortable', 'sortable_with_nulls',
            'sortable_with_nulls_2', 'text',
        ],
        'name': 'sortable',
        'count': 201,
        'hidden': False,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'label_column': None,
        'fts_table': None,
        'primary_keys': ['pk1', 'pk2'],
    }, {
        'columns': ['pk', 'content'],
        'name': 'table/with/slashes.csv',
        'count': 1,
        'hidden': False,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'label_column': None,
        'fts_table': None,
        'primary_keys': ['pk'],
    }, {
        ""name"": ""tags"",
        ""columns"": [""tag""],
        ""primary_keys"": [""tag""],
        ""count"": 2,
        ""label_column"": None,
        ""hidden"": False,
        ""fts_table"": None,
        ""foreign_keys"": {
            ""incoming"": [
                {
                    ""other_table"": ""searchable_tags"",
                    ""column"": ""tag"",
                    ""other_column"": ""tag"",
                }
            ],
            ""outgoing"": [],
        },
    }, {
        'columns': ['pk', 'distance', 'frequency'],
        'name': 'units',
        'count': 3,
        'hidden': False,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'label_column': None,
        'fts_table': None,
        'primary_keys': ['pk'],
    },  {
        'columns': ['content', 'a', 'b', 'c'],
        'name': 'no_primary_key',
        'count': 201,
        'hidden': True,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'label_column': None,
        'fts_table': None,
        'primary_keys': [],
    },  {
        'columns': ['text1', 'text2', 'name with . and spaces', 'content'],
        'count': 2,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'fts_table': 'searchable_fts',
        'hidden': True,
        'label_column': None,
        'name': 'searchable_fts',
        'primary_keys': []
    }, {
        'columns': ['docid', 'c0text1', 'c1text2', 'c2name with . and spaces', 'c3content'],
        'count': 2,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'fts_table': None,
        'hidden': True,
        'label_column': None,
        'name': 'searchable_fts_content',
        'primary_keys': ['docid']
    }, {
        'columns': [
            'level', 'idx', 'start_block', 'leaves_end_block',
            'end_block', 'root'
        ],
        'count': 1,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'fts_table': None,
        'hidden': True,
        'label_column': None,
        'name': 'searchable_fts_segdir',
        'primary_keys': ['level', 'idx']
    }, {
        'columns': ['blockid', 'block'],
        'count': 0,
        'foreign_keys': {'incoming': [], 'outgoing': []},
        'fts_table': None,
        'hidden': True,
        'label_column': None,
        'name': 'searchable_fts_segments',
        'primary_keys': ['blockid']
    }] == data['tables']


def test_no_files_uses_memory_database(app_client_no_files):
    response = app_client_no_files.get(""/.json"")
    assert response.status == 200
    assert {
        "":memory:"": {
            ""hash"": ""000"",
            ""hidden_table_rows_sum"": 0,
            ""hidden_tables_count"": 0,
            ""name"": "":memory:"",
            ""path"": ""/:memory:"",
            ""table_rows_sum"": 0,
            ""tables_count"": 0,
            ""tables_more"": False,
            ""tables_truncated"": [],
            ""views_count"": 0,
        }
    } == response.json
    # Try that SQL query
    response = app_client_no_files.get(
        ""/:memory:.json?sql=select+sqlite_version()&_shape=array""
    )
    assert 1 == len(response.json)
    assert [""sqlite_version()""] == list(response.json[0].keys())


def test_database_page_for_database_with_dot_in_name(app_client_with_dot):
    response = app_client_with_dot.get(""/fixtures.dot.json"")
    assert 200 == response.status


def test_custom_sql(app_client):
    response = app_client.get(
        '/fixtures.json?sql=select+content+from+simple_primary_key&_shape=objects'
    )
    data = response.json
    assert {
        'sql': 'select content from simple_primary_key',
        'params': {}
    } == data['query']
    assert [
        {'content': 'hello'},
        {'content': 'world'},
        {'content': ''},
        {'content': 'RENDER_CELL_DEMO'}
    ] == data['rows']
    assert ['content'] == data['columns']
    assert 'fixtures' == data['database']
    assert not data['truncated']


def test_canned_query_with_named_parameter(app_client):
    response = app_client.get(
        ""/fixtures/neighborhood_search.json?text=town""
    )
    assert [
        [""Corktown"", ""Detroit"", ""MI""],
        [""Downtown"", ""Los Angeles"", ""CA""],
        [""Downtown"", ""Detroit"", ""MI""],
        [""Greektown"", ""Detroit"", ""MI""],
        [""Koreatown"", ""Los Angeles"", ""CA""],
        [""Mexicantown"", ""Detroit"", ""MI""],
    ] == response.json[""rows""]


def test_sql_time_limit(app_client_shorter_time_limit):
    response = app_client_shorter_time_limit.get(
        '/fixtures.json?sql=select+sleep(0.5)'
    )
    assert 400 == response.status
    assert 'SQL Interrupted' == response.json['title']


def test_custom_sql_time_limit(app_client):
    response = app_client.get(
        '/fixtures.json?sql=select+sleep(0.01)'
    )
    assert 200 == response.status
    response = app_client.get(
        '/fixtures.json?sql=select+sleep(0.01)&_timelimit=5'
    )
    assert 400 == response.status
    assert 'SQL Interrupted' == response.json['title']


def test_invalid_custom_sql(app_client):
    response = app_client.get(
        '/fixtures.json?sql=.schema'
    )
    assert response.status == 400
    assert response.json['ok'] is False
    assert 'Statement must be a SELECT' == response.json['error']


def test_allow_sql_off():
    for client in make_app_client(config={
        'allow_sql': False,
    }):
        assert 400 == client.get(
            ""/fixtures.json?sql=select+sleep(0.01)""
        ).status


def test_table_json(app_client):
    response = app_client.get('/fixtures/simple_primary_key.json?_shape=objects')
    assert response.status == 200
    data = response.json
    assert data['query']['sql'] == 'select * from simple_primary_key order by id limit 51'
    assert data['query']['params'] == {}
    assert data['rows'] == [{
        'id': '1',
        'content': 'hello',
    }, {
        'id': '2',
        'content': 'world',
    }, {
        'id': '3',
        'content': '',
    }, {
        'id': '4',
        'content': 'RENDER_CELL_DEMO',
    }]


def test_table_not_exists_json(app_client):
    assert {
        'ok': False,
        'error': 'Table not found: blah',
        'status': 404,
        'title': None,
    } == app_client.get('/fixtures/blah.json').json


def test_jsono_redirects_to_shape_objects(app_client_with_hash):
    response_1 = app_client_with_hash.get(
        '/fixtures/simple_primary_key.jsono',
        allow_redirects=False
    )
    response = app_client_with_hash.get(
        response_1.headers['Location'],
        allow_redirects=False
    )
    assert response.status == 302
    assert response.headers['Location'].endswith('?_shape=objects')


def test_table_shape_arrays(app_client):
    response = app_client.get(
        '/fixtures/simple_primary_key.json?_shape=arrays'
    )
    assert [
        ['1', 'hello'],
        ['2', 'world'],
        ['3', ''],
        ['4', 'RENDER_CELL_DEMO'],
    ] == response.json['rows']


def test_table_shape_arrayfirst(app_client):
    response = app_client.get(
        '/fixtures.json?' + urllib.parse.urlencode({
            'sql': 'select content from simple_primary_key order by id',
            '_shape': 'arrayfirst'
        })
    )
    assert ['hello', 'world', '', 'RENDER_CELL_DEMO'] == response.json


def test_table_shape_objects(app_client):
    response = app_client.get(
        '/fixtures/simple_primary_key.json?_shape=objects'
    )
    assert [{
        'id': '1',
        'content': 'hello',
    }, {
        'id': '2',
        'content': 'world',
    }, {
        'id': '3',
        'content': '',
    }, {
        'id': '4',
        'content': 'RENDER_CELL_DEMO',
    }] == response.json['rows']


def test_table_shape_array(app_client):
    response = app_client.get(
        '/fixtures/simple_primary_key.json?_shape=array'
    )
    assert [{
        'id': '1',
        'content': 'hello',
    }, {
        'id': '2',
        'content': 'world',
    }, {
        'id': '3',
        'content': '',
    }, {
        'id': '4',
        'content': 'RENDER_CELL_DEMO',
    }] == response.json


def test_table_shape_array_nl(app_client):
    response = app_client.get(
        '/fixtures/simple_primary_key.json?_shape=array&_nl=on'
    )
    lines = response.text.split(""\n"")
    results = [json.loads(line) for line in lines]
    assert [{
        'id': '1',
        'content': 'hello',
    }, {
        'id': '2',
        'content': 'world',
    }, {
        'id': '3',
        'content': '',
    }, {
        'id': '4',
        'content': 'RENDER_CELL_DEMO',
    }] == results


def test_table_shape_invalid(app_client):
    response = app_client.get(
        '/fixtures/simple_primary_key.json?_shape=invalid'
    )
    assert {
        'ok': False,
        'error': 'Invalid _shape: invalid',
        'status': 400,
        'title': None,
    } == response.json


def test_table_shape_object(app_client):
    response = app_client.get(
        '/fixtures/simple_primary_key.json?_shape=object'
    )
    assert {
        '1': {
            'id': '1',
            'content': 'hello',
        },
        '2': {
            'id': '2',
            'content': 'world',
        },
        '3': {
            'id': '3',
            'content': '',
        },
        '4': {
            'id': '4',
            'content': 'RENDER_CELL_DEMO',
        }
    } == response.json


def test_table_shape_object_compound_primary_Key(app_client):
    response = app_client.get(
        '/fixtures/compound_primary_key.json?_shape=object'
    )
    assert {
        'a,b': {
            'pk1': 'a',
            'pk2': 'b',
            'content': 'c',
        }
    } == response.json


def test_table_with_slashes_in_name(app_client):
    response = app_client.get('/fixtures/table%2Fwith%2Fslashes.csv?_shape=objects&_format=json')
    assert response.status == 200
    data = response.json
    assert data['rows'] == [{
        'pk': '3',
        'content': 'hey',
    }]


def test_table_with_reserved_word_name(app_client):
    response = app_client.get('/fixtures/select.json?_shape=objects')
    assert response.status == 200
    data = response.json
    assert data['rows'] == [{
        'rowid': 1,
        'group': 'group',
        'having': 'having',
        'and': 'and',
        'json': '{""href"": ""http://example.com/"", ""label"":""Example""}'
    }]


@pytest.mark.parametrize('path,expected_rows,expected_pages', [
    ('/fixtures/no_primary_key.json', 201, 5),
    ('/fixtures/paginated_view.json', 201, 5),
    ('/fixtures/no_primary_key.json?_size=25', 201, 9),
    ('/fixtures/paginated_view.json?_size=25', 201, 9),
    ('/fixtures/paginated_view.json?_size=max', 201, 3),
    ('/fixtures/123_starts_with_digits.json', 0, 1),
    # Ensure faceting doesn't break pagination:
    ('/fixtures/compound_three_primary_keys.json?_facet=pk1', 1001, 21),
])
def test_paginate_tables_and_views(app_client, path, expected_rows, expected_pages):
    fetched = []
    count = 0
    while path:
        response = app_client.get(path)
        assert 200 == response.status
        count += 1
        fetched.extend(response.json['rows'])
        path = response.json['next_url']
        if path:
            assert response.json['next']
            assert urllib.parse.urlencode({
                '_next': response.json['next']
            }) in path
        assert count < 30, 'Possible infinite loop detected'

    assert expected_rows == len(fetched)
    assert expected_pages == count


@pytest.mark.parametrize('path,expected_error', [
    ('/fixtures/no_primary_key.json?_size=-4', '_size must be a positive integer'),
    ('/fixtures/no_primary_key.json?_size=dog', '_size must be a positive integer'),
    ('/fixtures/no_primary_key.json?_size=1001', '_size must be <= 100'),
])
def test_validate_page_size(app_client, path, expected_error):
    response = app_client.get(path)
    assert expected_error == response.json['error']
    assert 400 == response.status


def test_page_size_zero(app_client):
    ""For _size=0 we return the counts, empty rows and no continuation token""
    response = app_client.get('/fixtures/no_primary_key.json?_size=0')
    assert 200 == response.status
    assert [] == response.json['rows']
    assert 201 == response.json['table_rows_count']
    assert 201 == response.json['filtered_table_rows_count']
    assert None is response.json['next']
    assert None is response.json['next_url']


def test_paginate_compound_keys(app_client):
    fetched = []
    path = '/fixtures/compound_three_primary_keys.json?_shape=objects'
    page = 0
    while path:
        page += 1
        response = app_client.get(path)
        fetched.extend(response.json['rows'])
        path = response.json['next_url']
        assert page < 100
    assert 1001 == len(fetched)
    assert 21 == page
    # Should be correctly ordered
    contents = [f['content'] for f in fetched]
    expected = [r[3] for r in generate_compound_rows(1001)]
    assert expected == contents


def test_paginate_compound_keys_with_extra_filters(app_client):
    fetched = []
    path = '/fixtures/compound_three_primary_keys.json?content__contains=d&_shape=objects'
    page = 0
    while path:
        page += 1
        assert page < 100
        response = app_client.get(path)
        fetched.extend(response.json['rows'])
        path = response.json['next_url']
    assert 2 == page
    expected = [
        r[3] for r in generate_compound_rows(1001)
        if 'd' in r[3]
    ]
    assert expected == [f['content'] for f in fetched]


@pytest.mark.parametrize('query_string,sort_key,human_description_en', [
    ('_sort=sortable', lambda row: row['sortable'], 'sorted by sortable'),
    ('_sort_desc=sortable', lambda row: -row['sortable'], 'sorted by sortable descending'),
    (
        '_sort=sortable_with_nulls',
        lambda row: (
            1 if row['sortable_with_nulls'] is not None else 0,
            row['sortable_with_nulls']
        ),
        'sorted by sortable_with_nulls'
    ),
    (
        '_sort_desc=sortable_with_nulls',
        lambda row: (
            1 if row['sortable_with_nulls'] is None else 0,
            -row['sortable_with_nulls'] if row['sortable_with_nulls'] is not None else 0,
            row['content']
        ),
        'sorted by sortable_with_nulls descending'
    ),
    # text column contains '$null' - ensure it doesn't confuse pagination:
    ('_sort=text', lambda row: row['text'], 'sorted by text'),
])
def test_sortable(app_client, query_string, sort_key, human_description_en):
    path = '/fixtures/sortable.json?_shape=objects&{}'.format(query_string)
    fetched = []
    page = 0
    while path:
        page += 1
        assert page < 100
        response = app_client.get(path)
        assert human_description_en == response.json['human_description_en']
        fetched.extend(response.json['rows'])
        path = response.json['next_url']
    assert 5 == page
    expected = list(generate_sortable_rows(201))
    expected.sort(key=sort_key)
    assert [
        r['content'] for r in expected
    ] == [
        r['content'] for r in fetched
    ]


def test_sortable_and_filtered(app_client):
    path = (
        '/fixtures/sortable.json'
        '?content__contains=d&_sort_desc=sortable&_shape=objects'
    )
    response = app_client.get(path)
    fetched = response.json['rows']
    assert 'where content contains ""d"" sorted by sortable descending' \
        == response.json['human_description_en']
    expected = [
        row for row in generate_sortable_rows(201)
        if 'd' in row['content']
    ]
    assert len(expected) == response.json['filtered_table_rows_count']
    assert 201 == response.json['table_rows_count']
    expected.sort(key=lambda row: -row['sortable'])
    assert [
        r['content'] for r in expected
    ] == [
        r['content'] for r in fetched
    ]


def test_sortable_argument_errors(app_client):
    response = app_client.get(
        '/fixtures/sortable.json?_sort=badcolumn'
    )
    assert 'Cannot sort table by badcolumn' == response.json['error']
    response = app_client.get(
        '/fixtures/sortable.json?_sort_desc=badcolumn2'
    )
    assert 'Cannot sort table by badcolumn2' == response.json['error']
    response = app_client.get(
        '/fixtures/sortable.json?_sort=sortable_with_nulls&_sort_desc=sortable'
    )
    assert 'Cannot use _sort and _sort_desc at the same time' == response.json['error']


def test_sortable_columns_metadata(app_client):
    response = app_client.get(
        '/fixtures/sortable.json?_sort=content'
    )
    assert 'Cannot sort table by content' == response.json['error']
    # no_primary_key has ALL sort options disabled
    for column in ('content', 'a', 'b', 'c'):
        response = app_client.get(
            '/fixtures/sortable.json?_sort={}'.format(column)
        )
        assert 'Cannot sort table by {}'.format(column) == response.json['error']


@pytest.mark.parametrize('path,expected_rows', [
    ('/fixtures/searchable.json?_search=dog', [
        [1, 'barry cat', 'terry dog', 'panther'],
        [2, 'terry dog', 'sara weasel', 'puma'],
    ]),
    ('/fixtures/searchable.json?_search=weasel', [
        [2, 'terry dog', 'sara weasel', 'puma'],
    ]),
    ('/fixtures/searchable.json?_search_text2=dog', [
        [1, 'barry cat', 'terry dog', 'panther'],
    ]),
    ('/fixtures/searchable.json?_search_name%20with%20.%20and%20spaces=panther', [
        [1, 'barry cat', 'terry dog', 'panther'],
    ]),
])
def test_searchable(app_client, path, expected_rows):
    response = app_client.get(path)
    assert expected_rows == response.json['rows']


def test_searchable_invalid_column(app_client):
    response = app_client.get(
        '/fixtures/searchable.json?_search_invalid=x'
    )
    assert 400 == response.status
    assert {
        'ok': False,
        'error': 'Cannot search by that column',
        'status': 400,
        'title': None
    } == response.json


@pytest.mark.parametrize('path,expected_rows', [
    ('/fixtures/simple_primary_key.json?content=hello', [
        ['1', 'hello'],
    ]),
    ('/fixtures/simple_primary_key.json?content__contains=o', [
        ['1', 'hello'],
        ['2', 'world'],
        ['4', 'RENDER_CELL_DEMO'],
    ]),
    ('/fixtures/simple_primary_key.json?content__exact=', [
        ['3', ''],
    ]),
    ('/fixtures/simple_primary_key.json?content__not=world', [
        ['1', 'hello'],
        ['3', ''],
        ['4', 'RENDER_CELL_DEMO'],
    ]),
])
def test_table_filter_queries(app_client, path, expected_rows):
    response = app_client.get(path)
    assert expected_rows == response.json['rows']


def test_max_returned_rows(app_client):
    response = app_client.get(
        '/fixtures.json?sql=select+content+from+no_primary_key'
    )
    data = response.json
    assert {
        'sql': 'select content from no_primary_key',
        'params': {}
    } == data['query']
    assert data['truncated']
    assert 100 == len(data['rows'])


def test_view(app_client):
    response = app_client.get('/fixtures/simple_view.json?_shape=objects')
    assert response.status == 200
    data = response.json
    assert data['rows'] == [{
        'upper_content': 'HELLO',
        'content': 'hello',
    }, {
        'upper_content': 'WORLD',
        'content': 'world',
    }, {
        'upper_content': '',
        'content': '',
    }, {
        'upper_content': 'RENDER_CELL_DEMO',
        'content': 'RENDER_CELL_DEMO',
    }]


def test_row(app_client):
    response = app_client.get('/fixtures/simple_primary_key/1.json?_shape=objects')
    assert response.status == 200
    assert [{'id': '1', 'content': 'hello'}] == response.json['rows']


def test_row_strange_table_name(app_client):
    response = app_client.get('/fixtures/table%2Fwith%2Fslashes.csv/3.json?_shape=objects')
    assert response.status == 200
    assert [{'pk': '3', 'content': 'hey'}] == response.json['rows']


def test_row_foreign_key_tables(app_client):
    response = app_client.get('/fixtures/simple_primary_key/1.json?_extras=foreign_key_tables')
    assert response.status == 200
    assert [{
        'column': 'id',
        'count': 1,
        'other_column': 'foreign_key_with_label',
        'other_table': 'foreign_key_references'
    }, {
        'column': 'id',
        'count': 1,
        'other_column': 'f3',
        'other_table': 'complex_foreign_keys'
    }, {
        'column': 'id',
        'count': 0,
        'other_column': 'f2',
        'other_table': 'complex_foreign_keys'
    }, {
        'column': 'id',
        'count': 1,
        'other_column': 'f1',
        'other_table': 'complex_foreign_keys'
    }] == response.json['foreign_key_tables']


def test_unit_filters(app_client):
    response = app_client.get(
        '/fixtures/units.json?distance__lt=75km&frequency__gt=1kHz'
    )
    assert response.status == 200
    data = response.json

    assert data['units']['distance'] == 'm'
    assert data['units']['frequency'] == 'Hz'

    assert len(data['rows']) == 1
    assert data['rows'][0][0] == 2


def test_metadata_json(app_client):
    response = app_client.get(
        ""/-/metadata.json""
    )
    assert METADATA == response.json


def test_inspect_json(app_client):
    response = app_client.get(
        ""/-/inspect.json""
    )
    assert app_client.ds.inspect() == response.json


def test_plugins_json(app_client):
    response = app_client.get(
        ""/-/plugins.json""
    )
    # This will include any plugins that have been installed into the
    # current virtual environment, so we only check for the presence of
    # the one we know will definitely be There
    assert {
        'name': 'my_plugin.py',
        'static': False,
        'templates': False,
        'version': None,
    } in response.json


def test_versions_json(app_client):
    response = app_client.get(
        ""/-/versions.json""
    )
    assert 'python' in response.json
    assert 'version' in response.json['python']
    assert 'full' in response.json['python']
    assert 'datasette' in response.json
    assert 'version' in response.json['datasette']
    assert 'sqlite' in response.json
    assert 'version' in response.json['sqlite']
    assert 'fts_versions' in response.json['sqlite']
    assert 'compile_options' in response.json['sqlite']


def test_config_json(app_client):
    response = app_client.get(
        ""/-/config.json""
    )
    assert {
        ""default_page_size"": 50,
        ""default_facet_size"": 30,
        ""facet_suggest_time_limit_ms"": 50,
        ""facet_time_limit_ms"": 200,
        ""max_returned_rows"": 100,
        ""sql_time_limit_ms"": 200,
        ""allow_download"": True,
        ""allow_facet"": True,
        ""suggest_facets"": True,
        ""allow_sql"": True,
        ""default_cache_ttl"": 5,
        ""default_cache_ttl_hashed"": 365 * 24 * 60 * 60,
        ""num_sql_threads"": 3,
        ""cache_size_kb"": 0,
        ""allow_csv_stream"": True,
        ""max_csv_mb"": 100,
        ""truncate_cells_html"": 2048,
        ""force_https_urls"": False,
        ""hash_urls"": False,
    } == response.json


def test_page_size_matching_max_returned_rows(app_client_returned_rows_matches_page_size):
    fetched = []
    path = '/fixtures/no_primary_key.json'
    while path:
        response = app_client_returned_rows_matches_page_size.get(path)
        fetched.extend(response.json['rows'])
        assert len(response.json['rows']) in (1, 50)
        path = response.json['next_url']
    assert 201 == len(fetched)


@pytest.mark.parametrize('path,expected_facet_results', [
    (
        ""/fixtures/facetable.json?_facet=state&_facet=city_id"",
        {
            ""state"": {
                ""name"": ""state"",
                ""results"": [
                    {
                        ""value"": ""CA"",
                        ""label"": ""CA"",
                        ""count"": 10,
                        ""toggle_url"": ""_facet=state&_facet=city_id&state=CA"",
                        ""selected"": False,
                    },
                    {
                        ""value"": ""MI"",
                        ""label"": ""MI"",
                        ""count"": 4,
                        ""toggle_url"": ""_facet=state&_facet=city_id&state=MI"",
                        ""selected"": False,
                    },
                    {
                        ""value"": ""MC"",
                        ""label"": ""MC"",
                        ""count"": 1,
                        ""toggle_url"": ""_facet=state&_facet=city_id&state=MC"",
                        ""selected"": False,
                    }
                ],
                ""truncated"": False,
            },
            ""city_id"": {
                ""name"": ""city_id"",
                ""results"": [
                    {
                        ""value"": 1,
                        ""label"": ""San Francisco"",
                        ""count"": 6,
                        ""toggle_url"": ""_facet=state&_facet=city_id&city_id=1"",
                        ""selected"": False,
                    },
                    {
                        ""value"": 2,
                        ""label"": ""Los Angeles"",
                        ""count"": 4,
                        ""toggle_url"": ""_facet=state&_facet=city_id&city_id=2"",
                        ""selected"": False,
                    },
                    {
                        ""value"": 3,
                        ""label"": ""Detroit"",
                        ""count"": 4,
                        ""toggle_url"": ""_facet=state&_facet=city_id&city_id=3"",
                        ""selected"": False,
                    },
                    {
                        ""value"": 4,
                        ""label"": ""Memnonia"",
                        ""count"": 1,
                        ""toggle_url"": ""_facet=state&_facet=city_id&city_id=4"",
                        ""selected"": False,
                    }
                ],
                ""truncated"": False,
            }
        }
    ), (
        ""/fixtures/facetable.json?_facet=state&_facet=city_id&state=MI"",
        {
            ""state"": {
                ""name"": ""state"",
                ""results"": [
                    {
                        ""value"": ""MI"",
                        ""label"": ""MI"",
                        ""count"": 4,
                        ""selected"": True,
                        ""toggle_url"": ""_facet=state&_facet=city_id"",
                    },
                ],
                ""truncated"": False,
            },
            ""city_id"": {
                ""name"": ""city_id"",
                ""results"": [
                    {
                        ""value"": 3,
                        ""label"": ""Detroit"",
                        ""count"": 4,
                        ""selected"": False,
                        ""toggle_url"": ""_facet=state&_facet=city_id&state=MI&city_id=3"",
                    },
                ],
                ""truncated"": False,
            },
        },
    ), (
        ""/fixtures/facetable.json?_facet=planet_int"",
        {
            ""planet_int"": {
                ""name"": ""planet_int"",
                ""results"": [
                    {
                        ""value"": 1,
                        ""label"": 1,
                        ""count"": 14,
                        ""selected"": False,
                        ""toggle_url"": ""_facet=planet_int&planet_int=1"",
                    },
                    {
                        ""value"": 2,
                        ""label"": 2,
                        ""count"": 1,
                        ""selected"": False,
                        ""toggle_url"": ""_facet=planet_int&planet_int=2"",
                    },
                ],
                ""truncated"": False,
            }
        },
    ), (
        # planet_int is an integer field:
        ""/fixtures/facetable.json?_facet=planet_int&planet_int=1"",
        {
            ""planet_int"": {
                ""name"": ""planet_int"",
                ""results"": [
                    {
                        ""value"": 1,
                        ""label"": 1,
                        ""count"": 14,
                        ""selected"": True,
                        ""toggle_url"": ""_facet=planet_int"",
                    }
                ],
                ""truncated"": False,
            },
        },
    )
])
def test_facets(app_client, path, expected_facet_results):
    response = app_client.get(path)
    facet_results = response.json['facet_results']
    # We only compare the querystring portion of the taggle_url
    for facet_name, facet_info in facet_results.items():
        assert facet_name == facet_info[""name""]
        assert False is facet_info[""truncated""]
        for facet_value in facet_info[""results""]:
            facet_value['toggle_url'] = facet_value['toggle_url'].split('?')[1]
    assert expected_facet_results == facet_results


def test_suggested_facets(app_client):
    assert len(app_client.get(
        ""/fixtures/facetable.json""
    ).json[""suggested_facets""]) > 0


def test_allow_facet_off():
    for client in make_app_client(config={
        'allow_facet': False,
    }):
        assert 400 == client.get(
            ""/fixtures/facetable.json?_facet=planet_int""
        ).status
        # Should not suggest any facets either:
        assert [] == client.get(
            ""/fixtures/facetable.json""
        ).json[""suggested_facets""]


def test_suggest_facets_off():
    for client in make_app_client(config={
        'suggest_facets': False,
    }):
        # Now suggested_facets should be []
        assert [] == client.get(
            ""/fixtures/facetable.json""
        ).json[""suggested_facets""]


def test_expand_labels(app_client):
    response = app_client.get(
        ""/fixtures/facetable.json?_shape=object&_labels=1&_size=2""
        ""&neighborhood__contains=c""
    )
    assert {
        ""2"": {
            ""pk"": 2,
            ""planet_int"": 1,
            ""on_earth"": 1,
            ""state"": ""CA"",
            ""city_id"": {
                ""value"": 1,
                ""label"": ""San Francisco""
            },
            ""neighborhood"": ""Dogpatch""
        },
        ""13"": {
            ""pk"": 13,
            ""planet_int"": 1,
            ""on_earth"": 1,
            ""state"": ""MI"",
            ""city_id"": {
                ""value"": 3,
                ""label"": ""Detroit""
            },
            ""neighborhood"": ""Corktown""
        }
    } == response.json


def test_expand_label(app_client):
    response = app_client.get(
        ""/fixtures/foreign_key_references.json?_shape=object""
        ""&_label=foreign_key_with_label""
    )
    assert {
        ""1"": {
            ""pk"": ""1"",
            ""foreign_key_with_label"": {
                ""value"": ""1"",
                ""label"": ""hello""
            },
            ""foreign_key_with_no_label"": ""1""
        }
    } == response.json


@pytest.mark.parametrize('path,expected_cache_control', [
    (""/fixtures/facetable.json"", ""max-age=5""),
    (""/fixtures/facetable.json?_ttl=invalid"", ""max-age=5""),
    (""/fixtures/facetable.json?_ttl=10"", ""max-age=10""),
    (""/fixtures/facetable.json?_ttl=0"", ""no-cache""),
])
def test_ttl_parameter(app_client, path, expected_cache_control):
    response = app_client.get(path)
    assert expected_cache_control == response.headers['Cache-Control']


@pytest.mark.parametrize(""path,expected_redirect"", [
    (""/fixtures/facetable.json?_hash=1"", ""/fixtures-HASH/facetable.json""),
    (""/fixtures/facetable.json?city_id=1&_hash=1"", ""/fixtures-HASH/facetable.json?city_id=1""),
])
def test_hash_parameter(app_client, path, expected_redirect):
    # First get the current hash for the fixtures database
    current_hash = app_client.get(""/-/inspect.json"").json[""fixtures""][""hash""][:7]
    response = app_client.get(path, allow_redirects=False)
    assert response.status == 302
    location = response.headers[""Location""]
    assert expected_redirect.replace(""HASH"", current_hash) == location


test_json_columns_default_expected = [{
    ""intval"": 1,
    ""strval"": ""s"",
    ""floatval"": 0.5,
    ""jsonval"": ""{\""foo\"": \""bar\""}""
}]


@pytest.mark.parametrize(""extra_args,expected"", [
    ("""", test_json_columns_default_expected),
    (""&_json=intval"", test_json_columns_default_expected),
    (""&_json=strval"", test_json_columns_default_expected),
    (""&_json=floatval"", test_json_columns_default_expected),
    (""&_json=jsonval"", [{
        ""intval"": 1,
        ""strval"": ""s"",
        ""floatval"": 0.5,
        ""jsonval"": {
            ""foo"": ""bar""
        }
    }])
])
def test_json_columns(app_client, extra_args, expected):
    sql = '''
        select 1 as intval, ""s"" as strval, 0.5 as floatval,
        '{""foo"": ""bar""}' as jsonval
    '''
    path = ""/fixtures.json?"" + urllib.parse.urlencode({
        ""sql"": sql,
        ""_shape"": ""array""
    })
    path += extra_args
    response = app_client.get(path)
    assert expected == response.json


def test_config_cache_size(app_client_larger_cache_size):
    response = app_client_larger_cache_size.get(
        '/fixtures/pragma_cache_size.json'
    )
    assert [[-2500]] == response.json['rows']


def test_config_force_https_urls():
    for client in make_app_client(config={""force_https_urls"": True}):
        response = client.get(""/fixtures/facetable.json?_size=3&_facet=state"")
        assert response.json[""next_url""].startswith(""https://"")
        assert response.json[""facet_results""][""state""][""results""][0][
            ""toggle_url""
        ].startswith(""https://"")
        assert response.json[""suggested_facets""][0][""toggle_url""].startswith(""https://"")


def test_infinity_returned_as_null(app_client):
    response = app_client.get(""/fixtures/infinity.json?_shape=array"")
    assert [
        {""rowid"": 1, ""value"": None},
        {""rowid"": 2, ""value"": None},
        {""rowid"": 3, ""value"": 1.5}
    ] == response.json


def test_infinity_returned_as_invalid_json_if_requested(app_client):
    response = app_client.get(""/fixtures/infinity.json?_shape=array&_json_infinity=1"")
    assert [
        {""rowid"": 1, ""value"": float(""inf"")},
        {""rowid"": 2, ""value"": float(""-inf"")},
        {""rowid"": 3, ""value"": 1.5}
    ] == response.json
/n/n/ntests/test_html.py/n/nfrom bs4 import BeautifulSoup as Soup
from .fixtures import ( # noqa
    app_client,
    app_client_shorter_time_limit,
    app_client_with_hash,
    make_app_client,
)
import pytest
import re
import urllib.parse


def test_homepage(app_client):
    response = app_client.get('/')
    assert response.status == 200
    assert 'fixtures' in response.text


def test_database_page_redirects_with_url_hash(app_client_with_hash):
    response = app_client_with_hash.get('/fixtures', allow_redirects=False)
    assert response.status == 302
    response = app_client_with_hash.get('/fixtures')
    assert 'fixtures' in response.text


def test_invalid_custom_sql(app_client):
    response = app_client.get(
        '/fixtures?sql=.schema'
    )
    assert response.status == 400
    assert 'Statement must be a SELECT' in response.text


def test_sql_time_limit(app_client_shorter_time_limit):
    response = app_client_shorter_time_limit.get(
        '/fixtures?sql=select+sleep(0.5)'
    )
    assert 400 == response.status
    expected_html_fragment = """"""
        <a href=""https://datasette.readthedocs.io/en/stable/config.html#sql-time-limit-ms"">sql_time_limit_ms</a>
    """""".strip()
    assert expected_html_fragment in response.text


def test_row_redirects_with_url_hash(app_client_with_hash):
    response = app_client_with_hash.get(
        '/fixtures/simple_primary_key/1',
        allow_redirects=False
    )
    assert response.status == 302
    assert response.headers['Location'].endswith('/1')
    response = app_client_with_hash.get('/fixtures/simple_primary_key/1')
    assert response.status == 200


def test_row_strange_table_name_with_url_hash(app_client_with_hash):
    response = app_client_with_hash.get(
        '/fixtures/table%2Fwith%2Fslashes.csv/3',
        allow_redirects=False
    )
    assert response.status == 302
    assert response.headers['Location'].endswith(
        '/table%2Fwith%2Fslashes.csv/3'
    )
    response = app_client_with_hash.get('/fixtures/table%2Fwith%2Fslashes.csv/3')
    assert response.status == 200


def test_table_cell_truncation():
    for client in make_app_client(config={
        ""truncate_cells_html"": 5,
    }):
        response = client.get(""/fixtures/facetable"")
        assert response.status == 200
        table = Soup(response.body, ""html.parser"").find(""table"")
        assert table[""class""] == [""rows-and-columns""]
        assert [
            ""Missi"", ""Dogpa"", ""SOMA"", ""Tende"", ""Berna"", ""Hayes"",
            ""Holly"", ""Downt"", ""Los F"", ""Korea"", ""Downt"", ""Greek"",
            ""Corkt"", ""Mexic"", ""Arcad""
        ] == [
            td.string for td in table.findAll(""td"", {
                ""class"": ""col-neighborhood""
            })
        ]


def test_row_page_does_not_truncate():
    for client in make_app_client(config={
        ""truncate_cells_html"": 5,
    }):
        response = client.get(""/fixtures/facetable/1"")
        assert response.status == 200
        table = Soup(response.body, ""html.parser"").find(""table"")
        assert table[""class""] == [""rows-and-columns""]
        assert [""Mission""] == [
            td.string for td in table.findAll(""td"", {
                ""class"": ""col-neighborhood""
            })
        ]


def test_add_filter_redirects(app_client):
    filter_args = urllib.parse.urlencode({
        '_filter_column': 'content',
        '_filter_op': 'startswith',
        '_filter_value': 'x'
    })
    path_base = '/fixtures/simple_primary_key'
    path = path_base + '?' + filter_args
    response = app_client.get(path, allow_redirects=False)
    assert response.status == 302
    assert response.headers['Location'].endswith('?content__startswith=x')

    # Adding a redirect to an existing querystring:
    path = path_base + '?foo=bar&' + filter_args
    response = app_client.get(path, allow_redirects=False)
    assert response.status == 302
    assert response.headers['Location'].endswith('?foo=bar&content__startswith=x')

    # Test that op with a __x suffix overrides the filter value
    path = path_base + '?' + urllib.parse.urlencode({
        '_filter_column': 'content',
        '_filter_op': 'isnull__5',
        '_filter_value': 'x'
    })
    response = app_client.get(path, allow_redirects=False)
    assert response.status == 302
    assert response.headers['Location'].endswith('?content__isnull=5')


def test_existing_filter_redirects(app_client):
    filter_args = {
        '_filter_column_1': 'name',
        '_filter_op_1': 'contains',
        '_filter_value_1': 'hello',
        '_filter_column_2': 'age',
        '_filter_op_2': 'gte',
        '_filter_value_2': '22',
        '_filter_column_3': 'age',
        '_filter_op_3': 'lt',
        '_filter_value_3': '30',
        '_filter_column_4': 'name',
        '_filter_op_4': 'contains',
        '_filter_value_4': 'world',
    }
    path_base = '/fixtures/simple_primary_key'
    path = path_base + '?' + urllib.parse.urlencode(filter_args)
    response = app_client.get(path, allow_redirects=False)
    assert response.status == 302
    assert_querystring_equal(
        'name__contains=hello&age__gte=22&age__lt=30&name__contains=world',
        response.headers['Location'].split('?')[1],
    )

    # Setting _filter_column_3 to empty string should remove *_3 entirely
    filter_args['_filter_column_3'] = ''
    path = path_base + '?' + urllib.parse.urlencode(filter_args)
    response = app_client.get(path, allow_redirects=False)
    assert response.status == 302
    assert_querystring_equal(
        'name__contains=hello&age__gte=22&name__contains=world',
        response.headers['Location'].split('?')[1],
    )

    # ?_filter_op=exact should be removed if unaccompanied by _fiter_column
    response = app_client.get(path_base + '?_filter_op=exact', allow_redirects=False)
    assert response.status == 302
    assert '?' not in response.headers['Location']


def test_empty_search_parameter_gets_removed(app_client):
    path_base = '/fixtures/simple_primary_key'
    path = path_base + '?' + urllib.parse.urlencode({
        '_search': '',
        '_filter_column': 'name',
        '_filter_op': 'exact',
        '_filter_value': 'chidi',
    })
    response = app_client.get(path, allow_redirects=False)
    assert response.status == 302
    assert response.headers['Location'].endswith(
        '?name__exact=chidi'
    )


def test_sort_by_desc_redirects(app_client):
    path_base = '/fixtures/sortable'
    path = path_base + '?' + urllib.parse.urlencode({
        '_sort': 'sortable',
        '_sort_by_desc': '1',
    })
    response = app_client.get(path, allow_redirects=False)
    assert response.status == 302
    assert response.headers['Location'].endswith('?_sort_desc=sortable')


def test_sort_links(app_client):
    response = app_client.get(
        '/fixtures/sortable?_sort=sortable'

    )
    assert response.status == 200
    ths = Soup(response.body, 'html.parser').findAll('th')
    attrs_and_link_attrs = [{
        'attrs': th.attrs,
        'a_href': (
            th.find('a')['href'].split('/')[-1]
            if th.find('a')
            else None
        ),
    } for th in ths]
    assert [
        {
            ""attrs"": {""class"": [""col-Link""], ""scope"": ""col""},
            ""a_href"": None
        },
        {
            ""attrs"": {""class"": [""col-pk1""], ""scope"": ""col""},
            ""a_href"": None
        },
        {
            ""attrs"": {""class"": [""col-pk2""], ""scope"": ""col""},
            ""a_href"": None
        },
        {
            ""attrs"": {""class"": [""col-content""], ""scope"": ""col""},
            ""a_href"": None
        },
        {
            ""attrs"": {""class"": [""col-sortable""], ""scope"": ""col""},
            ""a_href"": ""sortable?_sort_desc=sortable"",
        },
        {
            ""attrs"": {""class"": [""col-sortable_with_nulls""], ""scope"": ""col""},
            ""a_href"": ""sortable?_sort=sortable_with_nulls"",
        },
        {
            ""attrs"": {""class"": [""col-sortable_with_nulls_2""], ""scope"": ""col""},
            ""a_href"": ""sortable?_sort=sortable_with_nulls_2"",
        },
        {
            ""attrs"": {""class"": [""col-text""], ""scope"": ""col""},
            ""a_href"": ""sortable?_sort=text"",
        },
    ] == attrs_and_link_attrs


def test_facet_display(app_client):
    response = app_client.get(
        ""/fixtures/facetable?_facet=planet_int&_facet=city_id&_facet=on_earth""
    )
    assert response.status == 200
    soup = Soup(response.body, ""html.parser"")
    divs = soup.find(
        ""div"", {""class"": ""facet-results""}
    ).findAll(""div"")
    actual = []
    for div in divs:
        actual.append(
            {
                ""name"": div.find(""strong"").text,
                ""items"": [
                    {
                        ""name"": a.text,
                        ""qs"": a[""href""].split(""?"")[-1],
                        ""count"": int(str(a.parent).split(""</a>"")[1].split(""<"")[0]),
                    }
                    for a in div.find(""ul"").findAll(""a"")
                ],
            }
        )
    assert [
        {
            ""name"": ""city_id"",
            ""items"": [
                {
                    ""name"": ""San Francisco"",
                    ""qs"": ""_facet=planet_int&_facet=city_id&_facet=on_earth&city_id=1"",
                    ""count"": 6,
                },
                {
                    ""name"": ""Los Angeles"",
                    ""qs"": ""_facet=planet_int&_facet=city_id&_facet=on_earth&city_id=2"",
                    ""count"": 4,
                },
                {
                    ""name"": ""Detroit"",
                    ""qs"": ""_facet=planet_int&_facet=city_id&_facet=on_earth&city_id=3"",
                    ""count"": 4,
                },
                {
                    ""name"": ""Memnonia"",
                    ""qs"": ""_facet=planet_int&_facet=city_id&_facet=on_earth&city_id=4"",
                    ""count"": 1,
                },
            ],
        },
        {
            ""name"": ""planet_int"",
            ""items"": [
                {
                    ""name"": ""1"",
                    ""qs"": ""_facet=planet_int&_facet=city_id&_facet=on_earth&planet_int=1"",
                    ""count"": 14,
                },
                {
                    ""name"": ""2"",
                    ""qs"": ""_facet=planet_int&_facet=city_id&_facet=on_earth&planet_int=2"",
                    ""count"": 1,
                },
            ],
        },
        {
            ""name"": ""on_earth"",
            ""items"": [
                {
                    ""name"": ""1"",
                    ""qs"": ""_facet=planet_int&_facet=city_id&_facet=on_earth&on_earth=1"",
                    ""count"": 14,
                },
                {
                    ""name"": ""0"",
                    ""qs"": ""_facet=planet_int&_facet=city_id&_facet=on_earth&on_earth=0"",
                    ""count"": 1,
                },
            ],
        },
    ] == actual


def test_facets_persist_through_filter_form(app_client):
    response = app_client.get(
        '/fixtures/facetable?_facet=planet_int&_facet=city_id'
    )
    assert response.status == 200
    inputs = Soup(response.body, 'html.parser').find('form').findAll('input')
    hiddens = [i for i in inputs if i['type'] == 'hidden']
    assert [
        ('_facet', 'city_id'),
        ('_facet', 'planet_int'),
    ] == [
        (hidden['name'], hidden['value']) for hidden in hiddens
    ]


@pytest.mark.parametrize('path,expected_classes', [
    ('/', ['index']),
    ('/fixtures', ['db', 'db-fixtures']),
    ('/fixtures/simple_primary_key', [
        'table', 'db-fixtures', 'table-simple_primary_key'
    ]),
    ('/fixtures/table%2Fwith%2Fslashes.csv', [
        'table', 'db-fixtures', 'table-tablewithslashescsv-fa7563'
    ]),
    ('/fixtures/simple_primary_key/1', [
        'row', 'db-fixtures', 'table-simple_primary_key'
    ]),
])
def test_css_classes_on_body(app_client, path, expected_classes):
    response = app_client.get(path)
    assert response.status == 200
    classes = re.search(r'<body class=""(.*)"">', response.text).group(1).split()
    assert classes == expected_classes


def test_table_html_simple_primary_key(app_client):
    response = app_client.get('/fixtures/simple_primary_key?_size=3')
    assert response.status == 200
    table = Soup(response.body, 'html.parser').find('table')
    assert table['class'] == ['rows-and-columns']
    ths = table.findAll('th')
    assert 'id' == ths[0].find('a').string.strip()
    for expected_col, th in zip(('content',), ths[1:]):
        a = th.find('a')
        assert expected_col == a.string
        assert a['href'].endswith('/simple_primary_key?_size=3&_sort={}'.format(
            expected_col
        ))
        assert ['nofollow'] == a['rel']
    assert [
        [
            '<td class=""col-id""><a href=""/fixtures/simple_primary_key/1"">1</a></td>',
            '<td class=""col-content"">hello</td>'
        ], [
            '<td class=""col-id""><a href=""/fixtures/simple_primary_key/2"">2</a></td>',
            '<td class=""col-content"">world</td>'
        ], [
            '<td class=""col-id""><a href=""/fixtures/simple_primary_key/3"">3</a></td>',
            '<td class=""col-content"">\xa0</td>'
        ]
    ] == [[str(td) for td in tr.select('td')] for tr in table.select('tbody tr')]


def test_table_csv_json_export_interface(app_client):
    response = app_client.get('/fixtures/simple_primary_key?id__gt=2')
    assert response.status == 200
    # The links at the top of the page
    links = Soup(response.body, ""html.parser"").find(""p"", {
        ""class"": ""export-links""
    }).findAll(""a"")
    actual = [l[""href""].split(""/"")[-1] for l in links]
    expected = [
        ""simple_primary_key.json?id__gt=2"",
        ""simple_primary_key.csv?id__gt=2&_size=max"",
        ""#export""
    ]
    assert expected == actual
    # And the advaced export box at the bottom:
    div = Soup(response.body, ""html.parser"").find(""div"", {
        ""class"": ""advanced-export""
    })
    json_links = [a[""href""].split(""/"")[-1] for a in div.find(""p"").findAll(""a"")]
    assert [
        ""simple_primary_key.json?id__gt=2"",
        ""simple_primary_key.json?id__gt=2&_shape=array"",
        ""simple_primary_key.json?id__gt=2&_shape=array&_nl=on"",
        ""simple_primary_key.json?id__gt=2&_shape=object""
    ] == json_links
    # And the CSV form
    form = div.find(""form"")
    assert form[""action""].endswith(""/simple_primary_key.csv"")
    inputs = [str(input) for input in form.findAll(""input"")]
    assert [
        '<input name=""_dl"" type=""checkbox""/>',
        '<input type=""submit"" value=""Export CSV""/>',
        '<input name=""id__gt"" type=""hidden"" value=""2""/>',
        '<input name=""_size"" type=""hidden"" value=""max""/>'
    ] == inputs


def test_csv_json_export_links_include_labels_if_foreign_keys(app_client):
    response = app_client.get('/fixtures/facetable')
    assert response.status == 200
    links = Soup(response.body, ""html.parser"").find(""p"", {
        ""class"": ""export-links""
    }).findAll(""a"")
    actual = [l[""href""].split(""/"")[-1] for l in links]
    expected = [
        ""facetable.json?_labels=on"",
        ""facetable.csv?_labels=on&_size=max"",
        ""#export""
    ]
    assert expected == actual


def test_row_html_simple_primary_key(app_client):
    response = app_client.get('/fixtures/simple_primary_key/1')
    assert response.status == 200
    table = Soup(response.body, 'html.parser').find('table')
    assert [
        'id', 'content'
    ] == [th.string.strip() for th in table.select('thead th')]
    assert [
        [
            '<td class=""col-id"">1</td>',
            '<td class=""col-content"">hello</td>'
        ]
    ] == [[str(td) for td in tr.select('td')] for tr in table.select('tbody tr')]


def test_table_not_exists(app_client):
    assert 'Table not found: blah' in app_client.get(
        '/fixtures/blah'
    ).body.decode('utf8')


def test_table_html_no_primary_key(app_client):
    response = app_client.get('/fixtures/no_primary_key')
    assert response.status == 200
    table = Soup(response.body, 'html.parser').find('table')
    # We have disabled sorting for this table using metadata.json
    assert [
        'content', 'a', 'b', 'c'
    ] == [th.string.strip() for th in table.select('thead th')[2:]]
    expected = [
        [
            '<td class=""col-Link""><a href=""/fixtures/no_primary_key/{}"">{}</a></td>'.format(i, i),
            '<td class=""col-rowid"">{}</td>'.format(i),
            '<td class=""col-content"">{}</td>'.format(i),
            '<td class=""col-a"">a{}</td>'.format(i),
            '<td class=""col-b"">b{}</td>'.format(i),
            '<td class=""col-c"">c{}</td>'.format(i),
        ] for i in range(1, 51)
    ]
    assert expected == [[str(td) for td in tr.select('td')] for tr in table.select('tbody tr')]


def test_row_html_no_primary_key(app_client):
    response = app_client.get('/fixtures/no_primary_key/1')
    assert response.status == 200
    table = Soup(response.body, 'html.parser').find('table')
    assert [
        'rowid', 'content', 'a', 'b', 'c'
    ] == [th.string.strip() for th in table.select('thead th')]
    expected = [
        [
            '<td class=""col-rowid"">1</td>',
            '<td class=""col-content"">1</td>',
            '<td class=""col-a"">a1</td>',
            '<td class=""col-b"">b1</td>',
            '<td class=""col-c"">c1</td>',
        ]
    ]
    assert expected == [[str(td) for td in tr.select('td')] for tr in table.select('tbody tr')]


def test_table_html_compound_primary_key(app_client):
    response = app_client.get('/fixtures/compound_primary_key')
    assert response.status == 200
    table = Soup(response.body, 'html.parser').find('table')
    ths = table.findAll('th')
    assert 'Link' == ths[0].string.strip()
    for expected_col, th in zip(('pk1', 'pk2', 'content'), ths[1:]):
        a = th.find('a')
        assert expected_col == a.string
        assert th['class'] == ['col-{}'.format(expected_col)]
        assert a['href'].endswith('/compound_primary_key?_sort={}'.format(
            expected_col
        ))
    expected = [
        [
            '<td class=""col-Link""><a href=""/fixtures/compound_primary_key/a,b"">a,b</a></td>',
            '<td class=""col-pk1"">a</td>',
            '<td class=""col-pk2"">b</td>',
            '<td class=""col-content"">c</td>',
        ]
    ]
    assert expected == [[str(td) for td in tr.select('td')] for tr in table.select('tbody tr')]


def test_table_html_foreign_key_links(app_client):
    response = app_client.get('/fixtures/foreign_key_references')
    assert response.status == 200
    table = Soup(response.body, 'html.parser').find('table')
    expected = [
        [
            '<td class=""col-pk""><a href=""/fixtures/foreign_key_references/1"">1</a></td>',
            '<td class=""col-foreign_key_with_label""><a href=""/fixtures/simple_primary_key/1"">hello</a>\xa0<em>1</em></td>',
            '<td class=""col-foreign_key_with_no_label""><a href=""/fixtures/primary_key_multiple_columns/1"">1</a></td>'
        ]
    ]
    assert expected == [[str(td) for td in tr.select('td')] for tr in table.select('tbody tr')]


def test_table_html_disable_foreign_key_links_with_labels(app_client):
    response = app_client.get('/fixtures/foreign_key_references?_labels=off')
    assert response.status == 200
    table = Soup(response.body, 'html.parser').find('table')
    expected = [
        [
            '<td class=""col-pk""><a href=""/fixtures/foreign_key_references/1"">1</a></td>',
            '<td class=""col-foreign_key_with_label"">1</td>',
            '<td class=""col-foreign_key_with_no_label"">1</td>'
        ]
    ]
    assert expected == [[str(td) for td in tr.select('td')] for tr in table.select('tbody tr')]


def test_table_html_foreign_key_custom_label_column(app_client):
    response = app_client.get('/fixtures/custom_foreign_key_label')
    assert response.status == 200
    table = Soup(response.body, 'html.parser').find('table')
    expected = [
        [
            '<td class=""col-pk""><a href=""/fixtures/custom_foreign_key_label/1"">1</a></td>',
            '<td class=""col-foreign_key_with_custom_label""><a href=""/fixtures/primary_key_multiple_columns_explicit_label/1"">world2</a>\xa0<em>1</em></td>',
        ]
    ]
    assert expected == [[str(td) for td in tr.select('td')] for tr in table.select('tbody tr')]


def test_row_html_compound_primary_key(app_client):
    response = app_client.get('/fixtures/compound_primary_key/a,b')
    assert response.status == 200
    table = Soup(response.body, 'html.parser').find('table')
    assert [
        'pk1', 'pk2', 'content'
    ] == [th.string.strip() for th in table.select('thead th')]
    expected = [
        [
            '<td class=""col-pk1"">a</td>',
            '<td class=""col-pk2"">b</td>',
            '<td class=""col-content"">c</td>',
        ]
    ]
    assert expected == [[str(td) for td in tr.select('td')] for tr in table.select('tbody tr')]


def test_compound_primary_key_with_foreign_key_references(app_client):
    # e.g. a many-to-many table with a compound primary key on the two columns
    response = app_client.get('/fixtures/searchable_tags')
    assert response.status == 200
    table = Soup(response.body, 'html.parser').find('table')
    expected = [
        [
            '<td class=""col-Link""><a href=""/fixtures/searchable_tags/1,feline"">1,feline</a></td>',
            '<td class=""col-searchable_id""><a href=""/fixtures/searchable/1"">1</a>\xa0<em>1</em></td>',
            '<td class=""col-tag""><a href=""/fixtures/tags/feline"">feline</a></td>',
        ],
        [
            '<td class=""col-Link""><a href=""/fixtures/searchable_tags/2,canine"">2,canine</a></td>',
            '<td class=""col-searchable_id""><a href=""/fixtures/searchable/2"">2</a>\xa0<em>2</em></td>',
            '<td class=""col-tag""><a href=""/fixtures/tags/canine"">canine</a></td>',
        ],
    ]
    assert expected == [[str(td) for td in tr.select('td')] for tr in table.select('tbody tr')]


def test_view_html(app_client):
    response = app_client.get(""/fixtures/simple_view?_size=3"")
    assert response.status == 200
    table = Soup(response.body, ""html.parser"").find(""table"")
    ths = table.select(""thead th"")
    assert 2 == len(ths)
    assert ths[0].find(""a"") is not None
    assert ths[0].find(""a"")[""href""].endswith(""/simple_view?_size=3&_sort=content"")
    assert ths[0].find(""a"").string.strip() == ""content""
    assert ths[1].find(""a"") is None
    assert ths[1].string.strip() == ""upper_content""
    expected = [
        [
            '<td class=""col-content"">hello</td>',
            '<td class=""col-upper_content"">HELLO</td>',
        ],
        [
            '<td class=""col-content"">world</td>',
            '<td class=""col-upper_content"">WORLD</td>',
        ],
        [
            '<td class=""col-content"">\xa0</td>',
            '<td class=""col-upper_content"">\xa0</td>',
        ],
    ]
    assert expected == [
        [str(td) for td in tr.select(""td"")] for tr in table.select(""tbody tr"")
    ]


def test_index_metadata(app_client):
    response = app_client.get('/')
    assert response.status == 200
    soup = Soup(response.body, 'html.parser')
    assert 'Datasette Fixtures' == soup.find('h1').text
    assert 'An example SQLite database demonstrating Datasette' == inner_html(
        soup.find('div', {'class': 'metadata-description'})
    )
    assert_footer_links(soup)


def test_database_metadata(app_client):
    response = app_client.get('/fixtures')
    assert response.status == 200
    soup = Soup(response.body, 'html.parser')
    # Page title should be the default
    assert 'fixtures' == soup.find('h1').text
    # Description should be custom
    assert 'Test tables description' == inner_html(
        soup.find('div', {'class': 'metadata-description'})
    )
    # The source/license should be inherited
    assert_footer_links(soup)


def test_table_metadata(app_client):
    response = app_client.get('/fixtures/simple_primary_key')
    assert response.status == 200
    soup = Soup(response.body, 'html.parser')
    # Page title should be custom and should be HTML escaped
    assert 'This &lt;em&gt;HTML&lt;/em&gt; is escaped' == inner_html(soup.find('h1'))
    # Description should be custom and NOT escaped (we used description_html)
    assert 'Simple <em>primary</em> key' == inner_html(soup.find(
        'div', {'class': 'metadata-description'})
    )
    # The source/license should be inherited
    assert_footer_links(soup)


def test_allow_download_on(app_client):
    response = app_client.get(
        ""/fixtures""
    )
    soup = Soup(response.body, 'html.parser')
    assert len(soup.findAll('a', {'href': re.compile(r'\.db$')}))


def test_allow_download_off():
    for client in make_app_client(config={
        'allow_download': False,
    }):
        response = client.get(
            ""/fixtures"",

        )
        soup = Soup(response.body, 'html.parser')
        assert not len(soup.findAll('a', {'href': re.compile(r'\.db$')}))
        # Accessing URL directly should 403
        response = client.get(
            ""/fixtures.db"",

        )
        assert 403 == response.status


def test_allow_sql_on(app_client):
    response = app_client.get(
        ""/fixtures""
    )
    soup = Soup(response.body, 'html.parser')
    assert len(soup.findAll('textarea', {'name': 'sql'}))
    response = app_client.get(
        ""/fixtures/sortable""
    )
    assert b""View and edit SQL"" in response.body


def test_allow_sql_off():
    for client in make_app_client(config={
        'allow_sql': False,
    }):
        response = client.get(
            ""/fixtures""
        )
        soup = Soup(response.body, 'html.parser')
        assert not len(soup.findAll('textarea', {'name': 'sql'}))
        # The table page should no longer show ""View and edit SQL""
        response = client.get(
            ""/fixtures/sortable""
        )
        assert b""View and edit SQL"" not in response.body


def assert_querystring_equal(expected, actual):
    assert sorted(expected.split('&')) == sorted(actual.split('&'))


def assert_footer_links(soup):
    footer_links = soup.find('div', {'class': 'ft'}).findAll('a')
    assert 4 == len(footer_links)
    datasette_link, license_link, source_link, about_link = footer_links
    assert 'Datasette' == datasette_link.text.strip()
    assert 'tests/fixtures.py' == source_link.text.strip()
    assert 'Apache License 2.0' == license_link.text.strip()
    assert 'About Datasette' == about_link.text.strip()
    assert 'https://github.com/simonw/datasette' == datasette_link['href']
    assert 'https://github.com/simonw/datasette/blob/master/tests/fixtures.py' == source_link['href']
    assert 'https://github.com/simonw/datasette/blob/master/LICENSE' == license_link['href']
    assert 'https://github.com/simonw/datasette' == about_link['href']


def inner_html(soup):
    html = str(soup)
    # This includes the parent tag - so remove that
    inner_html = html.split('>', 1)[1].rsplit('<', 1)[0]
    return inner_html.strip()


@pytest.mark.parametrize('path,expected_redirect', [
    ('/fixtures/', '/fixtures'),
    ('/fixtures/simple_view/', '/fixtures/simple_view'),
])
def test_404_trailing_slash_redirect(app_client, path, expected_redirect):
    response = app_client.get(path, allow_redirects=False)
    assert 302 == response.status
    assert expected_redirect == response.headers[""Location""]


def test_canned_query_with_custom_metadata(app_client):
    response = app_client.get(""/fixtures/neighborhood_search?text=town"")
    assert response.status == 200
    soup = Soup(response.body, ""html.parser"")
    assert ""Search neighborhoods"" == soup.find(""h1"").text
    assert (
        """"""
<div class=""metadata-description"">
 <b>
  Demonstrating
 </b>
 simple like search
</div>"""""".strip()
        == soup.find(""div"", {""class"": ""metadata-description""}).prettify().strip()
    )


@pytest.mark.parametrize('path,has_object,has_stream,has_expand', [
    (""/fixtures/no_primary_key"", False, True, False),
    (""/fixtures/complex_foreign_keys"", True, False, True),
])
def test_advanced_export_box(app_client, path, has_object, has_stream, has_expand):
    response = app_client.get(path)
    assert response.status == 200
    soup = Soup(response.body, ""html.parser"")
    # JSON shape options
    expected_json_shapes = [""default"", ""array"", ""newline-delimited""]
    if has_object:
        expected_json_shapes.append(""object"")
    div = soup.find(""div"", {""class"": ""advanced-export""})
    assert expected_json_shapes == [a.text for a in div.find(""p"").findAll(""a"")]
    # ""stream all rows"" option
    if has_stream:
        assert ""stream all rows"" in str(div)
    # ""expand labels"" option
    if has_expand:
        assert ""expand labels"" in str(div)


def test_urlify_custom_queries(app_client):
    path = ""/fixtures?"" + urllib.parse.urlencode({
        ""sql"": ""select ('https://twitter.com/' || 'simonw') as user_url;""
    })
    response = app_client.get(path)
    assert response.status == 200
    soup = Soup(response.body, ""html.parser"")
    assert '''<td class=""col-user_url"">
 <a href=""https://twitter.com/simonw"">
  https://twitter.com/simonw
 </a>
</td>''' == soup.find(""td"", {""class"": ""col-user_url""}).prettify().strip()


def test_show_hide_sql_query(app_client):
    path = ""/fixtures?"" + urllib.parse.urlencode({
        ""sql"": ""select ('https://twitter.com/' || 'simonw') as user_url;""
    })
    response = app_client.get(path)
    soup = Soup(response.body, ""html.parser"")
    span = soup.select("".show-hide-sql"")[0]
    assert span.find(""a"")[""href""].endswith(""&_hide_sql=1"")
    assert ""(hide)"" == span.getText()
    assert soup.find(""textarea"") is not None
    # Now follow the link to hide it
    response = app_client.get(span.find(""a"")[""href""])
    soup = Soup(response.body, ""html.parser"")
    span = soup.select("".show-hide-sql"")[0]
    assert not span.find(""a"")[""href""].endswith(""&_hide_sql=1"")
    assert ""(show)"" == span.getText()
    assert soup.find(""textarea"") is None
/n/n/ntests/test_utils.py/n/n""""""
Tests for various datasette helper functions.
""""""

from datasette import utils
import json
import os
import pytest
from sanic.request import Request
import tempfile
from unittest.mock import patch


@pytest.mark.parametrize('path,expected', [
    ('foo', ['foo']),
    ('foo,bar', ['foo', 'bar']),
    ('123,433,112', ['123', '433', '112']),
    ('123%2C433,112', ['123,433', '112']),
    ('123%2F433%2F112', ['123/433/112']),
])
def test_urlsafe_components(path, expected):
    assert expected == utils.urlsafe_components(path)


@pytest.mark.parametrize('path,added_args,expected', [
    ('/foo', {'bar': 1}, '/foo?bar=1'),
    ('/foo?bar=1', {'baz': 2}, '/foo?bar=1&baz=2'),
    ('/foo?bar=1&bar=2', {'baz': 3}, '/foo?bar=1&bar=2&baz=3'),
    ('/foo?bar=1', {'bar': None}, '/foo'),
    # Test order is preserved
    ('/?_facet=prim_state&_facet=area_name', (
        ('prim_state', 'GA'),
    ), '/?_facet=prim_state&_facet=area_name&prim_state=GA'),
    ('/?_facet=state&_facet=city&state=MI', (
        ('city', 'Detroit'),
    ), '/?_facet=state&_facet=city&state=MI&city=Detroit'),
    ('/?_facet=state&_facet=city', (
        ('_facet', 'planet_int'),
    ), '/?_facet=state&_facet=city&_facet=planet_int'),
])
def test_path_with_added_args(path, added_args, expected):
    request = Request(
        path.encode('utf8'),
        {}, '1.1', 'GET', None
    )
    actual = utils.path_with_added_args(request, added_args)
    assert expected == actual


@pytest.mark.parametrize('path,args,expected', [
    ('/foo?bar=1', {'bar'}, '/foo'),
    ('/foo?bar=1&baz=2', {'bar'}, '/foo?baz=2'),
    ('/foo?bar=1&bar=2&bar=3', {'bar': '2'}, '/foo?bar=1&bar=3'),
])
def test_path_with_removed_args(path, args, expected):
    request = Request(
        path.encode('utf8'),
        {}, '1.1', 'GET', None
    )
    actual = utils.path_with_removed_args(request, args)
    assert expected == actual
    # Run the test again but this time use the path= argument
    request = Request(
        ""/"".encode('utf8'),
        {}, '1.1', 'GET', None
    )
    actual = utils.path_with_removed_args(request, args, path=path)
    assert expected == actual


@pytest.mark.parametrize('path,args,expected', [
    ('/foo?bar=1', {'bar': 2}, '/foo?bar=2'),
    ('/foo?bar=1&baz=2', {'bar': None}, '/foo?baz=2'),
])
def test_path_with_replaced_args(path, args, expected):
    request = Request(
        path.encode('utf8'),
        {}, '1.1', 'GET', None
    )
    actual = utils.path_with_replaced_args(request, args)
    assert expected == actual


@pytest.mark.parametrize(
    ""row,pks,expected_path"",
    [
        ({""A"": ""foo"", ""B"": ""bar""}, [""A"", ""B""], ""foo,bar""),
        ({""A"": ""f,o"", ""B"": ""bar""}, [""A"", ""B""], ""f%2Co,bar""),
        ({""A"": 123}, [""A""], ""123""),
        (
            utils.CustomRow(
                [""searchable_id"", ""tag""],
                [
                    (
                        ""searchable_id"",
                        {""value"": 1, ""label"": ""1""},
                    ),
                    (
                        ""tag"",
                        {
                            ""value"": ""feline"",
                            ""label"": ""feline"",
                        },
                    ),
                ],
            ),
            [""searchable_id"", ""tag""],
            ""1,feline"",
        ),
    ],
)
def test_path_from_row_pks(row, pks, expected_path):
    actual_path = utils.path_from_row_pks(row, pks, False)
    assert expected_path == actual_path


@pytest.mark.parametrize('obj,expected', [
    ({
        'Description': 'Soft drinks',
        'Picture': b""\x15\x1c\x02\xc7\xad\x05\xfe"",
        'CategoryID': 1,
    }, """"""
        {""CategoryID"": 1, ""Description"": ""Soft drinks"", ""Picture"": {""$base64"": true, ""encoded"": ""FRwCx60F/g==""}}
    """""".strip()),
])
def test_custom_json_encoder(obj, expected):
    actual = json.dumps(
        obj,
        cls=utils.CustomJSONEncoder,
        sort_keys=True
    )
    assert expected == actual


@pytest.mark.parametrize('args,expected_where,expected_params', [
    (
        {
            'name_english__contains': 'foo',
        },
        ['""name_english"" like :p0'],
        ['%foo%']
    ),
    (
        {
            'foo': 'bar',
            'bar__contains': 'baz',
        },
        ['""bar"" like :p0', '""foo"" = :p1'],
        ['%baz%', 'bar']
    ),
    (
        {
            'foo__startswith': 'bar',
            'bar__endswith': 'baz',
        },
        ['""bar"" like :p0', '""foo"" like :p1'],
        ['%baz', 'bar%']
    ),
    (
        {
            'foo__lt': '1',
            'bar__gt': '2',
            'baz__gte': '3',
            'bax__lte': '4',
        },
        ['""bar"" > :p0', '""bax"" <= :p1', '""baz"" >= :p2', '""foo"" < :p3'],
        [2, 4, 3, 1]
    ),
    (
        {
            'foo__like': '2%2',
            'zax__glob': '3*',
        },
        ['""foo"" like :p0', '""zax"" glob :p1'],
        ['2%2', '3*']
    ),
    (
        {
            'foo__isnull': '1',
            'baz__isnull': '1',
            'bar__gt': '10'
        },
        ['""bar"" > :p0', '""baz"" is null', '""foo"" is null'],
        [10]
    ),
])
def test_build_where(args, expected_where, expected_params):
    f = utils.Filters(sorted(args.items()))
    sql_bits, actual_params = f.build_where_clauses()
    assert expected_where == sql_bits
    assert {
        'p{}'.format(i): param
        for i, param in enumerate(expected_params)
    } == actual_params


@pytest.mark.parametrize('bad_sql', [
    'update blah;',
    'PRAGMA case_sensitive_like = true'
    ""SELECT * FROM pragma_index_info('idx52')"",
])
def test_validate_sql_select_bad(bad_sql):
    with pytest.raises(utils.InvalidSql):
        utils.validate_sql_select(bad_sql)


@pytest.mark.parametrize('good_sql', [
    'select count(*) from airports',
    'select foo from bar',
    'select 1 + 1',
    'SELECT\nblah FROM foo',
    'WITH RECURSIVE cnt(x) AS (SELECT 1 UNION ALL SELECT x+1 FROM cnt LIMIT 10) SELECT x FROM cnt;'
])
def test_validate_sql_select_good(good_sql):
    utils.validate_sql_select(good_sql)


def test_detect_fts():
    sql = '''
    CREATE TABLE ""Dumb_Table"" (
      ""TreeID"" INTEGER,
      ""qSpecies"" TEXT
    );
    CREATE TABLE ""Street_Tree_List"" (
      ""TreeID"" INTEGER,
      ""qSpecies"" TEXT,
      ""qAddress"" TEXT,
      ""SiteOrder"" INTEGER,
      ""qSiteInfo"" TEXT,
      ""PlantType"" TEXT,
      ""qCaretaker"" TEXT
    );
    CREATE VIEW Test_View AS SELECT * FROM Dumb_Table;
    CREATE VIRTUAL TABLE ""Street_Tree_List_fts"" USING FTS4 (""qAddress"", ""qCaretaker"", ""qSpecies"", content=""Street_Tree_List"");
    CREATE VIRTUAL TABLE r USING rtree(a, b, c);
    '''
    conn = utils.sqlite3.connect(':memory:')
    conn.executescript(sql)
    assert None is utils.detect_fts(conn, 'Dumb_Table')
    assert None is utils.detect_fts(conn, 'Test_View')
    assert None is utils.detect_fts(conn, 'r')
    assert 'Street_Tree_List_fts' == utils.detect_fts(conn, 'Street_Tree_List')


@pytest.mark.parametrize('url,expected', [
    ('http://www.google.com/', True),
    ('https://example.com/', True),
    ('www.google.com', False),
    ('http://www.google.com/ is a search engine', False),
])
def test_is_url(url, expected):
    assert expected == utils.is_url(url)


@pytest.mark.parametrize('s,expected', [
    ('simple', 'simple'),
    ('MixedCase', 'MixedCase'),
    ('-no-leading-hyphens', 'no-leading-hyphens-65bea6'),
    ('_no-leading-underscores', 'no-leading-underscores-b921bc'),
    ('no spaces', 'no-spaces-7088d7'),
    ('-', '336d5e'),
    ('no $ characters', 'no--characters-59e024'),
])
def test_to_css_class(s, expected):
    assert expected == utils.to_css_class(s)


def test_temporary_docker_directory_uses_hard_link():
    with tempfile.TemporaryDirectory() as td:
        os.chdir(td)
        open('hello', 'w').write('world')
        # Default usage of this should use symlink
        with utils.temporary_docker_directory(
            files=['hello'],
            name='t',
            metadata=None,
            extra_options=None,
            branch=None,
            template_dir=None,
            plugins_dir=None,
            static=[],
            install=[],
            spatialite=False,
            version_note=None,
        ) as temp_docker:
            hello = os.path.join(temp_docker, 'hello')
            assert 'world' == open(hello).read()
            # It should be a hard link
            assert 2 == os.stat(hello).st_nlink


@patch('os.link')
def test_temporary_docker_directory_uses_copy_if_hard_link_fails(mock_link):
    # Copy instead if os.link raises OSError (normally due to different device)
    mock_link.side_effect = OSError
    with tempfile.TemporaryDirectory() as td:
        os.chdir(td)
        open('hello', 'w').write('world')
        # Default usage of this should use symlink
        with utils.temporary_docker_directory(
            files=['hello'],
            name='t',
            metadata=None,
            extra_options=None,
            branch=None,
            template_dir=None,
            plugins_dir=None,
            static=[],
            install=[],
            spatialite=False,
            version_note=None,
        ) as temp_docker:
            hello = os.path.join(temp_docker, 'hello')
            assert 'world' == open(hello).read()
            # It should be a copy, not a hard link
            assert 1 == os.stat(hello).st_nlink


def test_compound_keys_after_sql():
    assert '((a > :p0))' == utils.compound_keys_after_sql(['a'])
    assert '''
((a > :p0)
  or
(a = :p0 and b > :p1))
    '''.strip() == utils.compound_keys_after_sql(['a', 'b'])
    assert '''
((a > :p0)
  or
(a = :p0 and b > :p1)
  or
(a = :p0 and b = :p1 and c > :p2))
    '''.strip() == utils.compound_keys_after_sql(['a', 'b', 'c'])


def table_exists(table):
    return table == ""exists.csv""


@pytest.mark.parametrize(
    ""table_and_format,expected_table,expected_format"",
    [
        (""blah"", ""blah"", None),
        (""blah.csv"", ""blah"", ""csv""),
        (""blah.json"", ""blah"", ""json""),
        (""blah.baz"", ""blah.baz"", None),
        (""exists.csv"", ""exists.csv"", None),
    ],
)
def test_resolve_table_and_format(
    table_and_format, expected_table, expected_format
):
    actual_table, actual_format = utils.resolve_table_and_format(
        table_and_format, table_exists
    )
    assert expected_table == actual_table
    assert expected_format == actual_format


@pytest.mark.parametrize(
    ""path,format,extra_qs,expected"",
    [
        (""/foo?sql=select+1"", ""csv"", {}, ""/foo.csv?sql=select+1""),
        (""/foo?sql=select+1"", ""json"", {}, ""/foo.json?sql=select+1""),
        (""/foo/bar"", ""json"", {}, ""/foo/bar.json""),
        (""/foo/bar"", ""csv"", {}, ""/foo/bar.csv""),
        (""/foo/bar.csv"", ""json"", {}, ""/foo/bar.csv?_format=json""),
        (""/foo/bar"", ""csv"", {""_dl"": 1}, ""/foo/bar.csv?_dl=1""),
        (""/foo/b.csv"", ""json"", {""_dl"": 1}, ""/foo/b.csv?_dl=1&_format=json""),
        (
            ""/sf-trees/Street_Tree_List?_search=cherry&_size=1000"",
            ""csv"",
            {""_dl"": 1},
            ""/sf-trees/Street_Tree_List.csv?_search=cherry&_size=1000&_dl=1"",
        ),
    ],
)
def test_path_with_format(path, format, extra_qs, expected):
    request = Request(
        path.encode('utf8'),
        {}, '1.1', 'GET', None
    )
    actual = utils.path_with_format(request, format, extra_qs)
    assert expected == actual


@pytest.mark.parametrize(
    ""bytes,expected"",
    [
        (120, '120 bytes'),
        (1024, '1.0 KB'),
        (1024 * 1024, '1.0 MB'),
        (1024 * 1024 * 1024, '1.0 GB'),
        (1024 * 1024 * 1024 * 1.3, '1.3 GB'),
        (1024 * 1024 * 1024 * 1024, '1.0 TB'),
    ]
)
def test_format_bytes(bytes, expected):
    assert expected == utils.format_bytes(bytes)
/n/n/n",0
117,117,6f6d0ff2b41f1cacaf42287b1b230b646bcba9ee,"/datasette/app.py/n/nimport asyncio
import click
import collections
import hashlib
import os
import sys
import threading
import traceback
import urllib.parse
from concurrent import futures
from pathlib import Path

from markupsafe import Markup
from jinja2 import ChoiceLoader, Environment, FileSystemLoader, PrefixLoader
from sanic import Sanic, response
from sanic.exceptions import InvalidUsage, NotFound

from .views.base import (
    DatasetteError,
    ureg
)
from .views.database import DatabaseDownload, DatabaseView
from .views.index import IndexView
from .views.special import JsonDataView
from .views.table import RowView, TableView

from .utils import (
    InterruptedError,
    Results,
    escape_css_string,
    escape_sqlite,
    get_plugins,
    module_from_path,
    sqlite3,
    sqlite_timelimit,
    to_css_class
)
from .inspect import inspect_hash, inspect_views, inspect_tables
from .plugins import pm, DEFAULT_PLUGINS
from .version import __version__

app_root = Path(__file__).parent.parent

connections = threading.local()
MEMORY = object()

ConfigOption = collections.namedtuple(
    ""ConfigOption"", (""name"", ""default"", ""help"")
)
CONFIG_OPTIONS = (
    ConfigOption(""default_page_size"", 100, """"""
        Default page size for the table view
    """""".strip()),
    ConfigOption(""max_returned_rows"", 1000, """"""
        Maximum rows that can be returned from a table or custom query
    """""".strip()),
    ConfigOption(""num_sql_threads"", 3, """"""
        Number of threads in the thread pool for executing SQLite queries
    """""".strip()),
    ConfigOption(""sql_time_limit_ms"", 1000, """"""
        Time limit for a SQL query in milliseconds
    """""".strip()),
    ConfigOption(""default_facet_size"", 30, """"""
        Number of values to return for requested facets
    """""".strip()),
    ConfigOption(""facet_time_limit_ms"", 200, """"""
        Time limit for calculating a requested facet
    """""".strip()),
    ConfigOption(""facet_suggest_time_limit_ms"", 50, """"""
        Time limit for calculating a suggested facet
    """""".strip()),
    ConfigOption(""allow_facet"", True, """"""
        Allow users to specify columns to facet using ?_facet= parameter
    """""".strip()),
    ConfigOption(""allow_download"", True, """"""
        Allow users to download the original SQLite database files
    """""".strip()),
    ConfigOption(""suggest_facets"", True, """"""
        Calculate and display suggested facets
    """""".strip()),
    ConfigOption(""allow_sql"", True, """"""
        Allow arbitrary SQL queries via ?sql= parameter
    """""".strip()),
    ConfigOption(""default_cache_ttl"", 365 * 24 * 60 * 60, """"""
        Default HTTP cache TTL (used in Cache-Control: max-age= header)
    """""".strip()),
    ConfigOption(""cache_size_kb"", 0, """"""
        SQLite cache size in KB (0 == use SQLite default)
    """""".strip()),
    ConfigOption(""allow_csv_stream"", True, """"""
        Allow .csv?_stream=1 to download all rows (ignoring max_returned_rows)
    """""".strip()),
    ConfigOption(""max_csv_mb"", 100, """"""
        Maximum size allowed for CSV export in MB - set 0 to disable this limit
    """""".strip()),
    ConfigOption(""truncate_cells_html"", 2048, """"""
        Truncate cells longer than this in HTML table view - set 0 to disable
    """""".strip()),
    ConfigOption(""force_https_urls"", False, """"""
        Force URLs in API output to always use https:// protocol
    """""".strip()),
)
DEFAULT_CONFIG = {
    option.name: option.default
    for option in CONFIG_OPTIONS
}


async def favicon(request):
    return response.text("""")


class Datasette:

    def __init__(
        self,
        files,
        cache_headers=True,
        cors=False,
        inspect_data=None,
        metadata=None,
        sqlite_extensions=None,
        template_dir=None,
        plugins_dir=None,
        static_mounts=None,
        memory=False,
        config=None,
        version_note=None,
    ):
        self.files = files
        if not self.files:
            self.files = [MEMORY]
        elif memory:
            self.files = (MEMORY,) + self.files
        self.cache_headers = cache_headers
        self.cors = cors
        self._inspect = inspect_data
        self._metadata = metadata or {}
        self.sqlite_functions = []
        self.sqlite_extensions = sqlite_extensions or []
        self.template_dir = template_dir
        self.plugins_dir = plugins_dir
        self.static_mounts = static_mounts or []
        self._config = dict(DEFAULT_CONFIG, **(config or {}))
        self.version_note = version_note
        self.executor = futures.ThreadPoolExecutor(
            max_workers=self.config(""num_sql_threads"")
        )
        self.max_returned_rows = self.config(""max_returned_rows"")
        self.sql_time_limit_ms = self.config(""sql_time_limit_ms"")
        self.page_size = self.config(""default_page_size"")
        # Execute plugins in constructor, to ensure they are available
        # when the rest of `datasette inspect` executes
        if self.plugins_dir:
            for filename in os.listdir(self.plugins_dir):
                filepath = os.path.join(self.plugins_dir, filename)
                mod = module_from_path(filepath, name=filename)
                try:
                    pm.register(mod)
                except ValueError:
                    # Plugin already registered
                    pass

    def config(self, key):
        return self._config.get(key, None)

    def config_dict(self):
        # Returns a fully resolved config dictionary, useful for templates
        return {
            option.name: self.config(option.name)
            for option in CONFIG_OPTIONS
        }

    def metadata(self, key=None, database=None, table=None, fallback=True):
        """"""
        Looks up metadata, cascading backwards from specified level.
        Returns None if metadata value is not found.
        """"""
        assert not (database is None and table is not None), \
            ""Cannot call metadata() with table= specified but not database=""
        databases = self._metadata.get(""databases"") or {}
        search_list = []
        if database is not None:
            search_list.append(databases.get(database) or {})
        if table is not None:
            table_metadata = (
                (databases.get(database) or {}).get(""tables"") or {}
            ).get(table) or {}
            search_list.insert(0, table_metadata)
        search_list.append(self._metadata)
        if not fallback:
            # No fallback allowed, so just use the first one in the list
            search_list = search_list[:1]
        if key is not None:
            for item in search_list:
                if key in item:
                    return item[key]
            return None
        else:
            # Return the merged list
            m = {}
            for item in search_list:
                m.update(item)
            return m

    def plugin_config(
        self, plugin_name, database=None, table=None, fallback=True
    ):
        ""Return config for plugin, falling back from specified database/table""
        plugins = self.metadata(
            ""plugins"", database=database, table=table, fallback=fallback
        )
        if plugins is None:
            return None
        return plugins.get(plugin_name)

    def app_css_hash(self):
        if not hasattr(self, ""_app_css_hash""):
            self._app_css_hash = hashlib.sha1(
                open(
                    os.path.join(str(app_root), ""datasette/static/app.css"")
                ).read().encode(
                    ""utf8""
                )
            ).hexdigest()[
                :6
            ]
        return self._app_css_hash

    def get_canned_queries(self, database_name):
        queries = self.metadata(
            ""queries"", database=database_name, fallback=False
        ) or {}
        names = queries.keys()
        return [
            self.get_canned_query(database_name, name) for name in names
        ]

    def get_canned_query(self, database_name, query_name):
        queries = self.metadata(
            ""queries"", database=database_name, fallback=False
        ) or {}
        query = queries.get(query_name)
        if query:
            if not isinstance(query, dict):
                query = {""sql"": query}
            query[""name""] = query_name
            return query

    async def get_table_definition(self, database_name, table, type_=""table""):
        table_definition_rows = list(
            await self.execute(
                database_name,
                'select sql from sqlite_master where name = :n and type=:t',
                {""n"": table, ""t"": type_},
            )
        )
        if not table_definition_rows:
            return None
        return table_definition_rows[0][0]

    def get_view_definition(self, database_name, view):
        return self.get_table_definition(database_name, view, 'view')

    def update_with_inherited_metadata(self, metadata):
        # Fills in source/license with defaults, if available
        metadata.update(
            {
                ""source"": metadata.get(""source"") or self.metadata(""source""),
                ""source_url"": metadata.get(""source_url"")
                or self.metadata(""source_url""),
                ""license"": metadata.get(""license"") or self.metadata(""license""),
                ""license_url"": metadata.get(""license_url"")
                or self.metadata(""license_url""),
                ""about"": metadata.get(""about"") or self.metadata(""about""),
                ""about_url"": metadata.get(""about_url"")
                or self.metadata(""about_url""),
            }
        )

    def prepare_connection(self, conn):
        conn.row_factory = sqlite3.Row
        conn.text_factory = lambda x: str(x, ""utf-8"", ""replace"")
        for name, num_args, func in self.sqlite_functions:
            conn.create_function(name, num_args, func)
        if self.sqlite_extensions:
            conn.enable_load_extension(True)
            for extension in self.sqlite_extensions:
                conn.execute(""SELECT load_extension('{}')"".format(extension))
        if self.config(""cache_size_kb""):
            conn.execute('PRAGMA cache_size=-{}'.format(self.config(""cache_size_kb"")))
        pm.hook.prepare_connection(conn=conn)

    def table_exists(self, database, table):
        return table in self.inspect().get(database, {}).get(""tables"")

    def inspect(self):
        "" Inspect the database and return a dictionary of table metadata ""
        if self._inspect:
            return self._inspect

        self._inspect = {}
        for filename in self.files:
            if filename is MEMORY:
                self._inspect["":memory:""] = {
                    ""hash"": ""000"",
                    ""file"": "":memory:"",
                    ""size"": 0,
                    ""views"": {},
                    ""tables"": {},
                }
            else:
                path = Path(filename)
                name = path.stem
                if name in self._inspect:
                    raise Exception(""Multiple files with same stem %s"" % name)
                try:
                    with sqlite3.connect(
                        ""file:{}?immutable=1"".format(path), uri=True
                    ) as conn:
                        self.prepare_connection(conn)
                        self._inspect[name] = {
                            ""hash"": inspect_hash(path),
                            ""file"": str(path),
                            ""size"": path.stat().st_size,
                            ""views"": inspect_views(conn),
                            ""tables"": inspect_tables(conn, (self.metadata(""databases"") or {}).get(name, {}))
                        }
                except sqlite3.OperationalError as e:
                    if (e.args[0] == 'no such module: VirtualSpatialIndex'):
                        raise click.UsageError(
                            ""It looks like you're trying to load a SpatiaLite""
                            "" database without first loading the SpatiaLite module.""
                            ""\n\nRead more: https://datasette.readthedocs.io/en/latest/spatialite.html""
                        )
                    else:
                        raise
        return self._inspect

    def register_custom_units(self):
        ""Register any custom units defined in the metadata.json with Pint""
        for unit in self.metadata(""custom_units"") or []:
            ureg.define(unit)

    def versions(self):
        conn = sqlite3.connect("":memory:"")
        self.prepare_connection(conn)
        sqlite_version = conn.execute(""select sqlite_version()"").fetchone()[0]
        sqlite_extensions = {}
        for extension, testsql, hasversion in (
            (""json1"", ""SELECT json('{}')"", False),
            (""spatialite"", ""SELECT spatialite_version()"", True),
        ):
            try:
                result = conn.execute(testsql)
                if hasversion:
                    sqlite_extensions[extension] = result.fetchone()[0]
                else:
                    sqlite_extensions[extension] = None
            except Exception as e:
                pass
        # Figure out supported FTS versions
        fts_versions = []
        for fts in (""FTS5"", ""FTS4"", ""FTS3""):
            try:
                conn.execute(
                    ""CREATE VIRTUAL TABLE v{fts} USING {fts} (data)"".format(fts=fts)
                )
                fts_versions.append(fts)
            except sqlite3.OperationalError:
                continue
        datasette_version = {""version"": __version__}
        if self.version_note:
            datasette_version[""note""] = self.version_note
        return {
            ""python"": {
                ""version"": ""."".join(map(str, sys.version_info[:3])), ""full"": sys.version
            },
            ""datasette"": datasette_version,
            ""sqlite"": {
                ""version"": sqlite_version,
                ""fts_versions"": fts_versions,
                ""extensions"": sqlite_extensions,
                ""compile_options"": [
                    r[0] for r in conn.execute(""pragma compile_options;"").fetchall()
                ],
            },
        }

    def plugins(self, show_all=False):
        ps = list(get_plugins(pm))
        if not show_all:
            ps = [p for p in ps if p[""name""] not in DEFAULT_PLUGINS]
        return [
            {
                ""name"": p[""name""],
                ""static"": p[""static_path""] is not None,
                ""templates"": p[""templates_path""] is not None,
                ""version"": p.get(""version""),
            }
            for p in ps
        ]

    async def execute(
        self,
        db_name,
        sql,
        params=None,
        truncate=False,
        custom_time_limit=None,
        page_size=None,
    ):
        """"""Executes sql against db_name in a thread""""""
        page_size = page_size or self.page_size

        def sql_operation_in_thread():
            conn = getattr(connections, db_name, None)
            if not conn:
                info = self.inspect()[db_name]
                if info[""file""] == "":memory:"":
                    conn = sqlite3.connect("":memory:"")
                else:
                    conn = sqlite3.connect(
                        ""file:{}?immutable=1"".format(info[""file""]),
                        uri=True,
                        check_same_thread=False,
                    )
                self.prepare_connection(conn)
                setattr(connections, db_name, conn)

            time_limit_ms = self.sql_time_limit_ms
            if custom_time_limit and custom_time_limit < time_limit_ms:
                time_limit_ms = custom_time_limit

            with sqlite_timelimit(conn, time_limit_ms):
                try:
                    cursor = conn.cursor()
                    cursor.execute(sql, params or {})
                    max_returned_rows = self.max_returned_rows
                    if max_returned_rows == page_size:
                        max_returned_rows += 1
                    if max_returned_rows and truncate:
                        rows = cursor.fetchmany(max_returned_rows + 1)
                        truncated = len(rows) > max_returned_rows
                        rows = rows[:max_returned_rows]
                    else:
                        rows = cursor.fetchall()
                        truncated = False
                except sqlite3.OperationalError as e:
                    if e.args == ('interrupted',):
                        raise InterruptedError(e)
                    print(
                        ""ERROR: conn={}, sql = {}, params = {}: {}"".format(
                            conn, repr(sql), params, e
                        )
                    )
                    raise

            if truncate:
                return Results(rows, truncated, cursor.description)

            else:
                return Results(rows, False, cursor.description)

        return await asyncio.get_event_loop().run_in_executor(
            self.executor, sql_operation_in_thread
        )

    def app(self):
        app = Sanic(__name__)
        default_templates = str(app_root / ""datasette"" / ""templates"")
        template_paths = []
        if self.template_dir:
            template_paths.append(self.template_dir)
        template_paths.extend(
            [
                plugin[""templates_path""]
                for plugin in get_plugins(pm)
                if plugin[""templates_path""]
            ]
        )
        template_paths.append(default_templates)
        template_loader = ChoiceLoader(
            [
                FileSystemLoader(template_paths),
                # Support {% extends ""default:table.html"" %}:
                PrefixLoader(
                    {""default"": FileSystemLoader(default_templates)}, delimiter="":""
                ),
            ]
        )
        self.jinja_env = Environment(loader=template_loader, autoescape=True)
        self.jinja_env.filters[""escape_css_string""] = escape_css_string
        self.jinja_env.filters[""quote_plus""] = lambda u: urllib.parse.quote_plus(u)
        self.jinja_env.filters[""escape_sqlite""] = escape_sqlite
        self.jinja_env.filters[""to_css_class""] = to_css_class
        pm.hook.prepare_jinja2_environment(env=self.jinja_env)
        app.add_route(IndexView.as_view(self), r""/<as_format:(\.jsono?)?$>"")
        # TODO: /favicon.ico and /-/static/ deserve far-future cache expires
        app.add_route(favicon, ""/favicon.ico"")
        app.static(""/-/static/"", str(app_root / ""datasette"" / ""static""))
        for path, dirname in self.static_mounts:
            app.static(path, dirname)
        # Mount any plugin static/ directories
        for plugin in get_plugins(pm):
            if plugin[""static_path""]:
                modpath = ""/-/static-plugins/{}/"".format(plugin[""name""])
                app.static(modpath, plugin[""static_path""])
        app.add_route(
            JsonDataView.as_view(self, ""inspect.json"", self.inspect),
            r""/-/inspect<as_format:(\.json)?$>"",
        )
        app.add_route(
            JsonDataView.as_view(self, ""metadata.json"", lambda: self._metadata),
            r""/-/metadata<as_format:(\.json)?$>"",
        )
        app.add_route(
            JsonDataView.as_view(self, ""versions.json"", self.versions),
            r""/-/versions<as_format:(\.json)?$>"",
        )
        app.add_route(
            JsonDataView.as_view(self, ""plugins.json"", self.plugins),
            r""/-/plugins<as_format:(\.json)?$>"",
        )
        app.add_route(
            JsonDataView.as_view(self, ""config.json"", lambda: self._config),
            r""/-/config<as_format:(\.json)?$>"",
        )
        app.add_route(
            DatabaseDownload.as_view(self), r""/<db_name:[^/]+?><as_db:(\.db)$>""
        )
        app.add_route(
            DatabaseView.as_view(self), r""/<db_name:[^/]+?><as_format:(\.jsono?|\.csv)?$>""
        )
        app.add_route(
            TableView.as_view(self),
            r""/<db_name:[^/]+>/<table_and_format:[^/]+?$>"",
        )
        app.add_route(
            RowView.as_view(self),
            r""/<db_name:[^/]+>/<table:[^/]+?>/<pk_path:[^/]+?><as_format:(\.jsono?)?$>"",
        )
        self.register_custom_units()
        # On 404 with a trailing slash redirect to path without that slash:
        @app.middleware(""response"")
        def redirect_on_404_with_trailing_slash(request, original_response):
            if original_response.status == 404 and request.path.endswith(""/""):
                path = request.path.rstrip(""/"")
                if request.query_string:
                    path = ""{}?{}"".format(path, request.query_string)
                return response.redirect(path)

        @app.exception(Exception)
        def on_exception(request, exception):
            title = None
            help = None
            if isinstance(exception, NotFound):
                status = 404
                info = {}
                message = exception.args[0]
            elif isinstance(exception, InvalidUsage):
                status = 405
                info = {}
                message = exception.args[0]
            elif isinstance(exception, DatasetteError):
                status = exception.status
                info = exception.error_dict
                message = exception.message
                if exception.messagge_is_html:
                    message = Markup(message)
                title = exception.title
            else:
                status = 500
                info = {}
                message = str(exception)
                traceback.print_exc()
            templates = [""500.html""]
            if status != 500:
                templates = [""{}.html"".format(status)] + templates
            info.update(
                {""ok"": False, ""error"": message, ""status"": status, ""title"": title}
            )
            if request is not None and request.path.split(""?"")[0].endswith("".json""):
                return response.json(info, status=status)

            else:
                template = self.jinja_env.select_template(templates)
                return response.html(template.render(info), status=status)

        return app
/n/n/n",1
54,54,7c610e95d8fccc797e153781ecde013da604b242,"modoboa/core/tests/test_authentication.py/n/n""""""Tests for core application.""""""

from __future__ import unicode_literals

import smtplib

from unittest import skipIf
from mock import patch

from django.core import mail
from django.core.urlresolvers import reverse
from django.test import override_settings

from modoboa.lib.tests import ModoTestCase
from modoboa.lib.tests import NO_SMTP

from .. import factories
from .. import models


class AuthenticationTestCase(ModoTestCase):
    """"""Validate authentication scenarios.""""""

    @classmethod
    def setUpTestData(cls):
        """"""Create test data.""""""
        super(AuthenticationTestCase, cls).setUpTestData()
        cls.account = factories.UserFactory(
            username=""user@test.com"", groups=('SimpleUsers',)
        )

    def test_authentication(self):
        """"""Validate simple case.""""""
        self.client.logout()
        data = {""username"": ""user@test.com"", ""password"": ""toto""}
        response = self.client.post(reverse(""core:login""), data)
        self.assertEqual(response.status_code, 302)
        self.assertTrue(response.url.endswith(reverse(""core:user_index"")))

        response = self.client.post(reverse(""core:logout""), {})
        self.assertEqual(response.status_code, 302)

        data = {""username"": ""admin"", ""password"": ""password""}
        response = self.client.post(reverse(""core:login""), data)
        self.assertEqual(response.status_code, 302)
        self.assertTrue(response.url.endswith(reverse(""core:dashboard"")))

    def test_open_redirect(self):
        """"""Check that open redirect is not allowed.""""""
        self.client.logout()
        data = {""username"": ""admin"", ""password"": ""password""}

        # 1. Check valid redirection
        url = ""{}?next=/admin/"".format(reverse(""core:login""))
        response = self.client.post(url, data)
        self.assertEqual(response.status_code, 302)
        self.assertTrue(response.url.endswith(reverse(""admin:index"")))
        self.client.logout()

        # 2. Check bad redirection
        url = ""{}?next=http://www.evil.com"".format(reverse(""core:login""))
        response = self.client.post(url, data)
        self.assertEqual(response.status_code, 302)
        self.assertTrue(response.url.endswith(reverse(""core:dashboard"")))


class PasswordResetTestCase(ModoTestCase):
    """"""Test password reset service.""""""

    @classmethod
    def setUpTestData(cls):
        """"""Create test data.""""""
        super(PasswordResetTestCase, cls).setUpTestData()
        cls.account_ok = factories.UserFactory(
            username=""user@test.com"", secondary_email=""test@ext.com"",
            groups=('SimpleUsers',)
        )
        cls.account_ko = factories.UserFactory(
            username=""user2@test.com"", groups=('SimpleUsers',)
        )

    def test_reset_password(self):
        """"""Validate simple case.""""""
        self.client.logout()
        url = reverse(""password_reset"")
        data = {""email"": self.account_ok.email}
        response = self.client.post(url, data, follow=True)
        self.assertContains(
            response,
            ""We've emailed you instructions for setting your password"")
        self.assertEqual(len(mail.outbox), 1)

    def test_reset_password_no_secondary_email(self):
        """"""Check email is not sent.""""""
        self.client.logout()
        url = reverse(""password_reset"")
        data = {""email"": self.account_ko.email}
        response = self.client.post(url, data, follow=True)
        self.assertContains(
            response,
            ""We've emailed you instructions for setting your password"")
        self.assertEqual(len(mail.outbox), 0)


@skipIf(NO_SMTP, 'No SMTP server available')
@override_settings(AUTHENTICATION_BACKENDS=(
    ""modoboa.lib.authbackends.SMTPBackend"",
    ""django.contrib.auth.backends.ModelBackend""
))
class SMTPAuthenticationTestCase(ModoTestCase):
    """"""Validate SMTP authentication scenarios.""""""

    def _test_smtp_authentication(self, mock_smtp):
        """"""Common code to check authentication""""""
        self.client.logout()
        username = ""user@unknown.test""
        password = ""toto""
        data = {""username"": username, ""password"": password}
        response = self.client.post(reverse(""core:login""), data)
        self.assertEqual(response.status_code, 302)
        self.assertTrue(response.url.endswith(reverse(""core:user_index"")))
        mock_smtp.return_value.login.assert_called_once_with(
            username, password)
        self.assertTrue(
            models.User.objects.filter(username=username).exists())

    @patch(""smtplib.SMTP"")
    def test_smtp_authentication(self, mock_smtp):
        """"""Check simple SMTP authentication.""""""
        self._test_smtp_authentication(mock_smtp)

    @patch(""smtplib.SMTP_SSL"")
    @override_settings(AUTH_SMTP_SECURED_MODE=""ssl"")
    def test_smtp_authentication_over_ssl(self, mock_smtp):
        """"""Check SMTP authentication over SSL.""""""
        self._test_smtp_authentication(mock_smtp)

    @patch(""smtplib.SMTP"")
    @override_settings(AUTH_SMTP_SECURED_MODE=""starttls"")
    def test_smtp_authentication_over_starttls(self, mock_smtp):
        """"""Check SMTP authentication over STARTTLS.""""""
        self._test_smtp_authentication(mock_smtp)

    @patch(""smtplib.SMTP"")
    def test_smtp_authentication_failure(self, mock_smtp):
        """"""Check SMTP authentication failure.""""""
        instance = mock_smtp.return_value
        instance.login.side_effect = smtplib.SMTPAuthenticationError(
            450, ""User not found"")
        self.client.logout()
        username = ""user@unknown.test""
        password = ""toto""
        data = {""username"": username, ""password"": password}
        response = self.client.post(reverse(""core:login""), data)
        self.assertEqual(response.status_code, 401)
        mock_smtp.return_value.login.assert_called_once_with(
            username, password)
        self.assertFalse(
            models.User.objects.filter(username=username).exists())
/n/n/nmodoboa/core/views/base.py/n/n""""""Base core views.""""""

from __future__ import unicode_literals

from django.core.urlresolvers import reverse
from django.utils.http import is_safe_url
from django.views import generic

from django.contrib.auth import mixins as auth_mixins

from ..extensions import exts_pool


def find_nextlocation(request, user):
    """"""Find next location for given user after login.""""""
    if not user.last_login:
        # Redirect to profile on first login
        return reverse(""core:user_index"")
    nextlocation = request.POST.get(""next"", request.GET.get(""next""))
    condition = (
        nextlocation is not None and nextlocation != """" and
        is_safe_url(nextlocation, host=request.get_host())
    )
    if condition:
        return nextlocation
    if request.user.role == ""SimpleUsers"":
        topredir = request.localconfig.parameters.get_value(
            ""default_top_redirection"")
        if topredir != ""user"":
            infos = exts_pool.get_extension_infos(topredir)
            nextlocation = infos[""topredirection_url""]
        else:
            nextlocation = reverse(""core:user_index"")
    else:
        nextlocation = reverse(""core:dashboard"")
    return nextlocation


class RootDispatchView(auth_mixins.LoginRequiredMixin, generic.RedirectView):
    """"""Handle root dispatching based on role.""""""

    def get_redirect_url(self):
        """"""Find proper next hop.""""""
        return find_nextlocation(self.request, self.request.user)
/n/n/n",0
55,55,7c610e95d8fccc797e153781ecde013da604b242,"/modoboa/core/views/base.py/n/n""""""Base core views.""""""

from __future__ import unicode_literals

from django.core.urlresolvers import reverse
from django.views import generic

from django.contrib.auth import mixins as auth_mixins

from ..extensions import exts_pool


def find_nextlocation(request, user):
    """"""Find next location for given user after login.""""""
    if not user.last_login:
        # Redirect to profile on first login
        return reverse(""core:user_index"")
    nextlocation = request.POST.get(""next"", None)
    if nextlocation is None or nextlocation == ""None"":
        if request.user.role == ""SimpleUsers"":
            topredir = request.localconfig.parameters.get_value(
                ""default_top_redirection"")
            if topredir != ""user"":
                infos = exts_pool.get_extension_infos(topredir)
                nextlocation = infos[""topredirection_url""]
            else:
                nextlocation = reverse(""core:user_index"")
        else:
            nextlocation = reverse(""core:dashboard"")
    return nextlocation


class RootDispatchView(auth_mixins.LoginRequiredMixin, generic.RedirectView):
    """"""Handle root dispatching based on role.""""""

    def get_redirect_url(self):
        """"""Find proper next hop.""""""
        return find_nextlocation(self.request, self.request.user)
/n/n/n",1
120,120,78359f2763bc21d9952b3745056b94bec985774d,"scanner/scanner.py/n/nfrom bs4 import BeautifulSoup
import requests
import re

from typing import TYPE_CHECKING

from pshtt.pshtt import inspect_domains
import tldextract

from django.utils import timezone

from directory.models import ScanResult, DirectoryEntry
from scanner.utils import url_to_domain

if TYPE_CHECKING:
    from directory.models import DirectoryEntryQuerySet  # noqa: F401


def perform_scan(url: str) -> ScanResult:
    try:
        page, soup = request_and_scrape_page(url)

    except requests.exceptions.RequestException:
        # Connection timed out, an invalid HTTP response was returned, or
        # a network problem occurred.
        # Catch the base class exception for these cases.
        return ScanResult(
            live=False,
            http_status_200_ok=False,
        )

    scan_data = {
        'live': False,
        'landing_page_url': url,
    }
    http_response_data = parse_page_data(page)
    scan_data.update(http_response_data)

    content_data = parse_soup_data(soup)
    scan_data.update(content_data)

    if http_response_data['no_cross_domain_redirects'] is False:
        return ScanResult(**scan_data)

    pshtt_results = inspect_domains([url_to_domain(page.url)], {'timeout': 10})

    https_data = parse_pshtt_data(pshtt_results[0])
    scan_data.update(https_data)

    return ScanResult(**scan_data)


def scan(entry: DirectoryEntry, commit=False) -> ScanResult:
    """"""
    Scan a single site. This method accepts a DirectoryEntry instance which
    may or may not be saved to the database. You can optionally pass True for
    the commit argument, which will save the result to the database. In that
    case, the passed DirectoryEntry *must* already be in the database.
    """"""
    result = perform_scan(entry.landing_page_url)

    if commit:
        result.save()

    return result


def bulk_scan(securedrops: 'DirectoryEntryQuerySet') -> None:
    """"""
    This method takes a queryset and scans the securedrop pages. Unlike the
    scan method that takes a single SecureDrop instance, this method requires
    a DirectoryEntryQueryset of SecureDrop instances that are in the database
    and always commits the results back to the database.
    """"""

    # Ensure that we have the domain annotation present
    securedrops = securedrops.with_domain_annotation()

    results_to_be_written = []
    for entry in securedrops:
        current_result = perform_scan(entry.landing_page_url)

        # These are usually handled by Result.save, but since we're doing a
        # bulk save, we need to do them here first
        current_result.securedrop = entry

        # Before we save, let's get the most recent scan before saving
        try:
            prior_result = entry.results.latest()
        except ScanResult.DoesNotExist:
            results_to_be_written.append(current_result)
            continue

        if prior_result.is_equal_to(current_result):
            # Then let's not waste a row in the database
            prior_result.result_last_seen = timezone.now()
            prior_result.save()
        else:
            # Then let's add this new scan result to the database
            results_to_be_written.append(current_result)

    # Write new results to the db in a batch
    return ScanResult.objects.bulk_create(results_to_be_written)


def request_and_scrape_page(url, allow_redirects=True):
    """"""Scrape and parse the HTML of a page into a BeautifulSoup""""""
    try:
        page = requests.get(url, allow_redirects=allow_redirects)
        soup = BeautifulSoup(page.content, ""lxml"")
    except requests.exceptions.MissingSchema:
        page = requests.get('https://{}'.format(url), allow_redirects=allow_redirects)
        soup = BeautifulSoup(page.content, ""lxml"")

    return page, soup


def parse_page_data(page):
    http_response_data = {
        'no_cross_domain_redirects': True,
        'http_status_200_ok': validate_200_ok(page),
        'no_cookies': validate_no_cookies(page),
        'no_cdn': validate_not_using_cdn(page),
        'expected_encoding': validate_encoding(page),
        'no_analytics': validate_not_using_analytics(page),
        'no_server_info': validate_server_software(page),
        'no_server_version': validate_server_version(page),
        'csp_origin_only': validate_csp(page),
        'mime_sniffing_blocked': validate_no_sniff(page),
        'noopen_download': validate_download_options(page),
        'xss_protection': validate_xss_protection(page),
        'clickjacking_protection': validate_clickjacking_protection(page),
        'good_cross_domain_policy': validate_cross_domain_policy(page),
        'http_1_0_caching_disabled': validate_pragma(page),
        'expires_set': validate_expires(page),
        'cache_control_set': validate_cache_control_set(page),
        'cache_control_revalidate_set': validate_cache_must_revalidate(page),
        'cache_control_nocache_set': validate_nocache(page),
        'cache_control_notransform_set': validate_notransform(page),
        'cache_control_nostore_set': validate_nostore(page),
        'cache_control_private_set': validate_private(page),
        'referrer_policy_set_to_no_referrer': validate_no_referrer_policy(page),
    }
    if page.history:
        http_response_data['redirect_target'] = page.url

        target_domain = url_to_domain(page.url)
        for response in page.history:
            if url_to_domain(response.url) != target_domain:
                http_response_data['no_cross_domain_redirects'] = False
                break

    return http_response_data


def parse_soup_data(soup):
    return {
        'safe_onion_address': validate_onion_address_not_in_href(soup),
    }


def parse_pshtt_data(pshtt_data):
    return {
        'live': pshtt_data['Live'],
        'forces_https': bool(pshtt_data['Strictly Forces HTTPS']),
        'hsts': pshtt_data['HSTS'],
        'hsts_max_age': validate_hsts_max_age(pshtt_data['HSTS Max Age']),
        'hsts_entire_domain': validate_hsts_entire_domain(pshtt_data['HSTS Entire Domain']),
        'hsts_preloaded': pshtt_data['HSTS Preloaded'],
    }


def validate_subdomain(url):
    """"""Is the landing page on a subdomain""""""
    parsed_domain = tldextract.extract(url)
    return parsed_domain.subdomain not in ('', 'www')


def validate_not_using_cdn(page):
    """"""Right now this is just checking for Cloudflare""""""
    if 'CF-Cache-Status' in page.headers or 'CF-RAY' in page.headers:
        return False
    else:
        return True


def validate_not_using_analytics(page):
    """"""Scan for common analytics scripts anywhere in the page

    Google Analytics: https://support.google.com/analytics/answer/1032399?hl=en

    Chartbeat: http://support.chartbeat.com/docs/

    Quantcast: https://quantcast.zendesk.com/hc/en-us/articles/115014888548--Implement-Quantcast-Tag-Directly-on-Your-Site

    comScore: http://www.scorecardresearch.com/ (no public docs)

    Krux Digital: https://whotracks.me/trackers/krux_digital.html#News%20and%20Portals
    """"""
    # Common scripts: Google Analytics, Quantcast, Chartbeat (two variants),
    # comScore
    analytics_scripts = ('ga.js', 'analytics.js', 'quant.js',
                         'chartbeat.js', 'chartbeat_mab.js', 'beacon.js',
                         'krxd.net')
    page_str = str(page.content)
    for script in analytics_scripts:
        if script in page_str:
            return False

    # No recognized script in page body
    return True


def validate_security_header(page, header, expected_value):
    if header not in page.headers:
        return False
    elif page.headers[header] == expected_value:
        return True
    else:
        return False


def validate_cache_control_header(page, expected_directive):
    header = page.headers.get('Cache-Control', '')
    directives = [directive.lower().strip() for directive in header.split(',')]

    return expected_directive in directives


def validate_no_redirects(page):
    if page.is_redirect:
        return False
    else:
        return True


def validate_200_ok(page):
    if page.status_code == 200:
        return True
    else:
        return False


def validate_hsts_max_age(max_age):
    if max_age and max_age >= 16070400:
        return True
    else:
        return False


def validate_hsts_entire_domain(pshtt_result):
    # Ensures a boolean response for proper template rendering
    if pshtt_result:
        return True
    else:
        return False


def validate_encoding(page):
    if page.encoding is None:
        return False
    if page.encoding.upper() in ('UTF-8', 'ISO-8859-1'):
        return True
    else:
        return False


def validate_server_software(page):
    if 'Server' not in page.headers:
        return True
    else:
        server_header = str.lower(page.headers['Server'])
    if 'nginx' in server_header or 'apache' in server_header:
        return False
    else:
        return True


def validate_server_version(page):
    version_regex = re.compile(r'\d+.\d+')

    if 'Server' not in page.headers:
        return True
    else:
        matches = version_regex.search(page.headers['Server'])

    if not matches:
        return True
    elif len(matches.group()) > 1:
        return False
    else:
        return True


def validate_csp(page):
    if 'Content-Security-Policy' not in page.headers:
        return False
    elif ""default-src 'self'"" not in page.headers['Content-Security-Policy']:
        return False
    else:
        return True


def validate_xss_protection(page):
    return validate_security_header(
        page,
        ""X-XSS-Protection"",
        ""1; mode=block"",
    )


def validate_no_sniff(page):
    return validate_security_header(
        page,
        ""X-Content-Type-Options"",
        ""nosniff"",
    )


def validate_download_options(page):
    return validate_security_header(
        page,
        ""X-Download-Options"",
        ""noopen"",
    )


def validate_clickjacking_protection(page):
    return validate_security_header(
        page,
        ""X-Frame-Options"",
        ""DENY"",
    )


def validate_cross_domain_policy(page):
    return validate_security_header(
        page,
        ""X-Permitted-Cross-Domain-Policies"",
        ""master-only"",
    )


def validate_pragma(page):
    return validate_security_header(page, ""Pragma"", ""no-cache"")


def validate_expires(page):
    return validate_security_header(page, ""Expires"", ""-1"")


def validate_cache_control_set(page):
    if 'Cache-Control' in page.headers:
        return True
    else:
        return False


def validate_cache_must_revalidate(page):
    return validate_cache_control_header(page, 'must-revalidate')


def validate_nocache(page):
    return validate_cache_control_header(page, 'no-cache')


def validate_nostore(page):
    return validate_cache_control_header(page, 'no-store')


def validate_notransform(page):
    return validate_cache_control_header(page, 'no-transform')


def validate_private(page):
    return validate_cache_control_header(page, 'private')


def validate_no_referrer_policy(page):
    return validate_security_header(page, ""Referrer-Policy"", ""no-referrer"")


def validate_no_cookies(page):
    if len(page.cookies.keys()) > 0:
        return False
    else:
        return True


def validate_onion_address_not_in_href(page):
    links_on_landing_page = page.find_all(""a"")
    for link in links_on_landing_page:
        try:
            if '.onion' in link.attrs['href']:
                return False
        except KeyError:
            # This means there isn't an href in the link. That's fine.
            pass
    return True
/n/n/nscanner/tests/test_scanner.py/n/nimport os
from unittest import mock

from django.test import TestCase
import vcr

from scanner import scanner
from scanner.tests.utils import (
    NON_EXISTENT_URL,
    requests_get_mock,
)
from directory.models import DirectoryEntry
from directory.tests.factories import DirectoryEntryFactory


VCR_DIR = os.path.join(os.path.dirname(__file__), 'scans_vcr')


class ScannerTest(TestCase):
    """"""
    Tests the landing page scanner. These tests make use of vcrpy, which
    records HTTP responses to YAML cassettes in scans_vcr/ the first time the
    tests are run. Every time after that, it simulates the responses from those
    cassettes, making responses consistent and eliminating the need for a live
    network connection for running tests
    """"""

    @mock.patch(
        'scanner.scanner.requests.get',
        new=requests_get_mock
    )
    @mock.patch(
        'pshtt.pshtt.requests.get',
        new=requests_get_mock
    )
    @vcr.use_cassette(os.path.join(VCR_DIR, 'full-scan-site-not-live.yaml'))
    def test_scan_returns_result_if_site_not_live(self):
        """"""
        If a site cannot be connected to, scanner should return a ScanResult
        with result.live False

        In addition to vcrpy, this test mocks requests.get to simulate a
        ConnectionError for a URL that does not exist without actually sending
        an HTTP request to that URL
        """"""
        securedrop = DirectoryEntry(
            title='Freedom of the Press Foundation',
            landing_page_url=NON_EXISTENT_URL,
            onion_address='notreal.onion'
        )
        result = scanner.scan(securedrop)
        self.assertFalse(result.live)

    @vcr.use_cassette(os.path.join(VCR_DIR, 'full-scan-site-live.yaml'))
    def test_scan_returns_result_if_site_live(self):
        """"""
        If a site can be connected to, scanner should return a result with
        result.live True
        """"""
        securedrop = DirectoryEntry(
            title='Freedom of the Press Foundation',
            landing_page_url='https://securedrop.org',
            onion_address='notreal.onion'
        )
        result = scanner.scan(securedrop)
        self.assertTrue(result.live)

    @vcr.use_cassette(os.path.join(VCR_DIR, 'full-scan-site-live.yaml'))
    def test_scan_result_attributes(self):
        """"""
        If the site can be connected to, scanner should return a result with
        all its attributes set

        """"""
        securedrop = DirectoryEntry(
            title='Freedom of the Press Foundation',
            landing_page_url='https://securedrop.org',
            onion_address='notreal.onion'
        )
        result = scanner.scan(securedrop)

        self.assertTrue(result.forces_https)
        self.assertTrue(result.http_status_200_ok)
        self.assertTrue(result.hsts)
        self.assertFalse(result.hsts_max_age)
        self.assertTrue(result.hsts_entire_domain)
        self.assertTrue(result.hsts_preloaded)
        self.assertFalse(result.subdomain)
        self.assertTrue(result.no_cookies)
        self.assertTrue(result.safe_onion_address)
        self.assertFalse(result.no_cdn)
        self.assertIsNone(result.http_no_redirect)
        self.assertTrue(result.expected_encoding)
        self.assertTrue(result.no_analytics)
        self.assertTrue(result.no_server_info)
        self.assertTrue(result.no_server_version)
        self.assertFalse(result.csp_origin_only)
        self.assertFalse(result.mime_sniffing_blocked)
        self.assertFalse(result.noopen_download)
        self.assertFalse(result.xss_protection)
        self.assertFalse(result.clickjacking_protection)
        self.assertFalse(result.good_cross_domain_policy)
        self.assertFalse(result.http_1_0_caching_disabled)
        self.assertFalse(result.expires_set)
        self.assertTrue(result.cache_control_set)
        self.assertTrue(result.cache_control_revalidate_set)
        self.assertTrue(result.cache_control_nocache_set)
        self.assertIs(result.cache_control_notransform_set, False)
        self.assertIs(result.cache_control_nostore_set, False)
        self.assertIs(result.cache_control_private_set, False)
        self.assertIs(result.referrer_policy_set_to_no_referrer, False)

    @vcr.use_cassette(os.path.join(VCR_DIR, 'scan-site-with-trackers.yaml'))
    def test_scan_detects_presence_of_trackers(self):
        """"""
        If a site contains common trackers, result.no_analytics should be False
        """"""
        ap_site = DirectoryEntry(
            title='AP',
            landing_page_url='https://www.ap.org/en-us/',
            onion_address='notreal.onion'
        )
        result = scanner.scan(ap_site)
        self.assertFalse(result.no_analytics)

    @vcr.use_cassette(os.path.join(VCR_DIR, 'scan-site-without-trackers.yaml'))
    def test_scan_detects_absence_of_trackers(self):
        """"""
        If a site contains no known trackers, result.no_analytics should be True
        """"""
        fpf_site = DirectoryEntry(
            title='FPF',
            landing_page_url='https://freedom.press/',
            onion_address='notreal.onion'
        )
        result = scanner.scan(fpf_site)
        self.assertTrue(result.no_analytics)

    @vcr.use_cassette(os.path.join(VCR_DIR, 'scrape-securedrop-dot-org.yaml'))
    def test_request_gets_page_if_protocol_identifier_present(self):
        ""request_and_scrape_page should handle a URL with a protocol""
        url = 'https://securedrop.org'
        page, soup = scanner.request_and_scrape_page(url)
        self.assertIn('SecureDrop Directory', str(page.content))

    @vcr.use_cassette(os.path.join(VCR_DIR, 'scrape-securedrop-dot-org.yaml'))
    def test_request_gets_page_if_protocol_identifier_not_present(self):
        ""request_and_scrape_page should handle a URL without a protocol""
        url = 'securedrop.org'
        page, soup = scanner.request_and_scrape_page(url)
        self.assertIn('SecureDrop Directory', str(page.content))

    @vcr.use_cassette(os.path.join(VCR_DIR, 'full-scan-site-live.yaml'))
    def test_scan_and_commit(self):
        """"""
        When scanner.scan is called with commit=True, the result of the scan
        should be newly saved to the database and associated with the
        correct DirectoryEntry
        """"""
        securedrop = DirectoryEntryFactory.create(
            title='Freedom of the Press Foundation',
            landing_page_url='https://securedrop.org',
            onion_address='notreal.onion'
        )
        self.assertEqual(
            0, DirectoryEntry.objects.get(pk=securedrop.pk).results.count()
        )
        scanner.scan(securedrop, commit=True)
        self.assertEqual(
            1, DirectoryEntry.objects.get(pk=securedrop.pk).results.count()
        )

    @vcr.use_cassette(os.path.join(VCR_DIR, 'full-scan-site-live.yaml'))
    def test_scan_and_no_commit(self):
        """"""
        When scanner.scan is called without commit=True, it should not save
        any results to the database
        """"""
        securedrop = DirectoryEntryFactory.create(
            title='Freedom of the Press Foundation',
            landing_page_url='https://securedrop.org',
            onion_address='notreal.onion'
        )
        scanner.scan(securedrop)
        self.assertEqual(
            0, DirectoryEntry.objects.get(pk=securedrop.pk).results.count()
        )

    @vcr.use_cassette(os.path.join(VCR_DIR, 'bulk-scan.yaml'))
    def test_bulk_scan(self):
        """"""
        When scanner.bulk_scan is called, it should save all new results to the
        database, associated with the correct DirectoryEntrys
        """"""
        DirectoryEntryFactory.create(
            title='SecureDrop',
            landing_page_url='https://securedrop.org',
            onion_address='notreal.onion'
        )
        DirectoryEntryFactory.create(
            title='Freedom of the Press Foundation',
            landing_page_url='https://freedom.press',
            onion_address='notreal-2.onion'
        )

        securedrop_pages_qs = DirectoryEntry.objects.all()
        scanner.bulk_scan(securedrop_pages_qs)

        for page in DirectoryEntry.objects.all():
            self.assertEqual(
                1, page.results.count()
            )

    @mock.patch(
        'scanner.scanner.requests.get',
        new=requests_get_mock
    )
    @mock.patch(
        'pshtt.pshtt.requests.get',
        new=requests_get_mock
    )
    @vcr.use_cassette(os.path.join(VCR_DIR, 'bulk-scan-not-live.yaml'))
    def test_bulk_scan_not_live(self):
        """"""
        When scanner.bulk_scan is called, it should save all new results to the
        database, even if one of the instances cannot be reached by HTTP. It
        should save a result to the database for the instance that cannot be
        reached by HTTP with live False

        In addition to vcrpy, this test mocks requests.get to simulate a
        ConnectionError for a URL that does not exist without actually sending
        an HTTP request to that URL
        """"""

        sd1 = DirectoryEntryFactory.create(
            title='SecureDrop',
            landing_page_url='https://securedrop.org',
            onion_address='notreal.onion'
        )
        sd2 = DirectoryEntryFactory.create(
            title='Freedom of the Press Foundation',
            landing_page_url=NON_EXISTENT_URL,
            onion_address='notreal-2.onion'
        )
        sd3 = DirectoryEntryFactory.create(
            title='Freedom of the Press Foundation',
            landing_page_url='https://freedom.press',
            onion_address='notreal-3.onion'
        )

        securedrop_pages_qs = DirectoryEntry.objects.all()
        scanner.bulk_scan(securedrop_pages_qs)

        self.assertTrue(
            DirectoryEntry.objects.get(pk=sd1.pk).results.all()[0].live
        )
        self.assertFalse(
            DirectoryEntry.objects.get(pk=sd2.pk).results.all()[0].live
        )
        self.assertTrue(
            DirectoryEntry.objects.get(pk=sd3.pk).results.all()[0].live
        )

    @vcr.use_cassette(os.path.join(VCR_DIR, 'scrape-sourceanonyme.yaml'))
    def test_forces_https_should_not_be_none(self):
        domain = 'https://sourceanonyme.radio-canada.ca'

        entry = DirectoryEntryFactory.create(
            title='Source Anonyme',
            landing_page_url=domain,
            onion_address='notreal.onion'
        )
        r = scanner.scan(entry, commit=True)
        self.assertIsNotNone(r.forces_https)


class ScannerRedirectionSuccess(TestCase):
    @vcr.use_cassette(os.path.join(VCR_DIR, 'scan-with-good-redirection.yaml'))
    def test_redirect_target_saved(self):
        entry = DirectoryEntryFactory.create(
            title='SecureDrop',
            landing_page_url='https://httpbin.org/redirect/3',
            onion_address='notreal.onion',
        )

        result = scanner.scan(entry)
        self.assertEqual(result.redirect_target, 'https://httpbin.org/get')

    @vcr.use_cassette(os.path.join(VCR_DIR, 'scan-with-permanent-redirection.yaml'))
    def test_permanent_redirect_target_saved(self):
        entry = DirectoryEntryFactory.create(
            title='SecureDrop',
            landing_page_url='https://httpbin.org/redirect-to?status_code=301&url=https%3A%2F%2Fhttpbin.org%2Fget',
            onion_address='notreal.onion',
        )

        result = scanner.scan(entry)
        self.assertEqual(result.redirect_target, 'https://httpbin.org/get')

    @vcr.use_cassette(os.path.join(VCR_DIR, 'scan-with-no-redirection.yaml'))
    def test_redirect_target_not_saved_if_not_redirect(self):
        entry = DirectoryEntryFactory.create(
            title='SecureDrop',
            landing_page_url='https://securedrop.org',
            onion_address='notreal.onion',
        )

        result = scanner.scan(entry)
        self.assertIsNone(result.redirect_target)

    @vcr.use_cassette(os.path.join(VCR_DIR, 'scan-with-redirection-not-found.yaml'))
    def test_redirection_not_200(self):
        entry = DirectoryEntryFactory.create(
            title='SecureDrop',
            landing_page_url='https://httpbin.org/redirect-to?url=https%3A%2F%2Fhttpbin.org%2Fstatus%2F404',
            onion_address='notreal.onion',
        )

        result = scanner.scan(entry)
        self.assertEqual(result.redirect_target, 'https://httpbin.org/status/404')
        self.assertFalse(result.http_status_200_ok)


class ScannerCrossDomainRedirect(TestCase):
    @vcr.use_cassette(os.path.join(VCR_DIR, 'scan-with-cross-domain-redirection.yaml'))
    def test_cross_domain_redirect_detected_and_saved(self):
        entry = DirectoryEntryFactory.create(
            title='SecureDrop',
            landing_page_url='https://httpbin.org/redirect-to?url=http%3A%2F%2Fwww.google.com&status_code=302',
            onion_address='notreal.onion',
        )

        r = scanner.scan(entry)
        self.assertFalse(r.no_cross_domain_redirects)
/n/n/n",0
121,121,78359f2763bc21d9952b3745056b94bec985774d,"/scanner/scanner.py/n/nfrom bs4 import BeautifulSoup
import requests
import re

from typing import Dict, TYPE_CHECKING

from pshtt.pshtt import inspect_domains
import tldextract

from django.utils import timezone

from directory.models import ScanResult, DirectoryEntry
from scanner.utils import url_to_domain

if TYPE_CHECKING:
    from directory.models import DirectoryEntryQuerySet  # noqa: F401


def pshtt_data_to_result(securedrop: DirectoryEntry, pshtt_results: Dict) -> ScanResult:
    """"""
    Takes a DirectoryEntry and a dictionary of pshtt results for that domain,
    scans the page itself and then combines those results into an unsaved
    ScanResult object
    """"""
    try:
        page, soup = request_and_scrape_page(securedrop.landing_page_url)

        # In order to check the HTTP status code and redirect status, we must
        # pass
        no_redirects_page, _ = request_and_scrape_page(
            securedrop.landing_page_url, allow_redirects=False
        )
    except requests.exceptions.RequestException:
        # Connection timed out, an invalid HTTP response was returned, or
        # a network problem occurred.
        # Catch the base class exception for these cases.
        return ScanResult(
            securedrop=securedrop,
            live=pshtt_results['Live'],
            http_status_200_ok=False,
        )

    return ScanResult(
        landing_page_url=securedrop.landing_page_url,
        live=pshtt_results['Live'],
        http_status_200_ok=validate_200_ok(no_redirects_page),
        forces_https=bool(pshtt_results['Strictly Forces HTTPS']),
        hsts=pshtt_results['HSTS'],
        hsts_max_age=validate_hsts_max_age(pshtt_results['HSTS Max Age']),
        hsts_entire_domain=validate_hsts_entire_domain(pshtt_results['HSTS Entire Domain']),
        hsts_preloaded=pshtt_results['HSTS Preloaded'],
        subdomain=validate_subdomain(securedrop.landing_page_url),
        no_cookies=validate_no_cookies(page),
        safe_onion_address=validate_onion_address_not_in_href(soup),
        no_cdn=validate_not_using_cdn(page),
        http_no_redirect=validate_no_redirects(no_redirects_page),
        expected_encoding=validate_encoding(page),
        no_analytics=validate_not_using_analytics(page),
        no_server_info=validate_server_software(page),
        no_server_version=validate_server_version(page),
        csp_origin_only=validate_csp(page),
        mime_sniffing_blocked=validate_no_sniff(page),
        noopen_download=validate_download_options(page),
        xss_protection=validate_xss_protection(page),
        clickjacking_protection=validate_clickjacking_protection(page),
        good_cross_domain_policy=validate_cross_domain_policy(page),
        http_1_0_caching_disabled=validate_pragma(page),
        expires_set=validate_expires(page),
        cache_control_set=validate_cache_control_set(page),
        cache_control_revalidate_set=validate_cache_must_revalidate(page),
        cache_control_nocache_set=validate_nocache(page),
        cache_control_notransform_set=validate_notransform(page),
        cache_control_nostore_set=validate_nostore(page),
        cache_control_private_set=validate_private(page),
        referrer_policy_set_to_no_referrer=validate_no_referrer_policy(page),
    )


def scan(securedrop: DirectoryEntry, commit=False) -> ScanResult:
    """"""
    Scan a single site. This method accepts a DirectoryEntry instance which
    may or may not be saved to the database. You can optionally pass True for
    the commit argument, which will save the result to the database. In that
    case, the passed DirectoryEntry *must* already be in the database.
    """"""

    securedrop_domain = url_to_domain(securedrop.landing_page_url)
    pshtt_results = inspect_domains([securedrop_domain], {'timeout': 10})
    result = pshtt_data_to_result(securedrop, pshtt_results[0])

    if commit:
        result.securedrop = securedrop
        result.save()

    return result


def bulk_scan(securedrops: 'DirectoryEntryQuerySet') -> None:
    """"""
    This method takes a queryset and scans the securedrop pages. Unlike the
    scan method that takes a single SecureDrop instance, this method requires
    a DirectoryEntryQueryset of SecureDrop instances that are in the database
    and always commits the results back to the database.
    """"""

    # Ensure that we have the domain annotation present
    securedrops = securedrops.with_domain_annotation()
    domains = securedrops.values_list('domain', flat=True)

    # Send the domains to pshtt. This will trigger HTTP requests for each domain
    # and can take some time!
    results = inspect_domains(domains, {'timeout': 10})

    results_to_be_written = []
    for result_data in results:
        securedrop = securedrops.get(domain=result_data['Domain'])
        current_result = pshtt_data_to_result(securedrop, result_data)

        # These are usually handled by Result.save, but since we're doing a
        # bulk save, we need to do them here first
        current_result.compute_grade()
        current_result.securedrop = securedrop

        # Before we save, let's get the most recent scan before saving
        try:
            prior_result = securedrop.results.latest()
        except ScanResult.DoesNotExist:
            results_to_be_written.append(current_result)
            continue

        if prior_result.is_equal_to(current_result):
            # Then let's not waste a row in the database
            prior_result.result_last_seen = timezone.now()
            prior_result.save()
        else:
            # Then let's add this new scan result to the database
            results_to_be_written.append(current_result)

    # Write new results to the db in a batch
    return ScanResult.objects.bulk_create(results_to_be_written)


def request_and_scrape_page(url, allow_redirects=True):
    """"""Scrape and parse the HTML of a page into a BeautifulSoup""""""
    try:
        page = requests.get(url, allow_redirects=allow_redirects)
        soup = BeautifulSoup(page.content, ""lxml"")
    except requests.exceptions.MissingSchema:
        page = requests.get('https://{}'.format(url), allow_redirects=allow_redirects)
        soup = BeautifulSoup(page.content, ""lxml"")

    return page, soup


def validate_subdomain(url):
    """"""Is the landing page on a subdomain""""""
    parsed_domain = tldextract.extract(url)
    return parsed_domain.subdomain not in ('', 'www')


def validate_not_using_cdn(page):
    """"""Right now this is just checking for Cloudflare""""""
    if 'CF-Cache-Status' in page.headers or 'CF-RAY' in page.headers:
        return False
    else:
        return True


def validate_not_using_analytics(page):
    """"""Scan for common analytics scripts anywhere in the page

    Google Analytics: https://support.google.com/analytics/answer/1032399?hl=en

    Chartbeat: http://support.chartbeat.com/docs/

    Quantcast: https://quantcast.zendesk.com/hc/en-us/articles/115014888548--Implement-Quantcast-Tag-Directly-on-Your-Site

    comScore: http://www.scorecardresearch.com/ (no public docs)

    Krux Digital: https://whotracks.me/trackers/krux_digital.html#News%20and%20Portals
    """"""
    # Common scripts: Google Analytics, Quantcast, Chartbeat (two variants),
    # comScore
    analytics_scripts = ('ga.js', 'analytics.js', 'quant.js',
                         'chartbeat.js', 'chartbeat_mab.js', 'beacon.js',
                         'krxd.net')
    page_str = str(page.content)
    for script in analytics_scripts:
        if script in page_str:
            return False

    # No recognized script in page body
    return True


def validate_security_header(page, header, expected_value):
    if header not in page.headers:
        return False
    elif page.headers[header] == expected_value:
        return True
    else:
        return False


def validate_cache_control_header(page, expected_directive):
    header = page.headers.get('Cache-Control', '')
    directives = [directive.lower().strip() for directive in header.split(',')]

    return expected_directive in directives


def validate_no_redirects(page):
    if page.is_redirect:
        return False
    else:
        return True


def validate_200_ok(page):
    if page.status_code == 200:
        return True
    else:
        return False


def validate_hsts_max_age(max_age):
    if max_age and max_age >= 16070400:
        return True
    else:
        return False


def validate_hsts_entire_domain(pshtt_result):
    # Ensures a boolean response for proper template rendering
    if pshtt_result:
        return True
    else:
        return False


def validate_encoding(page):
    if page.encoding is None:
        return False
    if page.encoding.upper() in ('UTF-8', 'ISO-8859-1'):
        return True
    else:
        return False


def validate_server_software(page):
    if 'Server' not in page.headers:
        return True
    else:
        server_header = str.lower(page.headers['Server'])
    if 'nginx' in server_header or 'apache' in server_header:
        return False
    else:
        return True


def validate_server_version(page):
    version_regex = re.compile(r'\d+.\d+')

    if 'Server' not in page.headers:
        return True
    else:
        matches = version_regex.search(page.headers['Server'])

    if not matches:
        return True
    elif len(matches.group()) > 1:
        return False
    else:
        return True


def validate_csp(page):
    if 'Content-Security-Policy' not in page.headers:
        return False
    elif ""default-src 'self'"" not in page.headers['Content-Security-Policy']:
        return False
    else:
        return True


def validate_xss_protection(page):
    return validate_security_header(
        page,
        ""X-XSS-Protection"",
        ""1; mode=block"",
    )


def validate_no_sniff(page):
    return validate_security_header(
        page,
        ""X-Content-Type-Options"",
        ""nosniff"",
    )


def validate_download_options(page):
    return validate_security_header(
        page,
        ""X-Download-Options"",
        ""noopen"",
    )


def validate_clickjacking_protection(page):
    return validate_security_header(
        page,
        ""X-Frame-Options"",
        ""DENY"",
    )


def validate_cross_domain_policy(page):
    return validate_security_header(
        page,
        ""X-Permitted-Cross-Domain-Policies"",
        ""master-only"",
    )


def validate_pragma(page):
    return validate_security_header(page, ""Pragma"", ""no-cache"")


def validate_expires(page):
    return validate_security_header(page, ""Expires"", ""-1"")


def validate_cache_control_set(page):
    if 'Cache-Control' in page.headers:
        return True
    else:
        return False


def validate_cache_must_revalidate(page):
    return validate_cache_control_header(page, 'must-revalidate')


def validate_nocache(page):
    return validate_cache_control_header(page, 'no-cache')


def validate_nostore(page):
    return validate_cache_control_header(page, 'no-store')


def validate_notransform(page):
    return validate_cache_control_header(page, 'no-transform')


def validate_private(page):
    return validate_cache_control_header(page, 'private')


def validate_no_referrer_policy(page):
    return validate_security_header(page, ""Referrer-Policy"", ""no-referrer"")


def validate_no_cookies(page):
    if len(page.cookies.keys()) > 0:
        return False
    else:
        return True


def validate_onion_address_not_in_href(page):
    links_on_landing_page = page.find_all(""a"")
    for link in links_on_landing_page:
        try:
            if '.onion' in link.attrs['href']:
                return False
        except KeyError:
            # This means there isn't an href in the link. That's fine.
            pass
    return True
/n/n/n",1
114,114,edad6dd8f6bfabce4d4f7b9e120df3ebcc8d9c33,"mysite/core/common/onboarding.py/n/nUSER_ID = 'user_id'
STEP_1 = 'view_introduction'
STEP_2 = 'test_courselet'
STEP_3 = 'create_course'
STEP_4 = 'create_courselet'
STEP_5 = 'create_thread'
STEP_6 = 'preview_courselet'
STEP_7 = 'next_steps'

# settings

INTRODUCTION_COURSE_ID = 'introduction_course_id'
VIEW_INTRODUCTION = STEP_1
INTRODUCTION_INTRO = STEP_2
CREATE_COURSE = STEP_3
CREATE_COURSELET = STEP_4
CREATE_THREAD = STEP_5
PREVIEW_COURSELET = STEP_6
NEXT_STEPS = STEP_7
/n/n/nmysite/core/common/utils.py/n/n""""""
Various utilities.
""""""
import functools

from django.dispatch import receiver
from django.conf import settings
from django.core.mail import send_mail
from django.template import loader, Context

from core.common.mongo import c_onboarding_status, c_onboarding_settings
from core.common import onboarding


def send_email(context_data, from_email, to_email, template_subject, template_text):
    """"""
    Send an email with specified content.

    Arguments:
        context_data (dict): data to be passed to templates.
        from_email (str): sender's email.
        to_email (list): list of addresses to send an email to.
        template_subject (str): path to a subject template, e.g. 'ctms/email/subject.txt'
        template_text (str):  path to a body template, e.g. 'ctms/email/text.txt'
    """"""
    context = Context(context_data)

    subj_template = loader.get_template(template_subject)
    rendered_subj = subj_template.render(context)

    text_template = loader.get_template(template_text)
    rendered_text = text_template.render(context)

    send_mail(
        rendered_subj,
        rendered_text,
        from_email,
        to_email,
        fail_silently=True
    )


def suspending_receiver(signal, **decorator_kwargs):
    """"""
    Custom decorator to disable signals.

    Reference:
        https://devblog.kogan.com/blog/disable-signal-receivers-in-your-django-tests
    """"""

    def our_wrapper(func):
        @receiver(signal, **decorator_kwargs)
        @functools.wraps(func)
        def fake_receiver(sender, **kwargs):
            if settings.SUSPEND_SIGNALS:
                return
            return func(sender, **kwargs)

        return fake_receiver

    return our_wrapper


def get_onboarding_steps():
    """"""
    Get fields from somewhere, haven't decided yet

    Return list of steps to be done
    """"""
    return [
        onboarding.STEP_1,
        onboarding.STEP_2,
        onboarding.STEP_3,
        onboarding.STEP_4,
        onboarding.STEP_5,
        onboarding.STEP_6,
        onboarding.STEP_7,
    ]


def get_onboarding_percentage(user_id):
    if user_id:
        status = c_onboarding_status(use_secondary=True).find_one({onboarding.USER_ID: user_id}) or {}
        if status:
            steps = [status.get(key, False) for key in get_onboarding_steps()]
            return round(
                len(filter(lambda x: x, steps)) / float(len(steps)) * 100,
                0
            )
    return 0


def update_onboarding_step(step, user_id):
    find_crit = {onboarding.USER_ID: user_id}
    onboarding_data = c_onboarding_status(use_secondary=True).find_one(find_crit)
    if not onboarding_data or not onboarding_data.get(step):
        c_onboarding_status().update_one(find_crit, {'$set': {
            step: True
        }}, upsert=True)


ONBOARDING_STEPS_DEFAULT_TEMPLATE = {
    'title': '',
    'description': '',
    'html': ''
}

ONBOARDING_SETTINGS_DEFAULT = {
    onboarding.INTRODUCTION_COURSE_ID: settings.ONBOARDING_INTRODUCTION_COURSE_ID,
    onboarding.VIEW_INTRODUCTION: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.INTRODUCTION_INTRO: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.CREATE_COURSE: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.CREATE_COURSELET: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.CREATE_THREAD: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.PREVIEW_COURSELET: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.NEXT_STEPS: ONBOARDING_STEPS_DEFAULT_TEMPLATE
}


# TODO: write unit tests
def get_onboarding_setting(setting_name):
    """"""
    Return settings for the certain `settings_name`
    If it does not exist take default settings and save it to the MongoDB
    Argument:
        setting_name (str): name of setting e.g. `create_course`
    Return:
        dict object with the data. See ONBOARDING_STEPS_DEFAULT_TEMPLATE
    """"""
    try:
        ONBOARDING_SETTINGS_DEFAULT[setting_name]
    except KeyError:
        return

    onboarding_setting = c_onboarding_settings(use_secondary=True).find_one({'name': setting_name})
    if not onboarding_setting:
        c_onboarding_settings().insert({'name': setting_name, 'data': ONBOARDING_SETTINGS_DEFAULT[setting_name]})
        return ONBOARDING_SETTINGS_DEFAULT[setting_name]
    return onboarding_setting['data']


# TODO: refactor this, settings for each step no need longer
def get_onboarding_status_with_settings(user_id):
    """"""
    Return combined data with the status by on-boarding steps (done: true/false)
    and settings for according status name
    Argument:
        user_id (int): user's id
    Return:
        dict with data
    Example:
    {
        ""instructor_intro"": {
            ""done"": true,
            ""settings"": {
                ""html"": """",
                ""description"": """",
                ""title"": """"
            }
        },
        ""create_course"": {
            ""done"": true,
            ""settings"": {
                ""html"": """",
                ""description"": """",
                ""title"": """"
            }
        },
        ""create_courselet"": {
            ""done"": false,
            ""settings"": {
                ""html"": """",
                ""description"": """",
                ""title"": """"
            }
        },
        ""review_answers"": {
            ""done"": true,
            ""settings"": {
                ""html"": ""<p>Title</p>"",
                ""description"": ""Here is some description"",
                ""title"": ""Title""
            }
        },
        ""invite_somebody"": {
            ""done"": true,
            ""settings"": {
                ""html"": """",
                ""description"": """",
                ""title"": """"
            }
        },
        ""create_thread"": {
            ""done"": false,
            ""settings"": {
                ""html"": """",
                ""description"": """",
                ""title"": """"
            }
        }
    }
    """"""
    onboarding_status = c_onboarding_status().find_one({onboarding.USER_ID: user_id}, {'_id': 0, 'user_id': 0}) or {}
    data = {}

    for step in get_onboarding_steps():
        data[step] = {
            'done': onboarding_status.get(step, False)
        }
    return data


/n/n/nmysite/core/tests/utils.py/n/n""""""
Test core utility functions.
""""""
import mock
from unittest import skip
from ddt import ddt, data, unpack
from django.conf import settings
from django.contrib.sites.models import Site
from django.core import mail
from django.test import TestCase

from core.common.utils import send_email, get_onboarding_percentage
from core.common import onboarding
from core.common.utils import get_onboarding_setting, ONBOARDING_STEPS_DEFAULT_TEMPLATE, \
    get_onboarding_status_with_settings


@ddt
class UtilityTest(TestCase):
    """"""
    Test auxiliary functions.
    """"""

    def test_send_email(self):
        """"""
        Test email sending.

        Ensure an email has proper subject and body.
        """"""
        send_email(
            context_data={
                ""milestone"": ""first"",
                ""students_number"": 2,
                ""course_title"": ""Test Course"",
                ""lesson_title"": ""Test Lesson"",
                ""current_site"": Site.objects.get_current(),
                ""course_id"": 1,
                ""unit_lesson_id"": 1,
                ""courselet_pk"": 1
            },
            from_email=settings.EMAIL_FROM,
            to_email=[""test@example.com""],
            template_subject=""ct/email/milestone_ortc_notify_subject"",
            template_text=""ct/email/milestone_ortc_notify_text""
        )

        self.assertEqual(len(mail.outbox), 1)

        # FIXME: outbox properties do not get overridden
        # self.assertEqual(mail.outbox[0].from_email, settings.EMAIL_FROM)
        # self.assertEqual(mail.outbox[0].to, ""test@example.com"")
        # self.assertContains(mail.outbox[0].subject, ""2"")
        # self.assertContains(mail.outbox[0].subject, ""first"")
        # self.assertContains(mail.outbox[0].body, ""first"")
        # self.assertContains(mail.outbox[0].body, ""2"")
        # self.assertContains(mail.outbox[0].body, ""Test Course"")
        # self.assertContains(mail.outbox[0].body, ""Test Lesson"")

    @mock.patch('core.common.utils.c_onboarding_status')
    @unpack
    @data(
        ({onboarding.STEP_1: 0, onboarding.STEP_2: 0, onboarding.STEP_3: 0, onboarding.STEP_4: 0, onboarding.STEP_5: 0, onboarding.STEP_6: 0, onboarding.STEP_7: 0}, 0),
        ({onboarding.STEP_1: 1, onboarding.STEP_2: 0, onboarding.STEP_3: 0, onboarding.STEP_4: 0, onboarding.STEP_5: 0, onboarding.STEP_6: 0, onboarding.STEP_7: 0}, 14.0),
        ({onboarding.STEP_1: 0, onboarding.STEP_2: 1, onboarding.STEP_3: 0, onboarding.STEP_4: 0, onboarding.STEP_5: 0, onboarding.STEP_6: 1, onboarding.STEP_7: 1}, 43.0),
        ({onboarding.STEP_1: 0, onboarding.STEP_2: 0, onboarding.STEP_3: 1, onboarding.STEP_4: 1, onboarding.STEP_5: 1, onboarding.STEP_6: 1, onboarding.STEP_7: 0}, 57.0),
        ({onboarding.STEP_1: 1, onboarding.STEP_2: 0, onboarding.STEP_3: 1, onboarding.STEP_4: 1, onboarding.STEP_5: 1, onboarding.STEP_6: 1, onboarding.STEP_7: 1}, 86.0),
        ({onboarding.STEP_1: 1, onboarding.STEP_2: 1, onboarding.STEP_3: 1, onboarding.STEP_4: 1, onboarding.STEP_5: 1, onboarding.STEP_6: 1, onboarding.STEP_7: 1}, 100.0)
    )
    def test_percentage_of_done(self, steps, result, mock):
        _mock = mock.return_value
        _mock.find_one.return_value = steps
        self.assertEqual(get_onboarding_percentage(1), result)

    @mock.patch('core.common.utils.c_onboarding_status')
    @unpack
    @data(
        (onboarding.INTRODUCTION_COURSE_ID, settings.ONBOARDING_INTRODUCTION_COURSE_ID),
        (onboarding.VIEW_INTRODUCTION, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.INTRODUCTION_INTRO, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.CREATE_COURSE, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.CREATE_COURSELET, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.CREATE_THREAD, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.PREVIEW_COURSELET, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.NEXT_STEPS, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        # nonexistent key
        ('fake_key', None)
    )
    def test_get_onboarding_setting(self, setting_name, value, _mock):
        self.assertEqual(get_onboarding_setting(setting_name), value)

    @skip
    @mock.patch('core.common.utils.get_onboarding_setting')
    @mock.patch('core.common.utils.c_onboarding_status')
    def test_get_onboarding_status_with_settings(self, status_mock, settings_mock):

        def mocked_setting(setting_name):
            data = {
                onboarding.INTRODUCTION_INTRO: {
                    ""html"": ""<p>instructor_intro</p>"",
                    ""description"": ""instructor_intro desc"",
                    ""title"": ""instructor_intro""
                },
                onboarding.CREATE_COURSE: {
                    ""html"": ""<p>create_course</p>"",
                    ""description"": ""create_course desc"",
                    ""title"": ""create_course""
                },
                onboarding.CREATE_COURSELET: {
                    ""html"": ""<p>create_courselet</p>"",
                    ""description"": ""create_courselet desc"",
                    ""title"": ""create_courselet""
                },
                onboarding.NEXT_STEPS: {
                    ""html"": ""<p>next_steps</p>"",
                    ""description"": ""next_steps desc"",
                    ""title"": ""next_steps""
                },
                onboarding.CREATE_THREAD: {
                    ""html"": ""<p>create_thread</p>"",
                    ""description"": ""create_thread desc"",
                    ""title"": ""create_thread""
                },
                onboarding.VIEW_INTRODUCTION: {
                    ""html"": ""<p>view_introduction</p>"",
                    ""description"": ""view_introduction desc"",
                    ""title"": ""view_introduction""
                },
                onboarding.PREVIEW_COURSELET: {
                    ""html"": ""<p>preview_courselet</p>"",
                    ""description"": ""preview_courselet desc"",
                    ""title"": ""preview_courselet""
                }
            }
            return data[setting_name]

        expected_result = {
            onboarding.INTRODUCTION_INTRO: {
                ""done"": False,
                ""settings"": {
                    ""html"": ""<p>instructor_intro</p>"",
                    ""description"": ""instructor_intro desc"",
                    ""title"": ""instructor_intro""
                }
            },
            onboarding.CREATE_COURSE: {
                ""done"": True,
                ""settings"": {
                    ""html"": ""<p>create_course</p>"",
                    ""description"": ""create_course desc"",
                    ""title"": ""create_course""
                }
            },
            onboarding.CREATE_COURSELET: {
                ""done"": False,
                ""settings"": {
                    ""html"": ""<p>create_courselet</p>"",
                    ""description"": ""create_courselet desc"",
                    ""title"": ""create_courselet""
                }
            },
            onboarding.NEXT_STEPS: {
                ""done"": False,
                ""settings"": {
                    ""html"": ""<p>next_steps</p>"",
                    ""description"": ""next_steps desc"",
                    ""title"": ""next_steps""
                }
            },
            onboarding.CREATE_THREAD: {
                ""done"": False,
                ""settings"": {
                    ""html"": ""<p>create_thread</p>"",
                    ""description"": ""create_thread desc"",
                    ""title"": ""create_thread""
                }
            },
            onboarding.VIEW_INTRODUCTION: {
                ""done"": False,
                ""settings"": {
                    ""html"": ""<p>view_introduction</p>"",
                    ""description"": ""view_introduction desc"",
                    ""title"": ""view_introduction""
                }
            },
            onboarding.PREVIEW_COURSELET: {
                ""done"": False,
                ""settings"": {
                    ""html"": ""<p>preview_courselet</p>"",
                    ""description"": ""preview_courselet desc"",
                    ""title"": ""preview_courselet""
                }
            }
        }
        status_mock = status_mock.return_value
        status_mock.find_one.return_value = {
            onboarding.VIEW_INTRODUCTION: False,
            onboarding.INTRODUCTION_INTRO: False,
            onboarding.CREATE_COURSE: True,
            onboarding.CREATE_COURSELET: False,
            onboarding.CREATE_THREAD: False,
            onboarding.NEXT_STEPS: False,
            onboarding.PREVIEW_COURSELET: False
        }
        settings_mock.side_effect = mocked_setting
        user_id = 1  # value doesn't matter
        data = get_onboarding_status_with_settings(user_id)
        self.assertEqual(data, expected_result)
/n/n/nmysite/ct/management/commands/onboarding_preprocess.py/n/n
from django.core.management.base import BaseCommand

from ct.models import Course, Role, UnitLesson, Unit, Lesson, Response
from ctms.models import Invite
from chat.models import Chat, EnrollUnitCode
from accounts.models import Instructor
from core.common.utils import update_onboarding_step, get_onboarding_percentage
from core.common import onboarding
from django.conf import settings


class Command(BaseCommand):
    help = 'Onboarding preprocessing'

    def handle(self, *args, **options):
        try:
            course = Course.objects.get(id=settings.ONBOARDING_INTRODUCTION_COURSE_ID)
        except Course.DoesNotExist:
            print(""Onboarding course is not provided"")
            return

        for instructor in Instructor.objects.all():

            chat_exists = Chat.objects.filter(
                user=instructor.user,
                enroll_code__courseUnit__course=course,
                progress__gte=70
            ).exists()
            if chat_exists:
                update_onboarding_step(onboarding.STEP_2, instructor.user_id)

            # if instructor has created create_course

            if Course.objects.filter(addedBy=instructor.user).exists():
                update_onboarding_step(onboarding.STEP_3, instructor.user_id)

            # if instructor has created a create_courselet

            if Unit.objects.filter(addedBy=instructor.user).exists():
                update_onboarding_step(onboarding.STEP_4, instructor.user_id)

            # if instructor has created a create_thread

            if Lesson.objects.filter(addedBy=instructor.user, kind=Lesson.ANSWER).exists():
                update_onboarding_step(onboarding.STEP_5, instructor.user_id)

            enroll_unit_code_exists = EnrollUnitCode.objects.filter(
                courseUnit__course__addedBy=instructor.user,
                isPreview=True,
                isLive=False,
                isTest=False
            ).exists()
            if enroll_unit_code_exists:
                update_onboarding_step(onboarding.STEP_6, instructor.user_id)

            print(""Instructor {} passed onboarding at {}%"".format(
                instructor.user.username, get_onboarding_percentage(instructor.user.id))
            )
/n/n/nmysite/ct/models.py/n/nimport re
import logging
from copy import copy

from django.core.validators import RegexValidator
from django.db import models
from django.contrib.auth.models import User
from django.template.loader import render_to_string
from django.utils import timezone
from django.core.urlresolvers import reverse
from django.db.models import Q, Count, Max


from django.db.models.signals import post_save
from django.dispatch import receiver
from core.common import onboarding
from core.common.utils import update_onboarding_step


not_only_spaces_validator = RegexValidator(
    regex=r'^\s+?$',
    inverse_match=True,
    message='This field can not consist of only spaces'
)

def copy_model_instance(inst, **kwargs):
    n_inst = copy(inst)
    n_inst.id = None
    if kwargs:
        for k, v in kwargs.items():
            setattr(n_inst, k, v)
    n_inst.save()
    return n_inst


class SubKindMixin(object):
    kind = None
    sub_kind = None

    MULTIPLE_CHOICES = 'choices'
    NUMBERS = 'numbers'
    EQUATION = 'equation'
    CANVAS = 'canvas'

    def is_canvas(self):
        try:
            unit_lesson = self.unitlesson_set.first()
            return unit_lesson.parent.sub_kind == self.CANVAS
        except AttributeError:
            pass
        return self.sub_kind == self.CANVAS

    def get_canvas_html(self, *args, **kwargs):
        raise NotImplementedError

    def get_html(self, *args, **kwargs):
        """"""
        Returns html by response type
        """"""
        if self.is_canvas():
            return self.get_canvas_html(*args, **kwargs)
        else:
            return None


########################################################
# Concept ID and graph -- not version controlled

class Concept(models.Model):
    title = models.CharField(max_length=200)
    addedBy = models.ForeignKey(User)
    approvedBy = models.ForeignKey(User, null=True, blank=True,
                                   related_name='approvedConcepts')
    isError = models.BooleanField(default=False)
    isAbort = models.BooleanField(default=False)
    isFail = models.BooleanField(default=False)
    isPuzzled = models.BooleanField(default=False)
    alwaysAsk = models.BooleanField(default=False)
    atime = models.DateTimeField('time submitted', default=timezone.now)

    def __unicode__(self):
        return self.title

    @classmethod
    def get_from_sourceDB(klass, sourceID, user, sourceDB='wikipedia'):
        lesson = Lesson.get_from_sourceDB(sourceID, user, sourceDB)
        if lesson.concept:
            return lesson.concept, lesson
        concept = klass(title=lesson.title, addedBy=user)
        concept.save()
        lesson.concept = concept
        lesson.save()
        return concept, lesson

    @classmethod
    def search_text(klass, s):
        'search Concept title'
        return klass.objects.filter(title__icontains=s).distinct()

    @classmethod
    def new_concept(klass, title, text, unit, user, isError=False):
        'add a new concept with associated Lesson, UnitLesson'
        lesson = Lesson(title=title, text=text, addedBy=user,
                        commitTime=timezone.now(), changeLog='initial commit')
        concept = klass(title=title, addedBy=user)
        if isError:
            concept.isError = True
            lesson.kind = lesson.ERROR_MODEL
        concept.save()
        lesson.concept = concept
        lesson.save_root()
        UnitLesson.create_from_lesson(lesson, unit)
        return concept

    def create_error_model(self, addedBy, **kwargs):
        'create a new error model for this concept'
        em = self.__class__(isError=True, addedBy=addedBy, **kwargs)
        em.save()
        em.relatedTo.create(toConcept=self, addedBy=addedBy,
                            relationship=ConceptGraph.MISUNDERSTANDS)
        return em

    def copy_error_models(self, parent):
        'add to parent one UnitLesson for each error RE: this concept'
        l = []
        for cg in self.relatedFrom \
                .filter(relationship=ConceptGraph.MISUNDERSTANDS):
            try:  # get one lesson representing this error model
                lesson = Lesson.objects.filter(concept=cg.fromConcept)[0]
            except IndexError:
                pass
            else:
                l.append(UnitLesson.create_from_lesson(lesson, parent.unit,
                                                       kind=UnitLesson.MISUNDERSTANDS, parent=parent))
        return l

    def get_url(self, basePath, forceDefault=False, subpath=None,
                isTeach=True):
        objID = unit_id = None
        try:
            unit_id = int(basePath.split('/')[-2])
        except (IndexError, TypeError):
            pass
        for ul in UnitLesson.objects.filter(lesson__concept=self):
            if objID is None or ul.unit_id == unit_id:  # in this unit!
                objID = ul.pk
        if self.isError:  # default settings
            head = 'errors'
            tail = ''
        else:
            head = 'concepts'
            tail = 'lessons/'
        if subpath:  # apply non-default subpath
            tail = subpath + '/'
        elif subpath == '':
            tail = ''
        try:
            return '%s%s/%d/%s' % (basePath, head, objID, tail)
        except TypeError:
            logging.error(
                ""Concept.get_url method were not able to build path correctly. ""
                ""Will return '#' instead. Concept id {}"".format(self.id)
            )
            return ""#""

    def get_error_tests(self, **kwargs):
        'get questions that test this error model'
        return distinct_subset(UnitLesson.objects
                               .filter(kind=UnitLesson.COMPONENT,
                                       unitlesson__kind=UnitLesson.MISUNDERSTANDS,
                                       unitlesson__lesson__concept=self, **kwargs))

    def get_conceptlinks(self, unit):
        'get list of conceptLinks deduped on (treeID, relationship)'
        d = {}
        for cl in ConceptLink.objects.filter(concept=self):
            for ul in UnitLesson.objects.filter(lesson=cl.lesson):
                t = (ul.treeID, cl.relationship)
                if t not in d or ul.unit == unit:
                    cl.unitLesson = ul  # add attribute to keep this info
                    d[t] = cl
        l = d.values()
        l.sort(lambda x, y: cmp(x.relationship, y.relationship))
        return l


class ConceptGraph(models.Model):
    DEPENDS = 'depends'
    MOTIVATES = 'motiv'
    MISUNDERSTANDS = 'errmod'
    VIOLATES = 'violates'
    CONTAINS = 'contains'
    TESTS = 'tests'
    CONFLICTS = 'conflicts'
    PROVES = 'proves'
    DISPROVES = 'dispro'
    REL_CHOICES = (
        (DEPENDS, 'Depends on'),
        (MOTIVATES, 'Motivates'),
        (MISUNDERSTANDS, 'misunderstands'),
        (VIOLATES, 'Violates'),
        (CONTAINS, 'Contains'),
        (TESTS, 'Tests'),
        (CONFLICTS, 'Conflicts with'),
        (PROVES, 'Proves'),
        (DISPROVES, 'Disproves'),
    )
    fromConcept = models.ForeignKey(Concept, related_name='relatedTo')
    toConcept = models.ForeignKey(Concept, related_name='relatedFrom')
    relationship = models.CharField(max_length=10, choices=REL_CHOICES,
                                    default=DEPENDS)
    addedBy = models.ForeignKey(User)
    approvedBy = models.ForeignKey(User, null=True, blank=True,
                                   related_name='approvedConceptEdges')
    atime = models.DateTimeField('time submitted', default=timezone.now)


########################################################
# version-controlled teaching material

PUBLIC_ACCESS = 'public'
INSTRUCTOR_ENROLLED = 'enroll'
FINAL_EXAM_ONLY = 'exam'
PRIVATE_ACCESS = 'private'
ACCESS_CHOICES = (
    (PUBLIC_ACCESS, 'Public'),
    (INSTRUCTOR_ENROLLED, 'By instructors only'),
    (FINAL_EXAM_ONLY, 'Protected exam only'),
    (PRIVATE_ACCESS, 'By author only'),
)
DEFAULT_FSM = 'chat'
TRIAL_FSM = 'chat_trial'


class Lesson(models.Model, SubKindMixin):
    BASE_EXPLANATION = 'base'  # focused on one concept, as intro for ORCT
    EXPLANATION = 'explanation'  # conventional textbook or lecture explanation

    ORCT_QUESTION = 'orct'
    CONCEPT_INVENTORY_QUESTION = 'mcct'
    EXERCISE = 'exercise'
    PROJECT = 'project'
    PRACTICE_EXAM = 'practice'

    ANSWER = 'answer'
    ERROR_MODEL = 'errmod'

    DATA = 'data'
    CASESTUDY = 'case'
    ENCYCLOPEDIA = 'e-pedia'
    FAQ_QUESTION = 'faq'
    FORUM = 'forum'
    # MEDIA CHOICES
    READING = 'reading'
    LECTURE = 'lecture'
    SLIDES = 'slides'
    VIDEO = 'video'
    AUDIO = 'audio'
    IMAGE = 'image'
    DATABASE = 'db'
    SOFTWARE = 'software'
    NOT_CORRECT_CHOICE = '()'
    CORRECT_CHOICE = '(*)'

    KIND_CHOICES = (
        (BASE_EXPLANATION, 'brief definition and explanation'),
        (EXPLANATION, 'long explanation'),
        (ORCT_QUESTION, 'Open Response Concept Test question'),
        (CONCEPT_INVENTORY_QUESTION, 'Concept Inventory Test question'),
        (EXERCISE, EXERCISE),
        (PROJECT, PROJECT),
        (PRACTICE_EXAM, 'practice exam question'),
        (ANSWER, ANSWER),
        (ERROR_MODEL, 'error model'),
        (DATA, DATA),
        (CASESTUDY, 'Case Study'),
        (ENCYCLOPEDIA, 'Encyclopedia'),
        (FAQ_QUESTION, 'frequently asked question'),
        (FORUM, FORUM),
    )
    SUB_KIND_CHOICES = (
        (SubKindMixin.MULTIPLE_CHOICES, 'Multiple Choices Question'),
        (SubKindMixin.NUMBERS, 'Numbers'),
        (SubKindMixin.EQUATION, 'Equation'),
        (SubKindMixin.CANVAS, 'Canvas'),
    )
    MEDIA_CHOICES = (
        (READING, READING),
        (LECTURE, LECTURE),
        (SLIDES, SLIDES),
        (VIDEO, VIDEO),
        (AUDIO, AUDIO),
        (IMAGE, IMAGE),
        (DATABASE, 'Database'),
        (SOFTWARE, SOFTWARE),
    )
    _sourceDBdict = {}
    title = models.CharField(max_length=200, validators=[not_only_spaces_validator])
    text = models.TextField(null=True, blank=True)
    attachment = models.FileField(null=True, blank=True, upload_to='questions')

    data = models.TextField(null=True, blank=True)  # JSON DATA
    url = models.CharField(max_length=256, null=True, blank=True)
    kind = models.CharField(max_length=50, choices=KIND_CHOICES,
                            default=BASE_EXPLANATION)
    sub_kind = models.CharField(max_length=50, choices=SUB_KIND_CHOICES, blank=True, null=True)
    # lessons with sub kind numbers
    number_value = models.FloatField(default=0)
    number_max_value = models.FloatField(default=0)
    number_min_value = models.FloatField(default=0)
    # end numbers

    enable_auto_grading = models.BooleanField(default=False)

    medium = models.CharField(max_length=10, choices=MEDIA_CHOICES,
                              default=READING)
    access = models.CharField(max_length=10, choices=ACCESS_CHOICES,
                              default=PUBLIC_ACCESS)
    sourceDB = models.CharField(max_length=32, null=True, blank=True)
    sourceID = models.CharField(max_length=100, null=True, blank=True)
    addedBy = models.ForeignKey(User)
    atime = models.DateTimeField('time submitted', default=timezone.now)
    concept = models.ForeignKey(Concept, null=True, blank=True)  # concept definition
    treeID = models.IntegerField(null=True, blank=True)  # VCS METADATA
    parent = models.ForeignKey('Lesson', null=True, blank=True,
                               related_name='children')
    mergeParent = models.ForeignKey('Lesson', null=True, blank=True,
                                    related_name='mergeChildren')
    changeLog = models.TextField(null=True, blank=True)
    commitTime = models.DateTimeField('time committed', null=True, blank=True)
    add_unit_aborts = models.BooleanField(default=False)
    mc_simplified = models.BooleanField(default=False)

    _cloneAttrs = ('title', 'text', 'data', 'url', 'kind', 'medium', 'access',
                   'sourceDB', 'sourceID', 'concept', 'treeID',
                   'attachment',
                   'number_value', 'number_min_value', 'number_max_value',
                   'enable_auto_grading',
                   )

    def get_choices(self, with_description=False):
        """"""Parse self.text and try to find choices.

        () - empty parenthes - for not correct answer
        (*) - for correct answer
        :return: list of choices
        """"""
        choices = []
        choice_description = []
        choice_index = -1  # To start with index 0 of choice
        if '[choices]' in self.text:
            listed = self.text.split('\r\n')
            for i in range(listed.index('[choices]') + 1, len(listed)):
                if listed[i].startswith(self.CORRECT_CHOICE) or listed[i].startswith(self.NOT_CORRECT_CHOICE):
                    choices.append(listed[i])
                    choice_index += 1
                elif with_description:
                    choice_description.append((choice_index, listed[i]))
        if with_description:
            # The structure of choices with description - [(choice, description), (choice, description)]
            _choices = []
            for ind, choice in enumerate(choices):
                choice_desc = ''
                for desc_index, desc in choice_description:
                    if desc_index == ind and desc:
                        choice_desc += desc + '\r\n'
                _choices.append((choice, choice_desc))
            return enumerate(_choices)
        return enumerate(choices)

    def get_choice_title(self, index):
        for idx, choice in self.get_choices():
            if index == idx:
                splitted_title = re.split('^\(\**\) *', choice)
                return splitted_title[1] if len(splitted_title) > 1 else splitted_title[0]

    def get_choice_description(self, index):
        for idx, (choice, description) in self.get_choices(with_description=True):
            if index == idx:
                return description

    def get_choices_wrap_text(self):
        return self.text.split('[choices]')[0]

    def get_correct_choices(self):
        """"""Return only correct choices from list of choices

        :return: correct choices.
        """"""
        return [(i, choice) for i, choice in self.get_choices() if choice.startswith(self.CORRECT_CHOICE)]

    def get_canvas_html(self, disabled=False):
        """"""
        Returns container for drawing
        """"""
        is_answer = self.kind == 'answer'
        if is_answer:
            background_image = self.unitlesson_set.first().parent.lesson.attachment
            svg_image = self.attachment
        else:
            background_image = self.attachment
            svg_image = None
        html = render_to_string('ct/lesson/sub_kind_canvas.html', context={
            'lesson': self,
            'disabled': self.kind == 'answer' or disabled,
            'background_image': background_image,
            'svg_image': svg_image,
        })
        return html

    @classmethod
    def get_sourceDB_plugin(klass, sourceDB):
        try:
            return klass._sourceDBdict[sourceDB]
        except KeyError:
            import importlib
            mod = importlib.import_module('ct.sourcedb_plugin.%s_plugin'
                                          % sourceDB)
            dataClass = mod.LessonDoc
            klass._sourceDBdict[sourceDB] = dataClass
            return dataClass

    @classmethod
    def get_from_sourceDB(klass, sourceID, user, sourceDB='wikipedia',
                          doSave=True):
        'get or create Lesson linked to sourceDB:sourceID external ref'
        try:
            return klass.objects.filter(sourceDB=sourceDB, sourceID=sourceID) \
                .order_by('-atime')[0]  # get most recent version
        except IndexError:
            pass
        dataClass = klass.get_sourceDB_plugin(sourceDB)
        data = dataClass(sourceID)
        try:  # attribute authorship to the sourceDB
            user = User.objects.get(username=sourceDB)
        except User.DoesNotExist:
            pass
        lesson = klass(title=data.title, url=data.url, sourceDB=sourceDB,
                       sourceID=sourceID, addedBy=user, text=data.description,
                       kind=klass.EXPLANATION, commitTime=timezone.now(),
                       changeLog='initial text from %s' % sourceDB)
        if doSave:  # not just temporary, but save as permanent record
            lesson.save_root()
        lesson._sourceDBdata = data
        return lesson

    @classmethod
    def search_sourceDB(klass, query, sourceDB='wikipedia', **kwargs):
        'get [(title, sourceID, url)] for query from sourceDB using plugin'
        dataClass = klass.get_sourceDB_plugin(sourceDB)
        return dataClass.search(query, **kwargs)

    ## @classmethod
    ## def create_from_concept(klass, concept, **kwargs):
    ##     'create lesson for initial concept definition'
    ##     if concept.isError:
    ##         kwargs['kind'] = klass.ERROR_MODEL
    ##     lesson = klass(title=concept.title, text=concept.description,
    ##                    addedBy=concept.addedBy, concept=concept, **kwargs)
    ##     lesson.save_root()
    ##     return lesson
    def save_root(self, concept=None, relationship=None):
        'create root commit by initializing treeID'
        if self.treeID is None:  # no tree ID, so save as root commit
            self.save()
            self.treeID = self.pk
        self.save()
        if concept:
            if relationship is None:
                relationship = DEFAULT_RELATION_MAP[self.kind]
            self.conceptlink_set.create(concept=concept,
                                        addedBy=self.addedBy, relationship=relationship)

    def save_as_error_model(self, concept, questionUL, errorModel=None):
        """"""Save this new lesson as an error model for the specified
        concept and question.  It does this by creating an error model
        concept and creating a child UnitLesson linking it to the
        questionUL.""""""
        self.kind = self.ERROR_MODEL
        if errorModel is None:
            em = concept.create_error_model(title=self.title,
                                            addedBy=self.addedBy)
        self.concept = em
        self.save_root()
        return UnitLesson.create_from_lesson(self, questionUL.unit,
                                             parent=questionUL)

    def is_committed(self):
        'True if already committed'
        return self.commitTime is not None

    def _clone_dict(self):
        'get dict of attrs to clone'
        kwargs = {}
        for attr in self._cloneAttrs:  # clone our attributes
            kwargs[attr] = getattr(self, attr)
        return kwargs

    def checkout(self, addedBy):
        '''prepare to update.  If this required cloning, returns the
        cloned Lesson object; caller must save()!!.  Otherwise returns None'''
        if not self.is_committed() and (self.addedBy != addedBy or
                                        self.response_set.count() > 0):
            # do not mix edits from different people, or lose response snapshot
            self.checkin(commit=True)
        if self.is_committed():
            kwargs = self._clone_dict()
            return self.__class__(parent=self, addedBy=addedBy, **kwargs)

    def checkin(self, commit, doSave=True, copyLinks=False):
        '''finish checkout process by saving cloned links,
        permanent commit etc. as required'''
        if commit:
            if self.parent and not self.parent.is_committed():
                self.parent.checkin(commit=True)
            self.commitTime = timezone.now()
        if commit or doSave:
            self.save()
        if copyLinks:
            for cl in self.parent.conceptlink_set.all():
                cl.copy(self)

    def add_concept_link(self, concept, relationship, addedBy):
        'add concept link if not already present'
        if self.conceptlink_set.filter(concept=concept,
                                       relationship=relationship).count() == 0:
            return self.conceptlink_set.create(concept=concept, addedBy=addedBy,
                                               relationship=relationship)

    def __unicode__(self):
        return self.title
    ## def get_url(self):
    ##     if self.sourceDB:
    ##         return self.url
    ##     else:
    ##         return reverse('ct:lesson', args=(self.id,))


def distinct_subset(inlist, distinct_func=lambda x: x.treeID):
    'eliminate duplicate treeIDs from the input list'
    s = set()
    outlist = []
    for o in inlist:
        k = distinct_func(o)
        if k not in s:
            s.add(k)
            outlist.append(o)
    return outlist


class ConceptLink(models.Model):
    DEFINES = 'defines'
    TESTS = 'tests'
    RESOLVES = 'resol'
    DERIVES = 'derives'
    PROVES = 'proves'
    ASSUMES = 'assumes'
    MOTIVATES = 'motiv'
    ILLUSTRATES = 'illust'
    INTRODUCES = 'intro'
    COMMENTS = 'comment'
    WARNS = 'warns'
    REL_CHOICES = (
        (DEFINES, 'Defines'),
        (TESTS, 'Tests understanding of'),
        (RESOLVES, 'Helps students resolve'),
        (DERIVES, 'Derives'),
        (PROVES, 'Proves'),
        (ASSUMES, 'Assumes'),
        (MOTIVATES, 'Motivates'),
        (ILLUSTRATES, 'Illustrates'),
        (INTRODUCES, 'Introduces'),
        (COMMENTS, 'Comments on'),
        (WARNS, 'Warns about'),
    )
    concept = models.ForeignKey(Concept)
    lesson = models.ForeignKey(Lesson)
    relationship = models.CharField(max_length=10, choices=REL_CHOICES,
                                    default=DEFINES)
    addedBy = models.ForeignKey(User)
    atime = models.DateTimeField('time submitted', default=timezone.now)

    def copy(self, lesson):
        'copy this conceptlink to a new lesson'
        cl = self.__class__(concept=self.concept, lesson=lesson,
                            relationship=self.relationship,
                            addedBy=self.addedBy, atime=self.atime)
        cl.save()
        return cl

    def annotate_ul(self, unit):
        '''add unitLesson as TEMPORARY attribute, within the specified unit.
        Note this attribute is NOT stored in the database!!'''
        try:
            self.unitLesson = UnitLesson.objects.filter(unit=unit,
                                                        lesson=self.lesson)[0]
        except IndexError:
            raise UnitLesson.DoesNotExist('unitLesson not in this unit')


DEFAULT_RELATION_MAP = {
    Lesson.BASE_EXPLANATION: ConceptLink.DEFINES,
    Lesson.EXPLANATION: ConceptLink.DEFINES,
    Lesson.ORCT_QUESTION: ConceptLink.TESTS,
    Lesson.CONCEPT_INVENTORY_QUESTION: ConceptLink.TESTS,
    Lesson.EXERCISE: ConceptLink.TESTS,
    Lesson.PROJECT: ConceptLink.TESTS,
    Lesson.PRACTICE_EXAM: ConceptLink.TESTS,

    Lesson.ANSWER: ConceptLink.ILLUSTRATES,
    Lesson.ERROR_MODEL: ConceptLink.DEFINES,

    Lesson.DATA: ConceptLink.ILLUSTRATES,
    Lesson.CASESTUDY: ConceptLink.ILLUSTRATES,
    Lesson.ENCYCLOPEDIA: ConceptLink.DEFINES,
    Lesson.FAQ_QUESTION: ConceptLink.COMMENTS,
    Lesson.FORUM: ConceptLink.COMMENTS,
}


class StudyList(models.Model):
    'list of materials of interest to each user'
    lesson = models.ForeignKey(Lesson)
    user = models.ForeignKey(User)

    def __unicode__(self):
        return self.lesson.title


############################################################
# unit lesson repo and graph

IS_ERROR = 0
IS_CONCEPT = 1
IS_LESSON = 2


class UnitLesson(models.Model):
    'pointer to a Lesson as part of a Unit branch'
    _headURL = 'lessons'
    _tasksPath = {IS_ERROR: 'faq', IS_CONCEPT: 'faq', IS_LESSON: 'tasks'}
    COMPONENT = 'part'
    ANSWERS = 'answers'
    MISUNDERSTANDS = 'errmod'
    RESOLVES = 'resol'
    PRETEST_POSTTEST = 'pretest'
    SUBUNIT = 'subunit'
    KIND_CHOICES = (
        (COMPONENT, 'Included in this courselet'),
        (ANSWERS, 'Answer for a question'),
        (MISUNDERSTANDS, 'Common error for a question'),
        (RESOLVES, 'Resolution for an error'),
        (PRETEST_POSTTEST, 'Pre-test/Post-test for this courselet'),
        (SUBUNIT, 'Container for this courselet'),
    )
    LESSON_ROLE = 'lesson'
    RESOURCE_ROLE = 'resource'
    ROLE_CHOICES = (
        (LESSON_ROLE, ""Show this lesson to all students as part of the courselet's main lesson sequence""),
        (RESOURCE_ROLE, ""Just list this as a follow-up study resource"")
    )
    unit = models.ForeignKey('Unit')
    kind = models.CharField(max_length=10, choices=KIND_CHOICES,
                            default=COMPONENT)
    lesson = models.ForeignKey(Lesson, null=True, blank=True)
    parent = models.ForeignKey('UnitLesson', null=True, blank=True)
    order = models.IntegerField(null=True, blank=True)
    atime = models.DateTimeField('time added', default=timezone.now)
    addedBy = models.ForeignKey(User)
    treeID = models.IntegerField()  # VCS METADATA
    branch = models.CharField(max_length=32, default='master')

    ## @classmethod
    ## def create_from_concept(klass, concept, unit=None, ulArgs={}, **kwargs):
    ##     'create lesson for initial concept definition'
    ##     lesson = Lesson.create_from_concept(concept, **kwargs)
    ##     return klass.create_from_lesson(lesson, unit, **ulArgs)

    @property
    def text(self):
        return self.lesson.text

    @property
    def sub_kind(self):
        """"""Initially sub_kind is present only in answers.""""""
        sub_kind = None
        if not self.lesson.sub_kind:
            if self.kind == self.COMPONENT:
                answer = self.get_answers().first()
                if answer and answer.sub_kind:
                    sub_kind = answer.sub_kind

            if self.kind == self.ANSWERS:
                sub_kind = self.parent.lesson.sub_kind
        else:
            sub_kind = self.lesson.sub_kind
        return sub_kind

    @sub_kind.setter
    def sub_kind(self, val):
        l = self.lesson
        l.sub_kind = val
        l.save()

    def __unicode__(self):
        return u""UnitLesson: {}"".format(self.lesson.title)

    @classmethod
    def create_from_lesson(klass, lesson, unit, order=None, kind=None,
                           addAnswer=False, **kwargs):
        if not kind:
            kindMap = {Lesson.ANSWER: klass.ANSWERS,
                       Lesson.ERROR_MODEL: klass.MISUNDERSTANDS}
            kind = kindMap.get(lesson.kind, klass.COMPONENT)
        if order == 'APPEND':
            order = unit.next_order()
        ul = klass(unit=unit, lesson=lesson, addedBy=lesson.addedBy,
                   treeID=lesson.treeID, order=order, kind=kind, **kwargs)
        ul.save()
        if addAnswer and lesson.kind == Lesson.ORCT_QUESTION:
            answer = Lesson(title='Answer', text='write an answer',
                            addedBy=lesson.addedBy, kind=Lesson.ANSWER)
            answer.save_root()
            ul._answer = klass.create_from_lesson(answer, unit,
                                                  kind=klass.ANSWERS, parent=ul)
        return ul

    @classmethod
    def search_text(klass, s, searchType=IS_LESSON, dedupe=True,
                    excludeArgs={}, **kwargs):
        'search lessons, concepts or errors for title and text'
        if searchType == 'lesson':  # exclude questions
            kwargs['kind'] = klass.COMPONENT
            excludeArgs = excludeArgs.copy()
            excludeArgs['lesson__kind'] = Lesson.ORCT_QUESTION
        elif searchType == 'question':
            kwargs['kind'] = klass.COMPONENT
            kwargs['lesson__kind'] = Lesson.ORCT_QUESTION
        elif searchType == IS_LESSON:  # anything but answer, error etc.
            kwargs['kind'] = klass.COMPONENT
        elif searchType == IS_ERROR:
            kwargs['lesson__concept__isnull'] = False
            kwargs['kind'] = klass.MISUNDERSTANDS
        else:  # search for regular concepts (not an error)
            kwargs['lesson__concept__isnull'] = False
            kwargs['lesson__concept__isError'] = False
        out = klass.objects.filter((Q(lesson__title__icontains=s) |
                                    Q(lesson__text__icontains=s)) &
                                   Q(**kwargs)).distinct()
        if excludeArgs:
            out = out.exclude(**excludeArgs)
        if dedupe:
            out = distinct_subset(out)
        return out

    @classmethod
    def search_sourceDB(klass, query, sourceDB='wikipedia', unit=None,
                        **kwargs):
        'get sourceDB search results, represented by existing ULs if any'
        resultsUL = []
        results = []
        for t in Lesson.search_sourceDB(query, sourceDB, **kwargs):
            queryArgs = dict(lesson__sourceDB=sourceDB, lesson__sourceID=t[1])
            hits = ()
            if unit:
                hits = klass.objects.filter(unit=unit, **queryArgs)
            try:  # use UL from this unit if any
                resultsUL.append(hits[0])
            except IndexError:
                hits = klass.objects.filter(**queryArgs)
                try:  # otherwise use any UL matching this sourceID
                    resultsUL.append(hits[0])
                except IndexError:  # no UL so just return tuple
                    results.append(t)
        return resultsUL, results

    def get_answers(self):
        'get query set with answer(s) if any'
        return self.unitlesson_set.filter(kind=self.ANSWERS)

    def get_errors(self):
        'get query set with errors if any'
        return self.unitlesson_set.filter(kind=self.MISUNDERSTANDS)

    def get_linked_concepts(self):
        'get all concept links (including errors) to this lesson'
        return self.lesson.conceptlink_set.all()

    def get_concepts(self):
        'get all concepts (not errors) linked to this lesson'
        return Concept.objects.filter(conceptlink__lesson=self.lesson,
                                      isError=False)

    def get_em_resolutions(self):
        'get list of resolution UL for this error UL'
        em = self.lesson.concept
        return em, list(self.unitlesson_set.filter(kind=self.RESOLVES))
        ## query = Q(kind=self.RESOLVES,
        ##           lesson__conceptlink__relationship=ConceptLink.RESOLVES,
        ##           lesson__conceptlink__concept=em)
        ## return em, distinct_subset(UnitLesson.objects.filter(query))

    def get_new_inquiries(self):
        return self.response_set.filter(kind=Response.STUDENT_QUESTION,
                                        needsEval=True)

    def get_alternative_defs(self, **kwargs):
        return distinct_subset(self.__class__.objects
                               .filter(lesson__concept=self.lesson.concept)
                               .exclude(treeID=self.treeID))

    def get_next_lesson(self):
        if self.order is not None:
            return self.unit.unitlesson_set.get(order=self.order + 1)
        else:
            raise self.__class__.DoesNotExist

    def checkout(self, addedBy):
        'get lesson object we can update (which may be a new object)'
        lesson = self.lesson.checkout(addedBy)
        if lesson:
            return lesson
        else:
            return self.lesson

    def checkin(self, lesson, commit=None, doSave=True):
        '''finalize update of checked-out lesson, committing if requested.
        If lesson != self.lesson, save it as self.lesson.'''
        newLesson = (lesson != self.lesson)
        if commit is None and lesson.changeLog:
            commit = True
        lesson.checkin(commit, doSave, newLesson)
        if newLesson:
            self.lesson = lesson
            self.save()

    def copy(self, unit, addedBy, parent=None, order=None, kind=None, **kwargs):
        'copy self and children to new unit'
        if not self.lesson.is_committed():  # to fork it, must commit it!
            name = addedBy.get_full_name()
            if not name:
                name = addedBy.get_username()
            self.lesson.changeLog = 'snapshot for fork by %s' % name
            self.lesson.checkin(commit=True)

        if order == 'APPEND':
            order = unit.next_order()
        elif order is None:
            order = self.order

        if kind == UnitLesson.RESOLVES:
            self.lesson.add_concept_link(parent.lesson.concept,
                                         ConceptLink.RESOLVES, addedBy)
        elif kind is None:
            kind = self.kind

        ul = copy_model_instance(self, lesson=self.lesson, addedBy=addedBy, unit=unit,
                                 kind=kind, treeID=self.treeID, parent=parent,
                                 order=order, branch=self.branch, **kwargs)
        ul.save()
        for child in self.unitlesson_set.all():  # copy children
            child.copy(unit, addedBy, parent=ul, **kwargs)
        return ul

    def save_resolution(self, lesson):
        'save new lesson as resolution for this error model UL'
        if not self.lesson.concept or self.kind != self.MISUNDERSTANDS:
            raise ValueError('not an error model!')
        lesson.save_root(self.lesson.concept,
                         ConceptLink.RESOLVES)  # link as resolution
        return self.__class__.create_from_lesson(lesson, self.unit,
                                                 kind=UnitLesson.RESOLVES, parent=self)

    def copy_resolution(self, ul, addedBy):
        'copy existing UL as resolution for this error model UL'
        try:  # already added?
            return self.unitlesson_set.get(treeID=ul.treeID,
                                           kind=UnitLesson.RESOLVES)
        except UnitLesson.DoesNotExist:
            return ul.copy(self.unit, addedBy, self, kind=UnitLesson.RESOLVES)

    def get_url(self, basePath, forceDefault=False, subpath=None,
                isTeach=True):
        'get URL path for this UL'
        pathDict = {IS_ERROR: ('errors', ''),
                    IS_CONCEPT: ('concepts', 'lessons/'),
                    IS_LESSON: ('lessons', ''), }
        if forceDefault:
            head, tail = pathDict[IS_LESSON]
        else:
            head, tail = pathDict[self.get_type()]
        if subpath:  # apply non-default subpath
            tail = subpath + '/'
        elif subpath == '':
            tail = ''
        return '%s%s/%d/%s' % (basePath, head, self.pk, tail)

    def get_type(self):
        'return classification as error model, concept, or regular lesson'
        if self.lesson.concept:
            if self.kind == self.MISUNDERSTANDS:
                return IS_ERROR
            else:
                return IS_CONCEPT
        return IS_LESSON

    def get_study_url(self, course_id):
        'return URL for student to read lesson or answer question'
        if self.lesson.kind == Lesson.ORCT_QUESTION:
            path = 'ct:ul_respond'
        else:
            path = 'ct:lesson'
        return reverse(path, args=(course_id, self.unit.pk, self.pk))

    def is_question(self):
        'is this a question?'
        return self.lesson.kind in [Lesson.ORCT_QUESTION, Lesson.MULTIPLE_CHOICES]


def reorder_exercise(self, old=0, new=0, l=()):
    """"""
    Renumber exercises to move an exercise from old -> new position

    Can be used to reorder all list of Lesson's(UnitLesson's).
    """"""
    if not l:
        l = self.get_exercises()
    if not l:  # no lessons, so nothing to do
        return l
    ex = l[old]  # select desired exercise by old position
    l = l[:old] + l[old + 1:]  # exclude this exercise
    l = l[:new] + [ex] + l[new:]  # insert ex in new position
    for i, ex in enumerate(l):
        if i != ex.order:  # order changed, have to update
            ex.order = i
            ex.save()
    return l  # hand back the reordered list


class Unit(models.Model):
    'a container of exercises performed together'
    COURSELET = 'unit'
    LIVE_SESSION = 'live'
    RESOLUTION = 'resol'
    KIND_CHOICES = (
        (COURSELET, 'Courselet'),
        (LIVE_SESSION, 'Live session'),
        (RESOLUTION, 'Resolutions for an error model'),
    )
    title = models.CharField(
        max_length=200,
        help_text='Your students will see this, so give your courselet a descriptive name.',
        validators=[not_only_spaces_validator]
    )
    kind = models.CharField(max_length=10, choices=KIND_CHOICES,
                            default=COURSELET)
    atime = models.DateTimeField('time created', default=timezone.now)
    addedBy = models.ForeignKey(User)
    description = models.TextField(blank=True)
    img_url = models.URLField(blank=True)
    small_img_url = models.URLField(blank=True)
    is_show_will_learn = models.BooleanField(default=False)

    def next_order(self):
        'get next order value for appending new UnitLesson.order'
        n = self.unitlesson_set.all().aggregate(n=Max('order'))['n']
        if n is None:
            return 0
        else:
            return n + 1

    def no_lessons(self):
        return not self.unitlesson_set.filter(order__isnull=False).count()

    def no_orct(self):
        return not self.unitlesson_set.filter(order__isnull=False,
                                              lesson__kind=Lesson.ORCT_QUESTION).count()

    def all_orct(self):
        """"""
        Return all ORCT objects.
        """"""
        return self.unitlesson_set.filter(order__isnull=False,
                                          lesson__kind=Lesson.ORCT_QUESTION)

    def create_lesson(self, title, text, author=None, **kwargs):
        if author is None:
            author = self.addedBy
        lesson = Lesson(title=title, text=text, addedBy=author, **kwargs)
        lesson.save()
        n = self.unitlesson_set.filter(order__isnull=False).count()
        ul = UnitLesson(unit=self, lesson=lesson, addedBy=author,
                        treeID=lesson.pk, order=n)
        ul.save()
        lesson.treeID = lesson.pk
        lesson.save()
        return lesson

    def get_related_concepts(self):
        'get dict of concepts linked to lessons in this unit'
        d = {}
        for ul in self.unitlesson_set.filter(lesson__concept__isnull=False,
                                             kind=UnitLesson.COMPONENT):
            cl = ConceptLink(lesson=ul.lesson, concept=ul.lesson.concept)
            cl.unitLesson = ul
            d[cl.concept] = [cl]
        for cld in ConceptLink.objects.filter(lesson__unitlesson__unit=self,
                                              concept__isError=False,
                                              lesson__unitlesson__kind=UnitLesson.COMPONENT) \
                .values('concept', 'relationship', 'lesson__unitlesson'):
            concept = Concept.objects.get(pk=cld['concept'])
            ul = UnitLesson.objects.get(pk=cld['lesson__unitlesson'])
            cl = ConceptLink(concept=concept,
                             relationship=cld['relationship'])
            cl.unitLesson = ul
            d.setdefault(cl.concept, []).append(cl)
        return d

    def get_exercises(self):
        'ordered list of lessons for this courselet'
        return list(self.unitlesson_set.filter(order__isnull=False)
                    .order_by('order'))

    reorder_exercise = reorder_exercise

    def get_aborts(self):
        'get query set with errors + generic ABORT, FAIL errors'
        aborts = list(self.unitlesson_set
                      .filter(kind=UnitLesson.MISUNDERSTANDS, parent__isnull=True))
        if not aborts:  # need to add ABORTs etc. to this unit
            aborts = []
            for errorLesson in distinct_subset(Lesson.objects
                                                       .filter(kind=Lesson.ERROR_MODEL, concept__alwaysAsk=True)):
                em = self.unitlesson_set.create(lesson=errorLesson,
                                                kind=UnitLesson.MISUNDERSTANDS,
                                                addedBy=errorLesson.addedBy,
                                                treeID=errorLesson.treeID)
                aborts.append(em)
        return aborts

    def get_new_inquiry_uls(self, **kwargs):
        return distinct_subset(self.unitlesson_set
                               .filter(response__kind=Response.STUDENT_QUESTION,
                                       response__needsEval=True, **kwargs))

    def get_errorless_uls(self, **kwargs):
        return distinct_subset(self.unitlesson_set
                               .filter(lesson__kind=Lesson.ORCT_QUESTION, **kwargs)
                               .exclude(unitlesson__kind=UnitLesson.MISUNDERSTANDS))

    def get_resoless_uls(self, **kwargs):
        return distinct_subset(self.unitlesson_set
                               .filter(Q(unitlesson__kind=UnitLesson.MISUNDERSTANDS, **kwargs)
                                       & ~Q(unitlesson__lesson__concept__conceptlink__relationship=
                                            ConceptLink.RESOLVES)))

    def get_unanswered_uls(self, user=None, **kwargs):
        if user:
            kwargs['response__author'] = user
        return distinct_subset(self.unitlesson_set
                               .filter(kind=UnitLesson.COMPONENT, order__isnull=False,
                                       lesson__kind=Lesson.ORCT_QUESTION)
                               .exclude(response__kind=Response.ORCT_RESPONSE, **kwargs))

    def get_selfeval_uls(self, user=None, **kwargs):
        if user:
            kwargs['response__author'] = user
        else:  # ensure it finds Response
            kwargs['response__isnull'] = False
        return distinct_subset(self.unitlesson_set
                               .filter(response__selfeval__isnull=True,
                                       response__kind=Response.ORCT_RESPONSE, **kwargs))

    def get_serrorless_uls(self, user=None, **kwargs):
        if user:
            kwargs['response__author'] = user
        return distinct_subset(self.unitlesson_set
                               .filter((Q(response__selfeval=Response.DIFFERENT) |
                                        Q(response__status=NEED_HELP_STATUS)) &
                                       Q(response__studenterror__isnull=True, **kwargs)))

    def get_unresolved_uls(self, user=None, **kwargs):
        'get ORCT with errors not yet DONE_STATUS'
        if user:
            kwargs['response__author'] = user
        return distinct_subset(self.unitlesson_set
                               .filter(response__studenterror__status__in=
                                       [NEED_HELP_STATUS, NEED_REVIEW_STATUS], **kwargs))

    def get_study_url(self, path, extension=['tasks']):
        'return URL for next study tasks on this unit'
        from ct.templatetags.ct_extras import get_base_url
        return get_base_url(path, extension)

    def append(self, ul, user):
        'append unitLesson to main lesson sequence'
        if ul.unit == self:
            if ul.order is None:  # add to tail
                ul.order = self.unitlesson_set.filter(order__isnull=False).count()
                ul.save()
                self.reorder_exercise()
            return ul
        else:  # not in this unit so copy
            return ul.copy(self, user, order='APPEND')

    def __unicode__(self):
        return self.title


############################################################
# student response and error data

def fmt_count(c, n):
    return '%.0f%% (%d)' % (c * 100. / n, c)


class CountsTable(object):
    'simple holder for one row of pretty-printed counts w/ headings & title'

    def __init__(self, title, choices, n, countDict):
        self.title = title
        self.headings = []
        counts = []
        for k, heading in choices:
            self.headings.append(heading)
            counts.append(countDict.get(k, 0))
        self.headings.append('(not yet)')
        total = sum(counts)
        if total > 0:
            counts.append(n - total)
            self.data = [fmt_count(i, n) for i in counts]
        else:
            self.data = ()

    def __len__(self):
        return len(self.data)


NEED_HELP_STATUS = 'help'
NEED_REVIEW_STATUS = 'review'
DONE_STATUS = 'done'
STATUS_CHOICES = (
    (NEED_HELP_STATUS, 'Still confused, need help'),
    (NEED_REVIEW_STATUS, 'OK, but flag this for me to review'),
    (DONE_STATUS, 'Solidly'),
)
STATUS_TABLE_LABELS = (
    (NEED_HELP_STATUS, 'Still confused, need help'),
    (NEED_REVIEW_STATUS, 'OK, but need review'),
    (DONE_STATUS, 'Solid understanding'),
)


class ResponseManager(models.Manager):
    '''
    Manager for Response model which will return by default Response's with field is_test equals to False
    To get test responses (marked with flag is_test=True) you should use method test_responses,
    which will return only test responses.
    '''

    # return ONLY valuable responses
    def get_queryset(self, **kwargs):
        return super(ResponseManager, self).get_queryset().filter(
            is_test=False, is_preview=False, **kwargs
        )

    def get_all_responses_queryset(self, **kwargs):
        """"""Return new queryset to filter all responsesn, not only valuable.""""""
        return self._queryset_class(model=self.model, using=self._db, hints=self._hints)

    def all_all(self):
        """"""Return all responses.""""""
        return self.get_all_responses_queryset().all()

    def filter_all(self, **kwargs):
        """"""Filter all responses.""""""
        return self.get_all_responses_queryset().filter(**kwargs)


    def test_responses(self, **kwargs):
        '''
        Return only test responses marked with flag is_test=True
        :return:
        '''
        return super(ResponseManager, self).get_queryset().filter(is_test=True, **kwargs)

    def preview_responses(self, **kwargs):
        '''
        Return only test responses marked with flag is_test=True
        :return:
        '''
        return super(ResponseManager, self).get_queryset().filter(is_preview=True, **kwargs)


class Response(models.Model, SubKindMixin):
    'answer entered by a student in response to a question'
    ORCT_RESPONSE = 'orct'
    STUDENT_QUESTION = 'sq'
    COMMENT = 'comment'

    KIND_CHOICES = (
        (ORCT_RESPONSE, 'ORCT response'),
        (STUDENT_QUESTION, 'Question about a lesson'),
        (COMMENT, 'Reply comment'),
    )

    # new interactions
    SUB_KIND_CHOICES = (
        (SubKindMixin.MULTIPLE_CHOICES, 'Multiple Choices response'),
        (SubKindMixin.NUMBERS, 'Numbers response'),
        (SubKindMixin.EQUATION, 'Equation response'),
        (SubKindMixin.CANVAS, 'Canvas response'),
    )
    CORRECT = 'correct'
    CLOSE = 'close'
    DIFFERENT = 'different'
    EVAL_CHOICES = (
        (DIFFERENT, 'Different'),
        (CLOSE, 'Close'),
        (CORRECT, 'Essentially the same'),
    )
    GUESS = 'guess'  # chosen for sort order g < n < s
    UNSURE = 'notsure'
    SURE = 'sure'
    CONF_CHOICES = (
        (GUESS, 'Just guessing'),
        (UNSURE, 'Not quite sure'),
        (SURE, 'Pretty sure'),
    )
    SELFEVAL_STEP = 'assess'
    CLASSIFY_STEP = 'errors'
    lesson = models.ForeignKey(Lesson)  # exact version this applies to
    unitLesson = models.ForeignKey(UnitLesson)
    course = models.ForeignKey('Course')
    kind = models.CharField(max_length=10, choices=KIND_CHOICES,
                            default=ORCT_RESPONSE)

    # test, preview flags
    is_test = models.BooleanField(default=False)
    is_preview = models.BooleanField(default=False)

    sub_kind = models.CharField(max_length=10, choices=SUB_KIND_CHOICES, blank=True, null=True)
    title = models.CharField(max_length=200, null=True, blank=True)
    text = models.TextField()
    attachment = models.FileField(null=True, blank=True, upload_to='answers')

    confidence = models.CharField(max_length=10, choices=CONF_CHOICES,
                                  blank=False, null=False)
    atime = models.DateTimeField('time submitted', default=timezone.now)
    selfeval = models.CharField(max_length=10, choices=EVAL_CHOICES,
                                blank=False, null=True)
    status = models.CharField(max_length=10, choices=STATUS_CHOICES,
                              blank=False, null=True)
    author = models.ForeignKey(User)
    needsEval = models.BooleanField(default=False)
    parent = models.ForeignKey('Response', null=True, blank=True)  # reply-to
    activity = models.ForeignKey('fsm.ActivityLog', null=True, blank=True)

    is_trial = models.BooleanField(default=False)

    objects = ResponseManager()

    def __unicode__(self):
        return u'answer by ' + self.author.username

    def get_canvas_html(self):
        """"""
        Returns container for drawing
        """"""
        html = render_to_string('ct/lesson/response_sub_kind_canvas.html', context={
            'response': self,
        })
        return html

    @classmethod
    def get_counts(klass, query, fmt_count=fmt_count, n=0, tableKey='status',
                   simpleTable=False,
                   title='Student Status for Understanding This Lesson'):
        'generate display tables for Response data'
        querySet = klass.objects.filter(query)
        statusDict = {}
        for d in querySet.values(tableKey).annotate(dcount=Count(tableKey)):
            statusDict[d[tableKey]] = d['dcount']
        if not n:
            n = querySet.count()
        if not n:  # prevent DivideByZero
            return (), (), 0
        choices = dict(status=STATUS_TABLE_LABELS,
                       confidence=klass.CONF_CHOICES)[tableKey]
        statusTable = CountsTable(title, choices, n, statusDict)
        if simpleTable:  # caller only wants statusTable
            return statusTable, n, None
        evalDict = {}
        for d in querySet.values('confidence', 'selfeval') \
                .annotate(dcount=Count('confidence')):
            evalDict[d['confidence'], d['selfeval']] = d['dcount']
        l = []
        for conf, label in klass.CONF_CHOICES:
            l.append((label, [fmt_count(evalDict.get((conf, selfeval), 0), n)
                              for selfeval, _ in klass.EVAL_CHOICES]))
        return statusTable, l, n

    @classmethod
    def get_novel_errors(klass, unitLesson=None, query=None,
                         selfeval=DIFFERENT, **kwargs):
        'get wrong responses with no StudentError classification'
        if not query:
            if not unitLesson:
                raise ValueError('no query and no unitLesson?!?')
            query = Q(unitLesson=unitLesson)
        return klass.objects.filter(query &
                    Q(selfeval=selfeval, studenterror__isnull=True), **kwargs)
    def get_url(self, basePath, forceDefault=False, subpath=None,
                isTeach=True):
        'URL for this response'
        if subpath:
            tail = subpath + '/'
        else:
            tail = ''
        return '%slessons/%d/responses/%d/%s' % (basePath, self.unitLesson_id,
                                                 self.pk, tail)

    def get_next_step(self):
        'indicate what task student should do next'
        if not self.selfeval:
            return self.SELFEVAL_STEP, 'self-assess your answer'
        if self.selfeval == self.DIFFERENT or self.status == NEED_HELP_STATUS:
            if self.studenterror_set.count() == 0:
                return self.CLASSIFY_STEP, 'classify your error(s)'

    def show_my_choices(self):
        if self.sub_kind != 'choices':
            raise ValueError('Response.sub_kind should be choices to call this function')

        available_choices = dict(self.lesson.get_choices())
        split_selected_choices = self.text.split('[selected_choices] ')
        if len(split_selected_choices) > 1:
            selected_choices = split_selected_choices[1]
            return ""\r\n"".join([
                available_choices.get(int(i), """")
                for i in selected_choices
                if unicode.isdigit(i)
            ])
        return """"


class StudentError(models.Model):
    'identification of a specific error model made by a student'
    response = models.ForeignKey(Response)
    atime = models.DateTimeField('time submitted', default=timezone.now)
    errorModel = models.ForeignKey(UnitLesson)
    status = models.CharField(max_length=10, choices=STATUS_CHOICES,
                              blank=False, null=True)
    author = models.ForeignKey(User)
    activity = models.ForeignKey('fsm.ActivityLog', null=True, blank=True)

    def __unicode__(self):
        return u'eval by ' + self.author.username

    @classmethod
    def get_counts(klass, query, n, fmt_count=fmt_count):
        'generate display table for StudentError data'
        querySet = klass.objects.filter(query)
        l = []
        for d in querySet.values('errorModel') \
                .annotate(c=Count('errorModel')):
            l.append((UnitLesson.objects.get(pk=d['errorModel']), d['c']))
        l.sort(lambda x, y: cmp(x[1], y[1]), reverse=True)
        return [(t[0], fmt_count(t[1], n)) for t in l]

    @classmethod
    def get_ul_errors(klass, ul, **kwargs):
        'get StudentErrors for a specific question'
        return klass.objects.filter(response__unitLesson=ul, **kwargs)


def errormodel_table(target, n, fmt='%d (%.0f%%)', includeAll=False, attr=''):
    if n == 0:  # prevent div by zero error
        n = 1
    kwargs = {'kind': Lesson.MISUNDERSTANDS, 'parent': target}
    l = []
    for em in UnitLesson.objects.filter(**kwargs):
        kwargs = {'errorModel': em}
        nse = StudentError.objects.filter(**kwargs).count()
        if nse > 0 or includeAll:
            l.append((em, nse))
    l.sort(lambda x, y: cmp(x[1], y[1]), reverse=True)
    fmt_count = lambda c: fmt % (c, c * 100. / n)
    return [(t[0], fmt_count(t[1])) for t in l]


class InquiryCount(models.Model):
    'record users who have the same question'
    response = models.ForeignKey(Response)
    addedBy = models.ForeignKey(User)
    atime = models.DateTimeField('time submitted', default=timezone.now)


class Liked(models.Model):
    'record users who found UnitLesson showed them something they were missing'
    unitLesson = models.ForeignKey(UnitLesson)
    addedBy = models.ForeignKey(User)
    atime = models.DateTimeField('time submitted', default=timezone.now)

    class Meta:
        verbose_name_plural = 'Likes'


class FAQ(models.Model):
    'link a student inquiry to a follow-up lesson'
    response = models.ForeignKey(Response)
    unitLesson = models.ForeignKey(UnitLesson)
    addedBy = models.ForeignKey(User)
    atime = models.DateTimeField('time submitted', default=timezone.now)


#######################################
# Course and membership info

class Course(models.Model):
    'top-level (enrollment) container'
    ACCESS_CHOICES = (
        (PUBLIC_ACCESS, 'Public'),
        (INSTRUCTOR_ENROLLED, 'By instructors only'),
        (PRIVATE_ACCESS, 'By author only'),
    )
    FSM_CHOICES = (
        (DEFAULT_FSM, 'Default FSM flow'),
        (TRIAL_FSM, 'Trial FSM flow - ABORTS before Student answer'),
    )
    title = models.CharField(
        max_length=200,
        validators=[not_only_spaces_validator]
    )
    description = models.TextField()
    access = models.CharField(max_length=10, choices=ACCESS_CHOICES,
                              default=PUBLIC_ACCESS)
    enrollCode = models.CharField(max_length=64, null=True, blank=True)
    lockout = models.CharField(max_length=200, null=True, blank=True)
    addedBy = models.ForeignKey(User)
    atime = models.DateTimeField('time submitted', default=timezone.now)

    copied_from = models.ForeignKey('Course', blank=True, null=True)
    trial = models.BooleanField(default=False)
    FSM_flow = models.CharField(max_length=10, choices=FSM_CHOICES,
                                default=DEFAULT_FSM)

    def deep_clone(self, **options):
        publish = options.get('publish', False)
        with_students = options.get('with_students', False)
        asis = options.get('asis', False)
        title = self.title.split('copied')[0] + "" copied {}"".format(
            timezone.now().astimezone(timezone.get_default_timezone())
        )

        new_course = copy_model_instance(
            self,
            atime=timezone.now(),
            title=title,
            copied_from=self
        )
        for cu in self.courseunit_set.all():
            # deal with Unit
            n_unit = copy_model_instance(cu.unit, atime=timezone.now())
            # deal with CourseUnit
            n_cu_kw = dict(
                course=new_course,
                unit=n_unit,
                atime=timezone.now(),
                releaseTime=timezone.now()
            )
            if not publish:
                n_cu_kw['releaseTime'] = None
            if asis:
                # if copy as is - remove release time from kw. it will be the same as in source obj.
                del n_cu_kw['releaseTime']

            n_cu = copy_model_instance(cu, **n_cu_kw)

            uls = list(cu.unit.get_exercises())
            # copy exercises and error models
            for ul in uls:
                n_ul = ul.copy(unit=n_unit, addedBy=ul.addedBy)

            # copy resources
            for ul in list(cu.unit.unitlesson_set.filter(kind=UnitLesson.COMPONENT, order__isnull=True)):
                n_ul = ul.copy(unit=n_unit, addedBy=ul.addedBy)
                n_unit.reorder_exercise()
        roles_to_copy = [
                            r[0] for r in Role.ROLE_CHOICES
                            if r[0] != Role.ENROLLED
                        ] + ([Role.ENROLLED] if with_students else [])
        for role in self.role_set.filter(role__in=roles_to_copy):
            n_role = copy_model_instance(role, course=new_course, atime=timezone.now())
        return new_course

    def create_unit(self, title, description=None, img_url=None, small_img_url=None, author=None):
        if author is None:
            author = self.addedBy
        unit = Unit(
            title=title,
            addedBy=author,
            description=description,
            img_url=img_url,
            small_img_url=small_img_url
        )
        unit.save()
        cu = CourseUnit(unit=unit, course=self, addedBy=author,
                        order=CourseUnit.objects.filter(course=self).count())
        cu.save()
        return unit

    def get_user_role(self, user, justOne=True, raiseError=True):
        'return role(s) of specified user in this course'
        l = [r.role for r in self.role_set.filter(user=user)]
        if (raiseError or justOne) and not l:
            raise KeyError('user not in this class')
        if justOne:
            return l[0]
        else:
            return l

    def get_course_units(self, publishedOnly=True):
        'ordered list of cunits for this course'
        if publishedOnly:  # only those already released
            return list(self.courseunit_set
                        .filter(releaseTime__isnull=False,
                                releaseTime__lt=timezone.now()).order_by('order'))
        else:
            return list(self.courseunit_set.all().order_by('order'))

    reorder_course_unit = reorder_exercise

    def get_users(self, role=None):
        if not role:
            role = Role.INSTRUCTOR
        return User.objects.filter(role__role=role, role__course=self)

    def __unicode__(self):
        return self.title


class CourseUnit(models.Model):
    '''list of units in a course'''
    unit = models.ForeignKey(Unit)
    course = models.ForeignKey(Course)
    order = models.IntegerField()
    addedBy = models.ForeignKey(User)
    atime = models.DateTimeField('time submitted', default=timezone.now)
    releaseTime = models.DateTimeField('time released', null=True, blank=True)

    def is_published(self):
        return self.releaseTime and self.releaseTime < timezone.now()

    def __unicode__(self):
        return u""Course - {}, Unit - {}"".format(self.course.title, self.unit.title)

    def get_responses(self):
        return Response.objects.filter(
            unitLesson__unit=self.unit,
            kind=Response.ORCT_RESPONSE,
            course=self.course,
        )


class Role(models.Model):
    'membership of a user in a course'
    INSTRUCTOR = 'prof'
    TA = 'TA'
    ENROLLED = 'student'
    SELFSTUDY = 'self'
    ROLE_CHOICES = (
        (INSTRUCTOR, 'Instructor'),
        (TA, 'Teaching Assistant'),
        (ENROLLED, 'Enrolled Student'),
        (SELFSTUDY, 'Self-study'),
    )
    role = models.CharField(max_length=10, choices=ROLE_CHOICES,
                            default=ENROLLED)
    course = models.ForeignKey(Course)
    user = models.ForeignKey(User)
    atime = models.DateTimeField('time submitted', default=timezone.now)
    trial_mode = models.NullBooleanField()

    class Meta:
        unique_together = ('role', 'course', 'user')


class UnitStatus(models.Model):
    'records what user has completed in a unit lesson sequence'
    unit = models.ForeignKey(Unit)
    user = models.ForeignKey(User)
    startTime = models.DateTimeField('time started', default=timezone.now)
    endTime = models.DateTimeField('time ended', null=True)
    order = models.IntegerField(default=0)  # index of current UL

    @classmethod
    def get_or_none(klass, unit, user, latest=False, **kwargs):
        try:
            query = klass.objects.filter(unit=unit, user=user, **kwargs)
            if latest:
                query = query.order_by('-startTime')
            return query[0]
        except IndexError:
            return None

    @classmethod
    def is_done(klass, unit, user):
        return klass.get_or_none(unit, user, endTime__isnull=False)

    def get_lesson(self):
        'get the current lesson'
        return self.unit.unitlesson_set.get(order=self.order)

    def set_lesson(self, ul):
        'advance to specified lesson, but prevent skipping on first run'
        if ul.order > self.order:
            if not self.endTime and ul.order > self.order + 1:
                return self.start_next_lesson()  # prevent skipping ahead
            self.order = ul.order
            self.save()
        return ul

    def done(self):
        'reset to start of sequence, and set endTime if not already'
        self.order = 0  # reset in case user wants to repeat
        if not self.endTime:
            self.endTime = timezone.now()  # mark as done
            self.save()
            return True
        self.save()

    def start_next_lesson(self):
        'advance to the next lesson, if any, else return None'
        self.order += 1
        try:
            ul = self.get_lesson()
            self.save()
            return ul
        except UnitLesson.DoesNotExist:
            self.done()
            return None


@receiver(post_save, sender=Course)
def onboarding_course_created(sender, instance, **kwargs):
    update_onboarding_step(onboarding.STEP_3, instance.addedBy.id)


@receiver(post_save, sender=Unit)
def onboarding_unit_created(sender, instance, **kwargs):
    update_onboarding_step(onboarding.STEP_4, instance.addedBy.id)


@receiver(post_save, sender=Lesson)
def onboarding_lesson_created(sender, instance, **kwargs):
    if instance.kind == Lesson.ANSWER:
        update_onboarding_step(onboarding.STEP_5, instance.addedBy.id)
/n/n/nmysite/ctms/models.py/n/nimport re
from uuid import uuid4

from django.db import models
from django.db.models.signals import post_save
from django.db.utils import IntegrityError
from django.dispatch import receiver
from django.contrib.auth.models import User
from django.contrib.sites.models import Site
from django.conf import settings
from django.core.mail import send_mail
from django.core.urlresolvers import reverse
from django.http.response import Http404
from django.template import loader, Context

from accounts.models import Instructor
from chat.models import EnrollUnitCode
from core.common import onboarding
from core.common.utils import update_onboarding_step
from ct.models import Course




STATUS_CHOICES = (
    ('pendind', 'pending'),
    ('joined', 'joined'),
)

TYPE_CHOICES = (
    ('student', 'student'),
    ('tester', 'tester')
)

def clean_email_name(email):
    email_name, domain = email.split('@', 1)
    email_name = email_name.replace('.', '')
    return email_name, domain

class InviteQuerySet(models.QuerySet):
    def my_invites(self, request):
        return self.filter(instructor=request.user.instructor)

    def testers(self):
        return self.filter(type='tester')

    def students(self):
        return self.filter(type='student')

    def shared_for_me(self, request):
        return self.filter(
            models.Q(user=request.user) | models.Q(email=request.user.email)
        )


class Invite(models.Model):
    instructor = models.ForeignKey(Instructor)
    user = models.ForeignKey(User, blank=True, null=True)
    email = models.EmailField()
    code = models.CharField('invite code', max_length=255)
    status = models.CharField('status', max_length=20, choices=STATUS_CHOICES, default='pending')
    type = models.CharField('invite type', max_length=50, choices=TYPE_CHOICES, default='tester')
    course = models.ForeignKey(Course)
    enroll_unit_code = models.ForeignKey(EnrollUnitCode, null=True)

    added = models.DateTimeField('added datetime', auto_now_add=True)

    objects = InviteQuerySet.as_manager()

    @staticmethod
    def search_user_by_email(email):
        return User.objects.filter(email=email).first()

    @classmethod
    def create_new(cls, commit, course, instructor, email, invite_type, enroll_unit_code):
        user = Invite.search_user_by_email(email)
        try:
            old_invite = Invite.get_by_user_or_404(
                user=user,
                type=invite_type,
                course=course,
                instructor=instructor,
                enroll_unit_code=enroll_unit_code
            )
            if old_invite:
                return old_invite
        except Http404:
            pass
        code = Invite(
            instructor=instructor,
            user=user,
            email=email,
            code=uuid4().hex,
            status='pending',
            type=invite_type,
            course=course,
            enroll_unit_code=enroll_unit_code
        )
        if commit:
            code.save()
        return code

    def get_invited_user_username(self):
        return self.email.split(""@"")[0] if self.email else ''

    class Meta:
        unique_together = ('instructor', 'email', 'type', 'course', 'enroll_unit_code')

    def save(self, force_insert=False, force_update=False, using=None,
             update_fields=None):
        user = Invite.search_user_by_email(self.email)
        self.user = user
        return super(Invite, self).save(force_insert, force_update, using, update_fields)

    def send_mail(self, request, view):
        try:
            # TODO: use `send_email` utility function here (see `core`)
            context = Context({
                'invite': self,
                'current_site': Site.objects.get_current(request)
            })
            subj_template = loader.get_template('ctms/email/invite_subject.txt')
            rendered_subj = subj_template.render(context)

            text_template = loader.get_template('ctms/email/invite_text.txt')
            rendered_text = text_template.render(context)
            send_mail(
                rendered_subj,
                rendered_text,
                settings.EMAIL_FROM,
                [self.email],
                fail_silently=False
            )
            return {
                'success': True,
                'message': 'Invitation successfully sent.',
                'invite': {
                    'status': self.status,
                }
            }
        except IntegrityError:
            return {
                'success': False,
                'message': 'You already have sent invite to user with {} email'.format(request.POST['email'])
            }

    def get_absolute_url(self):
        return reverse('ctms:tester_join_course', kwargs={'code': self.code})

    @staticmethod
    def get_by_user_or_404(user, **kwargs):
        '''
        Do a search for invite by passed parameters and user.
         NOTE: this function firstly try to get invite by passed kwargs,
         then check that Invite.email and user.email are equal,
         if they not - trying to check Invite.email and user.email
         !! excluding dots from email-name. !!
        :param user: request.user
        :param kwargs: params to search by
        :return: invite if found
        :raise: Http404 if not found
        '''
        if not user:
            raise Http404
        invites = Invite.objects.filter(
            **kwargs
        )
        my_invite = None

        for invite in invites:
            if invite and invite.email == user.email:
                my_invite = invite
                break
            user_email_name, user_domain = clean_email_name(user.email)
            invite_email, invite_domain = clean_email_name(invite.email)
            if invite_domain != user_domain:
                continue
            res = re.search(
                ""^{}@{}$"".format(r""\.?"".join(user_email_name), user_domain),
                ""{}@{}"".format(invite_email, invite_domain)
            )
            if res and res.string:
                my_invite = invite
                break
        else:
            raise Http404()
        if my_invite:
            return my_invite
        else:
            raise Http404()

    def __unicode__(self):
        return ""Code {}, User {}"".format(self.code, self.email)
/n/n/nmysite/ctms/views.py/n/nimport waffle
import json
from uuid import uuid4

from django.contrib.sites.models import Site
from django.http import JsonResponse
from django.http.response import Http404, HttpResponseRedirect, HttpResponse
from django.shortcuts import redirect, get_object_or_404
from django.core.urlresolvers import reverse
from django.contrib.auth.models import User
from django.template.response import TemplateResponse
from django.utils import timezone
from django.views.generic.base import View, TemplateView
from django.views.generic.detail import DetailView
from django.views.generic.edit import CreateView, UpdateView, DeleteView
from django.views.generic.list import ListView
from django.db import models
from django.contrib import messages
from django.contrib.auth import logout
from django.conf import settings
from django.core.cache import cache
from social_core.backends.utils import load_backends

from accounts.models import Instructor

from core.common import onboarding
from core.common.utils import get_onboarding_steps, get_onboarding_percentage, \
    get_onboarding_setting, get_onboarding_status_with_settings

from chat.models import EnrollUnitCode
from ct.forms import LessonRoleForm

from ctms.forms import (
    CreateEditUnitForm,
    ErrorModelFormSet,
    CreateEditUnitAnswerForm,
    CreateUnitForm)
from ct.models import Course, CourseUnit, Unit, UnitLesson, Lesson, Response, Role, Concept
from ctms.forms import CourseForm, CreateCourseletForm, EditUnitForm, InviteForm
from ctms.models import Invite
from mysite.mixins import NewLoginRequiredMixin
from psa.forms import SignUpForm, EmailLoginForm
from .utils import Memoize


memoize = Memoize()


def json_response(x):
    return HttpResponse(json.dumps(x, sort_keys=True, indent=2),
                        content_type='application/json; charset=UTF-8')


class CourseCoursletUnitMixin(View):
    course_pk_name = 'course_pk'
    courslet_pk_name = 'courslet_pk'
    unit_pk_name = 'unit_pk'
    NEED_INSTRUCTOR = True
    response_class = TemplateResponse

    def render(self, template_name, context):
        return self.response_class(
            request=self.request,
            template=template_name,
            context=context,
        )

    def dispatch(self, request, *args, **kwargs):
        if self.NEED_INSTRUCTOR and not self.am_i_instructor():
            return redirect(settings.BECOME_INSTRUCTOR_URL)
        return super(CourseCoursletUnitMixin, self).dispatch(request, *args, **kwargs)

    def am_i_course_owner(self):
        course = self.get_course()
        return course and course.addedBy != self.request.user or False

    def am_i_instructor(self):
        try:
            self.request.user.instructor
            return True
        except Instructor.DoesNotExist:
            return False

    def get_courses_where_im_instructor(self):
        return Course.objects.filter(role__role=Role.INSTRUCTOR, role__user=self.request.user)

    def get_course(self):
        return Course.objects.filter(id=self.kwargs.get(self.course_pk_name)).first()

    def get_courslet(self):
        return CourseUnit.objects.filter(id=self.kwargs.get(self.courslet_pk_name)).first()

    def get_unit_lesson(self):
        return UnitLesson.objects.filter(id=self.kwargs.get(self.unit_pk_name)).first()

    def get_context_data(self, **kwargs):
        try:
            context = super(CourseCoursletUnitMixin, self).get_context_data(**kwargs)
        except AttributeError:
            context = kwargs
        context.update(self.kwargs)
        return context

    def get_my_courses(self):
        return Course.objects.filter(
            models.Q(addedBy=self.request.user)
        )

    def get_my_or_shared_with_me_courses(self):
        return Course.objects.filter(
            models.Q(addedBy=self.request.user) |
            models.Q(role__role=Role.INSTRUCTOR, role__user=self.request.user)
        ).distinct()

    def get_my_or_shared_with_me_course_units(self):
        return CourseUnit.objects.filter(
            models.Q(addedBy=self.request.user) |
            models.Q(course__role__role=Role.INSTRUCTOR, course__role__user=self.request.user) |
            models.Q(course__addedBy=self.request.user)
        ).distinct()

    def get_courselets_by_course(self, course):
        return course.courseunit_set.filter(order__isnull=False)

    def get_units_by_courselet(self, courselet):
        cache_key = memoize.cache_key('get_units_by_courselet', courselet)
        cached = cache.get(cache_key)
        if cached:
            return cached
        # UnitLesson
        courslet_units = courselet.unit.unitlesson_set.filter(
            kind=UnitLesson.COMPONENT,
            order__isnull=False
        ).order_by(
            'order'
        ).annotate(
            responses_count=models.Sum(
                models.Case(
                    models.When(models.Q(response__is_test=False, response__is_preview=False), then=1),
                    default=0,
                    output_field=models.IntegerField()
                )
            )
        )
        for unit in courslet_units:
            unit.url = reverse(
                'ctms:unit_edit',
                # Commended out due to discussion in the https://github.com/cjlee112/socraticqs2/issues/755
                # 'ctms:unit_view' if unit.lesson.kind == Lesson.ORCT_QUESTION and unit.response_set.exists() else 'ctms:unit_edit',
                kwargs={
                    'course_pk': courselet.course.id,
                    'courslet_pk': courselet.id,
                    'pk': unit.id
                }
            )
        cache.set(cache_key, courslet_units, 60)
        return courslet_units

    def get_invite_by_code_request_or_404(self, code):
        return Invite.get_by_user_or_404(self.request.user, code=code)


class FormSetBaseView(object):
    formset_prefix = None

    def get_formset_class(self):
        return self.formset_class

    def get_formset(self, formset_class=None):
        """"""
        Returns an instance of the form to be used in this view.
        """"""
        if formset_class is None:
            formset_class = self.get_formset_class()
        return formset_class(**self.get_formset_kwargs())

    def formset_valid(self, formset):
        pass

    def formset_invalid(self, formset, *args, **kwargs):
        pass

    def get_formset_prefix(self):
        """"""
        Returns the prefix to use for forms on this view
        """"""
        return self.formset_prefix

    def get_formset_queryset(self):
        pass

    def get_formset_kwargs(self):
        kwargs = {
            'initial': self.get_formset_initial(),
            'prefix': self.get_formset_prefix(),
            'queryset': self.get_formset_queryset(),
        }

        if self.request.method in ('POST', 'PUT'):
            kwargs.update({
                'data': self.request.POST,
                'files': self.request.FILES,
            })
        return kwargs

    def get_formset_initial(self):
        return [{}]


class MyCoursesView(NewLoginRequiredMixin, CourseCoursletUnitMixin, ListView):
    template_name = 'ctms/my_courses.html'
    model = Course

    def get_context_data(self, **kwargs):
        my_courses = self.get_my_courses()
        courses_shared_by_role = self.get_courses_where_im_instructor()

        return {
            'my_courses': my_courses,
            'instructor_role_courses': courses_shared_by_role

        }

    def post(self, request):
        form = CourseForm(request.POST)
        if form.is_valid():
            course = form.save(commit=False)
            course.addedBy = request.user
            course.save()
            return redirect(reverse('ctms:course_view', kwargs={'course_id': course.id}))
        return self.render(
            'ctms/my_courses.html',
            {'course_form': form}
        )


class CreateCourseView(NewLoginRequiredMixin, CourseCoursletUnitMixin, CreateView):
    template_name = 'ctms/my_courses.html'
    model = Course
    fields = ['title']
    # form_class = CourseForm

    def get(self, request, *args, **kwargs):
        if not self.am_i_instructor():
            raise Http404()
        return super(CreateCourseView, self).get(request, *args, **kwargs)

    def post(self, request, *args, **kwargs):
        if not self.am_i_instructor():
            raise Http404()
        return super(CreateCourseView, self).post(request, *args, **kwargs)

    def form_valid(self, form):
        form.instance.addedBy = self.request.user
        self.object = form.save()
        Role.objects.create(course=self.object, role=Role.INSTRUCTOR, user=self.request.user)
        return redirect(reverse('ctms:course_view', kwargs={'pk': self.object.id}))


class UpdateCourseView(NewLoginRequiredMixin, CourseCoursletUnitMixin, UpdateView):
    template_name = 'ctms/course_form.html'
    model = Course
    fields = ['title', 'trial']

    def get(self, request, *args, **kwargs):
        if not self.am_i_instructor():
            raise Http404()
        return super(UpdateCourseView, self).get(request, *args, **kwargs)

    def post(self, request, *args, **kwargs):
        if not self.am_i_instructor():
            raise Http404()
        return super(UpdateCourseView, self).post(request, *args, **kwargs)

    def get_object(self, queryset=None):
        if 'pk' in self.kwargs:
            course = Course.objects.filter(
                models.Q(id=self.kwargs.get('pk')) &
                (
                    models.Q(addedBy=self.request.user) |
                    models.Q(role__role=Role.INSTRUCTOR, role__user=self.request.user)
                )
            ).distinct().first()
            if not course:
                raise Http404()
            return course

    def form_valid(self, form):
        form.instance.addedBy = self.request.user
        messages.add_message(self.request, messages.SUCCESS, ""Course successfully updated"")
        return super(UpdateCourseView, self).form_valid(form)

    def get_success_url(self):
        return reverse('ctms:course_view', kwargs={'pk': self.object.id})

    def get_context_data(self, **kwargs):
        kwargs = super(UpdateCourseView, self).get_context_data(**kwargs)
        kwargs.update(self.kwargs)
        kwargs['domain'] = 'https://{0}'.format(Site.objects.get_current().domain)
        kwargs['object'] = self.object
        return kwargs


class DeleteCourseView(NewLoginRequiredMixin, DeleteView):
    """"""
    Delete course view
    Delete course can only owner.
    """"""
    model = Course

    def get_queryset(self):
        return Course.objects.filter(addedBy=self.request.user)

    def get_success_url(self):
        return reverse('ctms:my_courses')

    def delete(self, request, *args, **kwargs):
        response = super(DeleteCourseView, self).delete(request, *args, **kwargs)
        messages.add_message(self.request, messages.SUCCESS, ""Course successfully deleted"")
        return response


class SharedCoursesListView(NewLoginRequiredMixin, ListView):
    context_object_name = 'shared_courses'
    template_name = 'ctms/sharedcourse_list.html'
    model = Invite
    queryset = Invite.objects.all()

    def get_queryset(self):
        qs = super(SharedCoursesListView, self).get_queryset()
        queryset = qs.shared_for_me(self.request)
        course_title = ''
        data = {}
        for invite in queryset:
            if invite.course.title != course_title and invite.course.title not in data:
                data[invite.course.title] = dict(
                    method='get',
                    link=reverse('ctms:tester_join_course', kwargs={'code': invite.code}),
                    title=invite.course.title,
                    instructor=invite.instructor,
                    course_pk=invite.course.id
                )
            else:
                if invite.course.title in data:
                    data[invite.course.title] = dict(
                        method='post',
                        link=reverse('ctms:shared_courses'),
                        title=invite.course.title,
                        instructor=invite.instructor,
                        course_pk=invite.course.id
                    )
            course_title = invite.course.title
        return data

    def get_context_data(self, **kwargs):
        kwargs = super(SharedCoursesListView, self).get_context_data(**kwargs)
        kwargs['instructor_role_courses'] = Course.objects.filter(
            role__role=Role.INSTRUCTOR, role__user=self.request.user
        )
        return kwargs

    def post(self, request, *args, **kwargs):
        if request.POST.get('course_pk'):
            Invite.objects.shared_for_me(request).filter(
                status='pending',
                course_id=request.POST.get('course_pk')
            ).update(status='joined')
            return HttpResponseRedirect(
                reverse('lms:tester_course_view', kwargs={'course_id': request.POST.get('course_pk')}))


class CourseView(NewLoginRequiredMixin, CourseCoursletUnitMixin, DetailView):
    model = Course
    template_name = 'ctms/course_detail.html'
    pk_url_kwarg = 'pk'

    def get_queryset(self):
        # return self.object.courslet_view(published_only=False)
        return self.get_my_or_shared_with_me_courses()

    def get_context_data(self, **kwargs):
        kwargs.update({
            'courslets': self.object.get_course_units(publishedOnly=False)
        })
        return kwargs


class CoursletView(NewLoginRequiredMixin, CourseCoursletUnitMixin, DetailView):
    model = CourseUnit
    template_name = 'ctms/courselet_detail.html'
    course_pk_name = 'course_pk'
    courslet_pk_name = 'pk'
    unit_pk_name = None

    def get_queryset(self):
        # UnitLesson
        return self.get_my_or_shared_with_me_course_units().filter(
            course=self.get_course()
        )

    def get_context_data(self, **kwargs):
        kwargs.update({
            'u_lessons': self.get_units_by_courselet(self.object)
        })
        kwargs.update(self.kwargs)
        return kwargs

    def get(self, request, *args, **kwargs):
        if request.GET.get('message'):
            message = """"""
            <p>
              <b>You've completed the ""Get Started"" tutorial</b> <br> 
              We hope that you feel ready to continue working on your courselet. 
              You can edit or add new threads on this page. 
              Remember that you can ask us anything in the chat in your lower right corner. 
              Thanks again for trying out Courselets, we're excited see what you'll create!
            </p>
            """"""
            messages.add_message(self.request, messages.SUCCESS, message)
            return HttpResponseRedirect(request.path)
        return super(CoursletView, self).get(request, args, kwargs)


class CreateCoursletView(NewLoginRequiredMixin, CourseCoursletUnitMixin, CreateView):
    model = Unit
    template_name = 'ctms/courselet_form.html'
    fields = ('title',)
    form = CreateCourseletForm

    def get_success_url(self):
        return reverse(
            'ctms:courslet_view',
            kwargs={
                'course_pk': self.get_course().pk,
                'pk': self.object.course_unit.id
            }
        )

    def get_queryset(self):
        return Unit.objects.filter(
            courseunit__course=self.kwargs.get('course_pk'),
            courseunit__course__addedBy=self.request.user
        )

    def form_valid(self, form):
        self.object = form.save(commit=False)
        self.object.addedBy = self.request.user
        self.object.save()
        self.object.course_unit = CourseUnit.objects.create(
            unit=self.object,
            course=self.get_course(),
            addedBy=self.request.user,
            order=0,
        )
        return redirect(self.get_success_url())

    def get_context_data(self, **kwargs):
        context = super(CreateCoursletView, self).get_context_data(**kwargs)
        context.update({
            'unit_lesson': self.get_unit_lesson(),
            'course': self.get_course(),
            'courslet': self.get_courslet()
        })
        return context


class UnitView(NewLoginRequiredMixin, CourseCoursletUnitMixin, DetailView):
    template_name = 'ctms/unit_detail.html'
    model = UnitLesson

    course_pk_name = 'course_pk'
    courslet_pk_name = 'courslet_pk'

    def get_queryset(self):
        return self.model.objects.filter(addedBy=self.request.user)

    def get_context_data(self, **kwargs):
        super(UnitView, self).get_context_data(**kwargs)
        course = self.get_course()
        courslet = self.get_courslet()
        is_trial = self.request.GET.get('is_trial') in ['true', 'True', '1']
        responses = self.object.response_set.filter(is_trial=is_trial).order_by('-atime')
        # Onboarding step 7, haven't resolved yet, need to decide.
        # if responses and course.id == get_onboarding_setting(onboarding.INTRODUCTION_COURSE_ID):
        #     update_onboarding_step(onboarding.STEP_7, self.request.user.id)
        kwargs.update({
            'course': course,
            'courslet': courslet,
            'responses': responses,
            'unit': self.get_object(),
            'is_trial': is_trial
        })
        kwargs.update(self.kwargs)
        self.request.session['unitID'] = kwargs['unit'].id
        return kwargs


class CreateUnitView(NewLoginRequiredMixin, CourseCoursletUnitMixin, CreateView):
    model = Lesson
    form_class = CreateUnitForm
    template_name = 'ctms/create_unit_form.html'
    course_pk_name = 'course_pk'
    courslet_pk_name = 'courslet_pk'
    unit_pk_name = 'pk'

    def post(self, request, *args, **kwargs):
        """"""
        Post handler for creating Unit
        Unit can create only course owner (Course.addedBy field)
        :param request:
        :param args:
        :param kwargs:
        :return:
        """"""
        course = self.get_course()
        if course.addedBy != self.request.user:
            raise Http404()
        return super(CreateUnitView, self).post(request, *args, **kwargs)

    def get_success_url(self):
        return reverse(
            'ctms:unit_edit',
            kwargs={
                'course_pk': self.get_course().id,
                'courslet_pk': self.get_courslet().id,
                'pk': self.object.unit_lesson.id
            }
        )

    def form_valid(self, form):
        courslet = self.get_courslet()
        unit = courslet.unit
        self.object = Lesson(title=form.cleaned_data['title'], text='',
                             kind=Lesson.ORCT_QUESTION, addedBy=self.request.user)
        self.object.save()
        self.object.treeID = self.object.pk
        self.object.save()
        # create UnitLesson with blank answer for this unit
        unit_lesson = UnitLesson.create_from_lesson(self.object, unit, order='APPEND', addAnswer=False)

        self.object.unit_lesson = unit_lesson
        cache.delete(memoize.cache_key('get_units_by_courselet', courslet))
        return redirect(self.get_success_url())

    def get_context_data(self, **kwargs):
        context = super(CreateUnitView, self).get_context_data(**kwargs)
        context.update({
            'unit_lesson': self.get_unit_lesson(),
            'course': self.get_course(),
            'courslet': self.get_courslet()
        })
        return context


class EditUnitView(NewLoginRequiredMixin, CourseCoursletUnitMixin, UpdateView):
    model = UnitLesson
    template_name = 'ctms/unit_form.html'
    course_pk_name = 'course_pk'
    courslet_pk_name = 'courslet_pk'
    unit_pk_name = 'pk'
    form_class = EditUnitForm

    def get_object(self, queryset=None):
        """"""
        Only course owner can edit Units in this course.
        :param queryset:
        :return:
        """"""
        course = self.get_course()
        if not course.addedBy == self.request.user:
            raise Http404()
        self.object = self.get_unit_lesson().lesson
        return self.object

    def get_success_url(self):
        return reverse('ctms:unit_view', kwargs=self.kwargs)

    def form_valid(self, form):
        self.object = form.save(commit=True)
        # self.object.save()
        messages.add_message(self.request, messages.SUCCESS, ""Thread successfully updated"")
        cache.delete(memoize.cache_key('get_units_by_courselet', self.get_courslet()))
        return redirect(self.get_success_url())

    def get_context_data(self, **kwargs):
        kwargs.update(self.kwargs)
        kwargs.update({
            'unit_lesson': self.get_unit_lesson(),
            'course': self.get_course(),
            'courslet': self.get_courslet()
        })
        return kwargs


class ResponseView(NewLoginRequiredMixin, CourseCoursletUnitMixin, DetailView):
    model = Response
    course_pk_name = 'course_pk'
    courslet_pk_name = 'courslet_pk'
    unit_pk_name = 'unit_pk'
    template_name = 'ctms/response_detail.html'

    def get_queryset(self):
        course = self.get_course()
        if not course.addedBy == self.request.user:
            raise Http404()
        return super(ResponseView, self).get_queryset()

    def get_context_data(self, **kwargs):
        kwargs.update(self.kwargs)
        return kwargs


class CoursletSettingsView(NewLoginRequiredMixin, CourseCoursletUnitMixin, UpdateView):
    model = Unit
    fields = ('title', 'is_show_will_learn')
    course_pk_name = 'course_pk'
    courslet_pk_name = 'pk'
    template_name = 'ctms/courslet_settings.html'

    def get_object(self, queryset=None):
        if queryset:
            return queryset.get(pk=self.kwargs.get('pk')).unit
        else:
            course_unit = self.get_my_or_shared_with_me_course_units().filter(pk=self.kwargs.get('pk')).first()
            if not course_unit:
                raise Http404()
            return course_unit.unit

    def get_success_url(self):
        return reverse('ctms:courselet_invite_student', kwargs={'pk': self.get_course().id,
                                                        'courselet_pk': self.get_courslet().id})

    def get_context_data(self, **kwargs):
        context = super(CoursletSettingsView, self).get_context_data(**kwargs)
        context.update(self.kwargs)
        courslet = self.get_courslet()
        context.update({
            'course': self.get_course(),
            'courslet': courslet,
            'domain': 'https://{0}'.format(Site.objects.get_current().domain),
            'enroll_code': EnrollUnitCode.get_code(courslet)
        })
        return context

    def form_valid(self, form):
        response = super(CoursletSettingsView, self).form_valid(form)
        messages.add_message(self.request, messages.SUCCESS, ""Courselet successfully updated"")
        return response

    def post(self, request, *args, **kwargs):
        task = request.POST.get('task')
        if task:
            cu = self.get_courslet()
            if task == 'release':
                cu.releaseTime = timezone.now()
            if task == 'unrelease':
                cu.releaseTime = None
            cu.save()
            messages.add_message(self.request, messages.SUCCESS, ""Courselet successfully updated"")
            return redirect(self.request.META.get('HTTP_REFERER', self.get_success_url()))
        else:
            return super(CoursletSettingsView, self).post(request, *args, **kwargs)


class CoursletDeleteView(NewLoginRequiredMixin, CourseCoursletUnitMixin, DeleteView):
    model = CourseUnit
    template_name = 'ctms/courselet_confirm_delete.html'
    courslet_pk_name = 'pk'

    def get_object(self, queryset=None):
        if queryset:
            return super(CoursletDeleteView, self).get_object(
                queryset=queryset.filter(addedBy=self.request.user)
            )
        courselet = self.get_courslet()
        if courselet and courselet.addedBy == self.request.user:
            return courselet
        raise Http404()

    def get_context_data(self, **kwargs):
        kwargs.update(self.kwargs)
        kwargs.update({
            'course': self.get_course(),
            'courslet': self.get_courslet(),
        })
        return kwargs

    def get_success_url(self):
        course = self.get_course()
        if course:
            return reverse('ctms:course_view', kwargs={'pk': course.id})
        return reverse('ctms:my_courses')

    def delete(self, request, *args, **kwargs):
        response = super(CoursletDeleteView, self).delete(request, *args, **kwargs)
        messages.add_message(self.request, messages.SUCCESS, ""Courselet successfully deleted"")
        return response


class DeleteUnitView(NewLoginRequiredMixin, CourseCoursletUnitMixin, DeleteView):
    model = UnitLesson
    unit_pk_name = 'pk'

    def get_object(self, queryset=None):
        if queryset:
            return super(DeleteUnitView, self).get_queryset(
                queryset=queryset.filter(addedBy=self.request.user)
            )
        ul = self.get_unit_lesson()
        if ul and ul.addedBy == self.request.user:
            return ul
        raise Http404()

    def get_success_url(self):
        course = self.get_course()
        courslet = self.get_courslet()
        if course and courslet:
            return reverse('ctms:courslet_view', kwargs={
                'course_pk': course.id,
                'pk': courslet.id
            })
        return reverse('ctms:my_courses')

    def delete(self, request, *args, **kwargs):
        response = super(DeleteUnitView, self).delete(request, *args, **kwargs)
        messages.add_message(self.request, messages.SUCCESS, ""Unit successfully deleted"")
        cache.delete(memoize.cache_key('get_units_by_courselet', self.get_courslet()))
        return response


class UnitSettingsView(NewLoginRequiredMixin, CourseCoursletUnitMixin, DetailView):
    model = UnitLesson
    course_pk_name = 'course_pk'
    courslet_pk_name = 'courslet_pk'
    unit_pk_name = 'pk'
    template_name = 'ctms/unit_settings.html'

    def post(self, request, *args, **kwargs):
        ul = self.get_unit_lesson()
        roleForm = LessonRoleForm('', self.request.POST)
        if roleForm.is_valid():
            if roleForm.cleaned_data['role'] == UnitLesson.RESOURCE_ROLE:
                ul.order = None
                ul.save()
                ul.unit.reorder_exercise()
            elif ul.order is None:
                ul.unit.append(ul, self.request.user)
            cache.delete(memoize.cache_key('get_units_by_courselet', self.get_courslet()))
        return redirect(reverse(
            ""ctms:unit_settings"",
            kwargs=self.kwargs)
        )

    def get_object(self, queryset=None):
        ul = self.get_unit_lesson()
        if ul and ul.addedBy == self.request.user:
            return ul.lesson
        raise Http404()

    def get_context_data(self, **kwargs):
        kw = super(UnitSettingsView, self).get_context_data(**kwargs)
        kw.update(self.kwargs)
        ul = self.get_unit_lesson()
        if ul.order is not None:
            initial = UnitLesson.LESSON_ROLE
        else:
            initial = UnitLesson.RESOURCE_ROLE
        roleForm = LessonRoleForm(initial)
        kw.update({
            'unit_lesson': ul,
            'course': self.get_course(),
            'courslet': self.get_courslet(),
            'unit': self.get_object(),
            'role_form': roleForm
        })
        return kw


class CreateEditUnitView(NewLoginRequiredMixin, CourseCoursletUnitMixin, FormSetBaseView, UpdateView):
    model = Lesson
    form_class = CreateEditUnitForm
    formset_class = ErrorModelFormSet
    unit_pk_name = 'pk'
    template_name = 'ctms/unit_edit.html'
    HANDLE_FORMSET = True

    def get_success_url(self):
        return reverse('ctms:unit_edit', kwargs={
            'course_pk': self.kwargs['course_pk'],
            'courslet_pk': self.kwargs['courslet_pk'],
            'pk': self.object.id
        })

    def post(self, request, *args, **kwargs):
        self.object = self.get_object()
        if not self.object:
            return self.render('ctms/error.html')
        form = self.get_form()
        answer_form = CreateEditUnitAnswerForm(**self.get_answer_form_kwargs())
        formset = self.get_formset()

        answer_required = self.request.POST['unit_type'] == Lesson.ORCT_QUESTION
        answer_form_is_valid = False
        if answer_required:
            answer_form_is_valid = answer_form.is_valid()

        has_error = False

        if form.is_valid():
            self.form_valid(form)
            if answer_required:
                if answer_form_is_valid:
                    answer_form.save(self.object.unit, self.request.user, self.object)
                else:
                    has_error = True
                    messages.add_message(request, messages.WARNING, ""Please correct error in answer"")

                if formset.is_valid():
                    messages.add_message(request, messages.SUCCESS, ""Thread successfully updated"")
                    self.formset_valid(formset)
                else:
                    has_error = True
                    self.formset_invalid(formset)
            else:
                messages.add_message(request, messages.SUCCESS, ""Thread successfully updated"")
        else:
            has_error = True
            messages.add_message(request, messages.WARNING, ""Please correct errors below"")

        if not has_error:
            cache.delete(memoize.cache_key('get_units_by_courselet', self.get_courslet()))
            # need to check only Lesson: Answer
            if Lesson.objects.filter(
                    addedBy=self.request.user, kind=Lesson.ANSWER).count() == 1:
                return HttpResponseRedirect('{}#preview'.format(reverse('ctms:onboarding')))

            return HttpResponseRedirect(self.get_success_url())

        context = {
            'course': self.get_course(),
            'courslet': self.get_courslet(),
            'unit': self.object,
            'errors_formset': formset,
            'form': form,
            'answer_form': answer_form,
        }
        context.update(self.kwargs)
        return self.render_to_response(context)

    def formset_invalid(self, formset):
        messages.add_message(self.request, messages.WARNING, ""Please correct errors in Error Models section"")

    def get_answer_form_kwargs(self):
        kwargs = {}
        ul = self.get_unit_lesson()
        answer = None
        if ul:
            answer = ul.get_answers().last()
        kwargs['initial'] = {'answer': answer.lesson.text} if answer else {}
        kwargs['instance'] = answer.lesson if answer else None
        kwargs['prefix'] = 'answer_form'

        if self.request.method in ('POST', 'PUT'):
            kwargs['data'] = self.request.POST
            kwargs['files'] = self.request.FILES
        return kwargs

    def formset_valid(self, formset):
        """"""Save data to db from formset instance. NOT return any response to user.""""""
        ul = self.get_unit_lesson()
        dummy_concept = self.get_or_create_dummy_concept(ul)
        if not ul.lesson.concept:
            ul.lesson.concept = dummy_concept
            ul.lesson.addedBy = self.request.user

        for err_form in formset:
            # go though all forms in formset except forms which should be deleted.
            if err_form.is_valid() and err_form.cleaned_data and not err_form.cleaned_data['DELETE']:
                err_form.save(ul, self.request.user)

        if formset.deleted_forms:
            formset.save(commit=False)
            for del_form in formset.deleted_forms:
                obj = del_form.instance
                err_ul = UnitLesson.objects.filter(id=formset.lesson_ul_ids.get(obj.id)).first()
                # check that ul.id was not corrupted and has such lesson.
                if err_ul and err_ul.lesson == obj:
                    err_ul.delete()

    def get_or_create_dummy_concept(self, ul):
        if not ul.lesson.concept:
            admin = User.objects.get(username='admin')
            concept, created = Concept.objects.get_or_create(
                title='Dummy Concept',
                isError=False,
                addedBy=admin
            )
        else:
            concept = ul.lesson.concept
        return concept

    def form_valid(self, form):
        """"""Save data to DB.""""""
        form.save(commit=True)

    def get_initial(self):
        init = super(CreateEditUnitView, self).get_initial()
        ul = self.get_unit_lesson()
        if ul:
            if ul.lesson.kind not in [choice[0] for choice in self.form_class.KIND_CHOICES]:
                init['unit_type'] = self.form_class.DEFAULT_UNIT_TYPE
            else:
                init['unit_type'] = ul.lesson.kind
        return init

    def get_form_kwargs(self):
        kwargs = {
            'initial': self.get_initial(),
            'prefix': self.get_prefix(),
            'instance': self.get_form_initial()
        }

        if self.request.method in ('POST', 'PUT'):
            kwargs.update({
                'data': self.request.POST,
                'files': self.request.FILES,
            })
        return kwargs

    def get_queryset(self):
        courselet = self.get_courslet()
        return self.get_units_by_courselet(courselet)

    def get_object(self, queryset=None):
        obj = self.get_unit_lesson()
        if not obj or (obj and obj.addedBy != self.request.user):
            raise Http404()
        return obj

    def get_form_initial(self):
        ul = self.get_unit_lesson()
        if ul:
            return ul.lesson

    def get_ul_errors(self):
        ul = self.get_unit_lesson()
        if ul:
            return ul.get_errors()
        else:
            return UnitLesson.objects.none()

    def get_formset_queryset(self):
        ul_errors = self.get_ul_errors().values('lesson', 'id')
        qs = Lesson.objects.filter(id__in=[i['lesson'] for i in ul_errors])
        lesson_ul_id = {i['lesson']: i['id'] for i in ul_errors}
        for lesson in qs:
            # hack to pass ul id to form
            setattr(lesson, 'ul_id', lesson_ul_id[lesson.id])
        return qs

    def get_context_data(self, **kwargs):
        context = super(CreateEditUnitView, self).get_context_data(**kwargs)
        context.update({
            'course': self.get_course(),
            'courslet': self.get_courslet(),
            'unit': self.object,
            'errors_formset': ErrorModelFormSet(**self.get_formset_kwargs()),
            'answer_form': CreateEditUnitAnswerForm(**self.get_answer_form_kwargs()),
        })
        return context


class RedirectToCourseletPreviewView(NewLoginRequiredMixin, CourseCoursletUnitMixin, View):
    course_pk_name = 'course_pk'

    def get(self, request, course_pk, pk):
        course = self.get_course()
        course_unit = course.courseunit_set.filter(id=pk).first()
        if course_unit:
            # create EnrollCode
            enroll = EnrollUnitCode.get_code_for_user_chat(
                course_unit=course_unit,
                is_live=False,
                user=request.user,
                is_preview=True
            )

        return redirect('chat:preview_courselet', **{'enroll_key': enroll.enrollCode})


class RedirectToAddUnitsView(NewLoginRequiredMixin, CourseCoursletUnitMixin, View):
    course_pk_name = 'course_pk'
    courslet_pk_name = 'courset_pk'

    def get(self, request, course_pk, pk):
        course = self.get_course()
        course_unit = course.courseunit_set.filter(id=pk).first()

        if course_unit:
            # create EnrollCode
            enroll = EnrollUnitCode.get_code_for_user_chat(
                course_unit=course_unit,
                is_live=False,
                user=request.user,
            )
        return redirect('chat:add_units_by_chat',
                        **{'enroll_key': enroll.enrollCode, 'course_id': course.id, 'courselet_id': course_unit.id})


class InvitesListView(NewLoginRequiredMixin, CourseCoursletUnitMixin, CreateView):
    model = Invite
    form_class = InviteForm
    course_pk_name = 'pk'
    template_name = 'ctms/invite_list.html'

    def get_success_url(self):
        return self.request.path

    def get_context_data(self, **kwargs):
        courselet_pk = self.kwargs.get('courselet_pk')
        course = self.get_course()
        if courselet_pk:
            courselet = CourseUnit.objects.get(id=courselet_pk)
        else:
            courselet = CourseUnit.objects.filter(course=course).first()
        kwargs['invites'] = Invite.objects.my_invites(request=self.request).filter(
            enroll_unit_code=EnrollUnitCode.get_code(courselet, give_instance=True))
        kwargs['invite_tester_form'] = self.form_class(
            initial={
                'type': 'tester',
                'course': self.get_course(),
            }
        )
        if waffle.switch_is_active('ctms_invite_students'):
            # We no longer need a form
            # kwargs['invite_student_form'] = self.form_class(initial={'type': 'student', 'course': self.get_course()})
            if courselet:
                kwargs['enroll_code'] = EnrollUnitCode.get_code(courselet)

        kwargs['courselet'] = courselet
        kwargs['course'] = course
        kwargs['domain'] = 'https://{0}'.format(Site.objects.get_current().domain)
        kwargs['courselets_email'] = settings.COURSELETS_EMAIL
        return kwargs

    def get_form_kwargs(self):
        kwargs = super(InvitesListView, self).get_form_kwargs()
        kwargs['course'] = self.get_course()
        kwargs['instructor'] = self.request.user.instructor
        kwargs['enroll_unit_code'] = EnrollUnitCode.get_code(self.kwargs.get('courselet_pk'), give_instance=True)
        return kwargs

    def get_initial(self):
        return {
            'course': self.get_course(),
        }

    def form_valid(self, form):
        # There's no longer a form on the students invitation page
        # if form.cleaned_data['type'] == 'student' and not waffle.switch_is_active('ctms_invite_students'):
        #     # if type - student and ctms_invite_students is disabled
        #     messages.add_message(
        #         self.request, messages.WARNING, ""You can not send invitations to students yet""
        #     )
        #     return self.form_invalid(form)
        response = super(InvitesListView, self).form_valid(form)
        self.object.send_mail(self.request, self)
        messages.add_message(self.request, messages.SUCCESS, ""Invitation successfully sent"")
        return response

    def form_invalid(self, form):
        response = super(InvitesListView, self).form_invalid(form)
        messages.add_message(self.request, messages.WARNING,
                             ""Invitation could not be sent because of errors listed below"")
        return response


class JoinCourseView(CourseCoursletUnitMixin, View):  # NewLoginRequiredMixin
    NEED_INSTRUCTOR = False

    def get(self, *args, **kwargs):
        invite = get_object_or_404(Invite, code=self.kwargs['code'])
        if self.request.user.is_authenticated() and invite.email != self.request.user.email:
            logout(self.request)
        if self.request.user.is_authenticated():
            if invite.user and invite.user == self.request.user or invite.email == self.request.user.email:
                # if user is a person for whom this invite
                if invite.type == 'tester':
                    messages.add_message(self.request, messages.SUCCESS,
                                         ""You just joined course as tester"")
                    invite.status = 'joined'
                    invite.save()
                    if invite.enroll_unit_code:
                        return redirect(reverse('chat:tester_chat_enroll', kwargs={'enroll_key': invite.enroll_unit_code.enrollCode}))
                    else:
                        return redirect(reverse('lms:tester_course_view', kwargs={'course_id': invite.course.id}))
                # TODO: It seems to be no longer needed owing to absent invites for students
                # elif invite.type == 'student':
                #     messages.add_message(self.request, messages.SUCCESS,
                #                          ""You just joined course as student"")
                #     invite.status = 'joined'
                #     invite.save()
                #     if invite.enroll_unit_code:
                #         return redirect(reverse('chat:chat_enroll', kwargs={'enroll_key': invite.enroll_unit_code.enrollCode}))
                #     else:
                #         return redirect(reverse('lms:course_view', kwargs={'course_id': invite.course.id}))
            # if user is not owned this invite
            return HttpResponseRedirect(""{}?next={}"".format(reverse('new_login'), self.request.path))
        else:
            u_hash = uuid4().hex
            self.request.session['u_hash'] = u_hash
            kwargs = dict(available_backends=load_backends(settings.AUTHENTICATION_BACKENDS))
            kwargs['u_hash'] = u_hash
            kwargs['next'] = self.request.path
            invite = get_object_or_404(Invite, code=self.kwargs['code'])
            init_data = {'next': kwargs['next'], 'email': invite.email, 'u_hash': kwargs['u_hash']}
            if invite.user:
                # user already registered
                # show login page
                kwargs['form'] = EmailLoginForm(initial=init_data)
                template_name = 'psa/new_custom_login.html'
            else:
                # user not yet registered
                # show signup page
                # try to find user with email
                user = invite.search_user_by_email(invite.email)
                if user:
                    invite.user = user
                    invite.save()
                    kwargs['form'] = EmailLoginForm(initial=init_data)
                    template_name = 'psa/new_custom_login.html'
                else:
                    kwargs['form'] = SignUpForm(initial=init_data)
                    template_name = 'psa/signup.html'
            return self.render(template_name, kwargs)


class ResendInviteView(NewLoginRequiredMixin, CourseCoursletUnitMixin, View):
    def post(self, request, code):
        invite = get_object_or_404(Invite, code=code)
        if invite.course.addedBy != self.request.user:
            raise Http404()
        response = invite.send_mail(self.request, self)
        messages.add_message(self.request, messages.SUCCESS,
                             ""We just resent invitation to {}"".format(invite.email))
        return json_response(response)


class DeleteInviteView(NewLoginRequiredMixin, CourseCoursletUnitMixin, DeleteView):
    query_pk_and_slug = True
    slug_url_kwarg = 'code'
    slug_field = 'code'
    pk_url_kwarg = 'pk'
    model = Invite

    def get_queryset(self, queryset=None):
        if queryset:
            return queryset.my_invitest(self.request)
        return Invite.objects.my_invites(self.request)

    def get_success_url(self):
        kwargs = {
            'pk': self.get_object().course.id,
            'courselet_pk': self.get_object().enroll_unit_code.courseUnit.unit.id
        }
        return reverse('ctms:courselet_invite', kwargs=kwargs)

    def delete(self, request, *args, **kwargs):
        response = super(DeleteInviteView, self).delete(request, *args, **kwargs)
        messages.add_message(self.request, messages.SUCCESS, ""Invite successfully deleted"")
        return response


class EmailSentView(TemplateView):  # NewLoginRequiredMixin , CourseCoursletUnitMixin ?
    template_name = 'ctms/email_sent.html'

    def get_context_data(self, **kwargs):
        kw = super(EmailSentView, self).get_context_data(**kwargs)
        kw.update({'resend_user_email': self.request.session.get('resend_user_email')})
        return kw


class ReorderUnits(NewLoginRequiredMixin, CourseCoursletUnitMixin, View):
    def post(self, request, course_pk, courslet_pk):
        # new ordered ids are in request.POST['ordered_ids']
        data = json.loads(request.POST.get('data') or '{}')
        ids = [int(i) for i in data.get('ordered_ids')]

        if not ids:
            return JsonResponse({'ok': 0, 'err': 'empty'})

        order = range(len(ids))
        id_order = dict(zip(ids, order))
        # check that all ids are unique
        if len(set(ids)) != len(ids):
            raise JsonResponse({'ok': 0, 'err': 'not uniq'})

        courselet = self.get_courslet()
        units = self.get_units_by_courselet(courselet)

        old_ids = units.values_list('id', flat=True)
        old_order = units.values_list('order', flat=True)
        old_id_order = dict(zip(old_ids, old_order))

        # check that all provided ids are correct
        for _id in ids:
            if _id not in old_ids:
                raise JsonResponse({'ok': 0, 'err': 'not correct ids'})

        for unit in units:
            _id = unit.id
            order = id_order[_id]
            if old_id_order[_id] == order:
                continue
            unit.order = order
            unit.save()
        cache.delete(memoize.cache_key('get_units_by_courselet', courselet))
        return JsonResponse({'ok': 1, 'msg': 'Order has been changed!'})


class Onboarding(NewLoginRequiredMixin, TemplateView):
    template_name = 'ctms/onboarding.html'

    def get_context_data(self, **kwargs):
        context = super(Onboarding, self).get_context_data(**kwargs)
        users_course = Course.objects.filter(addedBy=self.request.user).last()
        users_courselet = CourseUnit.objects.filter(
            addedBy=self.request.user,
            course=users_course
        ).last()
        users_thread = Lesson.objects.filter(addedBy=self.request.user).last()
        introduction_course_id = get_onboarding_setting(onboarding.INTRODUCTION_COURSE_ID)
        course = Course.objects.filter(id=introduction_course_id).first()
        enroll_unit_code = EnrollUnitCode.objects.filter(
            courseUnit__course_id=introduction_course_id,
            isLive=False, isPreview=False, isTest=False
        ).first()
        enroll_url = '/chat/enrollcode/{}'.format(
            enroll_unit_code.enrollCode or EnrollUnitCode.get_code(enroll_unit_code.courseUnit)
        ) if enroll_unit_code else '#'
        context.update(dict(
            introduction_course=course,
            users_course=users_course,
            users_courselet=users_courselet,
            users_thread=users_thread,
            enroll_url=enroll_url
        ))
        status = get_onboarding_status_with_settings(self.request.user.id)
        steps = {
            key: status.get(key) for key in get_onboarding_steps()
        }
        context.update(**steps)
        return context

    def get(self, request, *args, **kwargs):
        response = super(Onboarding, self).get(kwargs)
        if not waffle.switch_is_active('ctms_onboarding_enabled'):
            return redirect('ctms:my_courses')
        return response
/n/n/n",0
115,115,edad6dd8f6bfabce4d4f7b9e120df3ebcc8d9c33,"/mysite/core/common/onboarding.py/n/nUSER_ID = 'user_id'
STEP_1 = 'view_introduction'
STEP_2 = 'instructor_intro'
STEP_3 = 'create_course'
STEP_4 = 'create_courselet'
STEP_5 = 'create_thread'
STEP_6 = 'preview_courselet'
STEP_7 = 'next_steps'
STEP_8 = 'invite_somebody'

# settings

INTRODUCTION_COURSE_ID = 'introduction_course_id'
VIEW_INTRODUCTION = STEP_1
INTRODUCTION_INTRO = STEP_2
CREATE_COURSE = STEP_3
CREATE_COURSELET = STEP_4
CREATE_THREAD = STEP_5
PREVIEW_COURSELET = STEP_6
NEXT_STEPS = STEP_7
INVITE_SOMEBODY = STEP_8
/n/n/n/mysite/core/common/utils.py/n/n""""""
Various utilities.
""""""
import functools

from django.dispatch import receiver
from django.conf import settings
from django.core.mail import send_mail
from django.template import loader, Context

from core.common.mongo import c_onboarding_status, c_onboarding_settings
from core.common import onboarding


def send_email(context_data, from_email, to_email, template_subject, template_text):
    """"""
    Send an email with specified content.

    Arguments:
        context_data (dict): data to be passed to templates.
        from_email (str): sender's email.
        to_email (list): list of addresses to send an email to.
        template_subject (str): path to a subject template, e.g. 'ctms/email/subject.txt'
        template_text (str):  path to a body template, e.g. 'ctms/email/text.txt'
    """"""
    context = Context(context_data)

    subj_template = loader.get_template(template_subject)
    rendered_subj = subj_template.render(context)

    text_template = loader.get_template(template_text)
    rendered_text = text_template.render(context)

    send_mail(
        rendered_subj,
        rendered_text,
        from_email,
        to_email,
        fail_silently=True
    )


def suspending_receiver(signal, **decorator_kwargs):
    """"""
    Custom decorator to disable signals.

    Reference:
        https://devblog.kogan.com/blog/disable-signal-receivers-in-your-django-tests
    """"""

    def our_wrapper(func):
        @receiver(signal, **decorator_kwargs)
        @functools.wraps(func)
        def fake_receiver(sender, **kwargs):
            if settings.SUSPEND_SIGNALS:
                return
            return func(sender, **kwargs)

        return fake_receiver

    return our_wrapper


def get_onboarding_steps():
    """"""
    Get fields from somewhere, haven't decided yet

    Return list of steps to be done
    """"""
    return [
        onboarding.STEP_1,
        onboarding.STEP_2,
        onboarding.STEP_3,
        onboarding.STEP_4,
        onboarding.STEP_5,
        onboarding.STEP_6,
        onboarding.STEP_7,
        onboarding.STEP_8
    ]


def get_onboarding_percentage(user_id):
    if user_id:
        status = c_onboarding_status(use_secondary=True).find_one({onboarding.USER_ID: user_id}) or {}
        if status:
            steps = [status.get(key, False) for key in get_onboarding_steps()]
            return round(
                len(filter(lambda x: x, steps)) / float(len(steps)) * 100,
                0
            )
    return 0


def update_onboarding_step(step, user_id):
    find_crit = {onboarding.USER_ID: user_id}
    onboarding_data = c_onboarding_status(use_secondary=True).find_one(find_crit)
    if not onboarding_data or not onboarding_data.get(step):
        c_onboarding_status().update_one(find_crit, {'$set': {
            step: True
        }}, upsert=True)


ONBOARDING_STEPS_DEFAULT_TEMPLATE = {
    'title': '',
    'description': '',
    'html': ''
}

ONBOARDING_SETTINGS_DEFAULT = {
    onboarding.INTRODUCTION_COURSE_ID: settings.ONBOARDING_INTRODUCTION_COURSE_ID,
    onboarding.VIEW_INTRODUCTION: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.INTRODUCTION_INTRO: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.CREATE_COURSE: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.CREATE_COURSELET: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.CREATE_THREAD: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.INVITE_SOMEBODY: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.PREVIEW_COURSELET: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.NEXT_STEPS: ONBOARDING_STEPS_DEFAULT_TEMPLATE
}


# TODO: write unit tests
def get_onboarding_setting(setting_name):
    """"""
    Return settings for the certain `settings_name`
    If it does not exist take default settings and save it to the MongoDB
    Argument:
        setting_name (str): name of setting e.g. `create_course`
    Return:
        dict object with the data. See ONBOARDING_STEPS_DEFAULT_TEMPLATE
    """"""
    try:
        ONBOARDING_SETTINGS_DEFAULT[setting_name]
    except KeyError:
        return

    onboarding_setting = c_onboarding_settings(use_secondary=True).find_one({'name': setting_name})
    if not onboarding_setting:
        c_onboarding_settings().insert({'name': setting_name, 'data': ONBOARDING_SETTINGS_DEFAULT[setting_name]})
        return ONBOARDING_SETTINGS_DEFAULT[setting_name]
    return onboarding_setting['data']


# TODO: refactor this, settings for each step no need longer
def get_onboarding_status_with_settings(user_id):
    """"""
    Return combined data with the status by on-boarding steps (done: true/false)
    and settings for according status name
    Argument:
        user_id (int): user's id
    Return:
        dict with data
    Example:
    {
        ""instructor_intro"": {
            ""done"": true,
            ""settings"": {
                ""html"": """",
                ""description"": """",
                ""title"": """"
            }
        },
        ""create_course"": {
            ""done"": true,
            ""settings"": {
                ""html"": """",
                ""description"": """",
                ""title"": """"
            }
        },
        ""create_courselet"": {
            ""done"": false,
            ""settings"": {
                ""html"": """",
                ""description"": """",
                ""title"": """"
            }
        },
        ""review_answers"": {
            ""done"": true,
            ""settings"": {
                ""html"": ""<p>Title</p>"",
                ""description"": ""Here is some description"",
                ""title"": ""Title""
            }
        },
        ""invite_somebody"": {
            ""done"": true,
            ""settings"": {
                ""html"": """",
                ""description"": """",
                ""title"": """"
            }
        },
        ""create_thread"": {
            ""done"": false,
            ""settings"": {
                ""html"": """",
                ""description"": """",
                ""title"": """"
            }
        }
    }
    """"""
    onboarding_status = c_onboarding_status().find_one({onboarding.USER_ID: user_id}, {'_id': 0, 'user_id': 0}) or {}
    data = {}

    for step in get_onboarding_steps():
        data[step] = {
            'done': onboarding_status.get(step, False)
        }
    return data


/n/n/n/mysite/core/tests/utils.py/n/n""""""
Test core utility functions.
""""""
import mock
from unittest import skip
from ddt import ddt, data, unpack
from django.conf import settings
from django.contrib.sites.models import Site
from django.core import mail
from django.test import TestCase

from core.common.utils import send_email, get_onboarding_percentage
from core.common import onboarding
from core.common.utils import get_onboarding_setting, ONBOARDING_STEPS_DEFAULT_TEMPLATE, \
    get_onboarding_status_with_settings


@ddt
class UtilityTest(TestCase):
    """"""
    Test auxiliary functions.
    """"""

    def test_send_email(self):
        """"""
        Test email sending.

        Ensure an email has proper subject and body.
        """"""
        send_email(
            context_data={
                ""milestone"": ""first"",
                ""students_number"": 2,
                ""course_title"": ""Test Course"",
                ""lesson_title"": ""Test Lesson"",
                ""current_site"": Site.objects.get_current(),
                ""course_id"": 1,
                ""unit_lesson_id"": 1,
                ""courselet_pk"": 1
            },
            from_email=settings.EMAIL_FROM,
            to_email=[""test@example.com""],
            template_subject=""ct/email/milestone_ortc_notify_subject"",
            template_text=""ct/email/milestone_ortc_notify_text""
        )

        self.assertEqual(len(mail.outbox), 1)

        # FIXME: outbox properties do not get overridden
        # self.assertEqual(mail.outbox[0].from_email, settings.EMAIL_FROM)
        # self.assertEqual(mail.outbox[0].to, ""test@example.com"")
        # self.assertContains(mail.outbox[0].subject, ""2"")
        # self.assertContains(mail.outbox[0].subject, ""first"")
        # self.assertContains(mail.outbox[0].body, ""first"")
        # self.assertContains(mail.outbox[0].body, ""2"")
        # self.assertContains(mail.outbox[0].body, ""Test Course"")
        # self.assertContains(mail.outbox[0].body, ""Test Lesson"")

    @mock.patch('core.common.utils.c_onboarding_status')
    @unpack
    @data(
        ({onboarding.STEP_1: 0, onboarding.STEP_2: 0, onboarding.STEP_3: 0, onboarding.STEP_4: 0, onboarding.STEP_5: 0, onboarding.STEP_6: 0, onboarding.STEP_7: 0, onboarding.STEP_8: 0}, 0),
        ({onboarding.STEP_1: 1, onboarding.STEP_2: 0, onboarding.STEP_3: 0, onboarding.STEP_4: 0, onboarding.STEP_5: 0, onboarding.STEP_6: 0, onboarding.STEP_7: 0, onboarding.STEP_8: 0}, 13.0),
        ({onboarding.STEP_1: 0, onboarding.STEP_2: 1, onboarding.STEP_3: 0, onboarding.STEP_4: 0, onboarding.STEP_5: 0, onboarding.STEP_6: 1, onboarding.STEP_7: 1, onboarding.STEP_8: 0}, 38.0),
        ({onboarding.STEP_1: 0, onboarding.STEP_2: 0, onboarding.STEP_3: 1, onboarding.STEP_4: 1, onboarding.STEP_5: 1, onboarding.STEP_6: 1, onboarding.STEP_7: 0, onboarding.STEP_8: 0}, 50.0),
        ({onboarding.STEP_1: 1, onboarding.STEP_2: 0, onboarding.STEP_3: 1, onboarding.STEP_4: 1, onboarding.STEP_5: 1, onboarding.STEP_6: 1, onboarding.STEP_7: 1, onboarding.STEP_8: 0}, 75.0),
        ({onboarding.STEP_1: 1, onboarding.STEP_2: 1, onboarding.STEP_3: 1, onboarding.STEP_4: 1, onboarding.STEP_5: 1, onboarding.STEP_6: 1, onboarding.STEP_7: 1, onboarding.STEP_8: 1}, 100.0)
    )
    def test_percentage_of_done(self, steps, result, mock):
        _mock = mock.return_value
        _mock.find_one.return_value = steps
        self.assertEqual(get_onboarding_percentage(1), result)

    @mock.patch('core.common.utils.c_onboarding_status')
    @unpack
    @data(
        (onboarding.INTRODUCTION_COURSE_ID, settings.ONBOARDING_INTRODUCTION_COURSE_ID),
        (onboarding.VIEW_INTRODUCTION, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.INTRODUCTION_INTRO, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.CREATE_COURSE, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.CREATE_COURSELET, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.CREATE_THREAD, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.INVITE_SOMEBODY, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.PREVIEW_COURSELET, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        (onboarding.NEXT_STEPS, ONBOARDING_STEPS_DEFAULT_TEMPLATE),
        # nonexistent key
        ('fake_key', None)
    )
    def test_get_onboarding_setting(self, setting_name, value, _mock):
        self.assertEqual(get_onboarding_setting(setting_name), value)

    @skip
    @mock.patch('core.common.utils.get_onboarding_setting')
    @mock.patch('core.common.utils.c_onboarding_status')
    def test_get_onboarding_status_with_settings(self, status_mock, settings_mock):

        def mocked_setting(setting_name):
            data = {
                onboarding.INTRODUCTION_INTRO: {
                    ""html"": ""<p>instructor_intro</p>"",
                    ""description"": ""instructor_intro desc"",
                    ""title"": ""instructor_intro""
                },
                onboarding.CREATE_COURSE: {
                    ""html"": ""<p>create_course</p>"",
                    ""description"": ""create_course desc"",
                    ""title"": ""create_course""
                },
                onboarding.CREATE_COURSELET: {
                    ""html"": ""<p>create_courselet</p>"",
                    ""description"": ""create_courselet desc"",
                    ""title"": ""create_courselet""
                },
                onboarding.NEXT_STEPS: {
                    ""html"": ""<p>next_steps</p>"",
                    ""description"": ""next_steps desc"",
                    ""title"": ""next_steps""
                },
                onboarding.INVITE_SOMEBODY: {
                    ""html"": ""<p>invite_somebody</p>"",
                    ""description"": ""invite_somebody desc"",
                    ""title"": ""invite_somebody""
                },
                onboarding.CREATE_THREAD: {
                    ""html"": ""<p>create_thread</p>"",
                    ""description"": ""create_thread desc"",
                    ""title"": ""create_thread""
                },
                onboarding.VIEW_INTRODUCTION: {
                    ""html"": ""<p>view_introduction</p>"",
                    ""description"": ""view_introduction desc"",
                    ""title"": ""view_introduction""
                },
                onboarding.PREVIEW_COURSELET: {
                    ""html"": ""<p>preview_courselet</p>"",
                    ""description"": ""preview_courselet desc"",
                    ""title"": ""preview_courselet""
                }
            }
            return data[setting_name]

        expected_result = {
            onboarding.INTRODUCTION_INTRO: {
                ""done"": False,
                ""settings"": {
                    ""html"": ""<p>instructor_intro</p>"",
                    ""description"": ""instructor_intro desc"",
                    ""title"": ""instructor_intro""
                }
            },
            onboarding.CREATE_COURSE: {
                ""done"": True,
                ""settings"": {
                    ""html"": ""<p>create_course</p>"",
                    ""description"": ""create_course desc"",
                    ""title"": ""create_course""
                }
            },
            onboarding.CREATE_COURSELET: {
                ""done"": False,
                ""settings"": {
                    ""html"": ""<p>create_courselet</p>"",
                    ""description"": ""create_courselet desc"",
                    ""title"": ""create_courselet""
                }
            },
            onboarding.NEXT_STEPS: {
                ""done"": False,
                ""settings"": {
                    ""html"": ""<p>next_steps</p>"",
                    ""description"": ""next_steps desc"",
                    ""title"": ""next_steps""
                }
            },
            onboarding.INVITE_SOMEBODY: {
                ""done"": True,
                ""settings"": {
                    ""html"": ""<p>invite_somebody</p>"",
                    ""description"": ""invite_somebody desc"",
                    ""title"": ""invite_somebody""
                }
            },
            onboarding.CREATE_THREAD: {
                ""done"": False,
                ""settings"": {
                    ""html"": ""<p>create_thread</p>"",
                    ""description"": ""create_thread desc"",
                    ""title"": ""create_thread""
                }
            },
            onboarding.VIEW_INTRODUCTION: {
                ""done"": False,
                ""settings"": {
                    ""html"": ""<p>view_introduction</p>"",
                    ""description"": ""view_introduction desc"",
                    ""title"": ""view_introduction""
                }
            },
            onboarding.PREVIEW_COURSELET: {
                ""done"": False,
                ""settings"": {
                    ""html"": ""<p>preview_courselet</p>"",
                    ""description"": ""preview_courselet desc"",
                    ""title"": ""preview_courselet""
                }
            }
        }
        status_mock = status_mock.return_value
        status_mock.find_one.return_value = {
            onboarding.VIEW_INTRODUCTION: False,
            onboarding.INTRODUCTION_INTRO: False,
            onboarding.CREATE_COURSE: True,
            onboarding.CREATE_COURSELET: False,
            onboarding.CREATE_THREAD: False,
            onboarding.INVITE_SOMEBODY: True,
            onboarding.NEXT_STEPS: False,
            onboarding.PREVIEW_COURSELET: False
        }
        settings_mock.side_effect = mocked_setting
        user_id = 1  # value doesn't matter
        data = get_onboarding_status_with_settings(user_id)
        self.assertEqual(data, expected_result)
/n/n/n/mysite/ct/management/commands/onboarding_preprocess.py/n/n
from django.core.management.base import BaseCommand

from ct.models import Course, Role, UnitLesson, Unit, Lesson, Response
from ctms.models import Invite
from chat.models import Chat, EnrollUnitCode
from accounts.models import Instructor
from core.common.utils import update_onboarding_step, get_onboarding_percentage
from core.common import onboarding
from django.conf import settings


class Command(BaseCommand):
    help = 'Onboarding preprocessing'

    def handle(self, *args, **options):
        for instructor in Instructor.objects.all():

            try:
                course = Course.objects.get(id=settings.ONBOARDING_INTRODUCTION_COURSE_ID)
            except Course.DoesNotExist:
                print(""Onboarding course is not provided"")
                return

            chat_exists = Chat.objects.filter(
                user=instructor.user,
                enroll_code__courseUnit__course=course,
                progress__gte=70
            ).exists()
            if chat_exists:
                update_onboarding_step(onboarding.STEP_2, instructor.user_id)

            # if instructor has created create_course

            if Course.objects.filter(addedBy=instructor.user).exists():
                update_onboarding_step(onboarding.STEP_3, instructor.user_id)

            # if instructor has created a create_courselet

            if Unit.objects.filter(addedBy=instructor.user).exists():
                update_onboarding_step(onboarding.STEP_4, instructor.user_id)

            # if instructor has created a create_thread

            if Lesson.objects.filter(addedBy=instructor.user).exists():
                update_onboarding_step(onboarding.STEP_5, instructor.user_id)

            # if he has created invite_somebody
            if Invite.objects.filter(instructor=instructor).exists():
                update_onboarding_step(onboarding.STEP_8, instructor.user_id)

            enroll_unit_code_exists = EnrollUnitCode.objects.filter(
                courseUnit__course__addedBy=instructor.user,
                isPreview=True,
                isLive=False,
                isTest=False
            ).exists()
            if enroll_unit_code_exists:
                update_onboarding_step(onboarding.STEP_6, instructor.user_id)

            print(""Instructor {} passed onboarding at {}%"".format(
                instructor.user.username, get_onboarding_percentage(instructor.user.id))
            )
/n/n/n/mysite/ctms/models.py/n/nimport re
from uuid import uuid4

from django.db import models
from django.db.models.signals import post_save
from django.db.utils import IntegrityError
from django.dispatch import receiver
from django.contrib.auth.models import User
from django.contrib.sites.models import Site
from django.conf import settings
from django.core.mail import send_mail
from django.core.urlresolvers import reverse
from django.http.response import Http404
from django.template import loader, Context

from accounts.models import Instructor
from chat.models import EnrollUnitCode
from core.common import onboarding
from core.common.utils import update_onboarding_step
from ct.models import Course




STATUS_CHOICES = (
    ('pendind', 'pending'),
    ('joined', 'joined'),
)

TYPE_CHOICES = (
    ('student', 'student'),
    ('tester', 'tester')
)

def clean_email_name(email):
    email_name, domain = email.split('@', 1)
    email_name = email_name.replace('.', '')
    return email_name, domain

class InviteQuerySet(models.QuerySet):
    def my_invites(self, request):
        return self.filter(instructor=request.user.instructor)

    def testers(self):
        return self.filter(type='tester')

    def students(self):
        return self.filter(type='student')

    def shared_for_me(self, request):
        return self.filter(
            models.Q(user=request.user) | models.Q(email=request.user.email)
        )


class Invite(models.Model):
    instructor = models.ForeignKey(Instructor)
    user = models.ForeignKey(User, blank=True, null=True)
    email = models.EmailField()
    code = models.CharField('invite code', max_length=255)
    status = models.CharField('status', max_length=20, choices=STATUS_CHOICES, default='pending')
    type = models.CharField('invite type', max_length=50, choices=TYPE_CHOICES, default='tester')
    course = models.ForeignKey(Course)
    enroll_unit_code = models.ForeignKey(EnrollUnitCode, null=True)

    added = models.DateTimeField('added datetime', auto_now_add=True)

    objects = InviteQuerySet.as_manager()

    @staticmethod
    def search_user_by_email(email):
        return User.objects.filter(email=email).first()

    @classmethod
    def create_new(cls, commit, course, instructor, email, invite_type, enroll_unit_code):
        user = Invite.search_user_by_email(email)
        try:
            old_invite = Invite.get_by_user_or_404(
                user=user,
                type=invite_type,
                course=course,
                instructor=instructor,
                enroll_unit_code=enroll_unit_code
            )
            if old_invite:
                return old_invite
        except Http404:
            pass
        code = Invite(
            instructor=instructor,
            user=user,
            email=email,
            code=uuid4().hex,
            status='pending',
            type=invite_type,
            course=course,
            enroll_unit_code=enroll_unit_code
        )
        if commit:
            code.save()
        return code

    def get_invited_user_username(self):
        return self.email.split(""@"")[0] if self.email else ''

    class Meta:
        unique_together = ('instructor', 'email', 'type', 'course', 'enroll_unit_code')

    def save(self, force_insert=False, force_update=False, using=None,
             update_fields=None):
        user = Invite.search_user_by_email(self.email)
        self.user = user
        return super(Invite, self).save(force_insert, force_update, using, update_fields)

    def send_mail(self, request, view):
        try:
            # TODO: use `send_email` utility function here (see `core`)
            context = Context({
                'invite': self,
                'current_site': Site.objects.get_current(request)
            })
            subj_template = loader.get_template('ctms/email/invite_subject.txt')
            rendered_subj = subj_template.render(context)

            text_template = loader.get_template('ctms/email/invite_text.txt')
            rendered_text = text_template.render(context)
            send_mail(
                rendered_subj,
                rendered_text,
                settings.EMAIL_FROM,
                [self.email],
                fail_silently=False
            )
            return {
                'success': True,
                'message': 'Invitation successfully sent.',
                'invite': {
                    'status': self.status,
                }
            }
        except IntegrityError:
            return {
                'success': False,
                'message': 'You already have sent invite to user with {} email'.format(request.POST['email'])
            }

    def get_absolute_url(self):
        return reverse('ctms:tester_join_course', kwargs={'code': self.code})

    @staticmethod
    def get_by_user_or_404(user, **kwargs):
        '''
        Do a search for invite by passed parameters and user.
         NOTE: this function firstly try to get invite by passed kwargs,
         then check that Invite.email and user.email are equal,
         if they not - trying to check Invite.email and user.email
         !! excluding dots from email-name. !!
        :param user: request.user
        :param kwargs: params to search by
        :return: invite if found
        :raise: Http404 if not found
        '''
        if not user:
            raise Http404
        invites = Invite.objects.filter(
            **kwargs
        )
        my_invite = None

        for invite in invites:
            if invite and invite.email == user.email:
                my_invite = invite
                break
            user_email_name, user_domain = clean_email_name(user.email)
            invite_email, invite_domain = clean_email_name(invite.email)
            if invite_domain != user_domain:
                continue
            res = re.search(
                ""^{}@{}$"".format(r""\.?"".join(user_email_name), user_domain),
                ""{}@{}"".format(invite_email, invite_domain)
            )
            if res and res.string:
                my_invite = invite
                break
        else:
            raise Http404()
        if my_invite:
            return my_invite
        else:
            raise Http404()

    def __unicode__(self):
        return ""Code {}, User {}"".format(self.code, self.email)


@receiver(post_save, sender=Invite)
def onboarding_invite_created(sender, instance, **kwargs):
    update_onboarding_step(onboarding.STEP_8, instance.instructor.user_id)
/n/n/n",1
