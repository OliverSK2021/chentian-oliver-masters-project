,Unnamed: 0,id,code,label
68,68,3f28620d475220dfdb06f79787158ac50727c61a,"ZMSItem.py/n/n################################################################################
# ZMSItem.py
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
################################################################################

# Imports.
from DateTime.DateTime import DateTime
from Products.PageTemplates.PageTemplateFile import PageTemplateFile
from Persistence import Persistent
from Acquisition import Implicit
import OFS.SimpleItem, OFS.ObjectManager
import zope.interface
# Product Imports.
import IZMSDaemon


################################################################################
################################################################################
###
###   Abstract Class ZMSItem
###
################################################################################
################################################################################
class ZMSItem(
    OFS.ObjectManager.ObjectManager,
    OFS.SimpleItem.Item,
    Persistent,  # Persistent.
    Implicit,    # Acquisition.
    ):

    # Documentation string.
    __doc__ = """"""ZMS product module.""""""
    # Version string. 
    __version__ = '0.1' 
    
    # Management Permissions.
    # -----------------------
    __authorPermissions__ = (
      'manage_page_header', 'manage_page_footer', 'manage_tabs', 'manage_main_iframe' 
      )
    __viewPermissions__ = (
      'manage_menu',
      )
    __ac_permissions__=(
      ('ZMS Author', __authorPermissions__),
      ('View', __viewPermissions__),
      )

    # Templates.
    # ----------
    manage = PageTemplateFile('zpt/object/manage', globals())
    manage_workspace = PageTemplateFile('zpt/object/manage', globals())
    manage_main = PageTemplateFile('zpt/ZMSObject/manage_main', globals())
    manage_main_iframe = PageTemplateFile('zpt/ZMSObject/manage_main_iframe', globals())

    # --------------------------------------------------------------------------
    #  ZMSItem.zmi_body_content:
    # --------------------------------------------------------------------------
    def zmi_body_content(self, *args, **kwargs):
      request = self.REQUEST
      response = request.RESPONSE
      return self.getBodyContent(request)

    # --------------------------------------------------------------------------
    #  ZMSItem.zmi_manage_css:
    # --------------------------------------------------------------------------
    def zmi_manage_css(self, *args, **kwargs):
      """""" ZMSItem.zmi_manage_css """"""
      request = self.REQUEST
      response = request.RESPONSE
      response.setHeader('Content-Type','text/css')
      css = []
      for stylesheet in self.getStylesheets():
        try:
          s = stylesheet(self)
        except:
          s = str(stylesheet)
        css.append(""/* ######################################################################"")
        css.append(""   ### %s""%stylesheet.absolute_url())
        css.append(""   ###################################################################### */"")
        css.append(s)
      return '\n'.join(css)

    # --------------------------------------------------------------------------
    #  ZMSItem.zmi_manage_menu:
    # --------------------------------------------------------------------------
    def zmi_manage_menu(self, *args, **kwargs):
      return self.manage_menu(args,kwargs)

    # --------------------------------------------------------------------------
    #  zmi_body_attrs:
    # --------------------------------------------------------------------------
    def zmi_body_class(self, *args, **kwargs):
      request = self.REQUEST
      l = ['zmi']
      l.append(request['lang'])
      l.extend(map(lambda x:kwargs[x],kwargs.keys()))
      l.append(self.meta_id)
      # FOR EVALUATION: adding node specific css classes [list]
      internal_dict = self.attr('internal_dict')
      if isinstance(internal_dict,dict) and internal_dict.get('css_classes',None):
        l.extend( internal_dict['css_classes'] )
      l.extend(request['AUTHENTICATED_USER'].getRolesInContext(self))
      return ' '.join(l)

    # --------------------------------------------------------------------------
    #  ZMSItem.zmi_page_request:
    # --------------------------------------------------------------------------
    def _zmi_page_request(self, *args, **kwargs):
      for daemon in filter(lambda x:IZMSDaemon.IZMSDaemon in list(zope.interface.providedBy(x)),self.getDocumentElement().objectValues()):
        daemon.startDaemon()
      request = self.REQUEST
      request.set( 'ZMS_THIS',self.getSelf())
      request.set( 'ZMS_DOCELMNT',self.breadcrumbs_obj_path()[0])
      request.set( 'ZMS_ROOT',request['ZMS_DOCELMNT'].absolute_url())
      request.set( 'ZMS_COMMON',getattr(self,'common',self.getHome()).absolute_url())
      request.set( 'ZMI_TIME',DateTime().timeTime())
      request.set( 'ZMS_CHARSET',request.get('ZMS_CHARSET','utf-8'))
      if not request.get('HTTP_ACCEPT_CHARSET'):
        request.set('HTTP_ACCEPT_CHARSET','%s;q=0.7,*;q=0.7'%request['ZMS_CHARSET'])
      if (request.get('ZMS_PATHCROPPING',False) or self.getConfProperty('ZMS.pathcropping',0)==1) and request.get('export_format','')=='':
        base = request.get('BASE0','')
        if request['ZMS_ROOT'].startswith(base):
          request.set( 'ZMS_ROOT',request['ZMS_ROOT'][len(base):])
          request.set( 'ZMS_COMMON',request['ZMS_COMMON'][len(base):])
    
    def zmi_page_request(self, *args, **kwargs):
      request = self.REQUEST
      RESPONSE = request.RESPONSE
      SESSION = request.SESSION
      self._zmi_page_request()
      RESPONSE.setHeader('Expires',DateTime(request['ZMI_TIME']-10000).toZone('GMT+1').rfc822())
      RESPONSE.setHeader('Cache-Control', 'no-cache')
      RESPONSE.setHeader('Pragma', 'no-cache')
      RESPONSE.setHeader('Content-Type', 'text/html;charset=%s'%request['ZMS_CHARSET'])
      if not request.get( 'preview'):
        request.set( 'preview','preview')
      langs = self.getLanguages(request)
      if request.get('lang') not in langs:
        request.set('lang',langs[0])
      if request.get('manage_lang') not in self.getLocale().get_manage_langs():
        request.set('manage_lang',self.get_manage_lang())
      if not request.get('manage_tabs_message'):
        request.set( 'manage_tabs_message',self.getConfProperty('ZMS.manage_tabs_message',''))
      # manage_system
      if request.form.has_key('zmi-manage-system'):
        request.SESSION.set('zmi-manage-system',int(request.get('zmi-manage-system')))
      # avoid declarative urls
      physical_path = self.getPhysicalPath()
      path_to_handle = request['URL0'][len(request['BASE0']):].split('/')
      path = path_to_handle[:-1]
      if self.getDocumentElement().id in path and len(filter(lambda x:x.find('.')>0 or x.startswith('manage_'),path))==0:
        for i in range(len(path)):
          if path[:-(i+1)] != physical_path[:-(i+1)]:
            path[:-(i+1)] = physical_path[:-(i+1)]
        new_path = path+[path_to_handle[-1]]
        if path_to_handle != new_path:
          request.RESPONSE.redirect('/'.join(new_path))

    def f_standard_html_request(self, *args, **kwargs):
      request = self.REQUEST
      self._zmi_page_request()
      if not request.get( 'lang'):
        request.set( 'lang',self.getLanguage(request))
      if not request.get('manage_lang') in self.getLocale().get_manage_langs():
        request.set( 'manage_lang',self.get_manage_lang())


    # --------------------------------------------------------------------------
    #  ZMSItem.display_icon:
    #
    #  @param REQUEST
    # --------------------------------------------------------------------------
    def display_icon(self, REQUEST, meta_type=None, key='icon', zpt=None):
      if meta_type is None:
        return self.icon
      else:
        return self.aq_parent.display_icon( REQUEST, meta_type, key, zpt)


    # --------------------------------------------------------------------------
    #  ZMSItem.getTitlealt
    # --------------------------------------------------------------------------
    def getTitlealt( self, REQUEST):
      return self.getZMILangStr( self.meta_type)


    # --------------------------------------------------------------------------
    #  ZMSItem.breadcrumbs_obj_path:
    # --------------------------------------------------------------------------
    def breadcrumbs_obj_path(self, portalMaster=True):
      return self.aq_parent.breadcrumbs_obj_path(portalMaster)

################################################################################/n/n/n",0
69,69,3f28620d475220dfdb06f79787158ac50727c61a,"/ZMSItem.py/n/n################################################################################
# ZMSItem.py
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
################################################################################

# Imports.
from DateTime.DateTime import DateTime
from Products.PageTemplates.PageTemplateFile import PageTemplateFile
from Persistence import Persistent
from Acquisition import Implicit
import OFS.SimpleItem, OFS.ObjectManager
import zope.interface
# Product Imports.
import IZMSDaemon


################################################################################
################################################################################
###
###   Abstract Class ZMSItem
###
################################################################################
################################################################################
class ZMSItem(
    OFS.ObjectManager.ObjectManager,
    OFS.SimpleItem.Item,
    Persistent,  # Persistent.
    Implicit,    # Acquisition.
    ):

    # Documentation string.
    __doc__ = """"""ZMS product module.""""""
    # Version string. 
    __version__ = '0.1' 
    
    # Management Permissions.
    # -----------------------
    __authorPermissions__ = (
      'manage_page_header', 'manage_page_footer', 'manage_tabs', 'manage_main_iframe' 
      )
    __viewPermissions__ = (
      'manage_menu',
      )
    __ac_permissions__=(
      ('ZMS Author', __authorPermissions__),
      ('View', __viewPermissions__),
      )

    # Templates.
    # ----------
    manage = PageTemplateFile('zpt/object/manage', globals())
    manage_workspace = PageTemplateFile('zpt/object/manage', globals())
    manage_main = PageTemplateFile('zpt/ZMSObject/manage_main', globals())
    manage_main_iframe = PageTemplateFile('zpt/ZMSObject/manage_main_iframe', globals())

    # --------------------------------------------------------------------------
    #  ZMSItem.zmi_body_content:
    # --------------------------------------------------------------------------
    def zmi_body_content(self, *args, **kwargs):
      request = self.REQUEST
      response = request.RESPONSE
      return self.getBodyContent(request)

    # --------------------------------------------------------------------------
    #  ZMSItem.zmi_manage_css:
    # --------------------------------------------------------------------------
    def zmi_manage_css(self, *args, **kwargs):
      """""" ZMSItem.zmi_manage_css """"""
      request = self.REQUEST
      response = request.RESPONSE
      response.setHeader('Content-Type','text/css')
      css = []
      for stylesheet in self.getStylesheets():
        try:
          s = stylesheet(self)
        except:
          s = str(stylesheet)
        css.append(""/* ######################################################################"")
        css.append(""   ### %s""%stylesheet.absolute_url())
        css.append(""   ###################################################################### */"")
        css.append(s)
      return '\n'.join(css)

    # --------------------------------------------------------------------------
    #  ZMSItem.zmi_manage_menu:
    # --------------------------------------------------------------------------
    def zmi_manage_menu(self, *args, **kwargs):
      return self.manage_menu(args,kwargs)

    # --------------------------------------------------------------------------
    #  zmi_body_attrs:
    # --------------------------------------------------------------------------
    def zmi_body_class(self, *args, **kwargs):
      request = self.REQUEST
      l = ['zmi']
      l.append(request['lang'])
      l.extend(map(lambda x:kwargs[x],kwargs.keys()))
      l.append(self.meta_id)
      # FOR EVALUATION: adding node specific css classes [list]
      internal_dict = self.attr('internal_dict')
      if isinstance(internal_dict,dict) and internal_dict.get('css_classes',None):
        l.extend( internal_dict['css_classes'] )
      l.extend(request['AUTHENTICATED_USER'].getRolesInContext(self))
      return ' '.join(l)

    # --------------------------------------------------------------------------
    #  ZMSItem.zmi_page_request:
    # --------------------------------------------------------------------------
    def _zmi_page_request(self, *args, **kwargs):
      for daemon in filter(lambda x:IZMSDaemon.IZMSDaemon in list(zope.interface.providedBy(x)),self.getDocumentElement().objectValues()):
        daemon.startDaemon()
      request = self.REQUEST
      request.set( 'ZMS_THIS',self.getSelf())
      request.set( 'ZMS_DOCELMNT',self.breadcrumbs_obj_path()[0])
      request.set( 'ZMS_ROOT',request['ZMS_DOCELMNT'].absolute_url())
      request.set( 'ZMS_COMMON',getattr(self,'common',self.getHome()).absolute_url())
      request.set( 'ZMI_TIME',DateTime().timeTime())
      request.set( 'ZMS_CHARSET',request.get('ZMS_CHARSET','utf-8'))
      if not request.get('HTTP_ACCEPT_CHARSET'):
        request.set('HTTP_ACCEPT_CHARSET','%s;q=0.7,*;q=0.7'%request['ZMS_CHARSET'])
      if (request.get('ZMS_PATHCROPPING',False) or self.getConfProperty('ZMS.pathcropping',0)==1) and request.get('export_format','')=='':
        base = request.get('BASE0','')
        if request['ZMS_ROOT'].startswith(base):
          request.set( 'ZMS_ROOT',request['ZMS_ROOT'][len(base):])
          request.set( 'ZMS_COMMON',request['ZMS_COMMON'][len(base):])
    
    def zmi_page_request(self, *args, **kwargs):
      request = self.REQUEST
      RESPONSE = request.RESPONSE
      SESSION = request.SESSION
      self._zmi_page_request()
      RESPONSE.setHeader('Expires',DateTime(request['ZMI_TIME']-10000).toZone('GMT+1').rfc822())
      RESPONSE.setHeader('Cache-Control', 'no-cache')
      RESPONSE.setHeader('Pragma', 'no-cache')
      RESPONSE.setHeader('Content-Type', 'text/html;charset=%s'%request['ZMS_CHARSET'])
      if not request.get( 'preview'):
        request.set( 'preview','preview')
      langs = self.getLanguages(request)
      if request.get('lang') not in langs:
        request.set('lang',langs[0])
      if request.get('manage_lang') not in self.getLocale().get_manage_langs():
        request.set('manage_lang',self.get_manage_lang())
      if not request.get('manage_tabs_message'):
        request.set( 'manage_tabs_message',self.getConfProperty('ZMS.manage_tabs_message',''))
      # manage_system
      if request.form.has_key('zmi-manage-system'):
        request.SESSION.set('zmi-manage-system',int(request.get('zmi-manage-system')))
      # avoid declarative urls
      physical_path = self.getPhysicalPath()
      path_to_handle = request['URL0'][len(request['BASE0']):].split('/')
      path = path_to_handle[:-1]
      if len(filter(lambda x:x.find('.')>0 or x.startswith('manage_'),path))==0:
        for i in range(len(path)):
          if path[:-(i+1)] != physical_path[:-(i+1)]:
            path[:-(i+1)] = physical_path[:-(i+1)]
        new_path = path+[path_to_handle[-1]]
        if path_to_handle != new_path:
          request.RESPONSE.redirect('/'.join(new_path))

    def f_standard_html_request(self, *args, **kwargs):
      request = self.REQUEST
      self._zmi_page_request()
      if not request.get( 'lang'):
        request.set( 'lang',self.getLanguage(request))
      if not request.get('manage_lang') in self.getLocale().get_manage_langs():
        request.set( 'manage_lang',self.get_manage_lang())


    # --------------------------------------------------------------------------
    #  ZMSItem.display_icon:
    #
    #  @param REQUEST
    # --------------------------------------------------------------------------
    def display_icon(self, REQUEST, meta_type=None, key='icon', zpt=None):
      if meta_type is None:
        return self.icon
      else:
        return self.aq_parent.display_icon( REQUEST, meta_type, key, zpt)


    # --------------------------------------------------------------------------
    #  ZMSItem.getTitlealt
    # --------------------------------------------------------------------------
    def getTitlealt( self, REQUEST):
      return self.getZMILangStr( self.meta_type)


    # --------------------------------------------------------------------------
    #  ZMSItem.breadcrumbs_obj_path:
    # --------------------------------------------------------------------------
    def breadcrumbs_obj_path(self, portalMaster=True):
      return self.aq_parent.breadcrumbs_obj_path(portalMaster)

################################################################################/n/n/n",1
72,72,168cabf86730d56b7fa319278bf0f0034052666a,"cuckoo/core/submit.py/n/n# Copyright (C) 2016-2017 Cuckoo Foundation.
# This file is part of Cuckoo Sandbox - http://www.cuckoosandbox.org
# See the file 'docs/LICENSE' for copying permission.

import copy
import logging
import os
import sflock

from cuckoo.common.config import emit_options
from cuckoo.common.exceptions import CuckooOperationalError
from cuckoo.common.files import Folders, Files, Storage
from cuckoo.common.utils import validate_url, validate_hash
from cuckoo.common.virustotal import VirusTotalAPI
from cuckoo.core.database import Database

log = logging.getLogger(__name__)

db = Database()

class SubmitManager(object):
    def _handle_string(self, submit, tmppath, line):
        if not line:
            return

        if validate_hash(line):
            try:
                filedata = VirusTotalAPI().hash_fetch(line)
            except CuckooOperationalError as e:
                submit[""errors""].append(
                    ""Error retrieving file hash: %s"" % e
                )
                return

            filepath = Files.create(tmppath, line, filedata)

            submit[""data""].append({
                ""type"": ""file"",
                ""data"": filepath
            })
            return

        if validate_url(line):
            submit[""data""].append({
                ""type"": ""url"",
                ""data"": line
            })
            return

        submit[""errors""].append(
            ""'%s' was neither a valid hash or url"" % line
        )

    def pre(self, submit_type, data):
        """"""
        The first step to submitting new analysis.
        @param submit_type: ""files"" or ""strings""
        @param data: a list of dicts containing ""name"" (file name)
                and ""data"" (file data) or a list of strings (urls or hashes)
        @return: submit id
        """"""
        if submit_type not in (""strings"", ""files""):
            log.error(""Bad parameter '%s' for submit_type"", submit_type)
            return False

        path_tmp = Folders.create_temp()
        submit_data = {
            ""data"": [],
            ""errors"": []
        }

        if submit_type == ""strings"":
            for line in data:
                self._handle_string(submit_data, path_tmp, line)

        if submit_type == ""files"":
            for entry in data:
                filename = Storage.get_filename_from_path(entry[""name""])
                filepath = Files.create(path_tmp, filename, entry[""data""])
                submit_data[""data""].append({
                    ""type"": ""file"",
                    ""data"": filepath
                })

        return Database().add_submit(path_tmp, submit_type, submit_data)

    def get_files(self, submit_id, password=None, astree=False):
        """"""
        Returns files from a submitted analysis.
        @param password: The password to unlock container archives with
        @param astree: sflock option; determines the format in which the files are returned
        @return: A tree of files
        """"""
        submit = Database().view_submit(submit_id)
        files, duplicates = [], []

        for data in submit.data[""data""]:
            if data[""type""] == ""file"":
                filename = Storage.get_filename_from_path(data[""data""])
                filepath = os.path.join(submit.tmp_path, filename)

                unpacked = sflock.unpack(
                    filepath=filepath, password=password, duplicates=duplicates
                )

                if astree:
                    unpacked = unpacked.astree(sanitize=True)

                files.append(unpacked)
            elif data[""type""] == ""url"":
                files.append({
                    ""filename"": data[""data""],
                    ""filepath"": """",
                    ""relapath"": """",
                    ""selected"": True,
                    ""size"": 0,
                    ""type"": ""url"",
                    ""package"": ""ie"",
                    ""extrpath"": [],
                    ""duplicate"": False,
                    ""children"": [],
                    ""mime"": ""text/html"",
                    ""finger"": {
                        ""magic_human"": ""url"",
                        ""magic"": ""url""
                    }
                })
            else:
                raise RuntimeError(
                    ""Unknown data entry type: %s"" % data[""type""]
                )

        return files

    def translate_options(self, info, options):
        """"""Translates Web Interface options to Cuckoo database options.""""""
        ret = {}

        if not int(options[""simulated-human-interaction""]):
            ret[""human""] = int(options[""simulated-human-interaction""])

        return emit_options(ret)

    def submit(self, submit_id, config):
        """"""Reads, interprets, and converts the JSON configuration provided by
        the Web Interface into something we insert into the database.""""""
        ret = []
        submit = db.view_submit(submit_id)

        for entry in config[""file_selection""]:
            # Merge the global & per-file analysis options.
            info = copy.deepcopy(config[""global""])
            info.update(entry)
            options = copy.deepcopy(config[""global""][""options""])
            options.update(entry.get(""options"", {}))

            kw = {
                ""package"": info.get(""package""),
                ""timeout"": info.get(""timeout"", 120),
                ""priority"": info.get(""priority""),
                ""custom"": info.get(""custom""),
                ""owner"": info.get(""owner""),
                ""tags"": info.get(""tags""),
                ""memory"": info.get(""memory""),
                ""enforce_timeout"": options.get(""enforce-timeout""),
                ""machine"": info.get(""machine""),
                ""platform"": info.get(""platform""),
                ""options"": self.translate_options(info, options),
                ""submit_id"": submit_id,
            }

            if entry[""type""] == ""url"":
                ret.append(db.add_url(
                    url=info[""filename""], **kw
                ))
                continue

            # for each selected file entry, create a new temp. folder
            path_dest = Folders.create_temp()

            if not info[""extrpath""]:
                path = os.path.join(
                    submit.tmp_path, os.path.basename(info[""filename""])
                )

                filepath = Files.copy(path, path_dest=path_dest)

                ret.append(db.add_path(
                    file_path=filepath, **kw
                ))
            elif len(info[""extrpath""]) == 1:
                arcpath = os.path.join(
                    submit.tmp_path, os.path.basename(info[""arcname""])
                )
                if not os.path.exists(arcpath):
                    submit.data[""errors""].append(
                        ""Unable to find parent archive file: %s"" %
                        os.path.basename(info[""arcname""])
                    )
                    continue

                arc = sflock.zipify(sflock.unpack(
                    info[""arcname""], contents=open(arcpath, ""rb"").read()
                ))

                # Create a .zip archive out of this container.
                arcpath = Files.temp_named_put(
                    arc, os.path.basename(info[""arcname""])
                )

                ret.append(db.add_archive(
                    file_path=arcpath, filename=info[""filename""], **kw
                ))
            else:
                arcpath = os.path.join(
                    submit.tmp_path, os.path.basename(info[""arcname""])
                )
                if not os.path.exists(arcpath):
                    submit.data[""errors""].append(
                        ""Unable to find parent archive file: %s"" %
                        os.path.basename(info[""arcname""])
                    )
                    continue

                content = sflock.unpack(arcpath).read(info[""extrpath""][:-1])
                subarc = sflock.unpack(info[""extrpath""][-2], contents=content)

                # Write intermediate .zip archive file.
                arcpath = Files.temp_named_put(
                    sflock.zipify(subarc),
                    os.path.basename(info[""extrpath""][-2])
                )

                ret.append(db.add_archive(
                    file_path=arcpath, filename=info[""filename""], **kw
                ))

        return ret
/n/n/ncuckoo/web/controllers/analysis/analysis.py/n/n# Copyright (C) 2010-2013 Claudio Guarnieri.
# Copyright (C) 2014-2017 Cuckoo Foundation.
# This file is part of Cuckoo Sandbox - http://www.cuckoosandbox.org
# See the file 'docs/LICENSE' for copying permission.

import collections
import os
import pymongo

from django.http import Http404

from cuckoo.common.mongo import mongo
from cuckoo.core.database import Database, TASK_PENDING

db = Database()

class AnalysisController:
    @staticmethod
    def task_info(task_id):
        if not isinstance(task_id, int):
            raise Exception(""Task ID should be integer"")

        task = db.view_task(task_id, details=True)
        if not task:
            return Http404(""Task not found"")

        entry = task.to_dict()
        entry[""guest""] = {}
        if task.guest:
            entry[""guest""] = task.guest.to_dict()

        entry[""errors""] = []
        for error in task.errors:
            entry[""errors""].append(error.message)

        entry[""sample""] = {}
        if task.sample_id:
            sample = db.view_sample(task.sample_id)
            entry[""sample""] = sample.to_dict()

        entry[""target""] = os.path.basename(entry[""target""])
        return {
            ""task"": entry,
        }

    @staticmethod
    def get_recent(limit=50, offset=0):
        tasks_files = db.list_tasks(
            limit=limit,
            offset=offset,
            category=""file"",
            not_status=TASK_PENDING)

        tasks_urls = db.list_tasks(
            limit=limit,
            offset=offset,
            category=""url"",
            not_status=TASK_PENDING)

        data = []
        if tasks_files:
            for task in tasks_files:
                new = task.to_dict()
                new[""sample""] = db.view_sample(new[""sample_id""]).to_dict()

                filename = os.path.basename(new[""target""])
                new.update({""filename"": filename})

                if db.view_errors(task.id):
                    new[""errors""] = True

                data.append(new)

        if tasks_urls:
            for task in tasks_urls:
                new = task.to_dict()

                if db.view_errors(task.id):
                    new[""errors""] = True

                data.append(new)

        return data

    @staticmethod
    def get_report(task_id):
        report = AnalysisController._get_report(task_id)
        if not report:
            raise Http404(""the specified analysis does not exist"")

        data = {
            ""analysis"": report
        }

        dnsinfo = AnalysisController._get_dnsinfo(report)
        data.update(dnsinfo)
        return data

    @staticmethod
    def _get_report(task_id):
        return mongo.db.analysis.find_one({
            ""info.id"": int(task_id)
        }, sort=[(""_id"", pymongo.DESCENDING)])

    @staticmethod
    def get_reports(filters):
        cursor = mongo.db.analysis.find(
            filters, sort=[(""_id"", pymongo.DESCENDING)]
        )
        return [report for report in cursor]

    @staticmethod
    def _get_dnsinfo(report):
        """"""Create DNS information dicts by domain and ip""""""

        if ""network"" in report and ""domains"" in report[""network""]:
            domainlookups = dict((i[""domain""], i[""ip""]) for i in report[""network""][""domains""])
            iplookups = dict((i[""ip""], i[""domain""]) for i in report[""network""][""domains""])

            for i in report[""network""][""dns""]:
                for a in i[""answers""]:
                    iplookups[a[""data""]] = i[""request""]
        else:
            domainlookups = dict()
            iplookups = dict()

        return {
            ""domainlookups"": domainlookups,
            ""iplookups"": iplookups,
        }

    @staticmethod
    def get_behavior(task_id, report=None):
        """"""
        Returns behavioral information about an analysis
        sorted by category (files, registry, mutexes, etc)
        @param task_id: The analysis ID
        @param report: JSON analysis blob that is stored in MongoDB (results.json)
        @return: behavioral information as a dict
        """"""
        data = {}
        if not report:
            report = AnalysisController.get_report(task_id)[""analysis""]
        procs = AnalysisController.behavior_get_processes(task_id, report)

        for proc in procs[""data""]:
            pid = proc[""pid""]
            pname = proc[""process_name""]
            pdetails = None
            for p in report[""behavior""][""generic""]:
                if p[""pid""] == pid:
                    pdetails = p
            if not pdetails:
                continue

            watchers = AnalysisController.behavior_get_watchers(
                task_id, pid=pid, report=report)

            for category, events in watchers.iteritems():
                if not data.has_key(category):
                    data[category] = {}
                if not data[category].has_key(pid):
                    data[category][pname] = {
                        ""pid"": pid,
                        ""process_name"": pname,
                        ""events"": {}
                    }

                for event in events:
                    if not data[category][pname][""events""].has_key(event):
                        data[category][pname][""events""][event] = []
                    for _event in pdetails[""summary""][event]:
                        data[category][pname][""events""][event].append(_event)

        return data

    @staticmethod
    def behavior_get_processes(task_id, report=None):
        if not task_id:
            raise Exception(""missing task_id"")
        if not report:
            report = AnalysisController.get_report(task_id)[""analysis""]

        data = {
            ""data"": [],
            ""status"": True
        }

        for process in report.get(""behavior"", {}).get(""generic"", []):
            data[""data""].append({
                ""process_name"": process[""process_name""],
                ""pid"": process[""pid""]
            })

        # sort returning list of processes by their name
        data[""data""] = sorted(data[""data""], key=lambda k: k[""process_name""])

        return data

    @staticmethod
    def behavior_get_watchers(task_id, pid, report=None):
        if not task_id or not pid:
            raise Exception(""missing task_id or pid"")
        if not report:
            report = AnalysisController.get_report(task_id)[""analysis""]

        behavior_generic = report[""behavior""][""generic""]
        process = [z for z in behavior_generic if z[""pid""] == pid]

        if not process:
            raise Exception(""missing pid"")
        else:
            process = process[0]

        data = {}
        for category, watchers in AnalysisController.behavioral_mapping().iteritems():
            for watcher in watchers:
                if watcher in process[""summary""]:
                    if category not in data:
                        data[category] = [watcher]
                    else:
                        data[category].append(watcher)

        return data

    @staticmethod
    def behavior_get_watcher(task_id, pid, watcher, limit=None, offset=0, report=None):
        if not task_id or not watcher or not pid:
            raise Exception(""missing task_id, watcher, and/or pid"")
        if not report:
            report = AnalysisController.get_report(task_id)[""analysis""]

        behavior_generic = report[""behavior""][""generic""]
        process = [z for z in behavior_generic if z[""pid""] == pid]

        if not process:
            raise Exception(""supplied pid not found"")
        else:
            process = process[0]

        summary = process[""summary""]

        if watcher not in summary:
            raise Exception(""supplied watcher not found"")
        if offset:
            summary[watcher] = summary[watcher][offset:]
        if limit:
            summary[watcher] = summary[watcher][:limit]

        return summary[watcher]

    @staticmethod
    def behavioral_mapping():
        return {
            ""files"":
                [""file_opened"", ""file_read""],
            ""registry"":
                [""regkey_opened"", ""regkey_written"", ""regkey_read""],
            ""mutexes"":
                [""mutex""],
            ""directories"":
                [""directory_created"", ""directory_removed"", ""directory_enumerated""],
            ""processes"":
                [""command_line"", ""dll_loaded""],
        }

    @staticmethod
    def signatures(task_id, signatures=None):
        """"""Returns an OrderedDict containing a lists with signatures based on severity""""""
        if not task_id:
            raise Exception(""missing task_id"")
        if not signatures:
            signatures = AnalysisController.get_report(task_id)[""signatures""]

        data = collections.OrderedDict()
        for signature in signatures:
            severity = signature[""severity""]
            if severity > 3:
                severity = 3
            if not data.has_key(severity):
                data[severity] = []
            data[severity].append(signature)
        return data
/n/n/ncuckoo/web/controllers/submission/api.py/n/n# Copyright (C) 2010-2013 Claudio Guarnieri.
# Copyright (C) 2014-2017 Cuckoo Foundation.
# This file is part of Cuckoo Sandbox - http://www.cuckoosandbox.org
# See the file 'docs/LICENSE' for copying permission.

import json

from django.http import JsonResponse
from django.shortcuts import redirect
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods

from cuckoo.common.config import config
from cuckoo.core.submit import SubmitManager
from cuckoo.web.bin.utils import api_post, JsonSerialize, json_error_response

submit_manager = SubmitManager()

def defaults():
    machinery = config(""cuckoo:cuckoo:machinery"")

    if config(""routing:vpn:enabled""):
        vpns = config(""routing:vpn:vpns"")
    else:
        vpns = []

    return {
        ""machine"": config(""%s:%s:machines"" % (machinery, machinery)),
        ""package"": None,
        ""priority"": 2,
        ""timeout"": config(""cuckoo:timeouts:default""),
        ""routing"": {
            ""route"": config(""routing:routing:route""),
            ""inetsim"": config(""routing:inetsim:enabled""),
            ""tor"": config(""routing:tor:enabled""),
            ""vpns"": vpns,
        },
        ""options"": {
            ""enable-services"": False,
            ""enforce-timeout"": False,
            ""full-memory-dump"": config(""cuckoo:cuckoo:memory_dump""),
            ""no-injection"": False,
            ""process-memory-dump"": True,
            ""simulated-human-interaction"": True,
        },
    }

class SubmissionApi(object):
    @staticmethod
    @csrf_exempt
    @require_http_methods([""POST""])
    def presubmit(request):
        files = request.FILES.getlist(""files[]"")
        data = []

        if files:
            for f in files:
                data.append({
                    ""name"": f.name,
                    ""data"": f.file,
                })

            submit_id = submit_manager.pre(submit_type=""files"", data=data)
            return redirect(""submission/pre"", submit_id=submit_id)
        else:
            body = json.loads(request.body)
            submit_type = body[""type""]

            if submit_type != ""strings"":
                return json_error_response(""type not \""strings\"""")

            submit_id = submit_manager.pre(
                submit_type=submit_type, data=body[""data""].split(""\n"")
            )

            return JsonResponse({
                ""status"": True,
                ""submit_id"": submit_id,
            }, encoder=JsonSerialize)

    @api_post
    def get_files(request, body):
        submit_id = body.get(""submit_id"", 0)
        password = body.get(""password"", None)
        astree = body.get(""astree"", True)

        files = submit_manager.get_files(
            submit_id=submit_id,
            password=password,
            astree=astree
        )

        return JsonResponse({
            ""status"": True,
            ""files"": files,
            ""defaults"": defaults(),
        }, encoder=JsonSerialize)

    @api_post
    def submit(request, body):
        submit_id = body.pop(""submit_id"", None)
        submit_manager.submit(
            submit_id=submit_id, config=body
        )
        return JsonResponse({
            ""status"": True,
            ""submit_id"": submit_id,
        }, encoder=JsonSerialize)
/n/n/nsetup.py/n/n#!/usr/bin/env python
# Copyright (C) 2016-2017 Cuckoo Foundation.
# This file is part of Cuckoo Sandbox - https://cuckoosandbox.org/.
# See the file 'docs/LICENSE' for copying permission.

import os
import setuptools
import sys

# Update the MANIFEST.in file to include the one monitor version that is
# actively shipped for this distribution and exclude all the other monitors
# that we have lying around. Note: I tried to do this is in a better manner
# through exclude_package_data, but without much luck.

excl, monitor = [], os.path.join(""cuckoo"", ""data"", ""monitor"")
latest = open(os.path.join(monitor, ""latest""), ""rb"").read().strip()
for h in os.listdir(monitor):
    if h != ""latest"" and h != latest:
        excl.append(
            ""recursive-exclude cuckoo/data/monitor/%s *  # AUTOGENERATED"" % h
        )

if not os.path.isdir(os.path.join(monitor, latest)) and \
        not os.environ.get(""ONLYINSTALL""):
    sys.exit(
        ""Failure locating the monitoring binaries that belong to the latest ""
        ""monitor release. Please include those to create a distribution.""
    )

manifest = []
for line in open(""MANIFEST.in"", ""rb""):
    if not line.strip() or ""# AUTOGENERATED"" in line:
        continue

    manifest.append(line.strip())

manifest.extend(excl)

open(""MANIFEST.in"", ""wb"").write(""\n"".join(manifest) + ""\n"")

def githash():
    """"""Extracts the current Git hash.""""""
    git_head = os.path.join("".git"", ""HEAD"")
    if os.path.exists(git_head):
        head = open(git_head, ""rb"").read().strip()
        if not head.startswith(""ref: ""):
            return head

        git_ref = os.path.join("".git"", head.split()[1])
        if os.path.exists(git_ref):
            return open(git_ref, ""rb"").read().strip()

cwd_path = os.path.join(""cuckoo"", ""data-private"", "".cwd"")
open(cwd_path, ""wb"").write(githash() or """")

install_requires = []

# M2Crypto relies on swig being installed. We also don't support the latest
# version of SWIG. We should be replacing M2Crypto by something else when
# the time allows us to do so.
if os.path.exists(""/usr/bin/swig""):
    install_requires.append(""m2crypto==0.24.0"")

setuptools.setup(
    name=""Cuckoo"",
    version=""2.0.0"",
    author=""Stichting Cuckoo Foundation"",
    author_email=""cuckoo@cuckoofoundation.org"",
    packages=[
        ""cuckoo"",
    ],
    classifiers=[
        ""Development Status :: 4 - Beta"",
        # TODO: should become stable.
        # ""Development Status :: 5 - Production/Stable"",
        ""Environment :: Console"",
        ""Environment :: Web Environment"",
        ""Framework :: Django"",
        ""Framework :: Flask"",
        ""Framework :: Pytest"",
        ""Intended Audience :: Information Technology"",
        ""Intended Audience :: Science/Research"",
        ""Natural Language :: English"",
        ""License :: OSI Approved :: GNU General Public License v3 (GPLv3)"",
        ""Operating System :: POSIX :: Linux"",
        ""Programming Language :: Python :: 2.7"",
        ""Topic :: Security"",
    ],
    url=""https://cuckoosandbox.org/"",
    license=""GPLv3"",
    description=""Automated Malware Analysis System"",
    include_package_data=True,
    entry_points={
        ""console_scripts"": [
            ""cuckoo = cuckoo.main:main"",
        ],
    },
    install_requires=[
        ""alembic==0.8.8"",
        ""androguard==3.0"",
        ""beautifulsoup4==4.4.1"",
        ""chardet==2.3.0"",
        ""click==6.6"",
        ""django==1.8.4"",
        ""django_extensions==1.6.7"",
        ""dpkt==1.8.7"",
        ""elasticsearch==2.2.0"",
        ""flask==0.10.1"",
        ""httpreplay==0.1.18"",
        ""jinja2==2.8"",
        ""jsbeautifier==1.6.2"",
        ""lxml==3.6.0"",
        ""oletools==0.42"",
        ""peepdf==0.3.2"",
        ""pefile2==1.2.11"",
        ""pillow==3.2"",
        ""pymisp==2.4.54"",
        ""pymongo==3.0.3"",
        ""python-dateutil==2.4.2"",
        ""python-magic==0.4.12"",
        ""sflock==0.2.5"",
        ""sqlalchemy==1.0.8"",
        ""wakeonlan==0.2.2"",
    ] + install_requires,
    extras_require={
        "":sys_platform == 'win32'"": [
            ""requests==2.7.0"",
        ],
        "":sys_platform == 'darwin'"": [
            ""requests==2.7.0"",
        ],
        "":sys_platform == 'linux2'"": [
            ""requests[security]==2.7.0"",
            ""scapy==2.3.2"",
        ],
        ""distributed"": [
            ""flask-sqlalchemy==2.1"",
            ""gevent==1.1.1"",
            ""psycopg2==2.6.2"",
        ],
        ""postgresql"": [
            ""psycopg2==2.6.2"",
        ],
    },
    setup_requires=[
        ""pytest-runner"",
    ],
    tests_require=[
        ""coveralls"",
        ""pytest"",
        ""pytest-cov"",
        ""pytest-django"",
        ""pytest-pythonpath"",
        ""flask-sqlalchemy==2.1"",
        ""mock==2.0.0"",
        ""responses==0.5.1"",
    ],
)
/n/n/ntests/test_utils.py/n/n# Copyright (C) 2010-2013 Claudio Guarnieri.
# Copyright (C) 2014-2017 Cuckoo Foundation.
# This file is part of Cuckoo Sandbox - http://www.cuckoosandbox.org
# See the file 'docs/LICENSE' for copying permission.

import cStringIO
import io
import mock
import os
import pytest
import shutil
import tempfile

import cuckoo

from cuckoo.common.exceptions import CuckooOperationalError
from cuckoo.common.files import Folders, Files, Storage, temppath
from cuckoo.common import utils
from cuckoo.misc import set_cwd

class TestCreateFolders:
    def setup(self):
        self.tmp_dir = tempfile.gettempdir()

    def test_root_folder(self):
        """"""Tests a single folder creation based on the root parameter.""""""
        Folders.create(os.path.join(self.tmp_dir, ""foo""))
        assert os.path.exists(os.path.join(self.tmp_dir, ""foo""))
        os.rmdir(os.path.join(self.tmp_dir, ""foo""))

    def test_single_folder(self):
        """"""Tests a single folder creation.""""""
        Folders.create(self.tmp_dir, ""foo"")
        assert os.path.exists(os.path.join(self.tmp_dir, ""foo""))
        os.rmdir(os.path.join(self.tmp_dir, ""foo""))

    def test_multiple_folders(self):
        """"""Tests multiple folders creation.""""""
        Folders.create(self.tmp_dir, [""foo"", ""bar""])
        assert os.path.exists(os.path.join(self.tmp_dir, ""foo""))
        assert os.path.exists(os.path.join(self.tmp_dir, ""bar""))
        os.rmdir(os.path.join(self.tmp_dir, ""foo""))
        os.rmdir(os.path.join(self.tmp_dir, ""bar""))

    def test_copy_folder(self):
        """"""Tests recursive folder copy""""""
        dirpath = tempfile.mkdtemp()
        set_cwd(dirpath)

        Folders.copy(""tests/files/sample_analysis_storage"", dirpath)
        assert os.path.isfile(""%s/reports/report.json"" % dirpath)

    def test_duplicate_folder(self):
        """"""Tests a duplicate folder creation.""""""
        Folders.create(self.tmp_dir, ""foo"")
        assert os.path.exists(os.path.join(self.tmp_dir, ""foo""))
        Folders.create(self.tmp_dir, ""foo"")
        os.rmdir(os.path.join(self.tmp_dir, ""foo""))

    def test_delete_folder(self):
        """"""Tests folder deletion #1.""""""
        Folders.create(self.tmp_dir, ""foo"")
        assert os.path.exists(os.path.join(self.tmp_dir, ""foo""))
        Folders.delete(os.path.join(self.tmp_dir, ""foo""))
        assert not os.path.exists(os.path.join(self.tmp_dir, ""foo""))

    def test_delete_folder2(self):
        """"""Tests folder deletion #2.""""""
        Folders.create(self.tmp_dir, ""foo"")
        assert os.path.exists(os.path.join(self.tmp_dir, ""foo""))
        Folders.delete(self.tmp_dir, ""foo"")
        assert not os.path.exists(os.path.join(self.tmp_dir, ""foo""))

    def test_create_temp(self):
        """"""Test creation of temporary directory.""""""
        dirpath1 = Folders.create_temp(""/tmp"")
        dirpath2 = Folders.create_temp(""/tmp"")
        assert os.path.exists(dirpath1)
        assert os.path.exists(dirpath2)
        assert dirpath1 != dirpath2

    def test_create_temp_conf(self):
        """"""Test creation of temporary directory with configuration.""""""
        dirpath = tempfile.mkdtemp()
        set_cwd(dirpath)

        Folders.create(dirpath, ""conf"")
        with open(os.path.join(dirpath, ""conf"", ""cuckoo.conf""), ""wb"") as f:
            f.write(""[cuckoo]\ntmppath = %s"" % dirpath)

        dirpath2 = Folders.create_temp()
        assert dirpath2.startswith(os.path.join(dirpath, ""cuckoo-tmp""))

    @pytest.mark.skipif(""sys.platform != 'linux2'"")
    def test_create_invld_linux(self):
        """"""Test creation of a folder we can't access.""""""
        with pytest.raises(CuckooOperationalError):
            Folders.create(""/invalid/directory"")

    @pytest.mark.skipif(""sys.platform != 'win32'"")
    def test_create_invld_windows(self):
        """"""Test creation of a folder we can't access.""""""
        with pytest.raises(CuckooOperationalError):
            Folders.create(""Z:\\invalid\\directory"")

    def test_delete_invld(self):
        """"""Test deletion of a folder we can't access.""""""
        dirpath = tempfile.mkdtemp()

        os.chmod(dirpath, 0)
        with pytest.raises(CuckooOperationalError):
            Folders.delete(dirpath)

        os.chmod(dirpath, 0775)
        Folders.delete(dirpath)

    def test_create_tuple(self):
        dirpath = tempfile.mkdtemp()
        Folders.create(dirpath, ""a"")
        Folders.create((dirpath, ""a""), ""b"")
        Files.create((dirpath, ""a"", ""b""), ""c.txt"", ""nested"")

        filepath = os.path.join(dirpath, ""a"", ""b"", ""c.txt"")
        assert open(filepath, ""rb"").read() == ""nested""

class TestCreateFile:
    def test_temp_file(self):
        filepath1 = Files.temp_put(""hello"", ""/tmp"")
        filepath2 = Files.temp_put(""hello"", ""/tmp"")
        assert open(filepath1, ""rb"").read() == ""hello""
        assert open(filepath2, ""rb"").read() == ""hello""
        assert filepath1 != filepath2

    def test_create(self):
        dirpath = tempfile.mkdtemp()
        Files.create(dirpath, ""a.txt"", ""foo"")
        assert open(os.path.join(dirpath, ""a.txt""), ""rb"").read() == ""foo""
        shutil.rmtree(dirpath)

    def test_named_temp(self):
        filepath = Files.temp_named_put(""test"", ""hello.txt"", ""/tmp"")
        assert open(filepath, ""rb"").read() == ""test""
        assert os.path.basename(filepath) == ""hello.txt""

    def test_temp_conf(self):
        dirpath = tempfile.mkdtemp()
        set_cwd(dirpath)

        Folders.create(dirpath, ""conf"")
        with open(os.path.join(dirpath, ""conf"", ""cuckoo.conf""), ""wb"") as f:
            f.write(""[cuckoo]\ntmppath = %s"" % dirpath)

        filepath = Files.temp_put(""foo"")
        assert filepath.startswith(os.path.join(dirpath, ""cuckoo-tmp""))

    def test_stringio(self):
        filepath = Files.temp_put(cStringIO.StringIO(""foo""), ""/tmp"")
        assert open(filepath, ""rb"").read() == ""foo""

    def test_bytesio(self):
        filepath = Files.temp_put(io.BytesIO(""foo""), ""/tmp"")
        assert open(filepath, ""rb"").read() == ""foo""

    def test_create_bytesio(self):
        dirpath = tempfile.mkdtemp()
        filepath = Files.create(dirpath, ""a.txt"", io.BytesIO(""A""*1024*1024))
        assert open(filepath, ""rb"").read() == ""A""*1024*1024

    def test_hash_file(self):
        filepath = Files.temp_put(""hehe"", ""/tmp"")
        assert Files.md5_file(filepath) == ""529ca8050a00180790cf88b63468826a""
        assert Files.sha1_file(filepath) == ""42525bb6d3b0dc06bb78ae548733e8fbb55446b3""
        assert Files.sha256_file(filepath) == ""0ebe2eca800cf7bd9d9d9f9f4aafbc0c77ae155f43bbbeca69cb256a24c7f9bb""

    def test_create_tuple(self):
        dirpath = tempfile.mkdtemp()
        Folders.create(dirpath, ""foo"")
        Files.create((dirpath, ""foo""), ""a.txt"", ""bar"")

        filepath = os.path.join(dirpath, ""foo"", ""a.txt"")
        assert open(filepath, ""rb"").read() == ""bar""

    def test_fd_exhaustion(self):
        fd, filepath = tempfile.mkstemp()

        for x in xrange(0x100):
            Files.temp_put(""foo"")

        fd2, filepath = tempfile.mkstemp()

        # Let's leave a bit of working space.
        assert fd2 - fd < 64

class TestStorage:
    def test_basename(self):
        assert Storage.get_filename_from_path(""C:\\a.txt"") == ""a.txt""
        assert Storage.get_filename_from_path(""C:/a.txt"") == ""a.txt""
        assert Storage.get_filename_from_path(""C:\\\x00a.txt"") == ""\x00a.txt""
        assert Storage.get_filename_from_path(""/tmp/a.txt"") == ""a.txt""
        assert Storage.get_filename_from_path(""../../b.txt"") == ""b.txt""
        assert Storage.get_filename_from_path(""..\\..\\c.txt"") == ""c.txt""

class TestConvertChar:
    def test_utf(self):
        assert ""\\xe9"", utils.convert_char(u""\xe9"")

    def test_digit(self):
        assert ""9"" == utils.convert_char(u""9"")

    def test_literal(self):
        assert ""e"" == utils.convert_char(""e"")

    def test_punctation(self):
        assert ""."" == utils.convert_char(""."")

    def test_whitespace(self):
        assert "" "" == utils.convert_char("" "")

class TestConvertToPrintable:
    def test_utf(self):
        assert ""\\xe9"" == utils.convert_to_printable(u""\xe9"")

    def test_digit(self):
        assert ""9"" == utils.convert_to_printable(u""9"")

    def test_literal(self):
        assert ""e"" == utils.convert_to_printable(""e"")

    def test_punctation(self):
        assert ""."" == utils.convert_to_printable(""."")

    def test_whitespace(self):
        assert "" "" == utils.convert_to_printable("" "")

    def test_non_printable(self):
        assert r""\x0b"" == utils.convert_to_printable(chr(11))

class TestIsPrintable:
    def test_utf(self):
        assert not utils.is_printable(u""\xe9"")

    def test_digit(self):
        assert utils.is_printable(u""9"")

    def test_literal(self):
        assert utils.is_printable(""e"")

    def test_punctation(self):
        assert utils.is_printable(""."")

    def test_whitespace(self):
        assert utils.is_printable("" "")

    def test_non_printable(self):
        assert not utils.is_printable(chr(11))

def test_version():
    from cuckoo import __version__
    from cuckoo.misc import version
    assert __version__ == version

def test_exception():
    s = utils.exception_message()
    assert ""Cuckoo version: %s"" % cuckoo.__version__ in s
    assert ""alembic:"" in s
    assert ""django-extensions:"" in s
    assert ""peepdf:"" in s
    assert ""sflock:"" in s

def test_guid():
    assert utils.guid_name(""{0002e005-0000-0000-c000-000000000046}"") == ""InprocServer32""
    assert utils.guid_name(""{13709620-c279-11ce-a49e-444553540000}"") == ""Shell""

def test_jsbeautify():
    js = {
        ""if(1){a(1,2,3);}"": ""if (1) {\n    a(1, 2, 3);\n}"",
    }
    for k, v in js.items():
        assert utils.jsbeautify(k) == v

@mock.patch(""cuckoo.common.utils.jsbeautifier"")
def test_jsbeautify_packer(p, capsys):
    def beautify(s):
        print u""error: Unknown p.a.c.k.e.r. encoding.\n"",

    p.beautify.side_effect = beautify
    utils.jsbeautify(""thisisjavascript"")
    out, err = capsys.readouterr()
    assert not out and not err

def test_htmlprettify():
    html = {
        ""<a href=google.com>wow</a>"": '<a href=""google.com"">\n wow\n</a>',
    }
    for k, v in html.items():
        assert utils.htmlprettify(k) == v

def test_temppath():
    dirpath = tempfile.mkdtemp()
    set_cwd(dirpath)
    Folders.create(dirpath, ""conf"")

    assert temppath() == tempfile.gettempdir()

    Files.create(
        os.path.join(dirpath, ""conf""), ""cuckoo.conf"",
        ""[cuckoo]\ntmppath = ""
    )
    assert temppath() == tempfile.gettempdir()

    Files.create(
        os.path.join(dirpath, ""conf""), ""cuckoo.conf"",
        ""[cuckoo]\ntmppath = /tmp""
    )
    assert temppath() == tempfile.gettempdir()

    Files.create(
        os.path.join(dirpath, ""conf""), ""cuckoo.conf"",
        ""[cuckoo]\ntmppath = /custom/directory""
    )
    assert temppath() == ""/custom/directory""

def test_bool():
    assert utils.parse_bool(""true"") is True
    assert utils.parse_bool(""True"") is True
    assert utils.parse_bool(""yes"") is True
    assert utils.parse_bool(""on"") is True
    assert utils.parse_bool(""1"") is True

    assert utils.parse_bool(""false"") is False
    assert utils.parse_bool(""False"") is False
    assert utils.parse_bool(""None"") is False
    assert utils.parse_bool(""no"") is False
    assert utils.parse_bool(""off"") is False
    assert utils.parse_bool(""0"") is False

    assert utils.parse_bool(""2"") is True
    assert utils.parse_bool(""3"") is True

    assert utils.parse_bool(True) is True
    assert utils.parse_bool(1) is True
    assert utils.parse_bool(2) is True
    assert utils.parse_bool(False) is False
    assert utils.parse_bool(0) is False

def test_supported_version():
    assert utils.supported_version(""2.0"", ""2.0.0"", None) is True
    assert utils.supported_version(""2.0.0"", ""2.0.0"", None) is True
    assert utils.supported_version(""2.0.0"", ""2.0.0"", ""2.0.1"") is True
    assert utils.supported_version(""2.0.0"", ""2.0.0"", ""2.0.0"") is True

    assert utils.supported_version(""2.0.1a1"", ""2.0.0"", ""2.0.1"") is True
    assert utils.supported_version(""2.0.1a1"", ""2.0.1a0"", ""2.0.1b1"") is True
    assert utils.supported_version(""2.0.1b1"", ""2.0.1"", None) is False
    assert utils.supported_version(""2.0.1b1"", ""2.0.1a1"", None) is True
    assert utils.supported_version(""2.0.1b1"", ""2.0.1a1"", ""2.0.1"") is True

def test_validate_url():
    assert utils.validate_url(""http://google.com/"")
    assert utils.validate_url(""google.com"")
    assert utils.validate_url(""google.com/test"")
    assert utils.validate_url(""https://google.com/"")
    assert not utils.validate_url(""ftp://google.com/"")
/n/n/n",0
73,73,168cabf86730d56b7fa319278bf0f0034052666a,"/cuckoo/core/submit.py/n/n# Copyright (C) 2016-2017 Cuckoo Foundation.
# This file is part of Cuckoo Sandbox - http://www.cuckoosandbox.org
# See the file 'docs/LICENSE' for copying permission.

import copy
import logging
import os
import sflock

from cuckoo.common.config import emit_options
from cuckoo.common.exceptions import CuckooOperationalError
from cuckoo.common.files import Folders, Files, Storage
from cuckoo.common.utils import validate_url, validate_hash
from cuckoo.common.virustotal import VirusTotalAPI
from cuckoo.core.database import Database

log = logging.getLogger(__name__)

db = Database()

class SubmitManager(object):
    def _handle_string(self, submit, tmppath, line):
        if not line:
            return

        if validate_hash(line):
            try:
                filedata = VirusTotalAPI().hash_fetch(line)
            except CuckooOperationalError as e:
                submit[""errors""].append(
                    ""Error retrieving file hash: %s"" % e
                )
                return

            filepath = Files.create(tmppath, line, filedata)

            submit[""data""].append({
                ""type"": ""file"",
                ""data"": filepath
            })
            return

        if validate_url(line):
            submit[""data""].append({
                ""type"": ""url"",
                ""data"": line
            })
            return

        submit[""errors""].append(
            ""'%s' was neither a valid hash or url"" % line
        )

    def pre(self, submit_type, data):
        """"""
        The first step to submitting new analysis.
        @param submit_type: ""files"" or ""strings""
        @param data: a list of dicts containing ""name"" (file name)
                and ""data"" (file data) or a list of strings (urls or hashes)
        @return: submit id
        """"""
        if submit_type not in (""strings"", ""files""):
            log.error(""Bad parameter '%s' for submit_type"", submit_type)
            return False

        path_tmp = Folders.create_temp()
        submit_data = {
            ""data"": [],
            ""errors"": []
        }

        if submit_type == ""strings"":
            for line in data:
                self._handle_string(submit_data, path_tmp, line)

        if submit_type == ""files"":
            for entry in data:
                filename = Storage.get_filename_from_path(entry[""name""])
                filepath = Files.create(path_tmp, filename, entry[""data""])
                submit_data[""data""].append({
                    ""type"": ""file"",
                    ""data"": filepath
                })

        return Database().add_submit(path_tmp, submit_type, submit_data)

    def get_files(self, submit_id, password=None, astree=False):
        """"""
        Returns files from a submitted analysis.
        @param password: The password to unlock container archives with
        @param astree: sflock option; determines the format in which the files are returned
        @return: A tree of files
        """"""
        submit = Database().view_submit(submit_id)
        files, duplicates = [], []

        for data in submit.data[""data""]:
            if data[""type""] == ""file"":
                filename = Storage.get_filename_from_path(data[""data""])
                filepath = os.path.join(submit.tmp_path, data[""data""])
                filedata = open(filepath, ""rb"").read()

                unpacked = sflock.unpack(
                    filepath=filename, contents=filedata,
                    password=password, duplicates=duplicates
                )

                if astree:
                    unpacked = unpacked.astree()

                files.append(unpacked)
            elif data[""type""] == ""url"":
                files.append({
                    ""filename"": data[""data""],
                    ""filepath"": """",
                    ""relapath"": """",
                    ""selected"": True,
                    ""size"": 0,
                    ""type"": ""url"",
                    ""package"": ""ie"",
                    ""extrpath"": [],
                    ""duplicate"": False,
                    ""children"": [],
                    ""mime"": ""text/html"",
                    ""finger"": {
                        ""magic_human"": ""url"",
                        ""magic"": ""url""
                    }
                })
            else:
                raise RuntimeError(
                    ""Unknown data entry type: %s"" % data[""type""]
                )

        return {
            ""files"": files,
            ""path"": submit.tmp_path,
        }

    def translate_options(self, info, options):
        """"""Translates Web Interface options to Cuckoo database options.""""""
        ret = {}

        if not int(options[""simulated-human-interaction""]):
            ret[""human""] = int(options[""simulated-human-interaction""])

        return emit_options(ret)

    def submit(self, submit_id, config):
        """"""Reads, interprets, and converts the JSON configuration provided by
        the Web Interface into something we insert into the database.""""""
        ret = []
        submit = db.view_submit(submit_id)

        for entry in config[""file_selection""]:
            # Merge the global & per-file analysis options.
            info = copy.deepcopy(config[""global""])
            info.update(entry)
            options = copy.deepcopy(config[""global""][""options""])
            options.update(entry.get(""per_file_options"", {}))

            kw = {
                ""package"": info.get(""package""),
                ""timeout"": info.get(""timeout"", 120),
                ""priority"": info.get(""priority""),
                ""custom"": info.get(""custom""),
                ""owner"": info.get(""owner""),
                ""tags"": info.get(""tags""),
                ""memory"": info.get(""memory""),
                ""enforce_timeout"": options.get(""enforce-timeout""),
                ""machine"": info.get(""machine""),
                ""platform"": info.get(""platform""),
                ""options"": self.translate_options(info, options),
                ""submit_id"": submit_id,
            }

            if entry[""type""] == ""url"":
                ret.append(db.add_url(
                    url=info[""filename""], **kw
                ))
                continue

            # for each selected file entry, create a new temp. folder
            path_dest = Folders.create_temp()

            if not info[""extrpath""]:
                path = os.path.join(
                    submit.tmp_path, os.path.basename(info[""filename""])
                )

                filepath = Files.copy(path, path_dest=path_dest)

                ret.append(db.add_path(
                    file_path=filepath, **kw
                ))
            elif len(info[""extrpath""]) == 1:
                arcpath = os.path.join(
                    submit.tmp_path, os.path.basename(info[""arcname""])
                )
                if not os.path.exists(arcpath):
                    submit.data[""errors""].append(
                        ""Unable to find parent archive file: %s"" %
                        os.path.basename(info[""arcname""])
                    )
                    continue

                arc = sflock.zipify(sflock.unpack(
                    info[""arcname""], contents=open(arcpath, ""rb"").read()
                ))

                # Create a .zip archive out of this container.
                arcpath = Files.temp_named_put(
                    arc, os.path.basename(info[""arcname""])
                )

                ret.append(db.add_archive(
                    file_path=arcpath, filename=info[""filename""], **kw
                ))
            else:
                arcpath = os.path.join(
                    submit.tmp_path, os.path.basename(info[""arcname""])
                )
                if not os.path.exists(arcpath):
                    submit.data[""errors""].append(
                        ""Unable to find parent archive file: %s"" %
                        os.path.basename(info[""arcname""])
                    )
                    continue

                content = sflock.unpack(arcpath).read(info[""extrpath""][:-1])
                subarc = sflock.unpack(info[""extrpath""][-2], contents=content)

                # Write intermediate .zip archive file.
                arcpath = Files.temp_named_put(
                    sflock.zipify(subarc),
                    os.path.basename(info[""extrpath""][-2])
                )

                ret.append(db.add_archive(
                    file_path=arcpath, filename=info[""filename""], **kw
                ))

        return ret
/n/n/n/cuckoo/web/controllers/analysis/analysis.py/n/n# Copyright (C) 2010-2013 Claudio Guarnieri.
# Copyright (C) 2014-2017 Cuckoo Foundation.
# This file is part of Cuckoo Sandbox - http://www.cuckoosandbox.org
# See the file 'docs/LICENSE' for copying permission.

import collections
import os
import pymongo

from django.http import Http404

from cuckoo.core.database import Database, TASK_PENDING
from cuckoo.common.mongo import mongo

db = Database()

class AnalysisController:
    @staticmethod
    def task_info(task_id):
        if not isinstance(task_id, int):
            raise Exception(""Task ID should be integer"")
        data = {}

        task = db.view_task(task_id, details=True)
        if task:
            entry = task.to_dict()
            entry[""guest""] = {}
            if task.guest:
                entry[""guest""] = task.guest.to_dict()

            entry[""errors""] = []
            for error in task.errors:
                entry[""errors""].append(error.message)

            entry[""sample""] = {}
            if task.sample_id:
                sample = db.view_sample(task.sample_id)
                entry[""sample""] = sample.to_dict()

            data[""task""] = entry
        else:
            return Exception(""Task not found"")

        return data

    @staticmethod
    def get_recent(limit=50, offset=0):
        db = Database()
        tasks_files = db.list_tasks(
            limit=limit,
            offset=offset,
            category=""file"",
            not_status=TASK_PENDING)

        tasks_urls = db.list_tasks(
            limit=limit,
            offset=offset,
            category=""url"",
            not_status=TASK_PENDING)

        data = []
        if tasks_files:
            for task in tasks_files:
                new = task.to_dict()
                new[""sample""] = db.view_sample(new[""sample_id""]).to_dict()

                filename = os.path.basename(new[""target""])
                new.update({""filename"": filename})

                if db.view_errors(task.id):
                    new[""errors""] = True

                data.append(new)

        if tasks_urls:
            for task in tasks_urls:
                new = task.to_dict()

                if db.view_errors(task.id):
                    new[""errors""] = True

                data.append(new)

        return data

    @staticmethod
    def get_report(task_id):
        report = AnalysisController._get_report(task_id)
        if not report:
            raise Http404(""the specified analysis does not exist"")

        data = {
            ""analysis"": report
        }

        dnsinfo = AnalysisController._get_dnsinfo(report)
        data.update(dnsinfo)
        return data

    @staticmethod
    def _get_report(task_id):
        return mongo.db.analysis.find_one({
            ""info.id"": int(task_id)
        }, sort=[(""_id"", pymongo.DESCENDING)])

    @staticmethod
    def get_reports(filters):
        cursor = mongo.db.analysis.find(
            filters, sort=[(""_id"", pymongo.DESCENDING)]
        )
        return [report for report in cursor]

    @staticmethod
    def _get_dnsinfo(report):
        """"""Create DNS information dicts by domain and ip""""""

        if ""network"" in report and ""domains"" in report[""network""]:
            domainlookups = dict((i[""domain""], i[""ip""]) for i in report[""network""][""domains""])
            iplookups = dict((i[""ip""], i[""domain""]) for i in report[""network""][""domains""])

            for i in report[""network""][""dns""]:
                for a in i[""answers""]:
                    iplookups[a[""data""]] = i[""request""]
        else:
            domainlookups = dict()
            iplookups = dict()

        return {
            ""domainlookups"": domainlookups,
            ""iplookups"": iplookups,
        }

    @staticmethod
    def get_behavior(task_id, report=None):
        """"""
        Returns behavioral information about an analysis
        sorted by category (files, registry, mutexes, etc)
        @param task_id: The analysis ID
        @param report: JSON analysis blob that is stored in MongoDB (results.json)
        @return: behavioral information as a dict
        """"""
        data = {}
        if not report:
            report = AnalysisController.get_report(task_id)[""analysis""]
        procs = AnalysisController.behavior_get_processes(task_id, report)

        for proc in procs[""data""]:
            pid = proc[""pid""]
            pname = proc[""process_name""]
            pdetails = None
            for p in report[""behavior""][""generic""]:
                if p[""pid""] == pid:
                    pdetails = p
            if not pdetails:
                continue

            watchers = AnalysisController.behavior_get_watchers(
                task_id, pid=pid, report=report)

            for category, events in watchers.iteritems():
                if not data.has_key(category):
                    data[category] = {}
                if not data[category].has_key(pid):
                    data[category][pname] = {
                        ""pid"": pid,
                        ""process_name"": pname,
                        ""events"": {}
                    }

                for event in events:
                    if not data[category][pname][""events""].has_key(event):
                        data[category][pname][""events""][event] = []
                    for _event in pdetails[""summary""][event]:
                        data[category][pname][""events""][event].append(_event)

        return data

    @staticmethod
    def behavior_get_processes(task_id, report=None):
        if not task_id:
            raise Exception(""missing task_id"")
        if not report:
            report = AnalysisController.get_report(task_id)[""analysis""]

        data = {
            ""data"": [],
            ""status"": True
        }

        for process in report.get(""behavior"", {}).get(""generic"", []):
            data[""data""].append({
                ""process_name"": process[""process_name""],
                ""pid"": process[""pid""]
            })

        # sort returning list of processes by their name
        data[""data""] = sorted(data[""data""], key=lambda k: k[""process_name""])

        return data

    @staticmethod
    def behavior_get_watchers(task_id, pid, report=None):
        if not task_id or not pid:
            raise Exception(""missing task_id or pid"")
        if not report:
            report = AnalysisController.get_report(task_id)[""analysis""]

        behavior_generic = report[""behavior""][""generic""]
        process = [z for z in behavior_generic if z[""pid""] == pid]

        if not process:
            raise Exception(""missing pid"")
        else:
            process = process[0]

        data = {}
        for category, watchers in AnalysisController.behavioral_mapping().iteritems():
            for watcher in watchers:
                if watcher in process[""summary""]:
                    if category not in data:
                        data[category] = [watcher]
                    else:
                        data[category].append(watcher)

        return data

    @staticmethod
    def behavior_get_watcher(task_id, pid, watcher, limit=None, offset=0, report=None):
        if not task_id or not watcher or not pid:
            raise Exception(""missing task_id, watcher, and/or pid"")
        if not report:
            report = AnalysisController.get_report(task_id)[""analysis""]

        behavior_generic = report[""behavior""][""generic""]
        process = [z for z in behavior_generic if z[""pid""] == pid]

        if not process:
            raise Exception(""supplied pid not found"")
        else:
            process = process[0]

        summary = process[""summary""]

        if watcher not in summary:
            raise Exception(""supplied watcher not found"")
        if offset:
            summary[watcher] = summary[watcher][offset:]
        if limit:
            summary[watcher] = summary[watcher][:limit]

        return summary[watcher]

    @staticmethod
    def behavioral_mapping():
        return {
            ""files"":
                [""file_opened"", ""file_read""],
            ""registry"":
                [""regkey_opened"", ""regkey_written"", ""regkey_read""],
            ""mutexes"":
                [""mutex""],
            ""directories"":
                [""directory_created"", ""directory_removed"", ""directory_enumerated""],
            ""processes"":
                [""command_line"", ""dll_loaded""],
        }

    @staticmethod
    def signatures(task_id, signatures=None):
        """"""Returns an OrderedDict containing a lists with signatures based on severity""""""
        if not task_id:
            raise Exception(""missing task_id"")
        if not signatures:
            signatures = AnalysisController.get_report(task_id)[""signatures""]

        data = collections.OrderedDict()
        for signature in signatures:
            severity = signature[""severity""]
            if severity > 3:
                severity = 3
            if not data.has_key(severity):
                data[severity] = []
            data[severity].append(signature)
        return data
/n/n/n/cuckoo/web/controllers/submission/api.py/n/n# Copyright (C) 2010-2013 Claudio Guarnieri.
# Copyright (C) 2014-2017 Cuckoo Foundation.
# This file is part of Cuckoo Sandbox - http://www.cuckoosandbox.org
# See the file 'docs/LICENSE' for copying permission.

import json

from django.http import JsonResponse
from django.shortcuts import redirect
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_http_methods

from cuckoo.common.config import config
from cuckoo.core.submit import SubmitManager
from cuckoo.web.bin.utils import api_post, JsonSerialize, json_error_response

submit_manager = SubmitManager()

def defaults():
    machinery = config(""cuckoo:cuckoo:machinery"")

    if config(""routing:vpn:enabled""):
        vpns = config(""routing:vpn:vpns"")
    else:
        vpns = []

    return {
        ""machine"": config(""%s:%s:machines"" % (machinery, machinery)),
        ""package"": None,
        ""priority"": 2,
        ""timeout"": config(""cuckoo:timeouts:default""),
        ""routing"": {
            ""route"": config(""routing:routing:route""),
            ""inetsim"": config(""routing:inetsim:enabled""),
            ""tor"": config(""routing:tor:enabled""),
            ""vpns"": vpns,
        },
        ""options"": {
            ""enable-services"": False,
            ""enforce-timeout"": False,
            ""full-memory-dump"": config(""cuckoo:cuckoo:memory_dump""),
            ""no-injection"": False,
            ""process-memory-dump"": True,
            ""simulated-human-interaction"": True,
        },
    }

class SubmissionApi(object):
    @staticmethod
    @csrf_exempt
    @require_http_methods([""POST""])
    def presubmit(request):
        files = request.FILES.getlist(""files[]"")
        data = []

        if files:
            for f in files:
                data.append({
                    ""name"": f.name,
                    ""data"": f.file,
                })

            submit_id = submit_manager.pre(submit_type=""files"", data=data)
            return redirect(""submission/pre"", submit_id=submit_id)
        else:
            body = json.loads(request.body)
            submit_type = body[""type""]

            if submit_type != ""strings"":
                return json_error_response(""type not \""strings\"""")

            submit_id = submit_manager.pre(
                submit_type=submit_type, data=body[""data""].split(""\n"")
            )

            return JsonResponse({
                ""status"": True,
                ""submit_id"": submit_id,
            }, encoder=JsonSerialize)

    @api_post
    def get_files(request, body):
        submit_id = body.get(""submit_id"", 0)
        password = body.get(""password"", None)
        astree = body.get(""astree"", True)

        data = submit_manager.get_files(
            submit_id=submit_id,
            password=password,
            astree=astree
        )

        return JsonResponse({
            ""status"": True,
            ""data"": data,
            ""defaults"": defaults(),
        }, encoder=JsonSerialize)

    @api_post
    def submit(request, body):
        submit_id = body.pop(""submit_id"", None)
        submit_manager.submit(
            submit_id=submit_id, config=body
        )
        return JsonResponse({
            ""status"": True,
            ""submit_id"": submit_id,
        }, encoder=JsonSerialize)
/n/n/n",1
140,140,d7e7869ba3a5b040215ac4426b4dc10ad8f8e20d,"PythonCode/Ballance.py/n/nif __name__ == '__main__':
    simulationMode = True    #czy uruchomic program w trybie symulacji? wymaga rowniez zmiany w ServoControllerModule.py oraz w ImageProcessingModule.py

    import ImageProcessingModule as IPM
    import ServoControllerModule as SCM
    import PIDControllerModule as PIDCM
    import DataLoggerModule as DLM
    import PathPlannerModule as PPM
    
    from time import sleep
    import time
    import pygame
    import math
    import MathModule as MM

    #wykonanie wstepnych czynnosci
    if simulationMode:
        import SimulationCommunicatorModule as SimCM
        simulationCommunicator = SimCM.SimulationCommunicator()
    else: simulationCommunicator = None
    
    imageProcessor = IPM.ImageProcessor(simulationCommunicator)
    servoController = SCM.ServoController()
    pathPlanner = PPM.PathPlanner()
        
    dataLogger = DLM.DataLogger()
    pidController = PIDCM.PIDController()
    pidController.servo_pos_limit = servoController.servo_pos_limit

    pygame.init()
    pygame.display.set_mode((100, 100))

    #roizpoczynanie procesu wykrywania kulki
    if simulationMode: simulationCommunicator.StartProcessing()
    imageProcessor.StartProcessing()
    pathPlanner.startProcessing(imageProcessor.obstacle_map)

    targetDeltaTime = 1.0 / 40.0    #czas jednej iteracji programu sterujacego
    updatedTime = 0.0
    servoUpdateDeltaTime = 1.0 / 60 #czas odswiezania pozycji serw
    servoUpdatedTime = 0.0

    ball_position_actual = (0.0, 0.0)
    ball_position_previous = (0.0, 0.0)

    #parametry trajektorii kulki
    angle = 0.0
    angleSpeed = 0.9
    angleRadius = 0.25
    angleRadiusFactor = 0.0
    path_targets = [(0.18, 0.18), (0.82, 0.82)]
    path_target_index = 0
    targetPos = path_targets[path_target_index]
    moveSpeed = 0.05
    movementMode = 0
    modeChangeTimeDelta = 25 #czas po jakim zmieniana jest trajektoria kulki
    modeChangeTimer = 0.0

    #jak dlugo wykonywany ma byc program
    duration = 10000
    timeout = time.time() + duration
    ball_just_found = True    #czy kulka dopiero zostala znaleziona i nalezy zresetowac predkosc?

    #glowna petla programu
    while time.time() <= timeout:
        timeStart = time.perf_counter()
        
        #oczekiwanie na odpowiedni moment do wykonania programu sterujacego
        if timeStart - updatedTime >= targetDeltaTime:
            updatedTime = time.perf_counter()
            
            #pobranie pozycji kulki
            ball_position_actual = imageProcessor.getBallPosition()
            if ball_position_actual[0] >= 0: pidController.setActualValue(ball_position_actual)
            else: pidController.setActualValue(pidController.value_target)
                
            #aktualizacja kontrolera PID
            pidController.update(targetDeltaTime)
            ball_position_previous = ball_position_actual
            
            #aktualizacja pozycji kulki w pathplannerze
            pathPlanner.setBallPosition(ball_position_actual)
            pidController.setTargetValue(pathPlanner.getPathTarget())
            
            #przechodzenie do kolejnego waypoint'a
            if MM.sqrMagnitude(ball_position_actual[0] - targetPos[0], ball_position_actual[1] - targetPos[1]) < 0.01:
                path_target_index = (path_target_index + 1) % len(path_targets)
                targetPos = path_targets[path_target_index]
                pathPlanner.setTargetPosition(targetPos)
            #print(str(pidController.value_target))
            
            #obslugiwanie wejscia z klawiatury
            killLoop = False
            for event in pygame.event.get():
                if event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_g:
                        pidController.increaseKP()
                        
                    elif event.key == pygame.K_b:
                        pidController.decreaseKP()
                        
                    elif event.key == pygame.K_h:
                        pidController.increaseKI()
                        
                    elif event.key == pygame.K_n:
                        pidController.decreaseKI()
                        
                    elif event.key == pygame.K_j:
                        pidController.increaseKD()
                        
                    elif event.key == pygame.K_m:
                        pidController.decreaseKD()
                        
                    elif event.key == pygame.K_q:
                        killLoop = True
                        
                    elif event.key == pygame.K_UP:
                        targetPos[1] -= moveSpeed
                        
                    elif event.key == pygame.K_DOWN:
                        targetPos[1] += moveSpeed
                        
                    elif event.key == pygame.K_RIGHT:
                        targetPos[0] += moveSpeed
                        
                    elif event.key == pygame.K_LEFT:
                        targetPos[0] -= moveSpeed
                        
                    elif event.key == pygame.K_p:
                        angleSpeed += 0.1
                        print(""angleSpeed = "" + str(angleSpeed))
                        
                    elif event.key == pygame.K_o:
                        angleSpeed -= 0.1
                        print(""angleSpeed = "" + str(angleSpeed))
                        
            if killLoop:
                break
            
            #ustawianie nowych pozycji serw
            servoController.moveServo(0, round(pidController.x_servo))
            servoController.moveServo(1, -round(pidController.y_servo))
            
            #dostepne trajektorie ruchu kulki
            if False:
                if movementMode == 0:    #ksztalt osemki
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.sin(2.0 * angle)
                elif movementMode == 1:  #ksztalt okregu
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.cos(angle)
                elif movementMode == 2:   #ksztalt paraboli
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.cos(2.0 * angle)
                elif movementMode == 3:   #ksztalt litery S
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.sin(2.0 * angle)
                    if angle > 2:
                        angleSpeed = -angleSpeed
                        angle = 2
                    elif angle < -2:
                        angleSpeed = -angleSpeed
                        angle = -2
                    
            #targetPos[0] = 0.5 + angleRadiusFactor * angleRadius * targetPos[0]
            #targetPos[1] = 0.5 + angleRadiusFactor * angleRadius * targetPos[1]
            #ustawianie docelowej pozycji kulki
            #pidController.setTargetValue(targetPos[0], targetPos[1])
            #pathPlanner.setTargetPosition(tuple(targetPos))
            angle += angleSpeed * targetDeltaTime
            angleRadiusFactor += 0.25 * targetDeltaTime
            angleRadiusFactor = min(angleRadiusFactor, 1.0)
            
            modeChangeTimer += targetDeltaTime
            if modeChangeTimer >= modeChangeTimeDelta:
                modeChangeTimer = 0.0
                angleRadiusFactor = 0.0
                movementMode += 1
                movementMode = movementMode % 4
            
            #dodawanie wpisow do DataLog'u
            if False:
                path_target = pathPlanner.getPathTarget()
                dataLogger.addRecord(""timestamp"", time.perf_counter())
                dataLogger.addRecord(""ball_pos_x"", ball_position_actual[0])
                dataLogger.addRecord(""ball_pos_y"", ball_position_actual[1])
                dataLogger.addRecord(""target_pos_x"", path_target[0])
                dataLogger.addRecord(""target_pos_y"", path_target[1])
                dataLogger.addRecord(""KP"", pidController.KP)
                dataLogger.addRecord(""KI"", pidController.KI)
                dataLogger.addRecord(""KD"", pidController.KD)
                dataLogger.addRecord(""error_x"", pidController.x_error)
                dataLogger.addRecord(""error_y"", pidController.y_error)
                dataLogger.addRecord(""error_prev_x"", pidController.x_prev_error)
                dataLogger.addRecord(""error_prev_y"", pidController.y_prev_error)
                dataLogger.addRecord(""error_sum_x"", pidController.x_error_sum)
                dataLogger.addRecord(""error_sum_y"", pidController.y_error_sum)
                dataLogger.addRecord(""derivative_x"", pidController.x_derivative)
                dataLogger.addRecord(""derivative_y"", pidController.y_derivative)
                dataLogger.addRecord(""servo_actual_x"", servoController.servo_actual_pos[0])
                dataLogger.addRecord(""servo_actual_y"", servoController.servo_actual_pos[1])
                dataLogger.addRecord(""servo_target_x"", servoController.servo_target_pos[0])
                dataLogger.addRecord(""servo_target_y"", servoController.servo_target_pos[1])
                dataLogger.saveRecord()
            
        #oczekiwanie na odpowiedni moment do aktualizacji serw
        if time.perf_counter() - servoUpdatedTime >= servoUpdateDeltaTime:
            servoController.update(time.perf_counter() - servoUpdatedTime)
            servoUpdatedTime = time.perf_counter()
            
            if simulationMode:
                simulationCommunicator.moveServos(servoController.servo_actual_pos)
                
        sleep(0.004) #4 milisekundy na odpoczynek :)
            
    print(""Stopping program"")
    #dataLogger.saveToFile(""BallanceDataLog"")
    if simulationMode: simulationCommunicator.StopProcessing()
    else: imageProcessor.StopProcessing()
    pathPlanner.stopProcessing()/n/n/nPythonCode/ImageProcessingModule.py/n/nsimulationMode = True

if not simulationMode:
    import TensorflowProcessingModule as TPM
    from imutils.video.pivideostream import PiVideoStream

import MathModule as MM
import math, time, copy
import cv2
import numpy as np
from multiprocessing import Process, RawValue, RawArray
 
#program sluzacy do analizy obrazu z kamery, wykrywania kulki
class ImageProcessor:
    
    #parametry kamery
    camera_resolution = (256, 256)
    camera_framerate = 40
    
    corner_detecton_area = (0.08, 0.08, 0.14, 0.14) #prostakat, w ktorym szukana jest krawedz plyty, jest on powielany dla kazdego rogu obrazu
    detection_image_resolution = (200, 200)
    detection_image_resolution_cropped = (-1, -1)
    
    #rozmiar bitmapy przeszkod
    obstacle_map_size = 40
    obstacle_map_update_delta = 40
        
    def __init__(self, _simulationCommunicator=None):
        print(""ImageProcessor object created"")
        self.simulationCommunicator = _simulationCommunicator
        #wartosci-rezultaty przetwarzania obrazu
        self.result_x = RawValue('f', 0.0)
        self.result_y = RawValue('f', 0.0)
        self.key = RawValue('i', 0)
        
        self.obstacle_map = RawArray('i', ImageProcessor.obstacle_map_size**2)
        self.obstacle_map_update_counter = 0
        
    def getBallPosition(self):    #zwraca pozycje kulki
        if simulationMode: return self.simulationCommunicator.getBallPosition()
        return (self.result_x.value, self.result_y.value)
        
    def StartProcessing(self):   #uruchamia proces przetwarzajacy obraz
        print(""Starting image processing"")
        
        self.process = Process(target=ImageProcessor.ProcessImage, args=(self,))
        self.process.daemon = True
        self.process.start()
        #ImageProcessor.ProcessImage(self)
        
    def StopProcessing(self):    #wydaje polecenie do zatrzymania przetwarzania obrazu
        print(""Stopping image processing"")
        self.key.value = -666
        self.process.terminate()
        
    def ProcessImage(self):    #przetwarza obraz pobierajac klatke z kamery i wykonujac na niej operacje analizy
        
        #bufor dzielenia mapy przeszkod z innymi procesami
        self.obstacle_map_np = np.frombuffer(self.obstacle_map, dtype=np.int32).reshape(ImageProcessor.obstacle_map_size**2)
        
        #parametry trackera kulki
        self.ballTracker_pos = [ImageProcessor.detection_image_resolution[0]//2, ImageProcessor.detection_image_resolution[1]//2]
        self.ballTracker_size = 40
        self.ballTracker_result = [0, 0]
        
        if not simulationMode:
            self.tensorflowProcessor = TPM.TensorflowProcessor()
            videoStream = PiVideoStream(resolution=ImageProcessor.camera_resolution, framerate=ImageProcessor.camera_framerate).start()   #uruchamianie watku, ktory czyta kolejne klatki z kamery
        else:
            videoStream = self.simulationCommunicator
        
        time.sleep(1)
        self.frame_original = videoStream.read()
        
        lastTime = time.time()
        a = 190
        lastID = 0
        
        saveCounter = 0
        saveCount = 0
        
        while True:
            if self.key.value == -666: break
            
            #prosty licznik przetworzonych klatek w ciagu sekundy
            a = a + 1
            if a > 200:
                if ImageProcessor.detection_image_resolution_cropped[0] == -1:
                    ImageProcessor.detection_image_resolution_cropped = (np.size(self.frame_original, 0), np.size(self.frame_original, 1))
                print(str(a * 1.0 / (time.time() - lastTime)))
                lastTime = time.time()
                a = 0
            
            #synchronizacja pobierania nowej klatki z czestotliwascia kamery
            while True:
                frameGrabbed = videoStream.read()
                ID = id(frameGrabbed)
                if ID != lastID:
                    self.frame_original = frameGrabbed
                    lastID = ID
                    break
                elif not simulationMode:
                    time.sleep(0.01)
            
            #klatka przeznaczona do debugowania
            #self.frame_debug = copy.copy(self.frame_original)
            
            if not simulationMode: self.corners = ImageProcessor.FindBoardCorners(self)    #znajdowanie pozycji rogow plyty
            else: self.corners = self.simulationCommunicator.FindBoardCorners()
            ImageProcessor.ChangePerspective(self)    #zmiana perspektywy znalezionej tablicy, aby wygladala jak kwadrat
            #self.frame_original = self.frame_original[1:200, 1:200] #przycinanie zdjecia
            if not simulationMode: ImageProcessor.UpdateBallTracker(self)    #aktualizacja trackera kulki
            else:
                pos = self.simulationCommunicator.getBallPosition()
                self.ballTracker_result[0] = pos[0] * ImageProcessor.detection_image_resolution_cropped[0]
                self.ballTracker_result[1] = pos[1] * ImageProcessor.detection_image_resolution_cropped[1]
            ImageProcessor.UpdateObstacleMap(self)
            
            #ustawianie znalezionej pozycji kulki w zmiennych dzielonych miedzy procesami
            self.result_x.value = self.ballTracker_result[0] / ImageProcessor.detection_image_resolution_cropped[0]
            self.result_y.value = self.ballTracker_result[1] / ImageProcessor.detection_image_resolution_cropped[1]
            
            #cv2.imshow(""Frame debug"", self.frame_debug)
            if saveCounter < saveCount:
                cv2.imwrite(""Frame"" + str(saveCounter) + "".png"", self.frame_original)
                saveCounter += 1
                
            cv2.imshow(""Frame Casted"", self.frame_original)
            key = cv2.waitKey(1) & 0xFF
            #if key == ord(""q""):
            #    break
            
        videoStream.stop()
            
    #aktualizuje tracker kulki
    def UpdateBallTracker(self):
        self.ballTracker_pos[0] = MM.clamp(self.ballTracker_pos[0], 0, ImageProcessor.detection_image_resolution_cropped[0] - self.ballTracker_size)
        self.ballTracker_pos[1] = MM.clamp(self.ballTracker_pos[1], 0, ImageProcessor.detection_image_resolution_cropped[1] - self.ballTracker_size)
        
        self.ballTracker_pos[0] = int(self.ballTracker_pos[0])
        self.ballTracker_pos[1] = int(self.ballTracker_pos[1])
        
        #przygotowanie klatki z kamery do analizy
        tracker_frame = self.frame_original[self.ballTracker_pos[1]:self.ballTracker_pos[1]+self.ballTracker_size,
                                            self.ballTracker_pos[0]:self.ballTracker_pos[0]+self.ballTracker_size]
        tracker_frame = cv2.cvtColor(tracker_frame, cv2.COLOR_BGR2GRAY)
        
        #analiza klatki z uzyciem sieci neuronowych
        result = self.tensorflowProcessor.getBallPosition(tracker_frame)
        result = np.round(result * self.ballTracker_size).astype(""int"")
        
        self.ballTracker_result[0] = self.ballTracker_pos[0] + result[0]
        self.ballTracker_result[1] = self.ballTracker_pos[1] + result[1]
        
        #zaznaczanie wizualne pozycji kulki
        #cv2.circle(self.frame_original, tuple(self.ballTracker_result), 1, (0, 0, 255), -1)
        
        #aktualizacja pozycji trackera
        self.ballTracker_pos[0] = MM.lerp(self.ballTracker_pos[0], self.ballTracker_result[0] - self.ballTracker_size // 2, 0.7)
        self.ballTracker_pos[1] = MM.lerp(self.ballTracker_pos[1], self.ballTracker_result[1] - self.ballTracker_size // 2, 0.7)
    
    #znajduje pozycje krawedzi plyty
    def FindBoardCorners(self):
        corners = np.zeros((4, 2), dtype=np.int32)
        corner_detection_area_pixels = [round(self.corner_detecton_area[0] * self.camera_resolution[0]),
                                       round(self.corner_detecton_area[1] * self.camera_resolution[1]),
                                       round(self.corner_detecton_area[2] * self.camera_resolution[0]),
                                       round(self.corner_detecton_area[3] * self.camera_resolution[1])]
        for i in range(4):
            flipX = False
            flipY = False
            detectionArea = copy.copy(corner_detection_area_pixels)    #domyslnie lewy gorny
            if i == 1 or i == 2:
                detectionArea[0] = self.camera_resolution[0] - detectionArea[0] - detectionArea[2]
                flipX = True
            if i == 3 or i == 2:
                detectionArea[1] = self.camera_resolution[1] - detectionArea[1] - detectionArea[3]
                flipY = True
                
            rect = (detectionArea[0], detectionArea[1], detectionArea[0] + detectionArea[2], detectionArea[1] + detectionArea[3])
            #cv2.rectangle(self.frame_debug, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 1);
        
            img = self.frame_original[rect[1]:rect[3], rect[0]:rect[2]]
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            img = cv2.resize(img, (40, 40), interpolation=cv2.INTER_NEAREST)
            
            if flipX and flipY: img = cv2.flip(img, -1)
            elif flipX: img = cv2.flip(img, 1)
            elif flipY: img = cv2.flip(img, 0)
            #cv2.imshow(""Corner "" + str(i), img)
            
            result = self.tensorflowProcessor.getCornerPosition(img)
            corner = np.round(result * 40.0).astype(""int"")
            
            if flipX and flipY: corners[i] = (40 - corner[0] + detectionArea[0], 40 - corner[1] + detectionArea[1])
            elif flipX: corners[i] = (40 - corner[0] + detectionArea[0], corner[1] + detectionArea[1])
            elif flipY: corners[i] = (corner[0] + detectionArea[0], 40 - corner[1] + detectionArea[1])
            else: corners[i] = (corner[0] + detectionArea[0], corner[1] + detectionArea[1])
            #cv2.circle(self.frame_debug, corners[i], 1, (0, 0, 255), 1)

        return corners

    #zmienia perspektywe obrazu z kamery tak, aby niewidoczne bylo przechylenie plyty
    def ChangePerspective(self):
        pts = np.array(self.corners, np.float32)
        res = self.detection_image_resolution
        pts2 = np.float32([[0,0],[res[0],0],[res[0], res[1]], [0, res[1]]])

        M = cv2.getPerspectiveTransform(pts, pts2)
        self.frame_original = cv2.warpPerspective(self.frame_original, M, res)
        
    #aktualizuje mape przeszkod na plycie
    def UpdateObstacleMap(self):
        self.obstacle_map_update_counter += 1
        if self.obstacle_map_update_counter >= ImageProcessor.obstacle_map_update_delta:
            self.obstacle_map_update_counter = 0
            frame = cv2.resize(self.frame_original, (ImageProcessor.obstacle_map_size, ImageProcessor.obstacle_map_size), interpolation=cv2.INTER_NEAREST)
            frame = np.int32(frame)
            frame = 2 * frame[...,2] - frame[...,1] - frame[...,0]
            np.copyto(self.obstacle_map_np, frame.ravel())
            #self.obstacle_map = frame[...,2].ravel()/n/n/nPythonCode/MathModule.py/n/n#PRZYDATNE FUNKCJE MATEMATYCZNE
import math
import heapq

#zwrca znak liczby
def sign(num):
    if num > 0: return 1.0
    elif num < 0: return -1.0
    return 0.0

#interpolacja liniowa
def lerp(a, b, c):
    return c*b + (1-c) * a

#zwraca dlugosc wektora [x, y] do kwadratu
def sqrMagnitude(x, y=None):
    if y is not None: return x*x + y*y
    return x[0] * x[0] + x[1] * x[1]

#zwraca dlugosc wektora [x, y]
def magnitude(x, y=None):
    if y is not None: return math.sqrt(x*x + y*y)
    return math.sqrt(x[0]*x[0] + x[1]*x[1])

#zwraca odleglosc miedzy punktami A i B
def distance(A, B):
    x = A[0] - B[0]
    y = A[1] - B[1]
    return math.sqrt(x*x + y*y)

#zwraca znormalizowany wektor [x, y]
def normalized(x, y=None):
    if y is not None:
        if x == 0 and y == 0: return (0, 0)
        mag = magnitude(x, y)
        return (x/mag, y/mag)
    else:
        if x[0] == 0 and x[1] == 0: return (0, 0)
        mag = magnitude(x)
        return (x[0]/mag, x[1]/mag)

#zwraca roznice kwadratowa miedzy target a value
def errorsquare(target, value):
    size = len(target)
    sum = 0.0
    for i in range(size):
        a = int(target[i]) - value[i]
        sum += a * a
        
    return sum
        
#zwraca wartosc 'num' ograniczana przez <_min, _max>
def clamp(num, _min, _max):
    if num > _max: return _max
    elif num < _min: return _min
    return num

#kolejka priorytetowa
class PriorityQueue:
    def __init__(self):
        self.elements = []
        
    #dodaje element do kolejki
    def push(self, item, priority):
        heapq.heappush(self.elements, (priority, item))
        
    #zdejmuje i zwraca element z poczatku kolejki
    def pop(self):
        return heapq.heappop(self.elements)[1]
    
    #czy kolejka jest pusta?
    def empty(self):
        return len(self.elements) == 0
        /n/n/nPythonCode/PIDControllerModule.py/n/nimport MathModule as MM

class PIDController:
    
    #operacje zmiany pidow
    def increaseKP(self):
        self.KP += 50
        print(""KP = "" + str(self.KP))
        
    def increaseKI(self):
        self.KI += 50
        print(""KI = "" + str(self.KI))
        
    def increaseKD(self):
        self.KD += 50
        print(""KD = "" + str(self.KD))
        
    def decreaseKP(self):
        self.KP -= 50
        print(""KP = "" + str(self.KP))
        
    def decreaseKI(self):
        self.KI -= 50
        print(""KI = "" + str(self.KI))
        
    def decreaseKD(self):
        self.KD -= 50
        print(""KD = "" + str(self.KD))
        
    #ustawia aktualna wartosc
    def setActualValue(self, x, y=None):
        if y is not None:
            self.value_actual[0] = MM.lerp(self.value_actual[0], x, self.value_smoothing)
            self.value_actual[1] = MM.lerp(self.value_actual[1], y, self.value_smoothing)
        else:
            self.value_actual[0] = MM.lerp(self.value_actual[0], x[0], self.value_smoothing)
            self.value_actual[1] = MM.lerp(self.value_actual[1], x[1], self.value_smoothing)
        
    #ustawia docelowa wartosc
    def setTargetValue(self, x, y=None):
        if y is not None:
            self.value_target[0] = x
            self.value_target[1] = y
        else:
            self.value_target[0] = x[0]
            self.value_target[1] = x[1]
    
    def __init__(self):
        self.servo_pos_limit = (1000, 1000)    #ograniczenia wychylen serw (w skali od 0 do 1000)
        self.value_target = [0.5, 0.5]    #docelowa wartosc, ktora ma byc osiagnieta przez kontroler
        self.value_actual = [0.5, 0.5]    #aktualna wartosc
        self.value_smoothing = 0.7        #wspolczynnik wygladzania aktualizacji aktualnej wartosci

        #wspolczynniki kontroli
        self.KP = 1.3 * 1000   #wzmocnienie czesci proporcjonalnej
        self.KI = 2.0 * 1000    #wzmocnienie czesci calkujacej
        self.KD = 0.5 * 1000   #wzmocnienie czesci rozniczkujacej

        #pozycja serwa
        self.x_servo = 0.0
        self.y_servo = 0.0

        #wartosc bledu
        self.x_error = 0.0
        self.y_error = 0.0

        #wartosci poprzednich bledow
        self.x_prev_error = 0.0
        self.y_prev_error = 0.0

        #zmiana bledu w czasie
        self.x_derivative = 0.0
        self.y_derivative = 0.0

        #calkowita suma bledow
        self.x_error_sum = 0.0
        self.y_error_sum = 0.0

    #aktualizuje kontrolea PID
    def update(self, deltaTime):
        #liczenie bledu
        self.x_error = self.value_target[0] - self.value_actual[0]
        self.y_error = self.value_target[1] - self.value_actual[1]
        
        #print(""Error = ( "" + str(self.x_error) + ""; "" + str(self.y_error) + "")"")

        #liczenie pochodnej
        self.x_derivative = (self.x_error - self.x_prev_error) / deltaTime
        self.y_derivative = (self.y_error - self.y_prev_error) / deltaTime

        self.x_prev_error = self.x_error
        self.y_prev_error = self.y_error

        self.x_error_sum += self.x_error * deltaTime
        self.y_error_sum += self.y_error * deltaTime
        
        #zmiana pozycji serw z uwzglednieniem bledu biezacego, przyszlego oraz przeszlego
        self.x_servo = (self.x_error * self.KP) + (self.x_derivative * self.KD) + (self.x_error_sum * self.KI)
        self.y_servo = (self.y_error * self.KP) + (self.y_derivative * self.KD) + (self.y_error_sum * self.KI)
        
        self.x_servo = MM.clamp(self.x_servo, -self.servo_pos_limit[0], self.servo_pos_limit[0])
        self.y_servo = MM.clamp(self.y_servo, -self.servo_pos_limit[1], self.servo_pos_limit[1])
        
        self.x_error_sum = MM.clamp(self.x_error_sum, -1.0, 1.0) * 0.8
        self.y_error_sum = MM.clamp(self.y_error_sum, -1.0, 1.0) * 0.8/n/n/nPythonCode/PathPlannerModule.py/n/nimport cv2
import numpy as np
import MathModule as MM
import time
from multiprocessing import Process, RawValue
from collections import deque
import copy

#program odpowiadajacy za planiwanie sciezki kulki
class PathPlanner:
    
    obstacle_map_size = 40    #rozmiar mapy przeszkod
    obstacle_map_update_delta = 4    #co ile sekund odswiezana ma byc mapa przeszkod?
    path_sub_update_delta = 0.1    #co ile sekund aktualizowac podsciezke?
    
    def __init__(self):
        print(""PathPlanner object created"")
        
        self.obstacle_map = None
        self.path = None
        self_path_last_index = 0
        self.proximity_map = np.zeros((PathPlanner.obstacle_map_size, PathPlanner.obstacle_map_size)) #tablica 2D z kosztem bliskosci wykrytych przeszkod
        
        self.path_position = 0.0   #aktualna pozycja na sciezce
        self.path_speed = 0.3 * PathPlanner.obstacle_map_size    #predkosc przechodzenia sciezki
        
        self.ball_pos_x = RawValue('f', 0.5)
        self.ball_pos_y = RawValue('f', 0.5)
        self.target_pos_x = RawValue('f', 0.25)
        self.target_pos_y = RawValue('f', 0.25)
        self.path_x = RawValue('f', 0.5)
        self.path_y = RawValue('f', 0.5)
        
    def setBallPosition(self, pos):
        self.ball_pos_x.value = pos[1]
        self.ball_pos_y.value = pos[0]
        
    def setTargetPosition(self, pos):
        self.target_pos_x.value = pos[1]
        self.target_pos_y.value = pos[0]
        
    def getPathTarget(self):
        return (self.path_x.value, self.path_y.value)
        
    def startProcessing(self, _frame_array):
        print(""Starting PathPlanner process"")
        self.process = Process(target=PathPlanner.doPlanning, args=(self,_frame_array))
        self.process.daemon = True
        self.process.start()
        
    def stopProcessing(self):
        print(""Stopping PathPlanner process"")
        self.process.terminate()
        
    def doPlanning(self, _frame_array):
        obstacle_map_update_time = 0.0
        path_sub_update_time = 0.0
        while True:
            if time.perf_counter() - obstacle_map_update_time >= PathPlanner.obstacle_map_update_delta:
                obstacle_map_update_time = time.perf_counter()
                PathPlanner.updateObstacleMap(self, _frame_array)
                
            if time.perf_counter() - path_sub_update_time >= PathPlanner.path_sub_update_delta:
                path_sub_update_time = time.perf_counter()
                PathPlanner.UpdateSubPath(self)
        
    #aktualizuje bitmape przeszkod
    def updateObstacleMap(self, _frame_array):
        frame = np.frombuffer(_frame_array, dtype=np.int32)
        frame = np.clip(frame, 0, 255).astype('uint8').reshape((PathPlanner.obstacle_map_size, PathPlanner.obstacle_map_size))
        #cv2.imshow(""Map"", frame)
        frame = cv2.inRange(frame, 100, 255)
        #kernel = np.ones((2,2), np.uint8)
        #frame = cv2.dilate(frame, kernel, iterations=1)
        self.obstacle_map = frame
        
        #aktualizacja mapy bliskosci przeszkod
        self.proximity_map.fill(0)
        size = PathPlanner.obstacle_map_size - 1
        sides = ((1, 0), (1, -1), (0, -1), (-1, -1), (-1, 0), (-1, 1), (0, 1), (1, 1))
        for x in range(1, size):
            for y in range(1, size):
                if frame[x, y] > 0:
                    for side in sides:
                        self.proximity_map[x + side[0], y + side[1]] += 1
        
        #np.clip(self.proximity_map, 0, 1, self.proximity_map)
        self.proximity_map *= 5000
        
        #aktualizacja glownej sciezki
        start = (round(self.ball_pos_x.value * PathPlanner.obstacle_map_size), round(self.ball_pos_y.value * PathPlanner.obstacle_map_size))
        end = (round(self.target_pos_x.value * PathPlanner.obstacle_map_size), round(self.target_pos_y.value * PathPlanner.obstacle_map_size))
        self.path = PathPlanner.a_star(self, start, end)
        
        self.path_last_index = len(self.path)-1
        self.path_position = 0.0
        
    #aktualizuje podsciezke przy uzyciu algorytmu A*
    def UpdateSubPath(self):
        if self.path == None: return None
        
        ball_pos = (self.ball_pos_x.value, self.ball_pos_y.value)
        path = self.path
        
        index = int(self.path_position)
        A = PathPlanner.FromMapToUnitarySpace(path[index])
        
        if self.path_last_index > 0:
            B = PathPlanner.FromMapToUnitarySpace(path[index+1])
            dist = MM.distance(A, B)
            mant = self.path_position - index
            
            self.path_position += self.path_speed * PathPlanner.path_sub_update_delta / (dist * PathPlanner.obstacle_map_size)
            if self.path_position >= self.path_last_index: self.path_position = self.path_last_index - 0.00001
            
            target_y = MM.lerp(A[0], B[0], mant)
            target_x = MM.lerp(A[1], B[1], mant)
        else:
            target_y = A[0]
            target_x = A[1]
            
        print(target_x)
        print(target_y)
        print("""")
        
        self.path_x.value = target_x
        self.path_y.value = target_y
            
        frame = copy.copy(self.obstacle_map)
        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
        
        #DEBUG
        for p in path:
            if PathPlanner.isPointWithinMap(self, p):
                frame[p[0], p[1]] = [255, 255, 0]
            
        frame = cv2.resize(frame, (200, 200), interpolation=cv2.INTER_NEAREST)
        
        cv2.imshow(""PathPlanner frame"", frame)
        key = cv2.waitKey(1) & 0xFF
        
    #zmienia uklad odniesienia z mapy przeszkod na jednostkowy
    def FromMapToUnitarySpace(point):
        return (point[0] / PathPlanner.obstacle_map_size, point[1] / PathPlanner.obstacle_map_size)
        
    #sprawdza, czy punkt wewnatrz mapy przeszkod
    def isPointWithinMap(self, point):
        size = self.obstacle_map_size
        return point[0] >= 0 and point[0] < size and point[1] >= 0 and point[1] < size
        
    #algorytm A* wyznaczajacy sciezke z punktu A do B
    def a_star(self, A, B):
        start = B
        end = A
        movement = ((1, 0), (-1, 0), (0, 1), (0, -1))
        #movement = ((1, 0), (-1, 0), (0, 1), (0, -1), (-1, -1), (-1, 1), (1, 1), (1, -1))
        
        que = MM.PriorityQueue()
        que.push(start, 0)
        
        visited_from = {}
        cost = {}
        
        visited_from[start] = None
        visited_from[end] = None
        cost[start] = 0
        
        #timeStart = time.perf_counter()
        while not que.empty():
            v = que.pop()
            if v == end: break
            
            new_cost = cost[v] + 1
            for move in movement:
                nx = v[0] + move[0]
                ny = v[1] + move[1]
                
                if PathPlanner.isPointWithinMap(self, (nx, ny)) and self.obstacle_map[nx, ny] == 0:
                    u = (nx, ny)
                    if u not in cost or new_cost < cost[u]:
                        cost[u] = new_cost
                        center = PathPlanner.obstacle_map_size // 2
                        que.push(u, new_cost + MM.sqrMagnitude(v[0] - u[0], v[1] - u[1]) + self.proximity_map[u[0], u[1]] + int(MM.sqrMagnitude(center - u[0], center - u[1])))
                        visited_from[u] = v
        
        path = []
        if visited_from[end] != None:
            v = end
            while v != start:
                path.append(v)
                v = visited_from[v]
            path.append(start)
        else:
            time.sleep(0.05)
            path.append(end)
        
        return path
    
    #sprawdza, czy promien przecina pole, na ktorym znajduje sie przeszkoda
    def Raycast(self, origin, end):
        obstacle_map = self.obstacle_map
        if not PathPlanner.isPointWithinMap(self, origin) or not PathPlanner.isPointWithinMap(self, end): return False    #jesli punkt startowy jest poza mapa
        if origin == end: return obstacle_map[origin[0], origin[1]]    #jesli promien jest punktem
        
        vec = (end[0] - origin[0], end[1] - origin[1])
        flipped = False    #czy wspolrzedne w ukladzie sa zamienione miejscami? (x; y) -> (y; x)
        if abs(vec[1]) > abs(vec[0]):
            #jesli nachylenie wektora jest wieksze niz 45 stopni
            #uklad wspolrzednych 'obracany jest' o 90 stopni
            vec = (vec[1], vec[0])
            origin = (origin[1], origin[0])
            end = (end[1], end[0])
            flipped = True
        
        dir = vec[1]/vec[0] #wspolczynnik kierunkowy promienia
        offset = origin[1] - dir * origin[0]    #skladnik 'b' w funkcji y = dir*x + b; przechodzi ona przez 'origin'
        
        #znaleznienie najbardziej lewego i prawego punktu promienia
        if origin[0] >= end[0]:
            left = end[0]
            right = origin[0]
        else:
            left = origin[0]
            right = end[0]
            
        #przejscie po wszystkich punktach mapy przeszkod nalezacych do promienia i sprawdzenie, czy ktorys z nich jest przeszkada
        if not flipped:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                #print(""Checked ("" + str(x) + "", "" + str(y) + "")"") 
                if obstacle_map[x, y] > 0:
                    return True
        else:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                #print(""Checked ("" + str(y) + "", "" + str(x) + "")"") 
                if obstacle_map[y, x] > 0:
                    return True
                
        return False
    
    #DEBUG
    def PaintRay(self, origin, end, frame):
        obstacle_map = self.obstacle_map
        if not PathPlanner.isPointWithinMap(self, origin) or not PathPlanner.isPointWithinMap(self, end): return    #jesli punkt startowy jest poza mapa
        if origin == end:
            frame[origin[0], origin[1]] = [0, 255, 0]
            return
            
        
        vec = (end[0] - origin[0], end[1] - origin[1])
        flipped = False    #czy wspolrzedne w ukladzie sa zamienione miejscami? (x; y) -> (y; x)
        if abs(vec[1]) > abs(vec[0]):
            #jesli nachylenie wektora jest wieksze niz 45 stopni
            #uklad wspolrzednych 'obracany jest' o 90 stopni
            vec = (vec[1], vec[0])
            origin = (origin[1], origin[0])
            end = (end[1], end[0])
            flipped = True
        
        dir = vec[1]/vec[0] #wspolczynnik kierunkowy promienia
        offset = origin[1] - dir * origin[0]    #skladnik 'b' w funkcji y = dir*x + b; przechodzi ona przez 'origin'
        
        #znaleznienie najbardziej lewego i prawego punktu promienia
        if origin[0] >= end[0]:
            left = end[0]
            right = origin[0]
        else:
            left = origin[0]
            right = end[0]
            
        #przejscie po wszystkich punktach mapy przeszkod nalezacych do promienia i sprawdzenie, czy ktorys z nich jest przeszkada
        if not flipped:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                frame[x, y] = [0, 255, 0]
        else:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                frame[y, x] = [0, 255, 0]/n/n/nPythonCode/ServoControllerModule.py/n/nfrom __future__ import division
simulationMode = True

if not simulationMode:
    import sys
    sys.path.append('/home/pi/Adafruit_Python_PCA9685/')
    import Adafruit_PCA9685
    
import math
import MathModule as MM

#program kontrolujacy ruch serw
class ServoController:
    
    #parametry serw
    servo_pulse_neutral = (388, 379)    #wartosci pwm dla pozycji neutralnych serw
    servo_pulse_range = (100, 100)      #zakres wartosci sygnalu pwm dla ruchu serw
    servo_pos_limit = (800, 800)    #ograniczenia wychylen serw (w skali od 0 do 1000)
    servo_movement_speed = (6000, 6000)    #szybkosci ruchu serw
    
    def __init__(self):
        if not simulationMode:
            self.pwm = Adafruit_PCA9685.PCA9685()  #laczenie sie z plytka sterujaca serwami
            self.pwm.set_pwm_freq(60)
        
        #zmienne wartosci
        self.servo_actual_pos = [0, 0]    #aktualna pozycja serwa
        self.servo_target_pos = [0, 0]    #docelowa pozycja serwa
        
        self.update(0)   #aplikowanie domyslnych ustawien serw

    #wydaje polecenie poruszenia serwem na kanale 'channel' na pozycje 'pos' (w skali od -1000 do 1000)
    def moveServo(self, channel, pos):
        self.servo_target_pos[channel] = MM.clamp(pos, -ServoController.servo_pos_limit[channel], ServoController.servo_pos_limit[channel])

    #aktualizuje pozycje serw
    def update(self, deltaTime):
        for i in range(2): #tylko 2 serwa
            
            movement_dir = MM.sign(self.servo_target_pos[i] - self.servo_actual_pos[i])
            self.servo_actual_pos[i] += ServoController.servo_movement_speed[i] * movement_dir * deltaTime
            
            if movement_dir > 0: self.servo_actual_pos[i] = min(self.servo_actual_pos[i], self.servo_target_pos[i])
            elif movement_dir < 0: self.servo_actual_pos[i] = max(self.servo_actual_pos[i], self.servo_target_pos[i])
                
            if not simulationMode:
                pos = round(ServoController.servo_pulse_neutral[i] + ServoController.servo_pulse_range[i] * self.servo_actual_pos[i] / 1000)
                self.pwm.set_pwm(i, 0, pos)
            else:
                self.servo_actual_pos[i] = round(self.servo_actual_pos[i])
/n/n/n",0
141,141,d7e7869ba3a5b040215ac4426b4dc10ad8f8e20d,"/PythonCode/Ballance.py/n/nif __name__ == '__main__':
    simulationMode = False    #czy uruchomic program w trybie symulacji? wymaga rowniez zmiany w ServoControllerModule.py oraz w ImageProcessingModule.py

    import ImageProcessingModule as IPM
    import ServoControllerModule as SCM
    import PIDControllerModule as PIDCM
    import DataLoggerModule as DLM
    import PathPlannerModule as PPM
    
    from time import sleep
    import time
    import pygame
    import math
    import MathModule as MM

    #wykonanie wstepnych czynnosci
    if simulationMode:
        import SimulationCommunicatorModule as SimCM
        simulationCommunicator = SimCM.SimulationCommunicator()
    else: simulationCommunicator = None
    
    imageProcessor = IPM.ImageProcessor(simulationCommunicator)
    servoController = SCM.ServoController()
    pathPlanner = PPM.PathPlanner()
        
    dataLogger = DLM.DataLogger()
    pidController = PIDCM.PIDController()
    pidController.servo_pos_limit = servoController.servo_pos_limit

    pygame.init()
    pygame.display.set_mode((100, 100))

    #roizpoczynanie procesu wykrywania kulki
    if simulationMode: simulationCommunicator.StartProcessing()
    imageProcessor.StartProcessing()
    pathPlanner.startProcessing(imageProcessor.obstacle_map)

    targetDeltaTime = 1.0 / 40.0    #czas jednej iteracji programu sterujacego
    updatedTime = 0.0
    servoUpdateDeltaTime = 1.0 / 60 #czas odswiezania pozycji serw
    servoUpdatedTime = 0.0

    ball_position_actual = (0.0, 0.0)
    ball_position_previous = (0.0, 0.0)

    #parametry trajektorii kulki
    angle = 0.0
    angleSpeed = 0.9
    angleRadius = 0.25
    angleRadiusFactor = 0.0
    path_targets = [(0.18, 0.18), (0.82, 0.82)]
    path_target_index = 0
    targetPos = path_targets[path_target_index]
    moveSpeed = 0.05
    movementMode = 0
    modeChangeTimeDelta = 25 #czas po jakim zmieniana jest trajektoria kulki
    modeChangeTimer = 0.0

    #jak dlugo wykonywany ma byc program
    duration = 10000
    timeout = time.time() + duration
    ball_just_found = True    #czy kulka dopiero zostala znaleziona i nalezy zresetowac predkosc?

    #glowna petla programu
    while time.time() <= timeout:
        timeStart = time.perf_counter()
        
        #oczekiwanie na odpowiedni moment do wykonania programu sterujacego
        if timeStart - updatedTime >= targetDeltaTime:
            updatedTime = time.perf_counter()
            
            #pobranie pozycji kulki
            ball_position_actual = imageProcessor.getBallPosition()
            if ball_position_actual[0] >= 0: pidController.setActualValue(ball_position_actual)
            else: pidController.setActualValue(pidController.value_target)
                
            #aktualizacja kontrolera PID
            pidController.update(targetDeltaTime)
            ball_position_previous = ball_position_actual
            
            #aktualizacja pozycji kulki w pathplannerze
            pathPlanner.setBallPosition(ball_position_actual)
            pidController.setTargetValue(pathPlanner.getPathTarget())
            
            #przechodzenie do kolejnego waypoint'a
            if MM.sqrMagnitude(ball_position_actual[0] - targetPos[0], ball_position_actual[1] - targetPos[1]) < 0.01:
                path_target_index = (path_target_index + 1) % len(path_targets)
                targetPos = path_targets[path_target_index]
                pathPlanner.setTargetPosition(targetPos)
            #print(str(pidController.value_target))
            
            #obslugiwanie wejscia z klawiatury
            killLoop = False
            for event in pygame.event.get():
                if event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_g:
                        pidController.increaseKP()
                        
                    elif event.key == pygame.K_b:
                        pidController.decreaseKP()
                        
                    elif event.key == pygame.K_h:
                        pidController.increaseKI()
                        
                    elif event.key == pygame.K_n:
                        pidController.decreaseKI()
                        
                    elif event.key == pygame.K_j:
                        pidController.increaseKD()
                        
                    elif event.key == pygame.K_m:
                        pidController.decreaseKD()
                        
                    elif event.key == pygame.K_q:
                        killLoop = True
                        
                    elif event.key == pygame.K_UP:
                        targetPos[1] -= moveSpeed
                        
                    elif event.key == pygame.K_DOWN:
                        targetPos[1] += moveSpeed
                        
                    elif event.key == pygame.K_RIGHT:
                        targetPos[0] += moveSpeed
                        
                    elif event.key == pygame.K_LEFT:
                        targetPos[0] -= moveSpeed
                        
                    elif event.key == pygame.K_p:
                        angleSpeed += 0.1
                        print(""angleSpeed = "" + str(angleSpeed))
                        
                    elif event.key == pygame.K_o:
                        angleSpeed -= 0.1
                        print(""angleSpeed = "" + str(angleSpeed))
                        
            if killLoop:
                break
            
            #ustawianie nowych pozycji serw
            servoController.moveServo(0, round(pidController.x_servo))
            servoController.moveServo(1, -round(pidController.y_servo))
            
            #dostepne trajektorie ruchu kulki
            if False:
                if movementMode == 0:    #ksztalt osemki
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.sin(2.0 * angle)
                elif movementMode == 1:  #ksztalt okregu
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.cos(angle)
                elif movementMode == 2:   #ksztalt paraboli
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.cos(2.0 * angle)
                elif movementMode == 3:   #ksztalt litery S
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.sin(2.0 * angle)
                    if angle > 2:
                        angleSpeed = -angleSpeed
                        angle = 2
                    elif angle < -2:
                        angleSpeed = -angleSpeed
                        angle = -2
                    
            #targetPos[0] = 0.5 + angleRadiusFactor * angleRadius * targetPos[0]
            #targetPos[1] = 0.5 + angleRadiusFactor * angleRadius * targetPos[1]
            #ustawianie docelowej pozycji kulki
            #pidController.setTargetValue(targetPos[0], targetPos[1])
            #pathPlanner.setTargetPosition(tuple(targetPos))
            angle += angleSpeed * targetDeltaTime
            angleRadiusFactor += 0.25 * targetDeltaTime
            angleRadiusFactor = min(angleRadiusFactor, 1.0)
            
            modeChangeTimer += targetDeltaTime
            if modeChangeTimer >= modeChangeTimeDelta:
                modeChangeTimer = 0.0
                angleRadiusFactor = 0.0
                movementMode += 1
                movementMode = movementMode % 4
            
            #dodawanie wpisow do DataLog'u
            if False:
                path_target = pathPlanner.getPathTarget()
                dataLogger.addRecord(""timestamp"", time.perf_counter())
                dataLogger.addRecord(""ball_pos_x"", ball_position_actual[0])
                dataLogger.addRecord(""ball_pos_y"", ball_position_actual[1])
                dataLogger.addRecord(""target_pos_x"", path_target[0])
                dataLogger.addRecord(""target_pos_y"", path_target[1])
                dataLogger.addRecord(""KP"", pidController.KP)
                dataLogger.addRecord(""KI"", pidController.KI)
                dataLogger.addRecord(""KD"", pidController.KD)
                dataLogger.addRecord(""error_x"", pidController.x_error)
                dataLogger.addRecord(""error_y"", pidController.y_error)
                dataLogger.addRecord(""error_prev_x"", pidController.x_prev_error)
                dataLogger.addRecord(""error_prev_y"", pidController.y_prev_error)
                dataLogger.addRecord(""error_sum_x"", pidController.x_error_sum)
                dataLogger.addRecord(""error_sum_y"", pidController.y_error_sum)
                dataLogger.addRecord(""derivative_x"", pidController.x_derivative)
                dataLogger.addRecord(""derivative_y"", pidController.y_derivative)
                dataLogger.addRecord(""servo_actual_x"", servoController.servo_actual_pos[0])
                dataLogger.addRecord(""servo_actual_y"", servoController.servo_actual_pos[1])
                dataLogger.addRecord(""servo_target_x"", servoController.servo_target_pos[0])
                dataLogger.addRecord(""servo_target_y"", servoController.servo_target_pos[1])
                dataLogger.saveRecord()
            
        #oczekiwanie na odpowiedni moment do aktualizacji serw
        if time.perf_counter() - servoUpdatedTime >= servoUpdateDeltaTime:
            servoController.update(time.perf_counter() - servoUpdatedTime)
            servoUpdatedTime = time.perf_counter()
            
            if simulationMode:
                simulationCommunicator.moveServos(servoController.servo_actual_pos)
                
        sleep(0.004) #4 milisekundy na odpoczynek :)
            
    print(""Stopping program"")
    #dataLogger.saveToFile(""BallanceDataLog"")
    if simulationMode: simulationCommunicator.StopProcessing()
    else: imageProcessor.StopProcessing()
    pathPlanner.stopProcessing()/n/n/n/PythonCode/ImageProcessingModule.py/n/nsimulationMode = False

if not simulationMode:
    import TensorflowProcessingModule as TPM
    from imutils.video.pivideostream import PiVideoStream

import MathModule as MM
import math, time, copy
import cv2
import numpy as np
from multiprocessing import Process, RawValue, RawArray
 
#program sluzacy do analizy obrazu z kamery, wykrywania kulki
class ImageProcessor:
    
    #parametry kamery
    camera_resolution = (256, 256)
    camera_framerate = 40
    
    corner_detecton_area = (0.08, 0.08, 0.14, 0.14) #prostakat, w ktorym szukana jest krawedz plyty, jest on powielany dla kazdego rogu obrazu
    detection_image_resolution = (200, 200)
    detection_image_resolution_cropped = (-1, -1)
    
    #rozmiar bitmapy przeszkod
    obstacle_map_size = 40
    obstacle_map_update_delta = 40
        
    def __init__(self, _simulationCommunicator=None):
        print(""ImageProcessor object created"")
        self.simulationCommunicator = _simulationCommunicator
        #wartosci-rezultaty przetwarzania obrazu
        self.result_x = RawValue('f', 0.0)
        self.result_y = RawValue('f', 0.0)
        self.key = RawValue('i', 0)
        
        self.obstacle_map = RawArray('i', ImageProcessor.obstacle_map_size**2)
        self.obstacle_map_update_counter = 0
        
    def getBallPosition(self):    #zwraca pozycje kulki
        if simulationMode: return self.simulationCommunicator.getBallPosition()
        return (self.result_x.value, self.result_y.value)
        
    def StartProcessing(self):   #uruchamia proces przetwarzajacy obraz
        print(""Starting image processing"")
        
        self.process = Process(target=ImageProcessor.ProcessImage, args=(self,))
        self.process.daemon = True
        self.process.start()
        #ImageProcessor.ProcessImage(self)
        
    def StopProcessing(self):    #wydaje polecenie do zatrzymania przetwarzania obrazu
        print(""Stopping image processing"")
        self.key.value = -666
        self.process.terminate()
        
    def ProcessImage(self):    #przetwarza obraz pobierajac klatke z kamery i wykonujac na niej operacje analizy
        
        #bufor dzielenia mapy przeszkod z innymi procesami
        self.obstacle_map_np = np.frombuffer(self.obstacle_map, dtype=np.int32).reshape(ImageProcessor.obstacle_map_size**2)
        
        #parametry trackera kulki
        self.ballTracker_pos = [ImageProcessor.detection_image_resolution[0]//2, ImageProcessor.detection_image_resolution[1]//2]
        self.ballTracker_size = 40
        self.ballTracker_result = [0, 0]
        
        if not simulationMode:
            self.tensorflowProcessor = TPM.TensorflowProcessor()
            videoStream = PiVideoStream(resolution=ImageProcessor.camera_resolution, framerate=ImageProcessor.camera_framerate).start()   #uruchamianie watku, ktory czyta kolejne klatki z kamery
        else:
            videoStream = self.simulationCommunicator
        
        time.sleep(1)
        self.frame_original = videoStream.read()
        
        lastTime = time.time()
        a = 190
        lastID = 0
        
        saveCounter = 0
        saveCount = 0
        
        while True:
            if self.key.value == -666: break
            
            #prosty licznik przetworzonych klatek w ciagu sekundy
            a = a + 1
            if a > 200:
                if ImageProcessor.detection_image_resolution_cropped[0] == -1:
                    ImageProcessor.detection_image_resolution_cropped = (np.size(self.frame_original, 0), np.size(self.frame_original, 1))
                print(str(a * 1.0 / (time.time() - lastTime)))
                lastTime = time.time()
                a = 0
            
            #synchronizacja pobierania nowej klatki z czestotliwascia kamery
            while True:
                frameGrabbed = videoStream.read()
                ID = id(frameGrabbed)
                if ID != lastID:
                    self.frame_original = frameGrabbed
                    lastID = ID
                    break
                elif not simulationMode:
                    time.sleep(0.01)
            
            #klatka przeznaczona do debugowania
            #self.frame_debug = copy.copy(self.frame_original)
            
            if not simulationMode: self.corners = ImageProcessor.FindBoardCorners(self)    #znajdowanie pozycji rogow plyty
            else: self.corners = self.simulationCommunicator.FindBoardCorners()
            ImageProcessor.ChangePerspective(self)    #zmiana perspektywy znalezionej tablicy, aby wygladala jak kwadrat
            #self.frame_original = self.frame_original[1:200, 1:200] #przycinanie zdjecia
            if not simulationMode: ImageProcessor.UpdateBallTracker(self)    #aktualizacja trackera kulki
            else:
                pos = self.simulationCommunicator.getBallPosition()
                self.ballTracker_result[0] = pos[0] * ImageProcessor.detection_image_resolution_cropped[0]
                self.ballTracker_result[1] = pos[1] * ImageProcessor.detection_image_resolution_cropped[1]
            ImageProcessor.UpdateObstacleMap(self)
            
            #ustawianie znalezionej pozycji kulki w zmiennych dzielonych miedzy procesami
            self.result_x.value = self.ballTracker_result[0] / ImageProcessor.detection_image_resolution_cropped[0]
            self.result_y.value = self.ballTracker_result[1] / ImageProcessor.detection_image_resolution_cropped[1]
            
            #cv2.imshow(""Frame debug"", self.frame_debug)
            if saveCounter < saveCount:
                cv2.imwrite(""Frame"" + str(saveCounter) + "".png"", self.frame_original)
                saveCounter += 1
                
            cv2.imshow(""Frame Casted"", self.frame_original)
            key = cv2.waitKey(1) & 0xFF
            #if key == ord(""q""):
            #    break
            
        videoStream.stop()
            
    #aktualizuje tracker kulki
    def UpdateBallTracker(self):
        self.ballTracker_pos[0] = MM.clamp(self.ballTracker_pos[0], 0, ImageProcessor.detection_image_resolution_cropped[0] - self.ballTracker_size)
        self.ballTracker_pos[1] = MM.clamp(self.ballTracker_pos[1], 0, ImageProcessor.detection_image_resolution_cropped[1] - self.ballTracker_size)
        
        self.ballTracker_pos[0] = int(self.ballTracker_pos[0])
        self.ballTracker_pos[1] = int(self.ballTracker_pos[1])
        
        #przygotowanie klatki z kamery do analizy
        tracker_frame = self.frame_original[self.ballTracker_pos[1]:self.ballTracker_pos[1]+self.ballTracker_size,
                                            self.ballTracker_pos[0]:self.ballTracker_pos[0]+self.ballTracker_size]
        tracker_frame = cv2.cvtColor(tracker_frame, cv2.COLOR_BGR2GRAY)
        
        #analiza klatki z uzyciem sieci neuronowych
        result = self.tensorflowProcessor.getBallPosition(tracker_frame)
        result = np.round(result * self.ballTracker_size).astype(""int"")
        
        self.ballTracker_result[0] = self.ballTracker_pos[0] + result[0]
        self.ballTracker_result[1] = self.ballTracker_pos[1] + result[1]
        
        #zaznaczanie wizualne pozycji kulki
        #cv2.circle(self.frame_original, tuple(self.ballTracker_result), 1, (0, 0, 255), -1)
        
        #aktualizacja pozycji trackera
        self.ballTracker_pos[0] = MM.lerp(self.ballTracker_pos[0], self.ballTracker_result[0] - self.ballTracker_size // 2, 0.7)
        self.ballTracker_pos[1] = MM.lerp(self.ballTracker_pos[1], self.ballTracker_result[1] - self.ballTracker_size // 2, 0.7)
    
    #znajduje pozycje krawedzi plyty
    def FindBoardCorners(self):
        corners = np.zeros((4, 2), dtype=np.int32)
        corner_detection_area_pixels = [round(self.corner_detecton_area[0] * self.camera_resolution[0]),
                                       round(self.corner_detecton_area[1] * self.camera_resolution[1]),
                                       round(self.corner_detecton_area[2] * self.camera_resolution[0]),
                                       round(self.corner_detecton_area[3] * self.camera_resolution[1])]
        for i in range(4):
            flipX = False
            flipY = False
            detectionArea = copy.copy(corner_detection_area_pixels)    #domyslnie lewy gorny
            if i == 1 or i == 2:
                detectionArea[0] = self.camera_resolution[0] - detectionArea[0] - detectionArea[2]
                flipX = True
            if i == 3 or i == 2:
                detectionArea[1] = self.camera_resolution[1] - detectionArea[1] - detectionArea[3]
                flipY = True
                
            rect = (detectionArea[0], detectionArea[1], detectionArea[0] + detectionArea[2], detectionArea[1] + detectionArea[3])
            #cv2.rectangle(self.frame_debug, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 1);
        
            img = self.frame_original[rect[1]:rect[3], rect[0]:rect[2]]
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            img = cv2.resize(img, (40, 40), interpolation=cv2.INTER_NEAREST)
            
            if flipX and flipY: img = cv2.flip(img, -1)
            elif flipX: img = cv2.flip(img, 1)
            elif flipY: img = cv2.flip(img, 0)
            #cv2.imshow(""Corner "" + str(i), img)
            
            result = self.tensorflowProcessor.getCornerPosition(img)
            corner = np.round(result * 40.0).astype(""int"")
            
            if flipX and flipY: corners[i] = (40 - corner[0] + detectionArea[0], 40 - corner[1] + detectionArea[1])
            elif flipX: corners[i] = (40 - corner[0] + detectionArea[0], corner[1] + detectionArea[1])
            elif flipY: corners[i] = (corner[0] + detectionArea[0], 40 - corner[1] + detectionArea[1])
            else: corners[i] = (corner[0] + detectionArea[0], corner[1] + detectionArea[1])
            #cv2.circle(self.frame_debug, corners[i], 1, (0, 0, 255), 1)

        return corners

    #zmienia perspektywe obrazu z kamery tak, aby niewidoczne bylo przechylenie plyty
    def ChangePerspective(self):
        pts = np.array(self.corners, np.float32)
        res = self.detection_image_resolution
        pts2 = np.float32([[0,0],[res[0],0],[res[0], res[1]], [0, res[1]]])

        M = cv2.getPerspectiveTransform(pts, pts2)
        self.frame_original = cv2.warpPerspective(self.frame_original, M, res)
        
    #aktualizuje mape przeszkod na plycie
    def UpdateObstacleMap(self):
        self.obstacle_map_update_counter += 1
        if self.obstacle_map_update_counter >= ImageProcessor.obstacle_map_update_delta:
            self.obstacle_map_update_counter = 0
            frame = cv2.resize(self.frame_original, (ImageProcessor.obstacle_map_size, ImageProcessor.obstacle_map_size), interpolation=cv2.INTER_NEAREST)
            frame = np.int32(frame)
            frame = 2 * frame[...,2] - frame[...,1] - frame[...,0]
            np.copyto(self.obstacle_map_np, frame.ravel())
            #self.obstacle_map = frame[...,2].ravel()/n/n/n/PythonCode/PIDControllerModule.py/n/nimport MathModule as MM

class PIDController:
    
    #operacje zmiany pidow
    def increaseKP(self):
        self.KP += 50
        print(""KP = "" + str(self.KP))
        
    def increaseKI(self):
        self.KI += 50
        print(""KI = "" + str(self.KI))
        
    def increaseKD(self):
        self.KD += 50
        print(""KD = "" + str(self.KD))
        
    def decreaseKP(self):
        self.KP -= 50
        print(""KP = "" + str(self.KP))
        
    def decreaseKI(self):
        self.KI -= 50
        print(""KI = "" + str(self.KI))
        
    def decreaseKD(self):
        self.KD -= 50
        print(""KD = "" + str(self.KD))
        
    #ustawia aktualna wartosc
    def setActualValue(self, x, y=None):
        if y is not None:
            self.value_actual[0] = MM.lerp(self.value_actual[0], x, self.value_smoothing)
            self.value_actual[1] = MM.lerp(self.value_actual[1], y, self.value_smoothing)
        else:
            self.value_actual[0] = MM.lerp(self.value_actual[0], x[0], self.value_smoothing)
            self.value_actual[1] = MM.lerp(self.value_actual[1], x[1], self.value_smoothing)
        
    #ustawia docelowa wartosc
    def setTargetValue(self, x, y=None):
        if y is not None:
            self.value_target[0] = x
            self.value_target[1] = y
        else:
            self.value_target[0] = x[0]
            self.value_target[1] = x[1]
    
    def __init__(self):
        self.servo_pos_limit = (1000, 1000)    #ograniczenia wychylen serw (w skali od 0 do 1000)
        self.value_target = [0.5, 0.5]    #docelowa wartosc, ktora ma byc osiagnieta przez kontroler
        self.value_actual = [0.5, 0.5]    #aktualna wartosc
        self.value_smoothing = 0.7        #wspolczynnik wygladzania aktualizacji aktualnej wartosci

        #wspolczynniki kontroli
        self.KP = 1.5 * 1000   #wzmocnienie czesci proporcjonalnej
        self.KI = 7.0 * 1000    #wzmocnienie czesci calkujacej
        self.KD = 0.5 * 1000   #wzmocnienie czesci rozniczkujacej

        #pozycja serwa
        self.x_servo = 0.0
        self.y_servo = 0.0

        #wartosc bledu
        self.x_error = 0.0
        self.y_error = 0.0

        #wartosci poprzednich bledow
        self.x_prev_error = 0.0
        self.y_prev_error = 0.0

        #zmiana bledu w czasie
        self.x_derivative = 0.0
        self.y_derivative = 0.0

        #calkowita suma bledow
        self.x_error_sum = 0.0
        self.y_error_sum = 0.0

    #aktualizuje kontrolea PID
    def update(self, deltaTime):
        #liczenie bledu
        self.x_error = self.value_target[0] - self.value_actual[0]
        self.y_error = self.value_target[1] - self.value_actual[1]
        
        #print(""Error = ( "" + str(self.x_error) + ""; "" + str(self.y_error) + "")"")

        #liczenie pochodnej
        self.x_derivative = (self.x_error - self.x_prev_error) / deltaTime
        self.y_derivative = (self.y_error - self.y_prev_error) / deltaTime

        self.x_prev_error = self.x_error
        self.y_prev_error = self.y_error

        self.x_error_sum += self.x_error * deltaTime
        self.y_error_sum += self.y_error * deltaTime
        
        #zmiana pozycji serw z uwzglednieniem bledu biezacego, przyszlego oraz przeszlego
        self.x_servo = (self.x_error * self.KP) + (self.x_derivative * self.KD) + (self.x_error_sum * self.KI)
        self.y_servo = (self.y_error * self.KP) + (self.y_derivative * self.KD) + (self.y_error_sum * self.KI)
        
        self.x_servo = MM.clamp(self.x_servo, -self.servo_pos_limit[0], self.servo_pos_limit[0])
        self.y_servo = MM.clamp(self.y_servo, -self.servo_pos_limit[1], self.servo_pos_limit[1])
        
        self.x_error_sum = MM.clamp(self.x_error_sum, -1.0, 1.0) * 0.8
        self.y_error_sum = MM.clamp(self.y_error_sum, -1.0, 1.0) * 0.8/n/n/n/PythonCode/PathPlannerModule.py/n/nimport cv2
import numpy as np
import MathModule as MM
import time
from multiprocessing import Process, RawValue
from collections import deque
import copy

#program odpowiadajacy za planiwanie sciezki kulki
class PathPlanner:
    
    obstacle_map_size = 40    #rozmiar mapy przeszkod
    obstacle_map_update_delta = 4    #co ile sekund odswiezana ma byc mapa przeszkod?
    path_sub_update_delta = 0.3    #co ile sekund aktualizowac podsciezke?
    
    def __init__(self):
        print(""PathPlanner object created"")
        
        self.obstacle_map = None
        self.path = None
        self_path_last_index = 0
        self.proximity_map = np.zeros((PathPlanner.obstacle_map_size, PathPlanner.obstacle_map_size)) #tablica 2D z kosztem bliskosci wykrytych przeszkod
        
        self.ball_pos_x = RawValue('f', 0.5)
        self.ball_pos_y = RawValue('f', 0.5)
        self.target_pos_x = RawValue('f', 0.25)
        self.target_pos_y = RawValue('f', 0.25)
        self.path_x = RawValue('f', 0.5)
        self.path_y = RawValue('f', 0.5)
        
    def setBallPosition(self, pos):
        self.ball_pos_x.value = pos[1]
        self.ball_pos_y.value = pos[0]
        
    def setTargetPosition(self, pos):
        self.target_pos_x.value = pos[1]
        self.target_pos_y.value = pos[0]
        
    def getPathTarget(self):
        return (self.path_x.value, self.path_y.value)
        
    def startProcessing(self, _frame_array):
        print(""Starting PathPlanner process"")
        self.process = Process(target=PathPlanner.doPlanning, args=(self,_frame_array))
        self.process.daemon = True
        self.process.start()
        
    def stopProcessing(self):
        print(""Stopping PathPlanner process"")
        self.process.terminate()
        
    def doPlanning(self, _frame_array):
        obstacle_map_update_time = 0.0
        path_sub_update_time = 0.0
        while True:
            if time.perf_counter() - obstacle_map_update_time >= PathPlanner.obstacle_map_update_delta:
                obstacle_map_update_time = time.perf_counter()
                PathPlanner.updateObstacleMap(self, _frame_array)
                
            if time.perf_counter() - path_sub_update_time >= PathPlanner.path_sub_update_delta:
                path_sub_update_time = time.perf_counter()
                PathPlanner.UpdateSubPath(self)
        
    #aktualizuje bitmape przeszkod
    def updateObstacleMap(self, _frame_array):
        frame = np.frombuffer(_frame_array, dtype=np.int32)
        frame = np.clip(frame, 0, 255).astype('uint8').reshape((PathPlanner.obstacle_map_size, PathPlanner.obstacle_map_size))
        #cv2.imshow(""Map"", frame)
        frame = cv2.inRange(frame, 100, 255)
        #kernel = np.ones((2,2), np.uint8)
        #frame = cv2.dilate(frame, kernel, iterations=1)
        self.obstacle_map = frame
        
        #aktualizacja mapy bliskosci przeszkod
        self.proximity_map.fill(0)
        size = PathPlanner.obstacle_map_size - 1
        sides = ((1, 0), (1, -1), (0, -1), (-1, -1), (-1, 0), (-1, 1), (0, 1), (1, 1))
        for x in range(1, size):
            for y in range(1, size):
                if frame[x, y] > 0:
                    for side in sides:
                        self.proximity_map[x + side[0], y + side[1]] += 1
        
        #np.clip(self.proximity_map, 0, 1, self.proximity_map)
        self.proximity_map *= 0#5000
        
        #aktualizacja glownej sciezki
        start = (round(self.ball_pos_x.value * PathPlanner.obstacle_map_size), round(self.ball_pos_y.value * PathPlanner.obstacle_map_size))
        end = (round(self.target_pos_x.value * PathPlanner.obstacle_map_size), round(self.target_pos_y.value * PathPlanner.obstacle_map_size))
        self.path = PathPlanner.a_star(self, start, end)
        self.path_last_index = len(self.path)-1
        
    #aktualizuje podsciezke przy uzyciu algorytmu A*
    def UpdateSubPath(self):
        if self.path == None: return None
        
        ball_pos = (self.ball_pos_x.value, self.ball_pos_y.value)
        path = self.path
        start = (round(ball_pos[0] * PathPlanner.obstacle_map_size), round(ball_pos[1] * PathPlanner.obstacle_map_size))
        end = path[self.path_last_index]
        
        #wyszukiwanie binarne najdlaszego punktu na sciezce, do ktorego da sie dojsc w linii prostej
        x = 0
        y = self.path_last_index
        center = 0
        index = 0
        while x <= y:
            center = (x + y) // 2
            if not PathPlanner.Raycast(self, start, path[center]):
                index = center
                x = center + 1
            else: y = center - 1
        
        end = (end[0] / PathPlanner.obstacle_map_size, end[1] / PathPlanner.obstacle_map_size)
        dist = 0.13 * MM.clamp(4 * MM.magnitude(ball_pos[0] - end[0], ball_pos[1] - end[1]), 0.4, 1)
        #print(str(MM.magnitude(ball_pos[0] - self.target_pos_x.value, ball_pos[1] - self.target_pos_y.value)))
        
        vec2go = MM.normalized(path[index][0] - start[0], path[index][1]- start[1])    #wektor docelowego ruchu kulki
        mag = MM.magnitude(0.5 - ball_pos[0], 0.5 - ball_pos[1])    #odleglosc kulki od srodka plyty
        vec2center = ((0.5 - ball_pos[0]) / mag, (0.5 - ball_pos[1]) / mag)    #wektor z pozycji kulki do srodka plyty
        edgeReluctance = 0.012 / (0.6 - min(mag, 0.5))
        print(edgeReluctance)
        
        self.path_x.value = vec2go[1] * dist + ball_pos[1] + vec2center[1] * edgeReluctance
        self.path_y.value = vec2go[0] * dist + ball_pos[0] + vec2center[0] * edgeReluctance
            
        frame = copy.copy(self.obstacle_map)
        #frame = np.uint8(frame)
        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
        
        #DEBUG
        #for p in path:
        #    if PathPlanner.isPointWithinMap(self, p):
        #        frame[p[0], p[1]] = [255, 255, 0]
            
        PathPlanner.PaintRay(self, start, path[index], frame)
        frame = cv2.resize(frame, (200, 200), interpolation=cv2.INTER_NEAREST)
        
        cv2.imshow(""PathPlanner frame"", frame)
        key = cv2.waitKey(1) & 0xFF
        
    #sprawdza, czy punkt wewnatrz mapy przeszkod
    def isPointWithinMap(self, point):
        size = self.obstacle_map_size
        return point[0] >= 0 and point[0] < size and point[1] >= 0 and point[1] < size
        
    #algorytm A* wyznaczajacy sciezke z punktu A do B
    def a_star(self, A, B):
        start = B
        end = A
        movement = ((1, 0), (-1, 0), (0, 1), (0, -1))
        #movement = ((1, 0), (-1, 0), (0, 1), (0, -1), (-1, -1), (-1, 1), (1, 1), (1, -1))
        
        que = MM.PriorityQueue()
        que.push(start, 0)
        
        visited_from = {}
        cost = {}
        
        visited_from[start] = None
        visited_from[end] = None
        cost[start] = 0
        
        #timeStart = time.perf_counter()
        while not que.empty():
            v = que.pop()
            if v == end: break
            
            new_cost = cost[v] + 1
            for move in movement:
                nx = v[0] + move[0]
                ny = v[1] + move[1]
                
                if PathPlanner.isPointWithinMap(self, (nx, ny)) and self.obstacle_map[nx, ny] == 0:
                    u = (nx, ny)
                    if u not in cost or new_cost < cost[u]:
                        cost[u] = new_cost
                        center = PathPlanner.obstacle_map_size // 2
                        que.push(u, new_cost + MM.sqrMagnitude(v[0] - u[0], v[1] - u[1]) + self.proximity_map[u[0], u[1]] + int(MM.sqrMagnitude(center - u[0], center - u[1])))
                        visited_from[u] = v
        
        path = []
        if visited_from[end] != None:
            v = end
            while v != start:
                path.append(v)
                v = visited_from[v]
            path.append(start)
        else:
            time.sleep(0.05)
            path.append(end)
        
        return path
    
    #sprawdza, czy promien przecina pole, na ktorym znajduje sie przeszkoda
    def Raycast(self, origin, end):
        obstacle_map = self.obstacle_map
        if not PathPlanner.isPointWithinMap(self, origin) or not PathPlanner.isPointWithinMap(self, end): return False    #jesli punkt startowy jest poza mapa
        if origin == end: return obstacle_map[origin[0], origin[1]]    #jesli promien jest punktem
        
        vec = (end[0] - origin[0], end[1] - origin[1])
        flipped = False    #czy wspolrzedne w ukladzie sa zamienione miejscami? (x; y) -> (y; x)
        if abs(vec[1]) > abs(vec[0]):
            #jesli nachylenie wektora jest wieksze niz 45 stopni
            #uklad wspolrzednych 'obracany jest' o 90 stopni
            vec = (vec[1], vec[0])
            origin = (origin[1], origin[0])
            end = (end[1], end[0])
            flipped = True
        
        dir = vec[1]/vec[0] #wspolczynnik kierunkowy promienia
        offset = origin[1] - dir * origin[0]    #skladnik 'b' w funkcji y = dir*x + b; przechodzi ona przez 'origin'
        
        #znaleznienie najbardziej lewego i prawego punktu promienia
        if origin[0] >= end[0]:
            left = end[0]
            right = origin[0]
        else:
            left = origin[0]
            right = end[0]
            
        #przejscie po wszystkich punktach mapy przeszkod nalezacych do promienia i sprawdzenie, czy ktorys z nich jest przeszkada
        if not flipped:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                #print(""Checked ("" + str(x) + "", "" + str(y) + "")"") 
                if obstacle_map[x, y] > 0:
                    return True
        else:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                #print(""Checked ("" + str(y) + "", "" + str(x) + "")"") 
                if obstacle_map[y, x] > 0:
                    return True
                
        return False
    
    #DEBUG
    def PaintRay(self, origin, end, frame):
        obstacle_map = self.obstacle_map
        if not PathPlanner.isPointWithinMap(self, origin) or not PathPlanner.isPointWithinMap(self, end): return    #jesli punkt startowy jest poza mapa
        if origin == end:
            frame[origin[0], origin[1]] = [0, 255, 0]
            return
            
        
        vec = (end[0] - origin[0], end[1] - origin[1])
        flipped = False    #czy wspolrzedne w ukladzie sa zamienione miejscami? (x; y) -> (y; x)
        if abs(vec[1]) > abs(vec[0]):
            #jesli nachylenie wektora jest wieksze niz 45 stopni
            #uklad wspolrzednych 'obracany jest' o 90 stopni
            vec = (vec[1], vec[0])
            origin = (origin[1], origin[0])
            end = (end[1], end[0])
            flipped = True
        
        dir = vec[1]/vec[0] #wspolczynnik kierunkowy promienia
        offset = origin[1] - dir * origin[0]    #skladnik 'b' w funkcji y = dir*x + b; przechodzi ona przez 'origin'
        
        #znaleznienie najbardziej lewego i prawego punktu promienia
        if origin[0] >= end[0]:
            left = end[0]
            right = origin[0]
        else:
            left = origin[0]
            right = end[0]
            
        #przejscie po wszystkich punktach mapy przeszkod nalezacych do promienia i sprawdzenie, czy ktorys z nich jest przeszkada
        if not flipped:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                frame[x, y] = [0, 255, 0]
        else:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                frame[y, x] = [0, 255, 0]/n/n/n/PythonCode/ServoControllerModule.py/n/nfrom __future__ import division
simulationMode = False

if not simulationMode:
    import sys
    sys.path.append('/home/pi/Adafruit_Python_PCA9685/')
    import Adafruit_PCA9685
    
import math
import MathModule as MM

#program kontrolujacy ruch serw
class ServoController:
    
    #parametry serw
    servo_pulse_neutral = (388, 379)    #wartosci pwm dla pozycji neutralnych serw
    servo_pulse_range = (100, 100)      #zakres wartosci sygnalu pwm dla ruchu serw
    servo_pos_limit = (800, 800)    #ograniczenia wychylen serw (w skali od 0 do 1000)
    servo_movement_speed = (6000, 6000)    #szybkosci ruchu serw
    
    def __init__(self):
        if not simulationMode:
            self.pwm = Adafruit_PCA9685.PCA9685()  #laczenie sie z plytka sterujaca serwami
            self.pwm.set_pwm_freq(60)
        
        #zmienne wartosci
        self.servo_actual_pos = [0, 0]    #aktualna pozycja serwa
        self.servo_target_pos = [0, 0]    #docelowa pozycja serwa
        
        self.update(0)   #aplikowanie domyslnych ustawien serw

    #wydaje polecenie poruszenia serwem na kanale 'channel' na pozycje 'pos' (w skali od -1000 do 1000)
    def moveServo(self, channel, pos):
        self.servo_target_pos[channel] = MM.clamp(pos, -ServoController.servo_pos_limit[channel], ServoController.servo_pos_limit[channel])

    #aktualizuje pozycje serw
    def update(self, deltaTime):
        for i in range(2): #tylko 2 serwa
            
            movement_dir = MM.sign(self.servo_target_pos[i] - self.servo_actual_pos[i])
            self.servo_actual_pos[i] += ServoController.servo_movement_speed[i] * movement_dir * deltaTime
            
            if movement_dir > 0: self.servo_actual_pos[i] = min(self.servo_actual_pos[i], self.servo_target_pos[i])
            elif movement_dir < 0: self.servo_actual_pos[i] = max(self.servo_actual_pos[i], self.servo_target_pos[i])
                
            if not simulationMode:
                pos = round(ServoController.servo_pulse_neutral[i] + ServoController.servo_pulse_range[i] * self.servo_actual_pos[i] / 1000)
                self.pwm.set_pwm(i, 0, pos)
            else:
                self.servo_actual_pos[i] = round(self.servo_actual_pos[i])
/n/n/n",1
142,142,da22d46baf8362ce33dd89c8d5ac834632fc4e0f,"PythonCode/Ballance.py/n/nif __name__ == '__main__':
    simulationMode = False    #czy uruchomic program w trybie symulacji? wymaga rowniez zmiany w ServoControllerModule.py oraz w ImageProcessingModule.py

    import ImageProcessingModule as IPM
    import ServoControllerModule as SCM
    import PIDControllerModule as PIDCM
    import DataLoggerModule as DLM
    import PathPlannerModule as PPM
    
    from time import sleep
    import time
    import pygame
    import math
    import MathModule as MM

    #wykonanie wstepnych czynnosci
    if simulationMode:
        import SimulationCommunicatorModule as SimCM
        simulationCommunicator = SimCM.SimulationCommunicator()
    else: simulationCommunicator = None
    
    imageProcessor = IPM.ImageProcessor(simulationCommunicator)
    servoController = SCM.ServoController()
    pathPlanner = PPM.PathPlanner()
        
    dataLogger = DLM.DataLogger()
    pidController = PIDCM.PIDController()
    pidController.servo_pos_limit = servoController.servo_pos_limit

    pygame.init()
    pygame.display.set_mode((100, 100))

    #roizpoczynanie procesu wykrywania kulki
    if simulationMode: simulationCommunicator.StartProcessing()
    imageProcessor.StartProcessing()
    pathPlanner.startProcessing(imageProcessor.obstacle_map)

    targetDeltaTime = 1.0 / 40.0    #czas jednej iteracji programu sterujacego
    updatedTime = 0.0
    servoUpdateDeltaTime = 1.0 / 60 #czas odswiezania pozycji serw
    servoUpdatedTime = 0.0

    ball_position_actual = (0.0, 0.0)
    ball_position_previous = (0.0, 0.0)

    #parametry trajektorii kulki
    angle = 0.0
    angleSpeed = 0.9
    angleRadius = 0.25
    angleRadiusFactor = 0.0
    path_targets = [(0.18, 0.18), (0.82, 0.82)]
    path_target_index = 0
    targetPos = path_targets[path_target_index]
    moveSpeed = 0.05
    movementMode = 0
    modeChangeTimeDelta = 25 #czas po jakim zmieniana jest trajektoria kulki
    modeChangeTimer = 0.0

    #jak dlugo wykonywany ma byc program
    duration = 10000
    timeout = time.time() + duration
    ball_just_found = True    #czy kulka dopiero zostala znaleziona i nalezy zresetowac predkosc?

    #glowna petla programu
    while time.time() <= timeout:
        timeStart = time.perf_counter()
        
        #oczekiwanie na odpowiedni moment do wykonania programu sterujacego
        if timeStart - updatedTime >= targetDeltaTime:
            updatedTime = time.perf_counter()
            
            #pobranie pozycji kulki
            ball_position_actual = imageProcessor.getBallPosition()
            if ball_position_actual[0] >= 0: pidController.setActualValue(ball_position_actual)
            else: pidController.setActualValue(pidController.value_target)
                
            #aktualizacja kontrolera PID
            pidController.update(targetDeltaTime)
            ball_position_previous = ball_position_actual
            
            #aktualizacja pozycji kulki w pathplannerze
            pathPlanner.setBallPosition(ball_position_actual)
            pidController.setTargetValue(pathPlanner.getPathTarget())
            
            #przechodzenie do kolejnego waypoint'a
            if MM.sqrMagnitude(ball_position_actual[0] - targetPos[0], ball_position_actual[1] - targetPos[1]) < 0.01:
                path_target_index = (path_target_index + 1) % len(path_targets)
                targetPos = path_targets[path_target_index]
                pathPlanner.setTargetPosition(targetPos)
            #print(str(pidController.value_target))
            
            #obslugiwanie wejscia z klawiatury
            killLoop = False
            for event in pygame.event.get():
                if event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_g:
                        pidController.increaseKP()
                        
                    elif event.key == pygame.K_b:
                        pidController.decreaseKP()
                        
                    elif event.key == pygame.K_h:
                        pidController.increaseKI()
                        
                    elif event.key == pygame.K_n:
                        pidController.decreaseKI()
                        
                    elif event.key == pygame.K_j:
                        pidController.increaseKD()
                        
                    elif event.key == pygame.K_m:
                        pidController.decreaseKD()
                        
                    elif event.key == pygame.K_q:
                        killLoop = True
                        
                    elif event.key == pygame.K_UP:
                        targetPos[1] -= moveSpeed
                        
                    elif event.key == pygame.K_DOWN:
                        targetPos[1] += moveSpeed
                        
                    elif event.key == pygame.K_RIGHT:
                        targetPos[0] += moveSpeed
                        
                    elif event.key == pygame.K_LEFT:
                        targetPos[0] -= moveSpeed
                        
                    elif event.key == pygame.K_p:
                        angleSpeed += 0.1
                        print(""angleSpeed = "" + str(angleSpeed))
                        
                    elif event.key == pygame.K_o:
                        angleSpeed -= 0.1
                        print(""angleSpeed = "" + str(angleSpeed))
                        
            if killLoop:
                break
            
            #ustawianie nowych pozycji serw
            servoController.moveServo(0, round(pidController.x_servo))
            servoController.moveServo(1, -round(pidController.y_servo))
            
            #dostepne trajektorie ruchu kulki
            if False:
                if movementMode == 0:    #ksztalt osemki
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.sin(2.0 * angle)
                elif movementMode == 1:  #ksztalt okregu
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.cos(angle)
                elif movementMode == 2:   #ksztalt paraboli
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.cos(2.0 * angle)
                elif movementMode == 3:   #ksztalt litery S
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.sin(2.0 * angle)
                    if angle > 2:
                        angleSpeed = -angleSpeed
                        angle = 2
                    elif angle < -2:
                        angleSpeed = -angleSpeed
                        angle = -2
                    
            #targetPos[0] = 0.5 + angleRadiusFactor * angleRadius * targetPos[0]
            #targetPos[1] = 0.5 + angleRadiusFactor * angleRadius * targetPos[1]
            #ustawianie docelowej pozycji kulki
            #pidController.setTargetValue(targetPos[0], targetPos[1])
            #pathPlanner.setTargetPosition(tuple(targetPos))
            angle += angleSpeed * targetDeltaTime
            angleRadiusFactor += 0.25 * targetDeltaTime
            angleRadiusFactor = min(angleRadiusFactor, 1.0)
            
            modeChangeTimer += targetDeltaTime
            if modeChangeTimer >= modeChangeTimeDelta:
                modeChangeTimer = 0.0
                angleRadiusFactor = 0.0
                movementMode += 1
                movementMode = movementMode % 4
            
            #dodawanie wpisow do DataLog'u
            if False:
                path_target = pathPlanner.getPathTarget()
                dataLogger.addRecord(""timestamp"", time.perf_counter())
                dataLogger.addRecord(""ball_pos_x"", ball_position_actual[0])
                dataLogger.addRecord(""ball_pos_y"", ball_position_actual[1])
                dataLogger.addRecord(""target_pos_x"", path_target[0])
                dataLogger.addRecord(""target_pos_y"", path_target[1])
                dataLogger.addRecord(""KP"", pidController.KP)
                dataLogger.addRecord(""KI"", pidController.KI)
                dataLogger.addRecord(""KD"", pidController.KD)
                dataLogger.addRecord(""error_x"", pidController.x_error)
                dataLogger.addRecord(""error_y"", pidController.y_error)
                dataLogger.addRecord(""error_prev_x"", pidController.x_prev_error)
                dataLogger.addRecord(""error_prev_y"", pidController.y_prev_error)
                dataLogger.addRecord(""error_sum_x"", pidController.x_error_sum)
                dataLogger.addRecord(""error_sum_y"", pidController.y_error_sum)
                dataLogger.addRecord(""derivative_x"", pidController.x_derivative)
                dataLogger.addRecord(""derivative_y"", pidController.y_derivative)
                dataLogger.addRecord(""servo_actual_x"", servoController.servo_actual_pos[0])
                dataLogger.addRecord(""servo_actual_y"", servoController.servo_actual_pos[1])
                dataLogger.addRecord(""servo_target_x"", servoController.servo_target_pos[0])
                dataLogger.addRecord(""servo_target_y"", servoController.servo_target_pos[1])
                dataLogger.saveRecord()
            
        #oczekiwanie na odpowiedni moment do aktualizacji serw
        if time.perf_counter() - servoUpdatedTime >= servoUpdateDeltaTime:
            servoController.update(time.perf_counter() - servoUpdatedTime)
            servoUpdatedTime = time.perf_counter()
            
            if simulationMode:
                simulationCommunicator.moveServos(servoController.servo_actual_pos)
                
        sleep(0.004) #4 milisekundy na odpoczynek :)
            
    print(""Stopping program"")
    #dataLogger.saveToFile(""BallanceDataLog"")
    if simulationMode: simulationCommunicator.StopProcessing()
    else: imageProcessor.StopProcessing()
    pathPlanner.stopProcessing()/n/n/nPythonCode/ImageProcessingModule.py/n/nsimulationMode = False

if not simulationMode:
    import TensorflowProcessingModule as TPM
    from imutils.video.pivideostream import PiVideoStream

import MathModule as MM
import math, time, copy
import cv2
import numpy as np
from multiprocessing import Process, RawValue, RawArray
 
#program sluzacy do analizy obrazu z kamery, wykrywania kulki
class ImageProcessor:
    
    #parametry kamery
    camera_resolution = (256, 256)
    camera_framerate = 40
    
    corner_detecton_area = (0.09, 0.09, 0.11, 0.11) #prostakat, w ktorym szukana jest krawedz plyty, jest on powielany dla kazdego rogu obrazu
    detection_image_resolution = (200, 200)
    detection_image_resolution_cropped = (-1, -1)
    
    #rozmiar bitmapy przeszkod
    obstacle_map_size = 40
    obstacle_map_update_delta = 40
        
    def __init__(self, _simulationCommunicator=None):
        print(""ImageProcessor object created"")
        self.simulationCommunicator = _simulationCommunicator
        #wartosci-rezultaty przetwarzania obrazu
        self.result_x = RawValue('f', 0.0)
        self.result_y = RawValue('f', 0.0)
        self.key = RawValue('i', 0)
        
        self.obstacle_map = RawArray('i', ImageProcessor.obstacle_map_size**2)
        self.obstacle_map_update_counter = 0
        
    def getBallPosition(self):    #zwraca pozycje kulki
        if simulationMode: return self.simulationCommunicator.getBallPosition()
        return (self.result_x.value, self.result_y.value)
        
    def StartProcessing(self):   #uruchamia proces przetwarzajacy obraz
        print(""Starting image processing"")
        
        self.process = Process(target=ImageProcessor.ProcessImage, args=(self,))
        self.process.daemon = True
        self.process.start()
        #ImageProcessor.ProcessImage(self)
        
    def StopProcessing(self):    #wydaje polecenie do zatrzymania przetwarzania obrazu
        print(""Stopping image processing"")
        self.key.value = -666
        self.process.terminate()
        
    def ProcessImage(self):    #przetwarza obraz pobierajac klatke z kamery i wykonujac na niej operacje analizy
        
        #bufor dzielenia mapy przeszkod z innymi procesami
        self.obstacle_map_np = np.frombuffer(self.obstacle_map, dtype=np.int32).reshape(ImageProcessor.obstacle_map_size**2)
        
        #parametry trackera kulki
        self.ballTracker_pos = [ImageProcessor.detection_image_resolution[0]//2, ImageProcessor.detection_image_resolution[1]//2]
        self.ballTracker_size = 40
        self.ballTracker_result = [0, 0]
        
        if not simulationMode:
            self.tensorflowProcessor = TPM.TensorflowProcessor()
            videoStream = PiVideoStream(resolution=ImageProcessor.camera_resolution, framerate=ImageProcessor.camera_framerate).start()   #uruchamianie watku, ktory czyta kolejne klatki z kamery
        else:
            videoStream = self.simulationCommunicator
        
        time.sleep(1)
        self.frame_original = videoStream.read()
        
        lastTime = time.time()
        a = 190
        lastID = 0
        
        saveCounter = 0
        saveCount = 0
        
        while True:
            if self.key.value == -666: break
            
            #prosty licznik przetworzonych klatek w ciagu sekundy
            a = a + 1
            if a > 200:
                if ImageProcessor.detection_image_resolution_cropped[0] == -1:
                    ImageProcessor.detection_image_resolution_cropped = (np.size(self.frame_original, 0), np.size(self.frame_original, 1))
                print(str(a * 1.0 / (time.time() - lastTime)))
                lastTime = time.time()
                a = 0
            
            #synchronizacja pobierania nowej klatki z czestotliwascia kamery
            while True:
                frameGrabbed = videoStream.read()
                ID = id(frameGrabbed)
                if ID != lastID:
                    self.frame_original = frameGrabbed
                    lastID = ID
                    break
                elif not simulationMode:
                    time.sleep(0.01)
            
            #klatka przeznaczona do debugowania
            #self.frame_debug = copy.copy(self.frame_original)
            
            if not simulationMode: self.corners = ImageProcessor.FindBoardCorners(self)    #znajdowanie pozycji rogow plyty
            else: self.corners = self.simulationCommunicator.FindBoardCorners()
            ImageProcessor.ChangePerspective(self)    #zmiana perspektywy znalezionej tablicy, aby wygladala jak kwadrat
            #self.frame_original = self.frame_original[1:200, 1:200] #przycinanie zdjecia
            if not simulationMode: ImageProcessor.UpdateBallTracker(self)    #aktualizacja trackera kulki
            else:
                pos = self.simulationCommunicator.getBallPosition()
                self.ballTracker_result[0] = pos[0] * ImageProcessor.detection_image_resolution_cropped[0]
                self.ballTracker_result[1] = pos[1] * ImageProcessor.detection_image_resolution_cropped[1]
            ImageProcessor.UpdateObstacleMap(self)
            
            #ustawianie znalezionej pozycji kulki w zmiennych dzielonych miedzy procesami
            self.result_x.value = self.ballTracker_result[0] / ImageProcessor.detection_image_resolution_cropped[0]
            self.result_y.value = self.ballTracker_result[1] / ImageProcessor.detection_image_resolution_cropped[1]
            
            #cv2.imshow(""Frame debug"", self.frame_debug)
            if saveCounter < saveCount:
                cv2.imwrite(""Frame"" + str(saveCounter) + "".png"", self.frame_original)
                saveCounter += 1
                
            cv2.imshow(""Frame Casted"", self.frame_original)
            key = cv2.waitKey(1) & 0xFF
            #if key == ord(""q""):
            #    break
            
        videoStream.stop()
            
    #aktualizuje tracker kulki
    def UpdateBallTracker(self):
        self.ballTracker_pos[0] = MM.clamp(self.ballTracker_pos[0], 0, ImageProcessor.detection_image_resolution_cropped[0] - self.ballTracker_size)
        self.ballTracker_pos[1] = MM.clamp(self.ballTracker_pos[1], 0, ImageProcessor.detection_image_resolution_cropped[1] - self.ballTracker_size)
        
        self.ballTracker_pos[0] = int(self.ballTracker_pos[0])
        self.ballTracker_pos[1] = int(self.ballTracker_pos[1])
        
        #przygotowanie klatki z kamery do analizy
        tracker_frame = self.frame_original[self.ballTracker_pos[1]:self.ballTracker_pos[1]+self.ballTracker_size,
                                            self.ballTracker_pos[0]:self.ballTracker_pos[0]+self.ballTracker_size]
        tracker_frame = cv2.cvtColor(tracker_frame, cv2.COLOR_BGR2GRAY)
        
        #analiza klatki z uzyciem sieci neuronowych
        result = self.tensorflowProcessor.getBallPosition(tracker_frame)
        result = np.round(result * self.ballTracker_size).astype(""int"")
        
        self.ballTracker_result[0] = self.ballTracker_pos[0] + result[0]
        self.ballTracker_result[1] = self.ballTracker_pos[1] + result[1]
        
        #zaznaczanie wizualne pozycji kulki
        #cv2.circle(self.frame_original, tuple(self.ballTracker_result), 1, (0, 0, 255), -1)
        
        #aktualizacja pozycji trackera
        self.ballTracker_pos[0] = MM.lerp(self.ballTracker_pos[0], self.ballTracker_result[0] - self.ballTracker_size // 2, 0.7)
        self.ballTracker_pos[1] = MM.lerp(self.ballTracker_pos[1], self.ballTracker_result[1] - self.ballTracker_size // 2, 0.7)
    
    #znajduje pozycje krawedzi plyty
    def FindBoardCorners(self):
        corners = np.zeros((4, 2), dtype=np.int32)
        corner_detection_area_pixels = [round(self.corner_detecton_area[0] * self.camera_resolution[0]),
                                       round(self.corner_detecton_area[1] * self.camera_resolution[1]),
                                       round(self.corner_detecton_area[2] * self.camera_resolution[0]),
                                       round(self.corner_detecton_area[3] * self.camera_resolution[1])]
        for i in range(4):
            flipX = False
            flipY = False
            detectionArea = copy.copy(corner_detection_area_pixels)    #domyslnie lewy gorny
            if i == 1 or i == 2:
                detectionArea[0] = self.camera_resolution[0] - detectionArea[0] - detectionArea[2]
                flipX = True
            if i == 3 or i == 2:
                detectionArea[1] = self.camera_resolution[1] - detectionArea[1] - detectionArea[3]
                flipY = True
                
            rect = (detectionArea[0], detectionArea[1], detectionArea[0] + detectionArea[2], detectionArea[1] + detectionArea[3])
            #cv2.rectangle(self.frame_debug, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 1);
        
            img = self.frame_original[rect[1]:rect[3], rect[0]:rect[2]]
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            img = cv2.resize(img, (30, 30), interpolation=cv2.INTER_NEAREST)
            
            if flipX and flipY: img = cv2.flip(img, -1)
            elif flipX: img = cv2.flip(img, 1)
            elif flipY: img = cv2.flip(img, 0)
            #cv2.imshow(""Corner "" + str(i), img)
            
            result = self.tensorflowProcessor.getCornerPosition(img)
            
            if flipX: result[0] = 1.0 - result[0]
            if flipY: result[1] = 1.0 - result[1]
            corners[i] = (round(result[0] * detectionArea[2]) + detectionArea[0], round(result[1] * detectionArea[3]) + detectionArea[1])
            #cv2.circle(self.frame_debug, tuple(corners[i]), 1, (0, 0, 255), -1)

        return corners

    #zmienia perspektywe obrazu z kamery tak, aby niewidoczne bylo przechylenie plyty
    def ChangePerspective(self):
        pts = np.array(self.corners, np.float32)
        res = self.detection_image_resolution
        enlarge = 3
        pts2 = np.float32([[enlarge,enlarge],[res[0]-enlarge,enlarge],[res[0]-enlarge, res[1]-enlarge], [enlarge, res[1]-enlarge]])

        M = cv2.getPerspectiveTransform(pts, pts2)
        self.frame_original = cv2.warpPerspective(self.frame_original, M, res)
        
        #zamalowanie bialych pol w rogach plyty
        for x in (0, res[0]):
            for y in (0, res[1]):
                cv2.circle(self.frame_original, (x, y), 10, (0, 0, 0), -1)
        
    #aktualizuje mape przeszkod na plycie
    def UpdateObstacleMap(self):
        self.obstacle_map_update_counter += 1
        if self.obstacle_map_update_counter >= ImageProcessor.obstacle_map_update_delta:
            self.obstacle_map_update_counter = 0
            frame = cv2.resize(self.frame_original, (ImageProcessor.obstacle_map_size, ImageProcessor.obstacle_map_size), interpolation=cv2.INTER_NEAREST)
            frame = np.int32(frame)
            frame = 2 * frame[...,2] - frame[...,1] - frame[...,0]
            np.copyto(self.obstacle_map_np, frame.ravel())
            #self.obstacle_map = frame[...,2].ravel()/n/n/nPythonCode/MathModule.py/n/n#PRZYDATNE FUNKCJE MATEMATYCZNE
import math
import heapq

#zwrca znak liczby
def sign(num):
    if num > 0: return 1.0
    elif num < 0: return -1.0
    return 0.0

#interpolacja liniowa
def lerp(a, b, c):
    return c*b + (1-c) * a

#zwraca dlugosc wektora [x, y] do kwadratu
def sqrMagnitude(x, y=None):
    if y is not None: return x*x + y*y
    return x[0] * x[0] + x[1] * x[1]

#zwraca dlugosc wektora [x, y]
def magnitude(x, y=None):
    if y is not None: return math.sqrt(x*x + y*y)
    return math.sqrt(x[0]*x[0] + x[1]*x[1])

#zwraca odleglosc miedzy punktami A i B
def distance(A, B):
    x = A[0] - B[0]
    y = A[1] - B[1]
    return math.sqrt(x*x + y*y)

#zwraca kwadrat odleglosci miedzy punktami A i B
def sqrDistance(A, B):
    x = A[0] - B[0]
    y = A[1] - B[1]
    return x*x + y*y

#zwraca znormalizowany wektor [x, y]
def normalized(x, y=None):
    if y is not None:
        if x == 0 and y == 0: return (0, 0)
        mag = magnitude(x, y)
        return (x/mag, y/mag)
    else:
        if x[0] == 0 and x[1] == 0: return (0, 0)
        mag = magnitude(x)
        return (x[0]/mag, x[1]/mag)

#zwraca roznice kwadratowa miedzy target a value
def errorsquare(target, value):
    size = len(target)
    sum = 0.0
    for i in range(size):
        a = int(target[i]) - value[i]
        sum += a * a
        
    return sum
        
#zwraca wartosc 'num' ograniczana przez <_min, _max>
def clamp(num, _min, _max):
    if num > _max: return _max
    elif num < _min: return _min
    return num

#kolejka priorytetowa
class PriorityQueue:
    def __init__(self):
        self.elements = []
        
    #dodaje element do kolejki
    def push(self, item, priority):
        heapq.heappush(self.elements, (priority, item))
        
    #zdejmuje i zwraca element z poczatku kolejki
    def pop(self):
        return heapq.heappop(self.elements)[1]
    
    #czy kolejka jest pusta?
    def empty(self):
        return len(self.elements) == 0
        /n/n/nPythonCode/PIDControllerModule.py/n/nimport MathModule as MM

class PIDController:
    
    #operacje zmiany pidow
    def increaseKP(self):
        self.KP += 50
        print(""KP = "" + str(self.KP))
        
    def increaseKI(self):
        self.KI += 50
        print(""KI = "" + str(self.KI))
        
    def increaseKD(self):
        self.KD += 50
        print(""KD = "" + str(self.KD))        
    def decreaseKP(self):
        self.KP -= 50
        print(""KP = "" + str(self.KP))
        
    def decreaseKI(self):
        self.KI -= 50
        print(""KI = "" + str(self.KI))
        
    def decreaseKD(self):
        self.KD -= 50
        print(""KD = "" + str(self.KD))
        
    #ustawia aktualna wartosc
    def setActualValue(self, x, y=None):
        if y is not None:
            self.value_actual[0] = MM.lerp(self.value_actual[0], x, self.value_smoothing)
            self.value_actual[1] = MM.lerp(self.value_actual[1], y, self.value_smoothing)
        else:
            self.value_actual[0] = MM.lerp(self.value_actual[0], x[0], self.value_smoothing)
            self.value_actual[1] = MM.lerp(self.value_actual[1], x[1], self.value_smoothing)
        
    #ustawia docelowa wartosc
    def setTargetValue(self, x, y=None):
        if y is not None:
            self.value_target[0] = x
            self.value_target[1] = y
        else:
            self.value_target[0] = x[0]
            self.value_target[1] = x[1]
    
    def __init__(self):
        self.servo_pos_limit = (1000, 1000)    #ograniczenia wychylen serw (w skali od 0 do 1000)
        self.value_target = [0.5, 0.5]    #docelowa wartosc, ktora ma byc osiagnieta przez kontroler
        self.value_actual = [0.5, 0.5]    #aktualna wartosc
        self.value_smoothing = 1.0       #wspolczynnik wygladzania aktualizacji aktualnej wartosci

        #wspolczynniki kontroli
        self.KP = 1.3 * 1000   #wzmocnienie czesci proporcjonalnej
        self.KI = 0.6 * 1000    #wzmocnienie czesci calkujacej
        self.KD = 0.5 * 1000   #wzmocnienie czesci rozniczkujacej

        #pozycja serwa
        self.x_servo = 0.0
        self.y_servo = 0.0

        #wartosc bledu
        self.x_error = 0.0
        self.y_error = 0.0

        #wartosci poprzednich bledow
        self.x_prev_error = 0.0
        self.y_prev_error = 0.0

        #zmiana bledu w czasie
        self.x_derivative = 0.0
        self.y_derivative = 0.0

        #calkowita suma bledow
        self.x_error_sum = 0.0
        self.y_error_sum = 0.0

    #aktualizuje kontrolea PID
    def update(self, deltaTime):
        #liczenie bledu
        self.x_error = self.value_target[0] - self.value_actual[0]
        self.y_error = self.value_target[1] - self.value_actual[1]
        
        #print(""Error = ( "" + str(self.x_error) + ""; "" + str(self.y_error) + "")"")

        #liczenie pochodnej
        self.x_derivative = (self.x_error - self.x_prev_error) / deltaTime
        self.y_derivative = (self.y_error - self.y_prev_error) / deltaTime

        self.x_prev_error = self.x_error
        self.y_prev_error = self.y_error

        self.x_error_sum += self.x_error * deltaTime
        self.y_error_sum += self.y_error * deltaTime
        
        #zmiana pozycji serw z uwzglednieniem bledu biezacego, przyszlego oraz przeszlego
        self.x_servo = (self.x_error * self.KP) + (self.x_derivative * self.KD) + (self.x_error_sum * self.KI)
        self.y_servo = (self.y_error * self.KP) + (self.y_derivative * self.KD) + (self.y_error_sum * self.KI)
        
        self.x_servo = MM.clamp(self.x_servo, -self.servo_pos_limit[0], self.servo_pos_limit[0])
        self.y_servo = MM.clamp(self.y_servo, -self.servo_pos_limit[1], self.servo_pos_limit[1])
        
        self.x_error_sum = MM.clamp(self.x_error_sum, -1.0, 1.0) * 0.99
        self.y_error_sum = MM.clamp(self.y_error_sum, -1.0, 1.0) * 0.99/n/n/nPythonCode/PathPlannerModule.py/n/nimport cv2
import numpy as np
import MathModule as MM
import time
from multiprocessing import Process, RawValue
from collections import deque
import copy

#program odpowiadajacy za planiwanie sciezki kulki
class PathPlanner:
    
    obstacle_map_size = 40    #rozmiar mapy przeszkod
    obstacle_map_update_delta = 4    #co ile sekund odswiezana ma byc mapa przeszkod?
    path_sub_update_delta = 0.1    #co ile sekund aktualizowac podsciezke?
    
    def __init__(self):
        print(""PathPlanner object created"")
        
        self.obstacle_map = None
        self.path = None
        self_path_last_index = 0
        self.proximity_map = np.zeros((PathPlanner.obstacle_map_size, PathPlanner.obstacle_map_size)) #tablica 2D z kosztem bliskosci wykrytych przeszkod
        
        self.path_position = 0.0   #aktualna pozycja na sciezce
        self.path_speed = 0.25 * PathPlanner.obstacle_map_size    #predkosc przechodzenia sciezki
        self.path_max_dist = 0.1**2 #odleglosc kulki od celu, powyzej ktorej docelowa pozycja ""czeka"" az kulka do niej dotrze
        
        self.ball_pos_x = RawValue('f', 0.5)
        self.ball_pos_y = RawValue('f', 0.5)
        self.target_pos_x = RawValue('f', 0.25)
        self.target_pos_y = RawValue('f', 0.25)
        self.path_x = RawValue('f', 0.5)
        self.path_y = RawValue('f', 0.5)
        
    def setBallPosition(self, pos):
        self.ball_pos_x.value = pos[1]
        self.ball_pos_y.value = pos[0]
        
    def setTargetPosition(self, pos):
        self.target_pos_x.value = pos[1]
        self.target_pos_y.value = pos[0]
        
    def getPathTarget(self):
        return (self.path_x.value, self.path_y.value)
        
    def startProcessing(self, _frame_array):
        print(""Starting PathPlanner process"")
        self.process = Process(target=PathPlanner.doPlanning, args=(self,_frame_array))
        self.process.daemon = True
        self.process.start()
        
    def stopProcessing(self):
        print(""Stopping PathPlanner process"")
        self.process.terminate()
        
    def doPlanning(self, _frame_array):
        obstacle_map_update_time = 0.0
        path_sub_update_time = 0.0
        while True:
            if time.perf_counter() - obstacle_map_update_time >= PathPlanner.obstacle_map_update_delta:
                obstacle_map_update_time = time.perf_counter()
                PathPlanner.updateObstacleMap(self, _frame_array)
                
            if time.perf_counter() - path_sub_update_time >= PathPlanner.path_sub_update_delta:
                path_sub_update_time = time.perf_counter()
                PathPlanner.UpdateSubPath(self)
        
    #aktualizuje bitmape przeszkod
    def updateObstacleMap(self, _frame_array):
        frame = np.frombuffer(_frame_array, dtype=np.int32)
        frame = np.clip(frame, 0, 255).astype('uint8').reshape((PathPlanner.obstacle_map_size, PathPlanner.obstacle_map_size))
        #cv2.imshow(""Map"", frame)
        frame = cv2.inRange(frame, 80, 255)
        #kernel = np.ones((2,2), np.uint8)
        #frame = cv2.dilate(frame, kernel, iterations=1)
        self.obstacle_map = frame
        
        #aktualizacja mapy bliskosci przeszkod
        self.proximity_map.fill(0)
        size = PathPlanner.obstacle_map_size - 1
        sides = ((1, 0), (1, -1), (0, -1), (-1, -1), (-1, 0), (-1, 1), (0, 1), (1, 1))
        for x in range(1, size):
            for y in range(1, size):
                if frame[x, y] > 0:
                    for side in sides:
                        self.proximity_map[x + side[0], y + side[1]] += 1
        
        #np.clip(self.proximity_map, 0, 1, self.proximity_map)
        self.proximity_map *= 5000
        
        #aktualizacja glownej sciezki
        start = PathPlanner.FromUnitaryToMapSpace((self.ball_pos_x.value, self.ball_pos_y.value), self.obstacle_map_size)
        end = PathPlanner.FromUnitaryToMapSpace((self.target_pos_x.value, self.target_pos_y.value), self.obstacle_map_size)
        self.path = PathPlanner.a_star(self, start, end)
        
        self.path_last_index = len(self.path)-1
        self.path_position = 0.0
        
    #aktualizuje podsciezke przy uzyciu algorytmu A*
    def UpdateSubPath(self):
        if self.path == None: return None
        
        ball_pos = (self.ball_pos_x.value, self.ball_pos_y.value)
        path = self.path
        
        index = int(self.path_position)
        A = PathPlanner.FromMapToUnitarySpace(path[index])
        
        #DEBUG
        frame = copy.copy(self.obstacle_map)
        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
        for p in path:
            if PathPlanner.isPointWithinMap(self, p):
                frame[p[0], p[1]] = [255, 255, 0]
        
        if self.path_last_index > 0:
            B = PathPlanner.FromMapToUnitarySpace(path[index+1])
            dist = MM.distance(A, B)
            mant = self.path_position - index
            
            target_y = MM.lerp(A[0], B[0], mant)
            target_x = MM.lerp(A[1], B[1], mant)
            
            PathPlanner.PaintRay(self, PathPlanner.FromUnitaryToMapSpace(ball_pos, self.obstacle_map_size), path[index+1], frame)
            if not PathPlanner.Raycast(self, PathPlanner.FromUnitaryToMapSpace(ball_pos, self.obstacle_map_size), path[index+1]) and MM.sqrMagnitude(target_x - ball_pos[1], target_y - ball_pos[0]) <= self.path_max_dist:
                self.path_position += self.path_speed * PathPlanner.path_sub_update_delta / (dist * PathPlanner.obstacle_map_size)
            if self.path_position >= self.path_last_index: self.path_position = self.path_last_index - 0.00001
            
        else:
            target_y = A[0]
            target_x = A[1]
            
        #print(target_x)
        #print(target_y)
        #print("""")
        
        self.path_x.value = target_x
        self.path_y.value = target_y
            
        frame = cv2.resize(frame, (200, 200), interpolation=cv2.INTER_NEAREST)
        
        cv2.imshow(""PathPlanner frame"", frame)
        key = cv2.waitKey(1) & 0xFF
        
    #zmienia uklad odniesienia z mapy przeszkod na jednostkowy
    def FromMapToUnitarySpace(point):
        return (point[0] / PathPlanner.obstacle_map_size, point[1] / PathPlanner.obstacle_map_size)
    
    #zmienia uklad odniesienia z jednostkowego na mape przeszkod
    def FromUnitaryToMapSpace(point, size):
        return (round(point[0] * size), round(point[1] * size))
        
    #sprawdza, czy punkt wewnatrz mapy przeszkod
    def isPointWithinMap(self, point):
        size = self.obstacle_map_size
        return point[0] >= 0 and point[0] < size and point[1] >= 0 and point[1] < size
        
    #algorytm A* wyznaczajacy sciezke z punktu A do B
    def a_star(self, A, B):
        start = B
        end = A
        movement = ((1, 0), (-1, 0), (0, 1), (0, -1))
        #movement = ((1, 0), (-1, 0), (0, 1), (0, -1), (-1, -1), (-1, 1), (1, 1), (1, -1))
        
        que = MM.PriorityQueue()
        que.push(start, 0)
        
        visited_from = {}
        cost = {}
        
        visited_from[start] = None
        visited_from[end] = None
        cost[start] = 0
        
        #timeStart = time.perf_counter()
        while not que.empty():
            v = que.pop()
            if v == end: break
            
            new_cost = cost[v] + 1
            for move in movement:
                nx = v[0] + move[0]
                ny = v[1] + move[1]
                
                if PathPlanner.isPointWithinMap(self, (nx, ny)) and self.obstacle_map[nx, ny] == 0:
                    u = (nx, ny)
                    if u not in cost or new_cost < cost[u]:
                        cost[u] = new_cost
                        center = PathPlanner.obstacle_map_size // 2
                        que.push(u, new_cost + MM.sqrMagnitude(v[0] - u[0], v[1] - u[1]) + self.proximity_map[u[0], u[1]] + int(MM.sqrMagnitude(center - u[0], center - u[1])))
                        visited_from[u] = v
        
        path = []
        if visited_from[end] != None:
            v = end
            while v != start:
                path.append(v)
                v = visited_from[v]
            path.append(start)
        else:
            time.sleep(0.05)
            path.append(end)
        
        return path
    
    #sprawdza, czy promien przecina pole, na ktorym znajduje sie przeszkoda
    def Raycast(self, origin, end):
        obstacle_map = self.obstacle_map
        if not PathPlanner.isPointWithinMap(self, origin) or not PathPlanner.isPointWithinMap(self, end): return False    #jesli punkt startowy jest poza mapa
        if origin == end: return obstacle_map[origin[0], origin[1]]    #jesli promien jest punktem
        
        vec = (end[0] - origin[0], end[1] - origin[1])
        flipped = False    #czy wspolrzedne w ukladzie sa zamienione miejscami? (x; y) -> (y; x)
        if abs(vec[1]) > abs(vec[0]):
            #jesli nachylenie wektora jest wieksze niz 45 stopni
            #uklad wspolrzednych 'obracany jest' o 90 stopni
            vec = (vec[1], vec[0])
            origin = (origin[1], origin[0])
            end = (end[1], end[0])
            flipped = True
        
        dir = vec[1]/vec[0] #wspolczynnik kierunkowy promienia
        offset = origin[1] - dir * origin[0]    #skladnik 'b' w funkcji y = dir*x + b; przechodzi ona przez 'origin'
        
        #znaleznienie najbardziej lewego i prawego punktu promienia
        if origin[0] >= end[0]:
            left = end[0]
            right = origin[0]
        else:
            left = origin[0]
            right = end[0]
            
        #przejscie po wszystkich punktach mapy przeszkod nalezacych do promienia i sprawdzenie, czy ktorys z nich jest przeszkada
        if not flipped:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                #print(""Checked ("" + str(x) + "", "" + str(y) + "")"") 
                if obstacle_map[x, y] > 0:
                    return True
        else:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                #print(""Checked ("" + str(y) + "", "" + str(x) + "")"") 
                if obstacle_map[y, x] > 0:
                    return True
                
        return False
    
    #DEBUG
    def PaintRay(self, origin, end, frame):
        obstacle_map = self.obstacle_map
        if not PathPlanner.isPointWithinMap(self, origin) or not PathPlanner.isPointWithinMap(self, end): return    #jesli punkt startowy jest poza mapa
        if origin == end:
            frame[origin[0], origin[1]] = [0, 255, 0]
            return
            
        
        vec = (end[0] - origin[0], end[1] - origin[1])
        flipped = False    #czy wspolrzedne w ukladzie sa zamienione miejscami? (x; y) -> (y; x)
        if abs(vec[1]) > abs(vec[0]):
            #jesli nachylenie wektora jest wieksze niz 45 stopni
            #uklad wspolrzednych 'obracany jest' o 90 stopni
            vec = (vec[1], vec[0])
            origin = (origin[1], origin[0])
            end = (end[1], end[0])
            flipped = True
        
        dir = vec[1]/vec[0] #wspolczynnik kierunkowy promienia
        offset = origin[1] - dir * origin[0]    #skladnik 'b' w funkcji y = dir*x + b; przechodzi ona przez 'origin'
        
        #znaleznienie najbardziej lewego i prawego punktu promienia
        if origin[0] >= end[0]:
            left = end[0]
            right = origin[0]
        else:
            left = origin[0]
            right = end[0]
            
        #przejscie po wszystkich punktach mapy przeszkod nalezacych do promienia i sprawdzenie, czy ktorys z nich jest przeszkada
        if not flipped:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                frame[x, y] = [0, 255, 0]
        else:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                frame[y, x] = [0, 255, 0]/n/n/nPythonCode/ServoControllerModule.py/n/nfrom __future__ import division
simulationMode = False

if not simulationMode:
    import sys
    sys.path.append('/home/pi/Adafruit_Python_PCA9685/')
    import Adafruit_PCA9685
    
import math
import MathModule as MM

#program kontrolujacy ruch serw
class ServoController:
    
    #parametry serw
    servo_pulse_neutral = (388, 379)    #wartosci pwm dla pozycji neutralnych serw
    servo_pulse_range = (100, 100)      #zakres wartosci sygnalu pwm dla ruchu serw
    servo_pos_limit = (800, 800)    #ograniczenia wychylen serw (w skali od 0 do 1000)
    servo_movement_speed = (6000, 6000)    #szybkosci ruchu serw
    
    def __init__(self):
        if not simulationMode:
            self.pwm = Adafruit_PCA9685.PCA9685()  #laczenie sie z plytka sterujaca serwami
            self.pwm.set_pwm_freq(60)
        
        #zmienne wartosci
        self.servo_actual_pos = [0, 0]    #aktualna pozycja serwa
        self.servo_target_pos = [0, 0]    #docelowa pozycja serwa
        
        self.update(0)   #aplikowanie domyslnych ustawien serw

    #wydaje polecenie poruszenia serwem na kanale 'channel' na pozycje 'pos' (w skali od -1000 do 1000)
    def moveServo(self, channel, pos):
        self.servo_target_pos[channel] = MM.clamp(pos, -ServoController.servo_pos_limit[channel], ServoController.servo_pos_limit[channel])

    #aktualizuje pozycje serw
    def update(self, deltaTime):
        for i in range(2): #tylko 2 serwa
            
            movement_dir = MM.sign(self.servo_target_pos[i] - self.servo_actual_pos[i])
            self.servo_actual_pos[i] += ServoController.servo_movement_speed[i] * movement_dir * deltaTime
            
            if movement_dir > 0: self.servo_actual_pos[i] = min(self.servo_actual_pos[i], self.servo_target_pos[i])
            elif movement_dir < 0: self.servo_actual_pos[i] = max(self.servo_actual_pos[i], self.servo_target_pos[i])
                
            if not simulationMode:
                pos = round(ServoController.servo_pulse_neutral[i] + ServoController.servo_pulse_range[i] * self.servo_actual_pos[i] / 1000)
                self.pwm.set_pwm(i, 0, pos)
            else:
                self.servo_actual_pos[i] = round(self.servo_actual_pos[i])
/n/n/nPythonCode/TensorflowProcessingModule.py/n/nimport numpy as np

print(""Importing Tensorflow libraries"")
from tensorflow.contrib.lite.python import interpreter as interpreter_wrapper
import tensorflow as tf

#klasa z funkcjami do przetwarzania danych sieciami neuronowymi z Tensorflow
class TensorflowProcessor:
    
    #sciezka do uzywanego modelu
    ball_detector_model_path = ""/home/pi/ballance/Ballance/Tensorflow/ballancenet_conv_3_quant.tflite""
    corner_detector_model_path = ""/home/pi/ballance/Ballance/Tensorflow/ballancenet_boardcorner_conv_2.5_quant.tflite""
    
    #funkcja generujaca zoptymalizowany model
    def QuantizeModel(model_path, output_file_name):
        print(""Quantizing model"")
        converter = tf.contrib.lite.TocoConverter.from_saved_model(model_path)
        converter.post_training_quantize = True
        quant_model = converter.convert()
        open(output_file_name + "".tflite"", ""wb"").write(quant_model)
        
    def __init__(self):
        print(""Creating TensorflowProcessor object"")
        #wczytywanie modelu do wykrywania kulki
        print(""Loading ball detection tflite model"")
        self.ball_detector_interpreter = interpreter_wrapper.Interpreter(model_path=TensorflowProcessor.ball_detector_model_path)
        self.ball_detector_interpreter.allocate_tensors()
        self.ball_detector_input_details = self.ball_detector_interpreter.get_input_details()
        self.ball_detector_output_details = self.ball_detector_interpreter.get_output_details()
        
        #wczytywanie modelu do wykrywania krawedzi plyty
        print(""Loading corner detection tflite model"")
        self.corner_detector_interpreter = interpreter_wrapper.Interpreter(model_path=TensorflowProcessor.corner_detector_model_path)
        self.corner_detector_interpreter.allocate_tensors()
        self.corner_detector_input_details = self.corner_detector_interpreter.get_input_details()
        self.corner_detector_output_details = self.corner_detector_interpreter.get_output_details()
        
        print(""TensorflowProcessor object created"")
        
    def getBallPosition(self, image):
        #przygotowanie obrazu
        image = np.float32(image)
        image /= 255.0
        image = np.expand_dims(image, axis=0)
        image = np.expand_dims(image, axis=3)
        
        #wykonanie interpretacji
        self.ball_detector_interpreter.set_tensor(self.ball_detector_input_details[0]['index'], image)
        self.ball_detector_interpreter.invoke()
        
        return np.squeeze(self.ball_detector_interpreter.get_tensor(self.ball_detector_output_details[0]['index']))
    
    def getCornerPosition(self, image):
        #przygotowanie obrazu
        image = np.float32(image)
        image /= 255.0
        image = np.expand_dims(image, axis=0)
        image = np.expand_dims(image, axis=3)
        
        #wykonanie interpretacji
        self.corner_detector_interpreter.set_tensor(self.corner_detector_input_details[0]['index'], image)
        self.corner_detector_interpreter.invoke()
        
        return np.squeeze(self.corner_detector_interpreter.get_tensor(self.corner_detector_output_details[0]['index']))/n/n/nPythonCode/test.py/n/nimport TensorflowProcessingModule as TPM

TPM.TensorflowProcessor.QuantizeModel(""/home/pi/ballance/ballance_net/ballancenet_boardcorner_conv2.5"", ""ballancenet_boardcorner_conv_2.5_quant"")/n/n/n",0
143,143,da22d46baf8362ce33dd89c8d5ac834632fc4e0f,"/PythonCode/Ballance.py/n/nif __name__ == '__main__':
    simulationMode = True    #czy uruchomic program w trybie symulacji? wymaga rowniez zmiany w ServoControllerModule.py oraz w ImageProcessingModule.py

    import ImageProcessingModule as IPM
    import ServoControllerModule as SCM
    import PIDControllerModule as PIDCM
    import DataLoggerModule as DLM
    import PathPlannerModule as PPM
    
    from time import sleep
    import time
    import pygame
    import math
    import MathModule as MM

    #wykonanie wstepnych czynnosci
    if simulationMode:
        import SimulationCommunicatorModule as SimCM
        simulationCommunicator = SimCM.SimulationCommunicator()
    else: simulationCommunicator = None
    
    imageProcessor = IPM.ImageProcessor(simulationCommunicator)
    servoController = SCM.ServoController()
    pathPlanner = PPM.PathPlanner()
        
    dataLogger = DLM.DataLogger()
    pidController = PIDCM.PIDController()
    pidController.servo_pos_limit = servoController.servo_pos_limit

    pygame.init()
    pygame.display.set_mode((100, 100))

    #roizpoczynanie procesu wykrywania kulki
    if simulationMode: simulationCommunicator.StartProcessing()
    imageProcessor.StartProcessing()
    pathPlanner.startProcessing(imageProcessor.obstacle_map)

    targetDeltaTime = 1.0 / 40.0    #czas jednej iteracji programu sterujacego
    updatedTime = 0.0
    servoUpdateDeltaTime = 1.0 / 60 #czas odswiezania pozycji serw
    servoUpdatedTime = 0.0

    ball_position_actual = (0.0, 0.0)
    ball_position_previous = (0.0, 0.0)

    #parametry trajektorii kulki
    angle = 0.0
    angleSpeed = 0.9
    angleRadius = 0.25
    angleRadiusFactor = 0.0
    path_targets = [(0.18, 0.18), (0.82, 0.82)]
    path_target_index = 0
    targetPos = path_targets[path_target_index]
    moveSpeed = 0.05
    movementMode = 0
    modeChangeTimeDelta = 25 #czas po jakim zmieniana jest trajektoria kulki
    modeChangeTimer = 0.0

    #jak dlugo wykonywany ma byc program
    duration = 10000
    timeout = time.time() + duration
    ball_just_found = True    #czy kulka dopiero zostala znaleziona i nalezy zresetowac predkosc?

    #glowna petla programu
    while time.time() <= timeout:
        timeStart = time.perf_counter()
        
        #oczekiwanie na odpowiedni moment do wykonania programu sterujacego
        if timeStart - updatedTime >= targetDeltaTime:
            updatedTime = time.perf_counter()
            
            #pobranie pozycji kulki
            ball_position_actual = imageProcessor.getBallPosition()
            if ball_position_actual[0] >= 0: pidController.setActualValue(ball_position_actual)
            else: pidController.setActualValue(pidController.value_target)
                
            #aktualizacja kontrolera PID
            pidController.update(targetDeltaTime)
            ball_position_previous = ball_position_actual
            
            #aktualizacja pozycji kulki w pathplannerze
            pathPlanner.setBallPosition(ball_position_actual)
            pidController.setTargetValue(pathPlanner.getPathTarget())
            
            #przechodzenie do kolejnego waypoint'a
            if MM.sqrMagnitude(ball_position_actual[0] - targetPos[0], ball_position_actual[1] - targetPos[1]) < 0.01:
                path_target_index = (path_target_index + 1) % len(path_targets)
                targetPos = path_targets[path_target_index]
                pathPlanner.setTargetPosition(targetPos)
            #print(str(pidController.value_target))
            
            #obslugiwanie wejscia z klawiatury
            killLoop = False
            for event in pygame.event.get():
                if event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_g:
                        pidController.increaseKP()
                        
                    elif event.key == pygame.K_b:
                        pidController.decreaseKP()
                        
                    elif event.key == pygame.K_h:
                        pidController.increaseKI()
                        
                    elif event.key == pygame.K_n:
                        pidController.decreaseKI()
                        
                    elif event.key == pygame.K_j:
                        pidController.increaseKD()
                        
                    elif event.key == pygame.K_m:
                        pidController.decreaseKD()
                        
                    elif event.key == pygame.K_q:
                        killLoop = True
                        
                    elif event.key == pygame.K_UP:
                        targetPos[1] -= moveSpeed
                        
                    elif event.key == pygame.K_DOWN:
                        targetPos[1] += moveSpeed
                        
                    elif event.key == pygame.K_RIGHT:
                        targetPos[0] += moveSpeed
                        
                    elif event.key == pygame.K_LEFT:
                        targetPos[0] -= moveSpeed
                        
                    elif event.key == pygame.K_p:
                        angleSpeed += 0.1
                        print(""angleSpeed = "" + str(angleSpeed))
                        
                    elif event.key == pygame.K_o:
                        angleSpeed -= 0.1
                        print(""angleSpeed = "" + str(angleSpeed))
                        
            if killLoop:
                break
            
            #ustawianie nowych pozycji serw
            servoController.moveServo(0, round(pidController.x_servo))
            servoController.moveServo(1, -round(pidController.y_servo))
            
            #dostepne trajektorie ruchu kulki
            if False:
                if movementMode == 0:    #ksztalt osemki
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.sin(2.0 * angle)
                elif movementMode == 1:  #ksztalt okregu
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.cos(angle)
                elif movementMode == 2:   #ksztalt paraboli
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.cos(2.0 * angle)
                elif movementMode == 3:   #ksztalt litery S
                    targetPos[0] = math.sin(angle)
                    targetPos[1] = math.sin(2.0 * angle)
                    if angle > 2:
                        angleSpeed = -angleSpeed
                        angle = 2
                    elif angle < -2:
                        angleSpeed = -angleSpeed
                        angle = -2
                    
            #targetPos[0] = 0.5 + angleRadiusFactor * angleRadius * targetPos[0]
            #targetPos[1] = 0.5 + angleRadiusFactor * angleRadius * targetPos[1]
            #ustawianie docelowej pozycji kulki
            #pidController.setTargetValue(targetPos[0], targetPos[1])
            #pathPlanner.setTargetPosition(tuple(targetPos))
            angle += angleSpeed * targetDeltaTime
            angleRadiusFactor += 0.25 * targetDeltaTime
            angleRadiusFactor = min(angleRadiusFactor, 1.0)
            
            modeChangeTimer += targetDeltaTime
            if modeChangeTimer >= modeChangeTimeDelta:
                modeChangeTimer = 0.0
                angleRadiusFactor = 0.0
                movementMode += 1
                movementMode = movementMode % 4
            
            #dodawanie wpisow do DataLog'u
            if False:
                path_target = pathPlanner.getPathTarget()
                dataLogger.addRecord(""timestamp"", time.perf_counter())
                dataLogger.addRecord(""ball_pos_x"", ball_position_actual[0])
                dataLogger.addRecord(""ball_pos_y"", ball_position_actual[1])
                dataLogger.addRecord(""target_pos_x"", path_target[0])
                dataLogger.addRecord(""target_pos_y"", path_target[1])
                dataLogger.addRecord(""KP"", pidController.KP)
                dataLogger.addRecord(""KI"", pidController.KI)
                dataLogger.addRecord(""KD"", pidController.KD)
                dataLogger.addRecord(""error_x"", pidController.x_error)
                dataLogger.addRecord(""error_y"", pidController.y_error)
                dataLogger.addRecord(""error_prev_x"", pidController.x_prev_error)
                dataLogger.addRecord(""error_prev_y"", pidController.y_prev_error)
                dataLogger.addRecord(""error_sum_x"", pidController.x_error_sum)
                dataLogger.addRecord(""error_sum_y"", pidController.y_error_sum)
                dataLogger.addRecord(""derivative_x"", pidController.x_derivative)
                dataLogger.addRecord(""derivative_y"", pidController.y_derivative)
                dataLogger.addRecord(""servo_actual_x"", servoController.servo_actual_pos[0])
                dataLogger.addRecord(""servo_actual_y"", servoController.servo_actual_pos[1])
                dataLogger.addRecord(""servo_target_x"", servoController.servo_target_pos[0])
                dataLogger.addRecord(""servo_target_y"", servoController.servo_target_pos[1])
                dataLogger.saveRecord()
            
        #oczekiwanie na odpowiedni moment do aktualizacji serw
        if time.perf_counter() - servoUpdatedTime >= servoUpdateDeltaTime:
            servoController.update(time.perf_counter() - servoUpdatedTime)
            servoUpdatedTime = time.perf_counter()
            
            if simulationMode:
                simulationCommunicator.moveServos(servoController.servo_actual_pos)
                
        sleep(0.004) #4 milisekundy na odpoczynek :)
            
    print(""Stopping program"")
    #dataLogger.saveToFile(""BallanceDataLog"")
    if simulationMode: simulationCommunicator.StopProcessing()
    else: imageProcessor.StopProcessing()
    pathPlanner.stopProcessing()/n/n/n/PythonCode/ImageProcessingModule.py/n/nsimulationMode = True

if not simulationMode:
    import TensorflowProcessingModule as TPM
    from imutils.video.pivideostream import PiVideoStream

import MathModule as MM
import math, time, copy
import cv2
import numpy as np
from multiprocessing import Process, RawValue, RawArray
 
#program sluzacy do analizy obrazu z kamery, wykrywania kulki
class ImageProcessor:
    
    #parametry kamery
    camera_resolution = (256, 256)
    camera_framerate = 40
    
    corner_detecton_area = (0.08, 0.08, 0.14, 0.14) #prostakat, w ktorym szukana jest krawedz plyty, jest on powielany dla kazdego rogu obrazu
    detection_image_resolution = (200, 200)
    detection_image_resolution_cropped = (-1, -1)
    
    #rozmiar bitmapy przeszkod
    obstacle_map_size = 40
    obstacle_map_update_delta = 40
        
    def __init__(self, _simulationCommunicator=None):
        print(""ImageProcessor object created"")
        self.simulationCommunicator = _simulationCommunicator
        #wartosci-rezultaty przetwarzania obrazu
        self.result_x = RawValue('f', 0.0)
        self.result_y = RawValue('f', 0.0)
        self.key = RawValue('i', 0)
        
        self.obstacle_map = RawArray('i', ImageProcessor.obstacle_map_size**2)
        self.obstacle_map_update_counter = 0
        
    def getBallPosition(self):    #zwraca pozycje kulki
        if simulationMode: return self.simulationCommunicator.getBallPosition()
        return (self.result_x.value, self.result_y.value)
        
    def StartProcessing(self):   #uruchamia proces przetwarzajacy obraz
        print(""Starting image processing"")
        
        self.process = Process(target=ImageProcessor.ProcessImage, args=(self,))
        self.process.daemon = True
        self.process.start()
        #ImageProcessor.ProcessImage(self)
        
    def StopProcessing(self):    #wydaje polecenie do zatrzymania przetwarzania obrazu
        print(""Stopping image processing"")
        self.key.value = -666
        self.process.terminate()
        
    def ProcessImage(self):    #przetwarza obraz pobierajac klatke z kamery i wykonujac na niej operacje analizy
        
        #bufor dzielenia mapy przeszkod z innymi procesami
        self.obstacle_map_np = np.frombuffer(self.obstacle_map, dtype=np.int32).reshape(ImageProcessor.obstacle_map_size**2)
        
        #parametry trackera kulki
        self.ballTracker_pos = [ImageProcessor.detection_image_resolution[0]//2, ImageProcessor.detection_image_resolution[1]//2]
        self.ballTracker_size = 40
        self.ballTracker_result = [0, 0]
        
        if not simulationMode:
            self.tensorflowProcessor = TPM.TensorflowProcessor()
            videoStream = PiVideoStream(resolution=ImageProcessor.camera_resolution, framerate=ImageProcessor.camera_framerate).start()   #uruchamianie watku, ktory czyta kolejne klatki z kamery
        else:
            videoStream = self.simulationCommunicator
        
        time.sleep(1)
        self.frame_original = videoStream.read()
        
        lastTime = time.time()
        a = 190
        lastID = 0
        
        saveCounter = 0
        saveCount = 0
        
        while True:
            if self.key.value == -666: break
            
            #prosty licznik przetworzonych klatek w ciagu sekundy
            a = a + 1
            if a > 200:
                if ImageProcessor.detection_image_resolution_cropped[0] == -1:
                    ImageProcessor.detection_image_resolution_cropped = (np.size(self.frame_original, 0), np.size(self.frame_original, 1))
                print(str(a * 1.0 / (time.time() - lastTime)))
                lastTime = time.time()
                a = 0
            
            #synchronizacja pobierania nowej klatki z czestotliwascia kamery
            while True:
                frameGrabbed = videoStream.read()
                ID = id(frameGrabbed)
                if ID != lastID:
                    self.frame_original = frameGrabbed
                    lastID = ID
                    break
                elif not simulationMode:
                    time.sleep(0.01)
            
            #klatka przeznaczona do debugowania
            #self.frame_debug = copy.copy(self.frame_original)
            
            if not simulationMode: self.corners = ImageProcessor.FindBoardCorners(self)    #znajdowanie pozycji rogow plyty
            else: self.corners = self.simulationCommunicator.FindBoardCorners()
            ImageProcessor.ChangePerspective(self)    #zmiana perspektywy znalezionej tablicy, aby wygladala jak kwadrat
            #self.frame_original = self.frame_original[1:200, 1:200] #przycinanie zdjecia
            if not simulationMode: ImageProcessor.UpdateBallTracker(self)    #aktualizacja trackera kulki
            else:
                pos = self.simulationCommunicator.getBallPosition()
                self.ballTracker_result[0] = pos[0] * ImageProcessor.detection_image_resolution_cropped[0]
                self.ballTracker_result[1] = pos[1] * ImageProcessor.detection_image_resolution_cropped[1]
            ImageProcessor.UpdateObstacleMap(self)
            
            #ustawianie znalezionej pozycji kulki w zmiennych dzielonych miedzy procesami
            self.result_x.value = self.ballTracker_result[0] / ImageProcessor.detection_image_resolution_cropped[0]
            self.result_y.value = self.ballTracker_result[1] / ImageProcessor.detection_image_resolution_cropped[1]
            
            #cv2.imshow(""Frame debug"", self.frame_debug)
            if saveCounter < saveCount:
                cv2.imwrite(""Frame"" + str(saveCounter) + "".png"", self.frame_original)
                saveCounter += 1
                
            #cv2.imshow(""Frame Casted"", self.frame_original)
            #key = cv2.waitKey(1) & 0xFF
            #if key == ord(""q""):
            #    break
            
        videoStream.stop()
            
    #aktualizuje tracker kulki
    def UpdateBallTracker(self):
        self.ballTracker_pos[0] = MM.clamp(self.ballTracker_pos[0], 0, ImageProcessor.detection_image_resolution_cropped[0] - self.ballTracker_size)
        self.ballTracker_pos[1] = MM.clamp(self.ballTracker_pos[1], 0, ImageProcessor.detection_image_resolution_cropped[1] - self.ballTracker_size)
        
        self.ballTracker_pos[0] = int(self.ballTracker_pos[0])
        self.ballTracker_pos[1] = int(self.ballTracker_pos[1])
        
        #przygotowanie klatki z kamery do analizy
        tracker_frame = self.frame_original[self.ballTracker_pos[1]:self.ballTracker_pos[1]+self.ballTracker_size,
                                            self.ballTracker_pos[0]:self.ballTracker_pos[0]+self.ballTracker_size]
        tracker_frame = cv2.cvtColor(tracker_frame, cv2.COLOR_BGR2GRAY)
        
        #analiza klatki z uzyciem sieci neuronowych
        result = self.tensorflowProcessor.getBallPosition(tracker_frame)
        result = np.round(result * self.ballTracker_size).astype(""int"")
        
        self.ballTracker_result[0] = self.ballTracker_pos[0] + result[0]
        self.ballTracker_result[1] = self.ballTracker_pos[1] + result[1]
        
        #zaznaczanie wizualne pozycji kulki
        cv2.circle(self.frame_original, tuple(self.ballTracker_result), 1, (0, 0, 255), -1)
        
        #aktualizacja pozycji trackera
        self.ballTracker_pos[0] = MM.lerp(self.ballTracker_pos[0], self.ballTracker_result[0] - self.ballTracker_size // 2, 0.7)
        self.ballTracker_pos[1] = MM.lerp(self.ballTracker_pos[1], self.ballTracker_result[1] - self.ballTracker_size // 2, 0.7)
    
    #znajduje pozycje krawedzi plyty
    def FindBoardCorners(self):
        corners = np.zeros((4, 2), dtype=np.int32)
        corner_detection_area_pixels = [round(self.corner_detecton_area[0] * self.camera_resolution[0]),
                                       round(self.corner_detecton_area[1] * self.camera_resolution[1]),
                                       round(self.corner_detecton_area[2] * self.camera_resolution[0]),
                                       round(self.corner_detecton_area[3] * self.camera_resolution[1])]
        for i in range(4):
            flipX = False
            flipY = False
            detectionArea = copy.copy(corner_detection_area_pixels)    #domyslnie lewy gorny
            if i == 1 or i == 2:
                detectionArea[0] = self.camera_resolution[0] - detectionArea[0] - detectionArea[2]
                flipX = True
            if i == 3 or i == 2:
                detectionArea[1] = self.camera_resolution[1] - detectionArea[1] - detectionArea[3]
                flipY = True
                
            rect = (detectionArea[0], detectionArea[1], detectionArea[0] + detectionArea[2], detectionArea[1] + detectionArea[3])
            #cv2.rectangle(self.frame_debug, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 1);
        
            img = self.frame_original[rect[1]:rect[3], rect[0]:rect[2]]
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            img = cv2.resize(img, (40, 40), interpolation=cv2.INTER_NEAREST)
            
            if flipX and flipY: img = cv2.flip(img, -1)
            elif flipX: img = cv2.flip(img, 1)
            elif flipY: img = cv2.flip(img, 0)
            #cv2.imshow(""Corner "" + str(i), img)
            
            result = self.tensorflowProcessor.getCornerPosition(img)
            corner = np.round(result * 40.0).astype(""int"")
            
            if flipX and flipY: corners[i] = (40 - corner[0] + detectionArea[0], 40 - corner[1] + detectionArea[1])
            elif flipX: corners[i] = (40 - corner[0] + detectionArea[0], corner[1] + detectionArea[1])
            elif flipY: corners[i] = (corner[0] + detectionArea[0], 40 - corner[1] + detectionArea[1])
            else: corners[i] = (corner[0] + detectionArea[0], corner[1] + detectionArea[1])
            #cv2.circle(self.frame_debug, corners[i], 1, (0, 0, 255), 1)

        return corners

    #zmienia perspektywe obrazu z kamery tak, aby niewidoczne bylo przechylenie plyty
    def ChangePerspective(self):
        pts = np.array(self.corners, np.float32)
        res = self.detection_image_resolution
        pts2 = np.float32([[0,0],[res[0],0],[res[0], res[1]], [0, res[1]]])

        M = cv2.getPerspectiveTransform(pts, pts2)
        self.frame_original = cv2.warpPerspective(self.frame_original, M, res)
        
    #aktualizuje mape przeszkod na plycie
    def UpdateObstacleMap(self):
        self.obstacle_map_update_counter += 1
        if self.obstacle_map_update_counter >= ImageProcessor.obstacle_map_update_delta:
            self.obstacle_map_update_counter = 0
            frame = cv2.resize(self.frame_original, (ImageProcessor.obstacle_map_size, ImageProcessor.obstacle_map_size), interpolation=cv2.INTER_NEAREST)
            frame = np.int32(frame)
            frame = 2 * frame[...,2] - frame[...,1] - frame[...,0]
            np.copyto(self.obstacle_map_np, frame.ravel())
            #self.obstacle_map = frame[...,2].ravel()/n/n/n/PythonCode/PIDControllerModule.py/n/nimport MathModule as MM

class PIDController:
    
    #operacje zmiany pidow
    def increaseKP(self):
        self.KP += 50
        print(""KP = "" + str(self.KP))
        
    def increaseKI(self):
        self.KI += 50
        print(""KI = "" + str(self.KI))
        
    def increaseKD(self):
        self.KD += 50
        print(""KD = "" + str(self.KD))
        
    def decreaseKP(self):
        self.KP -= 50
        print(""KP = "" + str(self.KP))
        
    def decreaseKI(self):
        self.KI -= 50
        print(""KI = "" + str(self.KI))
        
    def decreaseKD(self):
        self.KD -= 50
        print(""KD = "" + str(self.KD))
        
    #ustawia aktualna wartosc
    def setActualValue(self, x, y=None):
        if y is not None:
            self.value_actual[0] = MM.lerp(self.value_actual[0], x, self.value_smoothing)
            self.value_actual[1] = MM.lerp(self.value_actual[1], y, self.value_smoothing)
        else:
            self.value_actual[0] = MM.lerp(self.value_actual[0], x[0], self.value_smoothing)
            self.value_actual[1] = MM.lerp(self.value_actual[1], x[1], self.value_smoothing)
        
    #ustawia docelowa wartosc
    def setTargetValue(self, x, y=None):
        if y is not None:
            self.value_target[0] = x
            self.value_target[1] = y
        else:
            self.value_target[0] = x[0]
            self.value_target[1] = x[1]
    
    def __init__(self):
        self.servo_pos_limit = (1000, 1000)    #ograniczenia wychylen serw (w skali od 0 do 1000)
        self.value_target = [0.5, 0.5]    #docelowa wartosc, ktora ma byc osiagnieta przez kontroler
        self.value_actual = [0.5, 0.5]    #aktualna wartosc
        self.value_smoothing = 1.0       #wspolczynnik wygladzania aktualizacji aktualnej wartosci

        #wspolczynniki kontroli
        self.KP = 1.3 * 1000   #wzmocnienie czesci proporcjonalnej
        self.KI = 0.6 * 1000    #wzmocnienie czesci calkujacej
        self.KD = 0.5 * 1000   #wzmocnienie czesci rozniczkujacej

        #pozycja serwa
        self.x_servo = 0.0
        self.y_servo = 0.0

        #wartosc bledu
        self.x_error = 0.0
        self.y_error = 0.0

        #wartosci poprzednich bledow
        self.x_prev_error = 0.0
        self.y_prev_error = 0.0

        #zmiana bledu w czasie
        self.x_derivative = 0.0
        self.y_derivative = 0.0

        #calkowita suma bledow
        self.x_error_sum = 0.0
        self.y_error_sum = 0.0

    #aktualizuje kontrolea PID
    def update(self, deltaTime):
        #liczenie bledu
        self.x_error = self.value_target[0] - self.value_actual[0]
        self.y_error = self.value_target[1] - self.value_actual[1]
        
        #print(""Error = ( "" + str(self.x_error) + ""; "" + str(self.y_error) + "")"")

        #liczenie pochodnej
        self.x_derivative = (self.x_error - self.x_prev_error) / deltaTime
        self.y_derivative = (self.y_error - self.y_prev_error) / deltaTime

        self.x_prev_error = self.x_error
        self.y_prev_error = self.y_error

        self.x_error_sum += self.x_error * deltaTime
        self.y_error_sum += self.y_error * deltaTime
        
        #zmiana pozycji serw z uwzglednieniem bledu biezacego, przyszlego oraz przeszlego
        self.x_servo = (self.x_error * self.KP) + (self.x_derivative * self.KD) + (self.x_error_sum * self.KI)
        self.y_servo = (self.y_error * self.KP) + (self.y_derivative * self.KD) + (self.y_error_sum * self.KI)
        
        self.x_servo = MM.clamp(self.x_servo, -self.servo_pos_limit[0], self.servo_pos_limit[0])
        self.y_servo = MM.clamp(self.y_servo, -self.servo_pos_limit[1], self.servo_pos_limit[1])
        
        self.x_error_sum = MM.clamp(self.x_error_sum, -1.0, 1.0) * 0.99
        self.y_error_sum = MM.clamp(self.y_error_sum, -1.0, 1.0) * 0.99/n/n/n/PythonCode/PathPlannerModule.py/n/nimport cv2
import numpy as np
import MathModule as MM
import time
from multiprocessing import Process, RawValue
from collections import deque
import copy

#program odpowiadajacy za planiwanie sciezki kulki
class PathPlanner:
    
    obstacle_map_size = 40    #rozmiar mapy przeszkod
    obstacle_map_update_delta = 4    #co ile sekund odswiezana ma byc mapa przeszkod?
    path_sub_update_delta = 0.1    #co ile sekund aktualizowac podsciezke?
    
    def __init__(self):
        print(""PathPlanner object created"")
        
        self.obstacle_map = None
        self.path = None
        self_path_last_index = 0
        self.proximity_map = np.zeros((PathPlanner.obstacle_map_size, PathPlanner.obstacle_map_size)) #tablica 2D z kosztem bliskosci wykrytych przeszkod
        
        self.path_position = 0.0   #aktualna pozycja na sciezce
        self.path_speed = 0.2 * PathPlanner.obstacle_map_size    #predkosc przechodzenia sciezki
        
        self.ball_pos_x = RawValue('f', 0.5)
        self.ball_pos_y = RawValue('f', 0.5)
        self.target_pos_x = RawValue('f', 0.25)
        self.target_pos_y = RawValue('f', 0.25)
        self.path_x = RawValue('f', 0.5)
        self.path_y = RawValue('f', 0.5)
        
    def setBallPosition(self, pos):
        self.ball_pos_x.value = pos[1]
        self.ball_pos_y.value = pos[0]
        
    def setTargetPosition(self, pos):
        self.target_pos_x.value = pos[1]
        self.target_pos_y.value = pos[0]
        
    def getPathTarget(self):
        return (self.path_x.value, self.path_y.value)
        
    def startProcessing(self, _frame_array):
        print(""Starting PathPlanner process"")
        self.process = Process(target=PathPlanner.doPlanning, args=(self,_frame_array))
        self.process.daemon = True
        self.process.start()
        
    def stopProcessing(self):
        print(""Stopping PathPlanner process"")
        self.process.terminate()
        
    def doPlanning(self, _frame_array):
        obstacle_map_update_time = 0.0
        path_sub_update_time = 0.0
        while True:
            if time.perf_counter() - obstacle_map_update_time >= PathPlanner.obstacle_map_update_delta:
                obstacle_map_update_time = time.perf_counter()
                PathPlanner.updateObstacleMap(self, _frame_array)
                
            if time.perf_counter() - path_sub_update_time >= PathPlanner.path_sub_update_delta:
                path_sub_update_time = time.perf_counter()
                PathPlanner.UpdateSubPath(self)
        
    #aktualizuje bitmape przeszkod
    def updateObstacleMap(self, _frame_array):
        frame = np.frombuffer(_frame_array, dtype=np.int32)
        frame = np.clip(frame, 0, 255).astype('uint8').reshape((PathPlanner.obstacle_map_size, PathPlanner.obstacle_map_size))
        #cv2.imshow(""Map"", frame)
        frame = cv2.inRange(frame, 90, 255)
        #kernel = np.ones((2,2), np.uint8)
        #frame = cv2.dilate(frame, kernel, iterations=1)
        self.obstacle_map = frame
        
        #aktualizacja mapy bliskosci przeszkod
        self.proximity_map.fill(0)
        size = PathPlanner.obstacle_map_size - 1
        sides = ((1, 0), (1, -1), (0, -1), (-1, -1), (-1, 0), (-1, 1), (0, 1), (1, 1))
        for x in range(1, size):
            for y in range(1, size):
                if frame[x, y] > 0:
                    for side in sides:
                        self.proximity_map[x + side[0], y + side[1]] += 1
        
        #np.clip(self.proximity_map, 0, 1, self.proximity_map)
        self.proximity_map *= 5000
        
        #aktualizacja glownej sciezki
        start = PathPlanner.FromUnitaryToMapSpace((self.ball_pos_x.value, self.ball_pos_y.value), self.obstacle_map_size)
        end = PathPlanner.FromUnitaryToMapSpace((self.target_pos_x.value, self.target_pos_y.value), self.obstacle_map_size)
        self.path = PathPlanner.a_star(self, start, end)
        
        self.path_last_index = len(self.path)-1
        self.path_position = 0.0
        
    #aktualizuje podsciezke przy uzyciu algorytmu A*
    def UpdateSubPath(self):
        if self.path == None: return None
        
        ball_pos = (self.ball_pos_x.value, self.ball_pos_y.value)
        path = self.path
        
        index = int(self.path_position)
        A = PathPlanner.FromMapToUnitarySpace(path[index])
        
        frame = copy.copy(self.obstacle_map)
        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
        
        if self.path_last_index > 0:
            B = PathPlanner.FromMapToUnitarySpace(path[index+1])
            dist = MM.distance(A, B)
            mant = self.path_position - index
            
            PathPlanner.PaintRay(self, PathPlanner.FromUnitaryToMapSpace(ball_pos, self.obstacle_map_size), path[index+1], frame)
            if not PathPlanner.Raycast(self, PathPlanner.FromUnitaryToMapSpace(ball_pos, self.obstacle_map_size), path[index+1]):
                print(""False"")
                self.path_position += self.path_speed * PathPlanner.path_sub_update_delta / (dist * PathPlanner.obstacle_map_size)
            if self.path_position >= self.path_last_index: self.path_position = self.path_last_index - 0.00001
            
            target_y = MM.lerp(A[0], B[0], mant)
            target_x = MM.lerp(A[1], B[1], mant)
        else:
            target_y = A[0]
            target_x = A[1]
            
        #print(target_x)
        #print(target_y)
        #print("""")
        
        self.path_x.value = target_x
        self.path_y.value = target_y
            
        
        
        #DEBUG
        for p in path:
            if PathPlanner.isPointWithinMap(self, p):
                frame[p[0], p[1]] = [255, 255, 0]
            
        frame = cv2.resize(frame, (200, 200), interpolation=cv2.INTER_NEAREST)
        
        cv2.imshow(""PathPlanner frame"", frame)
        key = cv2.waitKey(1) & 0xFF
        
    #zmienia uklad odniesienia z mapy przeszkod na jednostkowy
    def FromMapToUnitarySpace(point):
        return (point[0] / PathPlanner.obstacle_map_size, point[1] / PathPlanner.obstacle_map_size)
    
    #zmienia uklad odniesienia z jednostkowego na mape przeszkod
    def FromUnitaryToMapSpace(point, size):
        return (round(point[0] * size), round(point[1] * size))
        
    #sprawdza, czy punkt wewnatrz mapy przeszkod
    def isPointWithinMap(self, point):
        size = self.obstacle_map_size
        return point[0] >= 0 and point[0] < size and point[1] >= 0 and point[1] < size
        
    #algorytm A* wyznaczajacy sciezke z punktu A do B
    def a_star(self, A, B):
        start = B
        end = A
        #movement = ((1, 0), (-1, 0), (0, 1), (0, -1))
        movement = ((1, 0), (-1, 0), (0, 1), (0, -1), (-1, -1), (-1, 1), (1, 1), (1, -1))
        
        que = MM.PriorityQueue()
        que.push(start, 0)
        
        visited_from = {}
        cost = {}
        
        visited_from[start] = None
        visited_from[end] = None
        cost[start] = 0
        
        #timeStart = time.perf_counter()
        while not que.empty():
            v = que.pop()
            if v == end: break
            
            new_cost = cost[v] + 1
            i = 0
            for move in movement:
                nx = v[0] + move[0]
                ny = v[1] + move[1]
                
                i += 1
                if i == 5: new_cost += 0.4
                
                if PathPlanner.isPointWithinMap(self, (nx, ny)) and self.obstacle_map[nx, ny] == 0:
                    u = (nx, ny)
                    if u not in cost or new_cost < cost[u]:
                        cost[u] = new_cost
                        center = PathPlanner.obstacle_map_size // 2
                        que.push(u, new_cost + MM.sqrMagnitude(v[0] - u[0], v[1] - u[1]) + self.proximity_map[u[0], u[1]] + int(MM.sqrMagnitude(center - u[0], center - u[1])))
                        visited_from[u] = v
        
        path = []
        if visited_from[end] != None:
            v = end
            while v != start:
                path.append(v)
                v = visited_from[v]
            path.append(start)
        else:
            time.sleep(0.05)
            path.append(end)
        
        return path
    
    #sprawdza, czy promien przecina pole, na ktorym znajduje sie przeszkoda
    def Raycast(self, origin, end):
        obstacle_map = self.obstacle_map
        if not PathPlanner.isPointWithinMap(self, origin) or not PathPlanner.isPointWithinMap(self, end): return False    #jesli punkt startowy jest poza mapa
        if origin == end: return obstacle_map[origin[0], origin[1]]    #jesli promien jest punktem
        
        vec = (end[0] - origin[0], end[1] - origin[1])
        flipped = False    #czy wspolrzedne w ukladzie sa zamienione miejscami? (x; y) -> (y; x)
        if abs(vec[1]) > abs(vec[0]):
            #jesli nachylenie wektora jest wieksze niz 45 stopni
            #uklad wspolrzednych 'obracany jest' o 90 stopni
            vec = (vec[1], vec[0])
            origin = (origin[1], origin[0])
            end = (end[1], end[0])
            flipped = True
        
        dir = vec[1]/vec[0] #wspolczynnik kierunkowy promienia
        offset = origin[1] - dir * origin[0]    #skladnik 'b' w funkcji y = dir*x + b; przechodzi ona przez 'origin'
        
        #znaleznienie najbardziej lewego i prawego punktu promienia
        if origin[0] >= end[0]:
            left = end[0]
            right = origin[0]
        else:
            left = origin[0]
            right = end[0]
            
        #przejscie po wszystkich punktach mapy przeszkod nalezacych do promienia i sprawdzenie, czy ktorys z nich jest przeszkada
        if not flipped:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                #print(""Checked ("" + str(x) + "", "" + str(y) + "")"") 
                if obstacle_map[x, y] > 0:
                    return True
        else:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                #print(""Checked ("" + str(y) + "", "" + str(x) + "")"") 
                if obstacle_map[y, x] > 0:
                    return True
                
        return False
    
    #DEBUG
    def PaintRay(self, origin, end, frame):
        obstacle_map = self.obstacle_map
        if not PathPlanner.isPointWithinMap(self, origin) or not PathPlanner.isPointWithinMap(self, end): return    #jesli punkt startowy jest poza mapa
        if origin == end:
            frame[origin[0], origin[1]] = [0, 255, 0]
            return
            
        
        vec = (end[0] - origin[0], end[1] - origin[1])
        flipped = False    #czy wspolrzedne w ukladzie sa zamienione miejscami? (x; y) -> (y; x)
        if abs(vec[1]) > abs(vec[0]):
            #jesli nachylenie wektora jest wieksze niz 45 stopni
            #uklad wspolrzednych 'obracany jest' o 90 stopni
            vec = (vec[1], vec[0])
            origin = (origin[1], origin[0])
            end = (end[1], end[0])
            flipped = True
        
        dir = vec[1]/vec[0] #wspolczynnik kierunkowy promienia
        offset = origin[1] - dir * origin[0]    #skladnik 'b' w funkcji y = dir*x + b; przechodzi ona przez 'origin'
        
        #znaleznienie najbardziej lewego i prawego punktu promienia
        if origin[0] >= end[0]:
            left = end[0]
            right = origin[0]
        else:
            left = origin[0]
            right = end[0]
            
        #przejscie po wszystkich punktach mapy przeszkod nalezacych do promienia i sprawdzenie, czy ktorys z nich jest przeszkada
        if not flipped:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                frame[x, y] = [0, 255, 0]
        else:
            for x in range(left, right+1):
                y = round(dir * x + offset)
                frame[y, x] = [0, 255, 0]/n/n/n/PythonCode/ServoControllerModule.py/n/nfrom __future__ import division
simulationMode = True

if not simulationMode:
    import sys
    sys.path.append('/home/pi/Adafruit_Python_PCA9685/')
    import Adafruit_PCA9685
    
import math
import MathModule as MM

#program kontrolujacy ruch serw
class ServoController:
    
    #parametry serw
    servo_pulse_neutral = (388, 379)    #wartosci pwm dla pozycji neutralnych serw
    servo_pulse_range = (100, 100)      #zakres wartosci sygnalu pwm dla ruchu serw
    servo_pos_limit = (800, 800)    #ograniczenia wychylen serw (w skali od 0 do 1000)
    servo_movement_speed = (6000, 6000)    #szybkosci ruchu serw
    
    def __init__(self):
        if not simulationMode:
            self.pwm = Adafruit_PCA9685.PCA9685()  #laczenie sie z plytka sterujaca serwami
            self.pwm.set_pwm_freq(60)
        
        #zmienne wartosci
        self.servo_actual_pos = [0, 0]    #aktualna pozycja serwa
        self.servo_target_pos = [0, 0]    #docelowa pozycja serwa
        
        self.update(0)   #aplikowanie domyslnych ustawien serw

    #wydaje polecenie poruszenia serwem na kanale 'channel' na pozycje 'pos' (w skali od -1000 do 1000)
    def moveServo(self, channel, pos):
        self.servo_target_pos[channel] = MM.clamp(pos, -ServoController.servo_pos_limit[channel], ServoController.servo_pos_limit[channel])

    #aktualizuje pozycje serw
    def update(self, deltaTime):
        for i in range(2): #tylko 2 serwa
            
            movement_dir = MM.sign(self.servo_target_pos[i] - self.servo_actual_pos[i])
            self.servo_actual_pos[i] += ServoController.servo_movement_speed[i] * movement_dir * deltaTime
            
            if movement_dir > 0: self.servo_actual_pos[i] = min(self.servo_actual_pos[i], self.servo_target_pos[i])
            elif movement_dir < 0: self.servo_actual_pos[i] = max(self.servo_actual_pos[i], self.servo_target_pos[i])
                
            if not simulationMode:
                pos = round(ServoController.servo_pulse_neutral[i] + ServoController.servo_pulse_range[i] * self.servo_actual_pos[i] / 1000)
                self.pwm.set_pwm(i, 0, pos)
            else:
                self.servo_actual_pos[i] = round(self.servo_actual_pos[i])
/n/n/n/PythonCode/TensorflowProcessingModule.py/n/nimport numpy as np

print(""Importing Tensorflow libraries"")
from tensorflow.contrib.lite.python import interpreter as interpreter_wrapper
import tensorflow as tf

#klasa z funkcjami do przetwarzania danych sieciami neuronowymi z Tensorflow
class TensorflowProcessor:
    
    #sciezka do uzywanego modelu
    ball_detector_model_path = ""/home/pi/ballance/Ballance/Tensorflow/ballancenet_conv_3_quant.tflite""
    corner_detector_model_path = ""/home/pi/ballance/Ballance/Tensorflow/ballancenet_boardcorner_conv_2_quant.tflite""
    
    #funkcja generujaca zoptymalizowany model
    def QuantizeModel(model_path, output_file_name):
        print(""Quantizing model"")
        converter = tf.contrib.lite.TocoConverter.from_saved_model(model_path)
        converter.post_training_quantize = True
        quant_model = converter.convert()
        open(output_file_name + "".tflite"", ""wb"").write(quant_model)
        
    def __init__(self):
        print(""Creating TensorflowProcessor object"")
        #wczytywanie modelu do wykrywania kulki
        print(""Loading ball detection tflite model"")
        self.ball_detector_interpreter = interpreter_wrapper.Interpreter(model_path=TensorflowProcessor.ball_detector_model_path)
        self.ball_detector_interpreter.allocate_tensors()
        self.ball_detector_input_details = self.ball_detector_interpreter.get_input_details()
        self.ball_detector_output_details = self.ball_detector_interpreter.get_output_details()
        
        #wczytywanie modelu do wykrywania krawedzi plyty
        print(""Loading corner detection tflite model"")
        self.corner_detector_interpreter = interpreter_wrapper.Interpreter(model_path=TensorflowProcessor.corner_detector_model_path)
        self.corner_detector_interpreter.allocate_tensors()
        self.corner_detector_input_details = self.corner_detector_interpreter.get_input_details()
        self.corner_detector_output_details = self.corner_detector_interpreter.get_output_details()
        
        print(""TensorflowProcessor object created"")
        
    def getBallPosition(self, image):
        #przygotowanie obrazu
        image = np.float32(image)
        image /= 255.0
        image = np.expand_dims(image, axis=0)
        image = np.expand_dims(image, axis=3)
        
        #wykonanie interpretacji
        self.ball_detector_interpreter.set_tensor(self.ball_detector_input_details[0]['index'], image)
        self.ball_detector_interpreter.invoke()
        
        return np.squeeze(self.ball_detector_interpreter.get_tensor(self.ball_detector_output_details[0]['index']))
    
    def getCornerPosition(self, image):
        #przygotowanie obrazu
        image = np.float32(image)
        image /= 255.0
        image = np.expand_dims(image, axis=0)
        image = np.expand_dims(image, axis=3)
        
        #wykonanie interpretacji
        self.corner_detector_interpreter.set_tensor(self.corner_detector_input_details[0]['index'], image)
        self.corner_detector_interpreter.invoke()
        
        return np.squeeze(self.corner_detector_interpreter.get_tensor(self.corner_detector_output_details[0]['index']))/n/n/n/PythonCode/test.py/n/nimport PathPlannerModule as PPM
import math

pathPlanner = PPM.PathPlanner()

origin = (0, 0)
r = 10000

for angle in range(0, 360):
    ang = angle * math.pi / 180
    end = (int(round(math.sin(ang) * r)), int(round(math.cos(ang) * r)))
    print(""end = "" + str(end))
    pathPlanner.Raycast(origin, end)
    print("""")/n/n/n",1
16,16,c5abced949e6a4b001d1dee321593e74ecadecfe,"Lib/CGIHTTPServer.py/n/n""""""CGI-savvy HTTP Server.

This module builds on SimpleHTTPServer by implementing GET and POST
requests to cgi-bin scripts.

If the os.fork() function is not present (e.g. on Windows),
os.popen2() is used as a fallback, with slightly altered semantics; if
that function is not present either (e.g. on Macintosh), only Python
scripts are supported, and they are executed by the current process.

In all cases, the implementation is intentionally naive -- all
requests are executed sychronously.

SECURITY WARNING: DON'T USE THIS CODE UNLESS YOU ARE INSIDE A FIREWALL
-- it may execute arbitrary Python code or external programs.

Note that status code 200 is sent prior to execution of a CGI script, so
scripts cannot send other status codes such as 302 (redirect).
""""""


__version__ = ""0.4""

__all__ = [""CGIHTTPRequestHandler""]

import os
import sys
import urllib
import BaseHTTPServer
import SimpleHTTPServer
import select


class CGIHTTPRequestHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):

    """"""Complete HTTP server with GET, HEAD and POST commands.

    GET and HEAD also support running CGI scripts.

    The POST command is *only* implemented for CGI scripts.

    """"""

    # Determine platform specifics
    have_fork = hasattr(os, 'fork')
    have_popen2 = hasattr(os, 'popen2')
    have_popen3 = hasattr(os, 'popen3')

    # Make rfile unbuffered -- we need to read one line and then pass
    # the rest to a subprocess, so we can't use buffered input.
    rbufsize = 0

    def do_POST(self):
        """"""Serve a POST request.

        This is only implemented for CGI scripts.

        """"""

        if self.is_cgi():
            self.run_cgi()
        else:
            self.send_error(501, ""Can only POST to CGI scripts"")

    def send_head(self):
        """"""Version of send_head that support CGI scripts""""""
        if self.is_cgi():
            return self.run_cgi()
        else:
            return SimpleHTTPServer.SimpleHTTPRequestHandler.send_head(self)

    def is_cgi(self):
        """"""Test whether self.path corresponds to a CGI script.

        Returns True and updates the cgi_info attribute to the tuple
        (dir, rest) if self.path requires running a CGI script.
        Returns False otherwise.

        The default implementation tests whether the normalized url
        path begins with one of the strings in self.cgi_directories
        (and the next character is a '/' or the end of the string).
        """"""
        splitpath = _url_collapse_path_split(self.path)
        if splitpath[0] in self.cgi_directories:
            self.cgi_info = splitpath
            return True
        return False

    cgi_directories = ['/cgi-bin', '/htbin']

    def is_executable(self, path):
        """"""Test whether argument path is an executable file.""""""
        return executable(path)

    def is_python(self, path):
        """"""Test whether argument path is a Python script.""""""
        head, tail = os.path.splitext(path)
        return tail.lower() in ("".py"", "".pyw"")

    def run_cgi(self):
        """"""Execute a CGI script.""""""
        path = self.path
        dir, rest = self.cgi_info

        i = path.find('/', len(dir) + 1)
        while i >= 0:
            nextdir = path[:i]
            nextrest = path[i+1:]

            scriptdir = self.translate_path(nextdir)
            if os.path.isdir(scriptdir):
                dir, rest = nextdir, nextrest
                i = path.find('/', len(dir) + 1)
            else:
                break

        # find an explicit query string, if present.
        i = rest.rfind('?')
        if i >= 0:
            rest, query = rest[:i], rest[i+1:]
        else:
            query = ''

        # dissect the part after the directory name into a script name &
        # a possible additional path, to be stored in PATH_INFO.
        i = rest.find('/')
        if i >= 0:
            script, rest = rest[:i], rest[i:]
        else:
            script, rest = rest, ''

        scriptname = dir + '/' + script
        scriptfile = self.translate_path(scriptname)
        if not os.path.exists(scriptfile):
            self.send_error(404, ""No such CGI script (%r)"" % scriptname)
            return
        if not os.path.isfile(scriptfile):
            self.send_error(403, ""CGI script is not a plain file (%r)"" %
                            scriptname)
            return
        ispy = self.is_python(scriptname)
        if not ispy:
            if not (self.have_fork or self.have_popen2 or self.have_popen3):
                self.send_error(403, ""CGI script is not a Python script (%r)"" %
                                scriptname)
                return
            if not self.is_executable(scriptfile):
                self.send_error(403, ""CGI script is not executable (%r)"" %
                                scriptname)
                return

        # Reference: http://hoohoo.ncsa.uiuc.edu/cgi/env.html
        # XXX Much of the following could be prepared ahead of time!
        env = {}
        env['SERVER_SOFTWARE'] = self.version_string()
        env['SERVER_NAME'] = self.server.server_name
        env['GATEWAY_INTERFACE'] = 'CGI/1.1'
        env['SERVER_PROTOCOL'] = self.protocol_version
        env['SERVER_PORT'] = str(self.server.server_port)
        env['REQUEST_METHOD'] = self.command
        uqrest = urllib.unquote(rest)
        env['PATH_INFO'] = uqrest
        env['PATH_TRANSLATED'] = self.translate_path(uqrest)
        env['SCRIPT_NAME'] = scriptname
        if query:
            env['QUERY_STRING'] = query
        host = self.address_string()
        if host != self.client_address[0]:
            env['REMOTE_HOST'] = host
        env['REMOTE_ADDR'] = self.client_address[0]
        authorization = self.headers.getheader(""authorization"")
        if authorization:
            authorization = authorization.split()
            if len(authorization) == 2:
                import base64, binascii
                env['AUTH_TYPE'] = authorization[0]
                if authorization[0].lower() == ""basic"":
                    try:
                        authorization = base64.decodestring(authorization[1])
                    except binascii.Error:
                        pass
                    else:
                        authorization = authorization.split(':')
                        if len(authorization) == 2:
                            env['REMOTE_USER'] = authorization[0]
        # XXX REMOTE_IDENT
        if self.headers.typeheader is None:
            env['CONTENT_TYPE'] = self.headers.type
        else:
            env['CONTENT_TYPE'] = self.headers.typeheader
        length = self.headers.getheader('content-length')
        if length:
            env['CONTENT_LENGTH'] = length
        referer = self.headers.getheader('referer')
        if referer:
            env['HTTP_REFERER'] = referer
        accept = []
        for line in self.headers.getallmatchingheaders('accept'):
            if line[:1] in ""\t\n\r "":
                accept.append(line.strip())
            else:
                accept = accept + line[7:].split(',')
        env['HTTP_ACCEPT'] = ','.join(accept)
        ua = self.headers.getheader('user-agent')
        if ua:
            env['HTTP_USER_AGENT'] = ua
        co = filter(None, self.headers.getheaders('cookie'))
        if co:
            env['HTTP_COOKIE'] = ', '.join(co)
        # XXX Other HTTP_* headers
        # Since we're setting the env in the parent, provide empty
        # values to override previously set values
        for k in ('QUERY_STRING', 'REMOTE_HOST', 'CONTENT_LENGTH',
                  'HTTP_USER_AGENT', 'HTTP_COOKIE', 'HTTP_REFERER'):
            env.setdefault(k, """")
        os.environ.update(env)

        self.send_response(200, ""Script output follows"")

        decoded_query = query.replace('+', ' ')

        if self.have_fork:
            # Unix -- fork as we should
            args = [script]
            if '=' not in decoded_query:
                args.append(decoded_query)
            nobody = nobody_uid()
            self.wfile.flush() # Always flush before forking
            pid = os.fork()
            if pid != 0:
                # Parent
                pid, sts = os.waitpid(pid, 0)
                # throw away additional data [see bug #427345]
                while select.select([self.rfile], [], [], 0)[0]:
                    if not self.rfile.read(1):
                        break
                if sts:
                    self.log_error(""CGI script exit status %#x"", sts)
                return
            # Child
            try:
                try:
                    os.setuid(nobody)
                except os.error:
                    pass
                os.dup2(self.rfile.fileno(), 0)
                os.dup2(self.wfile.fileno(), 1)
                os.execve(scriptfile, args, os.environ)
            except:
                self.server.handle_error(self.request, self.client_address)
                os._exit(127)

        elif self.have_popen2 or self.have_popen3:
            # Windows -- use popen2 or popen3 to create a subprocess
            import shutil
            if self.have_popen3:
                popenx = os.popen3
            else:
                popenx = os.popen2
            cmdline = scriptfile
            if self.is_python(scriptfile):
                interp = sys.executable
                if interp.lower().endswith(""w.exe""):
                    # On Windows, use python.exe, not pythonw.exe
                    interp = interp[:-5] + interp[-4:]
                cmdline = ""%s -u %s"" % (interp, cmdline)
            if '=' not in query and '""' not in query:
                cmdline = '%s ""%s""' % (cmdline, query)
            self.log_message(""command: %s"", cmdline)
            try:
                nbytes = int(length)
            except (TypeError, ValueError):
                nbytes = 0
            files = popenx(cmdline, 'b')
            fi = files[0]
            fo = files[1]
            if self.have_popen3:
                fe = files[2]
            if self.command.lower() == ""post"" and nbytes > 0:
                data = self.rfile.read(nbytes)
                fi.write(data)
            # throw away additional data [see bug #427345]
            while select.select([self.rfile._sock], [], [], 0)[0]:
                if not self.rfile._sock.recv(1):
                    break
            fi.close()
            shutil.copyfileobj(fo, self.wfile)
            if self.have_popen3:
                errors = fe.read()
                fe.close()
                if errors:
                    self.log_error('%s', errors)
            sts = fo.close()
            if sts:
                self.log_error(""CGI script exit status %#x"", sts)
            else:
                self.log_message(""CGI script exited OK"")

        else:
            # Other O.S. -- execute script in this process
            save_argv = sys.argv
            save_stdin = sys.stdin
            save_stdout = sys.stdout
            save_stderr = sys.stderr
            try:
                save_cwd = os.getcwd()
                try:
                    sys.argv = [scriptfile]
                    if '=' not in decoded_query:
                        sys.argv.append(decoded_query)
                    sys.stdout = self.wfile
                    sys.stdin = self.rfile
                    execfile(scriptfile, {""__name__"": ""__main__""})
                finally:
                    sys.argv = save_argv
                    sys.stdin = save_stdin
                    sys.stdout = save_stdout
                    sys.stderr = save_stderr
                    os.chdir(save_cwd)
            except SystemExit, sts:
                self.log_error(""CGI script exit status %s"", str(sts))
            else:
                self.log_message(""CGI script exited OK"")


# TODO(gregory.p.smith): Move this into an appropriate library.
def _url_collapse_path_split(path):
    """"""
    Given a URL path, remove extra '/'s and '.' path elements and collapse
    any '..' references.

    Implements something akin to RFC-2396 5.2 step 6 to parse relative paths.

    Returns: A tuple of (head, tail) where tail is everything after the final /
    and head is everything before it.  Head will always start with a '/' and,
    if it contains anything else, never have a trailing '/'.

    Raises: IndexError if too many '..' occur within the path.
    """"""
    # Similar to os.path.split(os.path.normpath(path)) but specific to URL
    # path semantics rather than local operating system semantics.
    path_parts = []
    for part in path.split('/'):
        if part == '.':
            path_parts.append('')
        else:
            path_parts.append(part)
    # Filter out blank non trailing parts before consuming the '..'.
    path_parts = [part for part in path_parts[:-1] if part] + path_parts[-1:]
    if path_parts:
        tail_part = path_parts.pop()
    else:
        tail_part = ''
    head_parts = []
    for part in path_parts:
        if part == '..':
            head_parts.pop()
        else:
            head_parts.append(part)
    if tail_part and tail_part == '..':
        head_parts.pop()
        tail_part = ''
    return ('/' + '/'.join(head_parts), tail_part)


nobody = None

def nobody_uid():
    """"""Internal routine to get nobody's uid""""""
    global nobody
    if nobody:
        return nobody
    try:
        import pwd
    except ImportError:
        return -1
    try:
        nobody = pwd.getpwnam('nobody')[2]
    except KeyError:
        nobody = 1 + max(map(lambda x: x[2], pwd.getpwall()))
    return nobody


def executable(path):
    """"""Test for executable file.""""""
    try:
        st = os.stat(path)
    except os.error:
        return False
    return st.st_mode & 0111 != 0


def test(HandlerClass = CGIHTTPRequestHandler,
         ServerClass = BaseHTTPServer.HTTPServer):
    SimpleHTTPServer.test(HandlerClass, ServerClass)


if __name__ == '__main__':
    test()
/n/n/nLib/test/test_httpservers.py/n/n""""""Unittests for the various HTTPServer modules.

Written by Cody A.W. Somerville <cody-somerville@ubuntu.com>,
Josip Dzolonga, and Michael Otteneder for the 2007/08 GHOP contest.
""""""

from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer
from SimpleHTTPServer import SimpleHTTPRequestHandler
from CGIHTTPServer import CGIHTTPRequestHandler
import CGIHTTPServer

import os
import sys
import base64
import shutil
import urllib
import httplib
import tempfile
import threading

import unittest
from test import test_support


class NoLogRequestHandler:
    def log_message(self, *args):
        # don't write log messages to stderr
        pass


class TestServerThread(threading.Thread):
    def __init__(self, test_object, request_handler):
        threading.Thread.__init__(self)
        self.request_handler = request_handler
        self.test_object = test_object
        self.test_object.lock.acquire()

    def run(self):
        self.server = HTTPServer(('', 0), self.request_handler)
        self.test_object.PORT = self.server.socket.getsockname()[1]
        self.test_object.lock.release()
        try:
            self.server.serve_forever()
        finally:
            self.server.server_close()

    def stop(self):
        self.server.shutdown()


class BaseTestCase(unittest.TestCase):
    def setUp(self):
        self.lock = threading.Lock()
        self.thread = TestServerThread(self, self.request_handler)
        self.thread.start()
        self.lock.acquire()

    def tearDown(self):
        self.lock.release()
        self.thread.stop()

    def request(self, uri, method='GET', body=None, headers={}):
        self.connection = httplib.HTTPConnection('localhost', self.PORT)
        self.connection.request(method, uri, body, headers)
        return self.connection.getresponse()


class BaseHTTPServerTestCase(BaseTestCase):
    class request_handler(NoLogRequestHandler, BaseHTTPRequestHandler):
        protocol_version = 'HTTP/1.1'
        default_request_version = 'HTTP/1.1'

        def do_TEST(self):
            self.send_response(204)
            self.send_header('Content-Type', 'text/html')
            self.send_header('Connection', 'close')
            self.end_headers()

        def do_KEEP(self):
            self.send_response(204)
            self.send_header('Content-Type', 'text/html')
            self.send_header('Connection', 'keep-alive')
            self.end_headers()

        def do_KEYERROR(self):
            self.send_error(999)

        def do_CUSTOM(self):
            self.send_response(999)
            self.send_header('Content-Type', 'text/html')
            self.send_header('Connection', 'close')
            self.end_headers()

    def setUp(self):
        BaseTestCase.setUp(self)
        self.con = httplib.HTTPConnection('localhost', self.PORT)
        self.con.connect()

    def test_command(self):
        self.con.request('GET', '/')
        res = self.con.getresponse()
        self.assertEquals(res.status, 501)

    def test_request_line_trimming(self):
        self.con._http_vsn_str = 'HTTP/1.1\n'
        self.con.putrequest('GET', '/')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 501)

    def test_version_bogus(self):
        self.con._http_vsn_str = 'FUBAR'
        self.con.putrequest('GET', '/')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 400)

    def test_version_digits(self):
        self.con._http_vsn_str = 'HTTP/9.9.9'
        self.con.putrequest('GET', '/')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 400)

    def test_version_none_get(self):
        self.con._http_vsn_str = ''
        self.con.putrequest('GET', '/')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 501)

    def test_version_none(self):
        self.con._http_vsn_str = ''
        self.con.putrequest('PUT', '/')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 400)

    def test_version_invalid(self):
        self.con._http_vsn = 99
        self.con._http_vsn_str = 'HTTP/9.9'
        self.con.putrequest('GET', '/')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 505)

    def test_send_blank(self):
        self.con._http_vsn_str = ''
        self.con.putrequest('', '')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 400)

    def test_header_close(self):
        self.con.putrequest('GET', '/')
        self.con.putheader('Connection', 'close')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 501)

    def test_head_keep_alive(self):
        self.con._http_vsn_str = 'HTTP/1.1'
        self.con.putrequest('GET', '/')
        self.con.putheader('Connection', 'keep-alive')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 501)

    def test_handler(self):
        self.con.request('TEST', '/')
        res = self.con.getresponse()
        self.assertEquals(res.status, 204)

    def test_return_header_keep_alive(self):
        self.con.request('KEEP', '/')
        res = self.con.getresponse()
        self.assertEquals(res.getheader('Connection'), 'keep-alive')
        self.con.request('TEST', '/')

    def test_internal_key_error(self):
        self.con.request('KEYERROR', '/')
        res = self.con.getresponse()
        self.assertEquals(res.status, 999)

    def test_return_custom_status(self):
        self.con.request('CUSTOM', '/')
        res = self.con.getresponse()
        self.assertEquals(res.status, 999)


class SimpleHTTPServerTestCase(BaseTestCase):
    class request_handler(NoLogRequestHandler, SimpleHTTPRequestHandler):
        pass

    def setUp(self):
        BaseTestCase.setUp(self)
        self.cwd = os.getcwd()
        basetempdir = tempfile.gettempdir()
        os.chdir(basetempdir)
        self.data = 'We are the knights who say Ni!'
        self.tempdir = tempfile.mkdtemp(dir=basetempdir)
        self.tempdir_name = os.path.basename(self.tempdir)
        temp = open(os.path.join(self.tempdir, 'test'), 'wb')
        temp.write(self.data)
        temp.close()

    def tearDown(self):
        try:
            os.chdir(self.cwd)
            try:
                shutil.rmtree(self.tempdir)
            except:
                pass
        finally:
            BaseTestCase.tearDown(self)

    def check_status_and_reason(self, response, status, data=None):
        body = response.read()
        self.assert_(response)
        self.assertEquals(response.status, status)
        self.assert_(response.reason != None)
        if data:
            self.assertEqual(data, body)

    def test_get(self):
        #constructs the path relative to the root directory of the HTTPServer
        response = self.request(self.tempdir_name + '/test')
        self.check_status_and_reason(response, 200, data=self.data)
        response = self.request(self.tempdir_name + '/')
        self.check_status_and_reason(response, 200)
        response = self.request(self.tempdir_name)
        self.check_status_and_reason(response, 301)
        response = self.request('/ThisDoesNotExist')
        self.check_status_and_reason(response, 404)
        response = self.request('/' + 'ThisDoesNotExist' + '/')
        self.check_status_and_reason(response, 404)
        f = open(os.path.join(self.tempdir_name, 'index.html'), 'w')
        response = self.request('/' + self.tempdir_name + '/')
        self.check_status_and_reason(response, 200)
        if os.name == 'posix':
            # chmod won't work as expected on Windows platforms
            os.chmod(self.tempdir, 0)
            response = self.request(self.tempdir_name + '/')
            self.check_status_and_reason(response, 404)
            os.chmod(self.tempdir, 0755)

    def test_head(self):
        response = self.request(
            self.tempdir_name + '/test', method='HEAD')
        self.check_status_and_reason(response, 200)
        self.assertEqual(response.getheader('content-length'),
                         str(len(self.data)))
        self.assertEqual(response.getheader('content-type'),
                         'application/octet-stream')

    def test_invalid_requests(self):
        response = self.request('/', method='FOO')
        self.check_status_and_reason(response, 501)
        # requests must be case sensitive,so this should fail too
        response = self.request('/', method='get')
        self.check_status_and_reason(response, 501)
        response = self.request('/', method='GETs')
        self.check_status_and_reason(response, 501)


cgi_file1 = """"""\
#!%s

print ""Content-type: text/html""
print
print ""Hello World""
""""""

cgi_file2 = """"""\
#!%s
import cgi

print ""Content-type: text/html""
print

form = cgi.FieldStorage()
print ""%%s, %%s, %%s"" %% (form.getfirst(""spam""), form.getfirst(""eggs""),\
              form.getfirst(""bacon""))
""""""

class CGIHTTPServerTestCase(BaseTestCase):
    class request_handler(NoLogRequestHandler, CGIHTTPRequestHandler):
        pass

    def setUp(self):
        BaseTestCase.setUp(self)
        self.parent_dir = tempfile.mkdtemp()
        self.cgi_dir = os.path.join(self.parent_dir, 'cgi-bin')
        os.mkdir(self.cgi_dir)

        self.file1_path = os.path.join(self.cgi_dir, 'file1.py')
        with open(self.file1_path, 'w') as file1:
            file1.write(cgi_file1 % sys.executable)
        os.chmod(self.file1_path, 0777)

        self.file2_path = os.path.join(self.cgi_dir, 'file2.py')
        with open(self.file2_path, 'w') as file2:
            file2.write(cgi_file2 % sys.executable)
        os.chmod(self.file2_path, 0777)

        self.cwd = os.getcwd()
        os.chdir(self.parent_dir)

    def tearDown(self):
        try:
            os.chdir(self.cwd)
            os.remove(self.file1_path)
            os.remove(self.file2_path)
            os.rmdir(self.cgi_dir)
            os.rmdir(self.parent_dir)
        finally:
            BaseTestCase.tearDown(self)

    def test_url_collapse_path_split(self):
        test_vectors = {
            '': ('/', ''),
            '..': IndexError,
            '/.//..': IndexError,
            '/': ('/', ''),
            '//': ('/', ''),
            '/\\': ('/', '\\'),
            '/.//': ('/', ''),
            'cgi-bin/file1.py': ('/cgi-bin', 'file1.py'),
            '/cgi-bin/file1.py': ('/cgi-bin', 'file1.py'),
            'a': ('/', 'a'),
            '/a': ('/', 'a'),
            '//a': ('/', 'a'),
            './a': ('/', 'a'),
            './C:/': ('/C:', ''),
            '/a/b': ('/a', 'b'),
            '/a/b/': ('/a/b', ''),
            '/a/b/c/..': ('/a/b', ''),
            '/a/b/c/../d': ('/a/b', 'd'),
            '/a/b/c/../d/e/../f': ('/a/b/d', 'f'),
            '/a/b/c/../d/e/../../f': ('/a/b', 'f'),
            '/a/b/c/../d/e/.././././..//f': ('/a/b', 'f'),
            '../a/b/c/../d/e/.././././..//f': IndexError,
            '/a/b/c/../d/e/../../../f': ('/a', 'f'),
            '/a/b/c/../d/e/../../../../f': ('/', 'f'),
            '/a/b/c/../d/e/../../../../../f': IndexError,
            '/a/b/c/../d/e/../../../../f/..': ('/', ''),
        }
        for path, expected in test_vectors.iteritems():
            if isinstance(expected, type) and issubclass(expected, Exception):
                self.assertRaises(expected,
                                  CGIHTTPServer._url_collapse_path_split, path)
            else:
                actual = CGIHTTPServer._url_collapse_path_split(path)
                self.assertEquals(expected, actual,
                                  msg='path = %r\nGot:    %r\nWanted: %r' % (
                                  path, actual, expected))

    def test_headers_and_content(self):
        res = self.request('/cgi-bin/file1.py')
        self.assertEquals(('Hello World\n', 'text/html', 200), \
             (res.read(), res.getheader('Content-type'), res.status))

    def test_post(self):
        params = urllib.urlencode({'spam' : 1, 'eggs' : 'python', 'bacon' : 123456})
        headers = {'Content-type' : 'application/x-www-form-urlencoded'}
        res = self.request('/cgi-bin/file2.py', 'POST', params, headers)

        self.assertEquals(res.read(), '1, python, 123456\n')

    def test_invaliduri(self):
        res = self.request('/cgi-bin/invalid')
        res.read()
        self.assertEquals(res.status, 404)

    def test_authorization(self):
        headers = {'Authorization' : 'Basic %s' % \
                base64.b64encode('username:pass')}
        res = self.request('/cgi-bin/file1.py', 'GET', headers=headers)
        self.assertEquals(('Hello World\n', 'text/html', 200), \
             (res.read(), res.getheader('Content-type'), res.status))

    def test_no_leading_slash(self):
        # http://bugs.python.org/issue2254
        res = self.request('cgi-bin/file1.py')
        self.assertEquals(('Hello World\n', 'text/html', 200),
             (res.read(), res.getheader('Content-type'), res.status))


def test_main(verbose=None):
    try:
        cwd = os.getcwd()
        test_support.run_unittest(BaseHTTPServerTestCase,
                                  SimpleHTTPServerTestCase,
                                  CGIHTTPServerTestCase
                                  )
    finally:
        os.chdir(cwd)

if __name__ == '__main__':
    test_main()
/n/n/n",0
17,17,c5abced949e6a4b001d1dee321593e74ecadecfe,"/Lib/CGIHTTPServer.py/n/n""""""CGI-savvy HTTP Server.

This module builds on SimpleHTTPServer by implementing GET and POST
requests to cgi-bin scripts.

If the os.fork() function is not present (e.g. on Windows),
os.popen2() is used as a fallback, with slightly altered semantics; if
that function is not present either (e.g. on Macintosh), only Python
scripts are supported, and they are executed by the current process.

In all cases, the implementation is intentionally naive -- all
requests are executed sychronously.

SECURITY WARNING: DON'T USE THIS CODE UNLESS YOU ARE INSIDE A FIREWALL
-- it may execute arbitrary Python code or external programs.

Note that status code 200 is sent prior to execution of a CGI script, so
scripts cannot send other status codes such as 302 (redirect).
""""""


__version__ = ""0.4""

__all__ = [""CGIHTTPRequestHandler""]

import os
import sys
import urllib
import BaseHTTPServer
import SimpleHTTPServer
import select


class CGIHTTPRequestHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):

    """"""Complete HTTP server with GET, HEAD and POST commands.

    GET and HEAD also support running CGI scripts.

    The POST command is *only* implemented for CGI scripts.

    """"""

    # Determine platform specifics
    have_fork = hasattr(os, 'fork')
    have_popen2 = hasattr(os, 'popen2')
    have_popen3 = hasattr(os, 'popen3')

    # Make rfile unbuffered -- we need to read one line and then pass
    # the rest to a subprocess, so we can't use buffered input.
    rbufsize = 0

    def do_POST(self):
        """"""Serve a POST request.

        This is only implemented for CGI scripts.

        """"""

        if self.is_cgi():
            self.run_cgi()
        else:
            self.send_error(501, ""Can only POST to CGI scripts"")

    def send_head(self):
        """"""Version of send_head that support CGI scripts""""""
        if self.is_cgi():
            return self.run_cgi()
        else:
            return SimpleHTTPServer.SimpleHTTPRequestHandler.send_head(self)

    def is_cgi(self):
        """"""Test whether self.path corresponds to a CGI script,
        and return a boolean.

        This function sets self.cgi_info to a tuple (dir, rest)
        when it returns True, where dir is the directory part before
        the CGI script name.  Note that rest begins with a
        slash if it is not empty.

        The default implementation tests whether the path
        begins with one of the strings in the list
        self.cgi_directories (and the next character is a '/'
        or the end of the string).
        """"""

        path = self.path

        for x in self.cgi_directories:
            i = len(x)
            if path[:i] == x and (not path[i:] or path[i] == '/'):
                self.cgi_info = path[:i], path[i+1:]
                return True
        return False

    cgi_directories = ['/cgi-bin', '/htbin']

    def is_executable(self, path):
        """"""Test whether argument path is an executable file.""""""
        return executable(path)

    def is_python(self, path):
        """"""Test whether argument path is a Python script.""""""
        head, tail = os.path.splitext(path)
        return tail.lower() in ("".py"", "".pyw"")

    def run_cgi(self):
        """"""Execute a CGI script.""""""
        path = self.path
        dir, rest = self.cgi_info

        i = path.find('/', len(dir) + 1)
        while i >= 0:
            nextdir = path[:i]
            nextrest = path[i+1:]

            scriptdir = self.translate_path(nextdir)
            if os.path.isdir(scriptdir):
                dir, rest = nextdir, nextrest
                i = path.find('/', len(dir) + 1)
            else:
                break

        # find an explicit query string, if present.
        i = rest.rfind('?')
        if i >= 0:
            rest, query = rest[:i], rest[i+1:]
        else:
            query = ''

        # dissect the part after the directory name into a script name &
        # a possible additional path, to be stored in PATH_INFO.
        i = rest.find('/')
        if i >= 0:
            script, rest = rest[:i], rest[i:]
        else:
            script, rest = rest, ''

        scriptname = dir + '/' + script
        scriptfile = self.translate_path(scriptname)
        if not os.path.exists(scriptfile):
            self.send_error(404, ""No such CGI script (%r)"" % scriptname)
            return
        if not os.path.isfile(scriptfile):
            self.send_error(403, ""CGI script is not a plain file (%r)"" %
                            scriptname)
            return
        ispy = self.is_python(scriptname)
        if not ispy:
            if not (self.have_fork or self.have_popen2 or self.have_popen3):
                self.send_error(403, ""CGI script is not a Python script (%r)"" %
                                scriptname)
                return
            if not self.is_executable(scriptfile):
                self.send_error(403, ""CGI script is not executable (%r)"" %
                                scriptname)
                return

        # Reference: http://hoohoo.ncsa.uiuc.edu/cgi/env.html
        # XXX Much of the following could be prepared ahead of time!
        env = {}
        env['SERVER_SOFTWARE'] = self.version_string()
        env['SERVER_NAME'] = self.server.server_name
        env['GATEWAY_INTERFACE'] = 'CGI/1.1'
        env['SERVER_PROTOCOL'] = self.protocol_version
        env['SERVER_PORT'] = str(self.server.server_port)
        env['REQUEST_METHOD'] = self.command
        uqrest = urllib.unquote(rest)
        env['PATH_INFO'] = uqrest
        env['PATH_TRANSLATED'] = self.translate_path(uqrest)
        env['SCRIPT_NAME'] = scriptname
        if query:
            env['QUERY_STRING'] = query
        host = self.address_string()
        if host != self.client_address[0]:
            env['REMOTE_HOST'] = host
        env['REMOTE_ADDR'] = self.client_address[0]
        authorization = self.headers.getheader(""authorization"")
        if authorization:
            authorization = authorization.split()
            if len(authorization) == 2:
                import base64, binascii
                env['AUTH_TYPE'] = authorization[0]
                if authorization[0].lower() == ""basic"":
                    try:
                        authorization = base64.decodestring(authorization[1])
                    except binascii.Error:
                        pass
                    else:
                        authorization = authorization.split(':')
                        if len(authorization) == 2:
                            env['REMOTE_USER'] = authorization[0]
        # XXX REMOTE_IDENT
        if self.headers.typeheader is None:
            env['CONTENT_TYPE'] = self.headers.type
        else:
            env['CONTENT_TYPE'] = self.headers.typeheader
        length = self.headers.getheader('content-length')
        if length:
            env['CONTENT_LENGTH'] = length
        referer = self.headers.getheader('referer')
        if referer:
            env['HTTP_REFERER'] = referer
        accept = []
        for line in self.headers.getallmatchingheaders('accept'):
            if line[:1] in ""\t\n\r "":
                accept.append(line.strip())
            else:
                accept = accept + line[7:].split(',')
        env['HTTP_ACCEPT'] = ','.join(accept)
        ua = self.headers.getheader('user-agent')
        if ua:
            env['HTTP_USER_AGENT'] = ua
        co = filter(None, self.headers.getheaders('cookie'))
        if co:
            env['HTTP_COOKIE'] = ', '.join(co)
        # XXX Other HTTP_* headers
        # Since we're setting the env in the parent, provide empty
        # values to override previously set values
        for k in ('QUERY_STRING', 'REMOTE_HOST', 'CONTENT_LENGTH',
                  'HTTP_USER_AGENT', 'HTTP_COOKIE', 'HTTP_REFERER'):
            env.setdefault(k, """")
        os.environ.update(env)

        self.send_response(200, ""Script output follows"")

        decoded_query = query.replace('+', ' ')

        if self.have_fork:
            # Unix -- fork as we should
            args = [script]
            if '=' not in decoded_query:
                args.append(decoded_query)
            nobody = nobody_uid()
            self.wfile.flush() # Always flush before forking
            pid = os.fork()
            if pid != 0:
                # Parent
                pid, sts = os.waitpid(pid, 0)
                # throw away additional data [see bug #427345]
                while select.select([self.rfile], [], [], 0)[0]:
                    if not self.rfile.read(1):
                        break
                if sts:
                    self.log_error(""CGI script exit status %#x"", sts)
                return
            # Child
            try:
                try:
                    os.setuid(nobody)
                except os.error:
                    pass
                os.dup2(self.rfile.fileno(), 0)
                os.dup2(self.wfile.fileno(), 1)
                os.execve(scriptfile, args, os.environ)
            except:
                self.server.handle_error(self.request, self.client_address)
                os._exit(127)

        elif self.have_popen2 or self.have_popen3:
            # Windows -- use popen2 or popen3 to create a subprocess
            import shutil
            if self.have_popen3:
                popenx = os.popen3
            else:
                popenx = os.popen2
            cmdline = scriptfile
            if self.is_python(scriptfile):
                interp = sys.executable
                if interp.lower().endswith(""w.exe""):
                    # On Windows, use python.exe, not pythonw.exe
                    interp = interp[:-5] + interp[-4:]
                cmdline = ""%s -u %s"" % (interp, cmdline)
            if '=' not in query and '""' not in query:
                cmdline = '%s ""%s""' % (cmdline, query)
            self.log_message(""command: %s"", cmdline)
            try:
                nbytes = int(length)
            except (TypeError, ValueError):
                nbytes = 0
            files = popenx(cmdline, 'b')
            fi = files[0]
            fo = files[1]
            if self.have_popen3:
                fe = files[2]
            if self.command.lower() == ""post"" and nbytes > 0:
                data = self.rfile.read(nbytes)
                fi.write(data)
            # throw away additional data [see bug #427345]
            while select.select([self.rfile._sock], [], [], 0)[0]:
                if not self.rfile._sock.recv(1):
                    break
            fi.close()
            shutil.copyfileobj(fo, self.wfile)
            if self.have_popen3:
                errors = fe.read()
                fe.close()
                if errors:
                    self.log_error('%s', errors)
            sts = fo.close()
            if sts:
                self.log_error(""CGI script exit status %#x"", sts)
            else:
                self.log_message(""CGI script exited OK"")

        else:
            # Other O.S. -- execute script in this process
            save_argv = sys.argv
            save_stdin = sys.stdin
            save_stdout = sys.stdout
            save_stderr = sys.stderr
            try:
                save_cwd = os.getcwd()
                try:
                    sys.argv = [scriptfile]
                    if '=' not in decoded_query:
                        sys.argv.append(decoded_query)
                    sys.stdout = self.wfile
                    sys.stdin = self.rfile
                    execfile(scriptfile, {""__name__"": ""__main__""})
                finally:
                    sys.argv = save_argv
                    sys.stdin = save_stdin
                    sys.stdout = save_stdout
                    sys.stderr = save_stderr
                    os.chdir(save_cwd)
            except SystemExit, sts:
                self.log_error(""CGI script exit status %s"", str(sts))
            else:
                self.log_message(""CGI script exited OK"")


nobody = None

def nobody_uid():
    """"""Internal routine to get nobody's uid""""""
    global nobody
    if nobody:
        return nobody
    try:
        import pwd
    except ImportError:
        return -1
    try:
        nobody = pwd.getpwnam('nobody')[2]
    except KeyError:
        nobody = 1 + max(map(lambda x: x[2], pwd.getpwall()))
    return nobody


def executable(path):
    """"""Test for executable file.""""""
    try:
        st = os.stat(path)
    except os.error:
        return False
    return st.st_mode & 0111 != 0


def test(HandlerClass = CGIHTTPRequestHandler,
         ServerClass = BaseHTTPServer.HTTPServer):
    SimpleHTTPServer.test(HandlerClass, ServerClass)


if __name__ == '__main__':
    test()
/n/n/n",1
18,18,923ba361d8f757f0656cfd216525aca4848e02aa,"Lib/CGIHTTPServer.py/n/n""""""CGI-savvy HTTP Server.

This module builds on SimpleHTTPServer by implementing GET and POST
requests to cgi-bin scripts.

If the os.fork() function is not present (e.g. on Windows),
os.popen2() is used as a fallback, with slightly altered semantics; if
that function is not present either (e.g. on Macintosh), only Python
scripts are supported, and they are executed by the current process.

In all cases, the implementation is intentionally naive -- all
requests are executed sychronously.

SECURITY WARNING: DON'T USE THIS CODE UNLESS YOU ARE INSIDE A FIREWALL
-- it may execute arbitrary Python code or external programs.

Note that status code 200 is sent prior to execution of a CGI script, so
scripts cannot send other status codes such as 302 (redirect).
""""""


__version__ = ""0.4""

__all__ = [""CGIHTTPRequestHandler""]

import os
import sys
import urllib
import BaseHTTPServer
import SimpleHTTPServer
import select


class CGIHTTPRequestHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):

    """"""Complete HTTP server with GET, HEAD and POST commands.

    GET and HEAD also support running CGI scripts.

    The POST command is *only* implemented for CGI scripts.

    """"""

    # Determine platform specifics
    have_fork = hasattr(os, 'fork')
    have_popen2 = hasattr(os, 'popen2')
    have_popen3 = hasattr(os, 'popen3')

    # Make rfile unbuffered -- we need to read one line and then pass
    # the rest to a subprocess, so we can't use buffered input.
    rbufsize = 0

    def do_POST(self):
        """"""Serve a POST request.

        This is only implemented for CGI scripts.

        """"""

        if self.is_cgi():
            self.run_cgi()
        else:
            self.send_error(501, ""Can only POST to CGI scripts"")

    def send_head(self):
        """"""Version of send_head that support CGI scripts""""""
        if self.is_cgi():
            return self.run_cgi()
        else:
            return SimpleHTTPServer.SimpleHTTPRequestHandler.send_head(self)

    def is_cgi(self):
        """"""Test whether self.path corresponds to a CGI script.

        Returns True and updates the cgi_info attribute to the tuple
        (dir, rest) if self.path requires running a CGI script.
        Returns False otherwise.

        The default implementation tests whether the normalized url
        path begins with one of the strings in self.cgi_directories
        (and the next character is a '/' or the end of the string).
        """"""
        splitpath = _url_collapse_path_split(self.path)
        if splitpath[0] in self.cgi_directories:
            self.cgi_info = splitpath
            return True
        return False

    cgi_directories = ['/cgi-bin', '/htbin']

    def is_executable(self, path):
        """"""Test whether argument path is an executable file.""""""
        return executable(path)

    def is_python(self, path):
        """"""Test whether argument path is a Python script.""""""
        head, tail = os.path.splitext(path)
        return tail.lower() in ("".py"", "".pyw"")

    def run_cgi(self):
        """"""Execute a CGI script.""""""
        path = self.path
        dir, rest = self.cgi_info

        i = path.find('/', len(dir) + 1)
        while i >= 0:
            nextdir = path[:i]
            nextrest = path[i+1:]

            scriptdir = self.translate_path(nextdir)
            if os.path.isdir(scriptdir):
                dir, rest = nextdir, nextrest
                i = path.find('/', len(dir) + 1)
            else:
                break

        # find an explicit query string, if present.
        i = rest.rfind('?')
        if i >= 0:
            rest, query = rest[:i], rest[i+1:]
        else:
            query = ''

        # dissect the part after the directory name into a script name &
        # a possible additional path, to be stored in PATH_INFO.
        i = rest.find('/')
        if i >= 0:
            script, rest = rest[:i], rest[i:]
        else:
            script, rest = rest, ''

        scriptname = dir + '/' + script
        scriptfile = self.translate_path(scriptname)
        if not os.path.exists(scriptfile):
            self.send_error(404, ""No such CGI script (%r)"" % scriptname)
            return
        if not os.path.isfile(scriptfile):
            self.send_error(403, ""CGI script is not a plain file (%r)"" %
                            scriptname)
            return
        ispy = self.is_python(scriptname)
        if not ispy:
            if not (self.have_fork or self.have_popen2 or self.have_popen3):
                self.send_error(403, ""CGI script is not a Python script (%r)"" %
                                scriptname)
                return
            if not self.is_executable(scriptfile):
                self.send_error(403, ""CGI script is not executable (%r)"" %
                                scriptname)
                return

        # Reference: http://hoohoo.ncsa.uiuc.edu/cgi/env.html
        # XXX Much of the following could be prepared ahead of time!
        env = {}
        env['SERVER_SOFTWARE'] = self.version_string()
        env['SERVER_NAME'] = self.server.server_name
        env['GATEWAY_INTERFACE'] = 'CGI/1.1'
        env['SERVER_PROTOCOL'] = self.protocol_version
        env['SERVER_PORT'] = str(self.server.server_port)
        env['REQUEST_METHOD'] = self.command
        uqrest = urllib.unquote(rest)
        env['PATH_INFO'] = uqrest
        env['PATH_TRANSLATED'] = self.translate_path(uqrest)
        env['SCRIPT_NAME'] = scriptname
        if query:
            env['QUERY_STRING'] = query
        host = self.address_string()
        if host != self.client_address[0]:
            env['REMOTE_HOST'] = host
        env['REMOTE_ADDR'] = self.client_address[0]
        authorization = self.headers.getheader(""authorization"")
        if authorization:
            authorization = authorization.split()
            if len(authorization) == 2:
                import base64, binascii
                env['AUTH_TYPE'] = authorization[0]
                if authorization[0].lower() == ""basic"":
                    try:
                        authorization = base64.decodestring(authorization[1])
                    except binascii.Error:
                        pass
                    else:
                        authorization = authorization.split(':')
                        if len(authorization) == 2:
                            env['REMOTE_USER'] = authorization[0]
        # XXX REMOTE_IDENT
        if self.headers.typeheader is None:
            env['CONTENT_TYPE'] = self.headers.type
        else:
            env['CONTENT_TYPE'] = self.headers.typeheader
        length = self.headers.getheader('content-length')
        if length:
            env['CONTENT_LENGTH'] = length
        referer = self.headers.getheader('referer')
        if referer:
            env['HTTP_REFERER'] = referer
        accept = []
        for line in self.headers.getallmatchingheaders('accept'):
            if line[:1] in ""\t\n\r "":
                accept.append(line.strip())
            else:
                accept = accept + line[7:].split(',')
        env['HTTP_ACCEPT'] = ','.join(accept)
        ua = self.headers.getheader('user-agent')
        if ua:
            env['HTTP_USER_AGENT'] = ua
        co = filter(None, self.headers.getheaders('cookie'))
        if co:
            env['HTTP_COOKIE'] = ', '.join(co)
        # XXX Other HTTP_* headers
        # Since we're setting the env in the parent, provide empty
        # values to override previously set values
        for k in ('QUERY_STRING', 'REMOTE_HOST', 'CONTENT_LENGTH',
                  'HTTP_USER_AGENT', 'HTTP_COOKIE', 'HTTP_REFERER'):
            env.setdefault(k, """")
        os.environ.update(env)

        self.send_response(200, ""Script output follows"")

        decoded_query = query.replace('+', ' ')

        if self.have_fork:
            # Unix -- fork as we should
            args = [script]
            if '=' not in decoded_query:
                args.append(decoded_query)
            nobody = nobody_uid()
            self.wfile.flush() # Always flush before forking
            pid = os.fork()
            if pid != 0:
                # Parent
                pid, sts = os.waitpid(pid, 0)
                # throw away additional data [see bug #427345]
                while select.select([self.rfile], [], [], 0)[0]:
                    if not self.rfile.read(1):
                        break
                if sts:
                    self.log_error(""CGI script exit status %#x"", sts)
                return
            # Child
            try:
                try:
                    os.setuid(nobody)
                except os.error:
                    pass
                os.dup2(self.rfile.fileno(), 0)
                os.dup2(self.wfile.fileno(), 1)
                os.execve(scriptfile, args, os.environ)
            except:
                self.server.handle_error(self.request, self.client_address)
                os._exit(127)

        elif self.have_popen2 or self.have_popen3:
            # Windows -- use popen2 or popen3 to create a subprocess
            import shutil
            if self.have_popen3:
                popenx = os.popen3
            else:
                popenx = os.popen2
            cmdline = scriptfile
            if self.is_python(scriptfile):
                interp = sys.executable
                if interp.lower().endswith(""w.exe""):
                    # On Windows, use python.exe, not pythonw.exe
                    interp = interp[:-5] + interp[-4:]
                cmdline = ""%s -u %s"" % (interp, cmdline)
            if '=' not in query and '""' not in query:
                cmdline = '%s ""%s""' % (cmdline, query)
            self.log_message(""command: %s"", cmdline)
            try:
                nbytes = int(length)
            except (TypeError, ValueError):
                nbytes = 0
            files = popenx(cmdline, 'b')
            fi = files[0]
            fo = files[1]
            if self.have_popen3:
                fe = files[2]
            if self.command.lower() == ""post"" and nbytes > 0:
                data = self.rfile.read(nbytes)
                fi.write(data)
            # throw away additional data [see bug #427345]
            while select.select([self.rfile._sock], [], [], 0)[0]:
                if not self.rfile._sock.recv(1):
                    break
            fi.close()
            shutil.copyfileobj(fo, self.wfile)
            if self.have_popen3:
                errors = fe.read()
                fe.close()
                if errors:
                    self.log_error('%s', errors)
            sts = fo.close()
            if sts:
                self.log_error(""CGI script exit status %#x"", sts)
            else:
                self.log_message(""CGI script exited OK"")

        else:
            # Other O.S. -- execute script in this process
            save_argv = sys.argv
            save_stdin = sys.stdin
            save_stdout = sys.stdout
            save_stderr = sys.stderr
            try:
                save_cwd = os.getcwd()
                try:
                    sys.argv = [scriptfile]
                    if '=' not in decoded_query:
                        sys.argv.append(decoded_query)
                    sys.stdout = self.wfile
                    sys.stdin = self.rfile
                    execfile(scriptfile, {""__name__"": ""__main__""})
                finally:
                    sys.argv = save_argv
                    sys.stdin = save_stdin
                    sys.stdout = save_stdout
                    sys.stderr = save_stderr
                    os.chdir(save_cwd)
            except SystemExit, sts:
                self.log_error(""CGI script exit status %s"", str(sts))
            else:
                self.log_message(""CGI script exited OK"")


# TODO(gregory.p.smith): Move this into an appropriate library.
def _url_collapse_path_split(path):
    """"""
    Given a URL path, remove extra '/'s and '.' path elements and collapse
    any '..' references.

    Implements something akin to RFC-2396 5.2 step 6 to parse relative paths.

    Returns: A tuple of (head, tail) where tail is everything after the final /
    and head is everything before it.  Head will always start with a '/' and,
    if it contains anything else, never have a trailing '/'.

    Raises: IndexError if too many '..' occur within the path.
    """"""
    # Similar to os.path.split(os.path.normpath(path)) but specific to URL
    # path semantics rather than local operating system semantics.
    path_parts = []
    for part in path.split('/'):
        if part == '.':
            path_parts.append('')
        else:
            path_parts.append(part)
    # Filter out blank non trailing parts before consuming the '..'.
    path_parts = [part for part in path_parts[:-1] if part] + path_parts[-1:]
    if path_parts:
        tail_part = path_parts.pop()
    else:
        tail_part = ''
    head_parts = []
    for part in path_parts:
        if part == '..':
            head_parts.pop()
        else:
            head_parts.append(part)
    if tail_part and tail_part == '..':
        head_parts.pop()
        tail_part = ''
    return ('/' + '/'.join(head_parts), tail_part)


nobody = None

def nobody_uid():
    """"""Internal routine to get nobody's uid""""""
    global nobody
    if nobody:
        return nobody
    try:
        import pwd
    except ImportError:
        return -1
    try:
        nobody = pwd.getpwnam('nobody')[2]
    except KeyError:
        nobody = 1 + max(map(lambda x: x[2], pwd.getpwall()))
    return nobody


def executable(path):
    """"""Test for executable file.""""""
    try:
        st = os.stat(path)
    except os.error:
        return False
    return st.st_mode & 0111 != 0


def test(HandlerClass = CGIHTTPRequestHandler,
         ServerClass = BaseHTTPServer.HTTPServer):
    SimpleHTTPServer.test(HandlerClass, ServerClass)


if __name__ == '__main__':
    test()
/n/n/nLib/test/test_httpservers.py/n/n""""""Unittests for the various HTTPServer modules.

Written by Cody A.W. Somerville <cody-somerville@ubuntu.com>,
Josip Dzolonga, and Michael Otteneder for the 2007/08 GHOP contest.
""""""

from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer
from SimpleHTTPServer import SimpleHTTPRequestHandler
from CGIHTTPServer import CGIHTTPRequestHandler
import CGIHTTPServer

import os
import sys
import base64
import shutil
import urllib
import httplib
import tempfile
import threading

import unittest
from test import test_support


class NoLogRequestHandler:
    def log_message(self, *args):
        # don't write log messages to stderr
        pass


class TestServerThread(threading.Thread):
    def __init__(self, test_object, request_handler):
        threading.Thread.__init__(self)
        self.request_handler = request_handler
        self.test_object = test_object
        self.test_object.lock.acquire()

    def run(self):
        self.server = HTTPServer(('', 0), self.request_handler)
        self.test_object.PORT = self.server.socket.getsockname()[1]
        self.test_object.lock.release()
        try:
            self.server.serve_forever()
        finally:
            self.server.server_close()

    def stop(self):
        self.server.shutdown()


class BaseTestCase(unittest.TestCase):
    def setUp(self):
        self.lock = threading.Lock()
        self.thread = TestServerThread(self, self.request_handler)
        self.thread.start()
        self.lock.acquire()

    def tearDown(self):
        self.lock.release()
        self.thread.stop()

    def request(self, uri, method='GET', body=None, headers={}):
        self.connection = httplib.HTTPConnection('localhost', self.PORT)
        self.connection.request(method, uri, body, headers)
        return self.connection.getresponse()


class BaseHTTPServerTestCase(BaseTestCase):
    class request_handler(NoLogRequestHandler, BaseHTTPRequestHandler):
        protocol_version = 'HTTP/1.1'
        default_request_version = 'HTTP/1.1'

        def do_TEST(self):
            self.send_response(204)
            self.send_header('Content-Type', 'text/html')
            self.send_header('Connection', 'close')
            self.end_headers()

        def do_KEEP(self):
            self.send_response(204)
            self.send_header('Content-Type', 'text/html')
            self.send_header('Connection', 'keep-alive')
            self.end_headers()

        def do_KEYERROR(self):
            self.send_error(999)

        def do_CUSTOM(self):
            self.send_response(999)
            self.send_header('Content-Type', 'text/html')
            self.send_header('Connection', 'close')
            self.end_headers()

    def setUp(self):
        BaseTestCase.setUp(self)
        self.con = httplib.HTTPConnection('localhost', self.PORT)
        self.con.connect()

    def test_command(self):
        self.con.request('GET', '/')
        res = self.con.getresponse()
        self.assertEquals(res.status, 501)

    def test_request_line_trimming(self):
        self.con._http_vsn_str = 'HTTP/1.1\n'
        self.con.putrequest('GET', '/')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 501)

    def test_version_bogus(self):
        self.con._http_vsn_str = 'FUBAR'
        self.con.putrequest('GET', '/')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 400)

    def test_version_digits(self):
        self.con._http_vsn_str = 'HTTP/9.9.9'
        self.con.putrequest('GET', '/')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 400)

    def test_version_none_get(self):
        self.con._http_vsn_str = ''
        self.con.putrequest('GET', '/')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 501)

    def test_version_none(self):
        self.con._http_vsn_str = ''
        self.con.putrequest('PUT', '/')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 400)

    def test_version_invalid(self):
        self.con._http_vsn = 99
        self.con._http_vsn_str = 'HTTP/9.9'
        self.con.putrequest('GET', '/')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 505)

    def test_send_blank(self):
        self.con._http_vsn_str = ''
        self.con.putrequest('', '')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 400)

    def test_header_close(self):
        self.con.putrequest('GET', '/')
        self.con.putheader('Connection', 'close')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 501)

    def test_head_keep_alive(self):
        self.con._http_vsn_str = 'HTTP/1.1'
        self.con.putrequest('GET', '/')
        self.con.putheader('Connection', 'keep-alive')
        self.con.endheaders()
        res = self.con.getresponse()
        self.assertEquals(res.status, 501)

    def test_handler(self):
        self.con.request('TEST', '/')
        res = self.con.getresponse()
        self.assertEquals(res.status, 204)

    def test_return_header_keep_alive(self):
        self.con.request('KEEP', '/')
        res = self.con.getresponse()
        self.assertEquals(res.getheader('Connection'), 'keep-alive')
        self.con.request('TEST', '/')

    def test_internal_key_error(self):
        self.con.request('KEYERROR', '/')
        res = self.con.getresponse()
        self.assertEquals(res.status, 999)

    def test_return_custom_status(self):
        self.con.request('CUSTOM', '/')
        res = self.con.getresponse()
        self.assertEquals(res.status, 999)


class SimpleHTTPServerTestCase(BaseTestCase):
    class request_handler(NoLogRequestHandler, SimpleHTTPRequestHandler):
        pass

    def setUp(self):
        BaseTestCase.setUp(self)
        self.cwd = os.getcwd()
        basetempdir = tempfile.gettempdir()
        os.chdir(basetempdir)
        self.data = 'We are the knights who say Ni!'
        self.tempdir = tempfile.mkdtemp(dir=basetempdir)
        self.tempdir_name = os.path.basename(self.tempdir)
        temp = open(os.path.join(self.tempdir, 'test'), 'wb')
        temp.write(self.data)
        temp.close()

    def tearDown(self):
        try:
            os.chdir(self.cwd)
            try:
                shutil.rmtree(self.tempdir)
            except:
                pass
        finally:
            BaseTestCase.tearDown(self)

    def check_status_and_reason(self, response, status, data=None):
        body = response.read()
        self.assert_(response)
        self.assertEquals(response.status, status)
        self.assert_(response.reason != None)
        if data:
            self.assertEqual(data, body)

    def test_get(self):
        #constructs the path relative to the root directory of the HTTPServer
        response = self.request(self.tempdir_name + '/test')
        self.check_status_and_reason(response, 200, data=self.data)
        response = self.request(self.tempdir_name + '/')
        self.check_status_and_reason(response, 200)
        response = self.request(self.tempdir_name)
        self.check_status_and_reason(response, 301)
        response = self.request('/ThisDoesNotExist')
        self.check_status_and_reason(response, 404)
        response = self.request('/' + 'ThisDoesNotExist' + '/')
        self.check_status_and_reason(response, 404)
        f = open(os.path.join(self.tempdir_name, 'index.html'), 'w')
        response = self.request('/' + self.tempdir_name + '/')
        self.check_status_and_reason(response, 200)
        if os.name == 'posix':
            # chmod won't work as expected on Windows platforms
            os.chmod(self.tempdir, 0)
            response = self.request(self.tempdir_name + '/')
            self.check_status_and_reason(response, 404)
            os.chmod(self.tempdir, 0755)

    def test_head(self):
        response = self.request(
            self.tempdir_name + '/test', method='HEAD')
        self.check_status_and_reason(response, 200)
        self.assertEqual(response.getheader('content-length'),
                         str(len(self.data)))
        self.assertEqual(response.getheader('content-type'),
                         'application/octet-stream')

    def test_invalid_requests(self):
        response = self.request('/', method='FOO')
        self.check_status_and_reason(response, 501)
        # requests must be case sensitive,so this should fail too
        response = self.request('/', method='get')
        self.check_status_and_reason(response, 501)
        response = self.request('/', method='GETs')
        self.check_status_and_reason(response, 501)


cgi_file1 = """"""\
#!%s

print ""Content-type: text/html""
print
print ""Hello World""
""""""

cgi_file2 = """"""\
#!%s
import cgi

print ""Content-type: text/html""
print

form = cgi.FieldStorage()
print ""%%s, %%s, %%s"" %% (form.getfirst(""spam""), form.getfirst(""eggs""),\
              form.getfirst(""bacon""))
""""""

class CGIHTTPServerTestCase(BaseTestCase):
    class request_handler(NoLogRequestHandler, CGIHTTPRequestHandler):
        pass

    def setUp(self):
        BaseTestCase.setUp(self)
        self.parent_dir = tempfile.mkdtemp()
        self.cgi_dir = os.path.join(self.parent_dir, 'cgi-bin')
        os.mkdir(self.cgi_dir)

        self.file1_path = os.path.join(self.cgi_dir, 'file1.py')
        with open(self.file1_path, 'w') as file1:
            file1.write(cgi_file1 % sys.executable)
        os.chmod(self.file1_path, 0777)

        self.file2_path = os.path.join(self.cgi_dir, 'file2.py')
        with open(self.file2_path, 'w') as file2:
            file2.write(cgi_file2 % sys.executable)
        os.chmod(self.file2_path, 0777)

        self.cwd = os.getcwd()
        os.chdir(self.parent_dir)

    def tearDown(self):
        try:
            os.chdir(self.cwd)
            os.remove(self.file1_path)
            os.remove(self.file2_path)
            os.rmdir(self.cgi_dir)
            os.rmdir(self.parent_dir)
        finally:
            BaseTestCase.tearDown(self)

    def test_url_collapse_path_split(self):
        test_vectors = {
            '': ('/', ''),
            '..': IndexError,
            '/.//..': IndexError,
            '/': ('/', ''),
            '//': ('/', ''),
            '/\\': ('/', '\\'),
            '/.//': ('/', ''),
            'cgi-bin/file1.py': ('/cgi-bin', 'file1.py'),
            '/cgi-bin/file1.py': ('/cgi-bin', 'file1.py'),
            'a': ('/', 'a'),
            '/a': ('/', 'a'),
            '//a': ('/', 'a'),
            './a': ('/', 'a'),
            './C:/': ('/C:', ''),
            '/a/b': ('/a', 'b'),
            '/a/b/': ('/a/b', ''),
            '/a/b/c/..': ('/a/b', ''),
            '/a/b/c/../d': ('/a/b', 'd'),
            '/a/b/c/../d/e/../f': ('/a/b/d', 'f'),
            '/a/b/c/../d/e/../../f': ('/a/b', 'f'),
            '/a/b/c/../d/e/.././././..//f': ('/a/b', 'f'),
            '../a/b/c/../d/e/.././././..//f': IndexError,
            '/a/b/c/../d/e/../../../f': ('/a', 'f'),
            '/a/b/c/../d/e/../../../../f': ('/', 'f'),
            '/a/b/c/../d/e/../../../../../f': IndexError,
            '/a/b/c/../d/e/../../../../f/..': ('/', ''),
        }
        for path, expected in test_vectors.iteritems():
            if isinstance(expected, type) and issubclass(expected, Exception):
                self.assertRaises(expected,
                                  CGIHTTPServer._url_collapse_path_split, path)
            else:
                actual = CGIHTTPServer._url_collapse_path_split(path)
                self.assertEquals(expected, actual,
                                  msg='path = %r\nGot:    %r\nWanted: %r' % (
                                  path, actual, expected))

    def test_headers_and_content(self):
        res = self.request('/cgi-bin/file1.py')
        self.assertEquals(('Hello World\n', 'text/html', 200), \
             (res.read(), res.getheader('Content-type'), res.status))

    def test_post(self):
        params = urllib.urlencode({'spam' : 1, 'eggs' : 'python', 'bacon' : 123456})
        headers = {'Content-type' : 'application/x-www-form-urlencoded'}
        res = self.request('/cgi-bin/file2.py', 'POST', params, headers)

        self.assertEquals(res.read(), '1, python, 123456\n')

    def test_invaliduri(self):
        res = self.request('/cgi-bin/invalid')
        res.read()
        self.assertEquals(res.status, 404)

    def test_authorization(self):
        headers = {'Authorization' : 'Basic %s' % \
                base64.b64encode('username:pass')}
        res = self.request('/cgi-bin/file1.py', 'GET', headers=headers)
        self.assertEquals(('Hello World\n', 'text/html', 200), \
             (res.read(), res.getheader('Content-type'), res.status))

    def test_no_leading_slash(self):
        # http://bugs.python.org/issue2254
        res = self.request('cgi-bin/file1.py')
        self.assertEquals(('Hello World\n', 'text/html', 200),
             (res.read(), res.getheader('Content-type'), res.status))


def test_main(verbose=None):
    try:
        cwd = os.getcwd()
        test_support.run_unittest(BaseHTTPServerTestCase,
                                  SimpleHTTPServerTestCase,
                                  CGIHTTPServerTestCase
                                  )
    finally:
        os.chdir(cwd)

if __name__ == '__main__':
    test_main()
/n/n/n",0
19,19,923ba361d8f757f0656cfd216525aca4848e02aa,"/Lib/CGIHTTPServer.py/n/n""""""CGI-savvy HTTP Server.

This module builds on SimpleHTTPServer by implementing GET and POST
requests to cgi-bin scripts.

If the os.fork() function is not present (e.g. on Windows),
os.popen2() is used as a fallback, with slightly altered semantics; if
that function is not present either (e.g. on Macintosh), only Python
scripts are supported, and they are executed by the current process.

In all cases, the implementation is intentionally naive -- all
requests are executed sychronously.

SECURITY WARNING: DON'T USE THIS CODE UNLESS YOU ARE INSIDE A FIREWALL
-- it may execute arbitrary Python code or external programs.

Note that status code 200 is sent prior to execution of a CGI script, so
scripts cannot send other status codes such as 302 (redirect).
""""""


__version__ = ""0.4""

__all__ = [""CGIHTTPRequestHandler""]

import os
import sys
import urllib
import BaseHTTPServer
import SimpleHTTPServer
import select


class CGIHTTPRequestHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):

    """"""Complete HTTP server with GET, HEAD and POST commands.

    GET and HEAD also support running CGI scripts.

    The POST command is *only* implemented for CGI scripts.

    """"""

    # Determine platform specifics
    have_fork = hasattr(os, 'fork')
    have_popen2 = hasattr(os, 'popen2')
    have_popen3 = hasattr(os, 'popen3')

    # Make rfile unbuffered -- we need to read one line and then pass
    # the rest to a subprocess, so we can't use buffered input.
    rbufsize = 0

    def do_POST(self):
        """"""Serve a POST request.

        This is only implemented for CGI scripts.

        """"""

        if self.is_cgi():
            self.run_cgi()
        else:
            self.send_error(501, ""Can only POST to CGI scripts"")

    def send_head(self):
        """"""Version of send_head that support CGI scripts""""""
        if self.is_cgi():
            return self.run_cgi()
        else:
            return SimpleHTTPServer.SimpleHTTPRequestHandler.send_head(self)

    def is_cgi(self):
        """"""Test whether self.path corresponds to a CGI script,
        and return a boolean.

        This function sets self.cgi_info to a tuple (dir, rest)
        when it returns True, where dir is the directory part before
        the CGI script name.  Note that rest begins with a
        slash if it is not empty.

        The default implementation tests whether the path
        begins with one of the strings in the list
        self.cgi_directories (and the next character is a '/'
        or the end of the string).
        """"""

        path = self.path

        for x in self.cgi_directories:
            i = len(x)
            if path[:i] == x and (not path[i:] or path[i] == '/'):
                self.cgi_info = path[:i], path[i+1:]
                return True
        return False

    cgi_directories = ['/cgi-bin', '/htbin']

    def is_executable(self, path):
        """"""Test whether argument path is an executable file.""""""
        return executable(path)

    def is_python(self, path):
        """"""Test whether argument path is a Python script.""""""
        head, tail = os.path.splitext(path)
        return tail.lower() in ("".py"", "".pyw"")

    def run_cgi(self):
        """"""Execute a CGI script.""""""
        path = self.path
        dir, rest = self.cgi_info

        i = path.find('/', len(dir) + 1)
        while i >= 0:
            nextdir = path[:i]
            nextrest = path[i+1:]

            scriptdir = self.translate_path(nextdir)
            if os.path.isdir(scriptdir):
                dir, rest = nextdir, nextrest
                i = path.find('/', len(dir) + 1)
            else:
                break

        # find an explicit query string, if present.
        i = rest.rfind('?')
        if i >= 0:
            rest, query = rest[:i], rest[i+1:]
        else:
            query = ''

        # dissect the part after the directory name into a script name &
        # a possible additional path, to be stored in PATH_INFO.
        i = rest.find('/')
        if i >= 0:
            script, rest = rest[:i], rest[i:]
        else:
            script, rest = rest, ''

        scriptname = dir + '/' + script
        scriptfile = self.translate_path(scriptname)
        if not os.path.exists(scriptfile):
            self.send_error(404, ""No such CGI script (%r)"" % scriptname)
            return
        if not os.path.isfile(scriptfile):
            self.send_error(403, ""CGI script is not a plain file (%r)"" %
                            scriptname)
            return
        ispy = self.is_python(scriptname)
        if not ispy:
            if not (self.have_fork or self.have_popen2 or self.have_popen3):
                self.send_error(403, ""CGI script is not a Python script (%r)"" %
                                scriptname)
                return
            if not self.is_executable(scriptfile):
                self.send_error(403, ""CGI script is not executable (%r)"" %
                                scriptname)
                return

        # Reference: http://hoohoo.ncsa.uiuc.edu/cgi/env.html
        # XXX Much of the following could be prepared ahead of time!
        env = {}
        env['SERVER_SOFTWARE'] = self.version_string()
        env['SERVER_NAME'] = self.server.server_name
        env['GATEWAY_INTERFACE'] = 'CGI/1.1'
        env['SERVER_PROTOCOL'] = self.protocol_version
        env['SERVER_PORT'] = str(self.server.server_port)
        env['REQUEST_METHOD'] = self.command
        uqrest = urllib.unquote(rest)
        env['PATH_INFO'] = uqrest
        env['PATH_TRANSLATED'] = self.translate_path(uqrest)
        env['SCRIPT_NAME'] = scriptname
        if query:
            env['QUERY_STRING'] = query
        host = self.address_string()
        if host != self.client_address[0]:
            env['REMOTE_HOST'] = host
        env['REMOTE_ADDR'] = self.client_address[0]
        authorization = self.headers.getheader(""authorization"")
        if authorization:
            authorization = authorization.split()
            if len(authorization) == 2:
                import base64, binascii
                env['AUTH_TYPE'] = authorization[0]
                if authorization[0].lower() == ""basic"":
                    try:
                        authorization = base64.decodestring(authorization[1])
                    except binascii.Error:
                        pass
                    else:
                        authorization = authorization.split(':')
                        if len(authorization) == 2:
                            env['REMOTE_USER'] = authorization[0]
        # XXX REMOTE_IDENT
        if self.headers.typeheader is None:
            env['CONTENT_TYPE'] = self.headers.type
        else:
            env['CONTENT_TYPE'] = self.headers.typeheader
        length = self.headers.getheader('content-length')
        if length:
            env['CONTENT_LENGTH'] = length
        referer = self.headers.getheader('referer')
        if referer:
            env['HTTP_REFERER'] = referer
        accept = []
        for line in self.headers.getallmatchingheaders('accept'):
            if line[:1] in ""\t\n\r "":
                accept.append(line.strip())
            else:
                accept = accept + line[7:].split(',')
        env['HTTP_ACCEPT'] = ','.join(accept)
        ua = self.headers.getheader('user-agent')
        if ua:
            env['HTTP_USER_AGENT'] = ua
        co = filter(None, self.headers.getheaders('cookie'))
        if co:
            env['HTTP_COOKIE'] = ', '.join(co)
        # XXX Other HTTP_* headers
        # Since we're setting the env in the parent, provide empty
        # values to override previously set values
        for k in ('QUERY_STRING', 'REMOTE_HOST', 'CONTENT_LENGTH',
                  'HTTP_USER_AGENT', 'HTTP_COOKIE', 'HTTP_REFERER'):
            env.setdefault(k, """")
        os.environ.update(env)

        self.send_response(200, ""Script output follows"")

        decoded_query = query.replace('+', ' ')

        if self.have_fork:
            # Unix -- fork as we should
            args = [script]
            if '=' not in decoded_query:
                args.append(decoded_query)
            nobody = nobody_uid()
            self.wfile.flush() # Always flush before forking
            pid = os.fork()
            if pid != 0:
                # Parent
                pid, sts = os.waitpid(pid, 0)
                # throw away additional data [see bug #427345]
                while select.select([self.rfile], [], [], 0)[0]:
                    if not self.rfile.read(1):
                        break
                if sts:
                    self.log_error(""CGI script exit status %#x"", sts)
                return
            # Child
            try:
                try:
                    os.setuid(nobody)
                except os.error:
                    pass
                os.dup2(self.rfile.fileno(), 0)
                os.dup2(self.wfile.fileno(), 1)
                os.execve(scriptfile, args, os.environ)
            except:
                self.server.handle_error(self.request, self.client_address)
                os._exit(127)

        elif self.have_popen2 or self.have_popen3:
            # Windows -- use popen2 or popen3 to create a subprocess
            import shutil
            if self.have_popen3:
                popenx = os.popen3
            else:
                popenx = os.popen2
            cmdline = scriptfile
            if self.is_python(scriptfile):
                interp = sys.executable
                if interp.lower().endswith(""w.exe""):
                    # On Windows, use python.exe, not pythonw.exe
                    interp = interp[:-5] + interp[-4:]
                cmdline = ""%s -u %s"" % (interp, cmdline)
            if '=' not in query and '""' not in query:
                cmdline = '%s ""%s""' % (cmdline, query)
            self.log_message(""command: %s"", cmdline)
            try:
                nbytes = int(length)
            except (TypeError, ValueError):
                nbytes = 0
            files = popenx(cmdline, 'b')
            fi = files[0]
            fo = files[1]
            if self.have_popen3:
                fe = files[2]
            if self.command.lower() == ""post"" and nbytes > 0:
                data = self.rfile.read(nbytes)
                fi.write(data)
            # throw away additional data [see bug #427345]
            while select.select([self.rfile._sock], [], [], 0)[0]:
                if not self.rfile._sock.recv(1):
                    break
            fi.close()
            shutil.copyfileobj(fo, self.wfile)
            if self.have_popen3:
                errors = fe.read()
                fe.close()
                if errors:
                    self.log_error('%s', errors)
            sts = fo.close()
            if sts:
                self.log_error(""CGI script exit status %#x"", sts)
            else:
                self.log_message(""CGI script exited OK"")

        else:
            # Other O.S. -- execute script in this process
            save_argv = sys.argv
            save_stdin = sys.stdin
            save_stdout = sys.stdout
            save_stderr = sys.stderr
            try:
                save_cwd = os.getcwd()
                try:
                    sys.argv = [scriptfile]
                    if '=' not in decoded_query:
                        sys.argv.append(decoded_query)
                    sys.stdout = self.wfile
                    sys.stdin = self.rfile
                    execfile(scriptfile, {""__name__"": ""__main__""})
                finally:
                    sys.argv = save_argv
                    sys.stdin = save_stdin
                    sys.stdout = save_stdout
                    sys.stderr = save_stderr
                    os.chdir(save_cwd)
            except SystemExit, sts:
                self.log_error(""CGI script exit status %s"", str(sts))
            else:
                self.log_message(""CGI script exited OK"")


nobody = None

def nobody_uid():
    """"""Internal routine to get nobody's uid""""""
    global nobody
    if nobody:
        return nobody
    try:
        import pwd
    except ImportError:
        return -1
    try:
        nobody = pwd.getpwnam('nobody')[2]
    except KeyError:
        nobody = 1 + max(map(lambda x: x[2], pwd.getpwall()))
    return nobody


def executable(path):
    """"""Test for executable file.""""""
    try:
        st = os.stat(path)
    except os.error:
        return False
    return st.st_mode & 0111 != 0


def test(HandlerClass = CGIHTTPRequestHandler,
         ServerClass = BaseHTTPServer.HTTPServer):
    SimpleHTTPServer.test(HandlerClass, ServerClass)


if __name__ == '__main__':
    test()
/n/n/n",1
148,148,3f7c7442fa49aec37577dbdb47ce11a848e7bd03,"MeTal/core/utils.py/n/nimport urllib, re, html

from settings import (MAX_BASENAME_LENGTH, ITEMS_PER_PAGE,
    PASSWORD_KEY, SECRET_KEY, BASE_URL, BASE_URL_ROOT)

from core.libs.bottle import redirect, response

import hashlib, base64

from core.libs.bottle import _stderr

DATE_FORMAT = '%Y-%m-%d %H:%M:%S'

def default(obj):
    import datetime
    if isinstance(obj, datetime.datetime):
        return datetime.datetime.strftime(obj, '%Y-%m-%d %H:%M:%S')

def json_dump(obj):
    import json
    from core.libs.playhouse.shortcuts import model_to_dict
    # we have to do this as a way to keep dates from choking
    return json.loads(json.dumps(model_to_dict(obj, recurse=False),
            default=default,
            separators=(', ', ': '),
            indent=1))

def field_error(e):
    _ = re.compile('UNIQUE constraint failed: (.*)$')
    m = _.match(str(e))
    error = {'blog.local_path':'''
The file path for this blog is the same as another blog in this system.
File paths must be unique.
''', 'blog.url':'''
The URL for this blog is the same as another blog in this system.
URLs for blogs must be unique.
'''}[m.group(1)]
    return error

def quote_escape(string):
    string = string.replace(""'"", ""&#39"")
    string = string.replace('""', ""&#34"")
    return string

def preview_file(identifier, extension):
    file_identifier = ""preview-{}"".format(identifier)
    import zlib
    return ('preview-' +
        str(zlib.crc32(file_identifier.encode('utf-8'), 0xFFFF)) +
        ""."" + extension)

def preview_file_old(filename, extension):
    import zlib
    try:
        split_path = filename.rsplit('/', 1)[1]
    except IndexError:
        split_path = filename
    return ('preview-' +
        str(zlib.crc32(split_path.encode('utf-8'), 0xFFFF)) +
        ""."" + extension)

def verify_path(path):
    '''
    Stub function to ensure a given path
    a) exists
    b) is writable
    c) is not on top of a path used by the application
    '''

    # verify the path exists
    # verify that it is writable
    # verify it is not within the application directory

    pass

def is_blank(string):
    if string and string.strip():
        return False
    return True

def url_escape(url):
    return urllib.parse.quote_plus(url)

def url_unescape(url):
    return urllib.parse.unquote_plus(url)

def safe_redirect(url):
    url_unquoted = urllib.parse.unquote_plus(url)
    if url_unquoted.startswith(BASE_URL + ""/""):
        redirect(url)
    else:
        redirect(BASE_URL)

def _stddebug_():
    from core.boot import settings
    _stddebug = lambda x: _stderr(x) if (settings.DEBUG_MODE is True) else lambda x: None  # @UnusedVariable
    return _stddebug

class Status:
    '''
    Used to create status messages for AJAX UI.
    '''
    status_types = {'success':'ok-sign',
        'info':'info-sign',
        'warning':'exclamation-sign',
        'danger':'remove-sign'}

    def __init__(self, **ka):

        self.type = ka['type']
        if 'vals' in ka:
            formatting = list(map(html_escape, ka['vals']))
            self.message = ka['message'].format(*formatting)
        else:
            self.message = ka['message']

        if self.type not in ('success', 'info') and 'no_sure' not in ka:
            self.message += ""<p><b>Are you sure you want to do this?</b></p>""


        if self.type in self.status_types:
            self.icon = self.status_types[self.type]

        self.confirm = ka.get('yes', None)
        self.deny = ka.get('no', None)

        self.action = ka.get('action', None)
        self.url = ka.get('url', None)

        self.message_list = ka.get('message_list', None)
        self.close = ka.get('close', True)


def logout_nonce(user):
    return csrf_hash(str(user.id) + str(user.last_login) + 'LOGOUT')

def csrf_hash(csrf):
    '''
    Generates a CSRF token value, by taking an input and generating a SHA-256 hash from it,
    in conjunction with the secret key set for the installation.
    '''

    enc = str(csrf) + SECRET_KEY

    m = hashlib.sha256()
    m.update(enc.encode('utf-8'))
    m = m.digest()
    encrypted_csrf = base64.b64encode(m).decode('utf-8')

    return (encrypted_csrf)

def csrf_tag(csrf):
    '''
    Generates a hidden input field used to carry the CSRF token for form submissions.
    '''
    return ""<input type='hidden' name='csrf' id='csrf' value='{}'>"".format(csrf_hash(csrf))

def string_to_date(date_string):
    import datetime
    return datetime.datetime.strptime(date_string, DATE_FORMAT)

def date_format(date_time):
    '''
    Formats a datetime value in a consistent way for presentation.
    '%Y-%m-%d %H:%M:%S' is the standard format.
    '''
    if date_time is None:
        return ''
    else:
        return date_time.strftime(DATE_FORMAT)


def utf8_escape(input_string):
    '''
    Used for cross-converting a string to encoded UTF8;
    for instance, for database submissions,
    '''
    return bytes(input_string, 'iso-8859-1').decode('utf-8')

def html_escape(input_string):
    '''
    Used for returning text from the server that might have HTML that needs escaping,
    such as a status message that might have spurious HTML in it (e.g., a page title).
    '''
    return html.escape(str(input_string))

def create_basename_core(basename):
    try:
        basename = basename.casefold()
    except Exception:
        basename = basename.lower()

    basename = re.sub(r'[ \./]', r'-', basename)
    basename = re.sub(r'<[^>]*>', r'', basename)
    basename = re.sub(r'[^a-z0-9\-]', r'', basename)
    basename = re.sub(r'\-\-', r'-', basename)
    basename = urllib.parse.quote_plus(basename)

    return basename

def create_basename(input_string, blog):
    '''
    Generate a basename from a given input string.

    Checks across the entire blog in question for a basename collision.

    Basenames need to be unique to the filesystem for where the target files
    are to be written. By default this is enforced in the database by way of a
    unique column constraint.
    '''

    if not input_string:
        input_string = ""page""

    basename = input_string
    basename_test = create_basename_core(basename)

    from core.models import Page

    n = 0

    while True:

        try:
            Page.get(Page.basename == basename_test,
                Page.blog == blog)
        except Page.DoesNotExist:
            return (basename_test[:MAX_BASENAME_LENGTH])

        n += 1
        basename_test = basename + ""-"" + str(n)

def trunc(string, length=128):
    '''
    Truncates a string with ellipses.
    This function may eventually be replaced with a CSS-based approach.
    '''
    if string is None:
        return """"
    string = (string[:length] + ' ...') if len(string) > length else string
    return string

breaks_list = ['/', '.', '-', '_']

def breaks(string):
    '''
    Used to break up URLs and basenames so they wrap properly
    '''
    if string is None:
        return string

    for n in breaks_list:
        string = string.replace(n, n + '<wbr>')

    return string

def tpl_oneline(string):

    if string[0] == '%':
        string = '\\' + string

    return string

def tpl_include(tpl):
    # get absolute path for template relative to blog root
    # get default mapping
    # prepend /? do we need to have those in the mapping?
    return '<!--#include virtual=""{}"" -->'.format(
        tpl)

from core.libs.bottle import SimpleTemplate
class MetalTemplate(SimpleTemplate):
    includes = []
    def __init__(self, *args, **kwargs):
        super(MetalTemplate, self).__init__(*args, **kwargs)
        self._tags = kwargs.get('tags', None)

    def _include(self, env, _name=None, **kwargs):
        from core.models import Template
        template_to_import = Template.get(
            Template.blog == self._tags.get('blog', None),
            Template.title == _name)
        tpl = MetalTemplate(template_to_import.body, tags=self._tags)
        self.includes.append(_name)
        return tpl.execute(env['_stdout'], env)
    def render(self, *args, **kwargs):
        return super(MetalTemplate, self).render(*args, **kwargs)

def tpl(*args, **ka):
    '''
    Shim for the template function to force it to use a string that might be
    ambiguously a filename.
    '''
    # TODO: debug handler for errors in submitted user templates here?
    tp = MetalTemplate('\n' + args[0], tags=ka)
    x = tp.render(ka)
    return x[1:]

tp_cache = {}

def tpl2(template, **ka):
    try:
        template_to_render = tp_cache[template.blog.id][template.id]
    except KeyError:
        template_to_render = MetalTemplate('\n' + template.body, tags=ka)
        tp_cache[template.blog.id][template.id] = template_to_render
    x = template_to_render.render(ka)
    return x[1:]


def generate_paginator(obj, request, items_per_page=ITEMS_PER_PAGE):

    '''
    Generates a paginator block for browsing lists, for instance in the blog or site view.
    '''
    page_num = page_list_id(request)

    paginator = {}

    paginator['page_count'] = obj.count()

    paginator['max_pages'] = int((paginator['page_count'] / items_per_page) + (paginator['page_count'] % items_per_page > 0))

    if page_num > paginator['max_pages']:
        page_num = paginator['max_pages']

    paginator['next_page'] = (page_num + 1) if page_num < paginator['max_pages'] else paginator['max_pages']
    paginator['prev_page'] = (page_num - 1) if page_num > 1 else 1

    paginator['first_item'] = (page_num * items_per_page) - (items_per_page - 1)
    paginator['last_item'] = paginator['page_count'] if (page_num * items_per_page) > paginator['page_count'] else (page_num * items_per_page)

    paginator['page_num'] = page_num
    paginator['items_per_page'] = items_per_page

    obj_list = obj.paginate(page_num, ITEMS_PER_PAGE)

    return paginator, obj_list



def generate_date_mapping(date_value, tags, path_string):
    '''
    Generates a date mapping string, usually from a template mapping,
    using a date value, a tag set, and the supplied path string.
    This is often used for resolving template mappings.
    The tag set is contextual -- e.g., for a blog or a site.
    '''

    time_string = date_value.strftime(path_string)
    path_string = tpl(time_string, **tags.__dict__)

    return path_string

def postpone(function):
    '''
    Thread launcher function
    '''
    def decorator(*args, **ka):
        t = Thread(target=function, args=args, kwargs=ka)
        t.daemon = True
        t.start()

    return decorator


def encrypt_password(password, key=None):

    if key is None:
        p_key = PASSWORD_KEY
    else:
        p_key = key

    bin_password = password.encode('utf-8')
    bin_salt = p_key.encode('utf-8')

    m = hashlib.sha256()
    for n in range(1, 1000):
        m.update(bin_password + bin_salt)
    m = m.digest()
    encrypted_password = base64.b64encode(m)

    return encrypted_password

def memoize(f):
    '''
    Memoization decorator for a function taking one or more arguments.
    '''
    # pinched from http://code.activestate.com/recipes/578231-probably-the-fastest-memoization-decorator-in-the-/
    class memodict(dict):
        def __getitem__(self, *key):
            return dict.__getitem__(self, key)

        def __missing__(self, key):
            ret = self[key] = f(*key)
            return ret

    return memodict().__getitem__

def memoize_delete(obj, item):
    obj.__self__.__delitem__(item)

def _iter(item):
    try:
        (x for x in item)
    except BaseException:
        return (item,)
    else:
        return item


def page_list_id(request):

    if not request.query.page:
        return 1
    try:
        page = int(request.query.page)
    except ValueError:
        return 1
    return page


def raise_request_limit():
    from core.libs import bottle
    import settings
    bottle.BaseRequest.MEMFILE_MAX = settings.MAX_REQUEST

def disable_protection():
    response.set_header('Frame-Options', '')
    # response.set_header('Content-Security-Policy', '')

def action_button(label, url):
    action = ""<a href='{}'><button type='button' class='btn btn-sm'>{}</button></a>"".format(
        url,
        label
        )

    return action
/n/n/n",0
149,149,3f7c7442fa49aec37577dbdb47ce11a848e7bd03,"/MeTal/core/utils.py/n/nimport urllib, re, html

from settings import (MAX_BASENAME_LENGTH, ITEMS_PER_PAGE,
    PASSWORD_KEY, SECRET_KEY, BASE_URL, BASE_URL_ROOT)

from core.libs.bottle import redirect, response

import hashlib, base64

from core.libs.bottle import _stderr

DATE_FORMAT = '%Y-%m-%d %H:%M:%S'

def default(obj):
    import datetime
    if isinstance(obj, datetime.datetime):
        return datetime.datetime.strftime(obj, '%Y-%m-%d %H:%M:%S')

def json_dump(obj):
    import json
    from core.libs.playhouse.shortcuts import model_to_dict
    # we have to do this as a way to keep dates from choking
    return json.loads(json.dumps(model_to_dict(obj, recurse=False),
            default=default,
            separators=(', ', ': '),
            indent=1))

def field_error(e):
    _ = re.compile('UNIQUE constraint failed: (.*)$')
    m = _.match(str(e))
    error = {'blog.local_path':'''
The file path for this blog is the same as another blog in this system.
File paths must be unique.
''', 'blog.url':'''
The URL for this blog is the same as another blog in this system.
URLs for blogs must be unique.
'''}[m.group(1)]
    return error

def quote_escape(string):
    string = string.replace(""'"", ""&#39"")
    string = string.replace('""', ""&#34"")
    return string

def preview_file(identifier, extension):
    file_identifier = ""preview-{}"".format(identifier)
    import zlib
    return ('preview-' +
        str(zlib.crc32(file_identifier.encode('utf-8'), 0xFFFF)) +
        ""."" + extension)

def preview_file_old(filename, extension):
    import zlib
    try:
        split_path = filename.rsplit('/', 1)[1]
    except IndexError:
        split_path = filename
    return ('preview-' +
        str(zlib.crc32(split_path.encode('utf-8'), 0xFFFF)) +
        ""."" + extension)

def verify_path(path):
    '''
    Stub function to ensure a given path
    a) exists
    b) is writable
    c) is not on top of a path used by the application
    '''

    # verify the path exists
    # verify that it is writable
    # verify it is not within the application directory

    pass

def is_blank(string):
    if string and string.strip():
        return False
    return True

def url_escape(url):
    return urllib.parse.quote_plus(url)

def url_unescape(url):
    return urllib.parse.unquote_plus(url)

def safe_redirect(url):
    url_unquoted = urllib.parse.unquote_plus(url)
    if url_unquoted.startswith(BASE_URL + ""/""):
        redirect(url)
    else:
        redirect(BASE_URL)

def _stddebug_():
    from core.boot import settings
    _stddebug = lambda x: _stderr(x) if (settings.DEBUG_MODE is True) else lambda x: None  # @UnusedVariable
    return _stddebug

class Status:
    '''
    Used to create status messages for AJAX UI.
    '''
    status_types = {'success':'ok-sign',
        'info':'info-sign',
        'warning':'exclamation-sign',
        'danger':'remove-sign'}

    def __init__(self, **ka):

        self.type = ka['type']
        if 'vals' in ka:
            formatting = list(map(html_escape, ka['vals']))
            self.message = ka['message'].format(*formatting)
        else:
            self.message = ka['message']

        if self.type not in ('success', 'info') and 'no_sure' not in ka:
            self.message += ""<p><b>Are you sure you want to do this?</b></p>""


        if self.type in self.status_types:
            self.icon = self.status_types[self.type]

        self.confirm = ka.get('yes', None)
        self.deny = ka.get('no', None)

        self.action = ka.get('action', None)
        self.url = ka.get('url', None)

        self.message_list = ka.get('message_list', None)
        self.close = ka.get('close', True)


def logout_nonce(user):
    return csrf_hash(str(user.id) + str(user.last_login) + 'LOGOUT')

def csrf_hash(csrf):
    '''
    Generates a CSRF token value, by taking an input and generating a SHA-256 hash from it,
    in conjunction with the secret key set for the installation.
    '''

    enc = str(csrf) + SECRET_KEY

    m = hashlib.sha256()
    m.update(enc.encode('utf-8'))
    m = m.digest()
    encrypted_csrf = base64.b64encode(m).decode('utf-8')

    return (encrypted_csrf)

def csrf_tag(csrf):
    '''
    Generates a hidden input field used to carry the CSRF token for form submissions.
    '''
    return ""<input type='hidden' name='csrf' id='csrf' value='{}'>"".format(csrf_hash(csrf))

def string_to_date(date_string):
    import datetime
    return datetime.datetime.strptime(date_string, DATE_FORMAT)

def date_format(date_time):
    '''
    Formats a datetime value in a consistent way for presentation.
    '%Y-%m-%d %H:%M:%S' is the standard format.
    '''
    if date_time is None:
        return ''
    else:
        return date_time.strftime(DATE_FORMAT)


def utf8_escape(input_string):
    '''
    Used for cross-converting a string to encoded UTF8;
    for instance, for database submissions,
    '''
    return bytes(input_string, 'iso-8859-1').decode('utf-8')

def html_escape(input_string):
    '''
    Used for returning text from the server that might have HTML that needs escaping,
    such as a status message that might have spurious HTML in it (e.g., a page title).
    '''
    return html.escape(str(input_string))

def create_basename_core(basename):
    try:
        basename = basename.casefold()
    except Exception:
        basename = basename.lower()

    basename = basename.replace(' ', '-')
    basename = re.sub(r'<[^>]*>', r'', basename)
    basename = re.sub(r'[^a-z0-9\-]', r'', basename)
    basename = re.sub(r'\-\-', r'-', basename)
    basename = urllib.parse.quote_plus(basename)

    return basename

def create_basename(input_string, blog):
    '''
    Generate a basename from a given input string.

    Checks across the entire blog in question for a basename collision.

    Basenames need to be unique to the filesystem for where the target files
    are to be written. By default this is enforced in the database by way of a
    unique column constraint.
    '''

    if not input_string:
        input_string = ""page""

    basename = input_string
    basename_test = create_basename_core(basename)

    from core.models import Page

    n = 0

    while True:

        try:
            Page.get(Page.basename == basename_test,
                Page.blog == blog)
        except Page.DoesNotExist:
            return (basename_test[:MAX_BASENAME_LENGTH])

        n += 1
        basename_test = basename + ""-"" + str(n)

def trunc(string, length=128):
    '''
    Truncates a string with ellipses.
    This function may eventually be replaced with a CSS-based approach.
    '''
    if string is None:
        return """"
    string = (string[:length] + ' ...') if len(string) > length else string
    return string

breaks_list = ['/', '.', '-', '_']

def breaks(string):
    '''
    Used to break up URLs and basenames so they wrap properly
    '''
    if string is None:
        return string

    for n in breaks_list:
        string = string.replace(n, n + '<wbr>')

    return string

def tpl_oneline(string):

    if string[0] == '%':
        string = '\\' + string

    return string

def tpl_include(tpl):
    # get absolute path for template relative to blog root
    # get default mapping
    # prepend /? do we need to have those in the mapping?
    return '<!--#include virtual=""{}"" -->'.format(
        tpl)

from core.libs.bottle import SimpleTemplate
class MetalTemplate(SimpleTemplate):
    includes = []
    def __init__(self, *args, **kwargs):
        super(MetalTemplate, self).__init__(*args, **kwargs)
        self._tags = kwargs.get('tags', None)

    def _include(self, env, _name=None, **kwargs):
        from core.models import Template
        template_to_import = Template.get(
            Template.blog == self._tags.get('blog', None),
            Template.title == _name)
        tpl = MetalTemplate(template_to_import.body, tags=self._tags)
        self.includes.append(_name)
        return tpl.execute(env['_stdout'], env)
    def render(self, *args, **kwargs):
        return super(MetalTemplate, self).render(*args, **kwargs)

def tpl(*args, **ka):
    '''
    Shim for the template function to force it to use a string that might be
    ambiguously a filename.
    '''
    # TODO: debug handler for errors in submitted user templates here?
    tp = MetalTemplate('\n' + args[0], tags=ka)
    x = tp.render(ka)
    return x[1:]

tp_cache = {}

def tpl2(template, **ka):
    try:
        template_to_render = tp_cache[template.blog.id][template.id]
    except KeyError:
        template_to_render = MetalTemplate('\n' + template.body, tags=ka)
        tp_cache[template.blog.id][template.id] = template_to_render
    x = template_to_render.render(ka)
    return x[1:]


def generate_paginator(obj, request, items_per_page=ITEMS_PER_PAGE):

    '''
    Generates a paginator block for browsing lists, for instance in the blog or site view.
    '''
    page_num = page_list_id(request)

    paginator = {}

    paginator['page_count'] = obj.count()

    paginator['max_pages'] = int((paginator['page_count'] / items_per_page) + (paginator['page_count'] % items_per_page > 0))

    if page_num > paginator['max_pages']:
        page_num = paginator['max_pages']

    paginator['next_page'] = (page_num + 1) if page_num < paginator['max_pages'] else paginator['max_pages']
    paginator['prev_page'] = (page_num - 1) if page_num > 1 else 1

    paginator['first_item'] = (page_num * items_per_page) - (items_per_page - 1)
    paginator['last_item'] = paginator['page_count'] if (page_num * items_per_page) > paginator['page_count'] else (page_num * items_per_page)

    paginator['page_num'] = page_num
    paginator['items_per_page'] = items_per_page

    obj_list = obj.paginate(page_num, ITEMS_PER_PAGE)

    return paginator, obj_list



def generate_date_mapping(date_value, tags, path_string):
    '''
    Generates a date mapping string, usually from a template mapping,
    using a date value, a tag set, and the supplied path string.
    This is often used for resolving template mappings.
    The tag set is contextual -- e.g., for a blog or a site.
    '''

    time_string = date_value.strftime(path_string)
    path_string = tpl(time_string, **tags.__dict__)

    return path_string

def postpone(function):
    '''
    Thread launcher function
    '''
    def decorator(*args, **ka):
        t = Thread(target=function, args=args, kwargs=ka)
        t.daemon = True
        t.start()

    return decorator


def encrypt_password(password, key=None):

    if key is None:
        p_key = PASSWORD_KEY
    else:
        p_key = key

    bin_password = password.encode('utf-8')
    bin_salt = p_key.encode('utf-8')

    m = hashlib.sha256()
    for n in range(1, 1000):
        m.update(bin_password + bin_salt)
    m = m.digest()
    encrypted_password = base64.b64encode(m)

    return encrypted_password

def memoize(f):
    '''
    Memoization decorator for a function taking one or more arguments.
    '''
    # pinched from http://code.activestate.com/recipes/578231-probably-the-fastest-memoization-decorator-in-the-/
    class memodict(dict):
        def __getitem__(self, *key):
            return dict.__getitem__(self, key)

        def __missing__(self, key):
            ret = self[key] = f(*key)
            return ret

    return memodict().__getitem__

def memoize_delete(obj, item):
    obj.__self__.__delitem__(item)

def _iter(item):
    try:
        (x for x in item)
    except BaseException:
        return (item,)
    else:
        return item


def page_list_id(request):

    if not request.query.page:
        return 1
    try:
        page = int(request.query.page)
    except ValueError:
        return 1
    return page


def raise_request_limit():
    from core.libs import bottle
    import settings
    bottle.BaseRequest.MEMFILE_MAX = settings.MAX_REQUEST

def disable_protection():
    response.set_header('Frame-Options', '')
    # response.set_header('Content-Security-Policy', '')

def action_button(label, url):
    action = ""<a href='{}'><button type='button' class='btn btn-sm'>{}</button></a>"".format(
        url,
        label
        )

    return action
/n/n/n",1
150,150,10e70875b059602c3117cc40a75a980b5e88edc5,"dirb/ds.py/n/n#####################################################################
#
# Copyright 2015 Mayur Patel
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License. 
# 
#####################################################################

from . import pathexpr
from . import attrexpr
from . import ugoexpr

from . import fs

import copy
import collections
import itertools
import os
import glob



# A directory structure object:
#
# (1) has a schema,
# A set of rules which outline the tree-structure for the file system.
# One rule must be called ""ROOT"", but traversal can begin from anywhere
# and from any rule.
#
# (3) has collections, which connect with metadata
# It is handy to use collections as part of the directory structure,
# for example, to be able to use a departments list as a parameter
# for work area or publish area builds.
#
# (2) has globals, which are attributes that do not vary per-location.
#
#
# A directory location 
#   has an optional bookmark definition, which implicitly a parameterization by which the bookmark can be found.
#       in some ways, an bookmark is really just a special attribute tag.  
#       A bookmark can appear in different places, meaning that it can have multiple parameterizations
#       a bookmark is not inherited
#   has attributes, which can either be inherited down or not. (treeattribute, localattribute)
#   might be parameterized or not. a parameter is either unrestricted or restricted to a selection from a collection and
#   has a default owner and permissions.  The owner could be parameterized.
#
# Directory locations are stacked into rules as much as possible:
#   reduces the complexity of many kinds of structure schemas
#   allows optimizations to be placed strategically.
#   allows us to keep most of the directory structure as an explicit map/list,
#      converting on the absolutely bare essentials into additional complexity.
#
# Directory structure is meant to be flexible but not DYNAMIC!
#      You might want to change it a couple times a year, but not every day
#
# Need to resolve ambiguous paths by being strict with search order.
#     ""fixed"" directories should be listed first, in the reference list.
#     parameterized directories should be listed last (and ideally, there's only one!)
#




# before being compiled:
""""""

{
  
  'collections' : {
    },
    
  'globals' : {},
  
  'rules' : {
  
    'ROOT' : [
        ['multiple', { 
            'key' : 'department'
            'bookmarks' : ['workarea'],
            'localattributes' : {},
            'treeattributes' : {},
            'user' : '(parameter user)',
            'group' : 'vfx',
            'permissions' : 'rwxr-xr-x' 
         }],
        
        ['directory', {
           'name' : 'value'
         }]
      
      ],
    
    'alternative' : [
      ],
    
    'rule2' : [
      ]
    }
}

""""""

""""""
a rule is a list of directory levels.
a compiled rule has:
   a set of bookmarks under it
   a set of parameters under it
   a set of attributes under it

Directory level types:
  fixed : one or more fixed names, not parameterized
     fields : bookmarks, local attrs, tree attrs, name, user, group, permissions
  branch : redirects to one or more other rules, IN ORDER, no special attributes of its own
     fields: rules
  parameterized : any number of parameterized directories, there is one key and potentially many values.
     fields : bookmarks, local attrs, tree attrs, key, collection, user group, permissions
     if there is an collection attribute, then the values are restricted.
  regex : can represent zero or more parameters, as defined by the groups in the expression.  Also good when
     there is a prefix or suffix or restrictions on the character set.
     fields: bookmarks, local attrs, tree attrs, pattern, collections, user, group, permissions
     regex is TODO
""""""

FnLevel = {} # use of a singleton impairs ability to run multi-threaded, locks should be placed inside the level methods that need them.

# we use a class decorator here, instead of metaclasses for example,
# because what we really want is a dictionary of class instances (singletons actually),
# not some dictionary of classes, or other kind of class manipulation.
def register_level( cls ) :
  FnLevel[cls.__name__] = cls()
  return cls


class BaseLevel(object):
  def __init__(self):
    pass
  
  def validate( self, levelfields, path_list, client ): # for use during compile (?)
    return True
  
  def get_directories( self, levelctx, levelfields, searcher, ctxlist, client ):
    return []
  
  def get_bookmarks( self, levelfields, doc ): # used during compile
    return set(levelfields['bookmarks'] if 'bookmarks' in levelfields else [])
  
  def get_attributes( self, levelfields, doc ): # used during compile
    keys = levelfields['localattributes'].keys() if 'localattributes' in levelfields else []
    keys.extend( levelfields['treeattributes'].keys() if 'treeattributes' in levelfields else [] )
    return set( keys )
    
  def get_parameters( self, levelfields, doc ): # used during compile
    return set([levelfields['key']] if 'key' in levelfields else [])



@register_level
class FixedLevel(BaseLevel) :
  def __init__(self):
    BaseLevel.__init__(self) # can't use super() because we instance the class before definition is complete!
  
  def get_directories( self, levelctx, levelfields, searcher, ctxlist, client ):
    candidates = [(x, os.path.join(x.path, levelfields['name'])) for x in ctxlist]
    if searcher.do_existing_paths() :
      candidates = [(x, y) for x, y in candidates if os.path.isdir(y)]
    return candidates
    
  def get_parameters( self, levelfields, doc ): # used during compile
    return set()
  
@register_level
class BranchLevel(BaseLevel) :
  def __init__(self):
   BaseLevel.__init__(self) # can't use super() because we instance the class before definition is complete!
  
  def get_directories( self, levelctx, levelfields, searcher, ctxlist, client):
    rulenames = levelfields['rules']
    for rulename, ctx in itertools.product( rulenames, ctxlist ) :
      rule = client.get_rule( rulename )
      _traverse( searcher, rule, ctx, client ) # indirect recursion
    return None
  
  def get_bookmarks( self, levelfields, doc ):
    bookmarks = set()
    rulenames = levelfields['rules']
    for rulename in rulenames :
      rule = doc['rules'][ rulename ]
      bookmarks |= get_rule_bookmarks(rule,doc)
    return bookmarks
  
  def get_attributes( self, levelfields, doc ):
    attributes = set()
    rulenames = levelfields['rules']
    for rulename in rulenames :
      rule = doc['rules'][ rulename ]
      attributes |= get_rule_attributes(rule,doc)
    return attributes
    
  def get_parameters( self, levelfields, doc ):
    parameters = set()
    rulenames = levelfields['rules']
    for rulename in rulenames :
      rule = doc['rules'][ rulename ]
      parameters |= get_rule_parameters(rule,doc)
    return parameters



@register_level
class ParameterizedLevel(BaseLevel) :
  def __init__(self):
    BaseLevel.__init__(self) # can't use super() because we instance the class before definition is complete!
  
  def get_directories( self, levelctx, levelfields, searcher, ctxlist, client ):
    doexisting = searcher.do_existing_paths()
    dirlist = []
    
    if doexisting :
      
      for ictx in ctxlist:
        ctxdirs = glob.glob( os.path.join( ictx.path, '*' ))
        ctxdirs = ( x for x in ctxdirs if os.path.isdir( x ))
        
        if 'collection' in levelfields:
          coll = client.get_collection( levelfields['collection'] )
          ctxdirs = ( x for x in ctxdirs if os.path.split(x)[-1] in coll )
          
        dirlist.extend( (ictx, x) for x in ctxdirs )
      
    else:
      
      values = []
      if 'key' in levelfields:
        search_param = searcher.get_parameters(levelfields['key'], levelctx, ctxlist)
        if search_param:
          values.extend( x for x in search_param if x ) # eliminate None values
          
      if 'collection' in levelfields:
        coll = client.get_collection( levelfields['collection'] )
        bad_values = [x for x in values if x not in coll]
        if bad_values:
          raise KeyError( ""Collection '%s' does not contain %s"" % (levelfields['collection'], ','.join(""'%s'"" % x for x in bad_values)))
      
      for ctx, value in itertools.product( ctxlist, values ):
        dirlist.append((ctx, os.path.join( ctx.path, value )))
          
    return dirlist 
  
# -----------

def get_rule_bookmarks( levellist, doc ) : # used during compile
  ret = set()
  for level in levellist:
    leveltype = level[0]
    levelfields = level[1]
    ret |= FnLevel[leveltype].get_bookmarks( levelfields, doc)
  return ret
  
def get_rule_attributes( levellist, doc ): # used during compile
  ret = set()
  for level in levellist:
    leveltype = level[0]
    levelfields = level[1]
    ret |= FnLevel[leveltype].get_attributes( levelfields, doc)
  return ret

def get_rule_parameters( levellist, doc ): # used during compile
  ret = set()
  for level in levellist:
    leveltype = level[0]
    levelfields = level[1]
    ret |= FnLevel[leveltype].get_parameters( levelfields, doc)
  return ret  




RuleTraversalContext = collections.namedtuple( ""RuleTraversalContext"", (""bookmarks"", ""attributes"", ""parameters"")) # elements of levels contained
PathTraversalContext = collections.namedtuple( ""PathTraversalContext"", ( ""bookmarks"", ""attributes"", ""parameters"", ""path"", ""collections"", ""user"", ""group"", ""permissions"") ) # includes attrs and params from current level
LevelTraversalContext = collections.namedtuple( ""LevelTraversalContext"", ( ""bookmarks"", ""treeattributes"", ""localattributes"", ""parameter"", ""collection"", ""user"", ""group"", ""permissions"" )) # elements of current level only



def _traverse( searcher, rule, ctx, client ):
  if searcher.does_intersect_rule( RuleTraversalContext( rule['bookmarks'], rule['attributes'], rule['parameters'] ) ):
    
    pathlist = [ctx]
    for leveltype, levelfields in rule[ 'levels' ]:
      
      # create new level context:
      levelbookmarks = levelfields['bookmarks'] if 'bookmarks' in levelfields else []
      leveltreeattr = levelfields['treeattributes'] if 'treeattributes' in levelfields else {}
      levellocalattr = levelfields['localattributes'] if 'localattributes' in levelfields else {}
      levelparameter = levelfields['key'] if 'key' in levelfields else None
      levelcollection = levelfields['collection'] if 'collection' in levelfields else None
      leveluser = levelfields['user'] if 'user' in levelfields else None
      levelgroup = levelfields['group'] if 'group' in levelfields else None
      levelpermissions = levelfields['permissions'] if 'permissions' in levelfields else None
      
      levelctx = LevelTraversalContext( levelbookmarks, leveltreeattr, levellocalattr, levelparameter, levelcollection, leveluser, levelgroup, levelpermissions )
      
      # get directories for this level
      ruletuples = FnLevel[ leveltype ].get_directories( levelctx, levelfields, searcher, pathlist, client )
      
      if not ruletuples:
        break # end for
      
      passedlist = []
      for ictx, dirname in ruletuples: # breadth-first search with pruning

        treeattr = ictx.attributes.copy() # shallow
        if 'treeattributes' in levelfields:
          treeattr.update( leveltreeattr )
          
        localattr = treeattr.copy() # shallow
        if 'localattributes' in levelfields:
          localattr.update( levellocalattr )
          
        parameters = ictx.parameters.copy() # shallow
        collections = ictx.collections.copy() # shallow
        if levelparameter :
          basename = os.path.basename( dirname )
          parameters[ levelparameter ] = basename
          if levelcollection:
            collections[ levelparameter ] = levelcollection
            
        user = attrexpr.eval_attribute_expr( leveluser, localattr, parameters ) if leveluser else ictx.user
        group = attrexpr.eval_attribute_expr( levelgroup, localattr, parameters ) if levelgroup else ictx.group
        permissions = ugoexpr.eval_ugo_expr( levelpermissions ) if levelpermissions else ictx.permissions
        
        newctx = PathTraversalContext( levelbookmarks, localattr, parameters, dirname, collections, user, group, permissions )
        test = searcher.does_intersect_path( newctx )
        if test:
          searcher.test( newctx, levelctx )
          newctx = PathTraversalContext( levelbookmarks, treeattr, parameters, dirname, collections, user, group, permissions ) # context that the children see & modify
          passedlist.append( newctx )
        
      pathlist = passedlist

  return

  
""""""
a rule is a list of directory levels.
a compiled rule has:
   a set of bookmarks under it
   a set of parameters under it
   a set of attributes under it

Directory level types:
  fixed : one or more fixed names, not parameterized
     fields : bookmarks, local attrs, tree attrs, name
  branch : redirects to one or more other rules, IN ORDER, no special attributes of its own
     fields: rules
  parameterized : any number of parameterized directories, there is one key and potentially many values.
     fields : bookmarks, local attrs, tree attrs, key, collection,
     if there is an collection attribute, then the values are restricted.
     """"""

def compile_dir_structure( doc ):
    ""returns a compiled version of the input document""
    ret ={ 'globals': {}, 'collections':{}, 'rules':{} }
    # copy globals:
    if 'globals' in doc:
      ret['globals'] = copy.deepcopy( doc['globals'] )
    # copy collections:
    if 'collections' in doc:
      ret['collections'] = copy.deepcopy( doc['collections'] )
    # copy rules:
    if 'rules' in doc:
      # a document rule is a key-value pair
      #    name of the rule is the key
      #    list of levels is the value.
      for rulename in doc['rules']:
        levellist = doc['rules'][rulename]
        ret['rules'][rulename] = {
          'levels' : copy.deepcopy( levellist ),
          'bookmarks' : tuple(get_rule_bookmarks(levellist, doc)),
          'parameters' : tuple(get_rule_parameters(levellist, doc)),
          'attributes' : tuple(get_rule_attributes(levellist, doc))
          }
    return ret

# -----------
/n/n/ndirb/localclient.py/n/n#####################################################################
#
# Copyright 2015 Mayur Patel
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License. 
# 
#####################################################################

from . import pathexpr
from . import ds
from . import fs

# a compiledrule is a dictionary with fields:
#    ""bookmarks"": set of bookmarks (under it)
#    ""parameters"" : set of parameters (keys only) (under it) 
#    ""attributes"" : set of attributes (keys only) (under it)
#    ""levels"" : tuples of tuples, (( ""leveltype"", {<levelfields>}),( ""leveltype"", {<levelfields>}),etc)
#    as traversal occurs, the bookmarks, parameter, attributes move from rules to the contexts as they resolve.
#

#
# A searcher has :
# does_intersect_rule( self, rulectx ) return bool if the rule might contain our target
# does_intersect_path( self, pathctx ) returns bool if the path might contain our target
# test( self, pathctx, levelctx ) to detemine whether this level is our target
# do_existing_paths() : bool, are we traversing real directories on disk, or is this theoretical?
# get_parameters( self, key, levelctx, pathctxlist ) : if this is a theoretical traversal, then the searcher needs to supply possible values, for each parameter key, to advance the search.


  

class LocalClient( object ) :
  def __init__(self, compileddoc, startingpath ):
    self._doc = compileddoc
    self._root = startingpath

  def get_rule_names( self ):
    return self._doc['rules'].keys()
  
  def get_rule( self, rulename ): # advanced API, not necessarily public; returns compiled rule
    return self._doc['rules'][rulename] if rulename in self._doc['rules'] else None
  
  def get_collection_names( self ):
    return self._doc['collections'].keys()
  
  def get_collection( self, collectionname ) : 
    return self._doc['collections'][collectionname] if collectionname in self._doc['collections'] else None
  
  def get_global_names( self ):
    return self._doc['globals'].keys()
  
  def get_global( self, attrname ):
    return self._doc['globals'][attrname] if attrname in self._doc['globals'] else None

  def traverse( self, searcher ): # advanced API, not necessarily public
    ctx = ds.PathTraversalContext( [], {}, {}, self._root, {}, None, None, None )
    rule = self._doc[ 'rules' ][ 'ROOT' ]
    client = self
    return ds._traverse( searcher, rule, ctx, client )
  
  def get_bookmark_names( self ) :
    return self._doc['rules']['ROOT']['bookmarks']
  
  def get_bookmark_parameters( self, bookmark ):
    """"""returns the parameters required to find the bookmark.  A list of dictionaries.  Each dictionary is a set of parameters required to find the bookmark.  The key is the parameter name and the value determines which, if any, collection the parameter is associated with.""""""
    class SearcherBookmarks( object ):
      def __init__( self, dirstructure ) :
        self._store = []
        self._ds = dirstructure
      def does_intersect_rule( self, rulectx ):
        return bookmark in rulectx.bookmarks
      def does_intersect_path( self, pathctx ):
        return True
      def test( self, pathctx, levelctx ):
        if bookmark in levelctx.bookmarks:
          found = ( (x,None) if x not in pathctx.collections else (x,pathctx.collections[x]) for x in pathctx.parameters.keys() )
          self._store.append( dict(found) )
      def do_existing_paths( self ) :
        return False
      def get_parameters( self, key, levelctx, pathctxlist ):
        if levelctx.collection:
          coll = self._ds.get_collection( levelctx.collection )
          return (coll[0],)
        else:
          return ('X',)
    searcher = SearcherBookmarks( self )
    ctx = ds.PathTraversalContext( [], {}, {}, '', {}, None, None, None )
    rule = self._doc[ 'rules' ][ 'ROOT' ]
    ds._traverse( searcher, rule, ctx, self )  
    return searcher._store
  
  def search_paths( self, searchexpr ):
    """"""implies a query, with a specific predicate or filter to narrow the search, returns only paths that exist""""""
    searcher = pathexpr.SearcherExists( self, searchexpr )
    ctx = ds.PathTraversalContext( [], {}, {}, self._root, {}, None, None, None )
    rule = self._doc[ 'rules' ][ 'ROOT' ]
    ds._traverse( searcher, rule, ctx, self )  
    return searcher._store
  
  def depict_paths( self, createexpr ):
    ""this returns a not-exists path, but does not make a directory on disk""
    searcher = pathexpr.SearcherNotExists( self, createexpr )
    ctx = ds.PathTraversalContext( [], {}, {}, self._root, {}, None, None, None )
    rule = self._doc[ 'rules' ][ 'ROOT' ]
    ds._traverse( searcher, rule, ctx, self )  
    return searcher._store
  
  def get_path_context( self, targetpath ):
    ""returns the path traversal context for the given path, works for real paths or depicted paths, will reject invalid paths, will accept paths deeper than what the structure knows about giving the deepest context it can""
    class SearcherPath( object ):
      def __init__( self, targetpath, client ) :
        self._splitpath = fs.split_path( targetpath )
        self._lensplitpath = len( self._splitpath )
        self._store = {} # this keeps matches, indexed by their depths
        self._ds = client
      def does_intersect_rule( self, rulectx ):
        return True
      def does_intersect_path( self, pathctx ):
        testpath = fs.split_path( pathctx.path )
        lentestpath = len(testpath)
        lenpath = min( self._lensplitpath, lentestpath )
        does_pass = self._splitpath[:lenpath] == testpath and lentestpath <= self._lensplitpath
        if does_pass and lentestpath not in self._store :
          # when we reach a new depth, we create a new entry in our storage
          self._store[lentestpath] = []
        return does_pass
      def test( self, pathctx, levelctx ):
        testpath = fs.split_path( pathctx.path )
        lenpath = min( self._lensplitpath, len(testpath))
        if self._splitpath[:lenpath] == testpath[:lenpath] :
          # store hits at the depth they occur:
          self._store[lenpath].append( pathctx )
      def do_existing_paths( self ) :
        return False
      def get_parameters( self, key, levelctx, pathctxlist ):
        # we get parameters from the path itself
        ret = set()
        for pathctx in pathctxlist :
          testpath = fs.split_path( pathctx.path )
          lenpath = len(testpath)
          if self._lensplitpath > lenpath:
            ret.add( self._splitpath[lenpath] )
        return ret
      
    searcher = SearcherPath( targetpath, self )
    ctx = ds.PathTraversalContext( [], {}, {}, self._root, {}, None, None, None )
    rule = self._doc[ 'rules' ][ 'ROOT' ]
    ds._traverse( searcher, rule, ctx, self )
    ret = ctx if targetpath == self._root else None
    if searcher._store :
      # all depths in the traversal needed to have a match, otherwise the path was not valid for the directory structure:
      if all( searcher._store[i] for i in searcher._store ):
        # we want to return the deepest match:
        key = max( searcher._store.keys() )
        assert 1 == len(searcher._store[key]), ""Multiple targets found for single path (%s)"" % targetpath
        ret = searcher._store[key][0]
    return ret

  def get_frontier_contexts( self, targetpath ):
    """"""given an existing path, returns the 'next' parameter to be defined, as well as the paths to which that parameter leads.
    necessary for UI development.
    returns a dictionary where the key is the parameter name, and the value is the list of directories associated with that parameter
    
    """"""
    """"""
    
    implementation details:
    set of parameters:
    calculate extra parameters
    calculate missing parameters
    if there are missing parameters, then cull the search
    if there is one extra parameter, then add it to the hits
    if there is zero extra parameters, then continue
    if there is more than one extra parameters, then cull the search
    
    """"""
    class SearcherPath( object ):
      def __init__( self, targetctx, client ) :
        self._splitpath = fs.split_path( targetctx.path )
        self._targetparam = set( targetctx.parameters.keys() )
        self._lensplitpath = len( self._splitpath )
        self._store = {}
        self._ds = client
      def does_intersect_rule( self, rulectx ):
        return True
      def does_intersect_path( self, pathctx ):
        testpath = fs.split_path( pathctx.path )
        lentestpath = len(testpath)
        lenpath = min( self._lensplitpath, lentestpath )
        extra_count = len( set( pathctx.parameters.keys() ) - self._targetparam )
        return self._splitpath[:lenpath] == testpath[:lenpath] and extra_count < 2
      def test( self, pathctx, levelctx ):
        path_set = set( pathctx.parameters.keys() )
        extra_param = path_set - self._targetparam
        extra_count = len( extra_param )
        missing_count = len( self._targetparam - path_set )
        testpath = fs.split_path( pathctx.path )
        lenpath = min( self._lensplitpath, len(testpath))
        if extra_count == 1 and ( not missing_count ) and levelctx.parameter:
          key = extra_param.pop()
          if not key in self._store:
            self._store[key] = []
          self._store[key].append( pathctx )
      def do_existing_paths( self ) :
        return True
      def get_parameters( self, key, levelctx, pathctxlist ):
        return None

    targetctx = self.get_path_context( targetpath )
    searcher = SearcherPath( targetctx, self )
    ctx = ds.PathTraversalContext( [], {}, {}, self._root, {}, None, None, None )
    rule = self._doc[ 'rules' ][ 'ROOT' ]
    ds._traverse( searcher, rule, ctx, self )  
    return searcher._store

      /n/n/ntest.py/n/n#!/usr/bin/env python2.7

#####################################################################
#
# Copyright 2015 Mayur Patel
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License. 
# 
#####################################################################

import dirb.ds as ds
import dirb.localclient as localclient
import dirb.sexpr as sexpr
import dirb.pathexpr as pathexpr

import unittest
import os

# ==========================================
class SimpleSexprTest(unittest.TestCase):
  # ----------------------------------------
  def test_identity( self ):
    e = ""( and  (bookmark alpha) (parameter (key value) (key value) (key value)) )""
    self.assertEqual( sexpr.loads( e ), sexpr.loads(sexpr.dumps( sexpr.loads( e )))  )
    self.assertEqual( sexpr.loads( e ), ['and', ['bookmark', 'alpha'], ['parameter', ['key','value'], ['key','value'],['key','value']]]  )

  def test_escape_bracket( self ):
    e = r'(""(name)"" in bracket)'
    self.assertEqual( sexpr.loads( e ), ['(name)', 'in', 'bracket'] )
    
  def test_bracket( self ):
    e = r'(\(name\) in bracket)'
    self.assertEqual( sexpr.loads( e ), ['\\', ['name\\'], 'in', 'bracket'] )
  
  def test_quote( self ):
    e = '(""(name) (value)\""\"""" token2)'
    self.assertEqual( sexpr.loads( e ), ['(name) (value)\""\""', 'token2'] )
          
# ==========================================
# /<show>/sequence/<sequence>/<shot>/<dept>
# /<show>/asset/<assettype>/<asset>/<dept>
class SimpleLocalClientTest(unittest.TestCase):

  def setUp(self):
    self.dirlist = (
      '/tmp/dirbtest1/projects/',
      '/tmp/dirbtest1/projects/show',
      '/tmp/dirbtest1/projects/show/asset',
      '/tmp/dirbtest1/projects/show/asset/vehicle',
      '/tmp/dirbtest1/projects/show/asset/vehicle/car1',
      '/tmp/dirbtest1/projects/show/asset/vehicle/car1/lighting',
      '/tmp/dirbtest1/projects/show/sequence',
      '/tmp/dirbtest1/projects/show/sequence/aa',
      '/tmp/dirbtest1/projects/show/sequence/aa/xx',
      '/tmp/dirbtest1/projects/show/sequence/bb',
      '/tmp/dirbtest1/projects/show/sequence/bb/xx',
      '/tmp/dirbtest1/projects/show/sequence/bb/xx/animation',
      '/tmp/dirbtest1/projects/show/sequence/bb/xx/lighting',
      '/tmp/dirbtest1/projects/show/sequence/bb/yy',
      '/tmp/dirbtest1/projects/show/sequence/bb/zz',
      '/tmp/dirbtest1/projects/show/sequence/cc'
      )
    self.doc = ds.compile_dir_structure( { 
      'collections' : {""department"":[""animation"",""lighting""], ""app"":['katana','maya']},
      'rules' : {
          
        'ROOT' : [
                ['ParameterizedLevel', { ""bookmarks"":[""showroot""], ""key"":'show'}],
                ['BranchLevel', {""rules"":[""sequence"",""asset""]}],
            ],
          
          
        'sequence' :[
                ['FixedLevel', {""name"":'sequence'}],
                ['ParameterizedLevel', { ""key"":'sequence'}],
                ['ParameterizedLevel', { ""key"":'shot', ""bookmarks"":['shotroot']}],
                ['ParameterizedLevel', { ""key"":'dept', ""collection"":""department"", 'bookmarks':['workarea']}]
            ],
          
          
        'asset' : [
                ['FixedLevel', {""name"":'asset'}],
                ['ParameterizedLevel', { ""key"":'assettype'}],
                ['ParameterizedLevel', { ""key"":'asset', 'bookmarks':['assetroot']}],
                ['ParameterizedLevel', { ""key"":'dept', ""collection"":""department"", 'bookmarks':['workarea']}]
            ]
        }
    } )
    self.d = localclient.LocalClient( self.doc, ""/tmp/dirbtest1/projects"" )
    for d in self.dirlist:
      if not os.path.isdir( d ):
        os.makedirs( d )

  # ----------------------------------------
  def test_simple_search(self):
    class ShotSearcher( object ) :
      def __init__( self ) :
        self.hold = []
      
      def does_intersect_rule( self, rulectx ):
        return 'shotroot' in rulectx.bookmarks
      
      def does_intersect_path( self, pathctx ):
        return True
      
      def test( self, pathctx, levelctx ):
        ret = 'shotroot' in levelctx.bookmarks
        if ret :
          self.hold.append( pathctx.path )
        return ret
            
      def do_existing_paths( self ):
        return False
    
      def get_parameters( self, key, levelctx, pathctxlist ) :
        if key == ""sequence"" :
          return (""SEQUENCE"",)
        if key == ""shot"" :
          return (""SHOT"",)
        if key == ""show"" :
          return (""SHOW"",)
        if key == 'dept':
          return ( ""animation"",""lighting"" )
        return []
      
    s = ShotSearcher()
    self.d.traverse( s )
    self.assertEqual(s.hold, ['/tmp/dirbtest1/projects/SHOW/sequence/SEQUENCE/SHOT'])
    
  # ----------------------------------------
  def test_bookmark_names(self):
    bookmarks = set( self.d.get_bookmark_names() )
    expected = set(('showroot','shotroot','assetroot','workarea'))
    self.assertEqual(bookmarks, expected)

  # ----------------------------------------
  def test_bookmark_parameters(self):
    found = self.d.get_bookmark_parameters('workarea')
    found = sorted( [ sorted(x.items()) for x in found ] )
    expected = [{'dept': 'department', 'show': None, 'shot': None, 'sequence': None}, {'dept': 'department', 'show': None, 'asset': None, 'assettype': None}]
    expected = sorted( [ sorted( x.items() ) for x in expected ] )
    self.assertEqual(found, expected)
    
  # ----------------------------------------
  def test_search_paths_and(self):
    searchexpr = '(and (bookmark shotroot) (parameters (show show)(shot xx)(sequence bb)))'
    foundlist = self.d.search_paths( searchexpr )
    self.assertEqual( len(foundlist), 1 )
    pathctx = foundlist[0]
    self.assertEqual( pathctx.path, '/tmp/dirbtest1/projects/show/sequence/bb/xx' )
    self.assertEqual( pathctx.parameters, {'show': 'show', 'shot': 'xx', 'sequence': 'bb'} )
    self.assertEqual( pathctx.bookmarks, ['shotroot'] )
    
  # ----------------------------------------
  def test_search_paths_multifinder_parameters(self):
    searchexpr = '(parameters (show show)(shot xx)(sequence bb))'
    foundlist = self.d.search_paths( searchexpr )
    foundlist = set( x.path for x in foundlist )
    expected = set((
      '/tmp/dirbtest1/projects/show/sequence/bb/xx/animation', 
      '/tmp/dirbtest1/projects/show/sequence/bb/xx/lighting', 
      '/tmp/dirbtest1/projects/show/sequence/bb/xx', 
      '/tmp/dirbtest1/projects/show/sequence/bb', 
      '/tmp/dirbtest1/projects/show/sequence', 
      '/tmp/dirbtest1/projects/show' ))
    self.assertEqual( foundlist, expected )

  # ----------------------------------------
  def test_search_paths_andor(self):
    searchexpr = '(and (bookmark workarea) (or (parameters (sequence bb))(parameters (asset car1))))'
    foundlist = self.d.search_paths( searchexpr )
    foundlist = set( x.path for x in foundlist )
    expected = set((
      '/tmp/dirbtest1/projects/show/asset/vehicle/car1/lighting',
      '/tmp/dirbtest1/projects/show/sequence/bb/xx/animation',
      '/tmp/dirbtest1/projects/show/sequence/bb/xx/lighting'))
    self.assertEqual( foundlist, expected )
  
  # ----------------------------------------
  def test_search_paths_multifinder_bookmarks(self):
    searchexpr = '(bookmark shotroot)'
    foundlist = self.d.search_paths( searchexpr )
    foundlist = set( x.path for x in foundlist )
    expected = set((
      '/tmp/dirbtest1/projects/show/sequence/aa/xx',
      '/tmp/dirbtest1/projects/show/sequence/bb/xx',
      '/tmp/dirbtest1/projects/show/sequence/bb/yy',
      '/tmp/dirbtest1/projects/show/sequence/bb/zz'))
    self.assertEqual( foundlist, expected )
    
  # ----------------------------------------
  def test_parameter_collect_parameter(self):
    found = pathexpr.create_parameter_collect( sexpr.loads( ""(parameters (key1 value1) (key2 value2))"" ))
    expected = {'key2': ('value2',), 'key1': ('value1',)}
    self.assertEqual( found, expected )
    
  # ----------------------------------------
  def test_parameter_collect_and(self):
    found = pathexpr.create_parameter_collect( sexpr.loads( ""(and (parameters (key1 value1)) (parameters (key1 value1) (key2 value2)))"" ))
    self.assertEqual( set(found['key1']), set(('value1',)) )
    self.assertEqual( set(found.keys()), set(('key1',)) )
    
  # ----------------------------------------
  def test_parameter_collect_or(self):
    found = pathexpr.create_parameter_collect( sexpr.loads( ""(or (parameters (key1 value1)) (parameters (key2 value2)))"" ))
    self.assertEqual( set(found['key1']), set(('value1',)) )
    self.assertEqual( set(found['key2']), set(('value2',)) )
    self.assertEqual( set(found.keys()), set(('key1','key2')) )
    
  # ----------------------------------------
  def test_depict_paths_rootonly(self):
    searchexpr = '(parameters (show SHOW))'
    foundlist = self.d.depict_paths( searchexpr )
    foundlist = set( x.path for x in foundlist )
    expected = set((
      '/tmp/dirbtest1/projects/SHOW',))
    self.assertEqual( foundlist, expected )
    
  # ----------------------------------------
  def test_depict_paths_collect_exception(self):
    searchexpr = '(parameters (show SHOW) (sequence SEQUENCE) (shot SHOT) (dept DEPT))'
    # this is not a valid path specification, because DEPT is not in the 'department' collection.
    self.assertRaises( KeyError, self.d.depict_paths, searchexpr )
    
  # ----------------------------------------
  def test_depict_paths_multiparam_multidir(self):
    searchexpr = '(parameters (show SHOW) (sequence SEQUENCE) (shot SHOT) (dept animation))'
    # ""open"" parameterizations like this will build the entire ancestor hierarchy
    foundlist = self.d.depict_paths( searchexpr )
    foundlist = set( x.path for x in foundlist )
    expected = set((
      '/tmp/dirbtest1/projects/SHOW/sequence/SEQUENCE/SHOT',
      '/tmp/dirbtest1/projects/SHOW/asset',
      '/tmp/dirbtest1/projects/SHOW',
      '/tmp/dirbtest1/projects/SHOW/sequence',
      '/tmp/dirbtest1/projects/SHOW/sequence/SEQUENCE',
      '/tmp/dirbtest1/projects/SHOW/sequence/SEQUENCE/SHOT/animation'))
    self.assertEqual( foundlist, expected )   
    
  # ----------------------------------------
  def test_depict_paths_multiparam_bookmark(self):
    searchexpr = '(and (bookmark workarea) (parameters (show SHOW) (sequence SEQUENCE) (shot SHOT) (dept animation)))'
    # the bookmark forces only workareas, not the entire hierarchy up to the parameterized leaf.
    foundlist = self.d.depict_paths( searchexpr )
    foundlist = set( x.path for x in foundlist )
    expected = set((
      '/tmp/dirbtest1/projects/SHOW/sequence/SEQUENCE/SHOT/animation',))
    self.assertEqual( foundlist, expected )   
    
  # ----------------------------------------
  def test_depict_paths_andor(self):
    searchexpr = """"""
      (and 
        (bookmark workarea) 
        (or 
          (parameters (sequence SEQUENCE) (shot SHOT))
          (parameters (assettype TYPE) (asset ASSET))
          (parameters (show SHOW) (dept lighting))
        )
      )""""""
    # the bookmark forces only workareas, not the entire hierarchy up to the parameterized leaf.
    foundlist = self.d.depict_paths( searchexpr )
    foundlist = set( x.path for x in foundlist )
    expected = set((
      '/tmp/dirbtest1/projects/SHOW/sequence/SEQUENCE/SHOT/lighting',
      '/tmp/dirbtest1/projects/SHOW/asset/TYPE/ASSET/lighting'))
    self.assertEqual( foundlist, expected )
  
  # ----------------------------------------
  def test_get_path_context_realpath( self ):
    targetpath = '/tmp/dirbtest1/projects/show/asset/vehicle/car1/lighting'
    found = self.d.get_path_context( targetpath )
    expected = set( {'dept': 'lighting', 'assettype': 'vehicle', 'asset': 'car1', 'show': 'show'}.items() )
    self.assertEqual( found.path, targetpath )
    self.assertEqual( set(found.parameters.items()), expected )
    
  # ----------------------------------------
  def test_get_path_context_realpath2( self ):
    targetpath = '/tmp/dirbtest1/projects/show/sequence/bb'
    found = self.d.get_path_context( targetpath )
    expected = set( {'sequence': 'bb', 'show': 'show'}.items() )
    self.assertEqual( found.path, targetpath )
    self.assertEqual( set(found.parameters.items()), expected )
    
  # ----------------------------------------
  def test_get_path_context_depictedpath( self ):
    targetpath = '/tmp/dirbtest1/projects/newshow/asset/character/bigguy/animation'
    # this targetpath does not actually exist on disk, but can still be interrogated
    found = self.d.get_path_context( targetpath )
    expected = set( {'dept': 'animation', 'assettype': 'character', 'asset': 'bigguy', 'show': 'newshow'}.items() )
    self.assertEqual( found.path, targetpath )
    self.assertEqual( set(found.parameters.items()), expected )

  # ----------------------------------------
  def test_get_path_context_depictedfilename( self ):
    targetpath = '/tmp/dirbtest1/projects/SHOW/sequence/SEQUENCE/SHOT/animation/application/scenes/filename.scene'
    # it is okay to go deeper than the directory structure understands, it will return the deepest context it knows
    found = self.d.get_path_context( targetpath )
    expected = set( {'dept': 'animation', 'sequence': 'SEQUENCE', 'shot': 'SHOT', 'show': 'SHOW'}.items() )
    self.assertEqual( found.path, '/tmp/dirbtest1/projects/SHOW/sequence/SEQUENCE/SHOT/animation' )
    self.assertEqual( set(found.parameters.items()), expected )

  # ----------------------------------------
  def test_get_path_context_depictedpath_badcollection( self ):
    targetpath = '/tmp/dirbtest1/projects/falseshow/asset/set/castle/infantry'
    # department value in this targetpath is not a member of the department collection
    self.assertRaises( KeyError, self.d.get_path_context, targetpath )
  
  # ----------------------------------------
  def test_get_path_context_shallow( self ):
    targetpath = '/tmp/dirbtest1/projects/SHOW/editorial/workarea'
    # targetpath is not compatible with this directory structure
    found = self.d.get_path_context( targetpath )
    self.assertEqual( found.path, '/tmp/dirbtest1/projects/SHOW' )
    
  # ----------------------------------------
  def test_get_path_context_notvalidpath( self ):
    targetpath = '/tmp/dirbtest1/thing/SHOW'
    # targetpath is not compatible with this directory structure
    found = self.d.get_path_context( targetpath )
    self.assertEqual( found, None )
  
  # ----------------------------------------
  def test_get_frontier_contexts_root( self ):
    targetpath = '/tmp/dirbtest1/projects'
    found = self.d.get_frontier_contexts( targetpath )
    expected_keys = [""show""]
    expected_parameters = {'show':'show'}
    self.assertEqual( set(found.keys()), set(expected_keys) )
    self.assertEqual( len( found['show'] ), 1 )
    self.assertEqual( found['show'][0].parameters, expected_parameters )
    
  # ----------------------------------------
  def test_get_frontier_contexts_cluster( self ):
    targetpath = '/tmp/dirbtest1/projects/show/sequence'
    found = self.d.get_frontier_contexts( targetpath )
    expected_keys = [""sequence""]
    expected_parameters = set(['aa','bb','cc'])
    self.assertEqual( set(found.keys()), set(expected_keys) )
    self.assertEqual( len( found['sequence'] ), len(expected_parameters) )
    found_parameters = set( i.parameters['sequence'] for i in found['sequence'] )
    self.assertEqual( set(found_parameters), expected_parameters )

  # ----------------------------------------
  def test_get_frontier_contexts_branch( self ):
    targetpath = '/tmp/dirbtest1/projects/show'
    found = self.d.get_frontier_contexts( targetpath )
    expected_keys = set([""sequence"",'assettype'])
    expected_parameters = set(['aa','bb','cc'])
    self.assertEqual( set(found.keys()), expected_keys )
    self.assertEqual( len( found['sequence'] ), len(expected_parameters) )
    found_parameters = set( i.parameters['sequence'] for i in found['sequence'] )
    self.assertEqual( set(found_parameters), expected_parameters )
    
    expected_parameters = set(['vehicle'])
    self.assertEqual( len( found['assettype'] ), len(expected_parameters) )
    found_parameters = set( i.parameters['assettype'] for i in found['assettype'] )
    self.assertEqual( set(found_parameters), expected_parameters )
    
  # ----------------------------------------
  def tearDown(self):
    # TODO should we remove the directories we created?
    pass
  
# ==========================================

class SimplePermissionsTest(unittest.TestCase): 

  def setUp(self):

    self.doc = ds.compile_dir_structure( { 
      'collections' : {""datatype"":[""caches"",""scenes"",""images""], 'assettype':['character','prop','vehicle','set']},
      'rules' : {
          
        'ROOT' : [
                ['BranchLevel', {'rules':['assets','shots']}],
                ],
        
        'shots' : [
                ['ParameterizedLevel', { ""key"":'datatype', ""collection"":""datatype"", 'user':'root', 'group':'root', 'permissions':'rwxr-xr-x'}],
                ['ParameterizedLevel', { ""key"":'show'}],
                ['ParameterizedLevel', { ""key"":'sequence'}],
                ['ParameterizedLevel', { ""key"":'shot', 'bookmarks':['shotroot']}],
                ['ParameterizedLevel', { ""key"":'user', 'bookmarks':['workarea'], 'user':'(parameter user)', 'group':'shotdept', 'permissions':'rwxr-x---' }]
                ],                
          
          
        'assets' :[
                ['FixedLevel', {""name"":'assets', 'user':'root', 'group':'root', 'permissions':'rwxr-xr-x'}],
                ['ParameterizedLevel', { ""key"":'show', 'group':'assetdept'}],
                ['ParameterizedLevel', { ""key"":'assettype', 'collection':'assettype'}],
                ['ParameterizedLevel', { ""key"":'assetname', 'bookmarks':['assetroot'] }],
                ['ParameterizedLevel', { ""key"":'user', 'bookmarks':['workarea'], 'user':'(parameter user)', 'permissions':'rwxr-x---' }]
            ]
        }
    } )
    self.d = localclient.LocalClient( self.doc, ""/tmp/dirbtest1/projects"" )

  # ----------------------------------------
  def test_simple_depict1(self):
    createexpr = '(and (bookmark workarea) (parameters (show diehard)(assettype vehicle)(assetname gunshipA)(user bwillis)))'
    foundlist = self.d.depict_paths( createexpr )
    self.assertEqual( 1, len(foundlist) )
    expected = { 'attributes':{}, 'parameters':{'assetname': 'gunshipA', 'assettype': 'vehicle', 'user': 'bwillis', 'show': 'diehard'}, 'path':'/tmp/dirbtest1/projects/assets/diehard/vehicle/gunshipA/bwillis', 'collections':{'assettype': 'assettype'}, 'user':'bwillis', 'group':'assetdept', 'permissions':488 }
    found = foundlist[0]
    self.assertEqual( found.attributes, expected['attributes'] )
    self.assertEqual( found.parameters, expected['parameters'] )
    self.assertEqual( found.path, expected['path'] )
    self.assertEqual( found.collections, expected['collections'] )
    self.assertEqual( found.user, expected['user'] )
    self.assertEqual( found.group, expected['group'] )
    self.assertEqual( found.permissions, expected['permissions'] )
    
  # ----------------------------------------
  def test_simple_depict2(self):
    createexpr = '(and (bookmark workarea) (parameters (datatype caches)(show diehard)(sequence QQQ)(shot TTT)(user bwillis)))'
    foundlist = self.d.depict_paths( createexpr )
    self.assertEqual( 1, len(foundlist) )
    expected = { 'attributes':{}, 'parameters':{'datatype': 'caches', 'sequence': 'QQQ', 'shot': 'TTT', 'user': 'bwillis', 'show': 'diehard'}, 'path':'/tmp/dirbtest1/projects/caches/diehard/QQQ/TTT/bwillis', 'collections':{'datatype': 'datatype'}, 'user':'bwillis', 'group':'shotdept', 'permissions':488 }
    found = foundlist[0]
    self.assertEqual( found.attributes, expected['attributes'] )
    self.assertEqual( found.parameters, expected['parameters'] )
    self.assertEqual( found.path, expected['path'] )
    self.assertEqual( found.collections, expected['collections'] )
    self.assertEqual( found.user, expected['user'] )
    self.assertEqual( found.group, expected['group'] )
    self.assertEqual( found.permissions, expected['permissions'] )
    
  # ----------------------------------------
  def test_simple_depict3(self):
    createexpr = '(and (bookmark shotroot) (parameters (datatype images)(show dh2)(sequence qqq)(shot ttt)(user arickman)))'
    foundlist = self.d.depict_paths( createexpr )
    self.assertEqual( 1, len(foundlist) )
    expected = { 'attributes':{}, 'parameters':{'datatype': 'images', 'show': 'dh2', 'shot': 'ttt', 'sequence': 'qqq'}, 'path':'/tmp/dirbtest1/projects/images/dh2/qqq/ttt', 'collections':{'datatype': 'datatype'}, 'user':'root', 'group':'root', 'permissions':493 }
    found = foundlist[0]
    self.assertEqual( found.attributes, expected['attributes'] )
    self.assertEqual( found.parameters, expected['parameters'] )
    self.assertEqual( found.path, expected['path'] )
    self.assertEqual( found.collections, expected['collections'] )
    self.assertEqual( found.user, expected['user'] )
    self.assertEqual( found.group, expected['group'] )
    self.assertEqual( found.permissions, expected['permissions'] )
    
  # ----------------------------------------
  def tearDown(self):
    pass
  

  
  
#####################################################################
if __name__ == '__main__':
    unittest.main()


/n/n/n",0
151,151,10e70875b059602c3117cc40a75a980b5e88edc5,"/dirb/ds.py/n/n#####################################################################
#
# Copyright 2015 Mayur Patel
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License. 
# 
#####################################################################

from . import pathexpr
from . import attrexpr
from . import ugoexpr

from . import fs

import copy
import collections
import itertools
import os
import glob



# A directory structure object:
#
# (1) has a schema,
# A set of rules which outline the tree-structure for the file system.
# One rule must be called ""ROOT"", but traversal can begin from anywhere
# and from any rule.
#
# (3) has collections, which connect with metadata
# It is handy to use collections as part of the directory structure,
# for example, to be able to use a departments list as a parameter
# for work area or publish area builds.
#
# (2) has globals, which are attributes that do not vary per-location.
#
#
# A directory location 
#   has an optional bookmark definition, which implicitly a parameterization by which the bookmark can be found.
#       in some ways, an bookmark is really just a special attribute tag.  
#       A bookmark can appear in different places, meaning that it can have multiple parameterizations
#       a bookmark is not inherited
#   has attributes, which can either be inherited down or not. (treeattribute, localattribute)
#   might be parameterized or not. a parameter is either unrestricted or restricted to a selection from a collection and
#   has a default owner and permissions.  The owner could be parameterized.
#
# Directory locations are stacked into rules as much as possible:
#   reduces the complexity of many kinds of structure schemas
#   allows optimizations to be placed strategically.
#   allows us to keep most of the directory structure as an explicit map/list,
#      converting on the absolutely bare essentials into additional complexity.
#
# Directory structure is meant to be flexible but not DYNAMIC!
#      You might want to change it a couple times a year, but not every day
#
# Need to resolve ambiguous paths by being strict with search order.
#     ""fixed"" directories should be listed first, in the reference list.
#     parameterized directories should be listed last (and ideally, there's only one!)
#




# before being compiled:
""""""

{
  
  'collections' : {
    },
    
  'globals' : {},
  
  'rules' : {
  
    'ROOT' : [
        ['multiple', { 
            'key' : 'department'
            'bookmarks' : ['workarea'],
            'localattributes' : {},
            'treeattributes' : {},
            'user' : '(parameter user)',
            'group' : 'vfx',
            'permissions' : 'rwxr-xr-x' 
         }],
        
        ['directory', {
           'name' : 'value'
         }]
      
      ],
    
    'alternative' : [
      ],
    
    'rule2' : [
      ]
    }
}

""""""

""""""
a rule is a list of directory levels.
a compiled rule has:
   a set of bookmarks under it
   a set of parameters under it
   a set of attributes under it

Directory level types:
  fixed : one or more fixed names, not parameterized
     fields : bookmarks, local attrs, tree attrs, name, user, group, permissions
  branch : redirects to one or more other rules, IN ORDER, no special attributes of its own
     fields: rules
  parameterized : any number of parameterized directories, there is one key and potentially many values.
     fields : bookmarks, local attrs, tree attrs, key, collection, user group, permissions
     if there is an collection attribute, then the values are restricted.
  regex : can represent zero or more parameters, as defined by the groups in the expression.  Also good when
     there is a prefix or suffix or restrictions on the character set.
     fields: bookmarks, local attrs, tree attrs, pattern, collections, user, group, permissions
     regex is TODO
""""""

FnLevel = {} # use of a singleton impairs ability to run multi-threaded, locks should be placed inside the level methods that need them.

# we use a class decorator here, instead of metaclasses for example,
# because what we really want is a dictionary of class instances (singletons actually),
# not some dictionary of classes, or other kind of class manipulation.
def register_level( cls ) :
  FnLevel[cls.__name__] = cls()
  return cls


class BaseLevel(object):
  def __init__(self):
    pass
  
  def validate( self, levelfields, path_list, client ): # for use during compile (?)
    return True
  
  def get_directories( self, levelctx, levelfields, searcher, ctxlist, client ):
    return []
  
  def get_bookmarks( self, levelfields, doc ): # used during compile
    return set(levelfields['bookmarks'] if 'bookmarks' in levelfields else [])
  
  def get_attributes( self, levelfields, doc ): # used during compile
    keys = levelfields['localattributes'].keys() if 'localattributes' in levelfields else []
    keys.extend( levelfields['treeattributes'].keys() if 'treeattributes' in levelfields else [] )
    return set( keys )
    
  def get_parameters( self, levelfields, doc ): # used during compile
    return set([levelfields['key']] if 'key' in levelfields else [])



@register_level
class FixedLevel(BaseLevel) :
  def __init__(self):
    BaseLevel.__init__(self) # can't use super() because we instance the class before definition is complete!
  
  def get_directories( self, levelctx, levelfields, searcher, ctxlist, client ):
    candidates = [(x, os.path.join(x.path, levelfields['name'])) for x in ctxlist]
    if searcher.do_existing_paths() :
      candidates = [(x, y) for x, y in candidates if os.path.isdir(y)]
    return candidates
    
  def get_parameters( self, levelfields, doc ): # used during compile
    return set()
  
@register_level
class BranchLevel(BaseLevel) :
  def __init__(self):
   BaseLevel.__init__(self) # can't use super() because we instance the class before definition is complete!
  
  def get_directories( self, levelctx, levelfields, searcher, ctxlist, client):
    rulenames = levelfields['rules']
    for rulename, ctx in itertools.product( rulenames, ctxlist ) :
      rule = client.get_rule( rulename )
      _traverse( searcher, rule, ctx, client ) # indirect recursion
    return None
  
  def get_bookmarks( self, levelfields, doc ):
    bookmarks = set()
    rulenames = levelfields['rules']
    for rulename in rulenames :
      rule = doc['rules'][ rulename ]
      bookmarks |= get_rule_bookmarks(rule,doc)
    return bookmarks
  
  def get_attributes( self, levelfields, doc ):
    attributes = set()
    rulenames = levelfields['rules']
    for rulename in rulenames :
      rule = doc['rules'][ rulename ]
      attributes |= get_rule_attributes(rule,doc)
    return attributes
    
  def get_parameters( self, levelfields, doc ):
    parameters = set()
    rulenames = levelfields['rules']
    for rulename in rulenames :
      rule = doc['rules'][ rulename ]
      parameters |= get_rule_parameters(rule,doc)
    return parameters



@register_level
class ParameterizedLevel(BaseLevel) :
  def __init__(self):
    BaseLevel.__init__(self) # can't use super() because we instance the class before definition is complete!
  
  def get_directories( self, levelctx, levelfields, searcher, ctxlist, client ):
    doexisting = searcher.do_existing_paths()
    dirlist = []
    
    if doexisting :
      
      for ictx in ctxlist:
        ctxdirs = glob.glob( os.path.join( ictx.path, '*' ))
        ctxdirs = ( x for x in ctxdirs if os.path.isdir( x ))
        
        if 'collection' in levelfields:
          coll = client.get_collection( levelfields['collection'] )
          ctxdirs = ( x for x in ctxdirs if os.path.split(x)[-1] in coll )
          
        dirlist.extend( (ictx, x) for x in ctxdirs )
      
    else:
      
      values = []
      if 'key' in levelfields:
        search_param = searcher.get_parameters(levelfields['key'], levelctx, ctxlist)
        if search_param:
          values.extend( x for x in search_param if x ) # eliminate None values
          
      if 'collection' in levelfields:
        coll = client.get_collection( levelfields['collection'] )
        bad_values = [x for x in values if x not in coll]
        if bad_values:
          raise KeyError( ""Collection '%s' does not contain %s"" % (levelfields['collection'], ','.join(""'%s'"" % x for x in bad_values)))
      
      for ctx, value in itertools.product( ctxlist, values ):
        dirlist.append((ctx, os.path.join( ctx.path, value )))
          
    return dirlist 
  
# -----------

def get_rule_bookmarks( levellist, doc ) : # used during compile
  ret = set()
  for level in levellist:
    leveltype = level[0]
    levelfields = level[1]
    ret |= FnLevel[leveltype].get_bookmarks( levelfields, doc)
  return ret
  
def get_rule_attributes( levellist, doc ): # used during compile
  ret = set()
  for level in levellist:
    leveltype = level[0]
    levelfields = level[1]
    ret |= FnLevel[leveltype].get_attributes( levelfields, doc)
  return ret

def get_rule_parameters( levellist, doc ): # used during compile
  ret = set()
  for level in levellist:
    leveltype = level[0]
    levelfields = level[1]
    ret |= FnLevel[leveltype].get_parameters( levelfields, doc)
  return ret  




RuleTraversalContext = collections.namedtuple( ""RuleTraversalContext"", (""bookmarks"", ""attributes"", ""parameters"")) # elements of levels contained
PathTraversalContext = collections.namedtuple( ""PathTraversalContext"", (""attributes"", ""parameters"", ""path"", ""collections"", ""user"", ""group"", ""permissions"") ) # includes attrs and params from current level
LevelTraversalContext = collections.namedtuple( ""LevelTraversalContext"", ( ""bookmarks"", ""treeattributes"", ""localattributes"", ""parameter"", ""collection"", ""user"", ""group"", ""permissions"" )) # elements of current level only



def _traverse( searcher, rule, ctx, client ):
  if searcher.does_intersect_rule( RuleTraversalContext( rule['bookmarks'], rule['attributes'], rule['parameters'] ) ):
    
    pathlist = [ctx]
    for leveltype, levelfields in rule[ 'levels' ]:
      
      # create new level context:
      levelbookmarks = levelfields['bookmarks'] if 'bookmarks' in levelfields else []
      leveltreeattr = levelfields['treeattributes'] if 'treeattributes' in levelfields else {}
      levellocalattr = levelfields['localattributes'] if 'localattributes' in levelfields else {}
      levelparameter = levelfields['key'] if 'key' in levelfields else None
      levelcollection = levelfields['collection'] if 'collection' in levelfields else None
      leveluser = levelfields['user'] if 'user' in levelfields else None
      levelgroup = levelfields['group'] if 'group' in levelfields else None
      levelpermissions = levelfields['permissions'] if 'permissions' in levelfields else None
      
      levelctx = LevelTraversalContext( levelbookmarks, leveltreeattr, levellocalattr, levelparameter, levelcollection, leveluser, levelgroup, levelpermissions )
      
      # get directories for this level
      ruletuples = FnLevel[ leveltype ].get_directories( levelctx, levelfields, searcher, pathlist, client )
      
      if not ruletuples:
        break # end for
      
      passedlist = []
      for ictx, dirname in ruletuples: # breadth-first search with pruning

        treeattr = ictx.attributes.copy() # shallow
        if 'treeattributes' in levelfields:
          treeattr.update( leveltreeattr )
          
        localattr = treeattr.copy() # shallow
        if 'localattributes' in levelfields:
          localattr.update( levellocalattr )
          
        parameters = ictx.parameters.copy() # shallow
        collections = ictx.collections.copy() # shallow
        if levelparameter :
          basename = os.path.basename( dirname )
          parameters[ levelparameter ] = basename
          if levelcollection:
            collections[ levelparameter ] = levelcollection
            
        user = attrexpr.eval_attribute_expr( leveluser, localattr, parameters ) if leveluser else ictx.user
        group = attrexpr.eval_attribute_expr( levelgroup, localattr, parameters ) if levelgroup else ictx.group
        permissions = ugoexpr.eval_ugo_expr( levelpermissions ) if levelpermissions else ictx.permissions
        
        newctx = PathTraversalContext( localattr, parameters, dirname, collections, user, group, permissions )
        test = searcher.does_intersect_path( newctx )
        if test:
          searcher.test( newctx, levelctx )
          newctx = PathTraversalContext( treeattr, parameters, dirname, collections, user, group, permissions ) # context that the children see & modify
          passedlist.append( newctx )
        
      pathlist = passedlist

  return

  
""""""
a rule is a list of directory levels.
a compiled rule has:
   a set of bookmarks under it
   a set of parameters under it
   a set of attributes under it

Directory level types:
  fixed : one or more fixed names, not parameterized
     fields : bookmarks, local attrs, tree attrs, name
  branch : redirects to one or more other rules, IN ORDER, no special attributes of its own
     fields: rules
  parameterized : any number of parameterized directories, there is one key and potentially many values.
     fields : bookmarks, local attrs, tree attrs, key, collection,
     if there is an collection attribute, then the values are restricted.
     """"""

def compile_dir_structure( doc ):
    ""returns a compiled version of the input document""
    ret ={ 'globals': {}, 'collections':{}, 'rules':{} }
    # copy globals:
    if 'globals' in doc:
      ret['globals'] = copy.deepcopy( doc['globals'] )
    # copy collections:
    if 'collections' in doc:
      ret['collections'] = copy.deepcopy( doc['collections'] )
    # copy rules:
    if 'rules' in doc:
      # a document rule is a key-value pair
      #    name of the rule is the key
      #    list of levels is the value.
      for rulename in doc['rules']:
        levellist = doc['rules'][rulename]
        ret['rules'][rulename] = {
          'levels' : copy.deepcopy( levellist ),
          'bookmarks' : tuple(get_rule_bookmarks(levellist, doc)),
          'parameters' : tuple(get_rule_parameters(levellist, doc)),
          'attributes' : tuple(get_rule_attributes(levellist, doc))
          }
    return ret

# -----------
/n/n/n/dirb/localclient.py/n/n#####################################################################
#
# Copyright 2015 Mayur Patel
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License. 
# 
#####################################################################

from . import pathexpr
from . import ds
from . import fs

# a compiledrule is a dictionary with fields:
#    ""bookmarks"": set of bookmarks (under it)
#    ""parameters"" : set of parameters (keys only) (under it) 
#    ""attributes"" : set of attributes (keys only) (under it)
#    ""levels"" : tuples of tuples, (( ""leveltype"", {<levelfields>}),( ""leveltype"", {<levelfields>}),etc)
#    as traversal occurs, the bookmarks, parameter, attributes move from rules to the contexts as they resolve.
#

#
# A searcher has :
# does_intersect_rule( self, rulectx ) return bool if the rule might contain our target
# does_intersect_path( self, pathctx ) returns bool if the path might contain our target
# test( self, pathctx, levelctx ) to detemine whether this level is our target
# do_existing_paths() : bool, are we traversing real directories on disk, or is this theoretical?
# get_parameters( self, key, levelctx, pathctxlist ) : if this is a theoretical traversal, then the searcher needs to supply possible values, for each parameter key, to advance the search.


  

class LocalClient( object ) :
  def __init__(self, compileddoc, startingpath ):
    self._doc = compileddoc
    self._root = startingpath

  def get_rule_names( self ):
    return self._doc['rules'].keys()
  
  def get_rule( self, rulename ): # advanced API, not necessarily public; returns compiled rule
    return self._doc['rules'][rulename] if rulename in self._doc['rules'] else None
  
  def get_collection_names( self ):
    return self._doc['collections'].keys()
  
  def get_collection( self, collectionname ) : 
    return self._doc['collections'][collectionname] if collectionname in self._doc['collections'] else None
  
  def get_global_names( self ):
    return self._doc['globals'].keys()
  
  def get_global( self, attrname ):
    return self._doc['globals'][attrname] if attrname in self._doc['globals'] else None

  def traverse( self, searcher ): # advanced API, not necessarily public
    ctx = ds.PathTraversalContext( {}, {}, self._root, {}, None, None, None )
    rule = self._doc[ 'rules' ][ 'ROOT' ]
    client = self
    return ds._traverse( searcher, rule, ctx, client )
  
  def get_bookmark_names( self ) :
    return self._doc['rules']['ROOT']['bookmarks']
  
  def get_bookmark_parameters( self, bookmark ):
    """"""returns the parameters required to find the bookmark.  A list of dictionaries.  Each dictionary is a set of parameters required to find the bookmark.  The key is the parameter name and the value determines which, if any, collection the parameter is associated with.""""""
    class SearcherBookmarks( object ):
      def __init__( self, dirstructure ) :
        self._store = []
        self._ds = dirstructure
      def does_intersect_rule( self, rulectx ):
        return bookmark in rulectx.bookmarks
      def does_intersect_path( self, pathctx ):
        return True
      def test( self, pathctx, levelctx ):
        if bookmark in levelctx.bookmarks:
          found = ( (x,None) if x not in pathctx.collections else (x,pathctx.collections[x]) for x in pathctx.parameters.keys() )
          self._store.append( dict(found) )
      def do_existing_paths( self ) :
        return False
      def get_parameters( self, key, levelctx, pathctxlist ):
        if levelctx.collection:
          coll = self._ds.get_collection( levelctx.collection )
          return (coll[0],)
        else:
          return ('X',)
    searcher = SearcherBookmarks( self )
    ctx = ds.PathTraversalContext( {}, {}, '', {}, None, None, None )
    rule = self._doc[ 'rules' ][ 'ROOT' ]
    ds._traverse( searcher, rule, ctx, self )  
    return searcher._store
  
  def search_paths( self, searchexpr ):
    """"""implies a query, with a specific predicate or filter to narrow the search, returns only paths that exist""""""
    searcher = pathexpr.SearcherExists( self, searchexpr )
    ctx = ds.PathTraversalContext( {}, {}, self._root, {}, None, None, None )
    rule = self._doc[ 'rules' ][ 'ROOT' ]
    ds._traverse( searcher, rule, ctx, self )  
    return searcher._store
  
  def depict_paths( self, createexpr ):
    ""this returns a not-exists path, but does not make a directory on disk""
    searcher = pathexpr.SearcherNotExists( self, createexpr )
    ctx = ds.PathTraversalContext( {}, {}, self._root, {}, None, None, None )
    rule = self._doc[ 'rules' ][ 'ROOT' ]
    ds._traverse( searcher, rule, ctx, self )  
    return searcher._store
  
  def get_path_context( self, targetpath ):
    ""returns the path traversal context for the given path, works for real paths or depicted paths, will reject invalid paths, will accept paths deeper than what the structure knows about giving the deepest context it can""
    class SearcherPath( object ):
      def __init__( self, targetpath, client ) :
        self._splitpath = fs.split_path( targetpath )
        self._lensplitpath = len( self._splitpath )
        self._store = {} # this keeps matches, indexed by their depths
        self._ds = client
      def does_intersect_rule( self, rulectx ):
        return True
      def does_intersect_path( self, pathctx ):
        testpath = fs.split_path( pathctx.path )
        lentestpath = len(testpath)
        lenpath = min( self._lensplitpath, lentestpath )
        does_pass = self._splitpath[:lenpath] == testpath and lentestpath <= self._lensplitpath
        if does_pass and lentestpath not in self._store :
          # when we reach a new depth, we create a new entry in our storage
          self._store[lentestpath] = []
        return does_pass
      def test( self, pathctx, levelctx ):
        testpath = fs.split_path( pathctx.path )
        lenpath = min( self._lensplitpath, len(testpath))
        if self._splitpath[:lenpath] == testpath[:lenpath] :
          # store hits at the depth they occur:
          self._store[lenpath].append( pathctx )
      def do_existing_paths( self ) :
        return False
      def get_parameters( self, key, levelctx, pathctxlist ):
        # we get parameters from the path itself
        ret = set()
        for pathctx in pathctxlist :
          testpath = fs.split_path( pathctx.path )
          lenpath = len(testpath)
          if self._lensplitpath > lenpath:
            ret.add( self._splitpath[lenpath] )
        return ret
      
    searcher = SearcherPath( targetpath, self )
    ctx = ds.PathTraversalContext( {}, {}, self._root, {}, None, None, None )
    rule = self._doc[ 'rules' ][ 'ROOT' ]
    ds._traverse( searcher, rule, ctx, self )
    ret = ctx if targetpath == self._root else None
    if searcher._store :
      # all depths in the traversal needed to have a match, otherwise the path was not valid for the directory structure:
      if all( searcher._store[i] for i in searcher._store ):
        # we want to return the deepest match:
        key = max( searcher._store.keys() )
        assert 1 == len(searcher._store[key]), ""Multiple targets found for single path (%s)"" % targetpath
        ret = searcher._store[key][0]
    return ret

  def get_frontier_contexts( self, targetpath ):
    """"""given an existing path, returns the 'next' parameter to be defined, as well as the paths to which that parameter leads.
    necessary for UI development.
    returns a dictionary where the key is the parameter name, and the value is the list of directories associated with that parameter
    
    """"""
    """"""
    
    implementation details:
    set of parameters:
    calculate extra parameters
    calculate missing parameters
    if there are missing parameters, then cull the search
    if there is one extra parameter, then add it to the hits
    if there is zero extra parameters, then continue
    if there is more than one extra parameters, then cull the search
    
    """"""
    class SearcherPath( object ):
      def __init__( self, targetctx, client ) :
        self._splitpath = fs.split_path( targetctx.path )
        self._targetparam = set( targetctx.parameters.keys() )
        self._lensplitpath = len( self._splitpath )
        self._store = {}
        self._ds = client
      def does_intersect_rule( self, rulectx ):
        return True
      def does_intersect_path( self, pathctx ):
        testpath = fs.split_path( pathctx.path )
        lentestpath = len(testpath)
        lenpath = min( self._lensplitpath, lentestpath )
        extra_count = len( set( pathctx.parameters.keys() ) - self._targetparam )
        return self._splitpath[:lenpath] == testpath[:lenpath] and extra_count < 2
      def test( self, pathctx, levelctx ):
        path_set = set( pathctx.parameters.keys() )
        extra_param = path_set - self._targetparam
        extra_count = len( extra_param )
        missing_count = len( self._targetparam - path_set )
        testpath = fs.split_path( pathctx.path )
        lenpath = min( self._lensplitpath, len(testpath))
        if extra_count == 1 and ( not missing_count ) and levelctx.parameter:
          key = extra_param.pop()
          if not key in self._store:
            self._store[key] = []
          self._store[key].append( pathctx )
      def do_existing_paths( self ) :
        return True
      def get_parameters( self, key, levelctx, pathctxlist ):
        return None

    targetctx = self.get_path_context( targetpath )
    searcher = SearcherPath( targetctx, self )
    ctx = ds.PathTraversalContext( {}, {}, self._root, {}, None, None, None )
    rule = self._doc[ 'rules' ][ 'ROOT' ]
    ds._traverse( searcher, rule, ctx, self )  
    return searcher._store

      /n/n/n",1
152,152,c0418996aa5c69b22201de3223b13e31741a0c9d,"website/karakara/__init__.py/n/nimport os
import re
import operator
from functools import partial

# Pyramid imports
import pyramid.events
import pyramid.request
import pyramid.config
import pyramid.traversal
from pyramid.session import SignedCookieSessionFactory  # TODO: should needs to be replaced with an encrypted cookie or a hacker at an event may be able to intercept other users id's
from pyramid.i18n import get_localizer, TranslationStringFactory

# External Imports
from externals.lib.misc import convert_str_with_type, read_json, extract_subkeys, json_serializer, file_scan
from externals.lib.pyramid_helpers.auto_format2 import setup_pyramid_autoformater
from externals.lib.pyramid_helpers.session_identity2 import session_identity
from externals.lib.social._login import NullLoginProvider, FacebookLogin, GoogleLogin
from externals.lib.multisocket.auth_echo_server import AuthEchoServerManager

# Package Imports
from .traversal import TraversalGlobalRootFactory
from .templates import helpers as template_helpers
from .auth import ComunityUserStore, NullComunityUserStore
# SQLAlchemy imports
from .model import init_DBSession


import logging
log = logging.getLogger(__name__)

translation_string_factory = TranslationStringFactory('karakara')


def main(global_config, **settings):
    """"""
        This function returns a Pyramid WSGI application.
    """"""
    # Setup --------------------------------------------------------------------

    # Db
    init_DBSession(settings)

    # Pyramid Global Settings
    config = pyramid.config.Configurator(settings=settings, root_factory=TraversalGlobalRootFactory)  # , autocommit=True

    def assert_settings_keys(keys):
        for settings_key in key:
            assert config.registry.settings.get(settings_key)

    # Register Additional Includes ---------------------------------------------
    config.include('pyramid_mako')  # The mako.directories value is updated in the scan for addons. We trigger the import here to include the correct folders.

    # Reload on template change - Dedicated from pserve
    #template_filenames = map(operator.attrgetter('absolute'), file_scan(config.registry.settings['mako.directories']))
    #from pyramid.scripts.pserve import add_file_callback
    #add_file_callback(lambda: template_filenames)

    # Parse/Convert setting keys that have specified datatypes
    # Environment variables; capitalized and separated by underscores can override a settings key.
    # e.g.
    #   export KARAKARA_TEMPLATE_TITLE=Test
    #   can override 'karakara.template.title'
    for key in config.registry.settings.keys():
        value = os.getenv(key.replace('.', '_').upper(), '') or config.registry.settings[key]
        config.registry.settings[key] = convert_str_with_type(value)

    config.add_request_method(partial(session_identity, session_keys={'id', 'admin', 'faves', 'user'}), 'session_identity', reify=True)

    setup_pyramid_autoformater(config)

    # i18n
    config.add_translation_dirs(config.registry.settings['i18n.translation_dirs'])

    # Session Manager
    session_settings = extract_subkeys(config.registry.settings, 'session.')
    session_factory = SignedCookieSessionFactory(serializer=json_serializer, **session_settings)
    config.set_session_factory(session_factory)

    # Cachebust etags ----------------------------------------------------------
    #  crude implementation; count the number of tags in db, if thats changed, the etags will invalidate
    if not config.registry.settings['server.etag.cache_buster']:
        from .model.actions import last_update
        config.registry.settings['server.etag.cache_buster'] = 'last_update:{0}'.format(str(last_update()))

    # Search Config ------------------------------------------------------------
    import karakara.views.search
    karakara.views.search.search_config = read_json(config.registry.settings['karakara.search.view.config'])
    assert karakara.views.search.search_config, 'search_config data required'

    # WebSocket ----------------------------------------------------------------

    class NullAuthEchoServerManager(object):
        def recv(self, *args, **kwargs):
            pass
    socket_manager = NullAuthEchoServerManager()

    if config.registry.settings.get('karakara.websocket.port'):
        def authenticator(key):
            """"""Only admin authenticated keys can connect to the websocket""""""
            request = pyramid.request.Request({'HTTP_COOKIE':'{0}={1}'.format(config.registry.settings['session.cookie_name'],key)})
            session_data = session_factory(request)
            return session_data and session_data.get('admin')
        try:
            _socket_manager = AuthEchoServerManager(
                authenticator=authenticator,
                websocket_port=config.registry.settings['karakara.websocket.port'],
                tcp_port=config.registry.settings.get('karakara.tcp.port'),
            )
            _socket_manager.start()
            socket_manager = _socket_manager
        except OSError:
            log.warn('Unable to setup websocket')

    config.registry['socket_manager'] = socket_manager


    # Login Providers ----------------------------------------------------------

    from .views.comunity_login import social_login
    social_login.user_store = ComunityUserStore()
    login_providers = config.registry.settings.get('login.provider.enabled')
    # Facebook
    if 'facebook' in login_providers:
        assert_settings_keys(
            ('login.facebook.appid', 'login.facebook.secret'),
            message='To use facebook as a login provider appid and secret must be provided'
        )
        social_login.add_login_provider(FacebookLogin(
            appid=config.registry.settings.get('login.facebook.appid'),
            secret=config.registry.settings.get('login.facebook.secret'),
            permissions=config.registry.settings.get('login.facebook.permissions'),
        ))
    # Google
    if 'google' in login_providers:
        social_login.add_login_provider(GoogleLogin(
            client_secret_file=config.registry.settings.get('login.google.client_secret_file'),
        ))
    # Firefox Persona (Deprecated technology but a useful reference)
    #if 'persona' in login_providers:
    #    social_login.add_login_provider(PersonaLogin(
    #        site_url=config.registry.settings.get('server.url')
    #    ))
    # No login provider
    if not login_providers and config.registry.settings.get('karakara.server.mode') == 'development':
        # Auto login if no service keys are provided
        social_login.add_login_provider(NullLoginProvider())
        social_login.user_store = NullComunityUserStore()
    template_helpers.javascript_inline['comunity'] = social_login.html_includes

    # Renderers ----------------------------------------------------------------

    # AllanC - currently the auto_format decorator does all the formatting work
    #          it would be far preferable to use the pyramid renderer framework
    #          issue is, we want to set the renderer to be dynamic based on the url given
    #          I don't want to define EVERY method with loads of renderer tags
    #          and I don't want to define 5+ routes for every view callable with differnt formats
    #          We need a nice way of doing this in pyramid, and right now, after HOURS of trawling
    #          the doc and experimenting, I cant find one.
    #from .renderers.auto_render_factory import AutoRendererFactory, handle_before_render
    #config.add_renderer(None   , AutoRendererFactory) #'renderers.auto_render_factory.auto_renderer_factory'
    #config.add_renderer('.html', 'pyramid.mako_templating.renderer_factory')
    #config.add_subscriber(handle_before_render , pyramid.events.BeforeRender) # maybe use this to set renderer?
    # closeset ive seen
    #   http://zhuoqiang.me/a/restful-pyramid
    #   http://stackoverflow.com/questions/4633320/is-there-a-better-way-to-switch-between-html-and-json-output-in-pyramid


    # Routes -------------------------------------------------------------------

    def settings_path(key):
        path = os.path.join(os.getcwd(), config.registry.settings[key])
        if not os.path.isdir(path):
            log.error(f'Unable to add_static_view {key}:{path}')
        return path

    # Static Routes
    config.add_static_view(name='ext', path=settings_path('static.externals'))  # cache_max_age=3600
    config.add_static_view(name='static', path=settings_path('static.assets'))  # cache_max_age=3600
    config.add_static_view(name='player', path=settings_path('static.player'))

    # AllanC - it's official ... static route setup and generation is a mess in pyramid
    #config.add_static_view(name=settings[""static.media"" ], path=""karakara:media"" )
    config.add_static_view(name='files', path=config.registry.settings['static.processmedia2.config']['path_processed'])

    # Routes
    def append_format_pattern(route):
        return re.sub(r'{(.*)}', r'{\1:[^/\.]+}', route) #+ r'{spacer:[.]?}{format:(%s)?}' % '|'.join(registered_formats())

    #config.add_route('home'          , append_format_pattern('/')              )
    #config.add_route('track'         , append_format_pattern('/track/{id}')    )
    #config.add_route('track_list'    , append_format_pattern('/track_list')    )
    config.add_route('track_import'  , append_format_pattern('/track_import')  )
    #config.add_route('queue'         , append_format_pattern('/queue')         )
    config.add_route('priority_tokens', append_format_pattern('/priority_tokens'))
    config.add_route('fave'          , append_format_pattern('/fave')          )
    config.add_route('message'       , append_format_pattern('/message')          )
    config.add_route('admin_toggle'  , append_format_pattern('/admin')         )
    config.add_route('admin_lock'    , append_format_pattern('/admin_lock')    )
    config.add_route('remote'        , append_format_pattern('/remote')        )
    config.add_route('feedback'      , append_format_pattern('/feedback')      )
    config.add_route('settings'      , append_format_pattern('/settings')      )
    config.add_route('random_images' , append_format_pattern('/random_images') )
    config.add_route('inject_testdata' , append_format_pattern('/inject_testdata') )
    config.add_route('stats'         , append_format_pattern('/stats')         )
    config.add_route('comunity'      , append_format_pattern('/comunity')      )
    config.add_route('comunity_login', append_format_pattern('/comunity/login'))
    config.add_route('comunity_logout', append_format_pattern('/comunity/logout'))
    config.add_route('comunity_list' , append_format_pattern('/comunity/list') )
    config.add_route('comunity_track', append_format_pattern('/comunity/track/{id}'))
    config.add_route('comunity_upload', append_format_pattern('/comunity/upload'))
    config.add_route('comunity_settings', append_format_pattern('/comunity/settings'))
    config.add_route('comunity_processmedia_log', append_format_pattern('/comunity/processmedia_log'))

    config.add_route('search_tags'   , '/search_tags/{tags:.*}')
    config.add_route('search_list'   , '/search_list/{tags:.*}')

    # Upload extras -----
    #config.add_static_view(name=settings['upload.route.uploaded'], path=settings['upload.path'])  # the 'upload' route above always matchs first
    config.add_route('upload', '/upload{sep:/?}{name:.*}')

    # Events -------------------------------------------------------------------
    config.add_subscriber(add_localizer_to_request, pyramid.events.NewRequest)
    config.add_subscriber(add_render_globals_to_template, pyramid.events.BeforeRender)

    # Return -------------------------------------------------------------------
    config.scan(ignore='.tests')
    config.scan('externals.lib.pyramid_helpers.views')
    return config.make_wsgi_app()


def add_localizer_to_request(event):
    request = event.request
    localizer = get_localizer(request)
    def auto_translate(*args, **kwargs):
        return localizer.translate(translation_string_factory(*args, **kwargs))
    request.localizer = localizer
    request.translate = auto_translate


def add_render_globals_to_template(event):
    request = event['request']
    event['_'] = request.translate
    event['localizer'] = request.localizer
    event['h'] = template_helpers
    event['traversal'] = pyramid.traversal
/n/n/nwebsite/karakara/traversal.py/n/n""""""

""""""
import pyramid.traversal


class TraversalGlobalRootFactory():
    __template__ = 'home'
    __name__ = ''

    def __init__(self, request):
        pass

    def __getitem__(self, key):
        return {
            'queue': QueueContext,
            'track': TrackContext,  # Admin only for all tracks
            'track_list': TrackListContext,  # Admin only for all tracks
            #'comunity': ComunityContext(),
            #'track_import': TrackImportContext(),  # Needs secure permissions
        }[key](parent=self)


class KaraKaraResourceMixin():
    @property
    def queue_id(self):
        queue_context = pyramid.traversal.find_interface(self, QueueContext)
        if queue_context:
            return queue_context.id
        return None


class QueueContext():
    __template__ = 'queue_home'
    __name__ = 'queue'

    def __init__(self, parent=None, id=None):
        self.__parent__ = parent
        self.id = id
        if self.id:
            self.__name__ = self.id

    def __getitem__(self, key=None):
        if self.id:
            return {
                'track': TrackContext,
                'track_list': TrackListContext,
                'queue_items': QueueItemsContext,
            }[key](parent=self)
        return QueueContext(parent=self, id=key)


class QueueItemsContext():
    __template__ = 'queue_items'
    __name__ = 'queue_items'

    def __init__(self, parent=None):
        self.__parent__ = parent


class TrackContext(KaraKaraResourceMixin):
    __template__ = 'track'
    __name__ = 'track'

    def __init__(self, parent=None, id=None):
        self.__parent__ = parent
        self.id = id
        if self.id:
            self.__name__ = self.id

    def __getitem__(self, key):
        if self.id:
            raise KeyError()
        return TrackContext(parent=self, id=key)


class ComunityContext():
    __template__ = 'comunity'


class TrackListContext():
    __template__ = 'track_list'

    def __init__(self, parent=None):
        self.__parent__ = parent


class TrackImportContext():
    pass
/n/n/nwebsite/karakara/views/misc.py/n/nfrom pyramid.view import view_config
from pyramid.httpexceptions import HTTPFound


from externals.lib.log import log_event

from . import web, action_ok, action_error, admin_only


import logging
log = logging.getLogger(__name__)


@view_config(context='karakara.traversal.TraversalGlobalRootFactory')
@web
def home(request):
    # Short term hack. Do not allow normal root page in commuity mode - redirect to comunity
    # Need to implement a proper pyramid authorize system when in comunity mode
    if request.registry.settings.get('karakara.server.mode') == 'comunity':
        raise HTTPFound(location='/comunity')
    return action_ok()


@view_config(route_name='stats')
@web
def stats(request):
    return action_ok()


@view_config(route_name='admin_lock')
@web
@admin_only
def admin_lock(request):
    request.registry.settings['admin_locked'] = not request.registry.settings.get('admin_locked', False)
    #log.debug('admin locked - {0}'.format(request.registry.settings['admin_locked']))
    log_event(request, admin_locked=request.registry.settings['admin_locked'])
    return action_ok()


@view_config(route_name='admin_toggle')
@web
def admin_toggle(request):
    if request.registry.settings.get('admin_locked'):
        raise action_error(message='additional admin users have been prohibited', code=403)
    request.session['admin'] = not request.session.get('admin', False)
    #log.debug('admin - {0} - {1}'.format(request.session['id'], request.session['admin']))
    log_event(request, admin=request.session['admin'])
    return action_ok()


@view_config(route_name='random_images')
@web
def random_images(request):
    """"""
    The player interface titlescreen can be populated with random thumbnails from the system.
    This is a nice showcase.
    Not optimised as this is rarely called.
    """"""
    import random
    from karakara.model import DBSession
    from karakara.model.model_tracks import Attachment
    images = DBSession.query(Attachment.location).filter(Attachment.type == 'image').all()
    # TODO: use serach.restrict_trags to get the images for the current event
    random.shuffle(images)
    images = [t[0] for t in images]
    return action_ok(data={'images': images[0: int(request.params.get('count', 0) or 100)]})
/n/n/nwebsite/karakara/views/queue.py/n/nfrom pyramid.view import view_config

from . import web, action_ok, action_error, etag_decorator, generate_cache_key

import logging
log = logging.getLogger(__name__)


def generate_cache_key_homepage(request):
    """"""
    Custom etag for homepage
    The homepage template has a few if statements to display various buttons
    The buttons can be disables in settings.
    This custom etag takes all 'if' statements in the homepage template
    """"""
    return '-'.join((
        generate_cache_key(request),
        str(request.registry.settings.get('karakara.template.menu.disable')),
        str(bool(request.session.get('faves', [])) and request.registry.settings.get('karakara.faves.enabled')),
    ))


@view_config(context='karakara.traversal.QueueContext')
@etag_decorator(generate_cache_key_homepage)
@web
def queue_home(request):
    return action_ok()
/n/n/nwebsite/karakara/views/queue_items.py/n/nimport datetime
import random
from functools import partial

from pyramid.view import view_config

from externals.lib.misc import now, subdict
from externals.lib.log import log_event

from . import web, action_ok, action_error, etag_decorator, cache, generate_cache_key, method_delete_router, method_put_router, is_admin, modification_action, admin_only
from . import _logic

from ..model import DBSession, commit
from ..model.model_queue import QueueItem
from ..model.model_tracks import Track
from ..model.model_priority_token import PriorityToken
from ..model.actions import get_track

from ..templates.helpers import track_title

from sqlalchemy.orm import joinedload, defer  # , joinedload_all
from sqlalchemy.orm.exc import NoResultFound

from .track import invalidate_track

import logging
log = logging.getLogger(__name__)


#-------------------------------------------------------------------------------
# Cache Management
#-------------------------------------------------------------------------------
QUEUE_CACHE_KEY = 'queue'

queue_version = random.randint(0, 2000000000)
def invalidate_queue(request=None):
    commit() # Before invalidating any cache data, ensure the new data is persisted
    global queue_version
    queue_version += 1
    cache.delete(QUEUE_CACHE_KEY)
    if request:
        request.registry['socket_manager'].recv('queue_updated'.encode('utf-8'))

#invalidate_queue()
def generate_cache_key_queue(request):
    global queue_version
    return '-'.join([generate_cache_key(request), str(queue_version)])


#-------------------------------------------------------------------------------
# Queue
#-------------------------------------------------------------------------------

#@view_config(route_name='queue', request_method='GET')
@view_config(context='karakara.traversal.QueueItemsContext', request_method='GET')
@etag_decorator(generate_cache_key_queue)
@web
def queue_view(request):
    """"""
    view current queue
    """"""
    import pdb ; pdb.set_trace()
    def get_queue_dict():
        log.debug('cache gen - queue {0}'.format(queue_version))

        # Get queue order
        queue_dicts = DBSession.query(QueueItem).filter(QueueItem.status=='pending').order_by(QueueItem.queue_weight)
        queue_dicts = [queue_item.to_dict('full') for queue_item in queue_dicts]

        # Fetch all tracks with id's in the queue
        trackids = [queue_item['track_id'] for queue_item in queue_dicts]
        tracks = {}
        if trackids:
            tracks = DBSession.query(Track).\
                                filter(Track.id.in_(trackids)).\
                                options(\
                                    joinedload(Track.tags),\
                                    joinedload(Track.attachments),\
                                    joinedload('tags.parent'),\
                                    #defer(Track.lyrics),\
                                )
            tracks = {track['id']:track for track in [track.to_dict('full', exclude_fields='lyrics') for track in tracks]}

        # HACK
        # AllanC - Hack to overlay title on API return.
        # This technically cant be part of the model because the title rendering in 'helpers' uses the dict version of a track object rather than the DB object
        # This is half the best place for it. We want the model to be as clean as possible
        # But we need the 'title' field to be consistant for all API returns for tracks ... more consideration needed
        #
        # Solution: Setup SQLAlchemy event to render the title before commiting a track to the DB - like a DB trigger by handled Python size for cross db compatibility
        #           Stub created in model_track.py
        #           This is to be removed ...
        for track in tracks.values():
            track['title'] = track_title(track['tags'])

        # Attach track to queue_item
        for queue_item in queue_dicts:
            queue_item['track'] = tracks.get(queue_item['track_id'])

        # Calculate estimated track time
        # Overlay 'total_duration' on all tracks
        # It takes time for performers to change, so each track add a padding time
        #  +
        # Calculate the index to split the queue list
        #  - non admin users do not see the whole queue in order.
        #  - after a specifyed time threshold, the quque order is obscured
        #  - it is expected that consumers of this api return will obscure the
        #    order passed the specifyed 'split_index'
        split_markers = list(request.registry.settings.get('karakara.queue.group.split_markers'))
        time_padding = request.registry.settings.get('karakara.queue.track.padding')
        split_indexs = []
        total_duration = datetime.timedelta(seconds=0)
        for index, queue_item in enumerate(queue_dicts):
            if not queue_item['track']:
                continue
            queue_item['total_duration'] = total_duration
            total_duration += datetime.timedelta(seconds=queue_item['track']['duration']) + time_padding
            if split_markers and total_duration > split_markers[0]:
                split_indexs.append(index + 1)
                del split_markers[0]

        return {'queue': queue_dicts, 'queue_split_indexs': split_indexs}

    queue_data = cache.get_or_create(QUEUE_CACHE_KEY, get_queue_dict)
    return action_ok(data=queue_data)


#@view_config(route_name='queue', request_method='POST')
@view_config(context='karakara.traversal.QueueItemsContext', request_method='POST')
@web
@modification_action
def queue_item_add(request):
    """"""
    Add items to end of queue
    """"""
    _ = request.translate
    _log_event = partial(log_event, request, method='add')

    # Validation
    for field in ['track_id', 'performer_name']:
        if not request.params.get(field):
            raise action_error(message='no {0}'.format(field), code=400)
    track_id = request.params.get('track_id')
    try:
        track = DBSession.query(Track).get(track_id)
        assert track
    except AssertionError:
        raise action_error(message=_('view.queue.add.error.track_id ${track_id}', mapping={'track_id': track_id}), code=400)

    # If not admin, check additional restrictions
    if not is_admin(request):

        performer_name = request.params.get('performer_name').strip()  # TODO: It would be good to ensure this value is writen to the db. However we cant modify the request.param dict directly. See creation of queueitem below

        # Valid performer name
        valid_performer_names = request.registry.settings.get('karakara.queue.add.valid_performer_names')
        if valid_performer_names and performer_name.lower() not in map(lambda name: name.lower(), valid_performer_names):
            message = _('view.queue.add.invalid_performer_name ${performer_name}', mapping=dict(
                performer_name=performer_name
            ))
            raise action_error(message, code=400)

        # Duplucate performer resrictions
        queue_item_performed_tracks = _logic.queue_item_for_performer(request, DBSession, request.params.get('performer_name'))
        if queue_item_performed_tracks['performer_status'] == _logic.QUEUE_DUPLICATE.THRESHOLD:
            try:
                latest_track_title = get_track(queue_item_performed_tracks['queue_items'][0].track_id).title
            except Exception:
                latest_track_title = ''
            message = _('view.queue.add.dupicate_performer_limit ${performer_name} ${estimated_next_add_time} ${track_count} ${latest_queue_item_title}', mapping=dict(
                performer_name=performer_name,
                latest_queue_item_title=latest_track_title,
                **subdict(queue_item_performed_tracks, {
                    'estimated_next_add_time',
                    'track_count',
                })
            ))
            _log_event(status='reject', reason='dupicate.performer', message=message)
            raise action_error(message=message, code=400)

        # Duplicate Addition Restrictions
        queue_item_tracks_queued = _logic.queue_item_for_track(request, DBSession, track.id)
        if queue_item_tracks_queued['track_status'] == _logic.QUEUE_DUPLICATE.THRESHOLD:
            message = _('view.queue.add.dupicate_track_limit ${track_id} ${estimated_next_add_time} ${track_count}', mapping=dict(
                track_id=track.id,
                **subdict(queue_item_performed_tracks, {
                    'estimated_next_add_time',
                    'track_count',
                })
            ))
            _log_event(status='reject', reason='duplicate.track', message=message)
            raise action_error(message=message, code=400)

        # Max queue length restrictions
        queue_duration = _logic.get_queue_duration(request)

        # Event end time
        event_end = request.registry.settings.get('karakara.event.end')
        if event_end and now()+queue_duration > event_end:
            log.debug('event end restricted')
            _log_event(status='reject', reason='event_end')
            raise action_error(message=_('view.queue.add.event_end ${event_end}', mapping={'event_end': event_end}), code=400)

        # Queue time limit
        queue_limit = request.registry.settings.get('karakara.queue.add.limit')
        if queue_limit and queue_duration > queue_limit:
            # If no device priority token - issue token and abort
            # else consume the token and proceed with addition
            if not _logic.consume_priority_token(request, DBSession):
                # Issue a priority token
                priority_token = _logic.issue_priority_token(request, DBSession)
                if isinstance(priority_token, PriorityToken):
                    _log_event(status='reject', reason='token.issued')
                    raise action_error(message=_('view.queue.add.priority_token_issued'), code=400)
                if priority_token == _logic.TOKEN_ISSUE_ERROR.EVENT_END:
                    _log_event(status='reject', reason='event_end')
                    raise action_error(message=_('view.queue.add.event_end ${event_end}', mapping={'event_end': event_end}), code=400)
                if priority_token == _logic.TOKEN_ISSUE_ERROR.TOKEN_ISSUED:
                    _log_event(status='reject', reason='token.already_issued')
                    raise action_error(message=_('view.queue.add.priority_token_already_issued'), code=400)
                _log_event(status='reject', reason='token.limit')
                raise action_error(message=_('view.queue.add.token_limit'), code=400)

    queue_item = QueueItem()
    queue_item.queue_id = 'PLACEHOLDER'
    for key, value in request.params.items():
        if hasattr(queue_item, key):
            setattr(queue_item, key, value)

    # Set session owner - if admin allow manual setting of session_owner via params
    if is_admin(request) and queue_item.session_owner:
        pass
    else:
        queue_item.session_owner = request.session['id']

    DBSession.add(queue_item)
    _log_event(status='ok', track_id=queue_item.track_id, performer_name=queue_item.performer_name)
    #log.info('add - %s to queue by %s' % (queue_item.track_id, queue_item.performer_name))

    invalidate_queue(request)  # Invalidate Cache
    invalidate_track(track_id)

    return action_ok(message='track queued', data={'queue_item.id': ''}, code=201)  # TODO: should return 201 and have id of newly created object. data={'track':{'id':}}


#@view_config(route_name='queue', custom_predicates=(method_delete_router, lambda info,request: request.params.get('queue_item.id')) ) #request_method='POST',
@view_config(context='karakara.traversal.QueueItemsContext', custom_predicates=(method_delete_router, lambda info,request: request.params.get('queue_item.id')))
@web
@modification_action
def queue_item_del(request):
    """"""
    Remove items from the queue

    check session owner or admin
    state can be passed as ""complete"" to mark track as played

    TODO: THIS DOES NOT CONFORM TO THE REST STANDARD!!! Refactor
    """"""
    _log_event = partial(log_event, request, method='del')

    queue_item_id = int(request.params['queue_item.id'])
    queue_item = DBSession.query(QueueItem).get(queue_item_id)

    if not queue_item:
        _log_event(status='reject', reason='invalid.queue_item.id', queue_item_id=queue_item_id)
        raise action_error(message='invalid queue_item.id', code=404)
    if not is_admin(request) and queue_item.session_owner != request.session['id']:
        _log_event(status='reject', reason='not_owner', track_id=queue_item.track_id)
        raise action_error(message='you are not the owner of this queue_item', code=403)

    #DBSession.delete(queue_item)
    queue_item.status = request.params.get('status', 'removed')

    _log_event(status='ok', track_id=queue_item.track_id)
    #log.info('remove - %s from queue' % (queue_item.track_id))
    queue_item_track_id = queue_item.track_id  # Need to get queue_item.track_id now, as it will be cleared by invalidate_queue

    invalidate_queue(request)  # Invalidate Cache
    invalidate_track(queue_item_track_id)

    return action_ok(message='queue_item status changed')


#@view_config(route_name='queue', custom_predicates=(method_put_router,))  # request_method='PUT'
@view_config(context='karakara.traversal.QueueItemsContext', custom_predicates=(method_put_router,))
@web
@modification_action
def queue_item_update(request):
    """"""
    Used to touch queed items

    check session owner or admin

    TODO: THIS DOES NOT CONFORM TO THE REST STANDARD!!! Refactor
    """"""
    _log_event = partial(log_event, request, method='update')

    params = dict(request.params)

    for field in [f for f in ['queue_item.id', 'queue_item.move.target_id'] if f in params]:
        try:
            params[field] = int(params[field])
        except ValueError:
            raise action_error(message='invalid {0}'.format(field), code=404)

    queue_item_id = int(params['queue_item.id'])
    queue_item = DBSession.query(QueueItem).get(queue_item_id)

    if not queue_item:
        _log_event(status='reject', reason='invalid.queue_item.id', queue_item_id=queue_item_id)
        raise action_error(message='invalid queue_item.id', code=404)
    if not is_admin(request) and queue_item.session_owner != request.session['id']:
        _log_event(status='reject', reason='not_owner', track_id=queue_item.track_id)
        raise action_error(message='you are not the owner of this queue_item', code=403)

    # If moving, lookup new weighting from the target track id
    # The source is moved infront of the target_id
    if params.get('queue_item.move.target_id'):
        if not is_admin(request):
            _log_event(status='reject', reason='move.not_admin', queue_item_id=queue_item_id)
            raise action_error(message='admin only action', code=403)
        # get next and previous queueitem weights
        try:
            target_weight,  = DBSession.query(QueueItem.queue_weight).filter(QueueItem.id==params.pop('queue_item.move.target_id')).one()
            try:
                target_weight_next,  = DBSession.query(QueueItem.queue_weight).filter(QueueItem.queue_weight<target_weight).order_by(QueueItem.queue_weight.desc()).limit(1).one()
            except NoResultFound:
                target_weight_next = 0.0
            # calculate weight inbetween and inject that weight into the form params for saving
            params['queue_weight'] = (target_weight + target_weight_next) / 2.0
        except NoResultFound:
            log.debug('queue_item.move.target_id not found, assuming end of queue is the target')
            params['queue_weight'] = QueueItem.new_weight(DBSession)

    # Update any params to the db
    for key, value in params.items():
        if hasattr(queue_item, key):
            setattr(queue_item, key, value)
    queue_item.time_touched = datetime.datetime.now()  # Update touched timestamp

    #log.info('update - %s' % (queue_item.track_id))
    _log_event(status='ok', track_id=queue_item.track_id)

    queue_item_track_id = queue_item.track_id

    invalidate_queue(request)  # Invalidate Cache
    invalidate_track(queue_item_track_id)

    return action_ok(message='queue_item updated')


@view_config(route_name='priority_tokens')
@web
@admin_only
def priority_tokens(request):
    priority_tokens = DBSession.query(PriorityToken)\
        .filter(PriorityToken.valid_start >= now() - request.registry.settings.get('karakara.queue.add.duplicate.time_limit')) \
        .order_by(PriorityToken.valid_start)
    return action_ok(data={
        'priority_tokens': (priority_token.to_dict('full') for priority_token in priority_tokens),
    })
/n/n/n",0
153,153,c0418996aa5c69b22201de3223b13e31741a0c9d,"/website/karakara/__init__.py/n/nimport os
import re
import operator
from functools import partial

# Pyramid imports
import pyramid.events
import pyramid.request
import pyramid.config
from pyramid.session import SignedCookieSessionFactory  # TODO: should needs to be replaced with an encrypted cookie or a hacker at an event may be able to intercept other users id's
from pyramid.i18n import get_localizer, TranslationStringFactory

# External Imports
from externals.lib.misc import convert_str_with_type, read_json, extract_subkeys, json_serializer, file_scan
from externals.lib.pyramid_helpers.auto_format2 import setup_pyramid_autoformater
from externals.lib.pyramid_helpers.session_identity2 import session_identity
from externals.lib.social._login import NullLoginProvider, FacebookLogin, GoogleLogin
from externals.lib.multisocket.auth_echo_server import AuthEchoServerManager

# Package Imports
from .traversal import TraversalGlobalRootFactory
from .templates import helpers as template_helpers
from .auth import ComunityUserStore, NullComunityUserStore
# SQLAlchemy imports
from .model import init_DBSession


import logging
log = logging.getLogger(__name__)

translation_string_factory = TranslationStringFactory('karakara')


def main(global_config, **settings):
    """"""
        This function returns a Pyramid WSGI application.
    """"""
    # Setup --------------------------------------------------------------------

    # Db
    init_DBSession(settings)

    # Pyramid Global Settings
    config = pyramid.config.Configurator(settings=settings, root_factory=TraversalGlobalRootFactory)  # , autocommit=True

    def assert_settings_keys(keys):
        for settings_key in key:
            assert config.registry.settings.get(settings_key)

    # Register Additional Includes ---------------------------------------------
    config.include('pyramid_mako')  # The mako.directories value is updated in the scan for addons. We trigger the import here to include the correct folders.

    # Reload on template change - Dedicated from pserve
    #template_filenames = map(operator.attrgetter('absolute'), file_scan(config.registry.settings['mako.directories']))
    #from pyramid.scripts.pserve import add_file_callback
    #add_file_callback(lambda: template_filenames)

    # Parse/Convert setting keys that have specified datatypes
    # Environment variables; capitalized and separated by underscores can override a settings key.
    # e.g.
    #   export KARAKARA_TEMPLATE_TITLE=Test
    #   can override 'karakara.template.title'
    for key in config.registry.settings.keys():
        value = os.getenv(key.replace('.', '_').upper(), '') or config.registry.settings[key]
        config.registry.settings[key] = convert_str_with_type(value)

    config.add_request_method(partial(session_identity, session_keys={'id', 'admin', 'faves', 'user'}), 'session_identity', reify=True)

    setup_pyramid_autoformater(config)

    # i18n
    config.add_translation_dirs(config.registry.settings['i18n.translation_dirs'])

    # Session Manager
    session_settings = extract_subkeys(config.registry.settings, 'session.')
    session_factory = SignedCookieSessionFactory(serializer=json_serializer, **session_settings)
    config.set_session_factory(session_factory)

    # Cachebust etags ----------------------------------------------------------
    #  crude implementation; count the number of tags in db, if thats changed, the etags will invalidate
    if not config.registry.settings['server.etag.cache_buster']:
        from .model.actions import last_update
        config.registry.settings['server.etag.cache_buster'] = 'last_update:{0}'.format(str(last_update()))

    # Search Config ------------------------------------------------------------
    import karakara.views.search
    karakara.views.search.search_config = read_json(config.registry.settings['karakara.search.view.config'])
    assert karakara.views.search.search_config, 'search_config data required'

    # WebSocket ----------------------------------------------------------------

    class NullAuthEchoServerManager(object):
        def recv(self, *args, **kwargs):
            pass
    socket_manager = NullAuthEchoServerManager()

    if config.registry.settings.get('karakara.websocket.port'):
        def authenticator(key):
            """"""Only admin authenticated keys can connect to the websocket""""""
            request = pyramid.request.Request({'HTTP_COOKIE':'{0}={1}'.format(config.registry.settings['session.cookie_name'],key)})
            session_data = session_factory(request)
            return session_data and session_data.get('admin')
        try:
            _socket_manager = AuthEchoServerManager(
                authenticator=authenticator,
                websocket_port=config.registry.settings['karakara.websocket.port'],
                tcp_port=config.registry.settings.get('karakara.tcp.port'),
            )
            _socket_manager.start()
            socket_manager = _socket_manager
        except OSError:
            log.warn('Unable to setup websocket')

    config.registry['socket_manager'] = socket_manager


    # Login Providers ----------------------------------------------------------

    from .views.comunity_login import social_login
    social_login.user_store = ComunityUserStore()
    login_providers = config.registry.settings.get('login.provider.enabled')
    # Facebook
    if 'facebook' in login_providers:
        assert_settings_keys(
            ('login.facebook.appid', 'login.facebook.secret'),
            message='To use facebook as a login provider appid and secret must be provided'
        )
        social_login.add_login_provider(FacebookLogin(
            appid=config.registry.settings.get('login.facebook.appid'),
            secret=config.registry.settings.get('login.facebook.secret'),
            permissions=config.registry.settings.get('login.facebook.permissions'),
        ))
    # Google
    if 'google' in login_providers:
        social_login.add_login_provider(GoogleLogin(
            client_secret_file=config.registry.settings.get('login.google.client_secret_file'),
        ))
    # Firefox Persona (Deprecated technology but a useful reference)
    #if 'persona' in login_providers:
    #    social_login.add_login_provider(PersonaLogin(
    #        site_url=config.registry.settings.get('server.url')
    #    ))
    # No login provider
    if not login_providers and config.registry.settings.get('karakara.server.mode') == 'development':
        # Auto login if no service keys are provided
        social_login.add_login_provider(NullLoginProvider())
        social_login.user_store = NullComunityUserStore()
    template_helpers.javascript_inline['comunity'] = social_login.html_includes

    # Renderers ----------------------------------------------------------------

    # AllanC - currently the auto_format decorator does all the formatting work
    #          it would be far preferable to use the pyramid renderer framework
    #          issue is, we want to set the renderer to be dynamic based on the url given
    #          I don't want to define EVERY method with loads of renderer tags
    #          and I don't want to define 5+ routes for every view callable with differnt formats
    #          We need a nice way of doing this in pyramid, and right now, after HOURS of trawling
    #          the doc and experimenting, I cant find one.
    #from .renderers.auto_render_factory import AutoRendererFactory, handle_before_render
    #config.add_renderer(None   , AutoRendererFactory) #'renderers.auto_render_factory.auto_renderer_factory'
    #config.add_renderer('.html', 'pyramid.mako_templating.renderer_factory')
    #config.add_subscriber(handle_before_render , pyramid.events.BeforeRender) # maybe use this to set renderer?
    # closeset ive seen
    #   http://zhuoqiang.me/a/restful-pyramid
    #   http://stackoverflow.com/questions/4633320/is-there-a-better-way-to-switch-between-html-and-json-output-in-pyramid


    # Routes -------------------------------------------------------------------

    def settings_path(key):
        path = os.path.join(os.getcwd(), config.registry.settings[key])
        if not os.path.isdir(path):
            log.error(f'Unable to add_static_view {key}:{path}')
        return path

    # Static Routes
    config.add_static_view(name='ext', path=settings_path('static.externals'))  # cache_max_age=3600
    config.add_static_view(name='static', path=settings_path('static.assets'))  # cache_max_age=3600
    config.add_static_view(name='player', path=settings_path('static.player'))

    # AllanC - it's official ... static route setup and generation is a mess in pyramid
    #config.add_static_view(name=settings[""static.media"" ], path=""karakara:media"" )
    config.add_static_view(name='files', path=config.registry.settings['static.processmedia2.config']['path_processed'])

    # Routes
    def append_format_pattern(route):
        return re.sub(r'{(.*)}', r'{\1:[^/\.]+}', route) #+ r'{spacer:[.]?}{format:(%s)?}' % '|'.join(registered_formats())

    #config.add_route('home'          , append_format_pattern('/')              )
    #config.add_route('track'         , append_format_pattern('/track/{id}')    )
    #config.add_route('track_list'    , append_format_pattern('/track_list')    )
    config.add_route('track_import'  , append_format_pattern('/track_import')  )
    config.add_route('queue'         , append_format_pattern('/queue')         )
    config.add_route('priority_tokens', append_format_pattern('/priority_tokens'))
    config.add_route('fave'          , append_format_pattern('/fave')          )
    config.add_route('message'       , append_format_pattern('/message')          )
    config.add_route('admin_toggle'  , append_format_pattern('/admin')         )
    config.add_route('admin_lock'    , append_format_pattern('/admin_lock')    )
    config.add_route('remote'        , append_format_pattern('/remote')        )
    config.add_route('feedback'      , append_format_pattern('/feedback')      )
    config.add_route('settings'      , append_format_pattern('/settings')      )
    config.add_route('random_images' , append_format_pattern('/random_images') )
    config.add_route('inject_testdata' , append_format_pattern('/inject_testdata') )
    config.add_route('stats'         , append_format_pattern('/stats')         )
    config.add_route('comunity'      , append_format_pattern('/comunity')      )
    config.add_route('comunity_login', append_format_pattern('/comunity/login'))
    config.add_route('comunity_logout', append_format_pattern('/comunity/logout'))
    config.add_route('comunity_list' , append_format_pattern('/comunity/list') )
    config.add_route('comunity_track', append_format_pattern('/comunity/track/{id}'))
    config.add_route('comunity_upload', append_format_pattern('/comunity/upload'))
    config.add_route('comunity_settings', append_format_pattern('/comunity/settings'))
    config.add_route('comunity_processmedia_log', append_format_pattern('/comunity/processmedia_log'))

    config.add_route('search_tags'   , '/search_tags/{tags:.*}')
    config.add_route('search_list'   , '/search_list/{tags:.*}')

    # Upload extras -----
    #config.add_static_view(name=settings['upload.route.uploaded'], path=settings['upload.path'])  # the 'upload' route above always matchs first
    config.add_route('upload', '/upload{sep:/?}{name:.*}')

    # Events -------------------------------------------------------------------
    config.add_subscriber(add_localizer_to_request, pyramid.events.NewRequest)
    config.add_subscriber(add_render_globals_to_template, pyramid.events.BeforeRender)

    # Return -------------------------------------------------------------------
    config.scan(ignore='.tests')
    config.scan('externals.lib.pyramid_helpers.views')
    return config.make_wsgi_app()


def add_localizer_to_request(event):
    request = event.request
    localizer = get_localizer(request)
    def auto_translate(*args, **kwargs):
        return localizer.translate(translation_string_factory(*args, **kwargs))
    request.localizer = localizer
    request.translate = auto_translate


def add_render_globals_to_template(event):
    request = event['request']
    event['_'] = request.translate
    event['localizer'] = request.localizer
    event['h'] = template_helpers
/n/n/n",1
214,214,02256eedb8fecc60376f35d2f772e9bc275c5574,"ApkXmind.py/n/nimport xmind
from xmind.core import workbook,saver
from xmind.core.topic import TopicElement
from Configuration import *
from datetime import datetime
import time

class ApkXmind:

    app = """"
    workbook = """"
    sheet = """"
    configuration = Configuration()

    def __init__(self ,app):
        versionAlreadyExists = False
        self.app = app
        cwd = os.path.dirname(os.path.realpath(__file__))+""/output_xmind/""
        self.workbook = xmind.load(cwd+app.getPackageName( ) +"".xmind"")
	print ""[-]Generating Xmind""
        if len(self.workbook.getSheets()) == 1:
            if self.workbook.getPrimarySheet().getTitle() == None:
                self.sheet = self.workbook.getPrimarySheet()
                self.sheet.setTitle(app.getVersionCode())
            else:
                self.sheet = self.workbook.createSheet()
                self.sheet.setTitle(app.getVersionCode())
                self.workbook.addSheet(self.sheet)
        else:
            self.sheet = self.workbook.createSheet()
            self.sheet.setTitle(app.getVersionCode())
            self.workbook.addSheet(self.sheet)
        rootTopic =self.sheet.getRootTopic()
        rootTopic.setTitle(app.getPackageName())
        rootTopic.setTopicStructure(self.configuration.geXmindTopicStructure())
        self.createTopics()
        self.save()

    def getRootTopic(self):
        return self.sheet.getRootTopic()

    def createTopics(self):


        informationGatheringTopic = TopicElement()
        informationGatheringTopic.setTitle(""Information Gathering"")

        methodologyTopic = TopicElement()
        methodologyTopic.setTitle(""Methodology"")


        # Properties Topic

        topicElement = TopicElement()
        topicElement.setTitle(""Properties"")
        informationGatheringTopic.addSubTopic(topicElement)
        subtopics = [""Version Name"" ,""Version Code"" ,""SHA 256"" ,""Minimum SDK Version"",""Target SDK Version"" ,""Xamarin"" ,""Cordova""
                     ,""Outsystems"" ,""Backup Enabled"" ,""Multiple Dex Classes"" ,""Secret Codes""]
        self.createSubTopics(informationGatheringTopic.getSubTopicByIndex(0) ,subtopics)
        topicElement = TopicElement()
        topicElement.setTitle(self.app.getVersionName())
        informationGatheringTopic.getSubTopicByIndex(0).getSubTopicByIndex(0).addSubTopic(topicElement)
        topicElement = TopicElement()
        topicElement.setTitle(self.app.getVersionCode())
        informationGatheringTopic.getSubTopicByIndex(0).getSubTopicByIndex(1).addSubTopic(topicElement)
        topicElement = TopicElement()
        topicElement.setTitle(self.app.getSHA256())
        informationGatheringTopic.getSubTopicByIndex(0).getSubTopicByIndex(2).addSubTopic(topicElement)
        topicElement = TopicElement()
        topicElement.setTitle \
            (self.app.getMinSDKVersion( ) +"" ( "" +self.app.getCodeName(self.app.getMinSDKVersion() ) +"")"")
        informationGatheringTopic.getSubTopicByIndex(0).getSubTopicByIndex(3).addSubTopic(topicElement)

        topicElement = TopicElement()
        topicElement.setTitle \
            (self.app.getTargetSDKVersion() + "" ( "" + self.app.getCodeName(self.app.getTargetSDKVersion()) + "")"")
        informationGatheringTopic.getSubTopicByIndex(0).getSubTopicByIndex(4).addSubTopic(topicElement)

        topicElement = TopicElement()
        topicElement.setTitle(self.app.isXamarin())
        if self.app.isXamarin() == ""Yes"":
            bundledTopic = TopicElement()
            bundledTopic.setTitle(""Bundled?"")
            bundledValue = TopicElement()
            bundledValue.setTitle(self.app.isXamarinBundled())
            bundledTopic.addSubTopic(bundledValue)
            topicElement.addSubTopic(bundledTopic)
        informationGatheringTopic.getSubTopicByIndex(0).getSubTopicByIndex(5).addSubTopic(topicElement)
        topicElement = TopicElement()
        topicElement.setTitle(self.app.isCordova())
        if (self.app.isCordova() == ""Yes""):
            if (len(self.app.getCordovaPlugins())) > 0:
                cordovaPluginsTopic = TopicElement()
                cordovaPluginsTopic.setTitle(""Plugins"")
                self.createSubTopics(cordovaPluginsTopic,self.app.getCordovaPlugins())
                topicElement.addSubTopic(cordovaPluginsTopic)
        informationGatheringTopic.getSubTopicByIndex(0).getSubTopicByIndex(6).addSubTopic(topicElement)
        topicElement = TopicElement()
        topicElement.setTitle(self.app.isOutsystems())
        informationGatheringTopic.getSubTopicByIndex(0).getSubTopicByIndex(7).addSubTopic(topicElement)
        topicElement = TopicElement()
        topicElement = TopicElement()
        topicElement.setTitle(self.app.isBackupEnabled())
        informationGatheringTopic.getSubTopicByIndex(0).getSubTopicByIndex(8).addSubTopic(topicElement)
        topicElement = TopicElement()
        topicElement.setTitle(self.app.isMultiDex())
        informationGatheringTopic.getSubTopicByIndex(0).getSubTopicByIndex(9).addSubTopic(topicElement)
        topicElement = TopicElement()
        if len(self.app.getSecretCodes()) >0:
            self.createSubTopics(topicElement, self.app.getSecretCodes())
            informationGatheringTopic.getSubTopicByIndex(0).getSubTopicByIndex(10).addSubTopic(topicElement)
        else:
            topicElement.setTitle(""No"")
            informationGatheringTopic.getSubTopicByIndex(0).getSubTopicByIndex(10).addSubTopic(topicElement)

        # Permissions Topic

        topicElement = TopicElement()
        topicElement.setTitle(""Permissions"")
        informationGatheringTopic.addSubTopic(topicElement)
        self.createSubTopics(informationGatheringTopic.getSubTopicByIndex(1) ,self.app.getPermissions())
        if len(self.app.getPermissions()) > self.configuration.getXmindTopipFoldAt():
            topicElement.setFolded()


        # Exported Components Topic

        topicElement = TopicElement()
        topicElement.setTitle(""Exported Components"")
        informationGatheringTopic.addSubTopic(topicElement)
        subtopics = [""Activities"" ,""Broadcast Receivers"" ,""Content Providers"" ,""Services""]
        self.createSubTopics(informationGatheringTopic.getSubTopicByIndex(2) ,subtopics)
        for activity in self.app.getExportedActivities():
            topicElement = TopicElement()
            topicElement.setTitle(activity)
            if self.app.getComponentPermission(activity) != """":
                permissionTopic = TopicElement()
                permissionTopic.setTitle(""Permission: ""+self.app.getComponentPermission(activity))
                topicElement.addSubTopic(permissionTopic)
            try:
	        filters = self.app.getIntentFiltersList()[activity]
	        i = 1
	        for filter in filters:
	            intentTopic = TopicElement()
	            intentTopic.setTitle(""Intent Filter ""+str(i))
	            i+=1
	            action = TopicElement()
	            action.setTitle(""Action"")
	            self.createSubTopics(action, filter.getActionList())
	            category = TopicElement()
	            category.setTitle(""Categories"")
	            self.createSubTopics(category,filter.getCategoryList())
	            data = TopicElement()
	            data.setTitle(""Data"")
	            self.createSubTopics(data, filter.getDataList())
	            intentTopic.addSubTopic(action)
	            intentTopic.addSubTopic(category)
	            intentTopic.addSubTopic(data)
	            intentTopic.setFolded()
	            topicElement.addSubTopic(intentTopic)
            except:
                pass
            informationGatheringTopic.getSubTopicByIndex(2).getSubTopicByIndex(0).addSubTopic(topicElement)
        if len(self.app.getExportedActivities()) > self.configuration.getXmindTopipFoldAt():
            informationGatheringTopic.getSubTopicByIndex(2).getSubTopicByIndex(0).setFolded()
        for receiver in self.app.getExportedReceivers():
            topicElement = TopicElement()
            topicElement.setTitle(receiver)
            if self.app.getComponentPermission(receiver) != """":
                permissionTopic = TopicElement()
                permissionTopic.setTitle(""Permission: ""+self.app.getComponentPermission(receiver))
                topicElement.addSubTopic(permissionTopic)
            try:
                filters = self.app.getIntentFiltersList()[receiver]
                i = 1
                for filter in filters:
                    intentTopic = TopicElement()
                    intentTopic.setTitle(""Intent Filter "" + str(i))
                    i += 1
                    action = TopicElement()
                    action.setTitle(""Action"")
                    self.createSubTopics(action, filter.getActionList())
                    category = TopicElement()
                    category.setTitle(""Categories"")
                    self.createSubTopics(category, filter.getCategoryList())
                    data = TopicElement()
                    data.setTitle(""Data"")
                    self.createSubTopics(data, filter.getDataList())
                    intentTopic.addSubTopic(action)
                    intentTopic.addSubTopic(category)
                    intentTopic.addSubTopic(data)
                    intentTopic.setFolded()
                    topicElement.addSubTopic(intentTopic)
            except:
                pass
            informationGatheringTopic.getSubTopicByIndex(2).getSubTopicByIndex(1).addSubTopic(topicElement)
        if len(self.app.smaliChecks.getDynamicRegisteredBroadcastReceiversLocations()) > 0:
            dynamicRegisteredBroadcastReceiverTopic = TopicElement()
            dynamicRegisteredBroadcastReceiverTopic.setTitle(""Dynamically Registered"")
            self.createSubTopics(dynamicRegisteredBroadcastReceiverTopic,self.app.smaliChecks.getDynamicRegisteredBroadcastReceiversLocations())
            informationGatheringTopic.getSubTopicByIndex(2).getSubTopicByIndex(1).addSubTopic(dynamicRegisteredBroadcastReceiverTopic)
            if len(self.app.smaliChecks.getDynamicRegisteredBroadcastReceiversLocations()) > self.configuration.getXmindTopipFoldAt():
                dynamicRegisteredBroadcastReceiverTopic.setFolded()

        if len(self.app.getExportedReceivers()) > self.configuration.getXmindTopipFoldAt():
            informationGatheringTopic.getSubTopicByIndex(2).getSubTopicByIndex(1).setFolded()
        for provider in self.app.getExportedProviders():
            topicElement = TopicElement()
            topicElement.setTitle(provider)
            if self.app.getComponentPermission(provider) != """":
                permissionTopic = TopicElement()
                permissionTopic.setTitle(""Permission: ""+self.app.getComponentPermission(provider))
                topicElement.addSubTopic(permissionTopic)
            try:
                filters = self.app.getIntentFiltersList()[provider]
                i = 1
                for filter in filters:
                    intentTopic = TopicElement()
                    intentTopic.setTitle(""Intent Filter "" + str(i))
                    i += 1
                    action = TopicElement()
                    action.setTitle(""Action"")
                    self.createSubTopics(action, filter.getActionList())
                    category = TopicElement()
                    category.setTitle(""Categories"")
                    self.createSubTopics(category, filter.getCategoryList())
                    data = TopicElement()
                    data.setTitle(""Data"")
                    self.createSubTopics(data, filter.getDataList())
                    intentTopic.addSubTopic(action)
                    intentTopic.addSubTopic(category)
                    intentTopic.addSubTopic(data)
                    intentTopic.setFolded()
                    topicElement.addSubTopic(intentTopic)
            except:
                pass
            informationGatheringTopic.getSubTopicByIndex(2).getSubTopicByIndex(2).addSubTopic(topicElement)
        if len(self.app.getExportedProviders()) > self.configuration.getXmindTopipFoldAt():
            informationGatheringTopic.getSubTopicByIndex(2).getSubTopicByIndex(2).setFolded()
        for service in self.app.getExportedServices():
            topicElement = TopicElement()
            topicElement.setTitle(service)
            if self.app.getComponentPermission(service) != """":
                permissionTopic = TopicElement()
                permissionTopic.setTitle(""Permission: ""+self.app.getComponentPermission(service))
                topicElement.addSubTopic(permissionTopic)
            try:
                filters = self.app.getIntentFiltersList()[service]
                i = 1
                for filter in filters:
                    intentTopic = TopicElement()
                    intentTopic.setTitle(""Intent Filter "" + str(i))
                    i += 1
                    action = TopicElement()
                    action.setTitle(""Action"")
                    self.createSubTopics(action, filter.getActionList())
                    category = TopicElement()
                    category.setTitle(""Categories"")
                    self.createSubTopics(category, filter.getCategoryList())
                    data = TopicElement()
                    data.setTitle(""Data"")
                    self.createSubTopics(data, filter.getDataList())
                    intentTopic.addSubTopic(action)
                    intentTopic.addSubTopic(category)
                    intentTopic.addSubTopic(data)
                    intentTopic.setFolded()
                    topicElement.addSubTopic(intentTopic)
            except:
                pass
            informationGatheringTopic.getSubTopicByIndex(2).getSubTopicByIndex(3).addSubTopic(topicElement)
        if len(self.app.getExportedServices()) > self.configuration.getXmindTopipFoldAt():
            informationGatheringTopic.getSubTopicByIndex(2).getSubTopicByIndex(3).setFolded()

        # Files Topic

        topicElement = TopicElement()
        topicElement.setTitle(""Files"")
        topicElement.setPlainNotes(""Excluded files/locations: ""+self.configuration.getFileExclusions())
        fileTypes = [""Assets"" ,""Libs"" ,""Raw Resources"" ,""Dex Classes"" ,""Cordova Files"",""Xamarin Assemblies"",""Other""]
        tooManySubtopicsElement = TopicElement()
        tooManySubtopicsElement.setTitle(""Too many files. Hit configured threshold."")
        self.createSubTopics(topicElement ,fileTypes)
        self.createSubTopics(topicElement.getSubTopicByIndex(0) ,self.app.getAssets())
        if len(self.app.getAssets()) > self.configuration.getXmindTopipFoldAt():
            topicElement.getSubTopicByIndex(0).setFolded()
        if len(self.app.getLibs()) > self.configuration.getXmindTopipFoldAt():
            topicElement.getSubTopicByIndex(1).setFolded()
        if len(self.app.getRawResources()) > self.configuration.getXmindTopipFoldAt():
            topicElement.getSubTopicByIndex(2).setFolded()
        if len(self.app.getCordovaFiles()) > self.configuration.getXmindTopipFoldAt():
            topicElement.getSubTopicByIndex(4).setFolded()
        if len(self.app.getXamarinAssemblies()) > self.configuration.getXmindTopipFoldAt():
            topicElement.getSubTopicByIndex(5).setFolded()
        if len(self.app.getOtherFiles()) > self.configuration.getXmindTopipFoldAt():
            topicElement.getSubTopicByIndex(6).setFolded()
        self.createSubTopics(topicElement.getSubTopicByIndex(1) ,self.app.getLibs())
        self.createSubTopics(topicElement.getSubTopicByIndex(2) ,self.app.getRawResources())
        self.createSubTopics(topicElement.getSubTopicByIndex(3), self.app.getDexFiles())
        self.createSubTopics(topicElement.getSubTopicByIndex(4), self.app.getCordovaFiles())
        self.createSubTopics(topicElement.getSubTopicByIndex(5), self.app.getXamarinAssemblies())
        if len(self.app.getOtherFiles()) <= self.app.configuration.getMaxSubTopics():
            self.createSubTopics(topicElement.getSubTopicByIndex(6), self.app.getOtherFiles())
        else:
            topicElement.getSubTopicByIndex(6).addSubTopic(tooManySubtopicsElement)
        informationGatheringTopic.addSubTopic(topicElement)

        # Object Usage Topic

        topicElement = TopicElement()
        topicElement.setTitle(""Object Usage"")
        objectsSubTopics = [""WebViews loadUrl"",""Cryptographic Functions"", ""Custom""]
        self.createSubTopics(topicElement, objectsSubTopics)

        if len(self.app.smaliChecks.getWebViewsLoadUrlUsageLocations()) > self.configuration.getXmindTopipFoldAt():
            topicElement.getSubTopicByIndex(0).setFolded()


        self.createSubTopics(topicElement.getSubTopicByIndex(0),self.app.smaliChecks.getWebViewsLoadUrlUsageLocations())
        encryptionSubTopic = TopicElement()
        encryptionSubTopic.setTitle(""Encryption"")
        self.createSubTopics(encryptionSubTopic, self.app.smaliChecks.getEncryptionFunctionsLocations())
        if (len(self.app.smaliChecks.getEncryptionFunctionsLocations()) > self.configuration.getXmindTopipFoldAt()):
            encryptionSubTopic.setFolded()

        decryptionSubtopic = TopicElement()
        decryptionSubtopic.setTitle(""Decryption"")
        self.createSubTopics(decryptionSubtopic, self.app.smaliChecks.getDecryptionFunctionsLocations())
        if (len(self.app.smaliChecks.getDecryptionFunctionsLocations()) > self.configuration.getXmindTopipFoldAt()):
            decryptionSubtopic.setFolded()

        undeterminedSubtopic = TopicElement()
        undeterminedSubtopic.setTitle(""Undetermined"")
        self.createSubTopics(undeterminedSubtopic, self.app.smaliChecks.getUndeterminedCryptographicFunctionsLocations())
        if (len(self.app.smaliChecks.getUndeterminedCryptographicFunctionsLocations()) > self.configuration.getXmindTopipFoldAt()):
            undeterminedSubtopic.setFolded()


        topicElement.getSubTopicByIndex(1).addSubTopic(encryptionSubTopic)
        topicElement.getSubTopicByIndex(1).addSubTopic(decryptionSubtopic)
        topicElement.getSubTopicByIndex(1).addSubTopic(undeterminedSubtopic)
        informationGatheringTopic.addSubTopic(topicElement)


        if len(self.app.smaliChecks.getCustomChecksLocations()) > 0:
            for check in self.app.smaliChecks.getCustomChecksLocations():
                customCheckSubTopic = TopicElement()
                customCheckSubTopic.setTitle(check)
                self.createSubTopics(customCheckSubTopic,self.app.smaliChecks.getCustomChecksLocations()[check])
                topicElement.getSubTopicByIndex(2).addSubTopic(customCheckSubTopic)
            if len(self.app.smaliChecks.getCustomChecksLocations()[check]) > self.configuration.getXmindTopipFoldAt():
                customCheckSubTopic.setFolded()


        # Improper Platform Usage


        topicElement = TopicElement()
        topicElement.setTitle(""Improper Platform Usage"")
        ipSubTopics = [""Malicious interaction possible with exported components?""]
        self.createSubTopics(topicElement ,ipSubTopics)
        topicElement.getSubTopicByIndex(0).setURLHyperlink \
            (""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05h-Testing-Platform-Interaction.md#testing-for-sensitive-functionality-exposure-through-ipc"")

        if(len(self.app.smaliChecks.getVulnerableContentProvidersSQLiLocations()) > 0):
            contentProviderSQLi = TopicElement()
            contentProviderSQLi.addMarker('flag-yellow')
            contentProviderSQLi.setTitle(""Possibility of SQL Injection in exported ContentProvider"")
            self.createSubTopics(contentProviderSQLi,self.app.smaliChecks.getVulnerableContentProvidersSQLiLocations())
            topicElement.addSubTopic(contentProviderSQLi)

        if (len(self.app.smaliChecks.getVulnerableContentProvidersPathTraversalLocations()) > 0):
            contentProviderPathTraversal = TopicElement()
            contentProviderPathTraversal.addMarker('flag-yellow')
            contentProviderPathTraversal.setTitle(""Possibility of Path Traversal in exported ContentProvider"")
            self.createSubTopics(contentProviderPathTraversal, self.app.smaliChecks.getVulnerableContentProvidersPathTraversalLocations())
            topicElement.addSubTopic(contentProviderPathTraversal)



        debuggableEvidenceTopic = TopicElement()
        debuggableEvidenceTopic.setURLHyperlink(""https://github.com/OWASP/owasp-mstg/blob/master//Document/0x05i-Testing-Code-Quality-and-Build-Settings.md#testing-if-the-app-is-debuggable"")
        if self.app.isDebuggable() == ""Yes"":
            debuggableEvidenceTopic.setTitle(""Application is debuggable"")
            debuggableEvidenceTopic.addMarker('flag-red')
            debuggableEvidenceTopic.setURLHyperlink(
                ""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05i-Testing-Code-Quality-and-Build-Settings.md#testing-if-the-app-is-debuggable"")
        else:
            debuggableEvidenceTopic.setTitle(""Application is not debuggable"")
            debuggableEvidenceTopic.addMarker('flag-green')
        topicElement.addSubTopic(debuggableEvidenceTopic)

        activitiesVulnerableToPreferences = TopicElement()
        activitiesVulnerableToPreferences.setURLHyperlink(""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05h-Testing-Platform-Interaction.md#testing-for-fragment-injection"")
        if len(self.app.getActivitiesExtendPreferencesWithoutValidate()) != 0 and int(self.app.getMinSDKVersion()) < 19:
            activitiesVulnerableToPreferences.setTitle(""Activities vulnerable to Fragment Injection"")
            self.createSubTopics(activitiesVulnerableToPreferences,self.app.getActivitiesExtendPreferencesWithoutValidate())
            activitiesVulnerableToPreferences.addMarker('flag-red')
        if len(self.app.getActivitiesExtendPreferencesWithValidate()) != 0:
            activitiesVulnerableToPreferences.setTitle(""Activities with possible Fragment Injection (isValidFragment in place)"")
            self.createSubTopics(activitiesVulnerableToPreferences, self.app.getActivitiesExtendPreferencesWithValidate())
            activitiesVulnerableToPreferences.addMarker('flag-yellow')
        if len(self.app.getActivitiesExtendPreferencesWithoutValidate()) == 0 and len(self.app.getActivitiesExtendPreferencesWithValidate()) == 0:
            activitiesVulnerableToPreferences.setTitle(""No activities vulnerable to Fragment Injection"")
            activitiesVulnerableToPreferences.addMarker('flag-green')
        topicElement.addSubTopic(activitiesVulnerableToPreferences)
        addJavascriptInterfaceTopic = TopicElement()
        if len(self.app.smaliChecks.getWebviewAddJavascriptInterfaceLocations()) != 0:
            if int(self.app.getMinSDKVersion()) <= 16:
                addJavascriptInterfaceTopic.setTitle(""JavascriptInterface with RCE possibility"")
                addJavascriptInterfaceTopic.addMarker('flag-red')
            else:
                addJavascriptInterfaceTopic.setTitle(""JavascriptInterface available."")
                addJavascriptInterfaceTopic.addMarker('flag-yellow')
            self.createSubTopics(addJavascriptInterfaceTopic,self.app.smaliChecks.getWebviewAddJavascriptInterfaceLocations())
            if len(self.app.smaliChecks.getWebviewAddJavascriptInterfaceLocations()) > self.configuration.getXmindTopipFoldAt():
                addJavascriptInterfaceTopic.setFolded()
        else:
            addJavascriptInterfaceTopic.setTitle(""No presence of JavascriptInterface"")
            addJavascriptInterfaceTopic.addMarker('flag-green')
        addJavascriptInterfaceTopic.setURLHyperlink(
            ""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05h-Testing-Platform-Interaction.md#determining-whether-java-objects-are-exposed-through-webviews"")
        topicElement.addSubTopic(addJavascriptInterfaceTopic)

        javascriptEnabledWebviewTopic = TopicElement()
        javascriptEnabledWebviewTopic.setURLHyperlink(""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05h-Testing-Platform-Interaction.md#determining-whether-java-objects-are-exposed-through-webviews"")
        if len(self.app.smaliChecks.getJavascriptEnabledWebViews()) > 0:
            javascriptEnabledWebviewTopic.setTitle(""WebView with Javascript enabled."")
            self.createSubTopics(javascriptEnabledWebviewTopic,self.app.smaliChecks.getJavascriptEnabledWebViews())
            javascriptEnabledWebviewTopic.addMarker('flag-yellow')
            if len(self.app.smaliChecks.getJavascriptEnabledWebViews()) > self.configuration.getXmindTopipFoldAt():
                javascriptEnabledWebviewTopic.setFolded()
        else:
            javascriptEnabledWebviewTopic.setTitle(""No WebView with Javascript enabled."")
            javascriptEnabledWebviewTopic.addMarker('flag-green')
        topicElement.addSubTopic(javascriptEnabledWebviewTopic)
        fileAccessEnabledWebviewTopic = TopicElement()
        fileAccessEnabledWebviewTopic.setURLHyperlink(""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05h-Testing-Platform-Interaction.md#testing-webview-protocol-handlers"")
        if len(self.app.smaliChecks.getFileAccessEnabledWebViews()) > 0:
            fileAccessEnabledWebviewTopic.setTitle(""WebView with fileAccess enabled."")
            self.createSubTopics(fileAccessEnabledWebviewTopic, self.app.smaliChecks.getFileAccessEnabledWebViews())
            if int(self.app.getMinSDKVersion()) < 16:
                fileAccessEnabledWebviewTopic.setPlainNotes(""This app runs in versions bellow API 16 (Jelly Bean). If webview is opening local HTML files via file URL and loading external resources it might be possible to bypass Same Origin Policy and extract local files since AllowUniversalAccessFromFileURLs is enabled by default and there is not public API to disable it in this versions."")
                fileAccessEnabledWebviewTopic.addMarker('flag-yellow')
            else:
                fileAccessEnabledWebviewTopic.addMarker('flag-yellow')
            if len(self.app.smaliChecks.getFileAccessEnabledWebViews()) > self.configuration.getXmindTopipFoldAt():
                fileAccessEnabledWebviewTopic.setFolded()
        else:
            fileAccessEnabledWebviewTopic.setTitle(""No WebView with fileAccess enabled."")
            fileAccessEnabledWebviewTopic.addMarker('flag-green')
        topicElement.addSubTopic(fileAccessEnabledWebviewTopic)

        universalAccessEnabledWebviewTopic = TopicElement()
        if len(self.app.smaliChecks.getUniversalAccessFromFileURLEnabledWebviewsLocations()) > 0:
            self.createSubTopics(universalAccessEnabledWebviewTopic,self.app.smaliChecks.getUniversalAccessFromFileURLEnabledWebviewsLocations())
            universalAccessEnabledWebviewTopic.setTitle(""WebView with Universal Access from File URLs enabled."")
            universalAccessEnabledWebviewTopic.addMarker('flag-yellow')
        else:
            universalAccessEnabledWebviewTopic.setTitle(""No WebView with Universal Access from File URLs found."")
            universalAccessEnabledWebviewTopic.addMarker('flag-green')
        topicElement.addSubTopic(universalAccessEnabledWebviewTopic)

        methodologyTopic.addSubTopic(topicElement)



        # Insecure Communication Topic

        topicElement = TopicElement()
        topicElement.setTitle(""Insecure Communication"")
        icSubTopics = [""SSL Implementation"" ,""Mixed Mode Communication?""]
        self.createSubTopics(topicElement ,icSubTopics)
        sslSubTopics = [""Accepts self-sign certificates?"" ,""Accepts wrong host name?"" ,""Lack of Certificate Pinning?""]
        self.createSubTopics(topicElement.getSubTopicByIndex(0) ,sslSubTopics)

        trustManagerSubTopic = TopicElement()
        trustManagerSubTopic.setURLHyperlink(""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05g-Testing-Network-Communication.md#verifying-the-server-certificate"")
        if len(self.app.smaliChecks.getVulnerableTrustManagers()) != 0:
            trustManagerSubTopic.setTitle(""Vulnerable Trust Manager:"")
            self.createSubTopics(trustManagerSubTopic,self.app.smaliChecks.getVulnerableTrustManagers())
            topicElement.getSubTopicByIndex(0).addSubTopic(trustManagerSubTopic)
            trustManagerSubTopic.addMarker('flag-red')
        else:
            trustManagerSubTopic.setTitle(""No vulnerable Trust Manager found."")
            trustManagerSubTopic.addMarker('flag-green')
        topicElement.getSubTopicByIndex(0).addSubTopic(trustManagerSubTopic)

        sslErrorBypassSubTopic = TopicElement()
        sslErrorBypassSubTopic.setURLHyperlink(
            ""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05g-Testing-Network-Communication.md#webview-server-certificate-verification"")
        if len(self.app.smaliChecks.getVulnerableWebViewSSLErrorBypass()) != 0:
            sslErrorBypassSubTopic.setTitle(""Webview with vulnerable SSL Implementation:"")
            sslErrorBypassSubTopic.addMarker('flag-red')
            self.createSubTopics(sslErrorBypassSubTopic,self.app.smaliChecks.getVulnerableWebViewSSLErrorBypass())
        else:
            sslErrorBypassSubTopic.setTitle(""No WebView with SSL Errror Bypass found."")
            sslErrorBypassSubTopic.addMarker('flag-green')
        topicElement.getSubTopicByIndex(0).addSubTopic(sslErrorBypassSubTopic)

        vulnerableHostnameVerifiersSubTopic = TopicElement()
        vulnerableHostnameVerifiersSubTopic.setURLHyperlink(
            ""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05g-Testing-Network-Communication.md#hostname-verification"")
        if len(self.app.smaliChecks.getVulnerableHostnameVerifiers()) != 0:
            vulnerableHostnameVerifiersSubTopic.setTitle(""Vulnerable HostnameVerifier found"")
            vulnerableHostnameVerifiersSubTopic.addMarker('flag-red')
            self.createSubTopics(vulnerableHostnameVerifiersSubTopic,self.app.smaliChecks.getVulnerableHostnameVerifiers())
        else:
            vulnerableHostnameVerifiersSubTopic.setTitle(""No vulnerable HostnameVerifiers found."")
            vulnerableHostnameVerifiersSubTopic.addMarker('flag-green')
        topicElement.getSubTopicByIndex(0).addSubTopic(vulnerableHostnameVerifiersSubTopic)

        vulnerableSetHostnameVerifiersSubTopic = TopicElement()
        vulnerableSetHostnameVerifiersSubTopic.setURLHyperlink(
            ""hhttps://github.com/OWASP/owasp-mstg/blob/master/Document/0x05g-Testing-Network-Communication.md#hostname-verification"")
        if len(self.app.smaliChecks.getVulnerableSetHostnameVerifier()) != 0:
            vulnerableSetHostnameVerifiersSubTopic.setTitle(""setHostnameVerifier call with ALLOW_ALL_HOSTNAMES_VERIFIER"")
            vulnerableSetHostnameVerifiersSubTopic.addMarker('flag-red')
            self.createSubTopics(vulnerableSetHostnameVerifiersSubTopic,self.app.smaliChecks.getVulnerableSetHostnameVerifier())
        else:
            vulnerableSetHostnameVerifiersSubTopic.setTitle(""No vulnerable setHostnameVerifiers found."")
            vulnerableSetHostnameVerifiersSubTopic.addMarker('flag-green')
        topicElement.getSubTopicByIndex(0).addSubTopic(vulnerableSetHostnameVerifiersSubTopic)

        vulnerableSocketsSubTopic = TopicElement()
        vulnerableSocketsSubTopic.setURLHyperlink(
            """")
        if len(self.app.smaliChecks.getVulnerableSockets()) != 0:
            vulnerableSocketsSubTopic.setTitle(
                ""Direct usage of Socket without HostnameVerifier"")
            vulnerableSocketsSubTopic.addMarker('flag-red')
            self.createSubTopics(vulnerableSocketsSubTopic,
                                 self.app.smaliChecks.getVulnerableSockets())
        else:
            vulnerableSocketsSubTopic.setTitle(""No direct usage of Socket without HostnameVerifiers."")
            vulnerableSocketsSubTopic.addMarker('flag-green')
        topicElement.getSubTopicByIndex(0).addSubTopic(vulnerableSocketsSubTopic)

        networkSecurityConfig = TopicElement()
        networkSecurityConfig.setURLHyperlink(""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05g-Testing-Network-Communication.md#network-security-configuration"")
        if self.app.targetSDKVersion >= 25:
            if self.app.hasNetworkSecurityConfig == True:
                networkSecurityConfig.setTitle(
                    ""Usage of NetworkSecurityConfig file."")
                domains = self.app.getNetworkSecurityConfigDomains()
                for domain in domains:
                    domainTopic = TopicElement()
                    domainTopic.setTitle(','.join(domain['domains']))

                    clearTextAllowedTopic = TopicElement()
                    clearTextAllowedTopic.setTitle(""Clear Text Allowed"")
                    clearTextAllowedValueTopic = TopicElement()
                    if str(domain['allowClearText']) == ""True"":
                        clearTextAllowedValueTopic.setTitle(""Yes"")
                        clearTextAllowedValueTopic.addMarker('flag-red')
                    else:
                        clearTextAllowedValueTopic.setTitle(""No"")
                        clearTextAllowedValueTopic.addMarker('flag-green')
                    clearTextAllowedTopic.addSubTopic(clearTextAllowedValueTopic)

                    allowUserCATopic = TopicElement()
                    allowUserCATopic.setTitle(""User CA Trusted"")
                    allowUserCAValueTopic = TopicElement()
                    if str(domain['allowUserCA']) == ""True"":
                        allowUserCAValueTopic.setTitle(""Yes"")
                        allowUserCAValueTopic.addMarker('flag-red')
                    else:
                        allowUserCAValueTopic.setTitle(""No"")
                        allowUserCAValueTopic.addMarker('flag-green')
                    allowUserCATopic.addSubTopic(allowUserCAValueTopic)

                    pinningTopic = TopicElement()
                    pinningTopic.setTitle(""Pinning Configured"")
                    pinningValueTopic = TopicElement()
                    if str(domain['pinning']) == ""True"":
                        pinningValueTopic.setTitle(""Yes"")
                        pinningValueTopic.addMarker('flag-green')
                        pinningExpirationTopic = TopicElement()
                        pinningExpirationValueTopic = TopicElement()
                        pinningExpirationTopic.setTitle(""Pinning Expiration"")
                        if domain['pinningExpiration'] != '':
                            date_format = ""%Y-%m-%d""
                            a = datetime.strptime(domain['pinningExpiration'], date_format)
                            b = datetime.strptime(time.strftime(""%Y-%m-%d""), date_format)
                            days =  (a-b).days
                            pinningExpirationValueTopic.setTitle(domain['pinningExpiration'])
                            if days <=0:
                                pinningExpirationValueTopic.addMarker('flag-red')
                                pinningExpirationValueTopic.setPlainNotes('Certificate Pinning is disabled. The expiration date on the pin-set has been reached.')
                            elif days < 60:
                                pinningExpirationValueTopic.addMarker('flag-yellow')
                                pinningExpirationValueTopic.setPlainNotes(str+(days)+' days for Certificate Pinning to be disabled.')
                        else:
                            pinningExpirationValueTopic.setTitle(""No expiration"")
                        pinningExpirationTopic.addSubTopic(pinningExpirationValueTopic)
                        pinningTopic.addSubTopic(pinningExpirationTopic)
                    else:
                        pinningValueTopic.setTitle(""No"")
                        pinningValueTopic.addMarker('flag-yellow')
                    pinningTopic.addSubTopic(pinningValueTopic)

                    domainTopic.addSubTopic(clearTextAllowedTopic)
                    domainTopic.addSubTopic(allowUserCATopic)
                    domainTopic.addSubTopic(pinningTopic)
                    networkSecurityConfig.addSubTopic(domainTopic)

            else:
                networkSecurityConfig.setTitle(""No usage of NetworkSecurityConfig file."")
                networkSecurityConfig.addMarker('flag-yellow')
        else:
            networkSecurityConfig.setTitle(
                ""NetworkSecurityConfig check ignored."")
            networkSecurityConfig.addMarker('flag-green')
            networkSecurityConfig.setPlainNotes(""App is not targeting Android versions >= Nougat 7.0"")
        topicElement.getSubTopicByIndex(0).addSubTopic(networkSecurityConfig)

        certificatePinningTopic = TopicElement()
        certificatePinningTopic.setURLHyperlink(""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05g-Testing-Network-Communication.md#testing-custom-certificate-stores-and-certificate-pinning"")
        if len(self.app.smaliChecks.getOkHTTPCertificatePinningLocations())>0 or len(self.app.smaliChecks.getCustomCertificatePinningLocations())>0:
            certificatePinningTopic.setTitle(""Possible Certificate Pinning Usage"")
            certificatePinningTopic.addMarker('flag-green')
            okHttpCertificatePinningTopic = TopicElement()
            if len(self.app.smaliChecks.getOkHTTPCertificatePinningLocations())>0:
                okHttpCertificatePinningTopic.setTitle(""OkHTTP Certificate Pinning."")
                self.createSubTopics(okHttpCertificatePinningTopic,self.app.smaliChecks.getOkHTTPCertificatePinningLocations())
                certificatePinningTopic.addSubTopic(okHttpCertificatePinningTopic)
            customCertificatePinningTopic = TopicElement()
            if len(self.app.smaliChecks.getCustomCertificatePinningLocations()) > 0:
                customCertificatePinningTopic.setTitle(""Custom Certificate Pinning"")
                self.createSubTopics(customCertificatePinningTopic,self.app.smaliChecks.getCustomCertificatePinningLocations())
                certificatePinningTopic.addSubTopic(customCertificatePinningTopic)
        else:
            certificatePinningTopic.setTitle(""No usage of Certificate Pinning"")
            certificatePinningTopic.addMarker('flag-yellow')
        topicElement.getSubTopicByIndex(0).addSubTopic(certificatePinningTopic)






        sslImplementationTopic = topicElement.getSubTopicByIndex(0)
        sslImplementationTopic.getSubTopicByIndex(0).setURLHyperlink \
            (""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05g-Testing-Network-Communication.md#verifying-the-server-certificate"")
        sslImplementationTopic.getSubTopicByIndex(1).setURLHyperlink \
            (""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05g-Testing-Network-Communication.md#hostname-verification#hostname-verification"")
        sslImplementationTopic.getSubTopicByIndex(2).setURLHyperlink \
            (""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05g-Testing-Network-Communication.md#testing-custom-certificate-stores-and-certificate-pinning"")
        methodologyTopic.addSubTopic(topicElement)


        # Insecure Data Storage Topic

        topicElement = TopicElement()
        topicElement.setTitle(""Insecure Data Storage"")
        idsSubTopics = [""Sensitive information stored in cleartext in sdcard/sandbox?""
                        ,""Sensitive information saved to system logs?""
                        ,""Background screenshot with sensitive information?""]
        self.createSubTopics(topicElement ,idsSubTopics)


        activitiesWithoutSecureFlagSubTopic = TopicElement()
        activitiesWithoutSecureFlagSubTopic.setURLHyperlink(""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05d-Testing-Data-Storage.md#finding-sensitive-information-in-auto-generated-screenshots"")
        if len(self.app.getActivitiesWithoutSecureFlag()) != 0:
            activitiesWithoutSecureFlagSubTopic.setTitle(""Activities without FLAG_SECURE or android:excludeFromRecents :"")
            activitiesWithoutSecureFlagSubTopic.addMarker('flag-yellow')
            self.createSubTopics(activitiesWithoutSecureFlagSubTopic, self.app.getActivitiesWithoutSecureFlag())
            activitiesWithoutSecureFlagSubTopic.setFolded()
            if len(self.app.getActivitiesWithoutSecureFlag()) > self.configuration.getXmindTopipFoldAt():
                activitiesWithoutSecureFlagSubTopic.setFolded()
        else:
            activitiesWithoutSecureFlagSubTopic.setTitle(""All activities have FLAG_SECURE or android:excludeFromRecents."")
            activitiesWithoutSecureFlagSubTopic.addMarker('flag-green')
        topicElement.addSubTopic(activitiesWithoutSecureFlagSubTopic)



        topicElement.getSubTopicByIndex(0).setURLHyperlink \
            (""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05d-Testing-Data-Storage.md#testing-local-storage-for-sensitive-data"")
        topicElement.getSubTopicByIndex(1).setURLHyperlink \
            (""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05d-Testing-Data-Storage.md#testing-logs-for-sensitive-data"")
        topicElement.getSubTopicByIndex(2).setURLHyperlink \
            (""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05d-Testing-Data-Storage.md#finding-sensitive-information-in-auto-generated-screenshots"")
        methodologyTopic.addSubTopic(topicElement)


        # Insufficient Cryptography Topic

        topicElement = TopicElement()
        topicElement.setTitle(""Insufficient Cryptography"")
        icrSubTopics = [""Using weak algorithms/modes?"" ,""Using hardcoded properties?""]
        self.createSubTopics(topicElement ,icrSubTopics)
        topicElement.getSubTopicByIndex(0).setURLHyperlink \
            (""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x04g-Testing-Cryptography.md#identifying-insecure-andor-deprecated-cryptographic-algorithms"")
        topicElement.getSubTopicByIndex(1).setURLHyperlink \
            (""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05e-Testing-Cryptography.md#verifying-the-configuration-of-cryptographic-standard-algorithms"")
        AESTopic = TopicElement()
        AESTopic.setURLHyperlink(""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x04g-Testing-Cryptography.md#identifying-insecure-andor-deprecated-cryptographic-algorithms"")
        if len(self.app.smaliChecks.getAESwithECBLocations()) > 0:
            AESTopic.setTitle(""Usage of AES with ECB Mode"")
            self.createSubTopics(AESTopic,self.app.smaliChecks.getAESwithECBLocations())
            AESTopic.addMarker('flag-red')
        else:
            AESTopic.setTitle(""No usage of AES with ECB Mode"")
            AESTopic.addMarker('flag-green')
        topicElement.addSubTopic(AESTopic)
        DESTopic = TopicElement()
        DESTopic.setURLHyperlink(""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x04g-Testing-Cryptography.md#identifying-insecure-andor-deprecated-cryptographic-algorithms"")
        if len(self.app.smaliChecks.getDESLocations()) > 0:
            DESTopic.setTitle(""Usage of DES or 3DES"")
            self.createSubTopics(DESTopic,self.app.smaliChecks.getDESLocations())
            DESTopic.addMarker('flag-red')
        else:
            DESTopic.setTitle(""No usage of DES or 3DES"")
            DESTopic.addMarker('flag-green')
        topicElement.addSubTopic(DESTopic)

        keystoreTopic = TopicElement()
        if len(self.app.smaliChecks.getKeystoreLocations()) > 0:
            keystoreTopic.setTitle(""Usage of Android KeyStore"")
            keystoreTopic.addMarker('flag-green')
            self.createSubTopics(keystoreTopic,self.app.smaliChecks.getKeystoreLocations())
        else:
            keystoreTopic.setTitle(""No usage of Android KeyStore"")
            keystoreTopic.addMarker('flag-yellow')
        topicElement.addSubTopic(keystoreTopic)



        methodologyTopic.addSubTopic(topicElement)


        # Code Tampering Topic

        topicElement = TopicElement()
        topicElement.setTitle(""Code Tampering"")
        ctSubTopics = [""Lack of root detection?"" ,""Lack of hooking detection?""]
        self.createSubTopics(topicElement ,ctSubTopics)
        topicElement.getSubTopicByIndex(0).setURLHyperlink \
            (""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05j-Testing-Resiliency-Against-Reverse-Engineering.md#testing-root-detection"")
        topicElement.getSubTopicByIndex(1).setURLHyperlink \
            (""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05j-Testing-Resiliency-Against-Reverse-Engineering.md#testing-detection-of-reverse-engineering-tools"")
        methodologyTopic.addSubTopic(topicElement)

        # Reverse Engineering Topic

        topicElement = TopicElement()
        topicElement.setTitle(""Reverse Engineering"")
        reSubTopics = [""Lack of code obfuscation?""]
        self.createSubTopics(topicElement ,reSubTopics)
        topicElement.getSubTopicByIndex(0).setURLHyperlink \
            (""https://github.com/OWASP/owasp-mstg/blob/master/Document/0x05j-Testing-Resiliency-Against-Reverse-Engineering.md#testing-obfuscation"")
        methodologyTopic.addSubTopic(topicElement)

        self.getRootTopic().addSubTopic(informationGatheringTopic)
        self.getRootTopic().addSubTopic(methodologyTopic)

    def createSubTopics(self ,topic ,subTopics):
        for subtopic in subTopics:
            newTopic = TopicElement()
            newTopic.setTitle(subtopic)
            topic.addSubTopic(newTopic)

    def save(self):
        cwd = os.path.dirname(os.path.realpath(__file__))
        filename = self.app.getPackageName( ) +"".xmind""
        xmind.save(self.workbook ,cwd+""/output_xmind/""+filename)
        print ""Generated output_xmind/"" +filename
/n/n/nSmaliChecks.py/n/nimport re
from Configuration import *
from subprocess import *
from sys import platform


class NotFound(Exception):
    """"""Object not found in source code""""""

class SmaliChecks:

    smaliPaths = []
    vulnerableTrustManagers=[]
    vulnerableWebViewSSLErrorBypass=[]
    vulnerableSetHostnameVerifiers = []
    vulnerableHostnameVerifiers = []
    vulnerableSocketsLocations = []
    vulnerableContentProvidersSQLiLocations = []
    vulnerableContentProvidersPathTraversalLocations = []
    dynamicRegisteredBroadcastReceiversLocations = []
    encryptionFunctionsLocation = []
    decryptionFunctionsLocation = []
    undeterminedCryptographicFunctionsLocation = []
    keystoreLocations = []
    webViewLoadUrlUsageLocation = []
    webViewAddJavascriptInterfaceUsageLocation = []
    okHttpCertificatePinningLocation = []
    customCertifificatePinningLocation = []
    AESwithECBLocations = []
    DESLocations =[]
    javascriptEnabledWebviews = []
    fileAccessEnabledWebviews = []
    universalAccessFromFileURLEnabledWebviewsLocations = []
    customChecksLocations = {}
    configuration = Configuration()

    def __init__(self, paths):
        for path in paths:
            self.smaliPaths.append(path)
        self.checkWebviewSSLErrorBypass()
        self.findWebviewJavascriptInterfaceUsage()
        self.findWeakCryptographicUsage()
        self.checkVulnerableTrustManagers()
        self.checkInsecureHostnameVerifier()
        self.checkVulnerableSockets()
        self.findEncryptionFunctions()
        self.checkVulnerableHostnameVerifiers()
        self.findWebViewLoadUrlUsage()
        self.findCustomChecks()
        self.findPropertyEnabledWebViews()
        self.checkOKHttpCertificatePinning()
        self.checkCustomPinningImplementation()
        self.findKeystoreUsage()
        self.findDynamicRegisteredBroadcastReceivers()
        self.findPathTraversalContentProvider()

    def getSmaliPaths(self):
        return self.smaliPaths

    def getOSGnuGrepCommand(self):
        if platform == ""darwin"":
            return ""ggrep""
        else:
            return ""grep""


    def checkForExistenceInFolder(self,objectRegEx,folderPath):
        command = [self.getOSGnuGrepCommand(),""-s"" ,""-r"", ""-l"", ""-P"",objectRegEx,"" --exclude-dir=""+self.configuration.getFolderExclusions()]
        for path in folderPath:
            command.append(path)
        grep = Popen(command, stdout=PIPE)
        filePaths = grep.communicate()[0].strip().split('\n')
        if len(filePaths) > 0:
            return filePaths
        else:
            raise NotFound

    def existsInFile(self,objectRegEx,filePath):
        grep = Popen([self.getOSGnuGrepCommand(),""-l"", ""-P"",objectRegEx,filePath], stdout=PIPE)
        filePaths = grep.communicate()[0].strip().split('\n')
        if len(filePaths) > 0:
            return filePaths
        else:
            return False

    def getMethodCompleteInstructions(self,methodRegEx,filePath):
        sed = Popen([""sed"", ""-n"", methodRegEx, filePath], stdout=PIPE)
        methodContent = sed.communicate()[0]
        return methodContent.strip().replace('    ','').split('\n')

    def getFileContent(self,filePath):
        sed = Popen([""sed"", ""1p"",filePath], stdout=PIPE)
        fileContent = sed.communicate()[0]
        return fileContent.strip().replace('    ', '').split('\n')

    def getMethodInstructions(self,methodRegEx,filePath):
        sed = Popen([""sed"", ""-n"", methodRegEx, filePath], stdout=PIPE)
        methodContent = sed.communicate()[0]
        try:
            match = re.search(r"".locals \d{1,}([\S\s]*?).end method"", methodContent)
            instructions = str(match.group(1)).strip().replace('    ','').split('\n')
            return instructions
        except:
            return """"

    def isMethodEmpty(self,instructions):
        for i in range(len(instructions)-1,0,-1):
            if instructions[i] == '.end method':
                continue
            else:
                if instructions[i] == ""return-void"":
                    return True
                else:
                    return False

    def hasOperationProceed(self,instructions):
        for i in range(len(instructions) - 1, 0, -1):
            if 'Landroid/webkit/SslErrorHandler;->proceed()V' in instructions[i]:
                return True
            else:
                continue
        return False

    def doesMethodReturnNull(self,instructions):
        for i in range(len(instructions) - 1, 0, -1):
            if instructions[i] == ""return-object v0"":
                if i-2 >= 0  and instructions[i-2] == ""const/4 v0, 0x0"":
                    return True
                elif i-2 >=0 and instructions[i-2] == ""new-array v0, v0, [Ljava/security/cert/X509Certificate;"":
                    if i-4 >= 0 and instructions[i - 4] == ""const/4 v0, 0x0"":
                        return True
                    else:
                        return False
                else:
                    return False
            else:
                continue
        return False

    def doesMethodReturnTrue(self,instructions):
        maxLen = len(instructions)-1
        for i in range(maxLen, 0, -1):
            if instructions[i] == ""return v0"":
                if i-2 >= 0 and instructions[i-2] == ""const/4 v0, 0x1"":
                    return True
                else:
                    return False
            else:
                continue
        return False


    #Returns the register that has the target value assigned

    def searchRegisterByAssignedValue(self,instructions,value):
        register = """"
        for instruction in instructions:
            if ""const/"" in instruction and value in instruction:
                registerEnd = instruction.find("","")
                registerBegin = instruction.find("" "",0,registerEnd)+1
                register = instruction[registerBegin:registerEnd]
                break
        return register


    #Returns the assigned value to the targer register.

    def getAssignedValueByRegister(self,instructions,register):
        register = """"
        for instruction in instructions:
            if ""const/"" in instruction and register in instruction:
                registerEnd = instruction.find("","")
                registerBegin = instruction.find("" "",0,registerEnd)+1
                register = instruction[registerBegin:registerEnd]
                break
        return register


    def doesActivityExtendsPreferenceActivity(self,activity):
        activity = activity.replace(""."",""/"")
        activityLocation = self.checkForExistenceInFolder("".class public([a-zA-Z\s]*)L""+activity+"";"",self.getSmaliPaths())
        if activityLocation[0] != """":
            preferenceExtends = self.existsInFile("".super Landroid\/preference\/PreferenceActivity;"",activityLocation[0])
            if preferenceExtends[0] != '':
                return True
            else:
                return False

    def doesPreferenceActivityHasValidFragmentCheck(self,activity):
        activity = activity.replace(""."",""/"")
        activityLocation = self.checkForExistenceInFolder("".class public([a-zA-Z\s]*)L""+activity+"";"",self.getSmaliPaths())
        if activityLocation[0] != """":
            isValidFragmentFunction = self.getMethodCompleteInstructions('/.method protected isValidFragment(Ljava\/lang\/String;)Z/,/^.end method/p',activityLocation[0])
            if isValidFragmentFunction[0] != '':
                return True
            else:
                return False

    def doesActivityHasFlagSecure(self,activity):
        activity = activity.replace(""."",""/"")
	end = activity.rfind('/')+1
	customPath = []
        x = len(self.getSmaliPaths())
	for a in range(0,x):
		customPath.append(self.getSmaliPaths()[a]+activity[:end])
        activityLocation = self.checkForExistenceInFolder("".class public([a-zA-Z\s]*)L""+activity+"";"",customPath)
        if activityLocation[0] != """":
            methodInstructions = self.getMethodCompleteInstructions('/.method \([a-zA-Z]* \)onCreate(Landroid\/os\/Bundle;)V/,/^.end method/p',activityLocation[0])
            register = self.searchRegisterByAssignedValue(methodInstructions,""0x2000"")
            if register.strip() == """":
		        return False
            else:
                flag = self.existsInFile(""invoke-virtual.*""+register+"".*Landroid\/view\/Window;->setFlags\(II\)V"",activityLocation[0])
                if flag[0] != '':
                    return True
                else:
                    return False

    def findRegisterAssignedValueFromIndexBackwards(self,instructionsList,register,index):
        for pointer in range(index,0,-1):
            if register in instructionsList[pointer] and (""const"" in instructionsList[pointer] or ""sget-object"" in instructionsList[pointer]):
                valueBegin = instructionsList[pointer].find("","")
                value = instructionsList[pointer][valueBegin+2:]
                return value

    def findRegistersPassedToFunction(self,functionInstruction):
        match = re.search(r""{(.*)}"", functionInstruction)
        try:
            if ""range"" in functionInstruction:
                registers = str(match.group(1)).strip().replace(' ', '').split("".."")
            else:
                registers = str(match.group(1)).strip().replace(' ','').split("","")
        except:
            match = re.search(r""\D\d"", functionInstruction)
            try:
                registers = str(match.group(0))
            except:
                return """"
        return registers

    def findInstructionIndex(self,instructionsList,instructionToSearch):
        indexList = []
        for index,instruction in enumerate(instructionsList):
            m = re.search(instructionToSearch,instruction)
            try:
                output = m.group(0)
                indexList.append(index)
            except:
                continue
        return indexList



    def findDynamicRegisteredBroadcastReceivers(self):
        dynamicRegisteredBroadcastReceiversLocations = self.checkForExistenceInFolder(
            "";->registerReceiver\(Landroid\/content\/BroadcastReceiver;Landroid\/content\/IntentFilter;\)"",
            self.getSmaliPaths())
        for location in dynamicRegisteredBroadcastReceiversLocations:
            self.dynamicRegisteredBroadcastReceiversLocations.append(location)


    def findEncryptionFunctions(self):
        encryptionFunctionsLocations = self.checkForExistenceInFolder(""invoke-virtual {(.*)}, Ljavax\/crypto\/Cipher;->init\(ILjava\/security\/Key"",self.getSmaliPaths())
        if encryptionFunctionsLocations[0] != """":
            for location in encryptionFunctionsLocations:
                if ""org/bouncycastle"" in location:
                    continue
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,""Ljavax/crypto/Cipher;->init\(ILjava/security/Key"")
                if len(indexList) != 0:
                    for index in indexList:
                        registers = self.findRegistersPassedToFunction(instructions[index])
                        if self.findRegisterAssignedValueFromIndexBackwards(instructions,registers[1],index) == ""0x1"":
                            self.encryptionFunctionsLocation.append(location)
                        elif self.findRegisterAssignedValueFromIndexBackwards(instructions,registers[1],index) == ""0x2"":
                            self.decryptionFunctionsLocation.append(location)
                        else:
                            if location not in self.undeterminedCryptographicFunctionsLocation:
                                self.undeterminedCryptographicFunctionsLocation.append(location)

    def findKeystoreUsage(self):
        keystoreUsageLocations = self.checkForExistenceInFolder(""invoke-virtual {(.*)}, Ljava\/security\/KeyStore;->getEntry\(Ljava\/lang\/String;Ljava\/security\/KeyStore\$ProtectionParameter;\)Ljava\/security\/KeyStore\$Entry"",self.getSmaliPaths())
        if keystoreUsageLocations[0] != """":
            for location in keystoreUsageLocations:
                self.keystoreLocations.append(location)

    def findWebViewLoadUrlUsage(self):
        webViewUsageLocations = self.checkForExistenceInFolder(""Landroid\/webkit\/WebView;->loadUrl\(Ljava\/lang\/String;\)V"",self.getSmaliPaths())
        if webViewUsageLocations[0] != """":
            for location in webViewUsageLocations:
                self.webViewLoadUrlUsageLocation.append(location)


    # *** Improper Platform Usage ***

    def findPathTraversalContentProvider(self):
        contentProvidersLocations = self.checkForExistenceInFolder("".super Landroid\/content\/ContentProvider;"",self.getSmaliPaths())
        if contentProvidersLocations[0] != '':
            for location in contentProvidersLocations:
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,"""")
                if len(indexList) > 0:
                    indexList = self.findInstructionIndex(instructions,"""")

    def determineContentProviderPathTraversal(self,provider):
        location = self.checkForExistenceInFolder("".class .* L""+provider.replace(""."",""/""),self.getSmaliPaths())
        instructions = self.getMethodCompleteInstructions('/.method public openFile(Landroid\/net\/Uri;Ljava\/lang\/String;)Landroid\/os\/ParcelFileDescriptor;/,/^.end method/p', location[0])
        indexList = self.findInstructionIndex(instructions,""Ljava\/io\/File;->getCanonicalPath\(\)"")
        if len(indexList) > 0:
                self.vulnerableContentProvidersPathTraversalLocations.append(location[0])


    def determineContentProviderSQLi(self,provider):
        location = self.checkForExistenceInFolder("".class .* L""+provider.replace(""."",""/""),self.getSmaliPaths())
        instructions = self.getMethodCompleteInstructions('/.method public query(Landroid\/net\/Uri;\[Ljava\/lang\/String;Ljava\/lang\/String;\[Ljava\/lang\/String;Ljava\/lang\/String;)Landroid\/database\/Cursor;/,/^.end method/p', location[0])
        indexList = self.findInstructionIndex(instructions,""invoke-virtual(.*) {(.*)}, Landroid\/database\/sqlite\/SQLiteDatabase;->query"")
        if len(indexList) > 0:
            indexList = self.findInstructionIndex(instructions,""\?"")
            if len(indexList) == 0:
                self.vulnerableContentProvidersSQLiLocations.append(location[0])



    def findWeakCryptographicUsage(self):
        getInstanceLocations = self.checkForExistenceInFolder(""Ljavax\/crypto\/Cipher;->getInstance\(Ljava\/lang\/String;\)Ljavax\/crypto\/Cipher;"",self.getSmaliPaths())
        if getInstanceLocations[0] != '':
            for location in getInstanceLocations:
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,""Ljavax/crypto/Cipher;->getInstance\(Ljava/lang/String;\)Ljavax/crypto/Cipher;"")
                for index in indexList:
		    register = self.findRegistersPassedToFunction(instructions[index])
                    transformationValue = self.findRegisterAssignedValueFromIndexBackwards(instructions, register[0], index)
                    if transformationValue is not None:
                        if transformationValue == ""\""AES\"""" or ""AES/ECB/"" in transformationValue:
                            self.AESwithECBLocations.append(location)
                        elif ""DES"" in transformationValue:
                            self.DESLocations.append(location)


    def findPropertyEnabledWebViews(self):
        webviewUsageLocations = self.checkForExistenceInFolder("";->getSettings\(\)Landroid\/webkit\/WebSettings;"",self.getSmaliPaths())
        if webviewUsageLocations[0] != '':
            for location in webviewUsageLocations:
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,""Landroid/webkit/WebSettings;->setJavaScriptEnabled\(Z\)V"")
                if len(indexList) > 0:
                    for index in indexList:
                        register = self.findRegistersPassedToFunction(instructions[index])
                        value = self.findRegisterAssignedValueFromIndexBackwards(instructions,register[1],index)
                        if value == ""0x1"":
                            self.javascriptEnabledWebviews.append(location)
                indexList = self.findInstructionIndex(instructions,""Landroid/webkit/WebSettings;->setAllowFileAccess\(Z\)V"")
                if len(indexList) > 0:
                    for index in indexList:
                        register = self.findRegistersPassedToFunction(instructions[index])
                        value = self.findRegisterAssignedValueFromIndexBackwards(instructions, register[1], index)
                        if value == ""0x1"":
                            self.fileAccessEnabledWebviews.append(location)
                else:
                    self.fileAccessEnabledWebviews.append(location)
                indexList = self.findInstructionIndex(instructions,""Landroid/webkit/WebSettings;->setAllowUniversalAccessFromFileURLs\(Z\)V"")
                if len(indexList) > 0:
                    for index in indexList:
                        register = self.findRegistersPassedToFunction(instructions[index])
                        value = self.findRegisterAssignedValueFromIndexBackwards(instructions, register[1], index)
                        if value == ""0x1"":
                            self.universalAccessFromFileURLEnabledWebviewsLocations.append(location)



    def findWebviewJavascriptInterfaceUsage(self):
        javascriptInterfaceLocations = self.checkForExistenceInFolder("";->addJavascriptInterface\(Ljava\/lang\/Object;Ljava\/lang\/String;\)V"",self.getSmaliPaths())
        if javascriptInterfaceLocations[0] != '':
            for location in javascriptInterfaceLocations:
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,"";->addJavascriptInterface\(Ljava/lang/Object;Ljava/lang/String;\)V"")
                if len(indexList) != 0:
                    for index in indexList:
                        registers = self.findRegistersPassedToFunction(instructions[index])
                    self.webViewAddJavascriptInterfaceUsageLocation.append(location)


    # *** Insecure Communication Checks ***

    #Check for the implementation of custom HostnameVerifiers

    def checkInsecureHostnameVerifier(self):
        insecureHostNameVerifierLocations = self.checkForExistenceInFolder("".implements Ljavax\/net\/ssl\/HostnameVerifier;"",self.getSmaliPaths())
        if insecureHostNameVerifierLocations[0] != '':
            for location in insecureHostNameVerifierLocations:
                methodInstructions = self.getMethodCompleteInstructions('/.method .* verify(Ljava\/lang\/String;Ljavax\/net\/ssl\/SSLSession;)Z/,/^.end method/p',location)
                if methodInstructions != """":
                    if self.doesMethodReturnTrue(methodInstructions) == True:
                        self.vulnerableHostnameVerifiers.append(location)

    #Check for the presence of the custom function that allows to bypass SSL errors in WebViews

    def checkWebviewSSLErrorBypass(self):
        webviewErrorBypassLocations = self.checkForExistenceInFolder(""Landroid\/webkit\/SslErrorHandler;->proceed\(\)V"",self.getSmaliPaths())
        if webviewErrorBypassLocations[0] != '':
            for location in webviewErrorBypassLocations:
                self.vulnerableWebViewSSLErrorBypass.append(location)

    #Check for the presence of custom TrustManagers that are vulnerable.

    def checkVulnerableTrustManagers(self):
        vulnerableTrustManagers = []
        try:
            checkClientTrustedLocations = self.checkForExistenceInFolder("".method public checkClientTrusted\(\[Ljava\/security\/cert\/X509Certificate;Ljava\/lang\/String;\)V"",self.getSmaliPaths())
            if checkClientTrustedLocations[0] != '':
                for location in checkClientTrustedLocations:
                    methodInstructions = self.getMethodCompleteInstructions('/method public checkClientTrusted\(\)/,/^.end method/p',location)
                    if methodInstructions != """":
                        if self.isMethodEmpty(methodInstructions) == True:
                            getAcceptedIssuersLocations = self.existsInFile("".method public getAcceptedIssuers\(\)\[Ljava\/security\/cert\/X509Certificate;"",location)
                            if methodInstructions != """":
                                methodInstructions = self.getMethodCompleteInstructions('/method public getAcceptedIssuers()\[Ljava\/security\/cert\/X509Certificate;/,/^.end method/p',getAcceptedIssuersLocations[0])
                                if self.doesMethodReturnNull(methodInstructions) == True:
                                    checkServerTrustedLocations = self.existsInFile("".method public checkServerTrusted\(\[Ljava\/security\/cert\/X509Certificate;Ljava\/lang\/String;\)V"",location)
                                    if methodInstructions != """":
                                        methodInstructions = self.getMethodCompleteInstructions('/method public checkServerTrusted\(\)/,/^.end method/p', checkServerTrustedLocations[0])
                                        if self.isMethodEmpty(methodInstructions) == True:
                                            vulnerableTrustManagers.append(location)
                                            self.vulnerableTrustManagers.append(location)
                return vulnerableTrustManagers
        except NotFound:
            pass

    #Check for the presence of setHostnameVerifier with ALLOW_ALL_HOSTNAME_VERIFIER

    def checkVulnerableHostnameVerifiers(self):
        setHostnameVerifierLocations = self.checkForExistenceInFolder(""invoke-virtual {(.*)}, Lorg\/apache\/http\/conn\/ssl\/SSLSocketFactory;->setHostnameVerifier\(Lorg\/apache\/http\/conn\/ssl\/X509HostnameVerifier;\)V"",self.getSmaliPaths())
        if setHostnameVerifierLocations[0] != """":
            for location in setHostnameVerifierLocations:
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,""Lorg/apache/http/conn/ssl/SSLSocketFactory;->setHostnameVerifier"")
                if len(indexList) != 0:
                    for index in indexList:
                        registers = self.findRegistersPassedToFunction(instructions[index])
                        if self.findRegisterAssignedValueFromIndexBackwards(instructions, registers[1], index) == ""Lorg/apache/http/conn/ssl/SSLSocketFactory;->ALLOW_ALL_HOSTNAME_VERIFIER:Lorg/apache/http/conn/ssl/X509HostnameVerifier;"":
                            self.vulnerableSetHostnameVerifiers.append(location)

    #Check for SocketFactory without Hostname Verify

    def checkVulnerableSockets(self):
        vulnerableSocketsLocations = self.checkForExistenceInFolder(""Ljavax\/net\/SocketFactory;->createSocket\(Ljava\/lang\/String;I\)Ljava\/net\/Socket;"",self.getSmaliPaths())
        if vulnerableSocketsLocations[0] != """":
            for location in vulnerableSocketsLocations:
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,""Ljavax/net/ssl/HostnameVerifier;->verify\(Ljava/lang/String;Ljavax/net/ssl/SSLSession;\)Z"")
                if len(indexList) == 0:
                    self.vulnerableSocketsLocations.append(location)

    #Check for the implementation of OKHttp Certificate Pinning

    def checkOKHttpCertificatePinning(self):
        okHttpCertificatePinningLocations = self.checkForExistenceInFolder(""add\(Ljava\/lang\/String;\[Ljava\/lang\/String;\)Lokhttp3\/CertificatePinner\$Builder"",self.getSmaliPaths())
        if okHttpCertificatePinningLocations[0] != '':
            for location in okHttpCertificatePinningLocations:
                #Bypass library files
                if ""/okhttp"" in location:
                    continue
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,""certificatePinner\(Lokhttp3/CertificatePinner;\)Lokhttp3/OkHttpClient$Builder;"")
                if len(indexList) == 0:
                    self.okHttpCertificatePinningLocation.append(location)

    #Check for custom Certificate Pinning Implementation

    def checkCustomPinningImplementation(self):
        customCertificatePinningLocations = self.checkForExistenceInFolder(""invoke-virtual {(.*)}, Ljavax\/net\/ssl\/TrustManagerFactory;->init\(Ljava\/security\/KeyStore;\)V"",self.getSmaliPaths())
        if customCertificatePinningLocations[0] != '':
            for location in customCertificatePinningLocations:
                if ""/okhttp"" in location or ""io/fabric"" in location:
                    continue
                self.customCertifificatePinningLocation.append(location)


    # *** CUSTOM CHECKS ***


    def findCustomChecks(self):
        for check in self.configuration.getCustomChecks():
                self.customChecksLocations[check[0]] = []
                customCheckLocationsFound = self.checkForExistenceInFolder(check[1],self.getSmaliPaths())
                if customCheckLocationsFound[0] != '':
                    for location in customCheckLocationsFound:
                        self.customChecksLocations[check[0]].append(location)
    # *** GETTERS ***

    def getVulnerableTrustManagers(self):
        return self.vulnerableTrustManagers

    def getVulnerableWebViewSSLErrorBypass(self):
        return self.vulnerableWebViewSSLErrorBypass

    def getVulnerableHostnameVerifiers(self):
        return self.vulnerableHostnameVerifiers

    def getEncryptionFunctionsLocations(self):
        return self.encryptionFunctionsLocation

    def getDecryptionFunctionsLocations(self):
        return self.decryptionFunctionsLocation

    def getUndeterminedCryptographicFunctionsLocations(self):
        return self.undeterminedCryptographicFunctionsLocation

    def getVulnerableSetHostnameVerifier(self):
        return self.vulnerableSetHostnameVerifiers

    def getVulnerableSockets(self):
        return self.vulnerableSocketsLocations

    def getWebViewsLoadUrlUsageLocations(self):
        return self.webViewLoadUrlUsageLocation

    def getCustomChecksLocations(self):
        return self.customChecksLocations

    def getWebviewAddJavascriptInterfaceLocations(self):
        return self.webViewAddJavascriptInterfaceUsageLocation

    def getAESwithECBLocations(self):
        return self.AESwithECBLocations

    def getDESLocations(self):
        return self.DESLocations

    def getJavascriptEnabledWebViews(self):
        return self.javascriptEnabledWebviews

    def getFileAccessEnabledWebViews(self):
        return self.fileAccessEnabledWebviews

    def getUniversalAccessFromFileURLEnabledWebviewsLocations(self):
        return self.universalAccessFromFileURLEnabledWebviewsLocations

    def getOkHTTPCertificatePinningLocations(self):
        return self.okHttpCertificatePinningLocation

    def getCustomCertificatePinningLocations(self):
        return self.customCertifificatePinningLocation

    def getKeystoreLocations(self):
        return self.keystoreLocations

    def getDynamicRegisteredBroadcastReceiversLocations(self):
        return self.dynamicRegisteredBroadcastReceiversLocations

    def getVulnerableContentProvidersSQLiLocations(self):
        return self.vulnerableContentProvidersSQLiLocations

    def getVulnerableContentProvidersPathTraversalLocations(self):
        return self.vulnerableContentProvidersPathTraversalLocations/n/n/n",0
215,215,02256eedb8fecc60376f35d2f772e9bc275c5574,"/SmaliChecks.py/n/nimport re
from Configuration import *
from subprocess import *
from sys import platform


class NotFound(Exception):
    """"""Object not found in source code""""""

class SmaliChecks:

    smaliPaths = []
    vulnerableTrustManagers=[]
    vulnerableWebViewSSLErrorBypass=[]
    vulnerableSetHostnameVerifiers = []
    vulnerableHostnameVerifiers = []
    vulnerableSocketsLocations = []
    dynamicRegisteredBroadcastReceiversLocations = []
    encryptionFunctionsLocation = []
    decryptionFunctionsLocation = []
    undeterminedCryptographicFunctionsLocation = []
    keystoreLocations = []
    webViewLoadUrlUsageLocation = []
    webViewAddJavascriptInterfaceUsageLocation = []
    okHttpCertificatePinningLocation = []
    customCertifificatePinningLocation = []
    AESwithECBLocations = []
    DESLocations =[]
    javascriptEnabledWebviews = []
    fileAccessEnabledWebviews = []
    universalAccessFromFileURLEnabledWebviewsLocations = []
    customChecksLocations = {}
    configuration = Configuration()

    def __init__(self, paths):
        for path in paths:
            self.smaliPaths.append(path)
        self.checkWebviewSSLErrorBypass()
        self.findWebviewJavascriptInterfaceUsage()
        self.findWeakCryptographicUsage()
        self.checkVulnerableTrustManagers()
        self.checkInsecureHostnameVerifier()
        self.checkVulnerableSockets()
        self.findEncryptionFunctions()
        self.checkVulnerableHostnameVerifiers()
        self.findWebViewLoadUrlUsage()
        self.findCustomChecks()
        self.findPropertyEnabledWebViews()
        self.checkOKHttpCertificatePinning()
        self.checkCustomPinningImplementation()
        self.findKeystoreUsage()
        self.findDynamicRegisteredBroadcastReceivers()
        self.findPathTraversalContentProvider()

    def getSmaliPaths(self):
        return self.smaliPaths

    def getOSGnuGrepCommand(self):
        if platform == ""darwin"":
            return ""ggrep""
        else:
            return ""grep""


    def checkForExistenceInFolder(self,objectRegEx,folderPath):
        command = [self.getOSGnuGrepCommand(),""-s"" ,""-r"", ""-l"", ""-P"",objectRegEx,"" --exclude-dir=""+self.configuration.getFolderExclusions()]
        for path in folderPath:
            command.append(path)
        grep = Popen(command, stdout=PIPE)
        filePaths = grep.communicate()[0].strip().split('\n')
        if len(filePaths) > 0:
            return filePaths
        else:
            raise NotFound

    def existsInFile(self,objectRegEx,filePath):
        grep = Popen([self.getOSGnuGrepCommand(),""-l"", ""-P"",objectRegEx,filePath], stdout=PIPE)
        filePaths = grep.communicate()[0].strip().split('\n')
        if len(filePaths) > 0:
            return filePaths
        else:
            return False

    def getMethodCompleteInstructions(self,methodRegEx,filePath):
        sed = Popen([""sed"", ""-n"", methodRegEx, filePath], stdout=PIPE)
        methodContent = sed.communicate()[0]
        return methodContent.strip().replace('    ','').split('\n')

    def getFileContent(self,filePath):
        sed = Popen([""sed"", ""1p"",filePath], stdout=PIPE)
        fileContent = sed.communicate()[0]
        return fileContent.strip().replace('    ', '').split('\n')

    def getMethodInstructions(self,methodRegEx,filePath):
        sed = Popen([""sed"", ""-n"", methodRegEx, filePath], stdout=PIPE)
        methodContent = sed.communicate()[0]
        try:
            match = re.search(r"".locals \d{1,}([\S\s]*?).end method"", methodContent)
            instructions = str(match.group(1)).strip().replace('    ','').split('\n')
            return instructions
        except:
            return """"

    def isMethodEmpty(self,instructions):
        for i in range(len(instructions)-1,0,-1):
            if instructions[i] == '.end method':
                continue
            else:
                if instructions[i] == ""return-void"":
                    return True
                else:
                    return False

    def hasOperationProceed(self,instructions):
        for i in range(len(instructions) - 1, 0, -1):
            if 'Landroid/webkit/SslErrorHandler;->proceed()V' in instructions[i]:
                return True
            else:
                continue
        return False

    def doesMethodReturnNull(self,instructions):
        for i in range(len(instructions) - 1, 0, -1):
            if instructions[i] == ""return-object v0"":
                if i-2 >= 0  and instructions[i-2] == ""const/4 v0, 0x0"":
                    return True
                elif i-2 >=0 and instructions[i-2] == ""new-array v0, v0, [Ljava/security/cert/X509Certificate;"":
                    if i-4 >= 0 and instructions[i - 4] == ""const/4 v0, 0x0"":
                        return True
                    else:
                        return False
                else:
                    return False
            else:
                continue
        return False

    def doesMethodReturnTrue(self,instructions):
        maxLen = len(instructions)-1
        for i in range(maxLen, 0, -1):
            if instructions[i] == ""return v0"":
                if i-2 >= 0 and instructions[i-2] == ""const/4 v0, 0x1"":
                    return True
                else:
                    return False
            else:
                continue
        return False


    #Returns the register that has the target value assigned

    def searchRegisterByAssignedValue(self,instructions,value):
        register = """"
        for instruction in instructions:
            if ""const/"" in instruction and value in instruction:
                registerEnd = instruction.find("","")
                registerBegin = instruction.find("" "",0,registerEnd)+1
                register = instruction[registerBegin:registerEnd]
                break
        return register


    #Returns the assigned value to the targer register.

    def getAssignedValueByRegister(self,instructions,register):
        register = """"
        for instruction in instructions:
            if ""const/"" in instruction and register in instruction:
                registerEnd = instruction.find("","")
                registerBegin = instruction.find("" "",0,registerEnd)+1
                register = instruction[registerBegin:registerEnd]
                break
        return register


    def doesActivityExtendsPreferenceActivity(self,activity):
        activity = activity.replace(""."",""/"")
        activityLocation = self.checkForExistenceInFolder("".class public([a-zA-Z\s]*)L""+activity+"";"",self.getSmaliPaths())
        if activityLocation[0] != """":
            preferenceExtends = self.existsInFile("".super Landroid\/preference\/PreferenceActivity;"",activityLocation[0])
            if preferenceExtends[0] != '':
                return True
            else:
                return False

    def doesPreferenceActivityHasValidFragmentCheck(self,activity):
        activity = activity.replace(""."",""/"")
        activityLocation = self.checkForExistenceInFolder("".class public([a-zA-Z\s]*)L""+activity+"";"",self.getSmaliPaths())
        if activityLocation[0] != """":
            isValidFragmentFunction = self.getMethodCompleteInstructions('/.method protected isValidFragment(Ljava\/lang\/String;)Z/,/^.end method/p',activityLocation[0])
            if isValidFragmentFunction[0] != '':
                return True
            else:
                return False

    def doesActivityHasFlagSecure(self,activity):
        activity = activity.replace(""."",""/"")
	end = activity.rfind('/')+1
	customPath = []
        x = len(self.getSmaliPaths())
	for a in range(0,x):
		customPath.append(self.getSmaliPaths()[a]+activity[:end])
        activityLocation = self.checkForExistenceInFolder("".class public([a-zA-Z\s]*)L""+activity+"";"",customPath)
        if activityLocation[0] != """":
            methodInstructions = self.getMethodCompleteInstructions('/.method \([a-zA-Z]* \)onCreate(Landroid\/os\/Bundle;)V/,/^.end method/p',activityLocation[0])
            register = self.searchRegisterByAssignedValue(methodInstructions,""0x2000"")
            if register.strip() == """":
		        return False
            else:
                flag = self.existsInFile(""invoke-virtual.*""+register+"".*Landroid\/view\/Window;->setFlags\(II\)V"",activityLocation[0])
                if flag[0] != '':
                    return True
                else:
                    return False

    def findRegisterAssignedValueFromIndexBackwards(self,instructionsList,register,index):
        for pointer in range(index,0,-1):
            if register in instructionsList[pointer] and (""const"" in instructionsList[pointer] or ""sget-object"" in instructionsList[pointer]):
                valueBegin = instructionsList[pointer].find("","")
                value = instructionsList[pointer][valueBegin+2:]
                return value

    def findRegistersPassedToFunction(self,functionInstruction):
        match = re.search(r""{(.*)}"", functionInstruction)
        try:
            if ""range"" in functionInstruction:
                registers = str(match.group(1)).strip().replace(' ', '').split("".."")
            else:
                registers = str(match.group(1)).strip().replace(' ','').split("","")
        except:
            match = re.search(r""\D\d"", functionInstruction)
            try:
                registers = str(match.group(0))
            except:
                return """"
        return registers

    def findInstructionIndex(self,instructionsList,instructionToSearch):
        indexList = []
        for index,instruction in enumerate(instructionsList):
            m = re.search(instructionToSearch,instruction)
            try:
                output = m.group(0)
                indexList.append(index)
            except:
                continue
        return indexList



    def findDynamicRegisteredBroadcastReceivers(self):
        dynamicRegisteredBroadcastReceiversLocations = self.checkForExistenceInFolder(
            "";->registerReceiver\(Landroid\/content\/BroadcastReceiver;Landroid\/content\/IntentFilter;\)"",
            self.getSmaliPaths())
        for location in dynamicRegisteredBroadcastReceiversLocations:
            self.dynamicRegisteredBroadcastReceiversLocations.append(location)


    def findEncryptionFunctions(self):
        encryptionFunctionsLocations = self.checkForExistenceInFolder(""invoke-virtual {(.*)}, Ljavax\/crypto\/Cipher;->init\(ILjava\/security\/Key"",self.getSmaliPaths())
        if encryptionFunctionsLocations[0] != """":
            for location in encryptionFunctionsLocations:
                if ""org/bouncycastle"" in location:
                    continue
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,""Ljavax/crypto/Cipher;->init\(ILjava/security/Key"")
                if len(indexList) != 0:
                    for index in indexList:
                        registers = self.findRegistersPassedToFunction(instructions[index])
                        if self.findRegisterAssignedValueFromIndexBackwards(instructions,registers[1],index) == ""0x1"":
                            self.encryptionFunctionsLocation.append(location)
                        elif self.findRegisterAssignedValueFromIndexBackwards(instructions,registers[1],index) == ""0x2"":
                            self.decryptionFunctionsLocation.append(location)
                        else:
                            if location not in self.undeterminedCryptographicFunctionsLocation:
                                self.undeterminedCryptographicFunctionsLocation.append(location)

    def findKeystoreUsage(self):
        keystoreUsageLocations = self.checkForExistenceInFolder(""invoke-virtual {(.*)}, Ljava\/security\/KeyStore;->getEntry\(Ljava\/lang\/String;Ljava\/security\/KeyStore\$ProtectionParameter;\)Ljava\/security\/KeyStore\$Entry"",self.getSmaliPaths())
        if keystoreUsageLocations[0] != """":
            for location in keystoreUsageLocations:
                self.keystoreLocations.append(location)

    def findWebViewLoadUrlUsage(self):
        webViewUsageLocations = self.checkForExistenceInFolder(""Landroid\/webkit\/WebView;->loadUrl\(Ljava\/lang\/String;\)V"",self.getSmaliPaths())
        if webViewUsageLocations[0] != """":
            for location in webViewUsageLocations:
                self.webViewLoadUrlUsageLocation.append(location)


    # *** Improper Platform Usage ***

    def findPathTraversalContentProvider(self):
        contentProvidersLocations = self.checkForExistenceInFolder("".super Landroid\/content\/ContentProvider;"",self.getSmaliPaths())
        if contentProvidersLocations[0] != '':
            for location in contentProvidersLocations:
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,"".method public openFile\(Landroid\/net\/Uri;Ljava\/lang\/String;\)Landroid\/os\/ParcelFileDescriptor;"")
                if len(indexList) > 0:
                    indexList = self.findInstructionIndex(instructions,""Ljava\/io\/File;->getCanonicalPath\(\)"")


    def findWeakCryptographicUsage(self):
        getInstanceLocations = self.checkForExistenceInFolder(""Ljavax\/crypto\/Cipher;->getInstance\(Ljava\/lang\/String;\)Ljavax\/crypto\/Cipher;"",self.getSmaliPaths())
        if getInstanceLocations[0] != '':
            for location in getInstanceLocations:
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,""Ljavax/crypto/Cipher;->getInstance\(Ljava/lang/String;\)Ljavax/crypto/Cipher;"")
                for index in indexList:
		    register = self.findRegistersPassedToFunction(instructions[index])
                    transformationValue = self.findRegisterAssignedValueFromIndexBackwards(instructions, register[0], index)
                    if transformationValue is not None:
                        if transformationValue == ""\""AES\"""" or ""AES/ECB/"" in transformationValue:
                            self.AESwithECBLocations.append(location)
                        elif ""DES"" in transformationValue:
                            self.DESLocations.append(location)


    def findPropertyEnabledWebViews(self):
        webviewUsageLocations = self.checkForExistenceInFolder("";->getSettings\(\)Landroid\/webkit\/WebSettings;"",self.getSmaliPaths())
        if webviewUsageLocations[0] != '':
            for location in webviewUsageLocations:
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,""Landroid/webkit/WebSettings;->setJavaScriptEnabled\(Z\)V"")
                if len(indexList) > 0:
                    for index in indexList:
                        register = self.findRegistersPassedToFunction(instructions[index])
                        value = self.findRegisterAssignedValueFromIndexBackwards(instructions,register[1],index)
                        if value == ""0x1"":
                            self.javascriptEnabledWebviews.append(location)
                indexList = self.findInstructionIndex(instructions,""Landroid/webkit/WebSettings;->setAllowFileAccess\(Z\)V"")
                if len(indexList) > 0:
                    for index in indexList:
                        register = self.findRegistersPassedToFunction(instructions[index])
                        value = self.findRegisterAssignedValueFromIndexBackwards(instructions, register[1], index)
                        if value == ""0x1"":
                            self.fileAccessEnabledWebviews.append(location)
                else:
                    self.fileAccessEnabledWebviews.append(location)
                indexList = self.findInstructionIndex(instructions,""Landroid/webkit/WebSettings;->setAllowUniversalAccessFromFileURLs\(Z\)V"")
                if len(indexList) > 0:
                    for index in indexList:
                        register = self.findRegistersPassedToFunction(instructions[index])
                        value = self.findRegisterAssignedValueFromIndexBackwards(instructions, register[1], index)
                        if value == ""0x1"":
                            self.universalAccessFromFileURLEnabledWebviewsLocations.append(location)



    def findWebviewJavascriptInterfaceUsage(self):
        javascriptInterfaceLocations = self.checkForExistenceInFolder("";->addJavascriptInterface\(Ljava\/lang\/Object;Ljava\/lang\/String;\)V"",self.getSmaliPaths())
        if javascriptInterfaceLocations[0] != '':
            for location in javascriptInterfaceLocations:
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,"";->addJavascriptInterface\(Ljava/lang/Object;Ljava/lang/String;\)V"")
                if len(indexList) != 0:
                    for index in indexList:
                        registers = self.findRegistersPassedToFunction(instructions[index])
                    self.webViewAddJavascriptInterfaceUsageLocation.append(location)


    # *** Insecure Communication Checks ***

    #Check for the implementation of custom HostnameVerifiers

    def checkInsecureHostnameVerifier(self):
        insecureHostNameVerifierLocations = self.checkForExistenceInFolder("".implements Ljavax\/net\/ssl\/HostnameVerifier;"",self.getSmaliPaths())
        if insecureHostNameVerifierLocations[0] != '':
            for location in insecureHostNameVerifierLocations:
                methodInstructions = self.getMethodCompleteInstructions('/.method .* verify(Ljava\/lang\/String;Ljavax\/net\/ssl\/SSLSession;)Z/,/^.end method/p',location)
                if methodInstructions != """":
                    if self.doesMethodReturnTrue(methodInstructions) == True:
                        self.vulnerableHostnameVerifiers.append(location)

    #Check for the presence of the custom function that allows to bypass SSL errors in WebViews

    def checkWebviewSSLErrorBypass(self):
        webviewErrorBypassLocations = self.checkForExistenceInFolder(""Landroid\/webkit\/SslErrorHandler;->proceed\(\)V"",self.getSmaliPaths())
        if webviewErrorBypassLocations[0] != '':
            for location in webviewErrorBypassLocations:
                self.vulnerableWebViewSSLErrorBypass.append(location)

    #Check for the presence of custom TrustManagers that are vulnerable.

    def checkVulnerableTrustManagers(self):
        vulnerableTrustManagers = []
        try:
            checkClientTrustedLocations = self.checkForExistenceInFolder("".method public checkClientTrusted\(\[Ljava\/security\/cert\/X509Certificate;Ljava\/lang\/String;\)V"",self.getSmaliPaths())
            if checkClientTrustedLocations[0] != '':
                for location in checkClientTrustedLocations:
                    methodInstructions = self.getMethodCompleteInstructions('/method public checkClientTrusted\(\)/,/^.end method/p',location)
                    if methodInstructions != """":
                        if self.isMethodEmpty(methodInstructions) == True:
                            getAcceptedIssuersLocations = self.existsInFile("".method public getAcceptedIssuers\(\)\[Ljava\/security\/cert\/X509Certificate;"",location)
                            if methodInstructions != """":
                                methodInstructions = self.getMethodCompleteInstructions('/method public getAcceptedIssuers()\[Ljava\/security\/cert\/X509Certificate;/,/^.end method/p',getAcceptedIssuersLocations[0])
                                if self.doesMethodReturnNull(methodInstructions) == True:
                                    checkServerTrustedLocations = self.existsInFile("".method public checkServerTrusted\(\[Ljava\/security\/cert\/X509Certificate;Ljava\/lang\/String;\)V"",location)
                                    if methodInstructions != """":
                                        methodInstructions = self.getMethodCompleteInstructions('/method public checkServerTrusted\(\)/,/^.end method/p', checkServerTrustedLocations[0])
                                        if self.isMethodEmpty(methodInstructions) == True:
                                            vulnerableTrustManagers.append(location)
                                            self.vulnerableTrustManagers.append(location)
                return vulnerableTrustManagers
        except NotFound:
            pass

    #Check for the presence of setHostnameVerifier with ALLOW_ALL_HOSTNAME_VERIFIER

    def checkVulnerableHostnameVerifiers(self):
        setHostnameVerifierLocations = self.checkForExistenceInFolder(""invoke-virtual {(.*)}, Lorg\/apache\/http\/conn\/ssl\/SSLSocketFactory;->setHostnameVerifier\(Lorg\/apache\/http\/conn\/ssl\/X509HostnameVerifier;\)V"",self.getSmaliPaths())
        if setHostnameVerifierLocations[0] != """":
            for location in setHostnameVerifierLocations:
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,""Lorg/apache/http/conn/ssl/SSLSocketFactory;->setHostnameVerifier"")
                if len(indexList) != 0:
                    for index in indexList:
                        registers = self.findRegistersPassedToFunction(instructions[index])
                        if self.findRegisterAssignedValueFromIndexBackwards(instructions, registers[1], index) == ""Lorg/apache/http/conn/ssl/SSLSocketFactory;->ALLOW_ALL_HOSTNAME_VERIFIER:Lorg/apache/http/conn/ssl/X509HostnameVerifier;"":
                            self.vulnerableSetHostnameVerifiers.append(location)

    #Check for SocketFactory without Hostname Verify

    def checkVulnerableSockets(self):
        vulnerableSocketsLocations = self.checkForExistenceInFolder(""Ljavax\/net\/SocketFactory;->createSocket\(Ljava\/lang\/String;I\)Ljava\/net\/Socket;"",self.getSmaliPaths())
        if vulnerableSocketsLocations[0] != """":
            for location in vulnerableSocketsLocations:
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,""Ljavax/net/ssl/HostnameVerifier;->verify\(Ljava/lang/String;Ljavax/net/ssl/SSLSession;\)Z"")
                if len(indexList) == 0:
                    self.vulnerableSocketsLocations.append(location)

    #Check for the implementation of OKHttp Certificate Pinning

    def checkOKHttpCertificatePinning(self):
        okHttpCertificatePinningLocations = self.checkForExistenceInFolder(""add\(Ljava\/lang\/String;\[Ljava\/lang\/String;\)Lokhttp3\/CertificatePinner\$Builder"",self.getSmaliPaths())
        if okHttpCertificatePinningLocations[0] != '':
            for location in okHttpCertificatePinningLocations:
                #Bypass library files
                if ""/okhttp"" in location:
                    continue
                instructions = self.getFileContent(location)
                indexList = self.findInstructionIndex(instructions,""certificatePinner\(Lokhttp3/CertificatePinner;\)Lokhttp3/OkHttpClient$Builder;"")
                if len(indexList) == 0:
                    self.okHttpCertificatePinningLocation.append(location)

    #Check for custom Certificate Pinning Implementation

    def checkCustomPinningImplementation(self):
        customCertificatePinningLocations = self.checkForExistenceInFolder(""invoke-virtual {(.*)}, Ljavax\/net\/ssl\/TrustManagerFactory;->init\(Ljava\/security\/KeyStore;\)V"",self.getSmaliPaths())
        if customCertificatePinningLocations[0] != '':
            for location in customCertificatePinningLocations:
                if ""/okhttp"" in location or ""io/fabric"" in location:
                    continue
                self.customCertifificatePinningLocation.append(location)


    # *** CUSTOM CHECKS ***


    def findCustomChecks(self):
        for check in self.configuration.getCustomChecks():
                self.customChecksLocations[check[0]] = []
                customCheckLocationsFound = self.checkForExistenceInFolder(check[1],self.getSmaliPaths())
                if customCheckLocationsFound[0] != '':
                    for location in customCheckLocationsFound:
                        self.customChecksLocations[check[0]].append(location)
    # *** GETTERS ***

    def getVulnerableTrustManagers(self):
        return self.vulnerableTrustManagers

    def getVulnerableWebViewSSLErrorBypass(self):
        return self.vulnerableWebViewSSLErrorBypass

    def getVulnerableHostnameVerifiers(self):
        return self.vulnerableHostnameVerifiers

    def getEncryptionFunctionsLocations(self):
        return self.encryptionFunctionsLocation

    def getDecryptionFunctionsLocations(self):
        return self.decryptionFunctionsLocation

    def getUndeterminedCryptographicFunctionsLocations(self):
        return self.undeterminedCryptographicFunctionsLocation

    def getVulnerableSetHostnameVerifier(self):
        return self.vulnerableSetHostnameVerifiers

    def getVulnerableSockets(self):
        return self.vulnerableSocketsLocations

    def getWebViewsLoadUrlUsageLocations(self):
        return self.webViewLoadUrlUsageLocation

    def getCustomChecksLocations(self):
        return self.customChecksLocations

    def getWebviewAddJavascriptInterfaceLocations(self):
        return self.webViewAddJavascriptInterfaceUsageLocation

    def getAESwithECBLocations(self):
        return self.AESwithECBLocations

    def getDESLocations(self):
        return self.DESLocations

    def getJavascriptEnabledWebViews(self):
        return self.javascriptEnabledWebviews

    def getFileAccessEnabledWebViews(self):
        return self.fileAccessEnabledWebviews

    def getUniversalAccessFromFileURLEnabledWebviewsLocations(self):
        return self.universalAccessFromFileURLEnabledWebviewsLocations

    def getOkHTTPCertificatePinningLocations(self):
        return self.okHttpCertificatePinningLocation

    def getCustomCertificatePinningLocations(self):
        return self.customCertifificatePinningLocation

    def getKeystoreLocations(self):
        return self.keystoreLocations

    def getDynamicRegisteredBroadcastReceiversLocations(self):
        return self.dynamicRegisteredBroadcastReceiversLocations
/n/n/n",1
216,216,7530515f25d8f5a2a1e1e2b2d6d8fc9d711f730a,"app/api/common.py/n/nfrom django.core.exceptions import ObjectDoesNotExist, SuspiciousFileOperation
from rest_framework import exceptions
import os

from app import models

def get_and_check_project(request, project_pk, perms=('view_project',)):
    """"""
    Django comes with a standard `model level` permission system. You can
    check whether users are logged-in and have privileges to act on things
    model wise (can a user add a project? can a user view projects?).
    Django-guardian adds a `row level` permission system. Now not only can you
    decide whether a user can add a project or view projects, you can specify exactly
    which projects a user has or has not access to.

    This brings up the reason the following function: tasks are part of a project,
    and it would add a tremendous headache (and redundancy) to specify row level permissions
    for each task. Instead, we check the row level permissions of the project
    to which a task belongs to.

    Perhaps this could be added as a django-rest filter?

    Retrieves a project and raises an exception if the current user
    has no access to it.
    """"""
    try:
        project = models.Project.objects.get(pk=project_pk, deleting=False)
        for perm in perms:
            if not request.user.has_perm(perm, project): raise ObjectDoesNotExist()
    except ObjectDoesNotExist:
        raise exceptions.NotFound()
    return project


def get_tile_json(name, tiles, bounds):
    return {
        'tilejson': '2.1.0',
        'name': name,
        'version': '1.0.0',
        'scheme': 'tms',
        'tiles': tiles,
        'minzoom': 0,
        'maxzoom': 22,
        'bounds': bounds
    }

def path_traversal_check(unsafe_path, known_safe_path):
    known_safe_path = os.path.abspath(known_safe_path)
    unsafe_path = os.path.abspath(unsafe_path)

    if (os.path.commonprefix([known_safe_path, unsafe_path]) != known_safe_path):
        raise SuspiciousFileOperation(""{} is not safe"".format(unsafe_path))

    # Passes the check
    return unsafe_path/n/n/napp/api/tasks.py/n/nimport mimetypes
import os

from django.contrib.gis.db.models import GeometryField
from django.contrib.gis.db.models.functions import Envelope
from django.core.exceptions import ObjectDoesNotExist, SuspiciousFileOperation
from django.db.models.functions import Cast
from django.http import HttpResponse
from wsgiref.util import FileWrapper
from rest_framework import status, serializers, viewsets, filters, exceptions, permissions, parsers
from rest_framework.response import Response
from rest_framework.decorators import detail_route
from rest_framework.views import APIView
from .common import get_and_check_project, get_tile_json, path_traversal_check

from app import models, scheduler, pending_actions
from nodeodm.models import ProcessingNode


class TaskIDsSerializer(serializers.BaseSerializer):
    def to_representation(self, obj):
        return obj.id


class TaskSerializer(serializers.ModelSerializer):
    project = serializers.PrimaryKeyRelatedField(queryset=models.Project.objects.all())
    processing_node = serializers.PrimaryKeyRelatedField(queryset=ProcessingNode.objects.all()) 
    images_count = serializers.SerializerMethodField()

    def get_images_count(self, obj):
        return obj.imageupload_set.count()

    class Meta:
        model = models.Task
        exclude = ('processing_lock', 'console_output', 'orthophoto', )


class TaskViewSet(viewsets.ViewSet):
    """"""
    Task get/add/delete/update
    A task represents a set of images and other input to be sent to a processing node.
    Once a processing node completes processing, results are stored in the task.
    """"""
    queryset = models.Task.objects.all().defer('orthophoto', 'console_output')
    
    # We don't use object level permissions on tasks, relying on
    # project's object permissions instead (but standard model permissions still apply)
    permission_classes = (permissions.DjangoModelPermissions, )
    parser_classes = (parsers.MultiPartParser, parsers.JSONParser, parsers.FormParser, )
    ordering_fields = '__all__'

    def set_pending_action(self, pending_action, request, pk=None, project_pk=None, perms=('change_project', )):
        get_and_check_project(request, project_pk, perms)
        try:
            task = self.queryset.get(pk=pk, project=project_pk)
        except ObjectDoesNotExist:
            raise exceptions.NotFound()

        task.pending_action = pending_action
        task.last_error = None
        task.save()

        # Call the scheduler (speed things up)
        scheduler.process_pending_tasks(background=True)

        return Response({'success': True})

    @detail_route(methods=['post'])
    def cancel(self, *args, **kwargs):
        return self.set_pending_action(pending_actions.CANCEL, *args, **kwargs)

    @detail_route(methods=['post'])
    def restart(self, *args, **kwargs):
        return self.set_pending_action(pending_actions.RESTART, *args, **kwargs)

    @detail_route(methods=['post'])
    def remove(self, *args, **kwargs):
        return self.set_pending_action(pending_actions.REMOVE, *args, perms=('delete_project', ), **kwargs)

    @detail_route(methods=['get'])
    def output(self, request, pk=None, project_pk=None):
        """"""
        Retrieve the console output for this task.
        An optional ""line"" query param can be passed to retrieve
        only the output starting from a certain line number.
        """"""
        get_and_check_project(request, project_pk)
        try:
            task = self.queryset.get(pk=pk, project=project_pk)
        except ObjectDoesNotExist:
            raise exceptions.NotFound()

        line_num = max(0, int(request.query_params.get('line', 0)))
        output = task.console_output or """"
        return Response('\n'.join(output.split('\n')[line_num:]))


    def list(self, request, project_pk=None):
        get_and_check_project(request, project_pk)
        tasks = self.queryset.filter(project=project_pk)
        tasks = filters.OrderingFilter().filter_queryset(self.request, tasks, self)
        serializer = TaskSerializer(tasks, many=True)
        return Response(serializer.data)

    def retrieve(self, request, pk=None, project_pk=None):
        get_and_check_project(request, project_pk)
        try:
            task = self.queryset.get(pk=pk, project=project_pk)
        except ObjectDoesNotExist:
            raise exceptions.NotFound()

        serializer = TaskSerializer(task)
        return Response(serializer.data)

    def create(self, request, project_pk=None):
        project = get_and_check_project(request, project_pk, ('change_project', ))
        
        # MultiValueDict in, flat array of files out
        files = [file for filesList in map(
                        lambda key: request.FILES.getlist(key), 
                        [keys for keys in request.FILES])
                    for file in filesList]

        task = models.Task.create_from_images(files, project)
        if task is not None:
            return Response({""id"": task.id}, status=status.HTTP_201_CREATED)
        else:
            raise exceptions.ValidationError(detail=""Cannot create task, input provided is not valid."")

    def update(self, request, pk=None, project_pk=None, partial=False):
        get_and_check_project(request, project_pk, ('change_project', ))
        try:
            task = self.queryset.get(pk=pk, project=project_pk)
        except ObjectDoesNotExist:
            raise exceptions.NotFound()

        serializer = TaskSerializer(task, data=request.data, partial=partial)
        serializer.is_valid(raise_exception=True)
        serializer.save()

        # Call the scheduler (speed things up)
        scheduler.process_pending_tasks(background=True)

        return Response(serializer.data)

    def partial_update(self, request, *args, **kwargs):
        kwargs['partial'] = True
        return self.update(request, *args, **kwargs)


class TaskNestedView(APIView):
    queryset = models.Task.objects.all().defer('orthophoto', 'console_output')

    def get_and_check_task(self, request, pk, project_pk, annotate={}):
        get_and_check_project(request, project_pk)
        try:
            task = self.queryset.annotate(**annotate).get(pk=pk, project=project_pk)
        except ObjectDoesNotExist:
            raise exceptions.NotFound()
        return task


class TaskTiles(TaskNestedView):
    def get(self, request, pk=None, project_pk=None, z="""", x="""", y=""""):
        """"""
        Get an orthophoto tile
        """"""
        task = self.get_and_check_task(request, pk, project_pk)
        tile_path = task.get_tile_path(z, x, y)
        if os.path.isfile(tile_path):
            tile = open(tile_path, ""rb"")
            return HttpResponse(FileWrapper(tile), content_type=""image/png"")
        else:
            raise exceptions.NotFound()


class TaskTilesJson(TaskNestedView):
    def get(self, request, pk=None, project_pk=None):
        """"""
        Get tile.json for this tasks's orthophoto
        """"""
        task = self.get_and_check_task(request, pk, project_pk, annotate={
                'orthophoto_area': Envelope(Cast(""orthophoto"", GeometryField()))
            })
        json = get_tile_json(task.name, [
                '/api/projects/{}/tasks/{}/tiles/{{z}}/{{x}}/{{y}}.png'.format(task.project.id, task.id)
            ], task.orthophoto_area.extent)
        return Response(json)


""""""
Task downloads are simply aliases to download the task's assets
(but require a shorter path and look nicer the API user)
""""""
class TaskDownloads(TaskNestedView):
        def get(self, request, pk=None, project_pk=None, asset=""""):
            """"""
            Downloads a task asset (if available)
            """"""
            task = self.get_and_check_task(request, pk, project_pk)

            allowed_assets = {
                'all': 'all.zip',
                'geotiff': os.path.join('odm_orthophoto', 'odm_orthophoto.tif'),
                'las': os.path.join('odm_georeferencing', 'odm_georeferenced_model.ply.las'),
                'ply': os.path.join('odm_georeferencing', 'odm_georeferenced_model.ply'),
                'csv': os.path.join('odm_georeferencing', 'odm_georeferenced_model.csv')
            }

            if asset in allowed_assets:
                asset_path = task.assets_path(allowed_assets[asset])

                if not os.path.exists(asset_path):
                    raise exceptions.NotFound(""Asset does not exist"")

                asset_filename = os.path.basename(asset_path)

                file = open(asset_path, ""rb"")
                response = HttpResponse(FileWrapper(file),
                                        content_type=(mimetypes.guess_type(asset_filename)[0] or ""application/zip""))
                response['Content-Disposition'] = ""attachment; filename={}"".format(asset_filename)
                return response
            else:
                raise exceptions.NotFound()

""""""
Raw access to the task's asset folder resources
Useful when accessing a textured 3d model, or the Potree point cloud data
""""""
class TaskAssets(TaskNestedView):
    def get(self, request, pk=None, project_pk=None, unsafe_asset_path=""""):
        """"""
        Downloads a task asset (if available)
        """"""
        task = self.get_and_check_task(request, pk, project_pk)

        # Check for directory traversal attacks
        try:
            asset_path = path_traversal_check(task.assets_path(unsafe_asset_path), task.assets_path(""""))
        except SuspiciousFileOperation:
            raise exceptions.NotFound(""Asset does not exist"")

        if (not os.path.exists(asset_path)) or os.path.isdir(asset_path):
            raise exceptions.NotFound(""Asset does not exist"")

        asset_filename = os.path.basename(asset_path)

        file = open(asset_path, ""rb"")
        response = HttpResponse(FileWrapper(file),
                                content_type=(mimetypes.guess_type(asset_filename)[0] or ""application/zip""))
        response['Content-Disposition'] = ""inline; filename={}"".format(asset_filename)
        return response
/n/n/napp/api/urls.py/n/nfrom django.conf.urls import url, include
from .projects import ProjectViewSet
from .tasks import TaskViewSet, TaskTiles, TaskTilesJson, TaskDownloads, TaskAssets
from .processingnodes import ProcessingNodeViewSet
from rest_framework_nested import routers

router = routers.DefaultRouter()
router.register(r'projects', ProjectViewSet)
router.register(r'processingnodes', ProcessingNodeViewSet)

tasks_router = routers.NestedSimpleRouter(router, r'projects', lookup='project')
tasks_router.register(r'tasks', TaskViewSet, base_name='projects-tasks')

urlpatterns = [
    url(r'^', include(router.urls)),
    url(r'^', include(tasks_router.urls)),

    url(r'projects/(?P<project_pk>[^/.]+)/tasks/(?P<pk>[^/.]+)/tiles/(?P<z>[\d]+)/(?P<x>[\d]+)/(?P<y>[\d]+)\.png$', TaskTiles.as_view()),
    url(r'projects/(?P<project_pk>[^/.]+)/tasks/(?P<pk>[^/.]+)/tiles\.json$', TaskTilesJson.as_view()),
    url(r'projects/(?P<project_pk>[^/.]+)/tasks/(?P<pk>[^/.]+)/download/(?P<asset>[^/.]+)/$', TaskDownloads.as_view()),
    url(r'projects/(?P<project_pk>[^/.]+)/tasks/(?P<pk>[^/.]+)/assets/(?P<unsafe_asset_path>.+)$', TaskAssets.as_view()),

    url(r'^auth/', include('rest_framework.urls')),
]/n/n/napp/tests/test_api.py/n/nfrom guardian.shortcuts import assign_perm

from app import pending_actions
from .classes import BootTestCase
from rest_framework.test import APIClient
from rest_framework import status
import datetime

from app.models import Project, Task
from nodeodm.models import ProcessingNode
from django.contrib.auth.models import User

class TestApi(BootTestCase):
    def setUp(self):
        pass

    def tearDown(self):
        pass

    def test_projects_and_tasks(self):
        client = APIClient()

        user = User.objects.get(username=""testuser"")
        self.assertFalse(user.is_superuser)

        project = Project.objects.create(
                owner=user,
                name=""test project""
            )
        other_project = Project.objects.create(
                owner=User.objects.get(username=""testuser2""),
                name=""another test project""
            )

        # Forbidden without credentials
        res = client.get('/api/projects/')
        self.assertEqual(res.status_code, status.HTTP_403_FORBIDDEN)
        
        client.login(username=""testuser"", password=""test1234"")
        res = client.get('/api/projects/')
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(len(res.data[""results""]) > 0)

        # Can sort
        res = client.get('/api/projects/?ordering=-created_at')
        last_project = Project.objects.filter(owner=user).latest('created_at')
        self.assertTrue(res.data[""results""][0]['id'] == last_project.id)

        res = client.get('/api/projects/{}/'.format(project.id))
        self.assertEqual(res.status_code, status.HTTP_200_OK)

        res = client.get('/api/projects/dasjkldas/')
        self.assertEqual(res.status_code, status.HTTP_404_NOT_FOUND)

        res = client.get('/api/projects/{}/'.format(other_project.id))
        self.assertEqual(res.status_code, status.HTTP_404_NOT_FOUND)

        # Can filter
        res = client.get('/api/projects/?name=999')
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(len(res.data[""results""]) == 0)

        # Cannot list somebody else's project without permission
        res = client.get('/api/projects/?id={}'.format(other_project.id))
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(len(res.data[""results""]) == 0)

        # Can access individual project
        res = client.get('/api/projects/{}/'.format(project.id))
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(res.data[""id""] == project.id)

        # Cannot access project for which we have no access to
        res = client.get('/api/projects/{}/'.format(other_project.id))
        self.assertEqual(res.status_code, status.HTTP_404_NOT_FOUND)

        # Can create project, but owner cannot be set
        res = client.post('/api/projects/', {'name': 'test', 'description': 'test descr'})
        self.assertEqual(res.status_code, status.HTTP_201_CREATED)
        self.assertTrue(Project.objects.get(pk=res.data['id']).owner.id == user.id)

        # Cannot leave name empty
        res = client.post('/api/projects/', {'description': 'test descr'})
        self.assertEqual(res.status_code, status.HTTP_400_BAD_REQUEST)


        # Create some tasks
        task = Task.objects.create(project=project)
        task2 = Task.objects.create(project=project, created_at=task.created_at + datetime.timedelta(0, 1))
        other_task = Task.objects.create(project=other_project)

        # Can list project tasks to a project we have access to
        res = client.get('/api/projects/{}/tasks/'.format(project.id))
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(len(res.data) == 2)

        # Can sort
        res = client.get('/api/projects/{}/tasks/?ordering=created_at'.format(project.id))
        self.assertTrue(res.data[0]['id'] == task.id)
        self.assertTrue(res.data[1]['id'] == task2.id)

        res = client.get('/api/projects/{}/tasks/?ordering=-created_at'.format(project.id))
        self.assertTrue(res.data[0]['id'] == task2.id)
        self.assertTrue(res.data[1]['id'] == task.id)

        # Cannot list project tasks for a project we don't have access to
        res = client.get('/api/projects/{}/tasks/'.format(other_project.id))
        self.assertEqual(res.status_code, status.HTTP_404_NOT_FOUND)

        # Cannot list project tasks for a project that doesn't exist
        res = client.get('/api/projects/999/tasks/')
        self.assertEqual(res.status_code, status.HTTP_404_NOT_FOUND)
        
        # Can list task details for a task belonging to a project we have access to
        res = client.get('/api/projects/{}/tasks/{}/'.format(project.id, task.id))
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(res.data[""id""] == task.id)

        # images_count field exists
        self.assertTrue(res.data[""images_count""] == 0)

        # Get console output
        res = client.get('/api/projects/{}/tasks/{}/output/'.format(project.id, task.id))
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(res.data == """")

        task.console_output = ""line1\nline2\nline3""
        task.save()

        res = client.get('/api/projects/{}/tasks/{}/output/'.format(project.id, task.id))
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(res.data == task.console_output)

        # Console output with line num
        res = client.get('/api/projects/{}/tasks/{}/output/?line=2'.format(project.id, task.id))
        self.assertTrue(res.data == ""line3"")

        # Console output with line num out of bounds
        res = client.get('/api/projects/{}/tasks/{}/output/?line=3'.format(project.id, task.id))
        self.assertTrue(res.data == """")
        res = client.get('/api/projects/{}/tasks/{}/output/?line=-1'.format(project.id, task.id))
        self.assertTrue(res.data == task.console_output)

        # Cannot list task details for a task belonging to a project we don't have access to
        res = client.get('/api/projects/{}/tasks/{}/'.format(other_project.id, other_task.id))
        self.assertEqual(res.status_code, status.HTTP_404_NOT_FOUND)

        # As above, but by trying to trick the API by using a project we have access to
        res = client.get('/api/projects/{}/tasks/{}/'.format(project.id, other_task.id))
        self.assertEqual(res.status_code, status.HTTP_404_NOT_FOUND)

        # Cannot access task details for a task that doesn't exist
        res = client.get('/api/projects/{}/tasks/999/'.format(project.id, other_task.id))
        self.assertEqual(res.status_code, status.HTTP_404_NOT_FOUND)

        # Can update a task
        res = client.patch('/api/projects/{}/tasks/{}/'.format(project.id, task.id), {'name': 'updated!'}, format='json')
        self.assertEqual(res.status_code, status.HTTP_200_OK)

        # Verify the task has been updated
        res = client.get('/api/projects/{}/tasks/{}/'.format(project.id, task.id))
        self.assertTrue(res.data[""name""] == ""updated!"")

        # Cannot update a task we have no access to
        res = client.patch('/api/projects/{}/tasks/{}/'.format(other_project.id, other_task.id), {'name': 'updated!'}, format='json')
        self.assertEqual(res.status_code, status.HTTP_404_NOT_FOUND)

        # Can cancel a task for which we have permission
        self.assertTrue(task.pending_action is None)
        res = client.post('/api/projects/{}/tasks/{}/cancel/'.format(project.id, task.id))
        self.assertTrue(res.data[""success""])
        task.refresh_from_db()
        self.assertTrue(task.last_error is None)
        self.assertTrue(task.pending_action == pending_actions.CANCEL)

        res = client.post('/api/projects/{}/tasks/{}/restart/'.format(project.id, task.id))
        self.assertTrue(res.data[""success""])
        task.refresh_from_db()
        self.assertTrue(task.last_error is None)
        self.assertTrue(task.pending_action == pending_actions.RESTART)

        # Cannot cancel, restart or delete a task for which we don't have permission
        for action in ['cancel', 'remove', 'restart']:
            res = client.post('/api/projects/{}/tasks/{}/{}/'.format(other_project.id, other_task.id, action))
            self.assertEqual(res.status_code, status.HTTP_404_NOT_FOUND)

        # Can delete
        res = client.post('/api/projects/{}/tasks/{}/remove/'.format(project.id, task.id))
        self.assertTrue(res.data[""success""])
        task.refresh_from_db()
        self.assertTrue(task.last_error is None)
        self.assertTrue(task.pending_action == pending_actions.REMOVE)


        # TODO test:
        # - tiles.json requests
        # - task creation via file upload
        # - scheduler processing steps
        # - tiles API urls (permissions, 404s)
        # - assets download (aliases)
        # - assets raw downloads
        # - project deletion

    def test_processingnodes(self):
        client = APIClient()

        pnode = ProcessingNode.objects.create(
                hostname=""localhost"",
                port=999
            )

        another_pnode = ProcessingNode.objects.create(
            hostname=""localhost"",
            port=998
        )

        # Cannot list processing nodes as guest
        res = client.get('/api/processingnodes/')
        self.assertEqual(res.status_code, status.HTTP_403_FORBIDDEN)

        res = client.get('/api/processingnodes/{}/'.format(pnode.id))
        self.assertEqual(res.status_code, status.HTTP_403_FORBIDDEN)

        client.login(username=""testuser"", password=""test1234"")

        # Cannot list processing nodes, unless permissions have been granted
        res = client.get('/api/processingnodes/')
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(len(res.data) == 0)

        user = User.objects.get(username=""testuser"")
        self.assertFalse(user.is_staff)
        self.assertFalse(user.is_superuser)
        self.assertFalse(user.has_perm('view_processingnode', pnode))
        assign_perm('view_processingnode', user, pnode)
        self.assertTrue(user.has_perm('view_processingnode', pnode))

        # Now we can list processing nodes as normal user
        res = client.get('/api/processingnodes/')
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(len(res.data) == 1)
        self.assertTrue(res.data[0][""hostname""] == ""localhost"")

        # Can use filters
        res = client.get('/api/processingnodes/?id={}'.format(pnode.id))
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(len(res.data) == 1)

        res = client.get('/api/processingnodes/?id={}'.format(another_pnode.id))
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(len(res.data) == 0)

        # Can filter nodes with valid options
        res = client.get('/api/processingnodes/?has_available_options=true')
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(len(res.data) == 0)

        res = client.get('/api/processingnodes/?has_available_options=false')
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(len(res.data) == 1)
        self.assertTrue(res.data[0]['hostname'] == 'localhost')


        # Can get single processing node as normal user
        res = client.get('/api/processingnodes/{}/'.format(pnode.id))
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(res.data[""hostname""] == ""localhost"")


        # Cannot delete a processing node as normal user
        res = client.delete('/api/processingnodes/{}/'.format(pnode.id))
        self.assertTrue(res.status_code, status.HTTP_403_FORBIDDEN)

        # Cannot create a processing node as normal user
        res = client.post('/api/processingnodes/', {'hostname': 'localhost', 'port':'1000'})
        self.assertTrue(res.status_code, status.HTTP_403_FORBIDDEN)

        client.login(username=""testsuperuser"", password=""test1234"")

        # Can delete a processing node as super user
        res = client.delete('/api/processingnodes/{}/'.format(pnode.id))
        self.assertTrue(res.status_code, status.HTTP_200_OK)

        # Can create a processing node as super user
        res = client.post('/api/processingnodes/', {'hostname': 'localhost', 'port':'1000'})
        self.assertTrue(res.status_code, status.HTTP_200_OK)

        # Verify node has been created
        res = client.get('/api/processingnodes/')
        self.assertEqual(res.status_code, status.HTTP_200_OK)
        self.assertTrue(len(res.data) == 2)
        self.assertTrue(res.data[1][""port""] == 1000)

/n/n/n",0
217,217,7530515f25d8f5a2a1e1e2b2d6d8fc9d711f730a,"/app/api/common.py/n/nfrom django.core.exceptions import ObjectDoesNotExist
from rest_framework import exceptions

from app import models

def get_and_check_project(request, project_pk, perms=('view_project',)):
    """"""
    Django comes with a standard `model level` permission system. You can
    check whether users are logged-in and have privileges to act on things
    model wise (can a user add a project? can a user view projects?).
    Django-guardian adds a `row level` permission system. Now not only can you
    decide whether a user can add a project or view projects, you can specify exactly
    which projects a user has or has not access to.

    This brings up the reason the following function: tasks are part of a project,
    and it would add a tremendous headache (and redundancy) to specify row level permissions
    for each task. Instead, we check the row level permissions of the project
    to which a task belongs to.

    Perhaps this could be added as a django-rest filter?

    Retrieves a project and raises an exception if the current user
    has no access to it.
    """"""
    try:
        project = models.Project.objects.get(pk=project_pk, deleting=False)
        for perm in perms:
            if not request.user.has_perm(perm, project): raise ObjectDoesNotExist()
    except ObjectDoesNotExist:
        raise exceptions.NotFound()
    return project


def get_tile_json(name, tiles, bounds):
    return {
        'tilejson': '2.1.0',
        'name': name,
        'version': '1.0.0',
        'scheme': 'tms',
        'tiles': tiles,
        'minzoom': 0,
        'maxzoom': 22,
        'bounds': bounds
    }/n/n/n/app/api/tasks.py/n/nimport mimetypes
import os

from django.contrib.gis.db.models import GeometryField
from django.contrib.gis.db.models.functions import Envelope
from django.core.exceptions import ObjectDoesNotExist
from django.db.models.functions import Cast
from django.http import HttpResponse
from wsgiref.util import FileWrapper
from rest_framework import status, serializers, viewsets, filters, exceptions, permissions, parsers
from rest_framework.response import Response
from rest_framework.decorators import detail_route
from rest_framework.views import APIView
from .common import get_and_check_project, get_tile_json

from app import models, scheduler, pending_actions
from nodeodm.models import ProcessingNode


class TaskIDsSerializer(serializers.BaseSerializer):
    def to_representation(self, obj):
        return obj.id


class TaskSerializer(serializers.ModelSerializer):
    project = serializers.PrimaryKeyRelatedField(queryset=models.Project.objects.all())
    processing_node = serializers.PrimaryKeyRelatedField(queryset=ProcessingNode.objects.all()) 
    images_count = serializers.SerializerMethodField()

    def get_images_count(self, obj):
        return obj.imageupload_set.count()

    class Meta:
        model = models.Task
        exclude = ('processing_lock', 'console_output', 'orthophoto', )


class TaskViewSet(viewsets.ViewSet):
    """"""
    Task get/add/delete/update
    A task represents a set of images and other input to be sent to a processing node.
    Once a processing node completes processing, results are stored in the task.
    """"""
    queryset = models.Task.objects.all().defer('orthophoto', 'console_output')
    
    # We don't use object level permissions on tasks, relying on
    # project's object permissions instead (but standard model permissions still apply)
    permission_classes = (permissions.DjangoModelPermissions, )
    parser_classes = (parsers.MultiPartParser, parsers.JSONParser, parsers.FormParser, )
    ordering_fields = '__all__'

    def set_pending_action(self, pending_action, request, pk=None, project_pk=None, perms=('change_project', )):
        get_and_check_project(request, project_pk, perms)
        try:
            task = self.queryset.get(pk=pk, project=project_pk)
        except ObjectDoesNotExist:
            raise exceptions.NotFound()

        task.pending_action = pending_action
        task.last_error = None
        task.save()

        # Call the scheduler (speed things up)
        scheduler.process_pending_tasks(background=True)

        return Response({'success': True})

    @detail_route(methods=['post'])
    def cancel(self, *args, **kwargs):
        return self.set_pending_action(pending_actions.CANCEL, *args, **kwargs)

    @detail_route(methods=['post'])
    def restart(self, *args, **kwargs):
        return self.set_pending_action(pending_actions.RESTART, *args, **kwargs)

    @detail_route(methods=['post'])
    def remove(self, *args, **kwargs):
        return self.set_pending_action(pending_actions.REMOVE, *args, perms=('delete_project', ), **kwargs)

    @detail_route(methods=['get'])
    def output(self, request, pk=None, project_pk=None):
        """"""
        Retrieve the console output for this task.
        An optional ""line"" query param can be passed to retrieve
        only the output starting from a certain line number.
        """"""
        get_and_check_project(request, project_pk)
        try:
            task = self.queryset.get(pk=pk, project=project_pk)
        except ObjectDoesNotExist:
            raise exceptions.NotFound()

        line_num = max(0, int(request.query_params.get('line', 0)))
        output = task.console_output or """"
        return Response('\n'.join(output.split('\n')[line_num:]))


    def list(self, request, project_pk=None):
        get_and_check_project(request, project_pk)
        tasks = self.queryset.filter(project=project_pk)
        tasks = filters.OrderingFilter().filter_queryset(self.request, tasks, self)
        serializer = TaskSerializer(tasks, many=True)
        return Response(serializer.data)

    def retrieve(self, request, pk=None, project_pk=None):
        get_and_check_project(request, project_pk)
        try:
            task = self.queryset.get(pk=pk, project=project_pk)
        except ObjectDoesNotExist:
            raise exceptions.NotFound()

        serializer = TaskSerializer(task)
        return Response(serializer.data)

    def create(self, request, project_pk=None):
        project = get_and_check_project(request, project_pk, ('change_project', ))
        
        # MultiValueDict in, flat array of files out
        files = [file for filesList in map(
                        lambda key: request.FILES.getlist(key), 
                        [keys for keys in request.FILES])
                    for file in filesList]

        task = models.Task.create_from_images(files, project)
        if task is not None:
            return Response({""id"": task.id}, status=status.HTTP_201_CREATED)
        else:
            raise exceptions.ValidationError(detail=""Cannot create task, input provided is not valid."")

    def update(self, request, pk=None, project_pk=None, partial=False):
        get_and_check_project(request, project_pk, ('change_project', ))
        try:
            task = self.queryset.get(pk=pk, project=project_pk)
        except ObjectDoesNotExist:
            raise exceptions.NotFound()

        serializer = TaskSerializer(task, data=request.data, partial=partial)
        serializer.is_valid(raise_exception=True)
        serializer.save()

        # Call the scheduler (speed things up)
        scheduler.process_pending_tasks(background=True)

        return Response(serializer.data)

    def partial_update(self, request, *args, **kwargs):
        kwargs['partial'] = True
        return self.update(request, *args, **kwargs)


class TaskNestedView(APIView):
    queryset = models.Task.objects.all().defer('orthophoto', 'console_output')

    def get_and_check_task(self, request, pk, project_pk, annotate={}):
        get_and_check_project(request, project_pk)
        try:
            task = self.queryset.annotate(**annotate).get(pk=pk, project=project_pk)
        except ObjectDoesNotExist:
            raise exceptions.NotFound()
        return task


class TaskTiles(TaskNestedView):
    def get(self, request, pk=None, project_pk=None, z="""", x="""", y=""""):
        """"""
        Get an orthophoto tile
        """"""
        task = self.get_and_check_task(request, pk, project_pk)
        tile_path = task.get_tile_path(z, x, y)
        if os.path.isfile(tile_path):
            tile = open(tile_path, ""rb"")
            return HttpResponse(FileWrapper(tile), content_type=""image/png"")
        else:
            raise exceptions.NotFound()


class TaskTilesJson(TaskNestedView):
    def get(self, request, pk=None, project_pk=None):
        """"""
        Get tile.json for this tasks's orthophoto
        """"""
        task = self.get_and_check_task(request, pk, project_pk, annotate={
                'orthophoto_area': Envelope(Cast(""orthophoto"", GeometryField()))
            })
        json = get_tile_json(task.name, [
                '/api/projects/{}/tasks/{}/tiles/{{z}}/{{x}}/{{y}}.png'.format(task.project.id, task.id)
            ], task.orthophoto_area.extent)
        return Response(json)


class TaskAssets(TaskNestedView):
        def get(self, request, pk=None, project_pk=None, asset=""""):
            """"""
            Downloads a task asset (if available)
            """"""
            task = self.get_and_check_task(request, pk, project_pk)

            allowed_assets = {
                'all': 'all.zip',
                'geotiff': os.path.join('odm_orthophoto', 'odm_orthophoto.tif'),
                'las': os.path.join('odm_georeferencing', 'odm_georeferenced_model.ply.las'),
                'ply': os.path.join('odm_georeferencing', 'odm_georeferenced_model.ply'),
                'csv': os.path.join('odm_georeferencing', 'odm_georeferenced_model.csv')
            }

            if asset in allowed_assets:
                asset_path = task.assets_path(allowed_assets[asset])

                if not os.path.exists(asset_path):
                    raise exceptions.NotFound(""Asset does not exist"")

                asset_filename = os.path.basename(asset_path)

                file = open(asset_path, ""rb"")
                response = HttpResponse(FileWrapper(file),
                                        content_type=(mimetypes.guess_type(asset_filename)[0] or ""application/zip""))
                response['Content-Disposition'] = ""attachment; filename={}"".format(asset_filename)
                return response
            else:
                raise exceptions.NotFound()/n/n/n/app/api/urls.py/n/nfrom django.conf.urls import url, include
from .projects import ProjectViewSet
from .tasks import TaskViewSet, TaskTiles, TaskTilesJson, TaskAssets
from .processingnodes import ProcessingNodeViewSet
from rest_framework_nested import routers

router = routers.DefaultRouter()
router.register(r'projects', ProjectViewSet)
router.register(r'processingnodes', ProcessingNodeViewSet)

tasks_router = routers.NestedSimpleRouter(router, r'projects', lookup='project')
tasks_router.register(r'tasks', TaskViewSet, base_name='projects-tasks')

urlpatterns = [
    url(r'^', include(router.urls)),
    url(r'^', include(tasks_router.urls)),

    url(r'projects/(?P<project_pk>[^/.]+)/tasks/(?P<pk>[^/.]+)/tiles/(?P<z>[\d]+)/(?P<x>[\d]+)/(?P<y>[\d]+)\.png$', TaskTiles.as_view()),
    url(r'projects/(?P<project_pk>[^/.]+)/tasks/(?P<pk>[^/.]+)/tiles\.json$', TaskTilesJson.as_view()),
    url(r'projects/(?P<project_pk>[^/.]+)/tasks/(?P<pk>[^/.]+)/download/(?P<asset>[^/.]+)/$', TaskAssets.as_view()),

    url(r'^auth/', include('rest_framework.urls')),
]/n/n/n",1
220,220,e6d319f68d4dcf355e89a7b21368c47c004a14c2,"scripts/spdxcheck.py/n/n#!/usr/bin/env python
# SPDX-License-Identifier: GPL-2.0
# Copyright Thomas Gleixner <tglx@linutronix.de>

from argparse import ArgumentParser
from ply import lex, yacc
import locale
import traceback
import sys
import git
import re
import os

class ParserException(Exception):
    def __init__(self, tok, txt):
        self.tok = tok
        self.txt = txt

class SPDXException(Exception):
    def __init__(self, el, txt):
        self.el = el
        self.txt = txt

class SPDXdata(object):
    def __init__(self):
        self.license_files = 0
        self.exception_files = 0
        self.licenses = [ ]
        self.exceptions = { }

# Read the spdx data from the LICENSES directory
def read_spdxdata(repo):

    # The subdirectories of LICENSES in the kernel source
    license_dirs = [ ""preferred"", ""deprecated"", ""exceptions"" ]
    lictree = repo.head.commit.tree['LICENSES']

    spdx = SPDXdata()

    for d in license_dirs:
        for el in lictree[d].traverse():
            if not os.path.isfile(el.path):
                continue

            exception = None
            for l in open(el.path).readlines():
                if l.startswith('Valid-License-Identifier:'):
                    lid = l.split(':')[1].strip().upper()
                    if lid in spdx.licenses:
                        raise SPDXException(el, 'Duplicate License Identifier: %s' %lid)
                    else:
                        spdx.licenses.append(lid)

                elif l.startswith('SPDX-Exception-Identifier:'):
                    exception = l.split(':')[1].strip().upper()
                    spdx.exceptions[exception] = []

                elif l.startswith('SPDX-Licenses:'):
                    for lic in l.split(':')[1].upper().strip().replace(' ', '').replace('\t', '').split(','):
                        if not lic in spdx.licenses:
                            raise SPDXException(None, 'Exception %s missing license %s' %(ex, lic))
                        spdx.exceptions[exception].append(lic)

                elif l.startswith(""License-Text:""):
                    if exception:
                        if not len(spdx.exceptions[exception]):
                            raise SPDXException(el, 'Exception %s is missing SPDX-Licenses' %excid)
                        spdx.exception_files += 1
                    else:
                        spdx.license_files += 1
                    break
    return spdx

class id_parser(object):

    reserved = [ 'AND', 'OR', 'WITH' ]
    tokens = [ 'LPAR', 'RPAR', 'ID', 'EXC' ] + reserved

    precedence = ( ('nonassoc', 'AND', 'OR'), )

    t_ignore = ' \t'

    def __init__(self, spdx):
        self.spdx = spdx
        self.lasttok = None
        self.lastid = None
        self.lexer = lex.lex(module = self, reflags = re.UNICODE)
        # Initialize the parser. No debug file and no parser rules stored on disk
        # The rules are small enough to be generated on the fly
        self.parser = yacc.yacc(module = self, write_tables = False, debug = False)
        self.lines_checked = 0
        self.checked = 0
        self.spdx_valid = 0
        self.spdx_errors = 0
        self.curline = 0
        self.deepest = 0

    # Validate License and Exception IDs
    def validate(self, tok):
        id = tok.value.upper()
        if tok.type == 'ID':
            if not id in self.spdx.licenses:
                raise ParserException(tok, 'Invalid License ID')
            self.lastid = id
        elif tok.type == 'EXC':
            if id not in self.spdx.exceptions:
                raise ParserException(tok, 'Invalid Exception ID')
            if self.lastid not in self.spdx.exceptions[id]:
                raise ParserException(tok, 'Exception not valid for license %s' %self.lastid)
            self.lastid = None
        elif tok.type != 'WITH':
            self.lastid = None

    # Lexer functions
    def t_RPAR(self, tok):
        r'\)'
        self.lasttok = tok.type
        return tok

    def t_LPAR(self, tok):
        r'\('
        self.lasttok = tok.type
        return tok

    def t_ID(self, tok):
        r'[A-Za-z.0-9\-+]+'

        if self.lasttok == 'EXC':
            print(tok)
            raise ParserException(tok, 'Missing parentheses')

        tok.value = tok.value.strip()
        val = tok.value.upper()

        if val in self.reserved:
            tok.type = val
        elif self.lasttok == 'WITH':
            tok.type = 'EXC'

        self.lasttok = tok.type
        self.validate(tok)
        return tok

    def t_error(self, tok):
        raise ParserException(tok, 'Invalid token')

    def p_expr(self, p):
        '''expr : ID
                | ID WITH EXC
                | expr AND expr
                | expr OR expr
                | LPAR expr RPAR'''
        pass

    def p_error(self, p):
        if not p:
            raise ParserException(None, 'Unfinished license expression')
        else:
            raise ParserException(p, 'Syntax error')

    def parse(self, expr):
        self.lasttok = None
        self.lastid = None
        self.parser.parse(expr, lexer = self.lexer)

    def parse_lines(self, fd, maxlines, fname):
        self.checked += 1
        self.curline = 0
        try:
            for line in fd:
                line = line.decode(locale.getpreferredencoding(False), errors='ignore')
                self.curline += 1
                if self.curline > maxlines:
                    break
                self.lines_checked += 1
                if line.find(""SPDX-License-Identifier:"") < 0:
                    continue
                expr = line.split(':')[1].strip()
                # Remove trailing comment closure
                if line.strip().endswith('*/'):
                    expr = expr.rstrip('*/').strip()
                # Special case for SH magic boot code files
                if line.startswith('LIST \""'):
                    expr = expr.rstrip('\""').strip()
                self.parse(expr)
                self.spdx_valid += 1
                #
                # Should we check for more SPDX ids in the same file and
                # complain if there are any?
                #
                break

        except ParserException as pe:
            if pe.tok:
                col = line.find(expr) + pe.tok.lexpos
                tok = pe.tok.value
                sys.stdout.write('%s: %d:%d %s: %s\n' %(fname, self.curline, col, pe.txt, tok))
            else:
                sys.stdout.write('%s: %d:0 %s\n' %(fname, self.curline, col, pe.txt))
            self.spdx_errors += 1

def scan_git_tree(tree):
    for el in tree.traverse():
        # Exclude stuff which would make pointless noise
        # FIXME: Put this somewhere more sensible
        if el.path.startswith(""LICENSES""):
            continue
        if el.path.find(""license-rules.rst"") >= 0:
            continue
        if not os.path.isfile(el.path):
            continue
        with open(el.path, 'rb') as fd:
            parser.parse_lines(fd, args.maxlines, el.path)

def scan_git_subtree(tree, path):
    for p in path.strip('/').split('/'):
        tree = tree[p]
    scan_git_tree(tree)

if __name__ == '__main__':

    ap = ArgumentParser(description='SPDX expression checker')
    ap.add_argument('path', nargs='*', help='Check path or file. If not given full git tree scan. For stdin use ""-""')
    ap.add_argument('-m', '--maxlines', type=int, default=15,
                    help='Maximum number of lines to scan in a file. Default 15')
    ap.add_argument('-v', '--verbose', action='store_true', help='Verbose statistics output')
    args = ap.parse_args()

    # Sanity check path arguments
    if '-' in args.path and len(args.path) > 1:
        sys.stderr.write('stdin input ""-"" must be the only path argument\n')
        sys.exit(1)

    try:
        # Use git to get the valid license expressions
        repo = git.Repo(os.getcwd())
        assert not repo.bare

        # Initialize SPDX data
        spdx = read_spdxdata(repo)

        # Initilize the parser
        parser = id_parser(spdx)

    except SPDXException as se:
        if se.el:
            sys.stderr.write('%s: %s\n' %(se.el.path, se.txt))
        else:
            sys.stderr.write('%s\n' %se.txt)
        sys.exit(1)

    except Exception as ex:
        sys.stderr.write('FAIL: %s\n' %ex)
        sys.stderr.write('%s\n' %traceback.format_exc())
        sys.exit(1)

    try:
        if len(args.path) and args.path[0] == '-':
            stdin = os.fdopen(sys.stdin.fileno(), 'rb')
            parser.parse_lines(stdin, args.maxlines, '-')
        else:
            if args.path:
                for p in args.path:
                    if os.path.isfile(p):
                        parser.parse_lines(open(p, 'rb'), args.maxlines, p)
                    elif os.path.isdir(p):
                        scan_git_subtree(repo.head.reference.commit.tree, p)
                    else:
                        sys.stderr.write('path %s does not exist\n' %p)
                        sys.exit(1)
            else:
                # Full git tree scan
                scan_git_tree(repo.head.commit.tree)

            if args.verbose:
                sys.stderr.write('\n')
                sys.stderr.write('License files:     %12d\n' %spdx.license_files)
                sys.stderr.write('Exception files:   %12d\n' %spdx.exception_files)
                sys.stderr.write('License IDs        %12d\n' %len(spdx.licenses))
                sys.stderr.write('Exception IDs      %12d\n' %len(spdx.exceptions))
                sys.stderr.write('\n')
                sys.stderr.write('Files checked:     %12d\n' %parser.checked)
                sys.stderr.write('Lines checked:     %12d\n' %parser.lines_checked)
                sys.stderr.write('Files with SPDX:   %12d\n' %parser.spdx_valid)
                sys.stderr.write('Files with errors: %12d\n' %parser.spdx_errors)

            sys.exit(0)

    except Exception as ex:
        sys.stderr.write('FAIL: %s\n' %ex)
        sys.stderr.write('%s\n' %traceback.format_exc())
        sys.exit(1)
/n/n/n",0
221,221,e6d319f68d4dcf355e89a7b21368c47c004a14c2,"/scripts/spdxcheck.py/n/n#!/usr/bin/env python
# SPDX-License-Identifier: GPL-2.0
# Copyright Thomas Gleixner <tglx@linutronix.de>

from argparse import ArgumentParser
from ply import lex, yacc
import locale
import traceback
import sys
import git
import re
import os

class ParserException(Exception):
    def __init__(self, tok, txt):
        self.tok = tok
        self.txt = txt

class SPDXException(Exception):
    def __init__(self, el, txt):
        self.el = el
        self.txt = txt

class SPDXdata(object):
    def __init__(self):
        self.license_files = 0
        self.exception_files = 0
        self.licenses = [ ]
        self.exceptions = { }

# Read the spdx data from the LICENSES directory
def read_spdxdata(repo):

    # The subdirectories of LICENSES in the kernel source
    license_dirs = [ ""preferred"", ""other"", ""exceptions"" ]
    lictree = repo.head.commit.tree['LICENSES']

    spdx = SPDXdata()

    for d in license_dirs:
        for el in lictree[d].traverse():
            if not os.path.isfile(el.path):
                continue

            exception = None
            for l in open(el.path).readlines():
                if l.startswith('Valid-License-Identifier:'):
                    lid = l.split(':')[1].strip().upper()
                    if lid in spdx.licenses:
                        raise SPDXException(el, 'Duplicate License Identifier: %s' %lid)
                    else:
                        spdx.licenses.append(lid)

                elif l.startswith('SPDX-Exception-Identifier:'):
                    exception = l.split(':')[1].strip().upper()
                    spdx.exceptions[exception] = []

                elif l.startswith('SPDX-Licenses:'):
                    for lic in l.split(':')[1].upper().strip().replace(' ', '').replace('\t', '').split(','):
                        if not lic in spdx.licenses:
                            raise SPDXException(None, 'Exception %s missing license %s' %(ex, lic))
                        spdx.exceptions[exception].append(lic)

                elif l.startswith(""License-Text:""):
                    if exception:
                        if not len(spdx.exceptions[exception]):
                            raise SPDXException(el, 'Exception %s is missing SPDX-Licenses' %excid)
                        spdx.exception_files += 1
                    else:
                        spdx.license_files += 1
                    break
    return spdx

class id_parser(object):

    reserved = [ 'AND', 'OR', 'WITH' ]
    tokens = [ 'LPAR', 'RPAR', 'ID', 'EXC' ] + reserved

    precedence = ( ('nonassoc', 'AND', 'OR'), )

    t_ignore = ' \t'

    def __init__(self, spdx):
        self.spdx = spdx
        self.lasttok = None
        self.lastid = None
        self.lexer = lex.lex(module = self, reflags = re.UNICODE)
        # Initialize the parser. No debug file and no parser rules stored on disk
        # The rules are small enough to be generated on the fly
        self.parser = yacc.yacc(module = self, write_tables = False, debug = False)
        self.lines_checked = 0
        self.checked = 0
        self.spdx_valid = 0
        self.spdx_errors = 0
        self.curline = 0
        self.deepest = 0

    # Validate License and Exception IDs
    def validate(self, tok):
        id = tok.value.upper()
        if tok.type == 'ID':
            if not id in self.spdx.licenses:
                raise ParserException(tok, 'Invalid License ID')
            self.lastid = id
        elif tok.type == 'EXC':
            if id not in self.spdx.exceptions:
                raise ParserException(tok, 'Invalid Exception ID')
            if self.lastid not in self.spdx.exceptions[id]:
                raise ParserException(tok, 'Exception not valid for license %s' %self.lastid)
            self.lastid = None
        elif tok.type != 'WITH':
            self.lastid = None

    # Lexer functions
    def t_RPAR(self, tok):
        r'\)'
        self.lasttok = tok.type
        return tok

    def t_LPAR(self, tok):
        r'\('
        self.lasttok = tok.type
        return tok

    def t_ID(self, tok):
        r'[A-Za-z.0-9\-+]+'

        if self.lasttok == 'EXC':
            print(tok)
            raise ParserException(tok, 'Missing parentheses')

        tok.value = tok.value.strip()
        val = tok.value.upper()

        if val in self.reserved:
            tok.type = val
        elif self.lasttok == 'WITH':
            tok.type = 'EXC'

        self.lasttok = tok.type
        self.validate(tok)
        return tok

    def t_error(self, tok):
        raise ParserException(tok, 'Invalid token')

    def p_expr(self, p):
        '''expr : ID
                | ID WITH EXC
                | expr AND expr
                | expr OR expr
                | LPAR expr RPAR'''
        pass

    def p_error(self, p):
        if not p:
            raise ParserException(None, 'Unfinished license expression')
        else:
            raise ParserException(p, 'Syntax error')

    def parse(self, expr):
        self.lasttok = None
        self.lastid = None
        self.parser.parse(expr, lexer = self.lexer)

    def parse_lines(self, fd, maxlines, fname):
        self.checked += 1
        self.curline = 0
        try:
            for line in fd:
                line = line.decode(locale.getpreferredencoding(False), errors='ignore')
                self.curline += 1
                if self.curline > maxlines:
                    break
                self.lines_checked += 1
                if line.find(""SPDX-License-Identifier:"") < 0:
                    continue
                expr = line.split(':')[1].strip()
                # Remove trailing comment closure
                if line.strip().endswith('*/'):
                    expr = expr.rstrip('*/').strip()
                # Special case for SH magic boot code files
                if line.startswith('LIST \""'):
                    expr = expr.rstrip('\""').strip()
                self.parse(expr)
                self.spdx_valid += 1
                #
                # Should we check for more SPDX ids in the same file and
                # complain if there are any?
                #
                break

        except ParserException as pe:
            if pe.tok:
                col = line.find(expr) + pe.tok.lexpos
                tok = pe.tok.value
                sys.stdout.write('%s: %d:%d %s: %s\n' %(fname, self.curline, col, pe.txt, tok))
            else:
                sys.stdout.write('%s: %d:0 %s\n' %(fname, self.curline, col, pe.txt))
            self.spdx_errors += 1

def scan_git_tree(tree):
    for el in tree.traverse():
        # Exclude stuff which would make pointless noise
        # FIXME: Put this somewhere more sensible
        if el.path.startswith(""LICENSES""):
            continue
        if el.path.find(""license-rules.rst"") >= 0:
            continue
        if not os.path.isfile(el.path):
            continue
        with open(el.path, 'rb') as fd:
            parser.parse_lines(fd, args.maxlines, el.path)

def scan_git_subtree(tree, path):
    for p in path.strip('/').split('/'):
        tree = tree[p]
    scan_git_tree(tree)

if __name__ == '__main__':

    ap = ArgumentParser(description='SPDX expression checker')
    ap.add_argument('path', nargs='*', help='Check path or file. If not given full git tree scan. For stdin use ""-""')
    ap.add_argument('-m', '--maxlines', type=int, default=15,
                    help='Maximum number of lines to scan in a file. Default 15')
    ap.add_argument('-v', '--verbose', action='store_true', help='Verbose statistics output')
    args = ap.parse_args()

    # Sanity check path arguments
    if '-' in args.path and len(args.path) > 1:
        sys.stderr.write('stdin input ""-"" must be the only path argument\n')
        sys.exit(1)

    try:
        # Use git to get the valid license expressions
        repo = git.Repo(os.getcwd())
        assert not repo.bare

        # Initialize SPDX data
        spdx = read_spdxdata(repo)

        # Initilize the parser
        parser = id_parser(spdx)

    except SPDXException as se:
        if se.el:
            sys.stderr.write('%s: %s\n' %(se.el.path, se.txt))
        else:
            sys.stderr.write('%s\n' %se.txt)
        sys.exit(1)

    except Exception as ex:
        sys.stderr.write('FAIL: %s\n' %ex)
        sys.stderr.write('%s\n' %traceback.format_exc())
        sys.exit(1)

    try:
        if len(args.path) and args.path[0] == '-':
            stdin = os.fdopen(sys.stdin.fileno(), 'rb')
            parser.parse_lines(stdin, args.maxlines, '-')
        else:
            if args.path:
                for p in args.path:
                    if os.path.isfile(p):
                        parser.parse_lines(open(p, 'rb'), args.maxlines, p)
                    elif os.path.isdir(p):
                        scan_git_subtree(repo.head.reference.commit.tree, p)
                    else:
                        sys.stderr.write('path %s does not exist\n' %p)
                        sys.exit(1)
            else:
                # Full git tree scan
                scan_git_tree(repo.head.commit.tree)

            if args.verbose:
                sys.stderr.write('\n')
                sys.stderr.write('License files:     %12d\n' %spdx.license_files)
                sys.stderr.write('Exception files:   %12d\n' %spdx.exception_files)
                sys.stderr.write('License IDs        %12d\n' %len(spdx.licenses))
                sys.stderr.write('Exception IDs      %12d\n' %len(spdx.exceptions))
                sys.stderr.write('\n')
                sys.stderr.write('Files checked:     %12d\n' %parser.checked)
                sys.stderr.write('Lines checked:     %12d\n' %parser.lines_checked)
                sys.stderr.write('Files with SPDX:   %12d\n' %parser.spdx_valid)
                sys.stderr.write('Files with errors: %12d\n' %parser.spdx_errors)

            sys.exit(0)

    except Exception as ex:
        sys.stderr.write('FAIL: %s\n' %ex)
        sys.stderr.write('%s\n' %traceback.format_exc())
        sys.exit(1)
/n/n/n",1
166,166,fb7d11509cd93463ac3ce9178b97910a8be1b05d,"opennode/oms/endpoint/httprest/base.py/n/nfrom grokcore.component import Adapter, implements, baseclass
from grokcore.security import require
from zope.interface import Interface


class IHttpRestView(Interface):
    def render(request):
        pass

    def render_recursive(request, depth):
        pass

    def rw_transaction(request):
        """"""Return true if we this request should be committed""""""


class IHttpRestSubViewFactory(Interface):
    def resolve(path, method):
        """"""Resolve a view for a given sub path""""""


class HttpRestView(Adapter):
    implements(IHttpRestView)
    baseclass()
    require('rest')

    __builtin_attributes__ = ['id', 'children']

    def filter_attributes(self, request, data):
        """"""Handle the filtering of attributes according to the 'attrs' parameter in the request""""""
        attrs = request.args.get('attrs', [''])[0]
        if attrs:
            filtered_data = {}
            for a in attrs.decode('utf-8').split(',') + self.__builtin_attributes__:
                if a in data:
                    filtered_data[a] = data[a]
            return filtered_data
        return data

    def render_recursive(self, request, depth):
        for method in ('render_' + request.method, 'render'):
            if hasattr(self, method):
                return self.filter_attributes(request, getattr(self, method)(request))
        raise NotImplemented(""method %s not implemented\n"" % request.method)

    def render_OPTIONS(self, request):
        all_methods = ['GET', 'POST', 'PUT', 'DELETE', 'HEAD']
        has_methods = [m for m in all_methods if hasattr(self, 'render_%s' % m)] + ['OPTIONS']
        request.setHeader('Allow', ', '.join(has_methods))

        from opennode.oms.endpoint.httprest.root import EmptyResponse
        return EmptyResponse

    def rw_transaction(self, request):
        return request.method != 'GET'
/n/n/nopennode/oms/endpoint/httprest/root.py/n/nimport json
import functools
import zope.security.interfaces

from twisted.internet import defer
from twisted.python import log, failure
from twisted.web import resource
from twisted.web.server import NOT_DONE_YET
from zope.component import queryAdapter, getUtility

from opennode.oms.config import get_config
from opennode.oms.endpoint.httprest.base import IHttpRestView, IHttpRestSubViewFactory
from opennode.oms.model.traversal import traverse_path
from opennode.oms.security.checker import proxy_factory
from opennode.oms.security.interaction import new_interaction
from opennode.oms.util import blocking_yield
from opennode.oms.zodb import db


class EmptyResponse(Exception):
    pass


class HttpStatus(Exception):
    def __init__(self, body=None, *args, **kwargs):
        super(HttpStatus, self).__init__(*args, **kwargs)
        self.body = body

    @property
    def status_code(self):
        raise NotImplementedError

    @property
    def status_description(self):
        raise NotImplementedError

    headers = {}


class NotFound(HttpStatus):
    status_code = 404
    status_description = ""Not Found""


class NotImplemented(HttpStatus):
    status_code = 501
    status_description = ""Not Implemented""


class AbstractRedirect(HttpStatus):
    def __init__(self, url, *args, **kwargs):
        super(AbstractRedirect, self).__init__(*args, **kwargs)
        self.url = url

    @property
    def headers(self):
        return {'Location': self.url}


class SeeCanonical(AbstractRedirect):
    status_code = 301
    status_description = ""Moved Permanently""


class SeeOther(AbstractRedirect):
    status_code = 303
    status_description = ""Moved Temporarily""


class Unauthorized(HttpStatus):
    status_code = 401
    status_description = ""Authorization Required""

    headers = {'WWW-Authenticate': 'Basic realm=OMS',
               'Set-Cookie': 'oms_auth_token=;expires=Wed, 01 Jan 2000 00:00:00 GMT'}


class Forbidden(HttpStatus):
    status_code = 403
    status_description = ""Forbidden""


class BadRequest(HttpStatus):
    status_code = 400
    status_description = ""Bad Request""


class MethodNotAllowed(HttpStatus):
    status_code = 405
    status_description = ""Method not allowed""

    def __init__(self, msg, allow):
        HttpStatus.__init__(self, msg)
        self.headers = {'Allow': ','.join(allow)}


def log_wrapper(self, f, server):
    @functools.wraps(f)
    def log_(request):
        """"""
        Log a request's result to the logfile, by default in combined log format.
        """"""
        if hasattr(request, 'interaction'):
            principals = map(lambda pp: pp.principal.id, request.interaction.participations)
        else:
            principals = []
        if hasattr(self, ""logFile""):
            line = '%s %s - %s ""%s"" %d %s ""%s"" ""%s""\n' % (
                request.getClientIP(),
                principals,
                self._logDateTime,
                '%s %s %s' % (self._escape(request.method),
                              self._escape(request.uri),
                              self._escape(request.clientproto)),
                request.code,
                request.sentLength or ""-"",
                self._escape(request.getHeader(""referer"") or ""-""),
                self._escape(request.getHeader(""user-agent"") or ""-""))
            self.logFile.write(line)
    return log_


class HttpRestServer(resource.Resource):
    """"""Restful HTTP API interface for OMS.

    Exposes a JSON web service to communicate with OMS.

    """"""

    def getChild(self, name, request):
        """"""We are the handler for anything below this base url, except what explicitly added in oms.tac.""""""
        return self

    def __init__(self, avatar=None):
        ## Twisted Resource is a not a new style class, so emulating a super-call
        resource.Resource.__init__(self)
        self.avatar = avatar

        self.use_security_proxy = get_config().getboolean('auth', 'security_proxy_rest')

    def render(self, request):
        request.site.log = log_wrapper(request.site, request.site.log, self)
        deferred = self._render(request)

        @deferred
        def on_error(error):
            log.msg(""Error while rendering http %s"", system='httprest')
            log.err(error, system='httprest')

        return NOT_DONE_YET

    @defer.inlineCallbacks
    def _render(self, request):
        request.setHeader('Content-type', 'application/json')
        origin = request.getHeader('Origin')
        if origin:
            request.setHeader('Access-Control-Allow-Origin', origin)
            request.setHeader('Access-Control-Allow-Credentials', 'true')
        else:
            request.setHeader('Access-Control-Allow-Origin', '*')
        request.setHeader('Access-Control-Allow-Methods', 'GET, PUT, POST, DELETE, OPTIONS, HEAD')
        request.setHeader('Access-Control-Allow-Headers',
                          'Origin, Content-Type, Cache-Control, X-Requested-With')

        ret = None
        try:
            ret = yield self.handle_request(request)
            if ret is EmptyResponse:
                raise ret
        except EmptyResponse:
            pass
        except HttpStatus as exc:
            request.setResponseCode(exc.status_code, exc.status_description)
            for name, value in exc.headers.items():
                request.responseHeaders.addRawHeader(name, value)
            if exc.body:
                request.write(json.dumps(exc.body))
            else:
                request.write(""%s %s\n"" % (exc.status_code, exc.status_description))
            if exc.message:
                request.write(""%s\n"" % exc.message)
        except Exception:
            request.setResponseCode(500, ""Server Error"")
            request.write(""%s %s\n\n"" % (500, ""Server Error""))
            log.err(system='httprest')
            failure.Failure().printTraceback(request)
        else:
            # allow views to take full control of output streaming
            if ret != NOT_DONE_YET:
                def render(obj):
                    if isinstance(obj, set):
                        return list(obj)  # safeguard against dumping sets
                    if hasattr(obj, '__str__'):
                        return str(obj)
                    log.msg(""RENDERING ERROR, cannot json serialize %s"" % obj, system='httprest')
                    raise TypeError

                request.write(json.dumps(ret, indent=2, default=render) + '\n')
        finally:
            if ret != NOT_DONE_YET:
                request.finish()

    def check_auth(self, request):
        from opennode.oms.endpoint.httprest.auth import IHttpRestAuthenticationUtility

        authentication_utility = getUtility(IHttpRestAuthenticationUtility)
        credentials = authentication_utility.get_basic_auth_credentials(request)
        if credentials:
            blocking_yield(authentication_utility.authenticate(request, credentials, basic_auth=True))
            return authentication_utility.generate_token(credentials)
        else:
            return authentication_utility.get_token(request)

    def find_view(self, obj, unresolved_path, method):
        view = queryAdapter(obj, IHttpRestView)

        if len(unresolved_path) == 0:
            return view

        subview_factory = queryAdapter(obj, IHttpRestSubViewFactory)

        subview = subview_factory.resolve(unresolved_path, method) if subview_factory else None

        if not subview:
            raise NotFound

        return subview

    @db.transact
    def handle_request(self, request):
        """"""Takes a request, maps it to a domain object and a
        corresponding IHttpRestView, and returns the rendered output
        of that view.

        """"""
        token = self.check_auth(request)

        oms_root = db.get_root()['oms_root']
        objs, unresolved_path = traverse_path(oms_root, request.path[1:])

        if not objs and unresolved_path:
            objs = [oms_root]

        obj = objs[-1]

        interaction = self.get_interaction(request, token)
        request.interaction = interaction

        if self.use_security_proxy:
            obj = proxy_factory(obj, interaction)

        view = self.find_view(obj, unresolved_path, request.method)

        needs_rw_transaction = view.rw_transaction(request)

        # create a security proxy if we have a secured interaction
        if interaction:
            try:
                view = proxy_factory(view, interaction)
            except:
                # XXX: TODO: define a real exception for this proxy creation error
                # right now we want to ignore security when there are no declared rules
                # on how to secure a view
                pass

        def get_renderer(view, method):
            try:
                return getattr(view, method, None)
            except zope.security.interfaces.Unauthorized:
                from opennode.oms.endpoint.httprest.auth import IHttpRestAuthenticationUtility
                auth_util = getUtility(IHttpRestAuthenticationUtility)
                if token or not auth_util.get_basic_auth_credentials(request):
                    raise Forbidden('User does not have permission to access this resource')
                raise Unauthorized()

        for method in ('render_' + request.method, 'render'):
            # hasattr will return false on unauthorized fields
            renderer = get_renderer(view, method)
            if renderer:
                res = renderer(request)

                if needs_rw_transaction:
                    return res
                else:
                    return db.RollbackValue(res)

        raise NotImplementedError(""method %s not implemented\n"" % request.method)

    def get_interaction(self, request, token):
        # TODO: we can quickly disable rest auth
        # if get_config().getboolean('auth', 'enable_anonymous'):
        #     return None

        from opennode.oms.endpoint.httprest.auth import IHttpRestAuthenticationUtility

        authentication_utility = getUtility(IHttpRestAuthenticationUtility)
        try:
            principal = authentication_utility.get_principal(token)
        except:
            # Avoid that changes in format of security token will require every user
            # to flush the cookies
            principal = 'oms.anonymous'

        if principal != 'oms.anonymous':
            authentication_utility.renew_token(request, token)

        if request.method == 'OPTIONS':
            principal = 'oms.rest_options'

        return new_interaction(principal)
/n/n/nopennode/oms/endpoint/httprest/view.py/n/nimport json
import os
import time
import Queue

from grokcore.component import context
from hashlib import sha1
from twisted.web.server import NOT_DONE_YET
from twisted.python import log
from twisted.internet import reactor, threads, defer
from zope.component import queryAdapter, handle
from zope.security.interfaces import Unauthorized
from zope.security.proxy import removeSecurityProxy

from opennode.oms.endpoint.httprest.base import HttpRestView, IHttpRestView
from opennode.oms.endpoint.httprest.root import BadRequest, NotFound
from opennode.oms.endpoint.ssh.cmd.security import effective_perms
from opennode.oms.endpoint.ssh.detached import DetachedProtocol
from opennode.oms.endpoint.ssh.cmdline import ArgumentParsingError
from opennode.oms.model.form import RawDataApplier
from opennode.oms.model.location import ILocation
from opennode.oms.model.model.base import IContainer
from opennode.oms.model.model.bin import ICommand
from opennode.oms.model.model.byname import ByNameContainer
from opennode.oms.model.model.events import ModelDeletedEvent
from opennode.oms.model.model.filtrable import IFiltrable
from opennode.oms.model.model.search import SearchContainer, SearchResult
from opennode.oms.model.model.stream import IStream, StreamSubscriber
from opennode.oms.model.model.symlink import Symlink, follow_symlinks
from opennode.oms.model.schema import model_to_dict
from opennode.oms.model.traversal import traverse_path
from opennode.oms.security.checker import get_interaction
from opennode.oms.zodb import db


class DefaultView(HttpRestView):
    context(object)

    def render_GET(self, request):
        if not request.interaction.checkPermission('view', self.context):
            raise NotFound

        data = model_to_dict(self.context)

        data['id'] = self.context.__name__
        data['__type__'] = type(removeSecurityProxy(self.context)).__name__
        try:
            data['url'] = ILocation(self.context).get_url()
        except Unauthorized:
            data['url'] = ''

        interaction = get_interaction(self.context)
        data['permissions'] = effective_perms(interaction, self.context) if interaction else []

        # XXX: simplejson can't serialize sets
        if 'tags' in data:
            data['tags'] = list(data['tags'])

        return data

    def render_PUT(self, request):
        data = json.load(request.content)
        if 'id' in data:
            del data['id']

        data = self.put_filter_attributes(request, data)

        form = RawDataApplier(data, self.context)
        if not form.errors:
            form.apply()
            return [IHttpRestView(self.context).render_recursive(request, depth=0)]
        else:
            request.setResponseCode(BadRequest.status_code)
            return form.error_dict()

    def put_filter_attributes(self, request, data):
        """"""Offer the possibility for subclasses to massage the received json before default behavior.""""""
        return data

    def render_DELETE(self, request):
        force = request.args.get('force', ['false'])[0] == 'true'

        parent = self.context.__parent__
        del parent[self.context.__name__]

        try:
            handle(self.context, ModelDeletedEvent(parent))
        except Exception as e:
            if not force:
                raise e
            return {'status': 'failure'}

        return {'status': 'success'}


class ContainerView(DefaultView):
    context(IContainer)

    def render_GET(self, request):
        depth = request.args.get('depth', ['0'])[0]
        try:
            depth = int(depth)
        except ValueError:
            depth = 0

        return self.render_recursive(request, depth, top_level=True)

    def render_recursive(self, request, depth, filter_=[], top_level=False):
        container_properties = super(ContainerView, self).render_GET(request)

        if depth < 1:
            return self.filter_attributes(request, container_properties)

        exclude = [excluded.strip() for excluded in request.args.get('exclude', [''])[0].split(',')]

        def preconditions(obj):
            yield request.interaction.checkPermission('view', obj)
            yield obj.__name__ not in exclude
            yield obj.target.__parent__ == obj.__parent__ if type(obj) is Symlink else True

        items = map(follow_symlinks, filter(lambda obj: all(preconditions(obj)), self.context.listcontent()))

        def secure_render_recursive(item):
            try:
                return IHttpRestView(item).render_recursive(request, depth - 1)
            except Unauthorized:
                permissions = effective_perms(get_interaction(item), item)
                if 'view' in permissions:
                    return dict(access='denied', permissions=permissions,
                                __type__=type(removeSecurityProxy(item)).__name__)

        qlist = []
        limit = None
        offset = 0

        if top_level:
            qlist = request.args.get('q', [])
            qlist = map(lambda q: q.decode('utf-8'), qlist)
            limit = int(request.args.get('limit', [0])[0])
            offset = int(request.args.get('offset', [1])[0]) - 1
            if offset <= 0:
                offset = 0

        def secure_filter_match(item, q):
            try:
                return IFiltrable(item).match(q)
            except Unauthorized:
                return

        for q in qlist:
            items = filter(lambda item: secure_filter_match(item, q), items)

        children = filter(None, [secure_render_recursive(item) for item in items
                                 if queryAdapter(item, IHttpRestView) and not self.blacklisted(item)])

        total_children = len(children)

        if (limit is not None and limit != 0) or offset:
            children = children[offset : offset + limit]

        # backward compatibility:
        # top level results for pure containers are plain lists
        if top_level and (not container_properties or len(container_properties.keys()) == 1):
            return children

        if not top_level or depth > 0:
            container_properties['children'] = children
            container_properties['totalChildren'] = total_children

        return self.filter_attributes(request, container_properties)

    def blacklisted(self, item):
        return isinstance(item, ByNameContainer)


class SearchView(ContainerView):
    context(SearchContainer)

    def render_GET(self, request):
        q = request.args.get('q', [''])[0]

        if not q:
            return super(SearchView, self).render_GET(request)

        search = db.get_root()['oms_root']['search']
        res = SearchResult(search, q.decode('utf-8'))

        return IHttpRestView(res).render_GET(request)


class StreamView(HttpRestView):
    context(StreamSubscriber)

    cached_subscriptions = dict()

    def rw_transaction(self, request):
        return False

    def render(self, request):
        timestamp = int(time.time() * 1000)
        oms_root = db.get_root()['oms_root']

        limit = int(request.args.get('limit', ['100'])[0])
        after = int(request.args.get('after', ['0'])[0])

        subscription_hash = request.args.get('subscription_hash', [''])[0]
        if subscription_hash:
            if subscription_hash in self.cached_subscriptions:
                data = self.cached_subscriptions[subscription_hash]
            else:
                raise BadRequest(""Unknown subscription hash"")
        elif not request.content.getvalue():
            return {}
        else:
            data = json.load(request.content)
            subscription_hash = sha1(request.content.getvalue()).hexdigest()
            self.cached_subscriptions[subscription_hash] = data
            request.responseHeaders.addRawHeader('X-OMS-Subscription-Hash', subscription_hash)

        def val(r):
            objs, unresolved_path = traverse_path(oms_root, r)
            if unresolved_path:
                return [(timestamp, dict(event='delete', name=os.path.basename(r), url=r))]
            return IStream(objs[-1]).events(after, limit=limit)

        # ONC wants it in ascending time order
        # while internally we prefer to keep it newest first to
        # speed up filtering.
        # Reversed is not json serializable so we have to reify to list.
        res = [list(reversed(val(resource))) for resource in data]
        res = [(i, v) for i, v in enumerate(res) if v]
        return [timestamp, dict(res)]


class CommandView(DefaultView):
    context(ICommand)

    def write_results(self, request, pid, cmd):
        log.msg('Called %s got result: pid(%s) term writes=%s' % (
                cmd, pid, len(cmd.write_buffer)), system='command-view')
        request.write(json.dumps({'status': 'ok', 'pid': pid,
                                  'stdout': cmd.write_buffer}))
        request.finish()

    def render_PUT(self, request):
        """""" Converts arguments into command-line counterparts and executes the omsh command.

        Parameters passed as 'arg' are converted into positional arguments, others are converted into
        named parameters:

            PUT /bin/ls?arg=/some/path&arg=/another/path&-l&--recursive

        thus translates to:

            /bin/ls /some/path /another/path -l --recursive

        Allows blocking (synchronous) and non-blocking operation using the 'asynchronous' parameter (any
        value will trigger it). Synchronous operation requires two threads to function.
        """"""

        def named_args_filter_and_flatten(nargs):
            for name, vallist in nargs:
                if name not in ('arg', 'asynchronous'):
                    for val in vallist:
                        yield name
                        yield val

        def convert_args(args):
            tokenized_args = args.get('arg', [])
            return tokenized_args + list(named_args_filter_and_flatten(args.items()))

        protocol = DetachedProtocol()
        protocol.interaction = get_interaction(self.context) or request.interaction

        args = convert_args(request.args)
        args = filter(None, args)
        cmd = self.context.cmd(protocol)
        # Setting write_buffer to a list makes command save the output to the buffer too
        cmd.write_buffer = []
        d0 = defer.Deferred()

        try:
            pid = threads.blockingCallFromThread(reactor, cmd.register, d0, args,
                                                 '%s %s' % (request.path, args))
        except ArgumentParsingError, e:
            raise BadRequest(str(e))

        q = Queue.Queue()

        def execute(cmd, args):
            d = defer.maybeDeferred(cmd, *args)
            d.addBoth(q.put)
            d.chainDeferred(d0)

        dt = threads.deferToThread(execute, cmd, args)

        if request.args.get('asynchronous', []):
            reactor.callFromThread(self.write_results, request, pid, cmd)
        else:
            dt.addBoth(lambda r: threads.deferToThread(q.get, True, 60))
            dt.addCallback(lambda r: reactor.callFromThread(self.write_results, request, pid, cmd))

            def errhandler(e, pid, cmd):
                e.trap(ArgumentParsingError)
                raise BadRequest(str(e))
            dt.addErrback(errhandler, pid, cmd)
        return NOT_DONE_YET
/n/n/nopennode/oms/model/traversal.py/n/nimport logging
import re

from grokcore.component import Adapter, implements, baseclass
from zope.interface import Interface

from opennode.oms.model.model.symlink import follow_symlinks


__all__ = ['traverse_path', 'traverse1']


log = logging.getLogger(__name__)


class ITraverser(Interface):
    """"""Adapters providing object traversal should implement this interface.""""""

    def traverse(name):
        """"""Takes the name of the object to traverse to and returns the traversed object, if any.""""""


class Traverser(Adapter):
    """"""Base class for all object traversers.""""""
    implements(ITraverser)
    baseclass()


def parse_path(path):
    if not path or path == '/':
        return []

    path = re.sub(r'\/+', '/', path)

    if path.endswith('/'):
        path = path[:-1]

    if path.startswith('/'):
        path = path[1:]

    path = path.split('/')
    return path


def traverse_path(obj, path):
    """"""Starting from the given object, traverses all its descendant
    objects to find an object that matches the given path.

    Returns a tuple that contains the object up to which the traversal
    was successful plus all objects that led to that object, and the
    part of the path that could not be resolved.

    """"""
    path = parse_path(path)

    if not path:
        return [obj], []

    ret = [obj]
    while path:
        name = path[0]
        try:
            traverser = ITraverser(ret[-1])
        except TypeError:
            break

        next_obj = follow_symlinks(traverser.traverse(name))

        if not next_obj:
            break

        ret.append(next_obj)
        path = path[1:]

    return ret[1:], path


def traverse1(path):
    """"""Provides a shortcut for absolute path traversals without
    needing to pass in the root object.

    """"""

    # Do it here just in case; to avoid circular imports:
    from opennode.oms.zodb import db

    oms_root = db.get_root()['oms_root']
    objs, untraversed_path = traverse_path(oms_root, path)
    if objs and not untraversed_path:
        return objs[-1]
    else:
        return None


def canonical_path(item):
    path = []
    from opennode.oms.security.authentication import Sudo
    while item:
        with Sudo(item):
            assert item.__name__ is not None, '%s.__name__ is None' % item
            item = follow_symlinks(item)
            path.insert(0, item.__name__)
            item = item.__parent__
    return '/'.join(path)
/n/n/nopennode/oms/util.py/n/nimport functools
import inspect
import json
import time
import threading

from Queue import Queue, Empty

import zope.interface
from zope.component import getSiteManager, implementedBy
from zope.interface import classImplements
from twisted.internet import defer, reactor
from twisted.python import log
from twisted.python.failure import Failure

from opennode.oms.config import get_config


def get_direct_interfaces(obj):
    """"""Returns the interfaces that the parent class of `obj`
    implements, exluding any that any of its ancestor classes
    implement.

    >>> from zope.interface import Interface, implements, implementedBy
    >>> class IA(Interface): pass
    >>> class IB(Interface): pass
    >>> class A: implements(IA)
    >>> class B(A): implements(IB)
    >>> b = B()
    >>> [i.__name__ for i in list(implementedBy(B).interfaces())]
    ['IB', 'IA']
    >>> [i.__name__ for i in get_direct_interfaces(b)]
    ['IB']

    """"""
    cls = obj if isinstance(obj, type) else type(obj)

    if not isinstance(obj, type) and hasattr(obj, 'implemented_interfaces'):
        interfaces = obj.implemented_interfaces()
    else:
        interfaces = list(zope.interface.implementedBy(cls).interfaces())

    for base_cls in cls.__bases__:
        for interface in list(zope.interface.implementedBy(base_cls).interfaces()):
            # in multiple inheritance this it could be already removed
            if interface in interfaces:
                interfaces.remove(interface)

    return interfaces


def get_direct_interface(obj):
    interfaces = get_direct_interfaces(obj)
    if not interfaces:
        return None

    if len(interfaces) == 1:
        return interfaces[0]
    else:
        raise Exception(""Object implements more than 1 interface"")


def query_adapter_for_class(cls, interface):
    return getSiteManager().adapters.lookup([implementedBy(cls)], interface)


class Singleton(type):
    """"""Singleton metaclass.""""""

    def __init__(cls, name, bases, dict):
        super(Singleton, cls).__init__(name, bases, dict)
        cls.instance = None

    def __call__(cls, *args, **kw):
        if cls.instance is None:
            cls.instance = super(Singleton, cls).__call__(*args, **kw)
        return cls.instance


def subscription_factory(cls, *args, **kwargs):
    """"""Utility which allows to to quickly register a subscription adapters which returns new
    instantiated objects of a given class

    >>> provideSubscriptionAdapter(subscription_factory(MetricsDaemonProcess), adapts=(IProc,))

    """"""

    class SubscriptionFactoryWrapper(object):
        def __new__(self, *_ignore):
            return cls(*args)

    interfaces = get_direct_interfaces(cls)
    classImplements(SubscriptionFactoryWrapper, *interfaces)
    return SubscriptionFactoryWrapper


def adapter_value(value):
    """"""Utility which allows to to quickly register a subscription adapter  as a value instead of

    >>> provideSubscriptionAdapter(adapter_value(['useful', 'stuff']), adapts=(Compute,), provides=ISomething)

    """"""

    def wrapper(*_):
        return value
    return wrapper


def async_sleep(secs):
    """"""Util which helps writing synchronous looking code with
    defer.inlineCallbacks.

    Returns a deferred which is triggered after `secs` seconds.

    """"""

    d = defer.Deferred()
    reactor.callLater(secs, d.callback, None)
    return d


def blocking_yield(deferred, timeout=None):
    """"""This utility is part of the HDK (hack development toolkit) use with care and remove its usage asap.

    Sometimes we have to synchronously wait for a deferred to complete,
    for example when executing inside db.transact code, which cannot 'yield'
    because currently db.transact doesn't handle returning a deferred.

    Or because we are running code inside a handler which cannot return a deferred
    otherwise we cannot block the caller or rollback the transaction in case of async code
    throwing exception (scenario: we want to prevent deletion of node)

    Use this utility only until you refactor the upstream code in order to use pure async code.
    """"""

    q = Queue()
    deferred.addBoth(q.put)
    try:
        ret = q.get(True, timeout or 100)
    except Empty:
        raise defer.TimeoutError
    if isinstance(ret, Failure):
        ret.raiseException()
    else:
        return ret


def threaded(fun):
    """"""Helper decorator to quickly turn a function in a threaded function using a newly allocated thread,
    mostly useful during debugging/profiling in order to see if there are any queuing issues in the
    threadpools.

    """"""

    @functools.wraps(fun)
    def wrapper(*args, **kwargs):
        thread = threading.Thread(target=fun, args=args, kwargs=kwargs)
        thread.start()
    return wrapper


def trace(fun):
    @functools.wraps(fun)
    def wrapper(*args, **kwargs):
        log.msg('%s %s %s' % (fun, args, kwargs), system='trace')
        return fun(*args, **kwargs)
    return wrapper


def trace_methods(cls):
    def trace_method(name):
        fun = getattr(cls, name)
        if inspect.ismethod(fun):
            setattr(cls, name, trace(fun))

    for name in cls.__dict__:
        trace_method(name)


def get_u(obj, key):
    val = obj.get(key)
    return unicode(val) if val is not None else None


def get_i(obj, key):
    val = obj.get(key)
    return int(val) if val is not None else None


def get_f(obj, key):
    val = obj.get(key)
    return float(val) if val is not None else None


def exception_logger(fun):
    @functools.wraps(fun)
    def wrapper(*args, **kwargs):
        try:
            res = fun(*args, **kwargs)
            if isinstance(res, defer.Deferred):
                @res
                def on_error(failure):
                    log.msg(""Got unhandled exception: %s"" % failure.getErrorMessage(), system='debug')
                    if get_config().getboolean('debug', 'print_exceptions'):
                        log.err(failure, system='debug')
            return res
        except Exception:
            if get_config().getboolean('debug', 'print_exceptions'):
                log.err(system='debug')
            raise
    return wrapper


def find_nth(haystack, needle, n, start_boundary=None):
    start = haystack.find(needle, start_boundary)
    while start >= 0 and n > 1:
        start = haystack.find(needle, start + len(needle))
        n -= 1
    return start


class benchmark(object):
    """"""Can be used either as decorator:
    >>> class Foo(object):
    ...   @benchmark(""some description"")
    ...   def doit(self, args):
    ...      # your code


    or as context manager:
    >>> with benchmark(""some description""):
    >>>    # your code

    and it will print out the time spent in the function or block.
    """"""

    def __init__(self, name):
        self.name = name

    def __call__(self, fun):
        @functools.wraps(fun)
        def wrapper(*args, **kwargs):
            with self:
                return fun(*args, **kwargs)
        return wrapper

    def __enter__(self):
        self.start = time.time()

    def __exit__(self, ty, val, tb):
        end = time.time()
        print(""%s : %0.3f seconds"" % (self.name, end - self.start))
        return False


class TimeoutException(Exception):
    """"""Raised when time expires in timeout decorator""""""


def timeout(secs):
    """"""
    Decorator to add timeout to Deferred calls
    """"""
    def wrap(func):
        @defer.inlineCallbacks
        @functools.wraps(func)
        def _timeout(*args, **kwargs):
            rawD = func(*args, **kwargs)
            if not isinstance(rawD, defer.Deferred):
                defer.returnValue(rawD)

            timeoutD = defer.Deferred()
            timesUp = reactor.callLater(secs, timeoutD.callback, None)

            try:
                rawResult, timeoutResult = yield defer.DeferredList([rawD, timeoutD],
                                                                    fireOnOneCallback=True,
                                                                    fireOnOneErrback=True,
                                                                    consumeErrors=True)
            except defer.FirstError, e:
                #Only rawD should raise an exception
                assert e.index == 0
                timesUp.cancel()
                e.subFailure.raiseException()
            else:
                #Timeout
                if timeoutD.called:
                    rawD.cancel()
                    raise TimeoutException(""%s secs have expired"" % secs)

            #No timeout
            timesUp.cancel()
            defer.returnValue(rawResult)
        return _timeout
    return wrap


class JsonSetEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, set):
            return list(obj)
        return json.JSONEncoder.default(self, obj)
/n/n/n",0
167,167,fb7d11509cd93463ac3ce9178b97910a8be1b05d,"/opennode/oms/endpoint/httprest/base.py/n/nfrom grokcore.component import Adapter, implements, baseclass
from grokcore.security import require
from zope.interface import Interface


class IHttpRestView(Interface):
    def render(request):
        pass

    def render_recursive(request, depth):
        pass

    def rw_transaction(request):
        """"""Return true if we this request should be committed""""""


class IHttpRestSubViewFactory(Interface):
    def resolve(path):
        """"""Resolve a view for a given sub path""""""


class HttpRestView(Adapter):
    implements(IHttpRestView)
    baseclass()
    require('rest')

    __builtin_attributes__ = ['id', 'children']

    def filter_attributes(self, request, data):
        """"""Handle the filtering of attributes according to the 'attrs' parameter in the request""""""
        attrs = request.args.get('attrs', [''])[0]
        if attrs:
            filtered_data = {}
            for a in attrs.decode('utf-8').split(',') + self.__builtin_attributes__:
                if a in data:
                    filtered_data[a] = data[a]
            return filtered_data
        return data

    def render_recursive(self, request, depth):
        for method in ('render_' + request.method, 'render'):
            if hasattr(self, method):
                return self.filter_attributes(request, getattr(self, method)(request))
        raise NotImplemented(""method %s not implemented\n"" % request.method)

    def render_OPTIONS(self, request):
        all_methods = ['GET', 'POST', 'PUT', 'DELETE', 'HEAD']
        has_methods = [m for m in all_methods if hasattr(self, 'render_%s' % m)] + ['OPTIONS']
        request.setHeader('Allow', ', '.join(has_methods))

        from opennode.oms.endpoint.httprest.root import EmptyResponse
        return EmptyResponse

    def rw_transaction(self, request):
        return request.method != 'GET'
/n/n/n/opennode/oms/endpoint/httprest/root.py/n/nimport json
import functools
import zope.security.interfaces

from twisted.internet import defer
from twisted.python import log, failure
from twisted.web import resource
from twisted.web.server import NOT_DONE_YET
from zope.component import queryAdapter, getUtility

from opennode.oms.config import get_config
from opennode.oms.endpoint.httprest.base import IHttpRestView, IHttpRestSubViewFactory
from opennode.oms.model.traversal import traverse_path
from opennode.oms.security.checker import proxy_factory
from opennode.oms.security.interaction import new_interaction
from opennode.oms.util import blocking_yield
from opennode.oms.zodb import db


class EmptyResponse(Exception):
    pass


class HttpStatus(Exception):
    def __init__(self, body=None, *args, **kwargs):
        super(HttpStatus, self).__init__(*args, **kwargs)
        self.body = body

    @property
    def status_code(self):
        raise NotImplementedError

    @property
    def status_description(self):
        raise NotImplementedError

    headers = {}


class NotFound(HttpStatus):
    status_code = 404
    status_description = ""Not Found""


class NotImplemented(HttpStatus):
    status_code = 501
    status_description = ""Not Implemented""


class AbstractRedirect(HttpStatus):
    def __init__(self, url, *args, **kwargs):
        super(AbstractRedirect, self).__init__(*args, **kwargs)
        self.url = url

    @property
    def headers(self):
        return {'Location': self.url}


class SeeCanonical(AbstractRedirect):
    status_code = 301
    status_description = ""Moved Permanently""


class SeeOther(AbstractRedirect):
    status_code = 303
    status_description = ""Moved Temporarily""


class Unauthorized(HttpStatus):
    status_code = 401
    status_description = ""Authorization Required""

    headers = {'WWW-Authenticate': 'Basic realm=OMS',
               'Set-Cookie': 'oms_auth_token=;expires=Wed, 01 Jan 2000 00:00:00 GMT'}


class Forbidden(HttpStatus):
    status_code = 403
    status_description = ""Forbidden""


class BadRequest(HttpStatus):
    status_code = 400
    status_description = ""Bad Request""


def log_wrapper(self, f, server):
    @functools.wraps(f)
    def log_(request):
        """"""
        Log a request's result to the logfile, by default in combined log format.
        """"""
        if hasattr(request, 'interaction'):
            principals = map(lambda pp: pp.principal.id, request.interaction.participations)
        else:
            principals = []
        if hasattr(self, ""logFile""):
            line = '%s %s - %s ""%s"" %d %s ""%s"" ""%s""\n' % (
                request.getClientIP(),
                principals,
                self._logDateTime,
                '%s %s %s' % (self._escape(request.method),
                              self._escape(request.uri),
                              self._escape(request.clientproto)),
                request.code,
                request.sentLength or ""-"",
                self._escape(request.getHeader(""referer"") or ""-""),
                self._escape(request.getHeader(""user-agent"") or ""-""))
            self.logFile.write(line)
    return log_


class HttpRestServer(resource.Resource):
    """"""Restful HTTP API interface for OMS.

    Exposes a JSON web service to communicate with OMS.

    """"""

    def getChild(self, name, request):
        """"""We are the handler for anything below this base url, except what explicitly added in oms.tac.""""""
        return self

    def __init__(self, avatar=None):
        ## Twisted Resource is a not a new style class, so emulating a super-call
        resource.Resource.__init__(self)
        self.avatar = avatar

        self.use_security_proxy = get_config().getboolean('auth', 'security_proxy_rest')

    def render(self, request):
        request.site.log = log_wrapper(request.site, request.site.log, self)
        deferred = self._render(request)

        @deferred
        def on_error(error):
            log.msg(""Error while rendering http %s"", system='httprest')
            log.err(error, system='httprest')

        return NOT_DONE_YET

    @defer.inlineCallbacks
    def _render(self, request):
        request.setHeader('Content-type', 'application/json')
        origin = request.getHeader('Origin')
        if origin:
            request.setHeader('Access-Control-Allow-Origin', origin)
            request.setHeader('Access-Control-Allow-Credentials', 'true')
        else:
            request.setHeader('Access-Control-Allow-Origin', '*')
        request.setHeader('Access-Control-Allow-Methods', 'GET, PUT, POST, DELETE, OPTIONS, HEAD')
        request.setHeader('Access-Control-Allow-Headers',
                          'Origin, Content-Type, Cache-Control, X-Requested-With')

        ret = None
        try:
            ret = yield self.handle_request(request)
            if ret is EmptyResponse:
                raise ret
        except EmptyResponse:
            pass
        except HttpStatus as exc:
            request.setResponseCode(exc.status_code, exc.status_description)
            for name, value in exc.headers.items():
                request.responseHeaders.addRawHeader(name, value)
            if exc.body:
                request.write(json.dumps(exc.body))
            else:
                request.write(""%s %s\n"" % (exc.status_code, exc.status_description))
            if exc.message:
                request.write(""%s\n"" % exc.message)
        except Exception:
            request.setResponseCode(500, ""Server Error"")
            request.write(""%s %s\n\n"" % (500, ""Server Error""))
            log.err(system='httprest')
            failure.Failure().printTraceback(request)
        else:
            # allow views to take full control of output streaming
            if ret != NOT_DONE_YET:
                def render(obj):
                    if isinstance(obj, set):
                        return list(obj)  # safeguard against dumping sets
                    if hasattr(obj, '__str__'):
                        return str(obj)
                    log.msg(""RENDERING ERROR, cannot json serialize %s"" % obj, system='httprest')
                    raise TypeError

                request.write(json.dumps(ret, indent=2, default=render) + '\n')
        finally:
            if ret != NOT_DONE_YET:
                request.finish()

    def check_auth(self, request):
        from opennode.oms.endpoint.httprest.auth import IHttpRestAuthenticationUtility

        authentication_utility = getUtility(IHttpRestAuthenticationUtility)
        credentials = authentication_utility.get_basic_auth_credentials(request)
        if credentials:
            blocking_yield(authentication_utility.authenticate(request, credentials, basic_auth=True))
            return authentication_utility.generate_token(credentials)
        else:
            return authentication_utility.get_token(request)

    def find_view(self, obj, unresolved_path):

        sub_view_factory = queryAdapter(obj, IHttpRestSubViewFactory)
        if sub_view_factory:
            view = sub_view_factory.resolve(unresolved_path)
        else:
            view = queryAdapter(obj, IHttpRestView)

        if not view:
            raise NotFound

        return view

    @db.transact
    def handle_request(self, request):
        """"""Takes a request, maps it to a domain object and a
        corresponding IHttpRestView, and returns the rendered output
        of that view.

        """"""
        token = self.check_auth(request)

        oms_root = db.get_root()['oms_root']
        objs, unresolved_path = traverse_path(oms_root, request.path[1:])

        if not objs and unresolved_path:
            objs = [oms_root]

        obj = objs[-1]

        interaction = self.get_interaction(request, token)
        request.interaction = interaction

        if self.use_security_proxy:
            obj = proxy_factory(obj, interaction)

        view = self.find_view(obj, unresolved_path)
        needs_rw_transaction = view.rw_transaction(request)

        # create a security proxy if we have a secured interaction
        if interaction:
            try:
                view = proxy_factory(view, interaction)
            except:
                # XXX: TODO: define a real exception for this proxy creation error
                # right now we want to ignore security when there are no declared rules
                # on how to secure a view
                pass

        def get_renderer(view, method):
            try:
                return getattr(view, method, None)
            except zope.security.interfaces.Unauthorized:
                from opennode.oms.endpoint.httprest.auth import IHttpRestAuthenticationUtility

                if token or not getUtility(IHttpRestAuthenticationUtility).get_basic_auth_credentials(request):
                    raise Forbidden('User does not have permission to access this resource')
                raise Unauthorized()

        for method in ('render_' + request.method, 'render'):
            # hasattr will return false on unauthorized fields
            renderer = get_renderer(view, method)
            if renderer:
                res = renderer(request)

                if needs_rw_transaction:
                    return res
                else:
                    return db.RollbackValue(res)

        raise NotImplementedError(""method %s not implemented\n"" % request.method)

    def get_interaction(self, request, token):
        # TODO: we can quickly disable rest auth
        # if get_config().getboolean('auth', 'enable_anonymous'):
        #     return None

        from opennode.oms.endpoint.httprest.auth import IHttpRestAuthenticationUtility

        authentication_utility = getUtility(IHttpRestAuthenticationUtility)
        try:
            principal = authentication_utility.get_principal(token)
        except:
            # Avoid that changes in format of security token will require every user
            # to flush the cookies
            principal = 'oms.anonymous'

        if principal != 'oms.anonymous':
            authentication_utility.renew_token(request, token)

        if request.method == 'OPTIONS':
            principal = 'oms.rest_options'

        return new_interaction(principal)
/n/n/n/opennode/oms/endpoint/httprest/view.py/n/nimport json
import os
import time
import Queue

from grokcore.component import context
from hashlib import sha1
from twisted.web.server import NOT_DONE_YET
from twisted.python import log
from twisted.internet import reactor, threads, defer
from zope.component import queryAdapter, handle
from zope.security.interfaces import Unauthorized
from zope.security.proxy import removeSecurityProxy

from opennode.oms.endpoint.httprest.base import HttpRestView, IHttpRestView
from opennode.oms.endpoint.httprest.root import BadRequest, NotFound
from opennode.oms.endpoint.ssh.cmd.security import effective_perms
from opennode.oms.endpoint.ssh.detached import DetachedProtocol
from opennode.oms.endpoint.ssh.cmdline import ArgumentParsingError
from opennode.oms.model.form import RawDataApplier
from opennode.oms.model.location import ILocation
from opennode.oms.model.model.base import IContainer
from opennode.oms.model.model.bin import ICommand
from opennode.oms.model.model.byname import ByNameContainer
from opennode.oms.model.model.events import ModelDeletedEvent
from opennode.oms.model.model.filtrable import IFiltrable
from opennode.oms.model.model.search import SearchContainer, SearchResult
from opennode.oms.model.model.stream import IStream, StreamSubscriber
from opennode.oms.model.model.symlink import Symlink, follow_symlinks
from opennode.oms.model.schema import model_to_dict
from opennode.oms.model.traversal import traverse_path
from opennode.oms.security.checker import get_interaction
from opennode.oms.zodb import db


class DefaultView(HttpRestView):
    context(object)

    def render_GET(self, request):
        if not request.interaction.checkPermission('view', self.context):
            raise NotFound()

        data = model_to_dict(self.context)

        data['id'] = self.context.__name__
        data['__type__'] = type(removeSecurityProxy(self.context)).__name__
        try:
            data['url'] = ILocation(self.context).get_url()
        except Unauthorized:
            data['url'] = ''

        interaction = get_interaction(self.context)
        data['permissions'] = effective_perms(interaction, self.context) if interaction else []

        # XXX: simplejson can't serialize sets
        if 'tags' in data:
            data['tags'] = list(data['tags'])

        return data

    def render_PUT(self, request):
        data = json.load(request.content)
        if 'id' in data:
            del data['id']

        data = self.put_filter_attributes(request, data)

        form = RawDataApplier(data, self.context)
        if not form.errors:
            form.apply()
            return [IHttpRestView(self.context).render_recursive(request, depth=0)]
        else:
            request.setResponseCode(BadRequest.status_code)
            return form.error_dict()

    def put_filter_attributes(self, request, data):
        """"""Offer the possibility to subclasses to massage the received json before default behavior.""""""
        return data

    def render_DELETE(self, request):
        force = request.args.get('force', ['false'])[0] == 'true'

        parent = self.context.__parent__
        del parent[self.context.__name__]

        try:
            handle(self.context, ModelDeletedEvent(parent))
        except Exception as e:
            if not force:
                raise e
            return {'status': 'failure'}

        return {'status': 'success'}


class ContainerView(DefaultView):
    context(IContainer)

    def render_GET(self, request):
        depth = request.args.get('depth', ['0'])[0]
        try:
            depth = int(depth)
        except ValueError:
            depth = 0

        return self.render_recursive(request, depth, top_level=True)

    def render_recursive(self, request, depth, filter_=[], top_level=False):
        container_properties = super(ContainerView, self).render_GET(request)

        if depth < 1:
            return self.filter_attributes(request, container_properties)

        exclude = [excluded.strip() for excluded in request.args.get('exclude', [''])[0].split(',')]

        def preconditions(obj):
            yield request.interaction.checkPermission('view', obj)
            yield obj.__name__ not in exclude
            yield obj.target.__parent__ == obj.__parent__ if type(obj) is Symlink else True

        items = map(follow_symlinks, filter(lambda obj: all(preconditions(obj)), self.context.listcontent()))

        def secure_render_recursive(item):
            try:
                return IHttpRestView(item).render_recursive(request, depth - 1)
            except Unauthorized:
                permissions = effective_perms(get_interaction(item), item)
                if 'view' in permissions:
                    return dict(access='denied', permissions=permissions,
                                __type__=type(removeSecurityProxy(item)).__name__)

        qlist = []
        limit = None
        offset = 0

        if top_level:
            qlist = request.args.get('q', [])
            qlist = map(lambda q: q.decode('utf-8'), qlist)
            limit = int(request.args.get('limit', [0])[0])
            offset = int(request.args.get('offset', [1])[0]) - 1
            if offset <= 0:
                offset = 0

        def secure_filter_match(item, q):
            try:
                return IFiltrable(item).match(q)
            except Unauthorized:
                return

        for q in qlist:
            items = filter(lambda item: secure_filter_match(item, q), items)

        children = filter(None, [secure_render_recursive(item) for item in items
                                 if queryAdapter(item, IHttpRestView) and not self.blacklisted(item)])

        total_children = len(children)

        if (limit is not None and limit != 0) or offset:
            children = children[offset : offset + limit]

        # backward compatibility:
        # top level results for pure containers are plain lists
        if top_level and (not container_properties or len(container_properties.keys()) == 1):
            return children

        if not top_level or depth > 0:
            container_properties['children'] = children
            container_properties['totalChildren'] = total_children

        return self.filter_attributes(request, container_properties)

    def blacklisted(self, item):
        return isinstance(item, ByNameContainer)


class SearchView(ContainerView):
    context(SearchContainer)

    def render_GET(self, request):
        q = request.args.get('q', [''])[0]

        if not q:
            return super(SearchView, self).render_GET(request)

        search = db.get_root()['oms_root']['search']
        res = SearchResult(search, q.decode('utf-8'))

        return IHttpRestView(res).render_GET(request)


class StreamView(HttpRestView):
    context(StreamSubscriber)

    cached_subscriptions = dict()

    def rw_transaction(self, request):
        return False

    def render(self, request):
        timestamp = int(time.time() * 1000)
        oms_root = db.get_root()['oms_root']

        limit = int(request.args.get('limit', ['100'])[0])
        after = int(request.args.get('after', ['0'])[0])

        subscription_hash = request.args.get('subscription_hash', [''])[0]
        if subscription_hash:
            if subscription_hash in self.cached_subscriptions:
                data = self.cached_subscriptions[subscription_hash]
            else:
                raise BadRequest(""Unknown subscription hash"")
        elif not request.content.getvalue():
            return {}
        else:
            data = json.load(request.content)
            subscription_hash = sha1(request.content.getvalue()).hexdigest()
            self.cached_subscriptions[subscription_hash] = data
            request.responseHeaders.addRawHeader('X-OMS-Subscription-Hash', subscription_hash)

        def val(r):
            objs, unresolved_path = traverse_path(oms_root, r)
            if unresolved_path:
                return [(timestamp, dict(event='delete', name=os.path.basename(r), url=r))]
            return IStream(objs[-1]).events(after, limit=limit)

        # ONC wants it in ascending time order
        # while internally we prefer to keep it newest first to
        # speed up filtering.
        # Reversed is not json serializable so we have to reify to list.
        res = [list(reversed(val(resource))) for resource in data]
        res = [(i, v) for i, v in enumerate(res) if v]
        return [timestamp, dict(res)]


class CommandView(DefaultView):
    context(ICommand)

    def write_results(self, request, pid, cmd):
        log.msg('Called %s got result: pid(%s) term writes=%s' % (
                cmd, pid, len(cmd.write_buffer)), system='command-view')
        request.write(json.dumps({'status': 'ok', 'pid': pid,
                                  'stdout': cmd.write_buffer}))
        request.finish()

    def render_PUT(self, request):
        """""" Converts arguments into command-line counterparts and executes the omsh command.

        Parameters passed as 'arg' are converted into positional arguments, others are converted into
        named parameters:

            PUT /bin/ls?arg=/some/path&arg=/another/path&-l&--recursive

        thus translates to:

            /bin/ls /some/path /another/path -l --recursive

        Allows blocking (synchronous) and non-blocking operation using the 'asynchronous' parameter (any
        value will trigger it). Synchronous operation requires two threads to function.
        """"""

        def named_args_filter_and_flatten(nargs):
            for name, vallist in nargs:
                if name not in ('arg', 'asynchronous'):
                    for val in vallist:
                        yield name
                        yield val

        def convert_args(args):
            tokenized_args = args.get('arg', [])
            return tokenized_args + list(named_args_filter_and_flatten(args.items()))

        protocol = DetachedProtocol()
        protocol.interaction = get_interaction(self.context) or request.interaction

        args = convert_args(request.args)
        args = filter(None, args)
        cmd = self.context.cmd(protocol)
        # Setting write_buffer to a list makes command save the output to the buffer too
        cmd.write_buffer = []
        d0 = defer.Deferred()

        try:
            pid = threads.blockingCallFromThread(reactor, cmd.register, d0, args,
                                                 '%s %s' % (request.path, args))
        except ArgumentParsingError, e:
            raise BadRequest(str(e))

        q = Queue.Queue()

        def execute(cmd, args):
            d = defer.maybeDeferred(cmd, *args)
            d.addBoth(q.put)
            d.chainDeferred(d0)

        dt = threads.deferToThread(execute, cmd, args)

        if request.args.get('asynchronous', []):
            reactor.callFromThread(self.write_results, request, pid, cmd)
        else:
            dt.addBoth(lambda r: threads.deferToThread(q.get, True, 60))
            dt.addCallback(lambda r: reactor.callFromThread(self.write_results, request, pid, cmd))

            def errhandler(e, pid, cmd):
                e.trap(ArgumentParsingError)
                raise BadRequest(str(e))
            dt.addErrback(errhandler, pid, cmd)
        return NOT_DONE_YET
/n/n/n/opennode/oms/model/traversal.py/n/nimport logging
import re

from grokcore.component import Adapter, implements, baseclass
from zope.interface import Interface

from opennode.oms.model.model.symlink import follow_symlinks


__all__ = ['traverse_path', 'traverse1']


log = logging.getLogger(__name__)


class ITraverser(Interface):
    """"""Adapters providing object traversal should implement this interface.""""""

    def traverse(name):
        """"""Takes the name of the object to traverse to and returns the traversed object, if any.""""""


class Traverser(Adapter):
    """"""Base class for all object traversers.""""""
    implements(ITraverser)
    baseclass()


def traverse_path(obj, path):
    """"""Starting from the given object, traverses all its descendant
    objects to find an object that matches the given path.

    Returns a tuple that contains the object up to which the traversal
    was successful plus all objects that led to that object, and the
    part of the path that could not be resolved.

    """"""

    if not path or path == '/':
        return [obj], []

    path = re.sub(r'\/+', '/', path)
    if path.endswith('/'):
        path = path[:-1]
    if path.startswith('/'):
        path = path[1:]

    path = path.split('/')

    ret = [obj]
    while path:
        name = path[0]
        try:
            traverser = ITraverser(ret[-1])
        except TypeError:
            break

        next_obj = follow_symlinks(traverser.traverse(name))

        if not next_obj:
            break

        ret.append(next_obj)
        path = path[1:]

    return ret[1:], path


def traverse1(path):
    """"""Provides a shortcut for absolute path traversals without
    needing to pass in the root object.

    """"""

    # Do it here just in case; to avoid circular imports:
    from opennode.oms.zodb import db

    oms_root = db.get_root()['oms_root']
    objs, untraversed_path = traverse_path(oms_root, path)
    if objs and not untraversed_path:
        return objs[-1]
    else:
        return None


def canonical_path(item):
    path = []
    from opennode.oms.security.authentication import Sudo
    while item:
        with Sudo(item):
            assert item.__name__ is not None, '%s.__name__ is None' % item
            item = follow_symlinks(item)
            path.insert(0, item.__name__)
            item = item.__parent__
    return '/'.join(path)
/n/n/n/opennode/oms/util.py/n/nimport functools
import inspect
import time
import threading

from Queue import Queue, Empty

import zope.interface
from zope.component import getSiteManager, implementedBy
from zope.interface import classImplements
from twisted.internet import defer, reactor
from twisted.python import log
from twisted.python.failure import Failure

from opennode.oms.config import get_config


def get_direct_interfaces(obj):
    """"""Returns the interfaces that the parent class of `obj`
    implements, exluding any that any of its ancestor classes
    implement.

    >>> from zope.interface import Interface, implements, implementedBy
    >>> class IA(Interface): pass
    >>> class IB(Interface): pass
    >>> class A: implements(IA)
    >>> class B(A): implements(IB)
    >>> b = B()
    >>> [i.__name__ for i in list(implementedBy(B).interfaces())]
    ['IB', 'IA']
    >>> [i.__name__ for i in get_direct_interfaces(b)]
    ['IB']

    """"""
    cls = obj if isinstance(obj, type) else type(obj)

    if not isinstance(obj, type) and hasattr(obj, 'implemented_interfaces'):
        interfaces = obj.implemented_interfaces()
    else:
        interfaces = list(zope.interface.implementedBy(cls).interfaces())

    for base_cls in cls.__bases__:
        for interface in list(zope.interface.implementedBy(base_cls).interfaces()):
            # in multiple inheritance this it could be already removed
            if interface in interfaces:
                interfaces.remove(interface)

    return interfaces


def get_direct_interface(obj):
    interfaces = get_direct_interfaces(obj)
    if not interfaces:
        return None
    if len(interfaces) == 1:
        return interfaces[0]
    else:
        raise Exception(""Object implements more than 1 interface"")


def query_adapter_for_class(cls, interface):
    return getSiteManager().adapters.lookup([implementedBy(cls)], interface)


class Singleton(type):
    """"""Singleton metaclass.""""""

    def __init__(cls, name, bases, dict):
        super(Singleton, cls).__init__(name, bases, dict)
        cls.instance = None

    def __call__(cls, *args, **kw):
        if cls.instance is None:
            cls.instance = super(Singleton, cls).__call__(*args, **kw)
        return cls.instance


def subscription_factory(cls, *args, **kwargs):
    """"""Utility which allows to to quickly register a subscription adapters which returns new instantiated objects
    of a given class

    >>> provideSubscriptionAdapter(subscription_factory(MetricsDaemonProcess), adapts=(IProc,))

    """"""

    class SubscriptionFactoryWrapper(object):
        def __new__(self, *_ignore):
            return cls(*args)

    interfaces = get_direct_interfaces(cls)
    classImplements(SubscriptionFactoryWrapper, *interfaces)
    return SubscriptionFactoryWrapper


def adapter_value(value):
    """"""Utility which allows to to quickly register a subscription adapter  as a value instead of

    >>> provideSubscriptionAdapter(adapter_value(['useful', 'stuff']), adapts=(Compute,), provides=ISomething)

    """"""

    def wrapper(*_):
        return value
    return wrapper


def async_sleep(secs):
    """"""Util which helps writing synchronous looking code with
    defer.inlineCallbacks.

    Returns a deferred which is triggered after `secs` seconds.

    """"""

    d = defer.Deferred()
    reactor.callLater(secs, d.callback, None)
    return d


def blocking_yield(deferred, timeout=None):
    """"""This utility is part of the HDK (hack development toolkit) use with care and remove its usage asap.

    Sometimes we have to synchronously wait for a deferred to complete,
    for example when executing inside db.transact code, which cannot 'yield'
    because currently db.transact doesn't handle returning a deferred.

    Or because we are running code inside a handler which cannot return a deferred
    otherwise we cannot block the caller or rollback the transaction in case of async code
    throwing exception (scenario: we want to prevent deletion of node)

    Use this utility only until you refactor the upstream code in order to use pure async code.
    """"""

    q = Queue()
    deferred.addBoth(q.put)
    try:
        ret = q.get(True, timeout or 100)
    except Empty:
        raise defer.TimeoutError
    if isinstance(ret, Failure):
        ret.raiseException()
    else:
        return ret


def threaded(fun):
    """"""Helper decorator to quickly turn a function in a threaded function using a newly allocated thread,
    mostly useful during debugging/profiling in order to see if there are any queuing issues in the
    threadpools.

    """"""

    @functools.wraps(fun)
    def wrapper(*args, **kwargs):
        thread = threading.Thread(target=fun, args=args, kwargs=kwargs)
        thread.start()
    return wrapper


def trace(fun):
    @functools.wraps(fun)
    def wrapper(*args, **kwargs):
        log.msg('%s %s %s' % (fun, args, kwargs), system='trace')
        return fun(*args, **kwargs)
    return wrapper


def trace_methods(cls):
    def trace_method(name):
        fun = getattr(cls, name)
        if inspect.ismethod(fun):
            setattr(cls, name, trace(fun))

    for name in cls.__dict__:
        trace_method(name)


def get_u(obj, key):
    val = obj.get(key)
    return unicode(val) if val is not None else None


def get_i(obj, key):
    val = obj.get(key)
    return int(val) if val is not None else None


def get_f(obj, key):
    val = obj.get(key)
    return float(val) if val is not None else None


def exception_logger(fun):
    @functools.wraps(fun)
    def wrapper(*args, **kwargs):
        try:
            res = fun(*args, **kwargs)
            if isinstance(res, defer.Deferred):
                @res
                def on_error(failure):
                    log.msg(""Got unhandled exception: %s"" % failure.getErrorMessage(), system='debug')
                    if get_config().getboolean('debug', 'print_exceptions'):
                        log.err(failure, system='debug')
            return res
        except Exception:
            if get_config().getboolean('debug', 'print_exceptions'):
                log.err(system='debug')
            raise
    return wrapper


def find_nth(haystack, needle, n, start_boundary=None):
    start = haystack.find(needle, start_boundary)
    while start >= 0 and n > 1:
        start = haystack.find(needle, start + len(needle))
        n -= 1
    return start


class benchmark(object):
    """"""Can be used either as decorator:
    >>> class Foo(object):
    ...   @benchmark(""some description"")
    ...   def doit(self, args):
    ...      # your code


    or as context manager:
    >>> with benchmark(""some description""):
    >>>    # your code

    and it will print out the time spent in the function or block.
    """"""

    def __init__(self, name):
        self.name = name

    def __call__(self, fun):
        @functools.wraps(fun)
        def wrapper(*args, **kwargs):
            with self:
                return fun(*args, **kwargs)
        return wrapper

    def __enter__(self):
        self.start = time.time()

    def __exit__(self, ty, val, tb):
        end = time.time()
        print(""%s : %0.3f seconds"" % (self.name, end - self.start))
        return False


class TimeoutException(Exception):
    """"""Raised when time expires in timeout decorator""""""


def timeout(secs):
    """"""
    Decorator to add timeout to Deferred calls
    """"""
    def wrap(func):
        @defer.inlineCallbacks
        @functools.wraps(func)
        def _timeout(*args, **kwargs):
            rawD = func(*args, **kwargs)
            if not isinstance(rawD, defer.Deferred):
                defer.returnValue(rawD)

            timeoutD = defer.Deferred()
            timesUp = reactor.callLater(secs, timeoutD.callback, None)

            try:
                rawResult, timeoutResult = yield defer.DeferredList([rawD, timeoutD],
                                                                    fireOnOneCallback=True,
                                                                    fireOnOneErrback=True,
                                                                    consumeErrors=True)
            except defer.FirstError, e:
                #Only rawD should raise an exception
                assert e.index == 0
                timesUp.cancel()
                e.subFailure.raiseException()
            else:
                #Timeout
                if timeoutD.called:
                    rawD.cancel()
                    raise TimeoutException(""%s secs have expired"" % secs)

            #No timeout
            timesUp.cancel()
            defer.returnValue(rawResult)
        return _timeout
    return wrap
/n/n/n",1
104,104,1fb790712fe0c1d1957b31e34a8e0e6593af87a7,"seagull/routes/app.py/n/n#
# Seagull photo gallery app
# Copyright (C) 2016  Hajime Yamasaki Vukelic
#
# This program is free software: you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more
# details.
#

from os.path import join, exists

from bottle import static_file

from streamline import NonIterableRouteBase


class Static(NonIterableRouteBase):
    path = '/static/<path:path>'

    def get_base_paths(self):
        return (self.config['runtime.static_dir'],
                self.config['runtime.assets_dir'])

    @staticmethod
    def get_first_base(bases, path):
        """"""
        Return the first base path within which the path is found

        The last base path is always returned such that 404 errors are handled
        by bottle.
        """"""
        for b in bases:
            if not exists(join(b, path)):
                continue
            return b
        return b

    @staticmethod
    def sanitize_path(path):
        if path.startswith('/'):
            path = path[1:]
        return path.replace('..', '.')

    def get(self, path):
        path = self.sanitize_path(path)
        base_paths = self.get_base_paths()
        if hasattr(base_paths, 'split'):
            # String, so go simple
            base_path = base_paths
        else:
            base_path = self.get_first_base(base_paths, path)
        return static_file(path, base_path)

/n/n/nseagull/routes/gallery.py/n/n#
# Seagull photo gallery app
# Copyright (C) 2016  Hajime Yamasaki Vukelic
#
# This program is free software: you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more
# details.
#

from .app import Static
from ..app.templating import TemplateRoute
from ..gallery.pager import Pager


class Main(TemplateRoute):
    """"""
    Main page
    """"""
    path = '/'
    template_name = 'main.mako'

    @property
    def current_page(self):
        try:
            return int(self.request.query['page'])
        except (KeyError, ValueError, TypeError):
            return 1

    def get(self):
        index = self.config['runtime.gallery']
        pager = Pager(index, self.current_page)
        return {'pager': pager}


class Image(Static):
    path = '/gallery/<path:path>'

    def get_base_paths(self):
        return self.config['runtime.gallery_dir']


class Reindex(TemplateRoute):
    path = '/reindex/<token>'
    template_name = 'reset.mako'

    def get(self, token):
        index = self.config['runtime.gallery']
        index.rescan()
        return {}
/n/n/n",0
105,105,1fb790712fe0c1d1957b31e34a8e0e6593af87a7,"/seagull/routes/app.py/n/n#
# Seagull photo gallery app
# Copyright (C) 2016  Hajime Yamasaki Vukelic
#
# This program is free software: you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more
# details.
#

from bottle import static_file

from streamline import NonIterableRouteBase


class Static(NonIterableRouteBase):
    path = '/static/<path:path>'

    def get_base_path(self):
        return self.config['runtime.static_dir']

    def get(self, path):
        return static_file(path, self.get_base_path())
/n/n/n/seagull/routes/gallery.py/n/n#
# Seagull photo gallery app
# Copyright (C) 2016  Hajime Yamasaki Vukelic
#
# This program is free software: you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more
# details.
#

from .app import Static
from ..app.templating import TemplateRoute
from ..gallery.pager import Pager


class Main(TemplateRoute):
    """"""
    Main page
    """"""
    path = '/'
    template_name = 'main.mako'

    @property
    def current_page(self):
        try:
            return int(self.request.query['page'])
        except (KeyError, ValueError, TypeError):
            return 1

    def get(self):
        index = self.config['runtime.gallery']
        pager = Pager(index, self.current_page)
        return {'pager': pager}


class Image(Static):
    path = '/gallery/<path:path>'

    def get_base_path(self):
        return self.config['runtime.gallery_dir']


class Reindex(TemplateRoute):
    path = '/reindex/<token>'
    template_name = 'reset.mako'

    def get(self, token):
        index = self.config['runtime.gallery']
        index.rescan()
        return {}
/n/n/n",1
170,170,fd1549ee5288bbab0ff8e1cf03c2df60da8eac82,"path_traversal.py/n/nroot = ["""", ""home"", ""root""]
dirs = []
path = []
curr_path = [] or ["""", ""home"", ""root""]


# To create directory
def mkdir():
    global dirs
    if dir in dirs:
        print(""Directory already exist."")
    else:
        dirs.append(dir)
        path.append(dir)


# shows directory
def ls():
    global path
    if path == root:
        path = dirs
        path = path[0]
    print(*path, sep=""\n"")


# change directory
def cd():
    global curr_path, dir, path
    if dir == """":
        curr_path = root
        path = root
    elif dir in dirs:
        curr_path.append(dir)
        path.clear()
    elif dir == "".."":
        curr_path.pop()
        print(*curr_path, sep=""/"")
        i = len(dirs) - 1
        if dirs[i] in path:
            i = i - 1
            path.pop()
            path.append(dirs[i])
        else:
            path.append(dirs[i])
    else:
        print(""Directory doesn't exist."")


# show current directory
def pwd():
    global curr_path
    print(*curr_path, sep=""/"")


# remove directory
def rm():
    global dirs
    if dir in dirs:
        dirs.remove(dir)
        if dir in path:
            path.remove(dir)
    else:
        print(""Directory does not exist."")


# clean session data like it is executed just now
def session_clear():
    global dirs
    dirs.clear()
    global curr_path
    curr_path.clear()
    curr_path = root
    global path
    path.clear()


def commands(argument):
    comm = {
        ""mkdir"": mkdir,
        ""ls"": ls,
        ""cd"": cd,
        ""pwd"": pwd,
        ""rm"": rm,
        ""session_clear"": session_clear,
        ""exit"": exit,
    }
    if n in comm:
        # Get the function from comm dictionary
        func = comm.get(argument)
        # Execute the function
        func()
    else:
        print(""command does not exist!"")


print(""There are total 7 commands: mkdir, ls, cd, pwd, rm, session_clear, exit."")

while True:
    n = input(""$: "")
    a = []
    a.append(n.split("" ""))
    n = a[0][0]
    if n in [""mkdir"", ""rm""] and len(a[0]) == 1:
        print(""{}:missing operand"".format(n))
    elif len(a[0]) == 1:
        dir = """"
    elif len(a[0]) == 2:
        dir = a[0][1]
    else:
        print(""Invalid Syntax"")
    commands(n)
/n/n/n",0
171,171,fd1549ee5288bbab0ff8e1cf03c2df60da8eac82,"/path_traversal.py/n/nroot = ["""", ""home"", ""root""]dirs = []path = []curr_path = [] or ["""", ""home"", ""root""]# To create directorydef mkdir():    global dirs    if dir in dirs:        print(""Directory already exist."")    else:        dirs.append(dir)        path.append(dir)# shows directorydef ls():    global path    if path == root:        path = dirs        path = path[0]    print(*path, sep=""\n"")# change directorydef cd():    global curr_path, dir, path    if dir == """":        curr_path = root        path = root    elif dir in dirs:        curr_path.append(dir)        path.clear()    elif dir == "".."":        curr_path.pop()        print(*curr_path, sep=""/"")        i = len(dirs) - 1        if dirs[i] in path:            i = i - 1            path.pop()            path.append(dirs[i])        else:            path.append(dirs[i])    else:        print(""Directory doesn't exist."")# show current directorydef pwd():    global curr_path    print(*curr_path, sep=""/"")# remove directorydef rm():    global dirs    if dir in dirs:        dirs.remove(dir)        if dir in path:            path.remove(dir)    else:        print(""Directory does not exist."")# clean session data like it is executed just nowdef session_clear():    global dirs    dirs.clear()    global curr_path    curr_path.clear()    curr_path = root    global path    path.clear()def commands(argument):    comm = {        ""mkdir"": mkdir,        ""ls"": ls,        ""cd"": cd,        ""pwd"": pwd,        ""rm"": rm,        ""session_clear"": session_clear,        ""exit"": exit    }    if n in comm:        # Get the function from comm dictionary        func = comm.get(argument)        # Execute the function        func()    else:        print(""command does not exist!"")print(    ""There are total 7 commands: mkdir, ls, cd, pwd, rm, session_clear, exit."")while True:    n = input(""$: "")    a = []    a.append(n.split("" ""))    n = a[0][0]    if n in [""mkdir"", ""rm""] and len(a[0]) == 1:        print(""{}:missing operand"".format(n))    elif len(a[0]) == 1:        dir = """"    elif len(a[0]) == 2:        dir = a[0][1]    else:        print(""Invalid Syntax"")    commands(n)/n/n/n",1
114,114,dcdb81e6f86420c96cc113a726be8663566cfe95,"tests2/freetdstests.py/n/n#!/usr/bin/python
# -*- coding: latin-1 -*-

usage = """"""\
usage: %prog [options] connection_string

Unit tests for FreeTDS / SQL Server.  To use, pass a connection string as the parameter.
The tests will create and drop tables t1 and t2 as necessary.

These run using the version from the 'build' directory, not the version
installed into the Python directories.  You must run python setup.py build
before running the tests.

You can also put the connection string into a tmp/setup.cfg file like so:

  [freetdstests]
  connection-string=DSN=xyz;UID=test;PWD=test
""""""

import sys, os, re
import unittest
from decimal import Decimal
from datetime import datetime, date, time
from os.path import join, getsize, dirname, abspath
from testutils import *

_TESTSTR = '0123456789-abcdefghijklmnopqrstuvwxyz-'

def _generate_test_string(length):
    """"""
    Returns a string of `length` characters, constructed by repeating _TESTSTR as necessary.

    To enhance performance, there are 3 ways data is read, based on the length of the value, so most data types are
    tested with 3 lengths.  This function helps us generate the test data.

    We use a recognizable data set instead of a single character to make it less likely that ""overlap"" errors will
    be hidden and to help us manually identify where a break occurs.
    """"""
    if length <= len(_TESTSTR):
        return _TESTSTR[:length]

    c = (length + len(_TESTSTR)-1) / len(_TESTSTR)
    v = _TESTSTR * c
    return v[:length]

class FreeTDSTestCase(unittest.TestCase):

    SMALL_FENCEPOST_SIZES = [ 0, 1, 255, 256, 510, 511, 512, 1023, 1024, 2047, 2048, 4000 ]
    LARGE_FENCEPOST_SIZES = [ 4095, 4096, 4097, 10 * 1024, 20 * 1024 ]

    ANSI_FENCEPOSTS    = [ _generate_test_string(size) for size in SMALL_FENCEPOST_SIZES ]
    UNICODE_FENCEPOSTS = [ unicode(s) for s in ANSI_FENCEPOSTS ]
    IMAGE_FENCEPOSTS   = ANSI_FENCEPOSTS + [ _generate_test_string(size) for size in LARGE_FENCEPOST_SIZES ]

    def __init__(self, method_name, connection_string):
        unittest.TestCase.__init__(self, method_name)
        self.connection_string = connection_string

    def get_sqlserver_version(self):
        """"""
        Returns the major version: 8-->2000, 9-->2005, 10-->2008
        """"""
        self.cursor.execute(""exec master..xp_msver 'ProductVersion'"")
        row = self.cursor.fetchone()
        return int(row.Character_Value.split('.', 1)[0])

    def setUp(self):
        self.cnxn   = pyodbc.connect(self.connection_string)
        self.cursor = self.cnxn.cursor()

        for i in range(3):
            try:
                self.cursor.execute(""drop table t%d"" % i)
                self.cnxn.commit()
            except:
                pass

        for i in range(3):
            try:
                self.cursor.execute(""drop procedure proc%d"" % i)
                self.cnxn.commit()
            except:
                pass

        try:
            self.cursor.execute('drop function func1')
            self.cnxn.commit()
        except:
            pass

        self.cnxn.rollback()

    def tearDown(self):
        try:
            self.cursor.close()
            self.cnxn.close()
        except:
            # If we've already closed the cursor or connection, exceptions are thrown.
            pass

    def test_binary_type(self):
        if sys.hexversion >= 0x02060000:
            self.assertIs(pyodbc.BINARY, bytearray)
        else:
            self.assertIs(pyodbc.BINARY, buffer)

    def test_multiple_bindings(self):
        ""More than one bind and select on a cursor""
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t1 values (?)"", 2)
        self.cursor.execute(""insert into t1 values (?)"", 3)
        for i in range(3):
            self.cursor.execute(""select n from t1 where n < ?"", 10)
            self.cursor.execute(""select n from t1 where n < 3"")
        

    def test_different_bindings(self):
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""create table t2(d datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t2 values (?)"", datetime.now())

    def test_drivers(self):
        p = pyodbc.drivers()
        self.assertTrue(isinstance(p, list))

    def test_datasources(self):
        p = pyodbc.dataSources()
        self.assertTrue(isinstance(p, dict))

    def test_getinfo_string(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CATALOG_NAME_SEPARATOR)
        self.assertTrue(isinstance(value, str))

    def test_getinfo_bool(self):
        value = self.cnxn.getinfo(pyodbc.SQL_ACCESSIBLE_TABLES)
        self.assertTrue(isinstance(value, bool))

    def test_getinfo_int(self):
        value = self.cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)
        self.assertTrue(isinstance(value, (int, long)))

    def test_getinfo_smallint(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CONCAT_NULL_BEHAVIOR)
        self.assertTrue(isinstance(value, int))

    def test_noscan(self):
        self.assertEqual(self.cursor.noscan, False)
        self.cursor.noscan = True
        self.assertEqual(self.cursor.noscan, True)

    def test_guid(self):
        self.cursor.execute(""create table t1(g1 uniqueidentifier)"")
        self.cursor.execute(""insert into t1 values (newid())"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(len(v), 36)

    def test_nextset(self):
        self.cursor.execute(""create table t1(i int)"")
        for i in range(4):
            self.cursor.execute(""insert into t1(i) values(?)"", i)

        self.cursor.execute(""select i from t1 where i < 2 order by i; select i from t1 where i >= 2 order by i"")
        
        for i, row in enumerate(self.cursor):
            self.assertEqual(i, row.i)

        self.assertEqual(self.cursor.nextset(), True)

        for i, row in enumerate(self.cursor):
            self.assertEqual(i + 2, row.i)

    def test_fixed_unicode(self):
        value = u""t\xebsting""
        self.cursor.execute(""create table t1(s nchar(7))"")
        self.cursor.execute(""insert into t1 values(?)"", u""t\xebsting"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), unicode)
        self.assertEqual(len(v), len(value)) # If we alloc'd wrong, the test below might work because of an embedded NULL
        self.assertEqual(v, value)


    def _test_strtype(self, sqltype, value, resulttype=None, colsize=None):
        """"""
        The implementation for string, Unicode, and binary tests.
        """"""
        assert colsize is None or isinstance(colsize, int), colsize
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        if resulttype is None:
            resulttype = type(value)

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), resulttype)

        if value is not None:
            self.assertEqual(len(v), len(value))

        # To allow buffer --> db --> bytearray tests, always convert the input to the expected result type before
        # comparing.
        if type(value) is not resulttype:
            value = resulttype(value)

        self.assertEqual(v, value)


    def _test_strliketype(self, sqltype, value, resulttype=None, colsize=None):
        """"""
        The implementation for text, image, ntext, and binary.

        These types do not support comparison operators.
        """"""
        assert colsize is None or isinstance(colsize, int), colsize
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        if resulttype is None:
            resulttype = type(value)

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), resulttype)

        if value is not None:
            self.assertEqual(len(v), len(value))

        # To allow buffer --> db --> bytearray tests, always convert the input to the expected result type before
        # comparing.
        if type(value) is not resulttype:
            value = resulttype(value)

        self.assertEqual(v, value)


    #
    # varchar
    #

    def test_varchar_null(self):
        self._test_strtype('varchar', None, colsize=100)

    # Generate a test for each fencepost size: test_varchar_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('varchar', value, colsize=len(value))
        return t
    for value in ANSI_FENCEPOSTS:
        locals()['test_varchar_%s' % len(value)] = _maketest(value)

    def test_varchar_many(self):
        self.cursor.execute(""create table t1(c1 varchar(300), c2 varchar(300), c3 varchar(300))"")

        v1 = 'ABCDEFGHIJ' * 30
        v2 = '0123456789' * 30
        v3 = '9876543210' * 30

        self.cursor.execute(""insert into t1(c1, c2, c3) values (?,?,?)"", v1, v2, v3);
        row = self.cursor.execute(""select c1, c2, c3, len(c1) as l1, len(c2) as l2, len(c3) as l3 from t1"").fetchone()

        self.assertEqual(v1, row.c1)
        self.assertEqual(v2, row.c2)
        self.assertEqual(v3, row.c3)

    def test_varchar_upperlatin(self):
        self._test_strtype('varchar', '�')

    #
    # unicode
    #

    def test_unicode_null(self):
        self._test_strtype('nvarchar', None, colsize=100)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('nvarchar', value, colsize=len(value))
        return t
    for value in UNICODE_FENCEPOSTS:
        locals()['test_unicode_%s' % len(value)] = _maketest(value)

    def test_unicode_upperlatin(self):
        self._test_strtype('nvarchar', u'�')

    def test_unicode_longmax(self):
        # Issue 188:	Segfault when fetching NVARCHAR(MAX) data over 511 bytes

        ver = self.get_sqlserver_version()
        if ver < 9:            # 2005+
            return              # so pass / ignore
        self.cursor.execute(""select cast(replicate(N'x', 512) as nvarchar(max))"")

    def test_unicode_bind(self):
        value = u'test'
        v = self.cursor.execute(""select ?"", value).fetchone()[0]
        self.assertEqual(value, v)
        
    #
    # binary
    #

    def test_binary_null(self):
        # FreeTDS does not support SQLDescribeParam, so we must specifically tell it when we are inserting
        # a NULL into a binary column.
        self.cursor.execute(""create table t1(n varbinary(10))"")
        self.cursor.execute(""insert into t1 values (?)"", pyodbc.BinaryNull);

    # buffer

    def _maketest(value):
        def t(self):
            self._test_strtype('varbinary', buffer(value), resulttype=pyodbc.BINARY, colsize=len(value))
        return t
    for value in ANSI_FENCEPOSTS:
        locals()['test_binary_buffer_%s' % len(value)] = _maketest(value)

    # bytearray

    if sys.hexversion >= 0x02060000:
        def _maketest(value):
            def t(self):
                self._test_strtype('varbinary', bytearray(value), colsize=len(value))
            return t
        for value in ANSI_FENCEPOSTS:
            locals()['test_binary_bytearray_%s' % len(value)] = _maketest(value)

    #
    # image
    #

    def test_image_null(self):
        self._test_strliketype('image', None, type(None))

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strliketype('image', buffer(value), pyodbc.BINARY)
        return t
    for value in IMAGE_FENCEPOSTS:
        locals()['test_image_buffer_%s' % len(value)] = _maketest(value)

    if sys.hexversion >= 0x02060000:
        # Python 2.6+ supports bytearray, which pyodbc considers varbinary.
        
        # Generate a test for each fencepost size: test_unicode_0, etc.
        def _maketest(value):
            def t(self):
                self._test_strtype('image', bytearray(value))
            return t
        for value in IMAGE_FENCEPOSTS:
            locals()['test_image_bytearray_%s' % len(value)] = _maketest(value)

    def test_image_upperlatin(self):
        self._test_strliketype('image', buffer('�'), pyodbc.BINARY)

    #
    # text
    #

    # def test_empty_text(self):
    #     self._test_strliketype('text', bytearray(''))

    def test_null_text(self):
        self._test_strliketype('text', None, type(None))

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strliketype('text', value)
        return t
    for value in ANSI_FENCEPOSTS:
        locals()['test_text_buffer_%s' % len(value)] = _maketest(value)

    def test_text_upperlatin(self):
        self._test_strliketype('text', '�')

    #
    # bit
    #

    def test_bit(self):
        value = True
        self.cursor.execute(""create table t1(b bit)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        v = self.cursor.execute(""select b from t1"").fetchone()[0]
        self.assertEqual(type(v), bool)
        self.assertEqual(v, value)

    #
    # decimal
    #

    def _decimal(self, precision, scale, negative):
        # From test provided by planders (thanks!) in Issue 91

        self.cursor.execute(""create table t1(d decimal(%s, %s))"" % (precision, scale))

        # Construct a decimal that uses the maximum precision and scale.
        decStr = '9' * (precision - scale)
        if scale:
            decStr = decStr + ""."" + '9' * scale
        if negative:
            decStr = ""-"" + decStr
        value = Decimal(decStr)

        self.cursor.execute(""insert into t1 values(?)"", value)

        v = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(v, value)

    def _maketest(p, s, n):
        def t(self):
            self._decimal(p, s, n)
        return t
    for (p, s, n) in [ (1,  0,  False),
                       (1,  0,  True),
                       (6,  0,  False),
                       (6,  2,  False),
                       (6,  4,  True),
                       (6,  6,  True),
                       (38, 0,  False),
                       (38, 10, False),
                       (38, 38, False),
                       (38, 0,  True),
                       (38, 10, True),
                       (38, 38, True) ]:
        locals()['test_decimal_%s_%s_%s' % (p, s, n and 'n' or 'p')] = _maketest(p, s, n)


    def test_decimal_e(self):
        """"""Ensure exponential notation decimals are properly handled""""""
        value = Decimal((0, (1, 2, 3), 5)) # prints as 1.23E+7
        self.cursor.execute(""create table t1(d decimal(10, 2))"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_subquery_params(self):
        """"""Ensure parameter markers work in a subquery""""""
        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        row = self.cursor.execute(""""""
                                  select x.id
                                  from (
                                    select id
                                    from t1
                                    where s = ?
                                      and id between ? and ?
                                   ) x
                                   """""", 'test', 1, 10).fetchone()
        self.assertNotEqual(row, None)
        self.assertEqual(row[0], 1)

    def _exec(self):
        self.cursor.execute(self.sql)
        
    def test_close_cnxn(self):
        """"""Make sure using a Cursor after closing its connection doesn't crash.""""""

        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        self.cursor.execute(""select * from t1"")

        self.cnxn.close()
        
        # Now that the connection is closed, we expect an exception.  (If the code attempts to use
        # the HSTMT, we'll get an access violation instead.)
        self.sql = ""select * from t1""
        self.assertRaises(pyodbc.ProgrammingError, self._exec)

    def test_empty_string(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", """")

    def test_fixed_str(self):
        value = ""testing""
        self.cursor.execute(""create table t1(s char(7))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(len(v), len(value)) # If we alloc'd wrong, the test below might work because of an embedded NULL
        self.assertEqual(v, value)

    def test_empty_unicode(self):
        self.cursor.execute(""create table t1(s nvarchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", u"""")

    def test_unicode_query(self):
        self.cursor.execute(u""select 1"")
        
    def test_negative_row_index(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", ""1"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row[0], ""1"")
        self.assertEqual(row[-1], ""1"")

    def test_version(self):
        self.assertEqual(3, len(pyodbc.version.split('.'))) # 1.3.1 etc.

    #
    # date, time, datetime
    #

    def test_datetime(self):
        value = datetime(2007, 1, 15, 3, 4, 5)

        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(value, result)

    def test_datetime_fraction(self):
        # SQL Server supports milliseconds, but Python's datetime supports nanoseconds, so the most granular datetime
        # supported is xxx000.

        value = datetime(2007, 1, 15, 3, 4, 5, 123000)
     
        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
     
        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(result, value)

    def test_datetime_fraction_rounded(self):
        # SQL Server supports milliseconds, but Python's datetime supports nanoseconds.  pyodbc rounds down to what the
        # database supports.

        full    = datetime(2007, 1, 15, 3, 4, 5, 123456)
        rounded = datetime(2007, 1, 15, 3, 4, 5, 123000)
     
        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", full)
     
        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(result), datetime)
        self.assertEqual(result, rounded)

    #
    # ints and floats
    #

    def test_int(self):
        # Issue 226: Failure if there is more than one int?
        value1 =  1234
        value2 = -1234
        self.cursor.execute(""create table t1(n1 int, n2 int)"")
        self.cursor.execute(""insert into t1 values (?, ?)"", value1, value2)
        row = self.cursor.execute(""select n1, n2 from t1"").fetchone()
        self.assertEqual(row.n1, value1)
        self.assertEqual(row.n2, value2)

    def test_negative_int(self):
        value = -1
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_bigint(self):
        input = 3000000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_float(self):
        value = 1234.567
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_float(self):
        value = -200
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result  = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(value, result)


    #
    # stored procedures
    #

    # def test_callproc(self):
    #     ""callproc with a simple input-only stored procedure""
    #     pass

    def test_sp_results(self):
        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              select top 10 name, id, xtype, refdate
              from sysobjects
            """""")
        rows = self.cursor.execute(""exec proc1"").fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)


    def test_sp_results_from_temp(self):

        # Note: I've used ""set nocount on"" so that we don't get the number of rows deleted from #tmptable.
        # If you don't do this, you'd need to call nextset() once to skip it.

        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              set nocount on
              select top 10 name, id, xtype, refdate
              into #tmptable
              from sysobjects

              select * from #tmptable
            """""")
        self.cursor.execute(""exec proc1"")
        self.assertTrue(self.cursor.description is not None)
        self.assertTrue(len(self.cursor.description) == 4)

        rows = self.cursor.fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)


    def test_sp_results_from_vartbl(self):
        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              set nocount on
              declare @tmptbl table(name varchar(100), id int, xtype varchar(4), refdate datetime)

              insert into @tmptbl
              select top 10 name, id, xtype, refdate
              from sysobjects

              select * from @tmptbl
            """""")
        self.cursor.execute(""exec proc1"")
        rows = self.cursor.fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)

    def test_sp_with_dates(self):
        # Reported in the forums that passing two datetimes to a stored procedure doesn't work.
        self.cursor.execute(
            """"""
            if exists (select * from dbo.sysobjects where id = object_id(N'[test_sp]') and OBJECTPROPERTY(id, N'IsProcedure') = 1)
              drop procedure [dbo].[test_sp]
            """""")
        self.cursor.execute(
            """"""
            create procedure test_sp(@d1 datetime, @d2 datetime)
            AS
              declare @d as int
              set @d = datediff(year, @d1, @d2)
              select @d
            """""")
        self.cursor.execute(""exec test_sp ?, ?"", datetime.now(), datetime.now())
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(rows[0][0] == 0)   # 0 years apart

    def test_sp_with_none(self):
        # Reported in the forums that passing None caused an error.
        self.cursor.execute(
            """"""
            if exists (select * from dbo.sysobjects where id = object_id(N'[test_sp]') and OBJECTPROPERTY(id, N'IsProcedure') = 1)
              drop procedure [dbo].[test_sp]
            """""")
        self.cursor.execute(
            """"""
            create procedure test_sp(@x varchar(20))
            AS
              declare @y varchar(20)
              set @y = @x
              select @y
            """""")
        self.cursor.execute(""exec test_sp ?"", None)
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(rows[0][0] == None)   # 0 years apart
        

    #
    # rowcount
    #

    def test_rowcount_delete(self):
        self.assertEqual(self.cursor.rowcount, -1)
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, count)

    def test_rowcount_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.  On the other hand, we could hardcode a
        zero return value.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, 0)

    def test_rowcount_select(self):
        """"""
        Ensure Cursor.rowcount is set properly after a select statement.

        pyodbc calls SQLRowCount after each execute and sets Cursor.rowcount, but SQL Server 2005 returns -1 after a
        select statement, so we'll test for that behavior.  This is valid behavior according to the DB API
        specification, but people don't seem to like it.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""select * from t1"")
        self.assertEqual(self.cursor.rowcount, -1)

        rows = self.cursor.fetchall()
        self.assertEqual(len(rows), count)
        self.assertEqual(self.cursor.rowcount, -1)

    #
    # always return Cursor
    #

    # In the 2.0.x branch, Cursor.execute sometimes returned the cursor and sometimes the rowcount.  This proved very
    # confusing when things went wrong and added very little value even when things went right since users could always
    # use: cursor.execute(""..."").rowcount

    def test_retcursor_delete(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_select(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""select * from t1"")
        self.assertEqual(v, self.cursor)

    #
    # misc
    #

    def test_lower_case(self):
        ""Ensure pyodbc.lowercase forces returned column names to lowercase.""

        # Has to be set before creating the cursor, so we must recreate self.cursor.

        pyodbc.lowercase = True
        self.cursor = self.cnxn.cursor()

        self.cursor.execute(""create table t1(Abc int, dEf int)"")
        self.cursor.execute(""select * from t1"")

        names = [ t[0] for t in self.cursor.description ]
        names.sort()

        self.assertEqual(names, [ ""abc"", ""def"" ])

        # Put it back so other tests don't fail.
        pyodbc.lowercase = False
        
    def test_row_description(self):
        """"""
        Ensure Cursor.description is accessible as Row.cursor_description.
        """"""
        self.cursor = self.cnxn.cursor()
        self.cursor.execute(""create table t1(a int, b char(3))"")
        self.cnxn.commit()
        self.cursor.execute(""insert into t1 values(1, 'abc')"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        self.assertEqual(self.cursor.description, row.cursor_description)
        

    def test_temp_select(self):
        # A project was failing to create temporary tables via select into.
        self.cursor.execute(""create table t1(s char(7))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(v, ""testing"")

        self.cursor.execute(""select s into t2 from t1"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(v, ""testing"")


    def test_money(self):
        d = Decimal('123456.78')
        self.cursor.execute(""create table t1(i int identity(1,1), m money)"")
        self.cursor.execute(""insert into t1(m) values (?)"", d)
        v = self.cursor.execute(""select m from t1"").fetchone()[0]
        self.assertEqual(v, d)


    def test_executemany(self):
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (i, str(i)) for i in range(1, 6) ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])


    def test_executemany_one(self):
        ""Pass executemany a single sequence""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, ""test"") ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])
        

    def test_executemany_failure(self):
        """"""
        Ensure that an exception is raised if one query in an executemany fails.
        """"""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, 'good'),
                   ('error', 'not an int'),
                   (3, 'good') ]
        
        self.assertRaises(pyodbc.Error, self.cursor.executemany, ""insert into t1(a, b) value (?, ?)"", params)

        
    def test_row_slicing(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = row[:]
        self.assertTrue(result is row)

        result = row[:-1]
        self.assertEqual(result, (1,2,3))

        result = row[0:4]
        self.assertTrue(result is row)


    def test_row_repr(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = str(row)
        self.assertEqual(result, ""(1, 2, 3, 4)"")

        result = str(row[:-1])
        self.assertEqual(result, ""(1, 2, 3)"")

        result = str(row[:1])
        self.assertEqual(result, ""(1,)"")


    def test_concatenation(self):
        v2 = '0123456789' * 30
        v3 = '9876543210' * 30

        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(300), c3 varchar(300))"")
        self.cursor.execute(""insert into t1(c2, c3) values (?,?)"", v2, v3)

        row = self.cursor.execute(""select c2, c3, c2 + c3 as both from t1"").fetchone()

        self.assertEqual(row.both, v2 + v3)

    def test_view_select(self):
        # Reported in forum: Can't select from a view?  I think I do this a lot, but another test never hurts.

        # Create a table (t1) with 3 rows and a view (t2) into it.
        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(50))"")
        for i in range(3):
            self.cursor.execute(""insert into t1(c2) values (?)"", ""string%s"" % i)
        self.cursor.execute(""create view t2 as select * from t1"")

        # Select from the view
        self.cursor.execute(""select * from t2"")
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(len(rows) == 3)

    def test_autocommit(self):
        self.assertEqual(self.cnxn.autocommit, False)

        othercnxn = pyodbc.connect(self.connection_string, autocommit=True)
        self.assertEqual(othercnxn.autocommit, True)

        othercnxn.autocommit = False
        self.assertEqual(othercnxn.autocommit, False)

    def test_unicode_results(self):
        ""Ensure unicode_results forces Unicode""
        othercnxn = pyodbc.connect(self.connection_string, unicode_results=True)
        othercursor = othercnxn.cursor()

        # ANSI data in an ANSI column ...
        othercursor.execute(""create table t1(s varchar(20))"")
        othercursor.execute(""insert into t1 values(?)"", 'test')

        # ... should be returned as Unicode
        value = othercursor.execute(""select s from t1"").fetchone()[0]
        self.assertEqual(value, u'test')


    def test_sqlserver_callproc(self):
        try:
            self.cursor.execute(""drop procedure pyodbctest"")
            self.cnxn.commit()
        except:
            pass

        self.cursor.execute(""create table t1(s varchar(10))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")

        self.cursor.execute(""""""
                            create procedure pyodbctest @var1 varchar(32)
                            as 
                            begin 
                              select s 
                              from t1 
                            return 
                            end
                            """""")
        self.cnxn.commit()

        # for row in self.cursor.procedureColumns('pyodbctest'):
        #     print row.procedure_name, row.column_name, row.column_type, row.type_name

        self.cursor.execute(""exec pyodbctest 'hi'"")

        # print self.cursor.description
        # for row in self.cursor:
        #     print row.s

    def test_skip(self):
        # Insert 1, 2, and 3.  Fetch 1, skip 2, fetch 3.

        self.cursor.execute(""create table t1(id int)"");
        for i in range(1, 5):
            self.cursor.execute(""insert into t1 values(?)"", i)
        self.cursor.execute(""select id from t1 order by id"")
        self.assertEqual(self.cursor.fetchone()[0], 1)
        self.cursor.skip(2)
        self.assertEqual(self.cursor.fetchone()[0], 4)

    def test_timeout(self):
        self.assertEqual(self.cnxn.timeout, 0) # defaults to zero (off)

        self.cnxn.timeout = 30
        self.assertEqual(self.cnxn.timeout, 30)

        self.cnxn.timeout = 0
        self.assertEqual(self.cnxn.timeout, 0)

    def test_sets_execute(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.execute(""insert into t1 (word) VALUES (?)"", [words])

        self.assertRaises(pyodbc.ProgrammingError, f)

    def test_sets_executemany(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.executemany(""insert into t1 (word) values (?)"", [words])
            
        self.assertRaises(TypeError, f)

    def test_row_execute(self):
        ""Ensure we can use a Row object as a parameter to execute""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, 'a')"")
        row = self.cursor.execute(""select n, s from t1"").fetchone()
        self.assertNotEqual(row, None)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.execute(""insert into t2 values (?, ?)"", row)
        
    def test_row_executemany(self):
        ""Ensure we can use a Row object as a parameter to executemany""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")

        for i in range(3):
            self.cursor.execute(""insert into t1 values (?, ?)"", i, chr(ord('a')+i))

        rows = self.cursor.execute(""select n, s from t1"").fetchall()
        self.assertNotEqual(len(rows), 0)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.executemany(""insert into t2 values (?, ?)"", rows)
        
    def test_description(self):
        ""Ensure cursor.description is correct""

        self.cursor.execute(""create table t1(n int, s varchar(8), d decimal(5,2))"")
        self.cursor.execute(""insert into t1 values (1, 'abc', '1.23')"")
        self.cursor.execute(""select * from t1"")

        # (I'm not sure the precision of an int is constant across different versions, bits, so I'm hand checking the
        # items I do know.

        # int
        t = self.cursor.description[0]
        self.assertEqual(t[0], 'n')
        self.assertEqual(t[1], int)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # varchar(8)
        t = self.cursor.description[1]
        self.assertEqual(t[0], 's')
        self.assertEqual(t[1], str)
        self.assertEqual(t[4], 8)       # precision
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # decimal(5, 2)
        t = self.cursor.description[2]
        self.assertEqual(t[0], 'd')
        self.assertEqual(t[1], Decimal)
        self.assertEqual(t[4], 5)       # precision
        self.assertEqual(t[5], 2)       # scale
        self.assertEqual(t[6], True)    # nullable

        
    def test_none_param(self):
        ""Ensure None can be used for params other than the first""
        # Some driver/db versions would fail if NULL was not the first parameter because SQLDescribeParam (only used
        # with NULL) could not be used after the first call to SQLBindParameter.  This means None always worked for the
        # first column, but did not work for later columns.
        #
        # If SQLDescribeParam doesn't work, pyodbc would use VARCHAR which almost always worked.  However,
        # binary/varbinary won't allow an implicit conversion.

        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'xyzzy')"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row.n, 1)
        self.assertEqual(type(row.s), str)

        self.cursor.execute(""update t1 set n=?, s=?"", 2, None)
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row.n, 2)
        self.assertEqual(row.s, None)


    def test_output_conversion(self):
        def convert(value):
            # `value` will be a string.  We'll simply add an X at the beginning at the end.
            return 'X' + value + 'X'
        self.cnxn.add_output_converter(pyodbc.SQL_VARCHAR, convert)
        self.cursor.execute(""create table t1(n int, v varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, '123.45')"")
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, 'X123.45X')

        # Now clear the conversions and try again.  There should be no Xs this time.
        self.cnxn.clear_output_converters()
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, '123.45')


    def test_too_large(self):
        """"""Ensure error raised if insert fails due to truncation""""""
        value = 'x' * 1000
        self.cursor.execute(""create table t1(s varchar(800))"")
        def test():
            self.cursor.execute(""insert into t1 values (?)"", value)
        self.assertRaises(pyodbc.DataError, test)

    def test_geometry_null_insert(self):
        def convert(value):
            return value

        self.cnxn.add_output_converter(-151, convert) # -151 is SQL Server's geometry
        self.cursor.execute(""create table t1(n int, v geometry)"")
        self.cursor.execute(""insert into t1 values (?, ?)"", 1, None)
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, None)
        self.cnxn.clear_output_converters()

    def test_login_timeout(self):
        # This can only test setting since there isn't a way to cause it to block on the server side.
        cnxns = pyodbc.connect(self.connection_string, timeout=2)

    def test_row_equal(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test')"")
        row1 = self.cursor.execute(""select n, s from t1"").fetchone()
        row2 = self.cursor.execute(""select n, s from t1"").fetchone()
        b = (row1 == row2)
        self.assertEqual(b, True)

    def test_row_gtlt(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test1')"")
        self.cursor.execute(""insert into t1 values (1, 'test2')"")
        rows = self.cursor.execute(""select n, s from t1 order by s"").fetchall()
        self.assertTrue(rows[0] < rows[1])
        self.assertTrue(rows[0] <= rows[1])
        self.assertTrue(rows[1] > rows[0])
        self.assertTrue(rows[1] >= rows[0])
        self.assertTrue(rows[0] != rows[1])

        rows = list(rows)
        rows.sort() # uses <
        
    def test_context_manager_success(self):

        self.cursor.execute(""create table t1(n int)"")
        self.cnxn.commit()

        try:
            with pyodbc.connect(self.connection_string) as cnxn:
                cursor = cnxn.cursor()
                cursor.execute(""insert into t1 values (1)"")
        except Exception:
            pass

        cnxn = None
        cursor = None

        rows = self.cursor.execute(""select n from t1"").fetchall()
        self.assertEqual(len(rows), 1)
        self.assertEqual(rows[0][0], 1)


    def test_untyped_none(self):
        # From issue 129
        value = self.cursor.execute(""select ?"", None).fetchone()[0]
        self.assertEqual(value, None)
        
    def test_large_update_nodata(self):
        self.cursor.execute('create table t1(a varbinary(max))')
        hundredkb = bytearray('x'*100*1024)
        self.cursor.execute('update t1 set a=? where 1=0', (hundredkb,))

    def test_func_param(self):
        self.cursor.execute('''
                            create function func1 (@testparam varchar(4)) 
                            returns @rettest table (param varchar(4))
                            as 
                            begin
                                insert @rettest
                                select @testparam
                                return
                            end
                            ''')
        self.cnxn.commit()
        value = self.cursor.execute(""select * from func1(?)"", 'test').fetchone()[0]
        self.assertEqual(value, 'test')
        
    def test_no_fetch(self):
        # Issue 89 with FreeTDS: Multiple selects (or catalog functions that issue selects) without fetches seem to
        # confuse the driver.
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')

def main():
    from optparse import OptionParser
    parser = OptionParser(usage=usage)
    parser.add_option(""-v"", ""--verbose"", action=""count"", help=""Increment test verbosity (can be used multiple times)"")
    parser.add_option(""-d"", ""--debug"", action=""store_true"", default=False, help=""Print debugging items"")
    parser.add_option(""-t"", ""--test"", help=""Run only the named test"")

    (options, args) = parser.parse_args()

    if len(args) > 1:
        parser.error('Only one argument is allowed.  Do you need quotes around the connection string?')

    if not args:
        connection_string = load_setup_connection_string('freetdstests')

        if not connection_string:
            parser.print_help()
            raise SystemExit()
    else:
        connection_string = args[0]

    cnxn = pyodbc.connect(connection_string)
    print_library_info(cnxn)
    cnxn.close()

    suite = load_tests(FreeTDSTestCase, options.test, connection_string)

    testRunner = unittest.TextTestRunner(verbosity=options.verbose)
    result = testRunner.run(suite)


if __name__ == '__main__':

    # Add the build directory to the path so we're testing the latest build, not the installed version.

    add_to_path()

    import pyodbc
    main()
/n/n/ntests2/informixtests.py/n/n#!/usr/bin/python
# -*- coding: latin-1 -*-

usage = """"""\
usage: %prog [options] connection_string

Unit tests for Informix DB.  To use, pass a connection string as the parameter.
The tests will create and drop tables t1 and t2 as necessary.

These run using the version from the 'build' directory, not the version
installed into the Python directories.  You must run python setup.py build
before running the tests.

You can also put the connection string into a tmp/setup.cfg file like so:

  [informixtests]
  connection-string=DRIVER={IBM INFORMIX ODBC DRIVER (64-bit)};SERVER=localhost;UID=uid;PWD=pwd;DATABASE=db
""""""

import sys, os, re
import unittest
from decimal import Decimal
from datetime import datetime, date, time
from os.path import join, getsize, dirname, abspath
from testutils import *

_TESTSTR = '0123456789-abcdefghijklmnopqrstuvwxyz-'

def _generate_test_string(length):
    """"""
    Returns a string of `length` characters, constructed by repeating _TESTSTR as necessary.

    To enhance performance, there are 3 ways data is read, based on the length of the value, so most data types are
    tested with 3 lengths.  This function helps us generate the test data.

    We use a recognizable data set instead of a single character to make it less likely that ""overlap"" errors will
    be hidden and to help us manually identify where a break occurs.
    """"""
    if length <= len(_TESTSTR):
        return _TESTSTR[:length]

    c = (length + len(_TESTSTR)-1) / len(_TESTSTR)
    v = _TESTSTR * c
    return v[:length]

class InformixTestCase(unittest.TestCase):

    SMALL_FENCEPOST_SIZES = [ 0, 1, 255, 256, 510, 511, 512, 1023, 1024, 2047, 2048, 4000 ]
    LARGE_FENCEPOST_SIZES = [ 4095, 4096, 4097, 10 * 1024, 20 * 1024 ]

    ANSI_FENCEPOSTS    = [ _generate_test_string(size) for size in SMALL_FENCEPOST_SIZES ]
    UNICODE_FENCEPOSTS = [ unicode(s) for s in ANSI_FENCEPOSTS ]
    IMAGE_FENCEPOSTS   = ANSI_FENCEPOSTS + [ _generate_test_string(size) for size in LARGE_FENCEPOST_SIZES ]

    def __init__(self, method_name, connection_string):
        unittest.TestCase.__init__(self, method_name)
        self.connection_string = connection_string

    def setUp(self):
        self.cnxn   = pyodbc.connect(self.connection_string)
        self.cursor = self.cnxn.cursor()

        for i in range(3):
            try:
                self.cursor.execute(""drop table t%d"" % i)
                self.cnxn.commit()
            except:
                pass

        for i in range(3):
            try:
                self.cursor.execute(""drop procedure proc%d"" % i)
                self.cnxn.commit()
            except:
                pass

        try:
            self.cursor.execute('drop function func1')
            self.cnxn.commit()
        except:
            pass

        self.cnxn.rollback()

    def tearDown(self):
        try:
            self.cursor.close()
            self.cnxn.close()
        except:
            # If we've already closed the cursor or connection, exceptions are thrown.
            pass

    def test_multiple_bindings(self):
        ""More than one bind and select on a cursor""
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t1 values (?)"", 2)
        self.cursor.execute(""insert into t1 values (?)"", 3)
        for i in range(3):
            self.cursor.execute(""select n from t1 where n < ?"", 10)
            self.cursor.execute(""select n from t1 where n < 3"")
        

    def test_different_bindings(self):
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""create table t2(d datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t2 values (?)"", datetime.now())

    def test_drivers(self):
        p = pyodbc.drivers()
        self.assertTrue(isinstance(p, list))

    def test_datasources(self):
        p = pyodbc.dataSources()
        self.assertTrue(isinstance(p, dict))

    def test_getinfo_string(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CATALOG_NAME_SEPARATOR)
        self.assertTrue(isinstance(value, str))

    def test_getinfo_bool(self):
        value = self.cnxn.getinfo(pyodbc.SQL_ACCESSIBLE_TABLES)
        self.assertTrue(isinstance(value, bool))

    def test_getinfo_int(self):
        value = self.cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)
        self.assertTrue(isinstance(value, (int, long)))

    def test_getinfo_smallint(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CONCAT_NULL_BEHAVIOR)
        self.assertTrue(isinstance(value, int))

    def test_noscan(self):
        self.assertEqual(self.cursor.noscan, False)
        self.cursor.noscan = True
        self.assertEqual(self.cursor.noscan, True)

    def test_guid(self):
        self.cursor.execute(""create table t1(g1 uniqueidentifier)"")
        self.cursor.execute(""insert into t1 values (newid())"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(len(v), 36)

    def test_nextset(self):
        self.cursor.execute(""create table t1(i int)"")
        for i in range(4):
            self.cursor.execute(""insert into t1(i) values(?)"", i)

        self.cursor.execute(""select i from t1 where i < 2 order by i; select i from t1 where i >= 2 order by i"")
        
        for i, row in enumerate(self.cursor):
            self.assertEqual(i, row.i)

        self.assertEqual(self.cursor.nextset(), True)

        for i, row in enumerate(self.cursor):
            self.assertEqual(i + 2, row.i)

    def test_fixed_unicode(self):
        value = u""t\xebsting""
        self.cursor.execute(""create table t1(s nchar(7))"")
        self.cursor.execute(""insert into t1 values(?)"", u""t\xebsting"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), unicode)
        self.assertEqual(len(v), len(value)) # If we alloc'd wrong, the test below might work because of an embedded NULL
        self.assertEqual(v, value)


    def _test_strtype(self, sqltype, value, colsize=None):
        """"""
        The implementation for string, Unicode, and binary tests.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)

        # Reported by Andy Hochhaus in the pyodbc group: In 2.1.7 and earlier, a hardcoded length of 255 was used to
        # determine whether a parameter was bound as a SQL_VARCHAR or SQL_LONGVARCHAR.  Apparently SQL Server chokes if
        # we bind as a SQL_LONGVARCHAR and the target column size is 8000 or less, which is considers just SQL_VARCHAR.
        # This means binding a 256 character value would cause problems if compared with a VARCHAR column under
        # 8001. We now use SQLGetTypeInfo to determine the time to switch.
        #
        # [42000] [Microsoft][SQL Server Native Client 10.0][SQL Server]The data types varchar and text are incompatible in the equal to operator.

        self.cursor.execute(""select * from t1 where s=?"", value)


    def _test_strliketype(self, sqltype, value, colsize=None):
        """"""
        The implementation for text, image, ntext, and binary.

        These types do not support comparison operators.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)


    #
    # varchar
    #

    def test_varchar_null(self):
        self._test_strtype('varchar', None, 100)

    # Generate a test for each fencepost size: test_varchar_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('varchar', value, len(value))
        return t
    for value in ANSI_FENCEPOSTS:
        locals()['test_varchar_%s' % len(value)] = _maketest(value)

    def test_varchar_many(self):
        self.cursor.execute(""create table t1(c1 varchar(300), c2 varchar(300), c3 varchar(300))"")

        v1 = 'ABCDEFGHIJ' * 30
        v2 = '0123456789' * 30
        v3 = '9876543210' * 30

        self.cursor.execute(""insert into t1(c1, c2, c3) values (?,?,?)"", v1, v2, v3);
        row = self.cursor.execute(""select c1, c2, c3, len(c1) as l1, len(c2) as l2, len(c3) as l3 from t1"").fetchone()

        self.assertEqual(v1, row.c1)
        self.assertEqual(v2, row.c2)
        self.assertEqual(v3, row.c3)

    def test_varchar_upperlatin(self):
        self._test_strtype('varchar', '�')

    #
    # unicode
    #

    def test_unicode_null(self):
        self._test_strtype('nvarchar', None, 100)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('nvarchar', value, len(value))
        return t
    for value in UNICODE_FENCEPOSTS:
        locals()['test_unicode_%s' % len(value)] = _maketest(value)

    def test_unicode_upperlatin(self):
        self._test_strtype('varchar', '�')

    #
    # binary
    #

    def test_null_binary(self):
        self._test_strtype('varbinary', None, 100)
     
    def test_large_null_binary(self):
        # Bug 1575064
        self._test_strtype('varbinary', None, 4000)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('varbinary', buffer(value), len(value))
        return t
    for value in ANSI_FENCEPOSTS:
        locals()['test_binary_%s' % len(value)] = _maketest(value)

    #
    # image
    #

    def test_image_null(self):
        self._test_strliketype('image', None)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strliketype('image', buffer(value))
        return t
    for value in IMAGE_FENCEPOSTS:
        locals()['test_image_%s' % len(value)] = _maketest(value)

    def test_image_upperlatin(self):
        self._test_strliketype('image', buffer('�'))

    #
    # text
    #

    # def test_empty_text(self):
    #     self._test_strliketype('text', buffer(''))

    def test_null_text(self):
        self._test_strliketype('text', None)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strliketype('text', value)
        return t
    for value in ANSI_FENCEPOSTS:
        locals()['test_text_%s' % len(value)] = _maketest(value)

    def test_text_upperlatin(self):
        self._test_strliketype('text', '�')

    #
    # bit
    #

    def test_bit(self):
        value = True
        self.cursor.execute(""create table t1(b bit)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        v = self.cursor.execute(""select b from t1"").fetchone()[0]
        self.assertEqual(type(v), bool)
        self.assertEqual(v, value)

    #
    # decimal
    #

    def _decimal(self, precision, scale, negative):
        # From test provided by planders (thanks!) in Issue 91

        self.cursor.execute(""create table t1(d decimal(%s, %s))"" % (precision, scale))

        # Construct a decimal that uses the maximum precision and scale.
        decStr = '9' * (precision - scale)
        if scale:
            decStr = decStr + ""."" + '9' * scale
        if negative:
            decStr = ""-"" + decStr
        value = Decimal(decStr)

        self.cursor.execute(""insert into t1 values(?)"", value)

        v = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(v, value)

    def _maketest(p, s, n):
        def t(self):
            self._decimal(p, s, n)
        return t
    for (p, s, n) in [ (1,  0,  False),
                       (1,  0,  True),
                       (6,  0,  False),
                       (6,  2,  False),
                       (6,  4,  True),
                       (6,  6,  True),
                       (38, 0,  False),
                       (38, 10, False),
                       (38, 38, False),
                       (38, 0,  True),
                       (38, 10, True),
                       (38, 38, True) ]:
        locals()['test_decimal_%s_%s_%s' % (p, s, n and 'n' or 'p')] = _maketest(p, s, n)


    def test_decimal_e(self):
        """"""Ensure exponential notation decimals are properly handled""""""
        value = Decimal((0, (1, 2, 3), 5)) # prints as 1.23E+7
        self.cursor.execute(""create table t1(d decimal(10, 2))"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_subquery_params(self):
        """"""Ensure parameter markers work in a subquery""""""
        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        row = self.cursor.execute(""""""
                                  select x.id
                                  from (
                                    select id
                                    from t1
                                    where s = ?
                                      and id between ? and ?
                                   ) x
                                   """""", 'test', 1, 10).fetchone()
        self.assertNotEqual(row, None)
        self.assertEqual(row[0], 1)

    def _exec(self):
        self.cursor.execute(self.sql)
        
    def test_close_cnxn(self):
        """"""Make sure using a Cursor after closing its connection doesn't crash.""""""

        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        self.cursor.execute(""select * from t1"")

        self.cnxn.close()
        
        # Now that the connection is closed, we expect an exception.  (If the code attempts to use
        # the HSTMT, we'll get an access violation instead.)
        self.sql = ""select * from t1""
        self.assertRaises(pyodbc.ProgrammingError, self._exec)

    def test_empty_string(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", """")

    def test_fixed_str(self):
        value = ""testing""
        self.cursor.execute(""create table t1(s char(7))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(len(v), len(value)) # If we alloc'd wrong, the test below might work because of an embedded NULL
        self.assertEqual(v, value)

    def test_empty_unicode(self):
        self.cursor.execute(""create table t1(s nvarchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", u"""")

    def test_unicode_query(self):
        self.cursor.execute(u""select 1"")
        
    def test_negative_row_index(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", ""1"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row[0], ""1"")
        self.assertEqual(row[-1], ""1"")

    def test_version(self):
        self.assertEqual(3, len(pyodbc.version.split('.'))) # 1.3.1 etc.

    #
    # date, time, datetime
    #

    def test_datetime(self):
        value = datetime(2007, 1, 15, 3, 4, 5)

        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(value, result)

    def test_datetime_fraction(self):
        # SQL Server supports milliseconds, but Python's datetime supports nanoseconds, so the most granular datetime
        # supported is xxx000.

        value = datetime(2007, 1, 15, 3, 4, 5, 123000)
     
        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
     
        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(result, value)

    def test_datetime_fraction_rounded(self):
        # SQL Server supports milliseconds, but Python's datetime supports nanoseconds.  pyodbc rounds down to what the
        # database supports.

        full    = datetime(2007, 1, 15, 3, 4, 5, 123456)
        rounded = datetime(2007, 1, 15, 3, 4, 5, 123000)
     
        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", full)
     
        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(result), datetime)
        self.assertEqual(result, rounded)

    def test_date(self):
        value = date.today()
     
        self.cursor.execute(""create table t1(d date)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
     
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(type(value), date)
        self.assertEqual(value, result)

    def test_time(self):
        value = datetime.now().time()
        
        # We aren't yet writing values using the new extended time type so the value written to the database is only
        # down to the second.
        value = value.replace(microsecond=0)
         
        self.cursor.execute(""create table t1(t time)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
         
        result = self.cursor.execute(""select t from t1"").fetchone()[0]
        self.assertEqual(type(value), time)
        self.assertEqual(value, result)

    def test_datetime2(self):
        value = datetime(2007, 1, 15, 3, 4, 5)

        self.cursor.execute(""create table t1(dt datetime2)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(value, result)

    #
    # ints and floats
    #

    def test_int(self):
        value = 1234
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_int(self):
        value = -1
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_bigint(self):
        input = 3000000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_float(self):
        value = 1234.567
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_float(self):
        value = -200
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result  = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(value, result)


    #
    # stored procedures
    #

    # def test_callproc(self):
    #     ""callproc with a simple input-only stored procedure""
    #     pass

    def test_sp_results(self):
        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              select top 10 name, id, xtype, refdate
              from sysobjects
            """""")
        rows = self.cursor.execute(""exec proc1"").fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)


    def test_sp_results_from_temp(self):

        # Note: I've used ""set nocount on"" so that we don't get the number of rows deleted from #tmptable.
        # If you don't do this, you'd need to call nextset() once to skip it.

        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              set nocount on
              select top 10 name, id, xtype, refdate
              into #tmptable
              from sysobjects

              select * from #tmptable
            """""")
        self.cursor.execute(""exec proc1"")
        self.assertTrue(self.cursor.description is not None)
        self.assertTrue(len(self.cursor.description) == 4)

        rows = self.cursor.fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)


    def test_sp_results_from_vartbl(self):
        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              set nocount on
              declare @tmptbl table(name varchar(100), id int, xtype varchar(4), refdate datetime)

              insert into @tmptbl
              select top 10 name, id, xtype, refdate
              from sysobjects

              select * from @tmptbl
            """""")
        self.cursor.execute(""exec proc1"")
        rows = self.cursor.fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)

    def test_sp_with_dates(self):
        # Reported in the forums that passing two datetimes to a stored procedure doesn't work.
        self.cursor.execute(
            """"""
            if exists (select * from dbo.sysobjects where id = object_id(N'[test_sp]') and OBJECTPROPERTY(id, N'IsProcedure') = 1)
              drop procedure [dbo].[test_sp]
            """""")
        self.cursor.execute(
            """"""
            create procedure test_sp(@d1 datetime, @d2 datetime)
            AS
              declare @d as int
              set @d = datediff(year, @d1, @d2)
              select @d
            """""")
        self.cursor.execute(""exec test_sp ?, ?"", datetime.now(), datetime.now())
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(rows[0][0] == 0)   # 0 years apart

    def test_sp_with_none(self):
        # Reported in the forums that passing None caused an error.
        self.cursor.execute(
            """"""
            if exists (select * from dbo.sysobjects where id = object_id(N'[test_sp]') and OBJECTPROPERTY(id, N'IsProcedure') = 1)
              drop procedure [dbo].[test_sp]
            """""")
        self.cursor.execute(
            """"""
            create procedure test_sp(@x varchar(20))
            AS
              declare @y varchar(20)
              set @y = @x
              select @y
            """""")
        self.cursor.execute(""exec test_sp ?"", None)
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(rows[0][0] == None)   # 0 years apart
        

    #
    # rowcount
    #

    def test_rowcount_delete(self):
        self.assertEqual(self.cursor.rowcount, -1)
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, count)

    def test_rowcount_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.  On the other hand, we could hardcode a
        zero return value.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, 0)

    def test_rowcount_select(self):
        """"""
        Ensure Cursor.rowcount is set properly after a select statement.

        pyodbc calls SQLRowCount after each execute and sets Cursor.rowcount, but SQL Server 2005 returns -1 after a
        select statement, so we'll test for that behavior.  This is valid behavior according to the DB API
        specification, but people don't seem to like it.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""select * from t1"")
        self.assertEqual(self.cursor.rowcount, -1)

        rows = self.cursor.fetchall()
        self.assertEqual(len(rows), count)
        self.assertEqual(self.cursor.rowcount, -1)

    def test_rowcount_reset(self):
        ""Ensure rowcount is reset to -1""

        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.assertEqual(self.cursor.rowcount, 1)

        self.cursor.execute(""create table t2(i int)"")
        self.assertEqual(self.cursor.rowcount, -1)

    #
    # always return Cursor
    #

    # In the 2.0.x branch, Cursor.execute sometimes returned the cursor and sometimes the rowcount.  This proved very
    # confusing when things went wrong and added very little value even when things went right since users could always
    # use: cursor.execute(""..."").rowcount

    def test_retcursor_delete(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_select(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""select * from t1"")
        self.assertEqual(v, self.cursor)

    #
    # misc
    #

    def test_lower_case(self):
        ""Ensure pyodbc.lowercase forces returned column names to lowercase.""

        # Has to be set before creating the cursor, so we must recreate self.cursor.

        pyodbc.lowercase = True
        self.cursor = self.cnxn.cursor()

        self.cursor.execute(""create table t1(Abc int, dEf int)"")
        self.cursor.execute(""select * from t1"")

        names = [ t[0] for t in self.cursor.description ]
        names.sort()

        self.assertEqual(names, [ ""abc"", ""def"" ])

        # Put it back so other tests don't fail.
        pyodbc.lowercase = False
        
    def test_row_description(self):
        """"""
        Ensure Cursor.description is accessible as Row.cursor_description.
        """"""
        self.cursor = self.cnxn.cursor()
        self.cursor.execute(""create table t1(a int, b char(3))"")
        self.cnxn.commit()
        self.cursor.execute(""insert into t1 values(1, 'abc')"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        self.assertEqual(self.cursor.description, row.cursor_description)
        

    def test_temp_select(self):
        # A project was failing to create temporary tables via select into.
        self.cursor.execute(""create table t1(s char(7))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(v, ""testing"")

        self.cursor.execute(""select s into t2 from t1"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(v, ""testing"")


    def test_money(self):
        d = Decimal('123456.78')
        self.cursor.execute(""create table t1(i int identity(1,1), m money)"")
        self.cursor.execute(""insert into t1(m) values (?)"", d)
        v = self.cursor.execute(""select m from t1"").fetchone()[0]
        self.assertEqual(v, d)


    def test_executemany(self):
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (i, str(i)) for i in range(1, 6) ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])


    def test_executemany_one(self):
        ""Pass executemany a single sequence""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, ""test"") ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])
        

    def test_executemany_failure(self):
        """"""
        Ensure that an exception is raised if one query in an executemany fails.
        """"""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, 'good'),
                   ('error', 'not an int'),
                   (3, 'good') ]
        
        self.assertRaises(pyodbc.Error, self.cursor.executemany, ""insert into t1(a, b) value (?, ?)"", params)

        
    def test_row_slicing(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = row[:]
        self.assertTrue(result is row)

        result = row[:-1]
        self.assertEqual(result, (1,2,3))

        result = row[0:4]
        self.assertTrue(result is row)


    def test_row_repr(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = str(row)
        self.assertEqual(result, ""(1, 2, 3, 4)"")

        result = str(row[:-1])
        self.assertEqual(result, ""(1, 2, 3)"")

        result = str(row[:1])
        self.assertEqual(result, ""(1,)"")


    def test_concatenation(self):
        v2 = '0123456789' * 30
        v3 = '9876543210' * 30

        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(300), c3 varchar(300))"")
        self.cursor.execute(""insert into t1(c2, c3) values (?,?)"", v2, v3)

        row = self.cursor.execute(""select c2, c3, c2 + c3 as both from t1"").fetchone()

        self.assertEqual(row.both, v2 + v3)

    def test_view_select(self):
        # Reported in forum: Can't select from a view?  I think I do this a lot, but another test never hurts.

        # Create a table (t1) with 3 rows and a view (t2) into it.
        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(50))"")
        for i in range(3):
            self.cursor.execute(""insert into t1(c2) values (?)"", ""string%s"" % i)
        self.cursor.execute(""create view t2 as select * from t1"")

        # Select from the view
        self.cursor.execute(""select * from t2"")
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(len(rows) == 3)

    def test_autocommit(self):
        self.assertEqual(self.cnxn.autocommit, False)

        othercnxn = pyodbc.connect(self.connection_string, autocommit=True)
        self.assertEqual(othercnxn.autocommit, True)

        othercnxn.autocommit = False
        self.assertEqual(othercnxn.autocommit, False)

    def test_unicode_results(self):
        ""Ensure unicode_results forces Unicode""
        othercnxn = pyodbc.connect(self.connection_string, unicode_results=True)
        othercursor = othercnxn.cursor()

        # ANSI data in an ANSI column ...
        othercursor.execute(""create table t1(s varchar(20))"")
        othercursor.execute(""insert into t1 values(?)"", 'test')

        # ... should be returned as Unicode
        value = othercursor.execute(""select s from t1"").fetchone()[0]
        self.assertEqual(value, u'test')


    def test_informix_callproc(self):
        try:
            self.cursor.execute(""drop procedure pyodbctest"")
            self.cnxn.commit()
        except:
            pass

        self.cursor.execute(""create table t1(s varchar(10))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")

        self.cursor.execute(""""""
                            create procedure pyodbctest @var1 varchar(32)
                            as 
                            begin 
                              select s 
                              from t1 
                            return 
                            end
                            """""")
        self.cnxn.commit()

        # for row in self.cursor.procedureColumns('pyodbctest'):
        #     print row.procedure_name, row.column_name, row.column_type, row.type_name

        self.cursor.execute(""exec pyodbctest 'hi'"")

        # print self.cursor.description
        # for row in self.cursor:
        #     print row.s

    def test_skip(self):
        # Insert 1, 2, and 3.  Fetch 1, skip 2, fetch 3.

        self.cursor.execute(""create table t1(id int)"");
        for i in range(1, 5):
            self.cursor.execute(""insert into t1 values(?)"", i)
        self.cursor.execute(""select id from t1 order by id"")
        self.assertEqual(self.cursor.fetchone()[0], 1)
        self.cursor.skip(2)
        self.assertEqual(self.cursor.fetchone()[0], 4)

    def test_timeout(self):
        self.assertEqual(self.cnxn.timeout, 0) # defaults to zero (off)

        self.cnxn.timeout = 30
        self.assertEqual(self.cnxn.timeout, 30)

        self.cnxn.timeout = 0
        self.assertEqual(self.cnxn.timeout, 0)

    def test_sets_execute(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.execute(""insert into t1 (word) VALUES (?)"", [words])

        self.assertRaises(pyodbc.ProgrammingError, f)

    def test_sets_executemany(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.executemany(""insert into t1 (word) values (?)"", [words])
            
        self.assertRaises(TypeError, f)

    def test_row_execute(self):
        ""Ensure we can use a Row object as a parameter to execute""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, 'a')"")
        row = self.cursor.execute(""select n, s from t1"").fetchone()
        self.assertNotEqual(row, None)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.execute(""insert into t2 values (?, ?)"", row)
        
    def test_row_executemany(self):
        ""Ensure we can use a Row object as a parameter to executemany""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")

        for i in range(3):
            self.cursor.execute(""insert into t1 values (?, ?)"", i, chr(ord('a')+i))

        rows = self.cursor.execute(""select n, s from t1"").fetchall()
        self.assertNotEqual(len(rows), 0)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.executemany(""insert into t2 values (?, ?)"", rows)
        
    def test_description(self):
        ""Ensure cursor.description is correct""

        self.cursor.execute(""create table t1(n int, s varchar(8), d decimal(5,2))"")
        self.cursor.execute(""insert into t1 values (1, 'abc', '1.23')"")
        self.cursor.execute(""select * from t1"")

        # (I'm not sure the precision of an int is constant across different versions, bits, so I'm hand checking the
        # items I do know.

        # int
        t = self.cursor.description[0]
        self.assertEqual(t[0], 'n')
        self.assertEqual(t[1], int)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # varchar(8)
        t = self.cursor.description[1]
        self.assertEqual(t[0], 's')
        self.assertEqual(t[1], str)
        self.assertEqual(t[4], 8)       # precision
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # decimal(5, 2)
        t = self.cursor.description[2]
        self.assertEqual(t[0], 'd')
        self.assertEqual(t[1], Decimal)
        self.assertEqual(t[4], 5)       # precision
        self.assertEqual(t[5], 2)       # scale
        self.assertEqual(t[6], True)    # nullable

        
    def test_none_param(self):
        ""Ensure None can be used for params other than the first""
        # Some driver/db versions would fail if NULL was not the first parameter because SQLDescribeParam (only used
        # with NULL) could not be used after the first call to SQLBindParameter.  This means None always worked for the
        # first column, but did not work for later columns.
        #
        # If SQLDescribeParam doesn't work, pyodbc would use VARCHAR which almost always worked.  However,
        # binary/varbinary won't allow an implicit conversion.

        self.cursor.execute(""create table t1(n int, blob varbinary(max))"")
        self.cursor.execute(""insert into t1 values (1, newid())"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row.n, 1)
        self.assertEqual(type(row.blob), buffer)

        self.cursor.execute(""update t1 set n=?, blob=?"", 2, None)
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row.n, 2)
        self.assertEqual(row.blob, None)


    def test_output_conversion(self):
        def convert(value):
            # `value` will be a string.  We'll simply add an X at the beginning at the end.
            return 'X' + value + 'X'
        self.cnxn.add_output_converter(pyodbc.SQL_VARCHAR, convert)
        self.cursor.execute(""create table t1(n int, v varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, '123.45')"")
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, 'X123.45X')

        # Now clear the conversions and try again.  There should be no Xs this time.
        self.cnxn.clear_output_converters()
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, '123.45')


    def test_too_large(self):
        """"""Ensure error raised if insert fails due to truncation""""""
        value = 'x' * 1000
        self.cursor.execute(""create table t1(s varchar(800))"")
        def test():
            self.cursor.execute(""insert into t1 values (?)"", value)
        self.assertRaises(pyodbc.DataError, test)

    def test_geometry_null_insert(self):
        def convert(value):
            return value

        self.cnxn.add_output_converter(-151, convert) # -151 is SQL Server's geometry
        self.cursor.execute(""create table t1(n int, v geometry)"")
        self.cursor.execute(""insert into t1 values (?, ?)"", 1, None)
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, None)
        self.cnxn.clear_output_converters()

    def test_login_timeout(self):
        # This can only test setting since there isn't a way to cause it to block on the server side.
        cnxns = pyodbc.connect(self.connection_string, timeout=2)

    def test_row_equal(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test')"")
        row1 = self.cursor.execute(""select n, s from t1"").fetchone()
        row2 = self.cursor.execute(""select n, s from t1"").fetchone()
        b = (row1 == row2)
        self.assertEqual(b, True)

    def test_row_gtlt(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test1')"")
        self.cursor.execute(""insert into t1 values (1, 'test2')"")
        rows = self.cursor.execute(""select n, s from t1 order by s"").fetchall()
        self.assertTrue(rows[0] < rows[1])
        self.assertTrue(rows[0] <= rows[1])
        self.assertTrue(rows[1] > rows[0])
        self.assertTrue(rows[1] >= rows[0])
        self.assertTrue(rows[0] != rows[1])

        rows = list(rows)
        rows.sort() # uses <
        
    def test_context_manager(self):
        with pyodbc.connect(self.connection_string) as cnxn:
            cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)

        # The connection should be closed now.
        def test():
            cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)
        self.assertRaises(pyodbc.ProgrammingError, test)

    def test_untyped_none(self):
        # From issue 129
        value = self.cursor.execute(""select ?"", None).fetchone()[0]
        self.assertEqual(value, None)
        
    def test_large_update_nodata(self):
        self.cursor.execute('create table t1(a varbinary(max))')
        hundredkb = buffer('x'*100*1024)
        self.cursor.execute('update t1 set a=? where 1=0', (hundredkb,))

    def test_func_param(self):
        self.cursor.execute('''
                            create function func1 (@testparam varchar(4)) 
                            returns @rettest table (param varchar(4))
                            as 
                            begin
                                insert @rettest
                                select @testparam
                                return
                            end
                            ''')
        self.cnxn.commit()
        value = self.cursor.execute(""select * from func1(?)"", 'test').fetchone()[0]
        self.assertEqual(value, 'test')
        
    def test_no_fetch(self):
        # Issue 89 with FreeTDS: Multiple selects (or catalog functions that issue selects) without fetches seem to
        # confuse the driver.
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')

    def test_drivers(self):
        drivers = pyodbc.drivers()
        self.assertEqual(list, type(drivers))
        self.assertTrue(len(drivers) > 1)

        m = re.search('DRIVER={([^}]+)}', self.connection_string, re.IGNORECASE)
        current = m.group(1)
        self.assertTrue(current in drivers)
            
    def test_prepare_cleanup(self):
        # When statement is prepared, it is kept in case the next execute uses the same statement.  This must be
        # removed when a non-execute statement is used that returns results, such as SQLTables.

        self.cursor.execute(""select top 1 name from sysobjects where name = ?"", ""bogus"")
        self.cursor.fetchone()

        self.cursor.tables(""bogus"")
        
        self.cursor.execute(""select top 1 name from sysobjects where name = ?"", ""bogus"")
        self.cursor.fetchone()


def main():
    from optparse import OptionParser
    parser = OptionParser(usage=usage)
    parser.add_option(""-v"", ""--verbose"", action=""count"", help=""Increment test verbosity (can be used multiple times)"")
    parser.add_option(""-d"", ""--debug"", action=""store_true"", default=False, help=""Print debugging items"")
    parser.add_option(""-t"", ""--test"", help=""Run only the named test"")

    (options, args) = parser.parse_args()

    if len(args) > 1:
        parser.error('Only one argument is allowed.  Do you need quotes around the connection string?')

    if not args:
        connection_string = load_setup_connection_string('informixtests')

        if not connection_string:
            parser.print_help()
            raise SystemExit()
    else:
        connection_string = args[0]

    cnxn = pyodbc.connect(connection_string)
    print_library_info(cnxn)
    cnxn.close()

    suite = load_tests(InformixTestCase, options.test, connection_string)

    testRunner = unittest.TextTestRunner(verbosity=options.verbose)
    result = testRunner.run(suite)


if __name__ == '__main__':

    # Add the build directory to the path so we're testing the latest build, not the installed version.

    add_to_path()

    import pyodbc
    main()
/n/n/ntests2/sqlitetests.py/n/n#!/usr/bin/python
# -*- coding: latin-1 -*-

usage = """"""\
usage: %prog [options] connection_string

Unit tests for SQLite using the ODBC driver from http://www.ch-werner.de/sqliteodbc

To use, pass a connection string as the parameter. The tests will create and
drop tables t1 and t2 as necessary.  On Windows, use the 32-bit driver with
32-bit Python and the 64-bit driver with 64-bit Python (regardless of your
operating system bitness).

These run using the version from the 'build' directory, not the version
installed into the Python directories.  You must run python setup.py build
before running the tests.

You can also put the connection string into a tmp/setup.cfg file like so:

  [sqlitetests]
  connection-string=Driver=SQLite3 ODBC Driver;Database=sqlite.db
""""""

import sys, os, re
import unittest
from decimal import Decimal
from datetime import datetime, date, time
from os.path import join, getsize, dirname, abspath
from testutils import *

_TESTSTR = '0123456789-abcdefghijklmnopqrstuvwxyz-'

def _generate_test_string(length):
    """"""
    Returns a string of `length` characters, constructed by repeating _TESTSTR as necessary.

    To enhance performance, there are 3 ways data is read, based on the length of the value, so most data types are
    tested with 3 lengths.  This function helps us generate the test data.

    We use a recognizable data set instead of a single character to make it less likely that ""overlap"" errors will
    be hidden and to help us manually identify where a break occurs.
    """"""
    if length <= len(_TESTSTR):
        return _TESTSTR[:length]

    c = (length + len(_TESTSTR)-1) / len(_TESTSTR)
    v = _TESTSTR * c
    return v[:length]

class SqliteTestCase(unittest.TestCase):

    SMALL_FENCEPOST_SIZES = [ 0, 1, 255, 256, 510, 511, 512, 1023, 1024, 2047, 2048, 4000 ]
    LARGE_FENCEPOST_SIZES = [ 4095, 4096, 4097, 10 * 1024, 20 * 1024 ]

    ANSI_FENCEPOSTS    = [ _generate_test_string(size) for size in SMALL_FENCEPOST_SIZES ]
    UNICODE_FENCEPOSTS = [ unicode(s) for s in ANSI_FENCEPOSTS ]
    IMAGE_FENCEPOSTS   = ANSI_FENCEPOSTS + [ _generate_test_string(size) for size in LARGE_FENCEPOST_SIZES ]

    def __init__(self, method_name, connection_string):
        unittest.TestCase.__init__(self, method_name)
        self.connection_string = connection_string

    def setUp(self):
        self.cnxn   = pyodbc.connect(self.connection_string)
        self.cursor = self.cnxn.cursor()

        for i in range(3):
            try:
                self.cursor.execute(""drop table t%d"" % i)
                self.cnxn.commit()
            except:
                pass

        self.cnxn.rollback()

    def tearDown(self):
        try:
            self.cursor.close()
            self.cnxn.close()
        except:
            # If we've already closed the cursor or connection, exceptions are thrown.
            pass

    def test_multiple_bindings(self):
        ""More than one bind and select on a cursor""
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t1 values (?)"", 2)
        self.cursor.execute(""insert into t1 values (?)"", 3)
        for i in range(3):
            self.cursor.execute(""select n from t1 where n < ?"", 10)
            self.cursor.execute(""select n from t1 where n < 3"")
        

    def test_different_bindings(self):
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""create table t2(d datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t2 values (?)"", datetime.now())

    def test_drivers(self):
        p = pyodbc.drivers()
        self.assertTrue(isinstance(p, list))

    def test_datasources(self):
        p = pyodbc.dataSources()
        self.assertTrue(isinstance(p, dict))

    def test_getinfo_string(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CATALOG_NAME_SEPARATOR)
        self.assertTrue(isinstance(value, str))

    def test_getinfo_bool(self):
        value = self.cnxn.getinfo(pyodbc.SQL_ACCESSIBLE_TABLES)
        self.assertTrue(isinstance(value, bool))

    def test_getinfo_int(self):
        value = self.cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)
        self.assertTrue(isinstance(value, (int, long)))

    def test_getinfo_smallint(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CONCAT_NULL_BEHAVIOR)
        self.assertTrue(isinstance(value, int))

    def test_fixed_unicode(self):
        value = u""t\xebsting""
        self.cursor.execute(""create table t1(s nchar(7))"")
        self.cursor.execute(""insert into t1 values(?)"", u""t\xebsting"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), unicode)
        self.assertEqual(len(v), len(value)) # If we alloc'd wrong, the test below might work because of an embedded NULL
        self.assertEqual(v, value)


    def _test_strtype(self, sqltype, value, colsize=None):
        """"""
        The implementation for string, Unicode, and binary tests.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)

        # Reported by Andy Hochhaus in the pyodbc group: In 2.1.7 and earlier, a hardcoded length of 255 was used to
        # determine whether a parameter was bound as a SQL_VARCHAR or SQL_LONGVARCHAR.  Apparently SQL Server chokes if
        # we bind as a SQL_LONGVARCHAR and the target column size is 8000 or less, which is considers just SQL_VARCHAR.
        # This means binding a 256 character value would cause problems if compared with a VARCHAR column under
        # 8001. We now use SQLGetTypeInfo to determine the time to switch.
        #
        # [42000] [Microsoft][SQL Server Native Client 10.0][SQL Server]The data types varchar and text are incompatible in the equal to operator.

        self.cursor.execute(""select * from t1 where s=?"", value)


    def _test_strliketype(self, sqltype, value, colsize=None):
        """"""
        The implementation for text, image, ntext, and binary.

        These types do not support comparison operators.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)

    #
    # text
    #

    def test_text_null(self):
        self._test_strtype('text', None, 100)

    # Generate a test for each fencepost size: test_text_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('text', value, len(value))
        return t
    for value in UNICODE_FENCEPOSTS:
        locals()['test_text_%s' % len(value)] = _maketest(value)

    def test_text_upperlatin(self):
        self._test_strtype('varchar', u'�')

    #
    # blob
    #

    def test_null_blob(self):
        self._test_strtype('blob', None, 100)
     
    def test_large_null_blob(self):
        # Bug 1575064
        self._test_strtype('blob', None, 4000)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('blob', bytearray(value), len(value))
        return t
    for value in ANSI_FENCEPOSTS:
        locals()['test_blob_%s' % len(value)] = _maketest(value)

    def test_subquery_params(self):
        """"""Ensure parameter markers work in a subquery""""""
        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        row = self.cursor.execute(""""""
                                  select x.id
                                  from (
                                    select id
                                    from t1
                                    where s = ?
                                      and id between ? and ?
                                   ) x
                                   """""", 'test', 1, 10).fetchone()
        self.assertNotEqual(row, None)
        self.assertEqual(row[0], 1)

    def _exec(self):
        self.cursor.execute(self.sql)
        
    def test_close_cnxn(self):
        """"""Make sure using a Cursor after closing its connection doesn't crash.""""""

        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        self.cursor.execute(""select * from t1"")

        self.cnxn.close()
        
        # Now that the connection is closed, we expect an exception.  (If the code attempts to use
        # the HSTMT, we'll get an access violation instead.)
        self.sql = ""select * from t1""
        self.assertRaises(pyodbc.ProgrammingError, self._exec)

    def test_empty_unicode(self):
        self.cursor.execute(""create table t1(s nvarchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", u"""")

    def test_unicode_query(self):
        self.cursor.execute(u""select 1"")
        
    def test_negative_row_index(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", ""1"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row[0], ""1"")
        self.assertEqual(row[-1], ""1"")

    def test_version(self):
        self.assertEqual(3, len(pyodbc.version.split('.'))) # 1.3.1 etc.

    #
    # ints and floats
    #

    def test_int(self):
        value = 1234
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_int(self):
        value = -1
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_bigint(self):
        input = 3000000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_negative_bigint(self):
        # Issue 186: BIGINT problem on 32-bit architeture
        input = -430000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_float(self):
        value = 1234.567
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_float(self):
        value = -200
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result  = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(value, result)

    #
    # rowcount
    #

    # Note: SQLRowCount does not define what the driver must return after a select statement
    # and says that its value should not be relied upon.  The sqliteodbc driver is hardcoded to
    # return 0 so I've deleted the test.

    def test_rowcount_delete(self):
        self.assertEqual(self.cursor.rowcount, -1)
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, count)

    def test_rowcount_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.  On the other hand, we could hardcode a
        zero return value.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, 0)

    # In the 2.0.x branch, Cursor.execute sometimes returned the cursor and sometimes the rowcount.  This proved very
    # confusing when things went wrong and added very little value even when things went right since users could always
    # use: cursor.execute(""..."").rowcount

    def test_retcursor_delete(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_select(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""select * from t1"")
        self.assertEqual(v, self.cursor)

    #
    # misc
    #

    def test_lower_case(self):
        ""Ensure pyodbc.lowercase forces returned column names to lowercase.""

        # Has to be set before creating the cursor, so we must recreate self.cursor.

        pyodbc.lowercase = True
        self.cursor = self.cnxn.cursor()

        self.cursor.execute(""create table t1(Abc int, dEf int)"")
        self.cursor.execute(""select * from t1"")

        names = [ t[0] for t in self.cursor.description ]
        names.sort()

        self.assertEqual(names, [ ""abc"", ""def"" ])

        # Put it back so other tests don't fail.
        pyodbc.lowercase = False
        
    def test_row_description(self):
        """"""
        Ensure Cursor.description is accessible as Row.cursor_description.
        """"""
        self.cursor = self.cnxn.cursor()
        self.cursor.execute(""create table t1(a int, b char(3))"")
        self.cnxn.commit()
        self.cursor.execute(""insert into t1 values(1, 'abc')"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        self.assertEqual(self.cursor.description, row.cursor_description)
        

    def test_executemany(self):
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (i, str(i)) for i in range(1, 6) ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])


    def test_executemany_one(self):
        ""Pass executemany a single sequence""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, ""test"") ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])
        

    def test_executemany_failure(self):
        """"""
        Ensure that an exception is raised if one query in an executemany fails.
        """"""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, 'good'),
                   ('error', 'not an int'),
                   (3, 'good') ]
        
        self.assertRaises(pyodbc.Error, self.cursor.executemany, ""insert into t1(a, b) value (?, ?)"", params)

        
    def test_row_slicing(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = row[:]
        self.assertTrue(result is row)

        result = row[:-1]
        self.assertEqual(result, (1,2,3))

        result = row[0:4]
        self.assertTrue(result is row)


    def test_row_repr(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = str(row)
        self.assertEqual(result, ""(1, 2, 3, 4)"")

        result = str(row[:-1])
        self.assertEqual(result, ""(1, 2, 3)"")

        result = str(row[:1])
        self.assertEqual(result, ""(1,)"")


    def test_view_select(self):
        # Reported in forum: Can't select from a view?  I think I do this a lot, but another test never hurts.

        # Create a table (t1) with 3 rows and a view (t2) into it.
        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(50))"")
        for i in range(3):
            self.cursor.execute(""insert into t1(c2) values (?)"", ""string%s"" % i)
        self.cursor.execute(""create view t2 as select * from t1"")

        # Select from the view
        self.cursor.execute(""select * from t2"")
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(len(rows) == 3)

    def test_autocommit(self):
        self.assertEqual(self.cnxn.autocommit, False)

        othercnxn = pyodbc.connect(self.connection_string, autocommit=True)
        self.assertEqual(othercnxn.autocommit, True)

        othercnxn.autocommit = False
        self.assertEqual(othercnxn.autocommit, False)

    def test_unicode_results(self):
        ""Ensure unicode_results forces Unicode""
        othercnxn = pyodbc.connect(self.connection_string, unicode_results=True)
        othercursor = othercnxn.cursor()

        # ANSI data in an ANSI column ...
        othercursor.execute(""create table t1(s varchar(20))"")
        othercursor.execute(""insert into t1 values(?)"", 'test')

        # ... should be returned as Unicode
        value = othercursor.execute(""select s from t1"").fetchone()[0]
        self.assertEqual(value, u'test')

    def test_skip(self):
        # Insert 1, 2, and 3.  Fetch 1, skip 2, fetch 3.

        self.cursor.execute(""create table t1(id int)"");
        for i in range(1, 5):
            self.cursor.execute(""insert into t1 values(?)"", i)
        self.cursor.execute(""select id from t1 order by id"")
        self.assertEqual(self.cursor.fetchone()[0], 1)
        self.cursor.skip(2)
        self.assertEqual(self.cursor.fetchone()[0], 4)

    def test_sets_execute(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.execute(""insert into t1 (word) VALUES (?)"", [words])

        self.assertRaises(pyodbc.ProgrammingError, f)

    def test_sets_executemany(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.executemany(""insert into t1 (word) values (?)"", [words])
            
        self.assertRaises(TypeError, f)

    def test_row_execute(self):
        ""Ensure we can use a Row object as a parameter to execute""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, 'a')"")
        row = self.cursor.execute(""select n, s from t1"").fetchone()
        self.assertNotEqual(row, None)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.execute(""insert into t2 values (?, ?)"", row)
        
    def test_row_executemany(self):
        ""Ensure we can use a Row object as a parameter to executemany""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")

        for i in range(3):
            self.cursor.execute(""insert into t1 values (?, ?)"", i, chr(ord('a')+i))

        rows = self.cursor.execute(""select n, s from t1"").fetchall()
        self.assertNotEqual(len(rows), 0)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.executemany(""insert into t2 values (?, ?)"", rows)
        
    def test_description(self):
        ""Ensure cursor.description is correct""

        self.cursor.execute(""create table t1(n int, s text)"")
        self.cursor.execute(""insert into t1 values (1, 'abc')"")
        self.cursor.execute(""select * from t1"")

        # (I'm not sure the precision of an int is constant across different versions, bits, so I'm hand checking the
        # items I do know.

        # int
        t = self.cursor.description[0]
        self.assertEqual(t[0], 'n')
        self.assertEqual(t[1], int)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # text
        t = self.cursor.description[1]
        self.assertEqual(t[0], 's')
        self.assertEqual(t[1], str)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

    def test_row_equal(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test')"")
        row1 = self.cursor.execute(""select n, s from t1"").fetchone()
        row2 = self.cursor.execute(""select n, s from t1"").fetchone()
        b = (row1 == row2)
        self.assertEqual(b, True)

    def test_row_gtlt(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test1')"")
        self.cursor.execute(""insert into t1 values (1, 'test2')"")
        rows = self.cursor.execute(""select n, s from t1 order by s"").fetchall()
        self.assertTrue(rows[0] < rows[1])
        self.assertTrue(rows[0] <= rows[1])
        self.assertTrue(rows[1] > rows[0])
        self.assertTrue(rows[1] >= rows[0])
        self.assertTrue(rows[0] != rows[1])

        rows = list(rows)
        rows.sort() # uses <
        
    def _test_context_manager(self):
        # TODO: This is failing, but it may be due to the design of sqlite.  I've disabled it
        # for now until I can research it some more.

        # WARNING: This isn't working right now.  We've set the driver's autocommit to ""off"",
        # but that doesn't automatically start a transaction.  I'm not familiar enough with the
        # internals of the driver to tell what is going on, but it looks like there is support
        # for the autocommit flag.
        #
        # I thought it might be a timing issue, like it not actually starting a txn until you
        # try to do something, but that doesn't seem to work either.  I'll leave this in to
        # remind us that it isn't working yet but we need to contact the SQLite ODBC driver
        # author for some guidance.

        with pyodbc.connect(self.connection_string) as cnxn:
            cursor = cnxn.cursor()
            cursor.execute(""begin"")
            cursor.execute(""create table t1(i int)"")
            cursor.execute('rollback')

        # The connection should be closed now.
        def test():
            cnxn.execute('rollback')
        self.assertRaises(pyodbc.Error, test)

    def test_untyped_none(self):
        # From issue 129
        value = self.cursor.execute(""select ?"", None).fetchone()[0]
        self.assertEqual(value, None)
        
    def test_large_update_nodata(self):
        self.cursor.execute('create table t1(a blob)')
        hundredkb = 'x'*100*1024
        self.cursor.execute('update t1 set a=? where 1=0', (hundredkb,))

    def test_no_fetch(self):
        # Issue 89 with FreeTDS: Multiple selects (or catalog functions that issue selects) without fetches seem to
        # confuse the driver.
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')


def main():
    from optparse import OptionParser
    parser = OptionParser(usage=usage)
    parser.add_option(""-v"", ""--verbose"", default=0, action=""count"", help=""Increment test verbosity (can be used multiple times)"")
    parser.add_option(""-d"", ""--debug"", action=""store_true"", default=False, help=""Print debugging items"")
    parser.add_option(""-t"", ""--test"", help=""Run only the named test"")

    (options, args) = parser.parse_args()

    if len(args) > 1:
        parser.error('Only one argument is allowed.  Do you need quotes around the connection string?')

    if not args:
        connection_string = load_setup_connection_string('sqlitetests')

        if not connection_string:
            parser.print_help()
            raise SystemExit()
    else:
        connection_string = args[0]

    if options.verbose:
        cnxn = pyodbc.connect(connection_string)
        print_library_info(cnxn)
        cnxn.close()

    suite = load_tests(SqliteTestCase, options.test, connection_string)

    testRunner = unittest.TextTestRunner(verbosity=options.verbose)
    result = testRunner.run(suite)

    sys.exit(result.errors and 1 or 0)


if __name__ == '__main__':

    # Add the build directory to the path so we're testing the latest build, not the installed version.

    add_to_path()

    import pyodbc
    main()
/n/n/ntests2/sqlservertests.py/n/n#!/usr/bin/python
# -*- coding: utf-8 -*-

from __future__ import print_function

usage = """"""\
usage: %prog [options] connection_string

Unit tests for SQL Server.  To use, pass a connection string as the parameter.
The tests will create and drop tables t1 and t2 as necessary.

These run using the version from the 'build' directory, not the version
installed into the Python directories.  You must run python setup.py build
before running the tests.

You can also put the connection string into a tmp/setup.cfg file like so:

  [sqlservertests]
  connection-string=DRIVER={SQL Server};SERVER=localhost;UID=uid;PWD=pwd;DATABASE=db

The connection string above will use the 2000/2005 driver, even if SQL Server 2008
is installed:

  2000: DRIVER={SQL Server}
  2005: DRIVER={SQL Server}
  2008: DRIVER={SQL Server Native Client 10.0}
""""""

import sys, os, re, uuid
import unittest
from decimal import Decimal
from datetime import datetime, date, time
from os.path import join, getsize, dirname, abspath
from testutils import *

_TESTSTR = '0123456789-abcdefghijklmnopqrstuvwxyz-'

def _generate_test_string(length):
    """"""
    Returns a string of `length` characters, constructed by repeating _TESTSTR as necessary.

    To enhance performance, there are 3 ways data is read, based on the length of the value, so most data types are
    tested with 3 lengths.  This function helps us generate the test data.

    We use a recognizable data set instead of a single character to make it less likely that ""overlap"" errors will
    be hidden and to help us manually identify where a break occurs.
    """"""
    if length <= len(_TESTSTR):
        return _TESTSTR[:length]

    c = (length + len(_TESTSTR)-1) / len(_TESTSTR)
    v = _TESTSTR * c
    return v[:length]

class SqlServerTestCase(unittest.TestCase):

    SMALL_FENCEPOST_SIZES = [ 0, 1, 255, 256, 510, 511, 512, 1023, 1024, 2047, 2048, 4000 ]
    LARGE_FENCEPOST_SIZES = [ 4095, 4096, 4097, 10 * 1024, 20 * 1024 ]
    MAX_FENCEPOST_SIZES   = [ 5 * 1024 * 1024 ] #, 50 * 1024 * 1024 ]

    ANSI_SMALL_FENCEPOSTS    = [ _generate_test_string(size) for size in SMALL_FENCEPOST_SIZES ]
    UNICODE_SMALL_FENCEPOSTS = [ unicode(s) for s in ANSI_SMALL_FENCEPOSTS ]
    ANSI_LARGE_FENCEPOSTS    = ANSI_SMALL_FENCEPOSTS    + [ _generate_test_string(size) for size in LARGE_FENCEPOST_SIZES ]
    UNICODE_LARGE_FENCEPOSTS = UNICODE_SMALL_FENCEPOSTS + [ unicode(s) for s in [_generate_test_string(size) for size in LARGE_FENCEPOST_SIZES ]]

    ANSI_MAX_FENCEPOSTS    = ANSI_LARGE_FENCEPOSTS + [ _generate_test_string(size) for size in MAX_FENCEPOST_SIZES ]
    UNICODE_MAX_FENCEPOSTS = UNICODE_LARGE_FENCEPOSTS + [ unicode(s) for s in [_generate_test_string(size) for size in MAX_FENCEPOST_SIZES ]]


    def __init__(self, method_name, connection_string):
        unittest.TestCase.__init__(self, method_name)
        self.connection_string = connection_string

    def get_sqlserver_version(self):
        """"""
        Returns the major version: 8-->2000, 9-->2005, 10-->2008
        """"""
        self.cursor.execute(""exec master..xp_msver 'ProductVersion'"")
        row = self.cursor.fetchone()
        return int(row.Character_Value.split('.', 1)[0])

    def setUp(self):
        self.cnxn   = pyodbc.connect(self.connection_string)
        self.cursor = self.cnxn.cursor()

        for i in range(3):
            try:
                self.cursor.execute(""drop table t%d"" % i)
                self.cnxn.commit()
            except:
                pass

        for i in range(3):
            try:
                self.cursor.execute(""drop procedure proc%d"" % i)
                self.cnxn.commit()
            except:
                pass

        try:
            self.cursor.execute('drop function func1')
            self.cnxn.commit()
        except:
            pass

        self.cnxn.rollback()

    def tearDown(self):
        try:
            self.cursor.close()
            self.cnxn.close()
        except:
            # If we've already closed the cursor or connection, exceptions are thrown.
            pass

    def test_binary_type(self):
        if sys.hexversion >= 0x02060000:
            self.assertTrue(pyodbc.BINARY is bytearray)
        else:
            self.assertTrue(pyodbc.BINARY is buffer)

    def test_multiple_bindings(self):
        ""More than one bind and select on a cursor""
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t1 values (?)"", 2)
        self.cursor.execute(""insert into t1 values (?)"", 3)
        for i in range(3):
            self.cursor.execute(""select n from t1 where n < ?"", 10)
            self.cursor.execute(""select n from t1 where n < 3"")


    def test_different_bindings(self):
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""create table t2(d datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t2 values (?)"", datetime.now())

    def test_drivers(self):
        p = pyodbc.drivers()
        self.assertTrue(isinstance(p, list))

    def test_datasources(self):
        p = pyodbc.dataSources()
        self.assertTrue(isinstance(p, dict))

    def test_getinfo_string(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CATALOG_NAME_SEPARATOR)
        self.assertTrue(isinstance(value, str))

    def test_getinfo_bool(self):
        value = self.cnxn.getinfo(pyodbc.SQL_ACCESSIBLE_TABLES)
        self.assertTrue(isinstance(value, bool))

    def test_getinfo_int(self):
        value = self.cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)
        self.assertTrue(isinstance(value, (int, long)))

    def test_getinfo_smallint(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CONCAT_NULL_BEHAVIOR)
        self.assertTrue(isinstance(value, int))

    def test_noscan(self):
        self.assertEqual(self.cursor.noscan, False)
        self.cursor.noscan = True
        self.assertEqual(self.cursor.noscan, True)

    def test_nonnative_uuid(self):
        # The default is False meaning we should return a string.  Note that
        # SQL Server seems to always return uppercase.
        value = uuid.uuid4()
        self.cursor.execute(""create table t1(n uniqueidentifier)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        pyodbc.native_uuid = False
        result = self.cursor.execute(""select n from t1"").fetchval()
        self.assertEqual(type(result), unicode)
        self.assertEqual(result, unicode(value).upper())

    def test_native_uuid(self):
        # When true, we should return a uuid.UUID object.
        value = uuid.uuid4()
        self.cursor.execute(""create table t1(n uniqueidentifier)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        pyodbc.native_uuid = True
        result = self.cursor.execute(""select n from t1"").fetchval()
        self.assertTrue(isinstance(result, uuid.UUID))
        self.assertEqual(value, result)

    def test_nextset(self):
        self.cursor.execute(""create table t1(i int)"")
        for i in range(4):
            self.cursor.execute(""insert into t1(i) values(?)"", i)

        self.cursor.execute(""select i from t1 where i < 2 order by i; select i from t1 where i >= 2 order by i"")

        for i, row in enumerate(self.cursor):
            self.assertEqual(i, row.i)

        self.assertEqual(self.cursor.nextset(), True)

        for i, row in enumerate(self.cursor):
            self.assertEqual(i + 2, row.i)

    def test_nextset_with_raiserror(self):
        self.cursor.execute(""select i = 1; RAISERROR('c', 16, 1);"")
        row = next(self.cursor)
        self.assertEqual(1, row.i)
        self.assertRaises(pyodbc.ProgrammingError, self.cursor.nextset)

    def test_fixed_unicode(self):
        value = u""t\xebsting""
        self.cursor.execute(""create table t1(s nchar(7))"")
        self.cursor.execute(""insert into t1 values(?)"", u""t\xebsting"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), unicode)
        self.assertEqual(len(v), len(value)) # If we alloc'd wrong, the test below might work because of an embedded NULL
        self.assertEqual(v, value)


    def _test_strtype(self, sqltype, value, resulttype=None, colsize=None):
        """"""
        The implementation for string, Unicode, and binary tests.
        """"""
        assert colsize in (None, 'max') or isinstance(colsize, int), colsize
        assert colsize in (None, 'max') or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        if resulttype is None:
            resulttype = type(value)

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]

        # To allow buffer --> db --> bytearray tests, always convert the input to the expected result type before
        # comparing.
        if type(value) is not resulttype:
            value = resulttype(value)

        self.assertEqual(v, value)


    def _test_strliketype(self, sqltype, value, resulttype=None, colsize=None):
        """"""
        The implementation for text, image, ntext, and binary.

        These types do not support comparison operators.
        """"""
        assert colsize is None or isinstance(colsize, int), colsize
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        if resulttype is None:
            resulttype = type(value)

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        result = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(result), resulttype)

        # To allow buffer --> db --> bytearray tests, always convert the input to the expected result type before
        # comparing.
        if type(value) is not resulttype:
            value = resulttype(value)

        self.assertEqual(result, value)


    #
    # varchar
    #

    def test_varchar_null(self):
        self._test_strtype('varchar', None, colsize=100)

    # Generate a test for each fencepost size: test_varchar_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('varchar', value, colsize=len(value))
        return t
    for value in UNICODE_SMALL_FENCEPOSTS:
        locals()['test_varchar_%s' % len(value)] = _maketest(value)

    # Also test varchar(max)
    def _maketest(value):
        def t(self):
            self._test_strtype('varchar', value, colsize='max')
        return t
    for value in UNICODE_MAX_FENCEPOSTS:
        locals()['test_varcharmax_%s' % len(value)] = _maketest(value)

    def test_varchar_many(self):
        self.cursor.execute(""create table t1(c1 varchar(300), c2 varchar(300), c3 varchar(300))"")

        v1 = 'ABCDEFGHIJ' * 30
        v2 = '0123456789' * 30
        v3 = '9876543210' * 30

        self.cursor.execute(""insert into t1(c1, c2, c3) values (?,?,?)"", v1, v2, v3);
        row = self.cursor.execute(""select c1, c2, c3, len(c1) as l1, len(c2) as l2, len(c3) as l3 from t1"").fetchone()

        self.assertEqual(v1, row.c1)
        self.assertEqual(v2, row.c2)
        self.assertEqual(v3, row.c3)

    def test_varchar_upperlatin(self):
        self._test_strtype('varchar', u'\u00e5', colsize=1)

    #
    # nvarchar
    #

    def test_nvarchar_null(self):
        self._test_strtype('nvarchar', None, colsize=100)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('nvarchar', value, colsize=len(value))
        return t
    for value in UNICODE_SMALL_FENCEPOSTS:
        locals()['test_nvarchar_%s' % len(value)] = _maketest(value)

    # Also test nvarchar(max)
    def _maketest(value):
        def t(self):
            self._test_strtype('nvarchar', value, colsize='max')
        return t
    for value in UNICODE_MAX_FENCEPOSTS:
        locals()['test_nvarcharmax_%s' % len(value)] = _maketest(value)

    def test_unicode_upperlatin(self):
        self._test_strtype('nvarchar', u'\u00e5', colsize=1)

    def test_unicode_longmax(self):
        # Issue 188:    Segfault when fetching NVARCHAR(MAX) data over 511 bytes

        ver = self.get_sqlserver_version()
        if ver < 9:            # 2005+
            return              # so pass / ignore
        self.cursor.execute(""select cast(replicate(N'x', 512) as nvarchar(max))"")

    #
    # binary
    #

    def test_binary_null(self):
        self._test_strtype('varbinary', None, colsize=100)

    def test_large_binary_null(self):
        # Bug 1575064
        self._test_strtype('varbinary', None, colsize=4000)

    def test_binaryNull_object(self):
        self.cursor.execute(""create table t1(n varbinary(10))"")
        self.cursor.execute(""insert into t1 values (?)"", pyodbc.BinaryNull);

    # buffer

    def _maketest(value):
        def t(self):
            self._test_strtype('varbinary', buffer(value), resulttype=pyodbc.BINARY, colsize=len(value))
        return t
    for value in ANSI_SMALL_FENCEPOSTS:
        locals()['test_binary_buffer_%s' % len(value)] = _maketest(value)

    # bytearray

    if sys.hexversion >= 0x02060000:
        def _maketest(value):
            def t(self):
                self._test_strtype('varbinary', bytearray(value), colsize=len(value))
            return t
        for value in ANSI_SMALL_FENCEPOSTS:
            locals()['test_binary_bytearray_%s' % len(value)] = _maketest(value)

    # varbinary(max)
    def _maketest(value):
        def t(self):
            self._test_strtype('varbinary', buffer(value), resulttype=pyodbc.BINARY, colsize='max')
        return t
    for value in ANSI_MAX_FENCEPOSTS:
        locals()['test_binarymax_buffer_%s' % len(value)] = _maketest(value)

    # bytearray

    if sys.hexversion >= 0x02060000:
        def _maketest(value):
            def t(self):
                self._test_strtype('varbinary', bytearray(value), colsize='max')
            return t
        for value in ANSI_MAX_FENCEPOSTS:
            locals()['test_binarymax_bytearray_%s' % len(value)] = _maketest(value)

    #
    # image
    #

    def test_image_null(self):
        self._test_strliketype('image', None, type(None))

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strliketype('image', buffer(value), pyodbc.BINARY)
        return t
    for value in ANSI_LARGE_FENCEPOSTS:
        locals()['test_image_buffer_%s' % len(value)] = _maketest(value)

    if sys.hexversion >= 0x02060000:
        # Python 2.6+ supports bytearray, which pyodbc considers varbinary.

        # Generate a test for each fencepost size: test_unicode_0, etc.
        def _maketest(value):
            def t(self):
                self._test_strtype('image', bytearray(value))
            return t
        for value in ANSI_LARGE_FENCEPOSTS:
            locals()['test_image_bytearray_%s' % len(value)] = _maketest(value)

    def test_image_upperlatin(self):
        self._test_strliketype('image', buffer('á'), pyodbc.BINARY)

    #
    # text
    #

    # def test_empty_text(self):
    #     self._test_strliketype('text', bytearray(''))

    def test_null_text(self):
        self._test_strliketype('text', None, type(None))

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strliketype('text', value)
        return t
    for value in UNICODE_SMALL_FENCEPOSTS:
        locals()['test_text_buffer_%s' % len(value)] = _maketest(value)

    def test_text_upperlatin(self):
        self._test_strliketype('text', u'á')

    #
    # xml
    #

    # def test_empty_xml(self):
    #     self._test_strliketype('xml', bytearray(''))

    def test_null_xml(self):
        self._test_strliketype('xml', None, type(None))

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strliketype('xml', value)
        return t
    for value in UNICODE_SMALL_FENCEPOSTS:
        locals()['test_xml_buffer_%s' % len(value)] = _maketest(value)

    def test_xml_str(self):
        # SQL Server treats XML like *binary* data.
        # See https://msdn.microsoft.com/en-us/library/ms131375.aspx
        #
        # The real problem with this is that we *don't* know that a value is
        # XML when we write it to the database.  It is either an `str` or a
        # `unicode` object, so we're going to convert it into one of *two*
        # different formats.
        #
        # When we read it out of the database, all we know is that it is XML
        # and we don't know how it was encoded so we don't know how to decode
        # it.  Since almost everyone treats XML as Unicode nowdays, we're going
        # to decode XML as Unicode.  Force your XML to Unicode before writing
        # to the database.  (Otherwise, set a global encoder for the XMl type.)
        ascii = 'test'
        val = unicode(ascii)
        self.cursor.execute(""create table t1(a xml)"")
        self.cursor.execute(""insert into t1 values (?)"", val)
        result = self.cursor.execute(""select a from t1"").fetchval()
        self.assertEqual(result, val)

    def test_xml_upperlatin(self):
        val = u'á'
        self.cursor.execute(""create table t1(a xml)"")
        self.cursor.execute(""insert into t1 values (?)"", val)
        result = self.cursor.execute(""select a from t1"").fetchval()
        self.assertEqual(result, val)

    #
    # bit
    #

    def test_bit(self):
        value = True
        self.cursor.execute(""create table t1(b bit)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        v = self.cursor.execute(""select b from t1"").fetchone()[0]
        self.assertEqual(type(v), bool)
        self.assertEqual(v, value)

    #
    # decimal
    #

    def _decimal(self, precision, scale, negative):
        # From test provided by planders (thanks!) in Issue 91

        self.cursor.execute(""create table t1(d decimal(%s, %s))"" % (precision, scale))

        # Construct a decimal that uses the maximum precision and scale.
        decStr = '9' * (precision - scale)
        if scale:
            decStr = decStr + ""."" + '9' * scale
        if negative:
            decStr = ""-"" + decStr
        value = Decimal(decStr)

        self.cursor.execute(""insert into t1 values(?)"", value)

        v = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(v, value)

    def _maketest(p, s, n):
        def t(self):
            self._decimal(p, s, n)
        return t
    for (p, s, n) in [ (1,  0,  False),
                       (1,  0,  True),
                       (6,  0,  False),
                       (6,  2,  False),
                       (6,  4,  True),
                       (6,  6,  True),
                       (38, 0,  False),
                       (38, 10, False),
                       (38, 38, False),
                       (38, 0,  True),
                       (38, 10, True),
                       (38, 38, True) ]:
        locals()['test_decimal_%s_%s_%s' % (p, s, n and 'n' or 'p')] = _maketest(p, s, n)


    def test_decimal_e(self):
        """"""Ensure exponential notation decimals are properly handled""""""
        value = Decimal((0, (1, 2, 3), 5)) # prints as 1.23E+7
        self.cursor.execute(""create table t1(d decimal(10, 2))"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_subquery_params(self):
        """"""Ensure parameter markers work in a subquery""""""
        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        row = self.cursor.execute(""""""
                                  select x.id
                                  from (
                                    select id
                                    from t1
                                    where s = ?
                                      and id between ? and ?
                                   ) x
                                   """""", 'test', 1, 10).fetchone()
        self.assertNotEqual(row, None)
        self.assertEqual(row[0], 1)

    def _exec(self):
        self.cursor.execute(self.sql)

    def test_close_cnxn(self):
        """"""Make sure using a Cursor after closing its connection doesn't crash.""""""

        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        self.cursor.execute(""select * from t1"")

        self.cnxn.close()

        # Now that the connection is closed, we expect an exception.  (If the code attempts to use
        # the HSTMT, we'll get an access violation instead.)
        self.sql = ""select * from t1""
        self.assertRaises(pyodbc.ProgrammingError, self._exec)

    def test_empty_string(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", """")

    def test_empty_string_encoding(self):
        self.cnxn.setdecoding(pyodbc.SQL_CHAR, encoding='shift_jis')
        value = """"
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(v, value)

    def test_fixed_char(self):
        value = ""testing""
        self.cursor.execute(""create table t1(s char(7))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(v, value)

    def test_empty_unicode(self):
        self.cursor.execute(""create table t1(s nvarchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", u"""")

    def test_empty_unicode_encoding(self):
        self.cnxn.setdecoding(pyodbc.SQL_CHAR, encoding='shift_jis')
        value = """"
        self.cursor.execute(""create table t1(s nvarchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(v, value)

    def test_unicode_query(self):
        self.cursor.execute(u""select 1"")

    # From issue #206
    def _maketest(value):
        def t(self):
            self._test_strtype('nvarchar', value, colsize=len(value))
        return t
    locals()['test_chinese_param'] = _maketest(u'我的')

    def test_chinese(self):
        v = u'我的'
        self.cursor.execute(u""SELECT N'我的' AS [Name]"")
        row = self.cursor.fetchone()
        self.assertEqual(row[0], v)

        self.cursor.execute(u""SELECT N'我的' AS [Name]"")
        rows = self.cursor.fetchall()
        self.assertEqual(rows[0][0], v)

    def test_negative_row_index(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", ""1"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row[0], ""1"")
        self.assertEqual(row[-1], ""1"")

    def test_version(self):
        self.assertEqual(3, len(pyodbc.version.split('.'))) # 1.3.1 etc.

    #
    # date, time, datetime
    #

    def test_datetime(self):
        value = datetime(2007, 1, 15, 3, 4, 5)

        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(value, result)

    def test_datetime_fraction(self):
        # SQL Server supports milliseconds, but Python's datetime supports nanoseconds, so the most granular datetime
        # supported is xxx000.

        value = datetime(2007, 1, 15, 3, 4, 5, 123000)

        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(result, value)

    def test_datetime_fraction_rounded(self):
        # SQL Server supports milliseconds, but Python's datetime supports nanoseconds.  pyodbc rounds down to what the
        # database supports.

        full    = datetime(2007, 1, 15, 3, 4, 5, 123456)
        rounded = datetime(2007, 1, 15, 3, 4, 5, 123000)

        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", full)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(result), datetime)
        self.assertEqual(result, rounded)

    def test_date(self):
        ver = self.get_sqlserver_version()
        if ver < 10:            # 2008 only
            return              # so pass / ignore

        value = date.today()

        self.cursor.execute(""create table t1(d date)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(type(value), date)
        self.assertEqual(value, result)

    def test_time(self):
        ver = self.get_sqlserver_version()
        if ver < 10:            # 2008 only
            return              # so pass / ignore

        value = datetime.now().time()

        # We aren't yet writing values using the new extended time type so the value written to the database is only
        # down to the second.
        value = value.replace(microsecond=0)

        self.cursor.execute(""create table t1(t time)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select t from t1"").fetchone()[0]
        self.assertEqual(type(value), time)
        self.assertEqual(value, result)

    def test_datetime2(self):
        value = datetime(2007, 1, 15, 3, 4, 5)

        self.cursor.execute(""create table t1(dt datetime2)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(value, result)

    #
    # ints and floats
    #

    def test_int(self):
        value = 1234
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_int(self):
        value = -1
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_bigint(self):
        input = 3000000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_float(self):
        value = 1234.567
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_float(self):
        value = -200
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result  = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(value, result)


    #
    # stored procedures
    #

    # def test_callproc(self):
    #     ""callproc with a simple input-only stored procedure""
    #     pass

    def test_sp_results(self):
        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              select top 10 name, id, xtype, refdate
              from sysobjects
            """""")
        rows = self.cursor.execute(""exec proc1"").fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)


    def test_sp_results_from_temp(self):

        # Note: I've used ""set nocount on"" so that we don't get the number of rows deleted from #tmptable.
        # If you don't do this, you'd need to call nextset() once to skip it.

        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              set nocount on
              select top 10 name, id, xtype, refdate
              into #tmptable
              from sysobjects

              select * from #tmptable
            """""")
        self.cursor.execute(""exec proc1"")
        self.assertTrue(self.cursor.description is not None)
        self.assertTrue(len(self.cursor.description) == 4)

        rows = self.cursor.fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)


    def test_sp_results_from_vartbl(self):
        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              set nocount on
              declare @tmptbl table(name varchar(100), id int, xtype varchar(4), refdate datetime)

              insert into @tmptbl
              select top 10 name, id, xtype, refdate
              from sysobjects

              select * from @tmptbl
            """""")
        self.cursor.execute(""exec proc1"")
        rows = self.cursor.fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)

    def test_sp_with_dates(self):
        # Reported in the forums that passing two datetimes to a stored procedure doesn't work.
        self.cursor.execute(
            """"""
            if exists (select * from dbo.sysobjects where id = object_id(N'[test_sp]') and OBJECTPROPERTY(id, N'IsProcedure') = 1)
              drop procedure [dbo].[test_sp]
            """""")
        self.cursor.execute(
            """"""
            create procedure test_sp(@d1 datetime, @d2 datetime)
            AS
              declare @d as int
              set @d = datediff(year, @d1, @d2)
              select @d
            """""")
        self.cursor.execute(""exec test_sp ?, ?"", datetime.now(), datetime.now())
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(rows[0][0] == 0)   # 0 years apart

    def test_sp_with_none(self):
        # Reported in the forums that passing None caused an error.
        self.cursor.execute(
            """"""
            if exists (select * from dbo.sysobjects where id = object_id(N'[test_sp]') and OBJECTPROPERTY(id, N'IsProcedure') = 1)
              drop procedure [dbo].[test_sp]
            """""")
        self.cursor.execute(
            """"""
            create procedure test_sp(@x varchar(20))
            AS
              declare @y varchar(20)
              set @y = @x
              select @y
            """""")
        self.cursor.execute(""exec test_sp ?"", None)
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(rows[0][0] == None)   # 0 years apart


    #
    # rowcount
    #

    def test_rowcount_delete(self):
        self.assertEqual(self.cursor.rowcount, -1)
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, count)

    def test_rowcount_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.  On the other hand, we could hardcode a
        zero return value.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, 0)

    def test_rowcount_select(self):
        """"""
        Ensure Cursor.rowcount is set properly after a select statement.

        pyodbc calls SQLRowCount after each execute and sets Cursor.rowcount, but SQL Server 2005 returns -1 after a
        select statement, so we'll test for that behavior.  This is valid behavior according to the DB API
        specification, but people don't seem to like it.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""select * from t1"")
        self.assertEqual(self.cursor.rowcount, -1)

        rows = self.cursor.fetchall()
        self.assertEqual(len(rows), count)
        self.assertEqual(self.cursor.rowcount, -1)

    def test_rowcount_reset(self):
        ""Ensure rowcount is reset to -1""

        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.assertEqual(self.cursor.rowcount, 1)

        self.cursor.execute(""create table t2(i int)"")
        self.assertEqual(self.cursor.rowcount, -1)

    #
    # always return Cursor
    #

    # In the 2.0.x branch, Cursor.execute sometimes returned the cursor and sometimes the rowcount.  This proved very
    # confusing when things went wrong and added very little value even when things went right since users could always
    # use: cursor.execute(""..."").rowcount

    def test_retcursor_delete(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_select(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""select * from t1"")
        self.assertEqual(v, self.cursor)

    #
    # misc
    #

    def table_with_spaces(self):
        ""Ensure we can select using [x z] syntax""

        try:
            self.cursor.execute(""create table [test one](int n)"")
            self.cursor.execute(""insert into [test one] values(1)"")
            self.cursor.execute(""select * from [test one]"")
            v = self.cursor.fetchone()[0]
            self.assertEqual(v, 1)
        finally:
            self.cnxn.rollback()

    def test_lower_case(self):
        ""Ensure pyodbc.lowercase forces returned column names to lowercase.""

        # Has to be set before creating the cursor, so we must recreate self.cursor.

        pyodbc.lowercase = True
        self.cursor = self.cnxn.cursor()

        self.cursor.execute(""create table t1(Abc int, dEf int)"")
        self.cursor.execute(""select * from t1"")

        names = [ t[0] for t in self.cursor.description ]
        names.sort()

        self.assertEqual(names, [ ""abc"", ""def"" ])

        # Put it back so other tests don't fail.
        pyodbc.lowercase = False

    def test_row_description(self):
        """"""
        Ensure Cursor.description is accessible as Row.cursor_description.
        """"""
        self.cursor = self.cnxn.cursor()
        self.cursor.execute(""create table t1(a int, b char(3))"")
        self.cnxn.commit()
        self.cursor.execute(""insert into t1 values(1, 'abc')"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        self.assertEqual(self.cursor.description, row.cursor_description)


    def test_temp_select(self):
        # A project was failing to create temporary tables via select into.
        self.cursor.execute(""create table t1(s char(7))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), unicode)
        self.assertEqual(v, ""testing"")

        self.cursor.execute(""select s into t2 from t1"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), unicode)
        self.assertEqual(v, ""testing"")


    def test_money(self):
        d = Decimal('123456.78')
        self.cursor.execute(""create table t1(i int identity(1,1), m money)"")
        self.cursor.execute(""insert into t1(m) values (?)"", d)
        v = self.cursor.execute(""select m from t1"").fetchone()[0]
        self.assertEqual(v, d)


    def test_executemany(self):
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (i, str(i)) for i in range(1, 6) ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])


    def test_executemany_one(self):
        ""Pass executemany a single sequence""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, ""test"") ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])


    def test_executemany_failure(self):
        """"""
        Ensure that an exception is raised if one query in an executemany fails.
        """"""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, 'good'),
                   ('error', 'not an int'),
                   (3, 'good') ]

        self.assertRaises(pyodbc.Error, self.cursor.executemany, ""insert into t1(a, b) value (?, ?)"", params)


    def test_row_slicing(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = row[:]
        self.assertTrue(result is row)

        result = row[:-1]
        self.assertEqual(result, (1,2,3))

        result = row[0:4]
        self.assertTrue(result is row)


    def test_row_repr(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = str(row)
        self.assertEqual(result, ""(1, 2, 3, 4)"")

        result = str(row[:-1])
        self.assertEqual(result, ""(1, 2, 3)"")

        result = str(row[:1])
        self.assertEqual(result, ""(1,)"")


    def test_concatenation(self):
        v2 = '0123456789' * 30
        v3 = '9876543210' * 30

        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(300), c3 varchar(300))"")
        self.cursor.execute(""insert into t1(c2, c3) values (?,?)"", v2, v3)

        row = self.cursor.execute(""select c2, c3, c2 + c3 as both from t1"").fetchone()

        self.assertEqual(row.both, v2 + v3)

    def test_view_select(self):
        # Reported in forum: Can't select from a view?  I think I do this a lot, but another test never hurts.

        # Create a table (t1) with 3 rows and a view (t2) into it.
        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(50))"")
        for i in range(3):
            self.cursor.execute(""insert into t1(c2) values (?)"", ""string%s"" % i)
        self.cursor.execute(""create view t2 as select * from t1"")

        # Select from the view
        self.cursor.execute(""select * from t2"")
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(len(rows) == 3)

    def test_autocommit(self):
        self.assertEqual(self.cnxn.autocommit, False)

        othercnxn = pyodbc.connect(self.connection_string, autocommit=True)
        self.assertEqual(othercnxn.autocommit, True)

        othercnxn.autocommit = False
        self.assertEqual(othercnxn.autocommit, False)

    def test_cursorcommit(self):
        ""Ensure cursor.commit works""
        othercnxn = pyodbc.connect(self.connection_string)
        othercursor = othercnxn.cursor()
        othercnxn = None

        othercursor.execute(""create table t1(s varchar(20))"")
        othercursor.execute(""insert into t1 values(?)"", 'test')
        othercursor.commit()

        value = self.cursor.execute(""select s from t1"").fetchone()[0]
        self.assertEqual(value, 'test')


    def test_unicode_results(self):
        ""Ensure unicode_results forces Unicode""
        othercnxn = pyodbc.connect(self.connection_string, unicode_results=True)
        othercursor = othercnxn.cursor()

        # ANSI data in an ANSI column ...
        othercursor.execute(""create table t1(s varchar(20))"")
        othercursor.execute(""insert into t1 values(?)"", 'test')

        # ... should be returned as Unicode
        value = othercursor.execute(""select s from t1"").fetchone()[0]
        self.assertEqual(value, u'test')


    def test_sqlserver_callproc(self):
        try:
            self.cursor.execute(""drop procedure pyodbctest"")
            self.cnxn.commit()
        except:
            pass

        self.cursor.execute(""create table t1(s varchar(10))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")

        self.cursor.execute(""""""
                            create procedure pyodbctest @var1 varchar(32)
                            as
                            begin
                              select s
                              from t1
                            return
                            end
                            """""")
        self.cnxn.commit()

        # for row in self.cursor.procedureColumns('pyodbctest'):
        #     print row.procedure_name, row.column_name, row.column_type, row.type_name

        self.cursor.execute(""exec pyodbctest 'hi'"")

        # print self.cursor.description
        # for row in self.cursor:
        #     print row.s

    def test_skip(self):
        # Insert 1, 2, and 3.  Fetch 1, skip 2, fetch 3.

        self.cursor.execute(""create table t1(id int)"");
        for i in range(1, 5):
            self.cursor.execute(""insert into t1 values(?)"", i)
        self.cursor.execute(""select id from t1 order by id"")
        self.assertEqual(self.cursor.fetchone()[0], 1)
        self.cursor.skip(2)
        self.assertEqual(self.cursor.fetchone()[0], 4)

    def test_timeout(self):
        self.assertEqual(self.cnxn.timeout, 0) # defaults to zero (off)

        self.cnxn.timeout = 30
        self.assertEqual(self.cnxn.timeout, 30)

        self.cnxn.timeout = 0
        self.assertEqual(self.cnxn.timeout, 0)

    def test_sets_execute(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.execute(""insert into t1 (word) VALUES (?)"", [words])

        self.assertRaises(pyodbc.ProgrammingError, f)

    def test_sets_executemany(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.executemany(""insert into t1 (word) values (?)"", [words])

        self.assertRaises(TypeError, f)

    def test_row_execute(self):
        ""Ensure we can use a Row object as a parameter to execute""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, 'a')"")
        row = self.cursor.execute(""select n, s from t1"").fetchone()
        self.assertNotEqual(row, None)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.execute(""insert into t2 values (?, ?)"", row)

    def test_row_executemany(self):
        ""Ensure we can use a Row object as a parameter to executemany""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")

        for i in range(3):
            self.cursor.execute(""insert into t1 values (?, ?)"", i, chr(ord('a')+i))

        rows = self.cursor.execute(""select n, s from t1"").fetchall()
        self.assertNotEqual(len(rows), 0)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.executemany(""insert into t2 values (?, ?)"", rows)

    def test_description(self):
        ""Ensure cursor.description is correct""

        self.cursor.execute(""create table t1(n int, s varchar(8), d decimal(5,2))"")
        self.cursor.execute(""insert into t1 values (1, 'abc', '1.23')"")
        self.cursor.execute(""select * from t1"")

        # (I'm not sure the precision of an int is constant across different versions, bits, so I'm hand checking the
        # items I do know.

        # int
        t = self.cursor.description[0]
        self.assertEqual(t[0], 'n')
        self.assertEqual(t[1], int)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # varchar(8)
        t = self.cursor.description[1]
        self.assertEqual(t[0], 's')
        self.assertEqual(t[1], str)
        self.assertEqual(t[4], 8)       # precision
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # decimal(5, 2)
        t = self.cursor.description[2]
        self.assertEqual(t[0], 'd')
        self.assertEqual(t[1], Decimal)
        self.assertEqual(t[4], 5)       # precision
        self.assertEqual(t[5], 2)       # scale
        self.assertEqual(t[6], True)    # nullable


    def test_none_param(self):
        ""Ensure None can be used for params other than the first""
        # Some driver/db versions would fail if NULL was not the first parameter because SQLDescribeParam (only used
        # with NULL) could not be used after the first call to SQLBindParameter.  This means None always worked for the
        # first column, but did not work for later columns.
        #
        # If SQLDescribeParam doesn't work, pyodbc would use VARCHAR which almost always worked.  However,
        # binary/varbinary won't allow an implicit conversion.

        self.cursor.execute(""create table t1(n int, blob varbinary(max))"")
        self.cursor.execute(""insert into t1 values (1, newid())"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row.n, 1)
        self.assertEqual(type(row.blob), bytearray)

        self.cursor.execute(""update t1 set n=?, blob=?"", 2, None)
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row.n, 2)
        self.assertEqual(row.blob, None)


    def test_output_conversion(self):
        def convert(value):
            # `value` will be a string.  We'll simply add an X at the beginning at the end.
            return 'X' + value + 'X'
        self.cnxn.add_output_converter(pyodbc.SQL_VARCHAR, convert)
        self.cursor.execute(""create table t1(n int, v varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, '123.45')"")
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, 'X123.45X')

        # Now clear the conversions and try again.  There should be no Xs this time.
        self.cnxn.clear_output_converters()
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, '123.45')


    def test_too_large(self):
        """"""Ensure error raised if insert fails due to truncation""""""
        value = 'x' * 1000
        self.cursor.execute(""create table t1(s varchar(800))"")
        def test():
            self.cursor.execute(""insert into t1 values (?)"", value)
        self.assertRaises(pyodbc.DataError, test)

    def test_geometry_null_insert(self):
        def convert(value):
            return value

        self.cnxn.add_output_converter(-151, convert) # -151 is SQL Server's geometry
        self.cursor.execute(""create table t1(n int, v geometry)"")
        self.cursor.execute(""insert into t1 values (?, ?)"", 1, None)
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, None)
        self.cnxn.clear_output_converters()

    def test_login_timeout(self):
        # This can only test setting since there isn't a way to cause it to block on the server side.
        cnxns = pyodbc.connect(self.connection_string, timeout=2)

    def test_row_equal(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test')"")
        row1 = self.cursor.execute(""select n, s from t1"").fetchone()
        row2 = self.cursor.execute(""select n, s from t1"").fetchone()
        b = (row1 == row2)
        self.assertEqual(b, True)

    def test_row_gtlt(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test1')"")
        self.cursor.execute(""insert into t1 values (1, 'test2')"")
        rows = self.cursor.execute(""select n, s from t1 order by s"").fetchall()
        self.assertTrue(rows[0] < rows[1])
        self.assertTrue(rows[0] <= rows[1])
        self.assertTrue(rows[1] > rows[0])
        self.assertTrue(rows[1] >= rows[0])
        self.assertTrue(rows[0] != rows[1])

        rows = list(rows)
        rows.sort() # uses <

    def test_context_manager_success(self):
        """"""
        Ensure a successful with statement causes a commit.
        """"""
        self.cursor.execute(""create table t1(n int)"")
        self.cnxn.commit()

        with pyodbc.connect(self.connection_string) as cnxn:
            cursor = cnxn.cursor()
            cursor.execute(""insert into t1 values (1)"")

        cnxn = None
        cursor = None

        rows = self.cursor.execute(""select n from t1"").fetchall()
        self.assertEqual(len(rows), 1)
        self.assertEqual(rows[0][0], 1)


    def test_context_manager_fail(self):
        """"""
        Ensure an exception in a with statement causes a rollback.
        """"""
        self.cursor.execute(""create table t1(n int)"")
        self.cnxn.commit()

        try:
            with pyodbc.connect(self.connection_string) as cnxn:
                cursor = cnxn.cursor()
                cursor.execute(""insert into t1 values (1)"")
                raise Exception(""Testing failure"")
        except Exception:
            pass

        cnxn = None
        cursor = None

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, 0)


    def test_cursor_context_manager_success(self):
        """"""
        Ensure a successful with statement using a cursor causes a commit.
        """"""
        self.cursor.execute(""create table t1(n int)"")
        self.cnxn.commit()

        with pyodbc.connect(self.connection_string).cursor() as cursor:
            cursor.execute(""insert into t1 values (1)"")

        cursor = None

        rows = self.cursor.execute(""select n from t1"").fetchall()
        self.assertEqual(len(rows), 1)
        self.assertEqual(rows[0][0], 1)


    def test_cursor_context_manager_fail(self):
        """"""
        Ensure an exception in a with statement using a cursor causes a rollback.
        """"""
        self.cursor.execute(""create table t1(n int)"")
        self.cnxn.commit()

        try:
            with pyodbc.connect(self.connection_string).cursor() as cursor:
                cursor.execute(""insert into t1 values (1)"")
                raise Exception(""Testing failure"")
        except Exception:
            pass

        cursor = None

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, 0)


    def test_untyped_none(self):
        # From issue 129
        value = self.cursor.execute(""select ?"", None).fetchone()[0]
        self.assertEqual(value, None)

    def test_large_update_nodata(self):
        self.cursor.execute('create table t1(a varbinary(max))')
        hundredkb = bytearray('x'*100*1024)
        self.cursor.execute('update t1 set a=? where 1=0', (hundredkb,))

    def test_func_param(self):
        self.cursor.execute('''
                            create function func1 (@testparam varchar(4))
                            returns @rettest table (param varchar(4))
                            as
                            begin
                                insert @rettest
                                select @testparam
                                return
                            end
                            ''')
        self.cnxn.commit()
        value = self.cursor.execute(""select * from func1(?)"", 'test').fetchone()[0]
        self.assertEqual(value, 'test')

    def test_no_fetch(self):
        # Issue 89 with FreeTDS: Multiple selects (or catalog functions that issue selects) without fetches seem to
        # confuse the driver.
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')

    def test_drivers(self):
        drivers = pyodbc.drivers()
        self.assertEqual(list, type(drivers))
        self.assertTrue(len(drivers) > 0)

        m = re.search('DRIVER={([^}]+)}', self.connection_string, re.IGNORECASE)
        current = m.group(1)
        self.assertTrue(current in drivers)

    def test_prepare_cleanup(self):
        # When statement is prepared, it is kept in case the next execute uses the same statement.  This must be
        # removed when a non-execute statement is used that returns results, such as SQLTables.

        self.cursor.execute(""select top 1 name from sysobjects where name = ?"", ""bogus"")
        self.cursor.fetchone()

        self.cursor.tables(""bogus"")

        self.cursor.execute(""select top 1 name from sysobjects where name = ?"", ""bogus"")
        self.cursor.fetchone()

    def test_exc_integrity(self):
        ""Make sure an IntegretyError is raised""
        # This is really making sure we are properly encoding and comparing the SQLSTATEs.
        self.cursor.execute(""create table t1(s1 varchar(10) primary key)"")
        self.cursor.execute(""insert into t1 values ('one')"")
        self.assertRaises(pyodbc.IntegrityError, self.cursor.execute, ""insert into t1 values ('one')"")

    def test_emoticons(self):
        # https://github.com/mkleehammer/pyodbc/issues/423
        #
        # When sending a varchar parameter, pyodbc is supposed to set ColumnSize to the number
        # of characters.  Ensure it works even with 4-byte characters.
        #
        # http://www.fileformat.info/info/unicode/char/1f31c/index.htm

        v = ""x \U0001F31C z""

        self.cursor.execute(""create table t1(s varchar(100))"")
        self.cursor.execute(""insert into t1 values (?)"", v)

        result = self.cursor.execute(""select s from t1"").fetchone()[0]

        self.assertEqual(result, v)
        
def main():
    from optparse import OptionParser
    parser = OptionParser(usage=usage)
    parser.add_option(""-v"", ""--verbose"", action=""count"", help=""Increment test verbosity (can be used multiple times)"")
    parser.add_option(""-d"", ""--debug"", action=""store_true"", default=False, help=""Print debugging items"")
    parser.add_option(""-t"", ""--test"", help=""Run only the named test"")

    (options, args) = parser.parse_args()

    if len(args) > 1:
        parser.error('Only one argument is allowed.  Do you need quotes around the connection string?')

    if not args:
        connection_string = load_setup_connection_string('sqlservertests')

        if not connection_string:
            parser.print_help()
            raise SystemExit()
    else:
        connection_string = args[0]

    cnxn = pyodbc.connect(connection_string)
    print_library_info(cnxn)
    cnxn.close()

    suite = load_tests(SqlServerTestCase, options.test, connection_string)

    testRunner = unittest.TextTestRunner(verbosity=options.verbose)
    result = testRunner.run(suite)


if __name__ == '__main__':

    # Add the build directory to the path so we're testing the latest build, not the installed version.

    add_to_path()

    import pyodbc
    main()
/n/n/ntests3/informixtests.py/n/n#!/usr/bin/python
# -*- coding: latin-1 -*-

usage = """"""\
usage: %prog [options] connection_string

Unit tests for Informix DB.  To use, pass a connection string as the parameter.
The tests will create and drop tables t1 and t2 as necessary.

These run using the version from the 'build' directory, not the version
installed into the Python directories.  You must run python setup.py build
before running the tests.

You can also put the connection string into a tmp/setup.cfg file like so:

  [informixtests]
  connection-string=DRIVER={IBM INFORMIX ODBC DRIVER (64-bit)};SERVER=localhost;UID=uid;PWD=pwd;DATABASE=db
""""""

import sys, os, re
import unittest
from decimal import Decimal
from datetime import datetime, date, time
from os.path import join, getsize, dirname, abspath
from testutils import *

_TESTSTR = '0123456789-abcdefghijklmnopqrstuvwxyz-'

def _generate_test_string(length):
    """"""
    Returns a string of `length` characters, constructed by repeating _TESTSTR as necessary.

    To enhance performance, there are 3 ways data is read, based on the length of the value, so most data types are
    tested with 3 lengths.  This function helps us generate the test data.

    We use a recognizable data set instead of a single character to make it less likely that ""overlap"" errors will
    be hidden and to help us manually identify where a break occurs.
    """"""
    if length <= len(_TESTSTR):
        return _TESTSTR[:length]

    c = (length + len(_TESTSTR)-1) / len(_TESTSTR)
    v = _TESTSTR * c
    return v[:length]

class InformixTestCase(unittest.TestCase):

    SMALL_FENCEPOST_SIZES = [ 0, 1, 255, 256, 510, 511, 512, 1023, 1024, 2047, 2048, 4000 ]
    LARGE_FENCEPOST_SIZES = [ 4095, 4096, 4097, 10 * 1024, 20 * 1024 ]

    ANSI_FENCEPOSTS    = [ _generate_test_string(size) for size in SMALL_FENCEPOST_SIZES ]
    UNICODE_FENCEPOSTS = [ unicode(s) for s in ANSI_FENCEPOSTS ]
    IMAGE_FENCEPOSTS   = ANSI_FENCEPOSTS + [ _generate_test_string(size) for size in LARGE_FENCEPOST_SIZES ]

    def __init__(self, method_name, connection_string):
        unittest.TestCase.__init__(self, method_name)
        self.connection_string = connection_string

    def setUp(self):
        self.cnxn   = pyodbc.connect(self.connection_string)
        self.cursor = self.cnxn.cursor()

        for i in range(3):
            try:
                self.cursor.execute(""drop table t%d"" % i)
                self.cnxn.commit()
            except:
                pass

        for i in range(3):
            try:
                self.cursor.execute(""drop procedure proc%d"" % i)
                self.cnxn.commit()
            except:
                pass

        try:
            self.cursor.execute('drop function func1')
            self.cnxn.commit()
        except:
            pass

        self.cnxn.rollback()

    def tearDown(self):
        try:
            self.cursor.close()
            self.cnxn.close()
        except:
            # If we've already closed the cursor or connection, exceptions are thrown.
            pass

    def test_multiple_bindings(self):
        ""More than one bind and select on a cursor""
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t1 values (?)"", 2)
        self.cursor.execute(""insert into t1 values (?)"", 3)
        for i in range(3):
            self.cursor.execute(""select n from t1 where n < ?"", 10)
            self.cursor.execute(""select n from t1 where n < 3"")
        

    def test_different_bindings(self):
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""create table t2(d datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t2 values (?)"", datetime.now())

    def test_drivers(self):
        p = pyodbc.drivers()
        self.assertTrue(isinstance(p, list))

    def test_datasources(self):
        p = pyodbc.dataSources()
        self.assertTrue(isinstance(p, dict))

    def test_getinfo_string(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CATALOG_NAME_SEPARATOR)
        self.assertTrue(isinstance(value, str))

    def test_getinfo_bool(self):
        value = self.cnxn.getinfo(pyodbc.SQL_ACCESSIBLE_TABLES)
        self.assertTrue(isinstance(value, bool))

    def test_getinfo_int(self):
        value = self.cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)
        self.assertTrue(isinstance(value, (int, long)))

    def test_getinfo_smallint(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CONCAT_NULL_BEHAVIOR)
        self.assertTrue(isinstance(value, int))

    def test_noscan(self):
        self.assertEqual(self.cursor.noscan, False)
        self.cursor.noscan = True
        self.assertEqual(self.cursor.noscan, True)

    def test_guid(self):
        self.cursor.execute(""create table t1(g1 uniqueidentifier)"")
        self.cursor.execute(""insert into t1 values (newid())"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(len(v), 36)

    def test_nextset(self):
        self.cursor.execute(""create table t1(i int)"")
        for i in range(4):
            self.cursor.execute(""insert into t1(i) values(?)"", i)

        self.cursor.execute(""select i from t1 where i < 2 order by i; select i from t1 where i >= 2 order by i"")
        
        for i, row in enumerate(self.cursor):
            self.assertEqual(i, row.i)

        self.assertEqual(self.cursor.nextset(), True)

        for i, row in enumerate(self.cursor):
            self.assertEqual(i + 2, row.i)

    def test_fixed_unicode(self):
        value = u""t\xebsting""
        self.cursor.execute(""create table t1(s nchar(7))"")
        self.cursor.execute(""insert into t1 values(?)"", u""t\xebsting"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), unicode)
        self.assertEqual(len(v), len(value)) # If we alloc'd wrong, the test below might work because of an embedded NULL
        self.assertEqual(v, value)


    def _test_strtype(self, sqltype, value, colsize=None):
        """"""
        The implementation for string, Unicode, and binary tests.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)

        # Reported by Andy Hochhaus in the pyodbc group: In 2.1.7 and earlier, a hardcoded length of 255 was used to
        # determine whether a parameter was bound as a SQL_VARCHAR or SQL_LONGVARCHAR.  Apparently SQL Server chokes if
        # we bind as a SQL_LONGVARCHAR and the target column size is 8000 or less, which is considers just SQL_VARCHAR.
        # This means binding a 256 character value would cause problems if compared with a VARCHAR column under
        # 8001. We now use SQLGetTypeInfo to determine the time to switch.
        #
        # [42000] [Microsoft][SQL Server Native Client 10.0][SQL Server]The data types varchar and text are incompatible in the equal to operator.

        self.cursor.execute(""select * from t1 where s=?"", value)


    def _test_strliketype(self, sqltype, value, colsize=None):
        """"""
        The implementation for text, image, ntext, and binary.

        These types do not support comparison operators.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)


    #
    # varchar
    #

    def test_varchar_null(self):
        self._test_strtype('varchar', None, 100)

    # Generate a test for each fencepost size: test_varchar_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('varchar', value, len(value))
        return t
    for value in ANSI_FENCEPOSTS:
        locals()['test_varchar_%s' % len(value)] = _maketest(value)

    def test_varchar_many(self):
        self.cursor.execute(""create table t1(c1 varchar(300), c2 varchar(300), c3 varchar(300))"")

        v1 = 'ABCDEFGHIJ' * 30
        v2 = '0123456789' * 30
        v3 = '9876543210' * 30

        self.cursor.execute(""insert into t1(c1, c2, c3) values (?,?,?)"", v1, v2, v3);
        row = self.cursor.execute(""select c1, c2, c3, len(c1) as l1, len(c2) as l2, len(c3) as l3 from t1"").fetchone()

        self.assertEqual(v1, row.c1)
        self.assertEqual(v2, row.c2)
        self.assertEqual(v3, row.c3)

    def test_varchar_upperlatin(self):
        self._test_strtype('varchar', '�')

    #
    # unicode
    #

    def test_unicode_null(self):
        self._test_strtype('nvarchar', None, 100)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('nvarchar', value, len(value))
        return t
    for value in UNICODE_FENCEPOSTS:
        locals()['test_unicode_%s' % len(value)] = _maketest(value)

    def test_unicode_upperlatin(self):
        self._test_strtype('varchar', '�')

    #
    # binary
    #

    def test_null_binary(self):
        self._test_strtype('varbinary', None, 100)
     
    def test_large_null_binary(self):
        # Bug 1575064
        self._test_strtype('varbinary', None, 4000)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('varbinary', buffer(value), len(value))
        return t
    for value in ANSI_FENCEPOSTS:
        locals()['test_binary_%s' % len(value)] = _maketest(value)

    #
    # image
    #

    def test_image_null(self):
        self._test_strliketype('image', None)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strliketype('image', buffer(value))
        return t
    for value in IMAGE_FENCEPOSTS:
        locals()['test_image_%s' % len(value)] = _maketest(value)

    def test_image_upperlatin(self):
        self._test_strliketype('image', buffer('�'))

    #
    # text
    #

    # def test_empty_text(self):
    #     self._test_strliketype('text', buffer(''))

    def test_null_text(self):
        self._test_strliketype('text', None)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strliketype('text', value)
        return t
    for value in ANSI_FENCEPOSTS:
        locals()['test_text_%s' % len(value)] = _maketest(value)

    def test_text_upperlatin(self):
        self._test_strliketype('text', '�')

    #
    # bit
    #

    def test_bit(self):
        value = True
        self.cursor.execute(""create table t1(b bit)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        v = self.cursor.execute(""select b from t1"").fetchone()[0]
        self.assertEqual(type(v), bool)
        self.assertEqual(v, value)

    #
    # decimal
    #

    def _decimal(self, precision, scale, negative):
        # From test provided by planders (thanks!) in Issue 91

        self.cursor.execute(""create table t1(d decimal(%s, %s))"" % (precision, scale))

        # Construct a decimal that uses the maximum precision and scale.
        decStr = '9' * (precision - scale)
        if scale:
            decStr = decStr + ""."" + '9' * scale
        if negative:
            decStr = ""-"" + decStr
        value = Decimal(decStr)

        self.cursor.execute(""insert into t1 values(?)"", value)

        v = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(v, value)

    def _maketest(p, s, n):
        def t(self):
            self._decimal(p, s, n)
        return t
    for (p, s, n) in [ (1,  0,  False),
                       (1,  0,  True),
                       (6,  0,  False),
                       (6,  2,  False),
                       (6,  4,  True),
                       (6,  6,  True),
                       (38, 0,  False),
                       (38, 10, False),
                       (38, 38, False),
                       (38, 0,  True),
                       (38, 10, True),
                       (38, 38, True) ]:
        locals()['test_decimal_%s_%s_%s' % (p, s, n and 'n' or 'p')] = _maketest(p, s, n)


    def test_decimal_e(self):
        """"""Ensure exponential notation decimals are properly handled""""""
        value = Decimal((0, (1, 2, 3), 5)) # prints as 1.23E+7
        self.cursor.execute(""create table t1(d decimal(10, 2))"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_subquery_params(self):
        """"""Ensure parameter markers work in a subquery""""""
        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        row = self.cursor.execute(""""""
                                  select x.id
                                  from (
                                    select id
                                    from t1
                                    where s = ?
                                      and id between ? and ?
                                   ) x
                                   """""", 'test', 1, 10).fetchone()
        self.assertNotEqual(row, None)
        self.assertEqual(row[0], 1)

    def _exec(self):
        self.cursor.execute(self.sql)
        
    def test_close_cnxn(self):
        """"""Make sure using a Cursor after closing its connection doesn't crash.""""""

        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        self.cursor.execute(""select * from t1"")

        self.cnxn.close()
        
        # Now that the connection is closed, we expect an exception.  (If the code attempts to use
        # the HSTMT, we'll get an access violation instead.)
        self.sql = ""select * from t1""
        self.assertRaises(pyodbc.ProgrammingError, self._exec)

    def test_empty_string(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", """")

    def test_fixed_str(self):
        value = ""testing""
        self.cursor.execute(""create table t1(s char(7))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(len(v), len(value)) # If we alloc'd wrong, the test below might work because of an embedded NULL
        self.assertEqual(v, value)

    def test_empty_unicode(self):
        self.cursor.execute(""create table t1(s nvarchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", u"""")

    def test_unicode_query(self):
        self.cursor.execute(u""select 1"")
        
    def test_negative_row_index(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", ""1"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row[0], ""1"")
        self.assertEqual(row[-1], ""1"")

    def test_version(self):
        self.assertEqual(3, len(pyodbc.version.split('.'))) # 1.3.1 etc.

    #
    # date, time, datetime
    #

    def test_datetime(self):
        value = datetime(2007, 1, 15, 3, 4, 5)

        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(value, result)

    def test_datetime_fraction(self):
        # SQL Server supports milliseconds, but Python's datetime supports nanoseconds, so the most granular datetime
        # supported is xxx000.

        value = datetime(2007, 1, 15, 3, 4, 5, 123000)
     
        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
     
        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(result, value)

    def test_datetime_fraction_rounded(self):
        # SQL Server supports milliseconds, but Python's datetime supports nanoseconds.  pyodbc rounds down to what the
        # database supports.

        full    = datetime(2007, 1, 15, 3, 4, 5, 123456)
        rounded = datetime(2007, 1, 15, 3, 4, 5, 123000)
     
        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", full)
     
        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(result), datetime)
        self.assertEqual(result, rounded)

    def test_date(self):
        value = date.today()
     
        self.cursor.execute(""create table t1(d date)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
     
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(type(value), date)
        self.assertEqual(value, result)

    def test_time(self):
        value = datetime.now().time()
        
        # We aren't yet writing values using the new extended time type so the value written to the database is only
        # down to the second.
        value = value.replace(microsecond=0)
         
        self.cursor.execute(""create table t1(t time)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
         
        result = self.cursor.execute(""select t from t1"").fetchone()[0]
        self.assertEqual(type(value), time)
        self.assertEqual(value, result)

    def test_datetime2(self):
        value = datetime(2007, 1, 15, 3, 4, 5)

        self.cursor.execute(""create table t1(dt datetime2)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(value, result)

    #
    # ints and floats
    #

    def test_int(self):
        value = 1234
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_int(self):
        value = -1
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_bigint(self):
        input = 3000000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_float(self):
        value = 1234.567
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_float(self):
        value = -200
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result  = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(value, result)


    #
    # stored procedures
    #

    # def test_callproc(self):
    #     ""callproc with a simple input-only stored procedure""
    #     pass

    def test_sp_results(self):
        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              select top 10 name, id, xtype, refdate
              from sysobjects
            """""")
        rows = self.cursor.execute(""exec proc1"").fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)


    def test_sp_results_from_temp(self):

        # Note: I've used ""set nocount on"" so that we don't get the number of rows deleted from #tmptable.
        # If you don't do this, you'd need to call nextset() once to skip it.

        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              set nocount on
              select top 10 name, id, xtype, refdate
              into #tmptable
              from sysobjects

              select * from #tmptable
            """""")
        self.cursor.execute(""exec proc1"")
        self.assertTrue(self.cursor.description is not None)
        self.assertTrue(len(self.cursor.description) == 4)

        rows = self.cursor.fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)


    def test_sp_results_from_vartbl(self):
        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              set nocount on
              declare @tmptbl table(name varchar(100), id int, xtype varchar(4), refdate datetime)

              insert into @tmptbl
              select top 10 name, id, xtype, refdate
              from sysobjects

              select * from @tmptbl
            """""")
        self.cursor.execute(""exec proc1"")
        rows = self.cursor.fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)

    def test_sp_with_dates(self):
        # Reported in the forums that passing two datetimes to a stored procedure doesn't work.
        self.cursor.execute(
            """"""
            if exists (select * from dbo.sysobjects where id = object_id(N'[test_sp]') and OBJECTPROPERTY(id, N'IsProcedure') = 1)
              drop procedure [dbo].[test_sp]
            """""")
        self.cursor.execute(
            """"""
            create procedure test_sp(@d1 datetime, @d2 datetime)
            AS
              declare @d as int
              set @d = datediff(year, @d1, @d2)
              select @d
            """""")
        self.cursor.execute(""exec test_sp ?, ?"", datetime.now(), datetime.now())
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(rows[0][0] == 0)   # 0 years apart

    def test_sp_with_none(self):
        # Reported in the forums that passing None caused an error.
        self.cursor.execute(
            """"""
            if exists (select * from dbo.sysobjects where id = object_id(N'[test_sp]') and OBJECTPROPERTY(id, N'IsProcedure') = 1)
              drop procedure [dbo].[test_sp]
            """""")
        self.cursor.execute(
            """"""
            create procedure test_sp(@x varchar(20))
            AS
              declare @y varchar(20)
              set @y = @x
              select @y
            """""")
        self.cursor.execute(""exec test_sp ?"", None)
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(rows[0][0] == None)   # 0 years apart
        

    #
    # rowcount
    #

    def test_rowcount_delete(self):
        self.assertEqual(self.cursor.rowcount, -1)
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, count)

    def test_rowcount_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.  On the other hand, we could hardcode a
        zero return value.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, 0)

    def test_rowcount_select(self):
        """"""
        Ensure Cursor.rowcount is set properly after a select statement.

        pyodbc calls SQLRowCount after each execute and sets Cursor.rowcount, but SQL Server 2005 returns -1 after a
        select statement, so we'll test for that behavior.  This is valid behavior according to the DB API
        specification, but people don't seem to like it.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""select * from t1"")
        self.assertEqual(self.cursor.rowcount, -1)

        rows = self.cursor.fetchall()
        self.assertEqual(len(rows), count)
        self.assertEqual(self.cursor.rowcount, -1)

    def test_rowcount_reset(self):
        ""Ensure rowcount is reset to -1""

        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.assertEqual(self.cursor.rowcount, 1)

        self.cursor.execute(""create table t2(i int)"")
        self.assertEqual(self.cursor.rowcount, -1)

    #
    # always return Cursor
    #

    # In the 2.0.x branch, Cursor.execute sometimes returned the cursor and sometimes the rowcount.  This proved very
    # confusing when things went wrong and added very little value even when things went right since users could always
    # use: cursor.execute(""..."").rowcount

    def test_retcursor_delete(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_select(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""select * from t1"")
        self.assertEqual(v, self.cursor)

    #
    # misc
    #

    def test_lower_case(self):
        ""Ensure pyodbc.lowercase forces returned column names to lowercase.""

        # Has to be set before creating the cursor, so we must recreate self.cursor.

        pyodbc.lowercase = True
        self.cursor = self.cnxn.cursor()

        self.cursor.execute(""create table t1(Abc int, dEf int)"")
        self.cursor.execute(""select * from t1"")

        names = [ t[0] for t in self.cursor.description ]
        names.sort()

        self.assertEqual(names, [ ""abc"", ""def"" ])

        # Put it back so other tests don't fail.
        pyodbc.lowercase = False
        
    def test_row_description(self):
        """"""
        Ensure Cursor.description is accessible as Row.cursor_description.
        """"""
        self.cursor = self.cnxn.cursor()
        self.cursor.execute(""create table t1(a int, b char(3))"")
        self.cnxn.commit()
        self.cursor.execute(""insert into t1 values(1, 'abc')"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        self.assertEqual(self.cursor.description, row.cursor_description)
        

    def test_temp_select(self):
        # A project was failing to create temporary tables via select into.
        self.cursor.execute(""create table t1(s char(7))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(v, ""testing"")

        self.cursor.execute(""select s into t2 from t1"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(v, ""testing"")


    def test_money(self):
        d = Decimal('123456.78')
        self.cursor.execute(""create table t1(i int identity(1,1), m money)"")
        self.cursor.execute(""insert into t1(m) values (?)"", d)
        v = self.cursor.execute(""select m from t1"").fetchone()[0]
        self.assertEqual(v, d)


    def test_executemany(self):
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (i, str(i)) for i in range(1, 6) ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])


    def test_executemany_one(self):
        ""Pass executemany a single sequence""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, ""test"") ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])
        

    def test_executemany_failure(self):
        """"""
        Ensure that an exception is raised if one query in an executemany fails.
        """"""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, 'good'),
                   ('error', 'not an int'),
                   (3, 'good') ]
        
        self.assertRaises(pyodbc.Error, self.cursor.executemany, ""insert into t1(a, b) value (?, ?)"", params)

        
    def test_row_slicing(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = row[:]
        self.assertTrue(result is row)

        result = row[:-1]
        self.assertEqual(result, (1,2,3))

        result = row[0:4]
        self.assertTrue(result is row)


    def test_row_repr(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = str(row)
        self.assertEqual(result, ""(1, 2, 3, 4)"")

        result = str(row[:-1])
        self.assertEqual(result, ""(1, 2, 3)"")

        result = str(row[:1])
        self.assertEqual(result, ""(1,)"")


    def test_concatenation(self):
        v2 = '0123456789' * 30
        v3 = '9876543210' * 30

        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(300), c3 varchar(300))"")
        self.cursor.execute(""insert into t1(c2, c3) values (?,?)"", v2, v3)

        row = self.cursor.execute(""select c2, c3, c2 + c3 as both from t1"").fetchone()

        self.assertEqual(row.both, v2 + v3)

    def test_view_select(self):
        # Reported in forum: Can't select from a view?  I think I do this a lot, but another test never hurts.

        # Create a table (t1) with 3 rows and a view (t2) into it.
        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(50))"")
        for i in range(3):
            self.cursor.execute(""insert into t1(c2) values (?)"", ""string%s"" % i)
        self.cursor.execute(""create view t2 as select * from t1"")

        # Select from the view
        self.cursor.execute(""select * from t2"")
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(len(rows) == 3)

    def test_autocommit(self):
        self.assertEqual(self.cnxn.autocommit, False)

        othercnxn = pyodbc.connect(self.connection_string, autocommit=True)
        self.assertEqual(othercnxn.autocommit, True)

        othercnxn.autocommit = False
        self.assertEqual(othercnxn.autocommit, False)

    def test_unicode_results(self):
        ""Ensure unicode_results forces Unicode""
        othercnxn = pyodbc.connect(self.connection_string, unicode_results=True)
        othercursor = othercnxn.cursor()

        # ANSI data in an ANSI column ...
        othercursor.execute(""create table t1(s varchar(20))"")
        othercursor.execute(""insert into t1 values(?)"", 'test')

        # ... should be returned as Unicode
        value = othercursor.execute(""select s from t1"").fetchone()[0]
        self.assertEqual(value, u'test')


    def test_informix_callproc(self):
        try:
            self.cursor.execute(""drop procedure pyodbctest"")
            self.cnxn.commit()
        except:
            pass

        self.cursor.execute(""create table t1(s varchar(10))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")

        self.cursor.execute(""""""
                            create procedure pyodbctest @var1 varchar(32)
                            as 
                            begin 
                              select s 
                              from t1 
                            return 
                            end
                            """""")
        self.cnxn.commit()

        # for row in self.cursor.procedureColumns('pyodbctest'):
        #     print row.procedure_name, row.column_name, row.column_type, row.type_name

        self.cursor.execute(""exec pyodbctest 'hi'"")

        # print self.cursor.description
        # for row in self.cursor:
        #     print row.s

    def test_skip(self):
        # Insert 1, 2, and 3.  Fetch 1, skip 2, fetch 3.

        self.cursor.execute(""create table t1(id int)"");
        for i in range(1, 5):
            self.cursor.execute(""insert into t1 values(?)"", i)
        self.cursor.execute(""select id from t1 order by id"")
        self.assertEqual(self.cursor.fetchone()[0], 1)
        self.cursor.skip(2)
        self.assertEqual(self.cursor.fetchone()[0], 4)

    def test_timeout(self):
        self.assertEqual(self.cnxn.timeout, 0) # defaults to zero (off)

        self.cnxn.timeout = 30
        self.assertEqual(self.cnxn.timeout, 30)

        self.cnxn.timeout = 0
        self.assertEqual(self.cnxn.timeout, 0)

    def test_sets_execute(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.execute(""insert into t1 (word) VALUES (?)"", [words])

        self.assertRaises(pyodbc.ProgrammingError, f)

    def test_sets_executemany(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.executemany(""insert into t1 (word) values (?)"", [words])
            
        self.assertRaises(TypeError, f)

    def test_row_execute(self):
        ""Ensure we can use a Row object as a parameter to execute""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, 'a')"")
        row = self.cursor.execute(""select n, s from t1"").fetchone()
        self.assertNotEqual(row, None)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.execute(""insert into t2 values (?, ?)"", row)
        
    def test_row_executemany(self):
        ""Ensure we can use a Row object as a parameter to executemany""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")

        for i in range(3):
            self.cursor.execute(""insert into t1 values (?, ?)"", i, chr(ord('a')+i))

        rows = self.cursor.execute(""select n, s from t1"").fetchall()
        self.assertNotEqual(len(rows), 0)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.executemany(""insert into t2 values (?, ?)"", rows)
        
    def test_description(self):
        ""Ensure cursor.description is correct""

        self.cursor.execute(""create table t1(n int, s varchar(8), d decimal(5,2))"")
        self.cursor.execute(""insert into t1 values (1, 'abc', '1.23')"")
        self.cursor.execute(""select * from t1"")

        # (I'm not sure the precision of an int is constant across different versions, bits, so I'm hand checking the
        # items I do know.

        # int
        t = self.cursor.description[0]
        self.assertEqual(t[0], 'n')
        self.assertEqual(t[1], int)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # varchar(8)
        t = self.cursor.description[1]
        self.assertEqual(t[0], 's')
        self.assertEqual(t[1], str)
        self.assertEqual(t[4], 8)       # precision
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # decimal(5, 2)
        t = self.cursor.description[2]
        self.assertEqual(t[0], 'd')
        self.assertEqual(t[1], Decimal)
        self.assertEqual(t[4], 5)       # precision
        self.assertEqual(t[5], 2)       # scale
        self.assertEqual(t[6], True)    # nullable

        
    def test_none_param(self):
        ""Ensure None can be used for params other than the first""
        # Some driver/db versions would fail if NULL was not the first parameter because SQLDescribeParam (only used
        # with NULL) could not be used after the first call to SQLBindParameter.  This means None always worked for the
        # first column, but did not work for later columns.
        #
        # If SQLDescribeParam doesn't work, pyodbc would use VARCHAR which almost always worked.  However,
        # binary/varbinary won't allow an implicit conversion.

        self.cursor.execute(""create table t1(n int, blob varbinary(max))"")
        self.cursor.execute(""insert into t1 values (1, newid())"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row.n, 1)
        self.assertEqual(type(row.blob), buffer)

        self.cursor.execute(""update t1 set n=?, blob=?"", 2, None)
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row.n, 2)
        self.assertEqual(row.blob, None)


    def test_output_conversion(self):
        def convert(value):
            # `value` will be a string.  We'll simply add an X at the beginning at the end.
            return 'X' + value + 'X'
        self.cnxn.add_output_converter(pyodbc.SQL_VARCHAR, convert)
        self.cursor.execute(""create table t1(n int, v varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, '123.45')"")
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, 'X123.45X')

        # Now clear the conversions and try again.  There should be no Xs this time.
        self.cnxn.clear_output_converters()
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, '123.45')


    def test_too_large(self):
        """"""Ensure error raised if insert fails due to truncation""""""
        value = 'x' * 1000
        self.cursor.execute(""create table t1(s varchar(800))"")
        def test():
            self.cursor.execute(""insert into t1 values (?)"", value)
        self.assertRaises(pyodbc.DataError, test)

    def test_geometry_null_insert(self):
        def convert(value):
            return value

        self.cnxn.add_output_converter(-151, convert) # -151 is SQL Server's geometry
        self.cursor.execute(""create table t1(n int, v geometry)"")
        self.cursor.execute(""insert into t1 values (?, ?)"", 1, None)
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, None)
        self.cnxn.clear_output_converters()

    def test_login_timeout(self):
        # This can only test setting since there isn't a way to cause it to block on the server side.
        cnxns = pyodbc.connect(self.connection_string, timeout=2)

    def test_row_equal(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test')"")
        row1 = self.cursor.execute(""select n, s from t1"").fetchone()
        row2 = self.cursor.execute(""select n, s from t1"").fetchone()
        b = (row1 == row2)
        self.assertEqual(b, True)

    def test_row_gtlt(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test1')"")
        self.cursor.execute(""insert into t1 values (1, 'test2')"")
        rows = self.cursor.execute(""select n, s from t1 order by s"").fetchall()
        self.assertTrue(rows[0] < rows[1])
        self.assertTrue(rows[0] <= rows[1])
        self.assertTrue(rows[1] > rows[0])
        self.assertTrue(rows[1] >= rows[0])
        self.assertTrue(rows[0] != rows[1])

        rows = list(rows)
        rows.sort() # uses <
        
    def test_context_manager(self):
        with pyodbc.connect(self.connection_string) as cnxn:
            cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)

        # The connection should be closed now.
        def test():
            cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)
        self.assertRaises(pyodbc.ProgrammingError, test)

    def test_untyped_none(self):
        # From issue 129
        value = self.cursor.execute(""select ?"", None).fetchone()[0]
        self.assertEqual(value, None)
        
    def test_large_update_nodata(self):
        self.cursor.execute('create table t1(a varbinary(max))')
        hundredkb = buffer('x'*100*1024)
        self.cursor.execute('update t1 set a=? where 1=0', (hundredkb,))

    def test_func_param(self):
        self.cursor.execute('''
                            create function func1 (@testparam varchar(4)) 
                            returns @rettest table (param varchar(4))
                            as 
                            begin
                                insert @rettest
                                select @testparam
                                return
                            end
                            ''')
        self.cnxn.commit()
        value = self.cursor.execute(""select * from func1(?)"", 'test').fetchone()[0]
        self.assertEqual(value, 'test')
        
    def test_no_fetch(self):
        # Issue 89 with FreeTDS: Multiple selects (or catalog functions that issue selects) without fetches seem to
        # confuse the driver.
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')

    def test_drivers(self):
        drivers = pyodbc.drivers()
        self.assertEqual(list, type(drivers))
        self.assertTrue(len(drivers) > 1)

        m = re.search('DRIVER={([^}]+)}', self.connection_string, re.IGNORECASE)
        current = m.group(1)
        self.assertTrue(current in drivers)
            


def main():
    from optparse import OptionParser
    parser = OptionParser(usage=usage)
    parser.add_option(""-v"", ""--verbose"", action=""count"", help=""Increment test verbosity (can be used multiple times)"")
    parser.add_option(""-d"", ""--debug"", action=""store_true"", default=False, help=""Print debugging items"")
    parser.add_option(""-t"", ""--test"", help=""Run only the named test"")

    (options, args) = parser.parse_args()

    if len(args) > 1:
        parser.error('Only one argument is allowed.  Do you need quotes around the connection string?')

    if not args:
        connection_string = load_setup_connection_string('informixtests')

        if not connection_string:
            parser.print_help()
            raise SystemExit()
    else:
        connection_string = args[0]

    cnxn = pyodbc.connect(connection_string)
    print_library_info(cnxn)
    cnxn.close()

    suite = load_tests(InformixTestCase, options.test, connection_string)

    testRunner = unittest.TextTestRunner(verbosity=options.verbose)
    result = testRunner.run(suite)


if __name__ == '__main__':

    # Add the build directory to the path so we're testing the latest build, not the installed version.

    add_to_path()

    import pyodbc
    main()
/n/n/ntests3/mysqltests.py/n/n#!/usr/bin/env python3
# -*- coding: latin-1 -*-

usage = """"""\
usage: %prog [options] connection_string

Unit tests for MySQL.  To use, pass a connection string as the parameter.  The tests will create and drop tables t1 and
t2 as necessary.  The default installation of mysql allows you to connect locally with no password and already contains
a 'test' database, so you can probably use the following.  (Update the driver name as appropriate.)

  ./mysqltests DRIVER={MySQL};DATABASE=test

These tests use the pyodbc library from the build directory, not the version installed in your
Python directories.  You must run `python setup.py build` before running these tests.

You can also put the connection string into a tmp/setup.cfg file like so:

  [mysqltests]
  connection-string=DRIVER={MySQL};SERVER=localhost;UID=uid;PWD=pwd;DATABASE=db
""""""

import sys, os, re
import unittest
from decimal import Decimal
from datetime import datetime, date, time
from os.path import join, getsize, dirname, abspath, basename
from testutils import *

_TESTSTR = '0123456789-abcdefghijklmnopqrstuvwxyz-'

def _generate_test_string(length):
    """"""
    Returns a string of composed of `seed` to make a string `length` characters long.

    To enhance performance, there are 3 ways data is read, based on the length of the value, so most data types are
    tested with 3 lengths.  This function helps us generate the test data.

    We use a recognizable data set instead of a single character to make it less likely that ""overlap"" errors will
    be hidden and to help us manually identify where a break occurs.
    """"""
    if length <= len(_TESTSTR):
        return _TESTSTR[:length]

    c = (length + len(_TESTSTR)-1) // len(_TESTSTR)
    v = _TESTSTR * c
    return v[:length]

class MySqlTestCase(unittest.TestCase):

    INTEGERS = [ -1, 0, 1, 0x7FFFFFFF ]
    BIGINTS  = INTEGERS + [ 0xFFFFFFFF, 0x123456789 ]

    SMALL_FENCEPOST_SIZES = [ 0, 1, 255, 256, 510, 511, 512, 1023, 1024, 2047, 2048, 4000 ]
    LARGE_FENCEPOST_SIZES = [ 4095, 4096, 4097, 10 * 1024, 20 * 1024 ]

    STR_FENCEPOSTS    = [ _generate_test_string(size) for size in SMALL_FENCEPOST_SIZES ]
    BLOB_FENCEPOSTS   = STR_FENCEPOSTS + [ _generate_test_string(size) for size in LARGE_FENCEPOST_SIZES ]

    def __init__(self, method_name, connection_string):
        unittest.TestCase.__init__(self, method_name)
        self.connection_string = connection_string

    def setUp(self):
        self.cnxn   = pyodbc.connect(self.connection_string)
        self.cursor = self.cnxn.cursor()

        # As of libmyodbc5w 5.3 SQLGetTypeInfo returns absurdly small sizes
        # leading to slow writes.  Override them:
        self.cnxn.maxwrite = 1024 * 1024 * 1024

        # My MySQL configuration (and I think the default) sends *everything*
        # in UTF-8.  The pyodbc default is to send Unicode as UTF-16 and to
        # decode WCHAR via UTF-16.  Change them both to UTF-8.
        self.cnxn.setdecoding(pyodbc.SQL_WCHAR, encoding='utf-8')
        self.cnxn.setencoding(encoding='utf-8')

        for i in range(3):
            try:
                self.cursor.execute(""drop table t%d"" % i)
                self.cnxn.commit()
            except:
                pass

        for i in range(3):
            try:
                self.cursor.execute(""drop procedure proc%d"" % i)
                self.cnxn.commit()
            except:
                pass

        self.cnxn.rollback()

    def tearDown(self):
        try:
            self.cursor.close()
            self.cnxn.close()
        except:
            # If we've already closed the cursor or connection, exceptions are thrown.
            pass

    def test_multiple_bindings(self):
        ""More than one bind and select on a cursor""
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t1 values (?)"", 2)
        self.cursor.execute(""insert into t1 values (?)"", 3)
        for i in range(3):
            self.cursor.execute(""select n from t1 where n < ?"", 10)
            self.cursor.execute(""select n from t1 where n < 3"")


    def test_different_bindings(self):
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""create table t2(d datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t2 values (?)"", datetime.now())

    def test_drivers(self):
        p = pyodbc.drivers()
        self.assertTrue(isinstance(p, list))

    def test_datasources(self):
        p = pyodbc.dataSources()
        self.assertTrue(isinstance(p, dict))

    def test_getinfo_string(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CATALOG_NAME_SEPARATOR)
        self.assertTrue(isinstance(value, str))

    def test_getinfo_bool(self):
        value = self.cnxn.getinfo(pyodbc.SQL_ACCESSIBLE_TABLES)
        self.assertTrue(isinstance(value, bool))

    def test_getinfo_int(self):
        value = self.cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)
        self.assertTrue(isinstance(value, int))

    def test_getinfo_smallint(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CONCAT_NULL_BEHAVIOR)
        self.assertTrue(isinstance(value, int))

    def _test_strtype(self, sqltype, value, colsize=None):
        """"""
        The implementation for string and binary tests.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        try:
            self.cursor.execute(sql)
        except:
            print('>>>>', sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]

        # Removing this check for now until I get the charset working properly.
        # If we use latin1, results are 'str' instead of 'unicode', which would be
        # correct.  Setting charset to ucs-2 causes a crash in SQLGetTypeInfo(SQL_DATETIME).
        # self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)

    #
    # varchar
    #

    def test_varchar_null(self):
        self._test_strtype('varchar', None, 100)

    # Generate a test for each fencepost size: test_varchar_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('varchar', value, max(1, len(value)))
        return t
    for value in STR_FENCEPOSTS:
        locals()['test_varchar_%s' % len(value)] = _maketest(value)

    def test_varchar_many(self):
        self.cursor.execute(""create table t1(c1 varchar(300), c2 varchar(300), c3 varchar(300))"")

        v1 = 'ABCDEFGHIJ' * 30
        v2 = '0123456789' * 30
        v3 = '9876543210' * 30

        self.cursor.execute(""insert into t1(c1, c2, c3) values (?,?,?)"", v1, v2, v3);
        row = self.cursor.execute(""select c1, c2, c3 from t1"").fetchone()

        self.assertEqual(v1, row.c1)
        self.assertEqual(v2, row.c2)
        self.assertEqual(v3, row.c3)

    def test_varchar_upperlatin(self):
        self._test_strtype('varchar', u'�', colsize=3)

    def test_utf16(self):
        self.cursor.execute(""create table t1(c1 varchar(100) character set utf16, c2 varchar(100))"")
        self.cursor.execute(""insert into t1 values ('test', 'test')"")
        value = ""test""
        row = self.cursor.execute(""select c1,c2 from t1"").fetchone()
        for v in row:
            self.assertEqual(type(v), str)
            self.assertEqual(v, value)

    #
    # binary
    #

    def test_null_binary(self):
        self._test_strtype('varbinary', None, 100)

    def test_large_null_binary(self):
        # Bug 1575064
        self._test_strtype('varbinary', None, 4000)

    # Generate a test for each fencepost size: test_binary_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('varbinary', bytes(value, 'utf-8'), max(1, len(value)))
        return t
    for value in STR_FENCEPOSTS:
        locals()['test_binary_%s' % len(value)] = _maketest(value)

    #
    # blob
    #

    def test_blob_null(self):
        self._test_strtype('blob', None)

    # Generate a test for each fencepost size: test_blob_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('blob', bytes(value, 'utf-8'))
        return t
    for value in BLOB_FENCEPOSTS:
        locals()['test_blob_%s' % len(value)] = _maketest(value)

    def test_blob_upperlatin(self):
        self._test_strtype('blob', bytes('�', 'utf-8'))

    #
    # text
    #

    def test_null_text(self):
        self._test_strtype('text', None)

    # Generate a test for each fencepost size: test_text_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('text', value)
        return t
    for value in STR_FENCEPOSTS:
        locals()['test_text_%s' % len(value)] = _maketest(value)

    def test_text_upperlatin(self):
        self._test_strtype('text', '�')

    #
    # unicode
    #

    def test_unicode_query(self):
        self.cursor.execute(u""select 1"")

    #
    # bit
    #

    # The MySQL driver maps BIT colums to the ODBC bit data type, but they aren't behaving quite like a Boolean value
    # (which is what the ODBC bit data type really represents).  The MySQL BOOL data type is just an alias for a small
    # integer, so pyodbc can't recognize it and map it back to True/False.
    #
    # You can use both BIT and BOOL and they will act as you expect if you treat them as integers.  You can write 0 and
    # 1 to them and they will work.

    # def test_bit(self):
    #     value = True
    #     self.cursor.execute(""create table t1(b bit)"")
    #     self.cursor.execute(""insert into t1 values (?)"", value)
    #     v = self.cursor.execute(""select b from t1"").fetchone()[0]
    #     self.assertEqual(type(v), bool)
    #     self.assertEqual(v, value)
    #
    # def test_bit_string_true(self):
    #     self.cursor.execute(""create table t1(b bit)"")
    #     self.cursor.execute(""insert into t1 values (?)"", ""xyzzy"")
    #     v = self.cursor.execute(""select b from t1"").fetchone()[0]
    #     self.assertEqual(type(v), bool)
    #     self.assertEqual(v, True)
    #
    # def test_bit_string_false(self):
    #     self.cursor.execute(""create table t1(b bit)"")
    #     self.cursor.execute(""insert into t1 values (?)"", """")
    #     v = self.cursor.execute(""select b from t1"").fetchone()[0]
    #     self.assertEqual(type(v), bool)
    #     self.assertEqual(v, False)

    #
    # decimal
    #

    def test_small_decimal(self):
        # value = Decimal('1234567890987654321')
        value = Decimal('100010')       # (I use this because the ODBC docs tell us how the bytes should look in the C struct)
        self.cursor.execute(""create table t1(d numeric(19))"")
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), Decimal)
        self.assertEqual(v, value)


    def test_small_decimal_scale(self):
        # The same as small_decimal, except with a different scale.  This value exactly matches the ODBC documentation
        # example in the C Data Types appendix.
        value = '1000.10'
        value = Decimal(value)
        self.cursor.execute(""create table t1(d numeric(20,6))"")
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), Decimal)
        self.assertEqual(v, value)


    def test_negative_decimal_scale(self):
        value = Decimal('-10.0010')
        self.cursor.execute(""create table t1(d numeric(19,4))"")
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), Decimal)
        self.assertEqual(v, value)

    def _test_inttype(self, datatype, n):
        self.cursor.execute('create table t1(n %s)' % datatype)
        self.cursor.execute('insert into t1 values (?)', n)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, n)

    def _maketest(datatype, value):
        def t(self):
            self._test_inttype(datatype, value)
        return t

    for value in INTEGERS:
        name = str(abs(value))
        if value < 0:
            name = 'neg_' + name
        locals()['test_int_%s' % name] = _maketest('int', value)

    for value in BIGINTS:
        name = str(abs(value))
        if value < 0:
            name = 'neg_' + name
        locals()['test_bigint_%s' % name] = _maketest('bigint', value)

    def test_subquery_params(self):
        """"""Ensure parameter markers work in a subquery""""""
        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        row = self.cursor.execute(""""""
                                  select x.id
                                  from (
                                    select id
                                    from t1
                                    where s = ?
                                      and id between ? and ?
                                   ) x
                                   """""", 'test', 1, 10).fetchone()
        self.assertNotEqual(row, None)
        self.assertEqual(row[0], 1)

    def _exec(self):
        self.cursor.execute(self.sql)

    def test_close_cnxn(self):
        """"""Make sure using a Cursor after closing its connection doesn't crash.""""""

        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        self.cursor.execute(""select * from t1"")

        self.cnxn.close()

        # Now that the connection is closed, we expect an exception.  (If the code attempts to use
        # the HSTMT, we'll get an access violation instead.)
        self.sql = ""select * from t1""
        self.assertRaises(pyodbc.ProgrammingError, self._exec)

    def test_empty_string(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", """")

    def test_fixed_str(self):
        value = ""testing""
        self.cursor.execute(""create table t1(s char(7))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(v, value)

    def test_negative_row_index(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", ""1"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row[0], ""1"")
        self.assertEqual(row[-1], ""1"")

    def test_version(self):
        self.assertEqual(3, len(pyodbc.version.split('.'))) # 1.3.1 etc.

    #
    # date, time, datetime
    #

    def test_datetime(self):
        value = datetime(2007, 1, 15, 3, 4, 5)

        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(value, result)

    def test_date(self):
        value = date(2001, 1, 1)

        self.cursor.execute(""create table t1(dt date)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(result), type(value))
        self.assertEqual(result, value)

    #
    # ints and floats
    #

    def test_int(self):
        value = 1234
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_int(self):
        value = -1
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_bigint(self):

        # This fails on 64-bit Fedora with 5.1.
        # Should return 0x0123456789
        # Does return   0x0000000000
        #
        # Top 4 bytes are returned as 0x00 00 00 00.  If the input is high enough, they are returned as 0xFF FF FF FF.
        input = 0x123456789
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_float(self):
        value = 1234.5
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_float(self):
        value = -200
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result  = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(value, result)


    def test_date(self):
        value = date.today()

        self.cursor.execute(""create table t1(d date)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(value, result)


    def test_time(self):
        value = datetime.now().time()

        # We aren't yet writing values using the new extended time type so the value written to the database is only
        # down to the second.
        value = value.replace(microsecond=0)

        self.cursor.execute(""create table t1(t time)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select t from t1"").fetchone()[0]
        self.assertEqual(value, result)

    #
    # misc
    #

    def test_rowcount_delete(self):
        self.assertEqual(self.cursor.rowcount, -1)
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, count)

    def test_rowcount_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.  On the other hand, we could hardcode a
        zero return value.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, 0)

    def test_rowcount_select(self):
        """"""
        Ensure Cursor.rowcount is set properly after a select statement.

        pyodbc calls SQLRowCount after each execute and sets Cursor.rowcount.  Databases can return the actual rowcount
        or they can return -1 if it would help performance.  MySQL seems to always return the correct rowcount.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""select * from t1"")
        self.assertEqual(self.cursor.rowcount, count)

        rows = self.cursor.fetchall()
        self.assertEqual(len(rows), count)
        self.assertEqual(self.cursor.rowcount, count)

    def test_rowcount_reset(self):
        ""Ensure rowcount is reset to -1""

        # The Python DB API says that rowcount should be set to -1 and most ODBC drivers let us know there are no
        # records.  MySQL always returns 0, however.  Without parsing the SQL (which we are not going to do), I'm not
        # sure how we can tell the difference and set the value to -1.  For now, I'll have this test check for 0.

        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.assertEqual(self.cursor.rowcount, 1)

        self.cursor.execute(""create table t2(i int)"")
        self.assertEqual(self.cursor.rowcount, 0)

    def test_lower_case(self):
        ""Ensure pyodbc.lowercase forces returned column names to lowercase.""

        # Has to be set before creating the cursor, so we must recreate self.cursor.

        pyodbc.lowercase = True
        self.cursor = self.cnxn.cursor()

        self.cursor.execute(""create table t1(Abc int, dEf int)"")
        self.cursor.execute(""select * from t1"")

        names = [ t[0] for t in self.cursor.description ]
        names.sort()

        self.assertEqual(names, [ ""abc"", ""def"" ])

        # Put it back so other tests don't fail.
        pyodbc.lowercase = False

    def test_row_description(self):
        """"""
        Ensure Cursor.description is accessible as Row.cursor_description.
        """"""
        self.cursor = self.cnxn.cursor()
        self.cursor.execute(""create table t1(a int, b char(3))"")
        self.cnxn.commit()
        self.cursor.execute(""insert into t1 values(1, 'abc')"")

        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(self.cursor.description, row.cursor_description)

    def test_executemany(self):
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [(i, str(i)) for i in range(1, 6)]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])

    def test_fast_executemany(self):

        self.cursor.fast_executemany = True

        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [(i, str(i)) for i in range(1, 6)]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])

    def test_executemany_one(self):
        ""Pass executemany a single sequence""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, ""test"") ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])


    # REVIEW: The following fails.  Research.

    # def test_executemany_failure(self):
    #     """"""
    #     Ensure that an exception is raised if one query in an executemany fails.
    #     """"""
    #     self.cursor.execute(""create table t1(a int, b varchar(10))"")
    #
    #     params = [ (1, 'good'),
    #                ('error', 'not an int'),
    #                (3, 'good') ]
    #
    #     self.assertRaises(pyodbc.Error, self.cursor.executemany, ""insert into t1(a, b) value (?, ?)"", params)


    def test_row_slicing(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = row[:]
        self.assertTrue(result is row)

        result = row[:-1]
        self.assertEqual(result, (1,2,3))

        result = row[0:4]
        self.assertTrue(result is row)


    def test_row_repr(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = str(row)
        self.assertEqual(result, ""(1, 2, 3, 4)"")

        result = str(row[:-1])
        self.assertEqual(result, ""(1, 2, 3)"")

        result = str(row[:1])
        self.assertEqual(result, ""(1,)"")


    def test_autocommit(self):
        self.assertEqual(self.cnxn.autocommit, False)

        othercnxn = pyodbc.connect(self.connection_string, autocommit=True)
        self.assertEqual(othercnxn.autocommit, True)

        othercnxn.autocommit = False
        self.assertEqual(othercnxn.autocommit, False)

    def test_emoticons(self):
        # https://github.com/mkleehammer/pyodbc/issues/423
        #
        # When sending a varchar parameter, pyodbc is supposed to set ColumnSize to the number
        # of characters.  Ensure it works even with 4-byte characters.
        #
        # http://www.fileformat.info/info/unicode/char/1f31c/index.htm

        v = ""x \U0001F31C z""

        self.cursor.execute(""create table t1(s varchar(100))"")
        self.cursor.execute(""insert into t1 values (?)"", v)

        result = self.cursor.execute(""select s from t1"").fetchone()[0]

        self.assertEqual(result, v)
        
def main():
    from optparse import OptionParser
    parser = OptionParser(usage=usage)
    parser.add_option(""-v"", ""--verbose"", action=""count"", default=0, help=""Increment test verbosity (can be used multiple times)"")
    parser.add_option(""-d"", ""--debug"", action=""store_true"", default=False, help=""Print debugging items"")
    parser.add_option(""-t"", ""--test"", help=""Run only the named test"")

    (options, args) = parser.parse_args()

    if len(args) > 1:
        parser.error('Only one argument is allowed.  Do you need quotes around the connection string?')

    if not args:
        filename = basename(sys.argv[0])
        assert filename.endswith('.py')
        connection_string = load_setup_connection_string(filename[:-3])

        if not connection_string:
            parser.print_help()
            raise SystemExit()
    else:
        connection_string = args[0]

    cnxn = pyodbc.connect(connection_string)
    print_library_info(cnxn)
    cnxn.close()

    suite = load_tests(MySqlTestCase, options.test, connection_string)

    testRunner = unittest.TextTestRunner(verbosity=options.verbose)
    result = testRunner.run(suite)


if __name__ == '__main__':

    # Add the build directory to the path so we're testing the latest build, not the installed version.

    add_to_path()

    import pyodbc
    main()
/n/n/ntests3/sqlitetests.py/n/n#!/usr/bin/python
# -*- coding: latin-1 -*-

usage = """"""\
usage: %prog [options] connection_string

Unit tests for SQLite using the ODBC driver from http://www.ch-werner.de/sqliteodbc

To use, pass a connection string as the parameter. The tests will create and
drop tables t1 and t2 as necessary.  On Windows, use the 32-bit driver with
32-bit Python and the 64-bit driver with 64-bit Python (regardless of your
operating system bitness).

These run using the version from the 'build' directory, not the version
installed into the Python directories.  You must run python setup.py build
before running the tests.

You can also put the connection string into a tmp/setup.cfg file like so:

  [sqlitetests]
  connection-string=Driver=SQLite3 ODBC Driver;Database=sqlite.db
""""""

import sys, os, re
import unittest
from decimal import Decimal
from datetime import datetime, date, time
from os.path import join, getsize, dirname, abspath
from testutils import *

_TESTSTR = '0123456789-abcdefghijklmnopqrstuvwxyz-'

def _generate_test_string(length):
    """"""
    Returns a string of `length` characters, constructed by repeating _TESTSTR as necessary.

    To enhance performance, there are 3 ways data is read, based on the length of the value, so most data types are
    tested with 3 lengths.  This function helps us generate the test data.

    We use a recognizable data set instead of a single character to make it less likely that ""overlap"" errors will
    be hidden and to help us manually identify where a break occurs.
    """"""
    if length <= len(_TESTSTR):
        return _TESTSTR[:length]

    c = (length + len(_TESTSTR)-1) // len(_TESTSTR)
    v = _TESTSTR * c
    return v[:length]

class SqliteTestCase(unittest.TestCase):

    SMALL_FENCEPOST_SIZES = [ 0, 1, 255, 256, 510, 511, 512, 1023, 1024, 2047, 2048, 4000 ]
    LARGE_FENCEPOST_SIZES = [ 4095, 4096, 4097, 10 * 1024, 20 * 1024 ]

    STR_FENCEPOSTS = [ _generate_test_string(size) for size in SMALL_FENCEPOST_SIZES ]
    BYTE_FENCEPOSTS    = [ bytes(s, 'ascii') for s in STR_FENCEPOSTS ]
    IMAGE_FENCEPOSTS   = BYTE_FENCEPOSTS + [ bytes(_generate_test_string(size), 'ascii') for size in LARGE_FENCEPOST_SIZES ]

    def __init__(self, method_name, connection_string):
        unittest.TestCase.__init__(self, method_name)
        self.connection_string = connection_string

    def setUp(self):
        self.cnxn   = pyodbc.connect(self.connection_string)
        self.cursor = self.cnxn.cursor()

        for i in range(3):
            try:
                self.cursor.execute(""drop table t%d"" % i)
                self.cnxn.commit()
            except:
                pass

        self.cnxn.rollback()

    def tearDown(self):
        try:
            self.cursor.close()
            self.cnxn.close()
        except:
            # If we've already closed the cursor or connection, exceptions are thrown.
            pass

    def test_multiple_bindings(self):
        ""More than one bind and select on a cursor""
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t1 values (?)"", 2)
        self.cursor.execute(""insert into t1 values (?)"", 3)
        for i in range(3):
            self.cursor.execute(""select n from t1 where n < ?"", 10)
            self.cursor.execute(""select n from t1 where n < 3"")
        

    def test_different_bindings(self):
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""create table t2(d datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t2 values (?)"", datetime.now())

    def test_drivers(self):
        p = pyodbc.drivers()
        self.assertTrue(isinstance(p, list))

    def test_datasources(self):
        p = pyodbc.dataSources()
        self.assertTrue(isinstance(p, dict))

    def test_getinfo_string(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CATALOG_NAME_SEPARATOR)
        self.assertTrue(isinstance(value, str))

    def test_getinfo_bool(self):
        value = self.cnxn.getinfo(pyodbc.SQL_ACCESSIBLE_TABLES)
        self.assertTrue(isinstance(value, bool))

    def test_getinfo_int(self):
        value = self.cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)
        self.assertTrue(isinstance(value, int))

    def test_getinfo_smallint(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CONCAT_NULL_BEHAVIOR)
        self.assertTrue(isinstance(value, int))

    def _test_strtype(self, sqltype, value, colsize=None):
        """"""
        The implementation for string, Unicode, and binary tests.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)

        # Reported by Andy Hochhaus in the pyodbc group: In 2.1.7 and earlier, a hardcoded length of 255 was used to
        # determine whether a parameter was bound as a SQL_VARCHAR or SQL_LONGVARCHAR.  Apparently SQL Server chokes if
        # we bind as a SQL_LONGVARCHAR and the target column size is 8000 or less, which is considers just SQL_VARCHAR.
        # This means binding a 256 character value would cause problems if compared with a VARCHAR column under
        # 8001. We now use SQLGetTypeInfo to determine the time to switch.
        #
        # [42000] [Microsoft][SQL Server Native Client 10.0][SQL Server]The data types varchar and text are incompatible in the equal to operator.

        self.cursor.execute(""select * from t1 where s=?"", value)


    def _test_strliketype(self, sqltype, value, colsize=None):
        """"""
        The implementation for text, image, ntext, and binary.

        These types do not support comparison operators.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)

    #
    # text
    #

    def test_text_null(self):
        self._test_strtype('text', None, 100)

    # Generate a test for each fencepost size: test_text_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('text', value, len(value))
        return t
    for value in STR_FENCEPOSTS:
        locals()['test_text_%s' % len(value)] = _maketest(value)

    def test_text_upperlatin(self):
        self._test_strtype('varchar', '�')

    #
    # blob
    #

    def test_null_blob(self):
        self._test_strtype('blob', None, 100)
     
    def test_large_null_blob(self):
        # Bug 1575064
        self._test_strtype('blob', None, 4000)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('blob', value, len(value))
        return t
    for value in BYTE_FENCEPOSTS:
        locals()['test_blob_%s' % len(value)] = _maketest(value)

    def test_subquery_params(self):
        """"""Ensure parameter markers work in a subquery""""""
        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        row = self.cursor.execute(""""""
                                  select x.id
                                  from (
                                    select id
                                    from t1
                                    where s = ?
                                      and id between ? and ?
                                   ) x
                                   """""", 'test', 1, 10).fetchone()
        self.assertNotEqual(row, None)
        self.assertEqual(row[0], 1)

    def _exec(self):
        self.cursor.execute(self.sql)
        
    def test_close_cnxn(self):
        """"""Make sure using a Cursor after closing its connection doesn't crash.""""""

        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        self.cursor.execute(""select * from t1"")

        self.cnxn.close()
        
        # Now that the connection is closed, we expect an exception.  (If the code attempts to use
        # the HSTMT, we'll get an access violation instead.)
        self.sql = ""select * from t1""
        self.assertRaises(pyodbc.ProgrammingError, self._exec)

    def test_negative_row_index(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", ""1"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row[0], ""1"")
        self.assertEqual(row[-1], ""1"")

    def test_version(self):
        self.assertEqual(3, len(pyodbc.version.split('.'))) # 1.3.1 etc.

    #
    # ints and floats
    #

    def test_int(self):
        value = 1234
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_int(self):
        value = -1
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_bigint(self):
        input = 3000000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_negative_bigint(self):
        # Issue 186: BIGINT problem on 32-bit architeture
        input = -430000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_float(self):
        value = 1234.567
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_float(self):
        value = -200
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result  = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(value, result)

    #
    # rowcount
    #

    # Note: SQLRowCount does not define what the driver must return after a select statement
    # and says that its value should not be relied upon.  The sqliteodbc driver is hardcoded to
    # return 0 so I've deleted the test.

    def test_rowcount_delete(self):
        self.assertEqual(self.cursor.rowcount, -1)
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, count)

    def test_rowcount_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.  On the other hand, we could hardcode a
        zero return value.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, 0)

    # In the 2.0.x branch, Cursor.execute sometimes returned the cursor and sometimes the rowcount.  This proved very
    # confusing when things went wrong and added very little value even when things went right since users could always
    # use: cursor.execute(""..."").rowcount

    def test_retcursor_delete(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_select(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""select * from t1"")
        self.assertEqual(v, self.cursor)

    #
    # misc
    #

    def test_lower_case(self):
        ""Ensure pyodbc.lowercase forces returned column names to lowercase.""

        # Has to be set before creating the cursor, so we must recreate self.cursor.

        pyodbc.lowercase = True
        self.cursor = self.cnxn.cursor()

        self.cursor.execute(""create table t1(Abc int, dEf int)"")
        self.cursor.execute(""select * from t1"")

        names = [ t[0] for t in self.cursor.description ]
        names.sort()

        self.assertEqual(names, [ ""abc"", ""def"" ])

        # Put it back so other tests don't fail.
        pyodbc.lowercase = False
        
    def test_row_description(self):
        """"""
        Ensure Cursor.description is accessible as Row.cursor_description.
        """"""
        self.cursor = self.cnxn.cursor()
        self.cursor.execute(""create table t1(a int, b char(3))"")
        self.cnxn.commit()
        self.cursor.execute(""insert into t1 values(1, 'abc')"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        self.assertEqual(self.cursor.description, row.cursor_description)
        

    def test_executemany(self):
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (i, str(i)) for i in range(1, 6) ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])


    def test_executemany_one(self):
        ""Pass executemany a single sequence""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, ""test"") ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])
        

    def test_executemany_failure(self):
        """"""
        Ensure that an exception is raised if one query in an executemany fails.
        """"""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, 'good'),
                   ('error', 'not an int'),
                   (3, 'good') ]
        
        self.assertRaises(pyodbc.Error, self.cursor.executemany, ""insert into t1(a, b) value (?, ?)"", params)

        
    def test_row_slicing(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = row[:]
        self.assertTrue(result is row)

        result = row[:-1]
        self.assertEqual(result, (1,2,3))

        result = row[0:4]
        self.assertTrue(result is row)


    def test_row_repr(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = str(row)
        self.assertEqual(result, ""(1, 2, 3, 4)"")

        result = str(row[:-1])
        self.assertEqual(result, ""(1, 2, 3)"")

        result = str(row[:1])
        self.assertEqual(result, ""(1,)"")


    def test_view_select(self):
        # Reported in forum: Can't select from a view?  I think I do this a lot, but another test never hurts.

        # Create a table (t1) with 3 rows and a view (t2) into it.
        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(50))"")
        for i in range(3):
            self.cursor.execute(""insert into t1(c2) values (?)"", ""string%s"" % i)
        self.cursor.execute(""create view t2 as select * from t1"")

        # Select from the view
        self.cursor.execute(""select * from t2"")
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(len(rows) == 3)

    def test_autocommit(self):
        self.assertEqual(self.cnxn.autocommit, False)

        othercnxn = pyodbc.connect(self.connection_string, autocommit=True)
        self.assertEqual(othercnxn.autocommit, True)

        othercnxn.autocommit = False
        self.assertEqual(othercnxn.autocommit, False)

    def test_skip(self):
        # Insert 1, 2, and 3.  Fetch 1, skip 2, fetch 3.

        self.cursor.execute(""create table t1(id int)"");
        for i in range(1, 5):
            self.cursor.execute(""insert into t1 values(?)"", i)
        self.cursor.execute(""select id from t1 order by id"")
        self.assertEqual(self.cursor.fetchone()[0], 1)
        self.cursor.skip(2)
        self.assertEqual(self.cursor.fetchone()[0], 4)

    def test_sets_execute(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.execute(""insert into t1 (word) VALUES (?)"", [words])

        self.assertRaises(pyodbc.ProgrammingError, f)

    def test_sets_executemany(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.executemany(""insert into t1 (word) values (?)"", [words])
            
        self.assertRaises(TypeError, f)

    def test_row_execute(self):
        ""Ensure we can use a Row object as a parameter to execute""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, 'a')"")
        row = self.cursor.execute(""select n, s from t1"").fetchone()
        self.assertNotEqual(row, None)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.execute(""insert into t2 values (?, ?)"", row)
        
    def test_row_executemany(self):
        ""Ensure we can use a Row object as a parameter to executemany""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")

        for i in range(3):
            self.cursor.execute(""insert into t1 values (?, ?)"", i, chr(ord('a')+i))

        rows = self.cursor.execute(""select n, s from t1"").fetchall()
        self.assertNotEqual(len(rows), 0)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.executemany(""insert into t2 values (?, ?)"", rows)
        
    def test_description(self):
        ""Ensure cursor.description is correct""

        self.cursor.execute(""create table t1(n int, s text)"")
        self.cursor.execute(""insert into t1 values (1, 'abc')"")
        self.cursor.execute(""select * from t1"")

        # (I'm not sure the precision of an int is constant across different versions, bits, so I'm hand checking the
        # items I do know.

        # int
        t = self.cursor.description[0]
        self.assertEqual(t[0], 'n')
        self.assertEqual(t[1], int)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # text
        t = self.cursor.description[1]
        self.assertEqual(t[0], 's')
        self.assertEqual(t[1], str)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

    def test_row_equal(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test')"")
        row1 = self.cursor.execute(""select n, s from t1"").fetchone()
        row2 = self.cursor.execute(""select n, s from t1"").fetchone()
        b = (row1 == row2)
        self.assertEqual(b, True)

    def test_row_gtlt(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test1')"")
        self.cursor.execute(""insert into t1 values (1, 'test2')"")
        rows = self.cursor.execute(""select n, s from t1 order by s"").fetchall()
        self.assertTrue(rows[0] < rows[1])
        self.assertTrue(rows[0] <= rows[1])
        self.assertTrue(rows[1] > rows[0])
        self.assertTrue(rows[1] >= rows[0])
        self.assertTrue(rows[0] != rows[1])

        rows = list(rows)
        rows.sort() # uses <
        
    def _test_context_manager(self):
        # TODO: This is failing, but it may be due to the design of sqlite.  I've disabled it
        # for now until I can research it some more.

        # WARNING: This isn't working right now.  We've set the driver's autocommit to ""off"",
        # but that doesn't automatically start a transaction.  I'm not familiar enough with the
        # internals of the driver to tell what is going on, but it looks like there is support
        # for the autocommit flag.
        #
        # I thought it might be a timing issue, like it not actually starting a txn until you
        # try to do something, but that doesn't seem to work either.  I'll leave this in to
        # remind us that it isn't working yet but we need to contact the SQLite ODBC driver
        # author for some guidance.

        with pyodbc.connect(self.connection_string) as cnxn:
            cursor = cnxn.cursor()
            cursor.execute(""begin"")
            cursor.execute(""create table t1(i int)"")
            cursor.execute('rollback')

        # The connection should be closed now.
        def test():
            cnxn.execute('rollback')
        self.assertRaises(pyodbc.Error, test)

    def test_untyped_none(self):
        # From issue 129
        value = self.cursor.execute(""select ?"", None).fetchone()[0]
        self.assertEqual(value, None)
        
    def test_large_update_nodata(self):
        self.cursor.execute('create table t1(a blob)')
        hundredkb = 'x'*100*1024
        self.cursor.execute('update t1 set a=? where 1=0', (hundredkb,))

    def test_no_fetch(self):
        # Issue 89 with FreeTDS: Multiple selects (or catalog functions that issue selects) without fetches seem to
        # confuse the driver.
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')


def main():
    from optparse import OptionParser
    parser = OptionParser(usage=usage)
    parser.add_option(""-v"", ""--verbose"", default=0, action=""count"", help=""Increment test verbosity (can be used multiple times)"")
    parser.add_option(""-d"", ""--debug"", action=""store_true"", default=False, help=""Print debugging items"")
    parser.add_option(""-t"", ""--test"", help=""Run only the named test"")

    (options, args) = parser.parse_args()

    if len(args) > 1:
        parser.error('Only one argument is allowed.  Do you need quotes around the connection string?')

    if not args:
        connection_string = load_setup_connection_string('sqlitetests')

        if not connection_string:
            parser.print_help()
            raise SystemExit()
    else:
        connection_string = args[0]

    if options.verbose:
        cnxn = pyodbc.connect(connection_string)
        print_library_info(cnxn)
        cnxn.close()

    suite = load_tests(SqliteTestCase, options.test, connection_string)

    testRunner = unittest.TextTestRunner(verbosity=options.verbose)
    result = testRunner.run(suite)

    sys.exit(result.errors and 1 or 0)


if __name__ == '__main__':

    # Add the build directory to the path so we're testing the latest build, not the installed version.

    add_to_path()

    import pyodbc
    main()
/n/n/ntests3/sqlservertests.py/n/n#!/usr/bin/python
# -*- coding: utf-8 -*-

x = 1 # Getting an error if starting with usage for some reason.

usage = """"""\
usage: %prog [options] connection_string

Unit tests for SQL Server.  To use, pass a connection string as the parameter.
The tests will create and drop tables t1 and t2 as necessary.

These run using the version from the 'build' directory, not the version
installed into the Python directories.  You must run python setup.py build
before running the tests.

You can also put the connection string into a tmp/setup.cfg file like so:

  [sqlservertests]
  connection-string=DRIVER={SQL Server};SERVER=localhost;UID=uid;PWD=pwd;DATABASE=db

The connection string above will use the 2000/2005 driver, even if SQL Server 2008
is installed:

  2000: DRIVER={SQL Server}
  2005: DRIVER={SQL Server}
  2008: DRIVER={SQL Server Native Client 10.0}
""""""

import sys, os, re, uuid
import unittest
from decimal import Decimal
from datetime import datetime, date, time
from os.path import join, getsize, dirname, abspath
from testutils import *

_TESTSTR = '0123456789-abcdefghijklmnopqrstuvwxyz-'

def _generate_test_string(length):
    """"""
    Returns a string of `length` characters, constructed by repeating _TESTSTR as necessary.

    To enhance performance, there are 3 ways data is read, based on the length of the value, so most data types are
    tested with 3 lengths.  This function helps us generate the test data.

    We use a recognizable data set instead of a single character to make it less likely that ""overlap"" errors will
    be hidden and to help us manually identify where a break occurs.
    """"""
    if length <= len(_TESTSTR):
        return _TESTSTR[:length]

    c = int((length + len(_TESTSTR)-1) / len(_TESTSTR))
    v = _TESTSTR * c
    return v[:length]

class SqlServerTestCase(unittest.TestCase):

    SMALL_FENCEPOST_SIZES = [ 0, 1, 255, 256, 510, 511, 512, 1023, 1024, 2047, 2048, 4000 ]
    LARGE_FENCEPOST_SIZES = [ 4095, 4096, 4097, 10 * 1024, 20 * 1024 ]

    STR_FENCEPOSTS = [ _generate_test_string(size) for size in SMALL_FENCEPOST_SIZES ]
    BYTE_FENCEPOSTS    = [ bytes(s, 'ascii') for s in STR_FENCEPOSTS ]
    IMAGE_FENCEPOSTS   = BYTE_FENCEPOSTS + [ bytes(_generate_test_string(size), 'ascii') for size in LARGE_FENCEPOST_SIZES ]

    def __init__(self, method_name, connection_string):
        unittest.TestCase.__init__(self, method_name)
        self.connection_string = connection_string

    def get_sqlserver_version(self):
        """"""
        Returns the major version: 8-->2000, 9-->2005, 10-->2008
        """"""
        self.cursor.execute(""exec master..xp_msver 'ProductVersion'"")
        row = self.cursor.fetchone()
        return int(row.Character_Value.split('.', 1)[0])

    def setUp(self):
        self.cnxn   = pyodbc.connect(self.connection_string)
        self.cursor = self.cnxn.cursor()

        # I (Kleehammer) have been using a latin1 collation.  If you have a
        # different collation, you'll need to update this.  If someone knows of
        # a good way for this to be dynamic, please update.  (I suppose we
        # could maintain a map from collation to encoding?)
        self.cnxn.setdecoding(pyodbc.SQL_CHAR, 'latin1')

        for i in range(3):
            try:
                self.cursor.execute(""drop table t%d"" % i)
                self.cnxn.commit()
            except:
                pass

        for i in range(3):
            try:
                self.cursor.execute(""drop procedure proc%d"" % i)
                self.cnxn.commit()
            except:
                pass

        try:
            self.cursor.execute('drop function func1')
            self.cnxn.commit()
        except:
            pass

        self.cnxn.rollback()

    def tearDown(self):
        try:
            self.cursor.close()
            self.cnxn.close()
        except:
            # If we've already closed the cursor or connection, exceptions are thrown.
            pass

    def _simpletest(datatype, value):
        # A simple test that can be used for any data type where the Python
        # type we write is also what we expect to receive.
        def _t(self):
            self.cursor.execute('create table t1(value %s)' % datatype)
            self.cursor.execute('insert into t1 values (?)', value)
            result = self.cursor.execute(""select value from t1"").fetchone()[0]
            self.assertEqual(result, value)
        return _t

    def test_multiple_bindings(self):
        ""More than one bind and select on a cursor""
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t1 values (?)"", 2)
        self.cursor.execute(""insert into t1 values (?)"", 3)
        for i in range(3):
            self.cursor.execute(""select n from t1 where n < ?"", 10)
            self.cursor.execute(""select n from t1 where n < 3"")


    def test_different_bindings(self):
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""create table t2(d datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t2 values (?)"", datetime.now())

    def test_drivers(self):
        p = pyodbc.drivers()
        self.assertTrue(isinstance(p, list))

    def test_datasources(self):
        p = pyodbc.dataSources()
        self.assertTrue(isinstance(p, dict))

    def test_getinfo_string(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CATALOG_NAME_SEPARATOR)
        self.assertTrue(isinstance(value, str))

    def test_getinfo_bool(self):
        value = self.cnxn.getinfo(pyodbc.SQL_ACCESSIBLE_TABLES)
        self.assertTrue(isinstance(value, bool))

    def test_getinfo_int(self):
        value = self.cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)
        self.assertTrue(isinstance(value, (int, int)))

    def test_getinfo_smallint(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CONCAT_NULL_BEHAVIOR)
        self.assertTrue(isinstance(value, int))

    def test_noscan(self):
        self.assertEqual(self.cursor.noscan, False)
        self.cursor.noscan = True
        self.assertEqual(self.cursor.noscan, True)

    def test_nonnative_uuid(self):
        # The default is False meaning we should return a string.  Note that
        # SQL Server seems to always return uppercase.
        value = uuid.uuid4()
        self.cursor.execute(""create table t1(n uniqueidentifier)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        pyodbc.native_uuid = False
        result = self.cursor.execute(""select n from t1"").fetchval()
        self.assertEqual(type(result), str)
        self.assertEqual(result, str(value).upper())

    def test_native_uuid(self):
        # When true, we should return a uuid.UUID object.
        value = uuid.uuid4()
        self.cursor.execute(""create table t1(n uniqueidentifier)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        pyodbc.native_uuid = True
        result = self.cursor.execute(""select n from t1"").fetchval()
        self.assertIsInstance(result, uuid.UUID)
        self.assertEqual(value, result)

    def test_nextset(self):
        self.cursor.execute(""create table t1(i int)"")
        for i in range(4):
            self.cursor.execute(""insert into t1(i) values(?)"", i)

        self.cursor.execute(""select i from t1 where i < 2 order by i; select i from t1 where i >= 2 order by i"")

        for i, row in enumerate(self.cursor):
            self.assertEqual(i, row.i)

        self.assertEqual(self.cursor.nextset(), True)

        for i, row in enumerate(self.cursor):
            self.assertEqual(i + 2, row.i)

    def test_nextset_with_raiserror(self):
        self.cursor.execute(""select i = 1; RAISERROR('c', 16, 1);"")
        row = next(self.cursor)
        self.assertEqual(1, row.i)
        self.assertRaises(pyodbc.ProgrammingError, self.cursor.nextset)

    def test_fixed_unicode(self):
        value = ""t\xebsting""
        self.cursor.execute(""create table t1(s nchar(7))"")
        self.cursor.execute(""insert into t1 values(?)"", ""t\xebsting"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(len(v), len(value)) # If we alloc'd wrong, the test below might work because of an embedded NULL
        self.assertEqual(v, value)


    def _test_strtype(self, sqltype, value, resulttype=None, colsize=None):
        """"""
        The implementation for string, Unicode, and binary tests.
        """"""
        assert colsize is None or isinstance(colsize, int), colsize
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        if resulttype is None:
            resulttype = type(value)

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), resulttype)

        if value is not None:
            self.assertEqual(len(v), len(value))

        # To allow buffer --> db --> bytearray tests, always convert the input to the expected result type before
        # comparing.
        if type(value) is not resulttype:
            value = resulttype(value)

        self.assertEqual(v, value)


    def _test_strliketype(self, sqltype, value, resulttype=None, colsize=None):
        """"""
        The implementation for text, image, ntext, and binary.

        These types do not support comparison operators.
        """"""
        assert colsize is None or isinstance(colsize, int), colsize
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        if resulttype is None:
            resulttype = type(value)

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        result = self.cursor.execute(""select * from t1"").fetchone()[0]

        self.assertEqual(type(result), resulttype)

        # To allow buffer --> db --> bytearray tests, always convert the input to the expected result type before
        # comparing.
        if type(value) is not resulttype:
            value = resulttype(value)

        self.assertEqual(result, value)


    #
    # varchar
    #

    def test_varchar_null(self):
        self._test_strtype('varchar', None, colsize=100)

    # Generate a test for each fencepost size: test_varchar_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('varchar', value, colsize=len(value))
        return t
    for value in STR_FENCEPOSTS:
        locals()['test_varchar_%s' % len(value)] = _maketest(value)

    def test_varchar_many(self):
        self.cursor.execute(""create table t1(c1 varchar(300), c2 varchar(300), c3 varchar(300))"")

        v1 = 'ABCDEFGHIJ' * 30
        v2 = '0123456789' * 30
        v3 = '9876543210' * 30

        self.cursor.execute(""insert into t1(c1, c2, c3) values (?,?,?)"", v1, v2, v3);
        row = self.cursor.execute(""select c1, c2, c3, len(c1) as l1, len(c2) as l2, len(c3) as l3 from t1"").fetchone()

        self.assertEqual(v1, row.c1)
        self.assertEqual(v2, row.c2)
        self.assertEqual(v3, row.c3)

    #
    # nvarchar
    #

    def test_unicode_null(self):
        self._test_strtype('nvarchar', None, colsize=100)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('nvarchar', value, colsize=len(value))
        return t
    for value in STR_FENCEPOSTS:
        locals()['test_unicode_%s' % len(value)] = _maketest(value)

    def test_unicode_longmax(self):
        # Issue 188:	Segfault when fetching NVARCHAR(MAX) data over 511 bytes

        ver = self.get_sqlserver_version()
        if ver < 9:            # 2005+
            return              # so pass / ignore
        self.cursor.execute(""select cast(replicate(N'x', 512) as nvarchar(max))"")

    # From issue #206
    def _maketest(value):
        def t(self):
            self._test_strtype('nvarchar', value, colsize=len(value))
        return t
    locals()['test_chinese_param'] = _maketest('我的')

    def test_chinese(self):
        v = '我的'
        self.cursor.execute(u""SELECT N'我的' AS [Name]"")
        row = self.cursor.fetchone()
        self.assertEqual(row[0], v)

        self.cursor.execute(u""SELECT N'我的' AS [Name]"")
        rows = self.cursor.fetchall()
        self.assertEqual(rows[0][0], v)


    #
    # binary
    #

    def test_binary_null(self):
        self._test_strtype('varbinary', None, colsize=100)

    # bytearray

    def _maketest(value):
        def t(self):
            self._test_strtype('varbinary', bytearray(value), colsize=len(value), resulttype=bytes)
        return t
    for value in BYTE_FENCEPOSTS:
        locals()['test_binary_bytearray_%s' % len(value)] = _maketest(value)

    # bytes

    def _maketest(value):
        def t(self):
            self._test_strtype('varbinary', bytes(value), colsize=len(value))
        return t
    for value in BYTE_FENCEPOSTS:
        locals()['test_binary_bytes_%s' % len(value)] = _maketest(value)

    #
    # image
    #

    def test_image_null(self):
        self._test_strliketype('image', None)

    # bytearray

    def _maketest(value):
        def t(self):
            self._test_strliketype('image', bytearray(value), resulttype=bytes)
        return t
    for value in IMAGE_FENCEPOSTS:
        locals()['test_image_bytearray_%s' % len(value)] = _maketest(value)

    # bytes

    def _maketest(value):
        def t(self):
            self._test_strliketype('image', bytes(value))
        return t
    for value in IMAGE_FENCEPOSTS:
        locals()['test_image_bytes_%s' % len(value)] = _maketest(value)

    #
    # text
    #

    def test_null_text(self):
        self._test_strliketype('text', None)

    def _maketest(value):
        def t(self):
            self._test_strliketype('text', value)
        return t
    for value in STR_FENCEPOSTS:
        locals()['test_text_%s' % len(value)] = _maketest(value)

    #
    # bit
    #

    def test_bit(self):
        value = True
        self.cursor.execute(""create table t1(b bit)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        v = self.cursor.execute(""select b from t1"").fetchone()[0]
        self.assertEqual(type(v), bool)
        self.assertEqual(v, value)

    #
    # decimal
    #

    def _decimal(self, precision, scale, negative):
        # From test provided by planders (thanks!) in Issue 91

        self.cursor.execute(""create table t1(d decimal(%s, %s))"" % (precision, scale))

        # Construct a decimal that uses the maximum precision and scale.
        decStr = '9' * (precision - scale)
        if scale:
            decStr = decStr + ""."" + '9' * scale
        if negative:
            decStr = ""-"" + decStr

        value = Decimal(decStr)

        self.cursor.execute(""insert into t1 values(?)"", value)

        v = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(v, value)

    def _maketest(p, s, n):
        def t(self):
            self._decimal(p, s, n)
        return t
    for (p, s, n) in [ (1,  0,  False),
                       (1,  0,  True),
                       (6,  0,  False),
                       (6,  2,  False),
                       (6,  4,  True),
                       (6,  6,  True),
                       (38, 0,  False),
                       (38, 10, False),
                       (38, 38, False),
                       (38, 0,  True),
                       (38, 10, True),
                       (38, 38, True) ]:
        locals()['test_decimal_%s_%s_%s' % (p, s, n and 'n' or 'p')] = _maketest(p, s, n)


    def test_decimal_e(self):
        """"""Ensure exponential notation decimals are properly handled""""""
        value = Decimal((0, (1, 2, 3), 5)) # prints as 1.23E+7
        self.cursor.execute(""create table t1(d decimal(10, 2))"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_subquery_params(self):
        """"""Ensure parameter markers work in a subquery""""""
        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        row = self.cursor.execute(""""""
                                  select x.id
                                  from (
                                    select id
                                    from t1
                                    where s = ?
                                      and id between ? and ?
                                   ) x
                                   """""", 'test', 1, 10).fetchone()
        self.assertNotEqual(row, None)
        self.assertEqual(row[0], 1)

    def _exec(self):
        self.cursor.execute(self.sql)

    def test_close_cnxn(self):
        """"""Make sure using a Cursor after closing its connection doesn't crash.""""""

        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        self.cursor.execute(""select * from t1"")

        self.cnxn.close()

        # Now that the connection is closed, we expect an exception.  (If the code attempts to use
        # the HSTMT, we'll get an access violation instead.)
        self.sql = ""select * from t1""
        self.assertRaises(pyodbc.ProgrammingError, self._exec)

    def test_empty_string(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", """")

    def test_empty_string_encoding(self):
        self.cnxn.setdecoding(pyodbc.SQL_CHAR, encoding='shift_jis')
        value = """"
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(v, value)

    def test_fixed_str(self):
        value = ""testing""
        self.cursor.execute(""create table t1(s char(7))"")
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(len(v), len(value)) # If we alloc'd wrong, the test below might work because of an embedded NULL
        self.assertEqual(v, value)

    def test_empty_unicode(self):
        self.cursor.execute(""create table t1(s nvarchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", """")

    def test_empty_unicode_encoding(self):
        self.cnxn.setdecoding(pyodbc.SQL_CHAR, encoding='shift_jis')
        value = """"
        self.cursor.execute(""create table t1(s nvarchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(v, value)

    def test_negative_row_index(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", ""1"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row[0], ""1"")
        self.assertEqual(row[-1], ""1"")

    def test_version(self):
        self.assertEqual(3, len(pyodbc.version.split('.'))) # 1.3.1 etc.

    #
    # date, time, datetime
    #

    def test_datetime(self):
        value = datetime(2007, 1, 15, 3, 4, 5)

        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(value, result)

    def test_datetime_fraction(self):
        # SQL Server supports milliseconds, but Python's datetime supports nanoseconds, so the most granular datetime
        # supported is xxx000.

        value = datetime(2007, 1, 15, 3, 4, 5, 123000)

        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(result, value)

    def test_datetime_fraction_rounded(self):
        # SQL Server supports milliseconds, but Python's datetime supports nanoseconds.  pyodbc rounds down to what the
        # database supports.

        full    = datetime(2007, 1, 15, 3, 4, 5, 123456)
        rounded = datetime(2007, 1, 15, 3, 4, 5, 123000)

        self.cursor.execute(""create table t1(dt datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", full)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(result), datetime)
        self.assertEqual(result, rounded)

    def test_date(self):
        ver = self.get_sqlserver_version()
        if ver < 10:            # 2008 only
            return              # so pass / ignore

        value = date.today()

        self.cursor.execute(""create table t1(d date)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(type(value), date)
        self.assertEqual(value, result)

    def test_time(self):
        ver = self.get_sqlserver_version()
        if ver < 10:            # 2008 only
            return              # so pass / ignore

        value = datetime.now().time()

        # We aren't yet writing values using the new extended time type so the value written to the database is only
        # down to the second.
        value = value.replace(microsecond=0)

        self.cursor.execute(""create table t1(t time)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select t from t1"").fetchone()[0]
        self.assertEqual(type(value), time)
        self.assertEqual(value, result)

    def test_datetime2(self):
        value = datetime(2007, 1, 15, 3, 4, 5)

        self.cursor.execute(""create table t1(dt datetime2)"")
        self.cursor.execute(""insert into t1 values (?)"", value)

        result = self.cursor.execute(""select dt from t1"").fetchone()[0]
        self.assertEqual(type(value), datetime)
        self.assertEqual(value, result)

    #
    # ints and floats
    #

    def test_int(self):
        value = 1234
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_int(self):
        value = -1
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_bigint(self):
        input = 3000000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_float(self):
        value = 1234.567
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_float(self):
        value = -200
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result  = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(value, result)

    #
    # stored procedures
    #

    # def test_callproc(self):
    #     ""callproc with a simple input-only stored procedure""
    #     pass

    def test_sp_results(self):
        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              select top 10 name, id, xtype, refdate
              from sysobjects
            """""")
        rows = self.cursor.execute(""exec proc1"").fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)


    def test_sp_results_from_temp(self):

        # Note: I've used ""set nocount on"" so that we don't get the number of rows deleted from #tmptable.
        # If you don't do this, you'd need to call nextset() once to skip it.

        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              set nocount on
              select top 10 name, id, xtype, refdate
              into #tmptable
              from sysobjects

              select * from #tmptable
            """""")
        self.cursor.execute(""exec proc1"")
        self.assertTrue(self.cursor.description is not None)
        self.assertTrue(len(self.cursor.description) == 4)

        rows = self.cursor.fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)


    def test_sp_results_from_vartbl(self):
        self.cursor.execute(
            """"""
            Create procedure proc1
            AS
              set nocount on
              declare @tmptbl table(name varchar(100), id int, xtype varchar(4), refdate datetime)

              insert into @tmptbl
              select top 10 name, id, xtype, refdate
              from sysobjects

              select * from @tmptbl
            """""")
        self.cursor.execute(""exec proc1"")
        rows = self.cursor.fetchall()
        self.assertEqual(type(rows), list)
        self.assertEqual(len(rows), 10) # there has to be at least 10 items in sysobjects
        self.assertEqual(type(rows[0].refdate), datetime)

    def test_sp_with_dates(self):
        # Reported in the forums that passing two datetimes to a stored procedure doesn't work.
        self.cursor.execute(
            """"""
            if exists (select * from dbo.sysobjects where id = object_id(N'[test_sp]') and OBJECTPROPERTY(id, N'IsProcedure') = 1)
              drop procedure [dbo].[test_sp]
            """""")
        self.cursor.execute(
            """"""
            create procedure test_sp(@d1 datetime, @d2 datetime)
            AS
              declare @d as int
              set @d = datediff(year, @d1, @d2)
              select @d
            """""")
        self.cursor.execute(""exec test_sp ?, ?"", datetime.now(), datetime.now())
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(rows[0][0] == 0)   # 0 years apart

    def test_sp_with_none(self):
        # Reported in the forums that passing None caused an error.
        self.cursor.execute(
            """"""
            if exists (select * from dbo.sysobjects where id = object_id(N'[test_sp]') and OBJECTPROPERTY(id, N'IsProcedure') = 1)
              drop procedure [dbo].[test_sp]
            """""")
        self.cursor.execute(
            """"""
            create procedure test_sp(@x varchar(20))
            AS
              declare @y varchar(20)
              set @y = @x
              select @y
            """""")
        self.cursor.execute(""exec test_sp ?"", None)
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(rows[0][0] == None)   # 0 years apart


    #
    # rowcount
    #

    def test_rowcount_delete(self):
        self.assertEqual(self.cursor.rowcount, -1)
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, count)

    def test_rowcount_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.  On the other hand, we could hardcode a
        zero return value.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, 0)

    def test_rowcount_select(self):
        """"""
        Ensure Cursor.rowcount is set properly after a select statement.

        pyodbc calls SQLRowCount after each execute and sets Cursor.rowcount, but SQL Server 2005 returns -1 after a
        select statement, so we'll test for that behavior.  This is valid behavior according to the DB API
        specification, but people don't seem to like it.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""select * from t1"")
        self.assertEqual(self.cursor.rowcount, -1)

        rows = self.cursor.fetchall()
        self.assertEqual(len(rows), count)
        self.assertEqual(self.cursor.rowcount, -1)

    def test_rowcount_reset(self):
        ""Ensure rowcount is reset to -1""

        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.assertEqual(self.cursor.rowcount, 1)

        self.cursor.execute(""create table t2(i int)"")
        self.assertEqual(self.cursor.rowcount, -1)

    #
    # always return Cursor
    #

    # In the 2.0.x branch, Cursor.execute sometimes returned the cursor and sometimes the rowcount.  This proved very
    # confusing when things went wrong and added very little value even when things went right since users could always
    # use: cursor.execute(""..."").rowcount

    def test_retcursor_delete(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_select(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""select * from t1"")
        self.assertEqual(v, self.cursor)

    #
    # misc
    #

    def table_with_spaces(self):
        ""Ensure we can select using [x z] syntax""

        try:
            self.cursor.execute(""create table [test one](int n)"")
            self.cursor.execute(""insert into [test one] values(1)"")
            self.cursor.execute(""select * from [test one]"")
            v = self.cursor.fetchone()[0]
            self.assertEqual(v, 1)
        finally:
            self.cnxn.rollback()

    def test_lower_case(self):
        ""Ensure pyodbc.lowercase forces returned column names to lowercase.""

        # Has to be set before creating the cursor, so we must recreate self.cursor.

        pyodbc.lowercase = True
        self.cursor = self.cnxn.cursor()

        self.cursor.execute(""create table t1(Abc int, dEf int)"")
        self.cursor.execute(""select * from t1"")

        names = [ t[0] for t in self.cursor.description ]
        names.sort()

        self.assertEqual(names, [ ""abc"", ""def"" ])

        # Put it back so other tests don't fail.
        pyodbc.lowercase = False

    def test_row_description(self):
        """"""
        Ensure Cursor.description is accessible as Row.cursor_description.
        """"""
        self.cursor = self.cnxn.cursor()
        self.cursor.execute(""create table t1(a int, b char(3))"")
        self.cnxn.commit()
        self.cursor.execute(""insert into t1 values(1, 'abc')"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        self.assertEqual(self.cursor.description, row.cursor_description)


    def test_temp_select(self):
        # A project was failing to create temporary tables via select into.
        self.cursor.execute(""create table t1(s char(7))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(v, ""testing"")

        self.cursor.execute(""select s into t2 from t1"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), str)
        self.assertEqual(v, ""testing"")

    # Money
    #
    # The inputs are strings so we don't have to deal with floating point rounding.

    for value in ""-1234.56  -1  0  1  1234.56  123456789.21"".split():
        name = str(value).replace('.', '_').replace('-', 'neg_')
        locals()['test_money_%s' % name] = _simpletest('money', Decimal(str(value)))

    def test_executemany(self):
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (i, str(i)) for i in range(1, 6) ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])


    def test_executemany_one(self):
        ""Pass executemany a single sequence""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, ""test"") ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])


    def test_executemany_failure(self):
        """"""
        Ensure that an exception is raised if one query in an executemany fails.
        """"""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, 'good'),
                   ('error', 'not an int'),
                   (3, 'good') ]

        self.assertRaises(pyodbc.Error, self.cursor.executemany, ""insert into t1(a, b) value (?, ?)"", params)


    def test_row_slicing(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = row[:]
        self.assertTrue(result is row)

        result = row[:-1]
        self.assertEqual(result, (1,2,3))

        result = row[0:4]
        self.assertTrue(result is row)


    def test_row_repr(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = str(row)
        self.assertEqual(result, ""(1, 2, 3, 4)"")

        result = str(row[:-1])
        self.assertEqual(result, ""(1, 2, 3)"")

        result = str(row[:1])
        self.assertEqual(result, ""(1,)"")


    def test_concatenation(self):
        v2 = '0123456789' * 30
        v3 = '9876543210' * 30

        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(300), c3 varchar(300))"")
        self.cursor.execute(""insert into t1(c2, c3) values (?,?)"", v2, v3)

        row = self.cursor.execute(""select c2, c3, c2 + c3 as both from t1"").fetchone()

        self.assertEqual(row.both, v2 + v3)

    def test_view_select(self):
        # Reported in forum: Can't select from a view?  I think I do this a lot, but another test never hurts.

        # Create a table (t1) with 3 rows and a view (t2) into it.
        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(50))"")
        for i in range(3):
            self.cursor.execute(""insert into t1(c2) values (?)"", ""string%s"" % i)
        self.cursor.execute(""create view t2 as select * from t1"")

        # Select from the view
        self.cursor.execute(""select * from t2"")
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(len(rows) == 3)

    def test_autocommit(self):
        self.assertEqual(self.cnxn.autocommit, False)
        othercnxn = pyodbc.connect(self.connection_string, autocommit=True)
        self.assertEqual(othercnxn.autocommit, True)
        othercnxn.autocommit = False
        self.assertEqual(othercnxn.autocommit, False)

    def test_sqlserver_callproc(self):
        try:
            self.cursor.execute(""drop procedure pyodbctest"")
            self.cnxn.commit()
        except:
            pass

        self.cursor.execute(""create table t1(s varchar(10))"")
        self.cursor.execute(""insert into t1 values(?)"", ""testing"")

        self.cursor.execute(""""""
                            create procedure pyodbctest @var1 varchar(32)
                            as
                            begin
                              select s
                              from t1
                            return
                            end
                            """""")
        self.cnxn.commit()

        # for row in self.cursor.procedureColumns('pyodbctest'):
        #     print row.procedure_name, row.column_name, row.column_type, row.type_name

        self.cursor.execute(""exec pyodbctest 'hi'"")

        # print self.cursor.description
        # for row in self.cursor:
        #     print row.s

    def test_skip(self):
        # Insert 1, 2, and 3.  Fetch 1, skip 2, fetch 3.

        self.cursor.execute(""create table t1(id int)"");
        for i in range(1, 5):
            self.cursor.execute(""insert into t1 values(?)"", i)
        self.cursor.execute(""select id from t1 order by id"")
        self.assertEqual(self.cursor.fetchone()[0], 1)
        self.cursor.skip(2)
        self.assertEqual(self.cursor.fetchone()[0], 4)

    def test_timeout(self):
        self.assertEqual(self.cnxn.timeout, 0) # defaults to zero (off)

        self.cnxn.timeout = 30
        self.assertEqual(self.cnxn.timeout, 30)

        self.cnxn.timeout = 0
        self.assertEqual(self.cnxn.timeout, 0)

    def test_sets_execute(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.execute(""insert into t1 (word) VALUES (?)"", [words])

        self.assertRaises(pyodbc.ProgrammingError, f)

    def test_sets_executemany(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.executemany(""insert into t1 (word) values (?)"", [words])

        self.assertRaises(TypeError, f)

    def test_row_execute(self):
        ""Ensure we can use a Row object as a parameter to execute""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, 'a')"")
        row = self.cursor.execute(""select n, s from t1"").fetchone()
        self.assertNotEqual(row, None)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.execute(""insert into t2 values (?, ?)"", row)

    def test_row_executemany(self):
        ""Ensure we can use a Row object as a parameter to executemany""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")

        for i in range(3):
            self.cursor.execute(""insert into t1 values (?, ?)"", i, chr(ord('a')+i))

        rows = self.cursor.execute(""select n, s from t1"").fetchall()
        self.assertNotEqual(len(rows), 0)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.executemany(""insert into t2 values (?, ?)"", rows)

    def test_description(self):
        ""Ensure cursor.description is correct""

        self.cursor.execute(""create table t1(n int, s varchar(8), d decimal(5,2))"")
        self.cursor.execute(""insert into t1 values (1, 'abc', '1.23')"")
        self.cursor.execute(""select * from t1"")

        # (I'm not sure the precision of an int is constant across different versions, bits, so I'm hand checking the
        # items I do know.

        # int
        t = self.cursor.description[0]
        self.assertEqual(t[0], 'n')
        self.assertEqual(t[1], int)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # varchar(8)
        t = self.cursor.description[1]
        self.assertEqual(t[0], 's')
        self.assertEqual(t[1], str)
        self.assertEqual(t[4], 8)       # precision
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # decimal(5, 2)
        t = self.cursor.description[2]
        self.assertEqual(t[0], 'd')
        self.assertEqual(t[1], Decimal)
        self.assertEqual(t[4], 5)       # precision
        self.assertEqual(t[5], 2)       # scale
        self.assertEqual(t[6], True)    # nullable


    def test_none_param(self):
        ""Ensure None can be used for params other than the first""
        # Some driver/db versions would fail if NULL was not the first parameter because SQLDescribeParam (only used
        # with NULL) could not be used after the first call to SQLBindParameter.  This means None always worked for the
        # first column, but did not work for later columns.
        #
        # If SQLDescribeParam doesn't work, pyodbc would use VARCHAR which almost always worked.  However,
        # binary/varbinary won't allow an implicit conversion.

        self.cursor.execute(""create table t1(n int, blob varbinary(max))"")
        self.cursor.execute(""insert into t1 values (1, newid())"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row.n, 1)
        self.assertEqual(type(row.blob), bytes)

        self.cursor.execute(""update t1 set n=?, blob=?"", 2, None)
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row.n, 2)
        self.assertEqual(row.blob, None)


    def test_output_conversion(self):
        def convert(value):
            # The value is the raw bytes (as a bytes object) read from the
            # database.  We'll simply add an X at the beginning at the end.
            return 'X' + value.decode('latin1') + 'X'
        self.cnxn.add_output_converter(pyodbc.SQL_VARCHAR, convert)
        self.cursor.execute(""create table t1(n int, v varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, '123.45')"")
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, 'X123.45X')

        # Now clear the conversions and try again.  There should be no Xs this time.
        self.cnxn.clear_output_converters()
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, '123.45')


    def test_too_large(self):
        """"""Ensure error raised if insert fails due to truncation""""""
        value = 'x' * 1000
        self.cursor.execute(""create table t1(s varchar(800))"")
        def test():
            self.cursor.execute(""insert into t1 values (?)"", value)
        self.assertRaises(pyodbc.DataError, test)

    def test_geometry_null_insert(self):
        def convert(value):
            return value

        self.cnxn.add_output_converter(-151, convert) # -151 is SQL Server's geometry
        self.cursor.execute(""create table t1(n int, v geometry)"")
        self.cursor.execute(""insert into t1 values (?, ?)"", 1, None)
        value = self.cursor.execute(""select v from t1"").fetchone()[0]
        self.assertEqual(value, None)
        self.cnxn.clear_output_converters()

    def test_login_timeout(self):
        # This can only test setting since there isn't a way to cause it to block on the server side.
        cnxns = pyodbc.connect(self.connection_string, timeout=2)

    def test_row_equal(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test')"")
        row1 = self.cursor.execute(""select n, s from t1"").fetchone()
        row2 = self.cursor.execute(""select n, s from t1"").fetchone()
        b = (row1 == row2)
        self.assertEqual(b, True)

    def test_row_gtlt(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test1')"")
        self.cursor.execute(""insert into t1 values (1, 'test2')"")
        rows = self.cursor.execute(""select n, s from t1 order by s"").fetchall()
        self.assertTrue(rows[0] < rows[1])
        self.assertTrue(rows[0] <= rows[1])
        self.assertTrue(rows[1] > rows[0])
        self.assertTrue(rows[1] >= rows[0])
        self.assertTrue(rows[0] != rows[1])

        rows = list(rows)
        rows.sort() # uses <

    def test_context_manager_success(self):
        ""Ensure `with` commits if an exception is not raised""
        self.cursor.execute(""create table t1(n int)"")
        self.cnxn.commit()

        with self.cnxn:
            self.cursor.execute(""insert into t1 values (1)"")

        rows = self.cursor.execute(""select n from t1"").fetchall()
        self.assertEqual(len(rows), 1)
        self.assertEqual(rows[0][0], 1)

    def test_context_manager_failure(self):
        ""Ensure `with` rolls back if an exception is raised""
        # We'll insert a row and commit it.  Then we'll insert another row followed by an
        # exception.

        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        self.cnxn.commit()

        def _fail():
            with self.cnxn:
                self.cursor.execute(""insert into t1 values (2)"")
                self.cursor.execute(""delete from bogus"")

        self.assertRaises(pyodbc.Error, _fail)

        self.cursor.execute(""select max(n) from t1"")
        val = self.cursor.fetchval()
        self.assertEqual(val, 1)


    def test_untyped_none(self):
        # From issue 129
        value = self.cursor.execute(""select ?"", None).fetchone()[0]
        self.assertEqual(value, None)

    def test_large_update_nodata(self):
        self.cursor.execute('create table t1(a varbinary(max))')
        hundredkb = b'x'*100*1024
        self.cursor.execute('update t1 set a=? where 1=0', (hundredkb,))

    def test_func_param(self):
        self.cursor.execute('''
                            create function func1 (@testparam varchar(4))
                            returns @rettest table (param varchar(4))
                            as
                            begin
                                insert @rettest
                                select @testparam
                                return
                            end
                            ''')
        self.cnxn.commit()
        value = self.cursor.execute(""select * from func1(?)"", 'test').fetchone()[0]
        self.assertEqual(value, 'test')

    def test_no_fetch(self):
        # Issue 89 with FreeTDS: Multiple selects (or catalog functions that issue selects) without fetches seem to
        # confuse the driver.
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')

    def test_drivers(self):
        drivers = pyodbc.drivers()
        self.assertEqual(list, type(drivers))
        self.assertTrue(len(drivers) > 0)

        m = re.search('DRIVER={([^}]+)}', self.connection_string, re.IGNORECASE)
        current = m.group(1)
        self.assertTrue(current in drivers)

    def test_decode_meta(self):
        """"""
        Ensure column names with non-ASCII characters are converted using the configured encodings.
        """"""
        # This is from GitHub issue #190
        self.cursor.execute(""create table t1(a int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        self.cursor.execute('select a as ""Tipología"" from t1')
        self.assertEqual(self.cursor.description[0][0], ""Tipología"")

    def test_exc_integrity(self):
        ""Make sure an IntegretyError is raised""
        # This is really making sure we are properly encoding and comparing the SQLSTATEs.
        self.cursor.execute(""create table t1(s1 varchar(10) primary key)"")
        self.cursor.execute(""insert into t1 values ('one')"")
        self.assertRaises(pyodbc.IntegrityError, self.cursor.execute, ""insert into t1 values ('one')"")

    def test_columns(self):
        # When using aiohttp, `await cursor.primaryKeys('t1')` was raising the error
        #
        #   Error: TypeError: argument 2 must be str, not None
        #
        # I'm not sure why, but PyArg_ParseTupleAndKeywords fails if you use ""|s"" for an
        # optional string keyword when calling indirectly.

        self.cursor.execute(""create table t1(a int, b varchar(3))"")

        self.cursor.columns('t1')
        results = {row.column_name: row for row in self.cursor}
        row = results['a']
        assert row.type_name == 'int', row.type_name
        row = results['b']
        assert row.type_name == 'varchar'
        assert row.column_size == 3

        # Now do the same, but specifically pass in None to one of the keywords.  Old versions
        # were parsing arguments incorrectly and would raise an error.  (This crops up when
        # calling indirectly like columns(*args, **kwargs) which aiodbc does.)

        self.cursor.columns('t1', schema=None, catalog=None)
        results = {row.column_name: row for row in self.cursor}
        row = results['a']
        assert row.type_name == 'int', row.type_name
        row = results['b']
        assert row.type_name == 'varchar'
        assert row.column_size == 3

    def test_cancel(self):
        # I'm not sure how to reliably cause a hang to cancel, so for now we'll settle with
        # making sure SQLCancel is called correctly.
        self.cursor.execute(""select 1"")
        self.cursor.cancel()

    def test_emoticons(self):
        # https://github.com/mkleehammer/pyodbc/issues/423
        #
        # When sending a varchar parameter, pyodbc is supposed to set ColumnSize to the number
        # of characters.  Ensure it works even with 4-byte characters.
        #
        # http://www.fileformat.info/info/unicode/char/1f31c/index.htm
        v = ""x \U0001F31C z""

        self.cursor.execute(""create table t1(s nvarchar(100))"")
        self.cursor.execute(""insert into t1 values (?)"", v)

        result = self.cursor.execute(""select s from t1"").fetchone()[0]

        self.assertEqual(result, v)
        
def main():
    from optparse import OptionParser
    parser = OptionParser(usage=usage)
    parser.add_option(""-v"", ""--verbose"", action=""count"", default=0, help=""Increment test verbosity (can be used multiple times)"")
    parser.add_option(""-d"", ""--debug"", action=""store_true"", default=False, help=""Print debugging items"")
    parser.add_option(""-t"", ""--test"", help=""Run only the named test"")

    (options, args) = parser.parse_args()

    if len(args) > 1:
        parser.error('Only one argument is allowed.  Do you need quotes around the connection string?')

    if not args:
        connection_string = load_setup_connection_string('sqlservertests')

        if not connection_string:
            parser.print_help()
            raise SystemExit()
    else:
        connection_string = args[0]

    cnxn = pyodbc.connect(connection_string)
    print_library_info(cnxn)
    cnxn.close()

    suite = load_tests(SqlServerTestCase, options.test, connection_string)

    testRunner = unittest.TextTestRunner(verbosity=options.verbose)
    result = testRunner.run(suite)


if __name__ == '__main__':

    # Add the build directory to the path so we're testing the latest build, not the installed version.

    add_to_path()

    import pyodbc
    main()
/n/n/ntests3/testutils.py/n/nimport os, sys, platform
from os.path import join, dirname, abspath, basename
import unittest

def add_to_path():
    """"""
    Prepends the build directory to the path so that newly built pyodbc libraries are used, allowing it to be tested
    without installing it.
    """"""
    # Put the build directory into the Python path so we pick up the version we just built.
    #
    # To make this cross platform, we'll search the directories until we find the .pyd file.

    import imp

    library_exts  = [ t[0] for t in imp.get_suffixes() if t[-1] == imp.C_EXTENSION ]
    library_names = [ 'pyodbc%s' % ext for ext in library_exts ]

    # Only go into directories that match our version number.

    dir_suffix = '-%s.%s' % (sys.version_info[0], sys.version_info[1])

    build = join(dirname(dirname(abspath(__file__))), 'build')

    for root, dirs, files in os.walk(build):
        for d in dirs[:]:
            if not d.endswith(dir_suffix):
                dirs.remove(d)

        for name in library_names:
            if name in files:
                sys.path.insert(0, root)
                return

    print('Did not find the pyodbc library in the build directory.  Will use an installed version.')


def print_library_info(cnxn):
    import pyodbc
    print('python:  %s' % sys.version)
    print('pyodbc:  %s %s' % (pyodbc.version, os.path.abspath(pyodbc.__file__)))
    print('odbc:    %s' % cnxn.getinfo(pyodbc.SQL_ODBC_VER))
    print('driver:  %s %s' % (cnxn.getinfo(pyodbc.SQL_DRIVER_NAME), cnxn.getinfo(pyodbc.SQL_DRIVER_VER)))
    print('         supports ODBC version %s' % cnxn.getinfo(pyodbc.SQL_DRIVER_ODBC_VER))
    print('os:      %s' % platform.system())
    print('unicode: Py_Unicode=%s SQLWCHAR=%s' % (pyodbc.UNICODE_SIZE, pyodbc.SQLWCHAR_SIZE))

    cursor = cnxn.cursor()
    for typename in ['VARCHAR', 'WVARCHAR', 'BINARY']:
        t = getattr(pyodbc, 'SQL_' + typename)
        cursor.getTypeInfo(t)
        row = cursor.fetchone()
        print('Max %s = %s' % (typename, row and row[2] or '(not supported)'))

    if platform.system() == 'Windows':
        print('         %s' % ' '.join([s for s in platform.win32_ver() if s]))



def load_tests(testclass, name, *args):
    """"""
    Returns a TestSuite for tests in `testclass`.

    name
      Optional test name if you only want to run 1 test.  If not provided all tests in `testclass` will be loaded.

    args
      Arguments for the test class constructor.  These will be passed after the test method name.
    """"""
    if name:
        if not name.startswith('test_'):
            name = 'test_%s' % name
        names = [ name ]

    else:
        names = [ method for method in dir(testclass) if method.startswith('test_') ]

    return unittest.TestSuite([ testclass(name, *args) for name in names ])


def load_setup_connection_string(section):
    """"""
    Attempts to read the default connection string from the setup.cfg file.

    If the file does not exist or if it exists but does not contain the connection string, None is returned.  If the
    file exists but cannot be parsed, an exception is raised.
    """"""
    from os.path import exists, join, dirname, splitext, basename
    from configparser import SafeConfigParser

    FILENAME = 'setup.cfg'
    KEY      = 'connection-string'

    path = dirname(abspath(__file__))
    while True:
        fqn = join(path, 'tmp', FILENAME)
        if exists(fqn):
            break
        parent = dirname(path)
        print('{} --> {}'.format(path, parent))
        if parent == path:
            return None
        path = parent

    try:
        p = SafeConfigParser()
        p.read(fqn)
    except:
        raise SystemExit('Unable to parse %s: %s' % (path, sys.exc_info()[1]))

    if p.has_option(section, KEY):
        return p.get(section, KEY)
/n/n/n",0
115,115,dcdb81e6f86420c96cc113a726be8663566cfe95,"/tests2/sqlitetests.py/n/n#!/usr/bin/python
# -*- coding: latin-1 -*-

usage = """"""\
usage: %prog [options] connection_string

Unit tests for SQLite using the ODBC driver from http://www.ch-werner.de/sqliteodbc

To use, pass a connection string as the parameter. The tests will create and
drop tables t1 and t2 as necessary.  On Windows, use the 32-bit driver with
32-bit Python and the 64-bit driver with 64-bit Python (regardless of your
operating system bitness).

These run using the version from the 'build' directory, not the version
installed into the Python directories.  You must run python setup.py build
before running the tests.

You can also put the connection string into a setup.cfg file in the root of the project
(the same one setup.py would use) like so:

  [sqlitetests]
  connection-string=Driver=SQLite3 ODBC Driver;Database=sqlite.db
""""""

import sys, os, re
import unittest
from decimal import Decimal
from datetime import datetime, date, time
from os.path import join, getsize, dirname, abspath
from testutils import *

_TESTSTR = '0123456789-abcdefghijklmnopqrstuvwxyz-'

def _generate_test_string(length):
    """"""
    Returns a string of `length` characters, constructed by repeating _TESTSTR as necessary.

    To enhance performance, there are 3 ways data is read, based on the length of the value, so most data types are
    tested with 3 lengths.  This function helps us generate the test data.

    We use a recognizable data set instead of a single character to make it less likely that ""overlap"" errors will
    be hidden and to help us manually identify where a break occurs.
    """"""
    if length <= len(_TESTSTR):
        return _TESTSTR[:length]

    c = (length + len(_TESTSTR)-1) / len(_TESTSTR)
    v = _TESTSTR * c
    return v[:length]

class SqliteTestCase(unittest.TestCase):

    SMALL_FENCEPOST_SIZES = [ 0, 1, 255, 256, 510, 511, 512, 1023, 1024, 2047, 2048, 4000 ]
    LARGE_FENCEPOST_SIZES = [ 4095, 4096, 4097, 10 * 1024, 20 * 1024 ]

    ANSI_FENCEPOSTS    = [ _generate_test_string(size) for size in SMALL_FENCEPOST_SIZES ]
    UNICODE_FENCEPOSTS = [ unicode(s) for s in ANSI_FENCEPOSTS ]
    IMAGE_FENCEPOSTS   = ANSI_FENCEPOSTS + [ _generate_test_string(size) for size in LARGE_FENCEPOST_SIZES ]

    def __init__(self, method_name, connection_string):
        unittest.TestCase.__init__(self, method_name)
        self.connection_string = connection_string

    def setUp(self):
        self.cnxn   = pyodbc.connect(self.connection_string)
        self.cursor = self.cnxn.cursor()

        for i in range(3):
            try:
                self.cursor.execute(""drop table t%d"" % i)
                self.cnxn.commit()
            except:
                pass

        self.cnxn.rollback()

    def tearDown(self):
        try:
            self.cursor.close()
            self.cnxn.close()
        except:
            # If we've already closed the cursor or connection, exceptions are thrown.
            pass

    def test_multiple_bindings(self):
        ""More than one bind and select on a cursor""
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t1 values (?)"", 2)
        self.cursor.execute(""insert into t1 values (?)"", 3)
        for i in range(3):
            self.cursor.execute(""select n from t1 where n < ?"", 10)
            self.cursor.execute(""select n from t1 where n < 3"")
        

    def test_different_bindings(self):
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""create table t2(d datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t2 values (?)"", datetime.now())

    def test_drivers(self):
        p = pyodbc.drivers()
        self.assertTrue(isinstance(p, list))

    def test_datasources(self):
        p = pyodbc.dataSources()
        self.assertTrue(isinstance(p, dict))

    def test_getinfo_string(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CATALOG_NAME_SEPARATOR)
        self.assertTrue(isinstance(value, str))

    def test_getinfo_bool(self):
        value = self.cnxn.getinfo(pyodbc.SQL_ACCESSIBLE_TABLES)
        self.assertTrue(isinstance(value, bool))

    def test_getinfo_int(self):
        value = self.cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)
        self.assertTrue(isinstance(value, (int, long)))

    def test_getinfo_smallint(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CONCAT_NULL_BEHAVIOR)
        self.assertTrue(isinstance(value, int))

    def test_fixed_unicode(self):
        value = u""t\xebsting""
        self.cursor.execute(""create table t1(s nchar(7))"")
        self.cursor.execute(""insert into t1 values(?)"", u""t\xebsting"")
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), unicode)
        self.assertEqual(len(v), len(value)) # If we alloc'd wrong, the test below might work because of an embedded NULL
        self.assertEqual(v, value)


    def _test_strtype(self, sqltype, value, colsize=None):
        """"""
        The implementation for string, Unicode, and binary tests.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)

        # Reported by Andy Hochhaus in the pyodbc group: In 2.1.7 and earlier, a hardcoded length of 255 was used to
        # determine whether a parameter was bound as a SQL_VARCHAR or SQL_LONGVARCHAR.  Apparently SQL Server chokes if
        # we bind as a SQL_LONGVARCHAR and the target column size is 8000 or less, which is considers just SQL_VARCHAR.
        # This means binding a 256 character value would cause problems if compared with a VARCHAR column under
        # 8001. We now use SQLGetTypeInfo to determine the time to switch.
        #
        # [42000] [Microsoft][SQL Server Native Client 10.0][SQL Server]The data types varchar and text are incompatible in the equal to operator.

        self.cursor.execute(""select * from t1 where s=?"", value)


    def _test_strliketype(self, sqltype, value, colsize=None):
        """"""
        The implementation for text, image, ntext, and binary.

        These types do not support comparison operators.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)

    #
    # text
    #

    def test_text_null(self):
        self._test_strtype('text', None, 100)

    # Generate a test for each fencepost size: test_text_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('text', value, len(value))
        return t
    for value in UNICODE_FENCEPOSTS:
        locals()['test_text_%s' % len(value)] = _maketest(value)

    def test_text_upperlatin(self):
        self._test_strtype('varchar', u'')

    #
    # blob
    #

    def test_null_blob(self):
        self._test_strtype('blob', None, 100)
     
    def test_large_null_blob(self):
        # Bug 1575064
        self._test_strtype('blob', None, 4000)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('blob', bytearray(value), len(value))
        return t
    for value in ANSI_FENCEPOSTS:
        locals()['test_blob_%s' % len(value)] = _maketest(value)

    def test_subquery_params(self):
        """"""Ensure parameter markers work in a subquery""""""
        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        row = self.cursor.execute(""""""
                                  select x.id
                                  from (
                                    select id
                                    from t1
                                    where s = ?
                                      and id between ? and ?
                                   ) x
                                   """""", 'test', 1, 10).fetchone()
        self.assertNotEqual(row, None)
        self.assertEqual(row[0], 1)

    def _exec(self):
        self.cursor.execute(self.sql)
        
    def test_close_cnxn(self):
        """"""Make sure using a Cursor after closing its connection doesn't crash.""""""

        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        self.cursor.execute(""select * from t1"")

        self.cnxn.close()
        
        # Now that the connection is closed, we expect an exception.  (If the code attempts to use
        # the HSTMT, we'll get an access violation instead.)
        self.sql = ""select * from t1""
        self.assertRaises(pyodbc.ProgrammingError, self._exec)

    def test_empty_unicode(self):
        self.cursor.execute(""create table t1(s nvarchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", u"""")

    def test_unicode_query(self):
        self.cursor.execute(u""select 1"")
        
    def test_negative_row_index(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", ""1"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row[0], ""1"")
        self.assertEqual(row[-1], ""1"")

    def test_version(self):
        self.assertEqual(3, len(pyodbc.version.split('.'))) # 1.3.1 etc.

    #
    # ints and floats
    #

    def test_int(self):
        value = 1234
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_int(self):
        value = -1
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_bigint(self):
        input = 3000000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_negative_bigint(self):
        # Issue 186: BIGINT problem on 32-bit architeture
        input = -430000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_float(self):
        value = 1234.567
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_float(self):
        value = -200
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result  = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(value, result)

    #
    # rowcount
    #

    # Note: SQLRowCount does not define what the driver must return after a select statement
    # and says that its value should not be relied upon.  The sqliteodbc driver is hardcoded to
    # return 0 so I've deleted the test.

    def test_rowcount_delete(self):
        self.assertEqual(self.cursor.rowcount, -1)
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, count)

    def test_rowcount_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.  On the other hand, we could hardcode a
        zero return value.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, 0)

    # In the 2.0.x branch, Cursor.execute sometimes returned the cursor and sometimes the rowcount.  This proved very
    # confusing when things went wrong and added very little value even when things went right since users could always
    # use: cursor.execute(""..."").rowcount

    def test_retcursor_delete(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_select(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""select * from t1"")
        self.assertEqual(v, self.cursor)

    #
    # misc
    #

    def test_lower_case(self):
        ""Ensure pyodbc.lowercase forces returned column names to lowercase.""

        # Has to be set before creating the cursor, so we must recreate self.cursor.

        pyodbc.lowercase = True
        self.cursor = self.cnxn.cursor()

        self.cursor.execute(""create table t1(Abc int, dEf int)"")
        self.cursor.execute(""select * from t1"")

        names = [ t[0] for t in self.cursor.description ]
        names.sort()

        self.assertEqual(names, [ ""abc"", ""def"" ])

        # Put it back so other tests don't fail.
        pyodbc.lowercase = False
        
    def test_row_description(self):
        """"""
        Ensure Cursor.description is accessible as Row.cursor_description.
        """"""
        self.cursor = self.cnxn.cursor()
        self.cursor.execute(""create table t1(a int, b char(3))"")
        self.cnxn.commit()
        self.cursor.execute(""insert into t1 values(1, 'abc')"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        self.assertEqual(self.cursor.description, row.cursor_description)
        

    def test_executemany(self):
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (i, str(i)) for i in range(1, 6) ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])


    def test_executemany_one(self):
        ""Pass executemany a single sequence""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, ""test"") ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])
        

    def test_executemany_failure(self):
        """"""
        Ensure that an exception is raised if one query in an executemany fails.
        """"""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, 'good'),
                   ('error', 'not an int'),
                   (3, 'good') ]
        
        self.assertRaises(pyodbc.Error, self.cursor.executemany, ""insert into t1(a, b) value (?, ?)"", params)

        
    def test_row_slicing(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = row[:]
        self.assertTrue(result is row)

        result = row[:-1]
        self.assertEqual(result, (1,2,3))

        result = row[0:4]
        self.assertTrue(result is row)


    def test_row_repr(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = str(row)
        self.assertEqual(result, ""(1, 2, 3, 4)"")

        result = str(row[:-1])
        self.assertEqual(result, ""(1, 2, 3)"")

        result = str(row[:1])
        self.assertEqual(result, ""(1,)"")


    def test_view_select(self):
        # Reported in forum: Can't select from a view?  I think I do this a lot, but another test never hurts.

        # Create a table (t1) with 3 rows and a view (t2) into it.
        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(50))"")
        for i in range(3):
            self.cursor.execute(""insert into t1(c2) values (?)"", ""string%s"" % i)
        self.cursor.execute(""create view t2 as select * from t1"")

        # Select from the view
        self.cursor.execute(""select * from t2"")
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(len(rows) == 3)

    def test_autocommit(self):
        self.assertEqual(self.cnxn.autocommit, False)

        othercnxn = pyodbc.connect(self.connection_string, autocommit=True)
        self.assertEqual(othercnxn.autocommit, True)

        othercnxn.autocommit = False
        self.assertEqual(othercnxn.autocommit, False)

    def test_unicode_results(self):
        ""Ensure unicode_results forces Unicode""
        othercnxn = pyodbc.connect(self.connection_string, unicode_results=True)
        othercursor = othercnxn.cursor()

        # ANSI data in an ANSI column ...
        othercursor.execute(""create table t1(s varchar(20))"")
        othercursor.execute(""insert into t1 values(?)"", 'test')

        # ... should be returned as Unicode
        value = othercursor.execute(""select s from t1"").fetchone()[0]
        self.assertEqual(value, u'test')

    def test_skip(self):
        # Insert 1, 2, and 3.  Fetch 1, skip 2, fetch 3.

        self.cursor.execute(""create table t1(id int)"");
        for i in range(1, 5):
            self.cursor.execute(""insert into t1 values(?)"", i)
        self.cursor.execute(""select id from t1 order by id"")
        self.assertEqual(self.cursor.fetchone()[0], 1)
        self.cursor.skip(2)
        self.assertEqual(self.cursor.fetchone()[0], 4)

    def test_sets_execute(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.execute(""insert into t1 (word) VALUES (?)"", [words])

        self.assertRaises(pyodbc.ProgrammingError, f)

    def test_sets_executemany(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.executemany(""insert into t1 (word) values (?)"", [words])
            
        self.assertRaises(TypeError, f)

    def test_row_execute(self):
        ""Ensure we can use a Row object as a parameter to execute""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, 'a')"")
        row = self.cursor.execute(""select n, s from t1"").fetchone()
        self.assertNotEqual(row, None)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.execute(""insert into t2 values (?, ?)"", row)
        
    def test_row_executemany(self):
        ""Ensure we can use a Row object as a parameter to executemany""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")

        for i in range(3):
            self.cursor.execute(""insert into t1 values (?, ?)"", i, chr(ord('a')+i))

        rows = self.cursor.execute(""select n, s from t1"").fetchall()
        self.assertNotEqual(len(rows), 0)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.executemany(""insert into t2 values (?, ?)"", rows)
        
    def test_description(self):
        ""Ensure cursor.description is correct""

        self.cursor.execute(""create table t1(n int, s text)"")
        self.cursor.execute(""insert into t1 values (1, 'abc')"")
        self.cursor.execute(""select * from t1"")

        # (I'm not sure the precision of an int is constant across different versions, bits, so I'm hand checking the
        # items I do know.

        # int
        t = self.cursor.description[0]
        self.assertEqual(t[0], 'n')
        self.assertEqual(t[1], int)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # text
        t = self.cursor.description[1]
        self.assertEqual(t[0], 's')
        self.assertEqual(t[1], str)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

    def test_row_equal(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test')"")
        row1 = self.cursor.execute(""select n, s from t1"").fetchone()
        row2 = self.cursor.execute(""select n, s from t1"").fetchone()
        b = (row1 == row2)
        self.assertEqual(b, True)

    def test_row_gtlt(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test1')"")
        self.cursor.execute(""insert into t1 values (1, 'test2')"")
        rows = self.cursor.execute(""select n, s from t1 order by s"").fetchall()
        self.assertTrue(rows[0] < rows[1])
        self.assertTrue(rows[0] <= rows[1])
        self.assertTrue(rows[1] > rows[0])
        self.assertTrue(rows[1] >= rows[0])
        self.assertTrue(rows[0] != rows[1])

        rows = list(rows)
        rows.sort() # uses <
        
    def _test_context_manager(self):
        # TODO: This is failing, but it may be due to the design of sqlite.  I've disabled it
        # for now until I can research it some more.

        # WARNING: This isn't working right now.  We've set the driver's autocommit to ""off"",
        # but that doesn't automatically start a transaction.  I'm not familiar enough with the
        # internals of the driver to tell what is going on, but it looks like there is support
        # for the autocommit flag.
        #
        # I thought it might be a timing issue, like it not actually starting a txn until you
        # try to do something, but that doesn't seem to work either.  I'll leave this in to
        # remind us that it isn't working yet but we need to contact the SQLite ODBC driver
        # author for some guidance.

        with pyodbc.connect(self.connection_string) as cnxn:
            cursor = cnxn.cursor()
            cursor.execute(""begin"")
            cursor.execute(""create table t1(i int)"")
            cursor.execute('rollback')

        # The connection should be closed now.
        def test():
            cnxn.execute('rollback')
        self.assertRaises(pyodbc.Error, test)

    def test_untyped_none(self):
        # From issue 129
        value = self.cursor.execute(""select ?"", None).fetchone()[0]
        self.assertEqual(value, None)
        
    def test_large_update_nodata(self):
        self.cursor.execute('create table t1(a blob)')
        hundredkb = 'x'*100*1024
        self.cursor.execute('update t1 set a=? where 1=0', (hundredkb,))

    def test_no_fetch(self):
        # Issue 89 with FreeTDS: Multiple selects (or catalog functions that issue selects) without fetches seem to
        # confuse the driver.
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')


def main():
    from optparse import OptionParser
    parser = OptionParser(usage=usage)
    parser.add_option(""-v"", ""--verbose"", default=0, action=""count"", help=""Increment test verbosity (can be used multiple times)"")
    parser.add_option(""-d"", ""--debug"", action=""store_true"", default=False, help=""Print debugging items"")
    parser.add_option(""-t"", ""--test"", help=""Run only the named test"")

    (options, args) = parser.parse_args()

    if len(args) > 1:
        parser.error('Only one argument is allowed.  Do you need quotes around the connection string?')

    if not args:
        connection_string = load_setup_connection_string('sqlitetests')

        if not connection_string:
            parser.print_help()
            raise SystemExit()
    else:
        connection_string = args[0]

    if options.verbose:
        cnxn = pyodbc.connect(connection_string)
        print_library_info(cnxn)
        cnxn.close()

    suite = load_tests(SqliteTestCase, options.test, connection_string)

    testRunner = unittest.TextTestRunner(verbosity=options.verbose)
    result = testRunner.run(suite)

    sys.exit(result.errors and 1 or 0)


if __name__ == '__main__':

    # Add the build directory to the path so we're testing the latest build, not the installed version.

    add_to_path()

    import pyodbc
    main()
/n/n/n/tests3/sqlitetests.py/n/n#!/usr/bin/python
# -*- coding: latin-1 -*-

usage = """"""\
usage: %prog [options] connection_string

Unit tests for SQLite using the ODBC driver from http://www.ch-werner.de/sqliteodbc

To use, pass a connection string as the parameter. The tests will create and
drop tables t1 and t2 as necessary.  On Windows, use the 32-bit driver with
32-bit Python and the 64-bit driver with 64-bit Python (regardless of your
operating system bitness).

These run using the version from the 'build' directory, not the version
installed into the Python directories.  You must run python setup.py build
before running the tests.

You can also put the connection string into a setup.cfg file in the root of the project
(the same one setup.py would use) like so:

  [sqlitetests]
  connection-string=Driver=SQLite3 ODBC Driver;Database=sqlite.db
""""""

import sys, os, re
import unittest
from decimal import Decimal
from datetime import datetime, date, time
from os.path import join, getsize, dirname, abspath
from testutils import *

_TESTSTR = '0123456789-abcdefghijklmnopqrstuvwxyz-'

def _generate_test_string(length):
    """"""
    Returns a string of `length` characters, constructed by repeating _TESTSTR as necessary.

    To enhance performance, there are 3 ways data is read, based on the length of the value, so most data types are
    tested with 3 lengths.  This function helps us generate the test data.

    We use a recognizable data set instead of a single character to make it less likely that ""overlap"" errors will
    be hidden and to help us manually identify where a break occurs.
    """"""
    if length <= len(_TESTSTR):
        return _TESTSTR[:length]

    c = (length + len(_TESTSTR)-1) // len(_TESTSTR)
    v = _TESTSTR * c
    return v[:length]

class SqliteTestCase(unittest.TestCase):

    SMALL_FENCEPOST_SIZES = [ 0, 1, 255, 256, 510, 511, 512, 1023, 1024, 2047, 2048, 4000 ]
    LARGE_FENCEPOST_SIZES = [ 4095, 4096, 4097, 10 * 1024, 20 * 1024 ]

    STR_FENCEPOSTS = [ _generate_test_string(size) for size in SMALL_FENCEPOST_SIZES ]
    BYTE_FENCEPOSTS    = [ bytes(s, 'ascii') for s in STR_FENCEPOSTS ]
    IMAGE_FENCEPOSTS   = BYTE_FENCEPOSTS + [ bytes(_generate_test_string(size), 'ascii') for size in LARGE_FENCEPOST_SIZES ]

    def __init__(self, method_name, connection_string):
        unittest.TestCase.__init__(self, method_name)
        self.connection_string = connection_string

    def setUp(self):
        self.cnxn   = pyodbc.connect(self.connection_string)
        self.cursor = self.cnxn.cursor()

        for i in range(3):
            try:
                self.cursor.execute(""drop table t%d"" % i)
                self.cnxn.commit()
            except:
                pass

        self.cnxn.rollback()

    def tearDown(self):
        try:
            self.cursor.close()
            self.cnxn.close()
        except:
            # If we've already closed the cursor or connection, exceptions are thrown.
            pass

    def test_multiple_bindings(self):
        ""More than one bind and select on a cursor""
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t1 values (?)"", 2)
        self.cursor.execute(""insert into t1 values (?)"", 3)
        for i in range(3):
            self.cursor.execute(""select n from t1 where n < ?"", 10)
            self.cursor.execute(""select n from t1 where n < 3"")
        

    def test_different_bindings(self):
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""create table t2(d datetime)"")
        self.cursor.execute(""insert into t1 values (?)"", 1)
        self.cursor.execute(""insert into t2 values (?)"", datetime.now())

    def test_drivers(self):
        p = pyodbc.drivers()
        self.assertTrue(isinstance(p, list))

    def test_datasources(self):
        p = pyodbc.dataSources()
        self.assertTrue(isinstance(p, dict))

    def test_getinfo_string(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CATALOG_NAME_SEPARATOR)
        self.assertTrue(isinstance(value, str))

    def test_getinfo_bool(self):
        value = self.cnxn.getinfo(pyodbc.SQL_ACCESSIBLE_TABLES)
        self.assertTrue(isinstance(value, bool))

    def test_getinfo_int(self):
        value = self.cnxn.getinfo(pyodbc.SQL_DEFAULT_TXN_ISOLATION)
        self.assertTrue(isinstance(value, int))

    def test_getinfo_smallint(self):
        value = self.cnxn.getinfo(pyodbc.SQL_CONCAT_NULL_BEHAVIOR)
        self.assertTrue(isinstance(value, int))

    def _test_strtype(self, sqltype, value, colsize=None):
        """"""
        The implementation for string, Unicode, and binary tests.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)

        # Reported by Andy Hochhaus in the pyodbc group: In 2.1.7 and earlier, a hardcoded length of 255 was used to
        # determine whether a parameter was bound as a SQL_VARCHAR or SQL_LONGVARCHAR.  Apparently SQL Server chokes if
        # we bind as a SQL_LONGVARCHAR and the target column size is 8000 or less, which is considers just SQL_VARCHAR.
        # This means binding a 256 character value would cause problems if compared with a VARCHAR column under
        # 8001. We now use SQLGetTypeInfo to determine the time to switch.
        #
        # [42000] [Microsoft][SQL Server Native Client 10.0][SQL Server]The data types varchar and text are incompatible in the equal to operator.

        self.cursor.execute(""select * from t1 where s=?"", value)


    def _test_strliketype(self, sqltype, value, colsize=None):
        """"""
        The implementation for text, image, ntext, and binary.

        These types do not support comparison operators.
        """"""
        assert colsize is None or (value is None or colsize >= len(value))

        if colsize:
            sql = ""create table t1(s %s(%s))"" % (sqltype, colsize)
        else:
            sql = ""create table t1(s %s)"" % sqltype

        self.cursor.execute(sql)
        self.cursor.execute(""insert into t1 values(?)"", value)
        v = self.cursor.execute(""select * from t1"").fetchone()[0]
        self.assertEqual(type(v), type(value))

        if value is not None:
            self.assertEqual(len(v), len(value))

        self.assertEqual(v, value)

    #
    # text
    #

    def test_text_null(self):
        self._test_strtype('text', None, 100)

    # Generate a test for each fencepost size: test_text_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('text', value, len(value))
        return t
    for value in STR_FENCEPOSTS:
        locals()['test_text_%s' % len(value)] = _maketest(value)

    def test_text_upperlatin(self):
        self._test_strtype('varchar', '')

    #
    # blob
    #

    def test_null_blob(self):
        self._test_strtype('blob', None, 100)
     
    def test_large_null_blob(self):
        # Bug 1575064
        self._test_strtype('blob', None, 4000)

    # Generate a test for each fencepost size: test_unicode_0, etc.
    def _maketest(value):
        def t(self):
            self._test_strtype('blob', value, len(value))
        return t
    for value in BYTE_FENCEPOSTS:
        locals()['test_blob_%s' % len(value)] = _maketest(value)

    def test_subquery_params(self):
        """"""Ensure parameter markers work in a subquery""""""
        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        row = self.cursor.execute(""""""
                                  select x.id
                                  from (
                                    select id
                                    from t1
                                    where s = ?
                                      and id between ? and ?
                                   ) x
                                   """""", 'test', 1, 10).fetchone()
        self.assertNotEqual(row, None)
        self.assertEqual(row[0], 1)

    def _exec(self):
        self.cursor.execute(self.sql)
        
    def test_close_cnxn(self):
        """"""Make sure using a Cursor after closing its connection doesn't crash.""""""

        self.cursor.execute(""create table t1(id integer, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (?,?)"", 1, 'test')
        self.cursor.execute(""select * from t1"")

        self.cnxn.close()
        
        # Now that the connection is closed, we expect an exception.  (If the code attempts to use
        # the HSTMT, we'll get an access violation instead.)
        self.sql = ""select * from t1""
        self.assertRaises(pyodbc.ProgrammingError, self._exec)

    def test_negative_row_index(self):
        self.cursor.execute(""create table t1(s varchar(20))"")
        self.cursor.execute(""insert into t1 values(?)"", ""1"")
        row = self.cursor.execute(""select * from t1"").fetchone()
        self.assertEqual(row[0], ""1"")
        self.assertEqual(row[-1], ""1"")

    def test_version(self):
        self.assertEqual(3, len(pyodbc.version.split('.'))) # 1.3.1 etc.

    #
    # ints and floats
    #

    def test_int(self):
        value = 1234
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_int(self):
        value = -1
        self.cursor.execute(""create table t1(n int)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_bigint(self):
        input = 3000000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_negative_bigint(self):
        # Issue 186: BIGINT problem on 32-bit architeture
        input = -430000000
        self.cursor.execute(""create table t1(d bigint)"")
        self.cursor.execute(""insert into t1 values (?)"", input)
        result = self.cursor.execute(""select d from t1"").fetchone()[0]
        self.assertEqual(result, input)

    def test_float(self):
        value = 1234.567
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(result, value)

    def test_negative_float(self):
        value = -200
        self.cursor.execute(""create table t1(n float)"")
        self.cursor.execute(""insert into t1 values (?)"", value)
        result  = self.cursor.execute(""select n from t1"").fetchone()[0]
        self.assertEqual(value, result)

    #
    # rowcount
    #

    # Note: SQLRowCount does not define what the driver must return after a select statement
    # and says that its value should not be relied upon.  The sqliteodbc driver is hardcoded to
    # return 0 so I've deleted the test.

    def test_rowcount_delete(self):
        self.assertEqual(self.cursor.rowcount, -1)
        self.cursor.execute(""create table t1(i int)"")
        count = 4
        for i in range(count):
            self.cursor.execute(""insert into t1 values (?)"", i)
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, count)

    def test_rowcount_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.  On the other hand, we could hardcode a
        zero return value.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        self.cursor.execute(""delete from t1"")
        self.assertEqual(self.cursor.rowcount, 0)

    # In the 2.0.x branch, Cursor.execute sometimes returned the cursor and sometimes the rowcount.  This proved very
    # confusing when things went wrong and added very little value even when things went right since users could always
    # use: cursor.execute(""..."").rowcount

    def test_retcursor_delete(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_nodata(self):
        """"""
        This represents a different code path than a delete that deleted something.

        The return value is SQL_NO_DATA and code after it was causing an error.  We could use SQL_NO_DATA to step over
        the code that errors out and drop down to the same SQLRowCount code.
        """"""
        self.cursor.execute(""create table t1(i int)"")
        # This is a different code path internally.
        v = self.cursor.execute(""delete from t1"")
        self.assertEqual(v, self.cursor)

    def test_retcursor_select(self):
        self.cursor.execute(""create table t1(i int)"")
        self.cursor.execute(""insert into t1 values (1)"")
        v = self.cursor.execute(""select * from t1"")
        self.assertEqual(v, self.cursor)

    #
    # misc
    #

    def test_lower_case(self):
        ""Ensure pyodbc.lowercase forces returned column names to lowercase.""

        # Has to be set before creating the cursor, so we must recreate self.cursor.

        pyodbc.lowercase = True
        self.cursor = self.cnxn.cursor()

        self.cursor.execute(""create table t1(Abc int, dEf int)"")
        self.cursor.execute(""select * from t1"")

        names = [ t[0] for t in self.cursor.description ]
        names.sort()

        self.assertEqual(names, [ ""abc"", ""def"" ])

        # Put it back so other tests don't fail.
        pyodbc.lowercase = False
        
    def test_row_description(self):
        """"""
        Ensure Cursor.description is accessible as Row.cursor_description.
        """"""
        self.cursor = self.cnxn.cursor()
        self.cursor.execute(""create table t1(a int, b char(3))"")
        self.cnxn.commit()
        self.cursor.execute(""insert into t1 values(1, 'abc')"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        self.assertEqual(self.cursor.description, row.cursor_description)
        

    def test_executemany(self):
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (i, str(i)) for i in range(1, 6) ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])


    def test_executemany_one(self):
        ""Pass executemany a single sequence""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, ""test"") ]

        self.cursor.executemany(""insert into t1(a, b) values (?,?)"", params)

        count = self.cursor.execute(""select count(*) from t1"").fetchone()[0]
        self.assertEqual(count, len(params))

        self.cursor.execute(""select a, b from t1 order by a"")
        rows = self.cursor.fetchall()
        self.assertEqual(count, len(rows))

        for param, row in zip(params, rows):
            self.assertEqual(param[0], row[0])
            self.assertEqual(param[1], row[1])
        

    def test_executemany_failure(self):
        """"""
        Ensure that an exception is raised if one query in an executemany fails.
        """"""
        self.cursor.execute(""create table t1(a int, b varchar(10))"")

        params = [ (1, 'good'),
                   ('error', 'not an int'),
                   (3, 'good') ]
        
        self.assertRaises(pyodbc.Error, self.cursor.executemany, ""insert into t1(a, b) value (?, ?)"", params)

        
    def test_row_slicing(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = row[:]
        self.assertTrue(result is row)

        result = row[:-1]
        self.assertEqual(result, (1,2,3))

        result = row[0:4]
        self.assertTrue(result is row)


    def test_row_repr(self):
        self.cursor.execute(""create table t1(a int, b int, c int, d int)"");
        self.cursor.execute(""insert into t1 values(1,2,3,4)"")

        row = self.cursor.execute(""select * from t1"").fetchone()

        result = str(row)
        self.assertEqual(result, ""(1, 2, 3, 4)"")

        result = str(row[:-1])
        self.assertEqual(result, ""(1, 2, 3)"")

        result = str(row[:1])
        self.assertEqual(result, ""(1,)"")


    def test_view_select(self):
        # Reported in forum: Can't select from a view?  I think I do this a lot, but another test never hurts.

        # Create a table (t1) with 3 rows and a view (t2) into it.
        self.cursor.execute(""create table t1(c1 int identity(1, 1), c2 varchar(50))"")
        for i in range(3):
            self.cursor.execute(""insert into t1(c2) values (?)"", ""string%s"" % i)
        self.cursor.execute(""create view t2 as select * from t1"")

        # Select from the view
        self.cursor.execute(""select * from t2"")
        rows = self.cursor.fetchall()
        self.assertTrue(rows is not None)
        self.assertTrue(len(rows) == 3)

    def test_autocommit(self):
        self.assertEqual(self.cnxn.autocommit, False)

        othercnxn = pyodbc.connect(self.connection_string, autocommit=True)
        self.assertEqual(othercnxn.autocommit, True)

        othercnxn.autocommit = False
        self.assertEqual(othercnxn.autocommit, False)

    def test_skip(self):
        # Insert 1, 2, and 3.  Fetch 1, skip 2, fetch 3.

        self.cursor.execute(""create table t1(id int)"");
        for i in range(1, 5):
            self.cursor.execute(""insert into t1 values(?)"", i)
        self.cursor.execute(""select id from t1 order by id"")
        self.assertEqual(self.cursor.fetchone()[0], 1)
        self.cursor.skip(2)
        self.assertEqual(self.cursor.fetchone()[0], 4)

    def test_sets_execute(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.execute(""insert into t1 (word) VALUES (?)"", [words])

        self.assertRaises(pyodbc.ProgrammingError, f)

    def test_sets_executemany(self):
        # Only lists and tuples are allowed.
        def f():
            self.cursor.execute(""create table t1 (word varchar (100))"")
            words = set (['a'])
            self.cursor.executemany(""insert into t1 (word) values (?)"", [words])
            
        self.assertRaises(TypeError, f)

    def test_row_execute(self):
        ""Ensure we can use a Row object as a parameter to execute""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")
        self.cursor.execute(""insert into t1 values (1, 'a')"")
        row = self.cursor.execute(""select n, s from t1"").fetchone()
        self.assertNotEqual(row, None)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.execute(""insert into t2 values (?, ?)"", row)
        
    def test_row_executemany(self):
        ""Ensure we can use a Row object as a parameter to executemany""
        self.cursor.execute(""create table t1(n int, s varchar(10))"")

        for i in range(3):
            self.cursor.execute(""insert into t1 values (?, ?)"", i, chr(ord('a')+i))

        rows = self.cursor.execute(""select n, s from t1"").fetchall()
        self.assertNotEqual(len(rows), 0)

        self.cursor.execute(""create table t2(n int, s varchar(10))"")
        self.cursor.executemany(""insert into t2 values (?, ?)"", rows)
        
    def test_description(self):
        ""Ensure cursor.description is correct""

        self.cursor.execute(""create table t1(n int, s text)"")
        self.cursor.execute(""insert into t1 values (1, 'abc')"")
        self.cursor.execute(""select * from t1"")

        # (I'm not sure the precision of an int is constant across different versions, bits, so I'm hand checking the
        # items I do know.

        # int
        t = self.cursor.description[0]
        self.assertEqual(t[0], 'n')
        self.assertEqual(t[1], int)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

        # text
        t = self.cursor.description[1]
        self.assertEqual(t[0], 's')
        self.assertEqual(t[1], str)
        self.assertEqual(t[5], 0)       # scale
        self.assertEqual(t[6], True)    # nullable

    def test_row_equal(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test')"")
        row1 = self.cursor.execute(""select n, s from t1"").fetchone()
        row2 = self.cursor.execute(""select n, s from t1"").fetchone()
        b = (row1 == row2)
        self.assertEqual(b, True)

    def test_row_gtlt(self):
        self.cursor.execute(""create table t1(n int, s varchar(20))"")
        self.cursor.execute(""insert into t1 values (1, 'test1')"")
        self.cursor.execute(""insert into t1 values (1, 'test2')"")
        rows = self.cursor.execute(""select n, s from t1 order by s"").fetchall()
        self.assertTrue(rows[0] < rows[1])
        self.assertTrue(rows[0] <= rows[1])
        self.assertTrue(rows[1] > rows[0])
        self.assertTrue(rows[1] >= rows[0])
        self.assertTrue(rows[0] != rows[1])

        rows = list(rows)
        rows.sort() # uses <
        
    def _test_context_manager(self):
        # TODO: This is failing, but it may be due to the design of sqlite.  I've disabled it
        # for now until I can research it some more.

        # WARNING: This isn't working right now.  We've set the driver's autocommit to ""off"",
        # but that doesn't automatically start a transaction.  I'm not familiar enough with the
        # internals of the driver to tell what is going on, but it looks like there is support
        # for the autocommit flag.
        #
        # I thought it might be a timing issue, like it not actually starting a txn until you
        # try to do something, but that doesn't seem to work either.  I'll leave this in to
        # remind us that it isn't working yet but we need to contact the SQLite ODBC driver
        # author for some guidance.

        with pyodbc.connect(self.connection_string) as cnxn:
            cursor = cnxn.cursor()
            cursor.execute(""begin"")
            cursor.execute(""create table t1(i int)"")
            cursor.execute('rollback')

        # The connection should be closed now.
        def test():
            cnxn.execute('rollback')
        self.assertRaises(pyodbc.Error, test)

    def test_untyped_none(self):
        # From issue 129
        value = self.cursor.execute(""select ?"", None).fetchone()[0]
        self.assertEqual(value, None)
        
    def test_large_update_nodata(self):
        self.cursor.execute('create table t1(a blob)')
        hundredkb = 'x'*100*1024
        self.cursor.execute('update t1 set a=? where 1=0', (hundredkb,))

    def test_no_fetch(self):
        # Issue 89 with FreeTDS: Multiple selects (or catalog functions that issue selects) without fetches seem to
        # confuse the driver.
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')
        self.cursor.execute('select 1')


def main():
    from optparse import OptionParser
    parser = OptionParser(usage=usage)
    parser.add_option(""-v"", ""--verbose"", default=0, action=""count"", help=""Increment test verbosity (can be used multiple times)"")
    parser.add_option(""-d"", ""--debug"", action=""store_true"", default=False, help=""Print debugging items"")
    parser.add_option(""-t"", ""--test"", help=""Run only the named test"")

    (options, args) = parser.parse_args()

    if len(args) > 1:
        parser.error('Only one argument is allowed.  Do you need quotes around the connection string?')

    if not args:
        connection_string = load_setup_connection_string('sqlitetests')

        if not connection_string:
            parser.print_help()
            raise SystemExit()
    else:
        connection_string = args[0]

    if options.verbose:
        cnxn = pyodbc.connect(connection_string)
        print_library_info(cnxn)
        cnxn.close()

    suite = load_tests(SqliteTestCase, options.test, connection_string)

    testRunner = unittest.TextTestRunner(verbosity=options.verbose)
    result = testRunner.run(suite)

    sys.exit(result.errors and 1 or 0)


if __name__ == '__main__':

    # Add the build directory to the path so we're testing the latest build, not the installed version.

    add_to_path()

    import pyodbc
    main()
/n/n/n/tests3/testutils.py/n/nimport os, sys, platform
from os.path import join, dirname, abspath, basename
import unittest

def add_to_path():
    """"""
    Prepends the build directory to the path so that newly built pyodbc libraries are used, allowing it to be tested
    without installing it.
    """"""
    # Put the build directory into the Python path so we pick up the version we just built.
    #
    # To make this cross platform, we'll search the directories until we find the .pyd file.

    import imp

    library_exts  = [ t[0] for t in imp.get_suffixes() if t[-1] == imp.C_EXTENSION ]
    library_names = [ 'pyodbc%s' % ext for ext in library_exts ]

    # Only go into directories that match our version number.

    dir_suffix = '-%s.%s' % (sys.version_info[0], sys.version_info[1])

    build = join(dirname(dirname(abspath(__file__))), 'build')

    for root, dirs, files in os.walk(build):
        for d in dirs[:]:
            if not d.endswith(dir_suffix):
                dirs.remove(d)

        for name in library_names:
            if name in files:
                sys.path.insert(0, root)
                return

    print('Did not find the pyodbc library in the build directory.  Will use an installed version.')


def print_library_info(cnxn):
    import pyodbc
    print('python:  %s' % sys.version)
    print('pyodbc:  %s %s' % (pyodbc.version, os.path.abspath(pyodbc.__file__)))
    print('odbc:    %s' % cnxn.getinfo(pyodbc.SQL_ODBC_VER))
    print('driver:  %s %s' % (cnxn.getinfo(pyodbc.SQL_DRIVER_NAME), cnxn.getinfo(pyodbc.SQL_DRIVER_VER)))
    print('         supports ODBC version %s' % cnxn.getinfo(pyodbc.SQL_DRIVER_ODBC_VER))
    print('os:      %s' % platform.system())
    print('unicode: Py_Unicode=%s SQLWCHAR=%s' % (pyodbc.UNICODE_SIZE, pyodbc.SQLWCHAR_SIZE))

    cursor = cnxn.cursor()
    for typename in ['VARCHAR', 'WVARCHAR', 'BINARY']:
        t = getattr(pyodbc, 'SQL_' + typename)
        cursor.getTypeInfo(t)
        row = cursor.fetchone()
        print('Max %s = %s' % (typename, row and row[2] or '(not supported)'))

    if platform.system() == 'Windows':
        print('         %s' % ' '.join([s for s in platform.win32_ver() if s]))



def load_tests(testclass, name, *args):
    """"""
    Returns a TestSuite for tests in `testclass`.

    name
      Optional test name if you only want to run 1 test.  If not provided all tests in `testclass` will be loaded.

    args
      Arguments for the test class constructor.  These will be passed after the test method name.
    """"""
    if name:
        if not name.startswith('test_'):
            name = 'test_%s' % name
        names = [ name ]

    else:
        names = [ method for method in dir(testclass) if method.startswith('test_') ]

    return unittest.TestSuite([ testclass(name, *args) for name in names ])


def load_setup_connection_string(section):
    """"""
    Attempts to read the default connection string from the setup.cfg file.

    If the file does not exist or if it exists but does not contain the connection string, None is returned.  If the
    file exists but cannot be parsed, an exception is raised.
    """"""
    from os.path import exists, join, dirname, splitext, basename
    from configparser import SafeConfigParser

    FILENAME = 'setup.cfg'
    KEY      = 'connection-string'

    path = join(dirname(dirname(abspath(__file__))), 'tmp', FILENAME)

    if exists(path):
        try:
            p = SafeConfigParser()
            p.read(path)
        except:
            raise SystemExit('Unable to parse %s: %s' % (path, sys.exc_info()[1]))

        if p.has_option(section, KEY):
            return p.get(section, KEY)

    return None
/n/n/n",1
118,118,7c665e556987f4e2c1a75e143a1e80ae066ad833,"impl.py/n/nfrom flask import request
import jwt
import re
import os
from base64 import b64encode, b64decode

import HybridRSA

# Cache server keys because they don't change during program operation
SERVER_JWT_PRIVATE_KEY = open('resources/jwt_key', 'rb').read()
SERVER_JWT_PUBLIC_KEY  = open('resources/jwt_key.pub', 'rb').read()

# HTTP response codes
CREATED = 201
BAD_REQUEST = 400
NOT_FOUND = 404

KEY_SIZE_LIMIT = int(1e4)

def getKey(client):
	""""""Retrieves the specified key for the specified client
	Returns an error if the key doesn't exist, obviously.
	""""""
	global SERVER_JWT_PRIVATE_KEY
	global BAD_REQUEST

	validateClient(client)
	client_pub_key = loadClientRSAKey(client)
	token_data = decodeRequestToken(request.data, client_pub_key)
	validateKeyName(token_data['key'])

	# Keys may only have alpha-numeric names
	try:
		requested_key = open('keys/%s/%s.key' % (client, token_data['key']), 'r').read()
	except KeyError:
		raise FoxlockError(BAD_REQUEST, ""JWT did not contain attribute 'key'"")
	except IOError:
		raise FoxlockError(BAD_REQUEST, ""Key '%s' not found"" % token_data['key'])

	# Key is returned in a JWT encrypted with the client's public key, so only they can decrypt it
	keytoken = packJWT({'key': requested_key}, SERVER_JWT_PRIVATE_KEY, client_pub_key)

	return keytoken

def addKey(client):
	""""""Adds a new key with the specified name and contents.
	Returns an error if a key with the specified name already exists.
	""""""
	global BAD_REQUEST
	global CREATED

	validateClient(client)
	client_pub_key = loadClientRSAKey(client)
	token_data = decodeRequestToken(request.data, client_pub_key)
	validateNewKeyData(token_data)
	validateKeyName(token_data['name'])

	# Use 'x' flag so we can throw an error if a key with this name already exists
	try:
		with open('keys/%s/%s.key' % (client, token_data['name']), 'x') as f:
			f.write(token_data['key'])
	except FileExistsError:
		raise FoxlockError(BAD_REQUEST, ""Key '%s' already exists"" % token_data['name'])

	return 'Key successfully created', CREATED

def updateKey(client):
	""""""Updates the contents of a key that already exists in our system.
	Returns an error if the specified key doesn't exist for the specified user.
	""""""
	global NOT_FOUND
	global CREATED

	validateClient(client)
	client_pub_key = loadClientRSAKey(client)
	token_data = decodeRequestToken(request.data, client_pub_key)
	validateNewKeyData(token_data)
	validateKeyName(token_data['name'])

	# Use 'w' flag to replace existing key file with the new key data
	if os.path.isfile('keys/%s/%s.key' % (client, token_data['name'])):
		with open('keys/%s/%s.key' % (client, token_data['name']), 'w') as f:
			f.write(token_data['key'])
	else:
		raise FoxlockError(NOT_FOUND, ""Key '%s' not found"" % token_data['name'])

	return 'Key successfully updated', CREATED

def deleteKey(client):
	""""""Deletes the specified key.
	Returns an error if the key doesn't exist
	""""""
	global NOT_FOUND

	validateClient(client)
	client_pub_key = loadClientRSAKey(client)
	token_data = decodeRequestToken(request.data, client_pub_key)
	validateKeyName(token_data['key'])

	try:
		os.remove('keys/%s/%s.key' % (client, token_data['key']))
	except FileNotFoundError:
		raise FoxlockError(NOT_FOUND, ""Key '%s' not found"" % token_data['key'])

	return ""Key '%s' successfully deleted"" % token_data['key']

def getJwtKey():
	""""""Simply returns the RSA public key the server uses to sign JWTs""""""
	global SERVER_JWT_PUBLIC_KEY
	return SERVER_JWT_PUBLIC_KEY

##################
# Helper Functions
##################

def validateClient(client):
	global BAD_REQUEST
	global NOT_FOUND

	if re.search('[^a-zA-Z0-9]', client):
		raise FoxlockError(BAD_REQUEST, 'Client may only have alpha-numeric names')
	if not os.path.isdir('keys/' + client):
		raise FoxlockError(NOT_FOUND, ""Client '%s' not found"" % client)

def loadClientRSAKey(client):
	""""""Load a client's RSA public key, if they exist in our system""""""
	global NOT_FOUND

	try:
		key = open('keys/%s/key_rsa.pub' % client, 'rb').read()
	except IOError:
		raise FoxlockError(NOT_FOUND, 'Client RSA public key not found')
	return key

def decodeRequestToken(token, client_pub_key):
	""""""Decrypts / decodes the request's JWT with the server's JWT private key.""""""
	global SERVER_JWT_PRIVATE_KEY
	global BAD_REQUEST

	if token is None:
		raise FoxlockError(BAD_REQUEST, 'No token found in request')

	# Most JWT errors will come from clients signing JWTs with the wrong key
	try:
		decoded_token_data = unpackJWT(token, client_pub_key, SERVER_JWT_PRIVATE_KEY)
	except jwt.exceptions.DecodeError:
		raise FoxlockError(BAD_REQUEST, 'Failed to decode JWT. Are you using the right key?')
	except jwt.exceptions.InvalidTokenError:
		raise FoxlockError(BAD_REQUEST, 'JWT is malformed')
	return decoded_token_data

def validateNewKeyData(data):
	""""""Verify the request key name and key data are valid""""""
	global BAD_REQUEST
	global KEY_SIZE_LIMIT

	try:
		data['name']
		data['key']
	except KeyError:
		raise FoxlockError(BAD_REQUEST, ""Token data must include 'key' and 'name'"")

	if len(data['key']) > KEY_SIZE_LIMIT:
		raise FoxlockError(BAD_REQUEST, 'Key size limited to %s bytes' % KEY_SIZE_LIMIT)

def validateKeyName(name):
	""""""Ensures key names are alpha-numeric""""""
	global BAD_REQUEST

	if re.search('[^a-zA-Z0-9]', name):
		raise FoxlockError(BAD_REQUEST, 'Invalid key name')

# We've switched JWT libraries 3 times in one week, so let's just wrap JWT functionality

def packJWT(data, sign_key, encrypt_key):
	""""""Encrypt/encode in a compact statement""""""
	token = jwt.encode(data, sign_key, algorithm='RS256')
	enc_token = HybridRSA.encrypt(token, encrypt_key)
	return b64encode(enc_token).decode('utf-8')

def unpackJWT(encoded_jwt, verify_key, decrypt_key):
	""""""Decode/Decrypt in a compact statement""""""
	decoded = b64decode(encoded_jwt)
	dec_token = HybridRSA.decrypt(decoded, decrypt_key)
	token = jwt.decode(dec_token, verify_key, algorithm='RS256')
	return token


class FoxlockError(Exception):
	""""""This gives us a general purpose error Flask can catch""""""
	def __init__(self, code, message):
		self.message = message
		self.code = code

/n/n/n",0
119,119,7c665e556987f4e2c1a75e143a1e80ae066ad833,"/impl.py/n/nfrom flask import request
import jwt
import re
import os
from base64 import b64encode, b64decode

import HybridRSA

# Cache server keys because they don't change during program operation
SERVER_JWT_PRIVATE_KEY = open('resources/jwt_key', 'rb').read()
SERVER_JWT_PUBLIC_KEY  = open('resources/jwt_key.pub', 'rb').read()

# HTTP response codes
CREATED = 201
BAD_REQUEST = 400
NOT_FOUND = 404

KEY_SIZE_LIMIT = int(1e4)

def getKey(client):
	""""""Retrieves the specified key for the specified client
	Returns an error if the key doesn't exist, obviously.
	""""""
	global SERVER_JWT_PRIVATE_KEY
	global BAD_REQUEST

	validateClient(client)

	client_pub_key = loadClientRSAKey(client)
	token_data = decodeRequestToken(request.data, client_pub_key)

	# Keys may only have alpha-numeric names
	try:
		if re.search('[^a-zA-Z0-9]', token_data['key']):
			raise FoxlockError(BAD_REQUEST, 'Invalid key requested')
		requested_key = open('keys/%s/%s.key' % (client, token_data['key']), 'r').read()
	except KeyError:
		raise FoxlockError(BAD_REQUEST, ""JWT did not contain attribute 'key'"")
	except IOError:
		raise FoxlockError(BAD_REQUEST, ""Key '%s' not found"" % token_data['key'])

	# Key is returned in a JWT encrypted with the client's public key, so only they can decrypt it
	keytoken = packJWT({'key': requested_key}, SERVER_JWT_PRIVATE_KEY, client_pub_key)

	return keytoken

def addKey(client):
	""""""Adds a new key with the specified name and contents.
	Returns an error if a key with the specified name already exists.
	""""""
	global BAD_REQUEST
	global CREATED

	validateClient(client)

	client_pub_key = loadClientRSAKey(client)
	token_data = decodeRequestToken(request.data, client_pub_key)
	validateNewKeyData(token_data)

	# Use 'x' flag so we can throw an error if a key with this name already exists
	try:
		with open('keys/%s/%s.key' % (client, token_data['name']), 'x') as f:
			f.write(token_data['key'])
	except FileExistsError:
		raise FoxlockError(BAD_REQUEST, ""Key '%s' already exists"" % token_data['name'])

	return 'Key successfully created', CREATED

def updateKey(client):
	""""""Updates the contents of a key that already exists in our system.
	Returns an error if the specified key doesn't exist for the specified user.
	""""""
	global NOT_FOUND
	global CREATED

	validateClient(client)

	client_pub_key = loadClientRSAKey(client)
	token_data = decodeRequestToken(request.data, client_pub_key)
	validateNewKeyData(token_data)

	# Use 'w' flag to replace existing key file with the new key data
	if os.path.isfile('keys/%s/%s.key' % (client, token_data['name'])):
		with open('keys/%s/%s.key' % (client, token_data['name']), 'w') as f:
			f.write(token_data['key'])
	else:
		raise FoxlockError(NOT_FOUND, ""Key '%s' not found"" % token_data['name'])

	return 'Key successfully updated', CREATED

def deleteKey(client):
	""""""Deletes the specified key.
	Returns an error if the key doesn't exist
	""""""
	global BAD_REQUEST
	global NOT_FOUND

	validateClient(client)

	client_pub_key = loadClientRSAKey(client)
	token_data = decodeRequestToken(request.data, client_pub_key)

	if re.search('[^a-zA-Z0-9]', token_data['key']):
		raise FoxlockError(BAD_REQUEST, 'Invalid key requested')

	try:
		os.remove('keys/%s/%s.key' % (client, token_data['key']))
	except FileNotFoundError:
		raise FoxlockError(NOT_FOUND, ""Key '%s' not found"" % token_data['key'])

	return ""Key '%s' successfully deleted"" % token_data['key']

def getJwtKey():
	""""""Simply returns the RSA public key the server uses to sign JWTs""""""
	global SERVER_JWT_PUBLIC_KEY
	return SERVER_JWT_PUBLIC_KEY

##################
# Helper Functions
##################

def validateClient(client):
	global BAD_REQUEST
	global NOT_FOUND

	if re.search('[^a-zA-Z0-9]', client):
		raise FoxlockError(BAD_REQUEST, 'Client may only have alpha-numeric names')
	if not os.path.isdir('keys/' + client):
		raise FoxlockError(NOT_FOUND, ""Client '%s' not found"" % client)

def loadClientRSAKey(client):
	""""""Load a client's RSA public key, if they exist in our system""""""
	global NOT_FOUND

	try:
		key = open('keys/%s/key_rsa.pub' % client, 'rb').read()
	except IOError:
		raise FoxlockError(NOT_FOUND, 'Client RSA public key not found')
	return key

def decodeRequestToken(token, client_pub_key):
	""""""Decrypts / decodes the request's JWT with the server's JWT private key.""""""
	global SERVER_JWT_PRIVATE_KEY
	global BAD_REQUEST

	if token is None:
		raise FoxlockError(BAD_REQUEST, 'No token found in request')

	# Most JWT errors will come from clients signing JWTs with the wrong key
	try:
		decoded_token_data = unpackJWT(token, client_pub_key, SERVER_JWT_PRIVATE_KEY)
	except jwt.exceptions.DecodeError:
		raise FoxlockError(BAD_REQUEST, 'Failed to decode JWT. Are you using the right key?')
	except jwt.exceptions.InvalidTokenError:
		raise FoxlockError(BAD_REQUEST, 'JWT is malformed')
	return decoded_token_data

def validateNewKeyData(data):
	""""""Verify the request key name and key data are valid""""""
	global BAD_REQUEST
	global KEY_SIZE_LIMIT

	try:
		data['name']
		data['key']
	except KeyError:
		raise FoxlockError(BAD_REQUEST, ""Token data must include 'key' and 'name'"")

	if len(data['key']) > KEY_SIZE_LIMIT:
		raise FoxlockError(BAD_REQUEST, 'Key size limited to %s bytes' % KEY_SIZE_LIMIT)


# We've switched JWT libraries 3 times in one week, so let's just wrap JWT functionality

def packJWT(data, sign_key, encrypt_key):
	""""""Encrypt/encode in a compact statement""""""
	token = jwt.encode(data, sign_key, algorithm='RS256')
	enc_token = HybridRSA.encrypt(token, encrypt_key)
	return b64encode(enc_token).decode('utf-8')

def unpackJWT(encoded_jwt, verify_key, decrypt_key):
	""""""Decode/Decrypt in a compact statement""""""
	decoded = b64decode(encoded_jwt)
	dec_token = HybridRSA.decrypt(decoded, decrypt_key)
	token = jwt.decode(dec_token, verify_key, algorithm='RS256')
	return token


class FoxlockError(Exception):
	""""""This gives us a general purpose error Flask can catch""""""
	def __init__(self, code, message):
		self.message = message
		self.code = code

/n/n/n",1
124,124,9725ca3005f492cb5c10e7ba0cce29ed76f57daa,"navloc.py/n/n"""""" Navigation and localization
    
Author:
    Annaleah Ernst
""""""
import tf
import rospy
import numpy as np

from copy import deepcopy
from geometry_msgs.msg import Pose, Point, Quaternion
from math import sin, cos, pi
from time import time

from localization import Localization
from logger import Logger
from navigation import Navigation

class NavLoc(Navigation, Localization):
    """""" Navigate and localize on a map.
    
    Args:
        point_ids (set): Unique identifier for each waypoint in the graph.
        locations (dict): Point_ids mapped to tuples representing locations.
        neighbors (dict): Point_ids mapped to lists containing other point_ids representing 
            the current node's neighbors.
        landmark_ids (set): Unique identifier for each landmark in the graph.
        landmark_positions (dict): Map AprilTag landmark ids to their absolute
            position on the floorplan.
        landmark_angles (dict): Map AprilTag landmark ids to their absolute
            position on the floorplan. This specifies the angle of rotation of the landmark in the 
            xy plane; ie, how much has its horizontal vector deviated from the x axis.
        jerky (bool, optional): If true, robot will not decelerate, but stop abruptly.
            Defaults to False.
        walking_speed (float, optional): Percentage of maximum speed, magnitude between 0 and 1.
                Values with magnitude greater than 1 will be ignored.
    
    Attributes:
        tags (geometry_msgs.msg.PoseStamped dict): A dict of all the AprilTags currently in view in 
            their raw form.
        tags_odom (geometry_msgs.msg.PoseStamped dict): Same as above, but in the odometry frame.
        floorplan (FloorPlan): The map of the current space as a floorplan.
        p (geometry_msgs.msg.Point): The position of the robot in the ekf odometry frame according to
            the robot_pose_ekf package.
        q (geometry_msgs.msg.Quaternion): The orientation of the robot in the ekf odometry frame
            according the the robot_pose_ekf package.
        angle (float): The angle (in radians) that the robot is from 0 in the ekf odometry frame. 
            Between -pi and pi
        map_pos (geometry_msgs.msg.Point): The position of the robot in the map frame.
        map_angle (float): The angle (in radians) of the robot in the map frame.
    """"""
    
    def __init__(self, point_ids, locations, neighbors, landmark_ids, landmark_positions, landmark_angles, jerky = False, walking_speed = 1):
        
        # create map position
        self.map_pos = Point()
        self.map_angle = 0
        
        # create a path variable so that we can navigate via waypoints
        self._path = None
    
        # initialize what we're inheriting from
        Localization.__init__(self, point_ids, locations, neighbors, landmark_ids, landmark_positions, landmark_angles)
        Navigation.__init__(self, jerky = jerky, walking_speed = walking_speed)

        self._logger = Logger(""NavLoc"")
    
        # give ourselves a second to see if there's a nearby AR tag
        timer = time()
        while time() - timer < 0.5:
            pass
    
    def _ekfCallback(self, data):
        """""" Process robot_pose_ekf data. """"""
        
        # get the ekf data
        Navigation._ekfCallback(self, data)
        
        # compute map data
        self.map_pos = self.transformPoint(self.p, ""odom"", ""map"")
        self.map_angle = self.transformAngle(self.angle, ""odom"", ""map"")
    
    def _handleObstacle(self, turn_delta):
        """""" Handle obstacle and reset path if necessary. """"""
        
        if Navigation._handleObstacle(self, turn_delta):
            self._path = None
            return True
            
        return False
    
    def goToOrientation(self, angle):
        """""" Go to orientation in the map frame. """"""
        return Navigation.goToOrientation(self, self.transformAngle(angle, ""map"", ""odom""))
    
    def takePathToDest(self, x, y):
        """""" Go the target pos via waypoints from the floorplan. 
        
        Args:
            x (float): The destination x coord in the map frame.
            y (float): The destination y coord in the map frame.
        """"""
        
        # we currently aren't on a mission, or we've been interrupted
        if self._path is None:
            self._path = self.floorplan.getShortestPath(self.map_pos, Point(x,y,0))
        
        # we've arrived a waypoint on our path to destination
        if self.goToPosition(self._path[0].x, self._path[0].y):
            self._logger.info(""Arrived at waypoint "" + str((self._path[0].x, self._path[0].y)) + "" (map position is "" +
                str((self.map_pos.x, self.map_pos.y)) + "")"")
            self._path.pop(0)
            
        # we've cleared out the traversal path, so we've reached our goal
        if self._path == []:
            self._path = None
            self._logger.debug(""no path!"")
            return True
        
        # we're still on our way to the destination
        return False
    
    def goToPosition(self, x, y):
        """""" Go to position x, y, in the map frame""""""
        transformed_point = self.transformPoint(Point(x, y, 0), ""map"", ""odom"")
        return Navigation.goToPosition(self, transformed_point.x, transformed_point.y)

    def csvLogArrival(self, test_name, x, y, folder = ""tests""):
        """""" Log the arrival of the robot at a waypoint. """"""
        
        self._logger.csv(test_name + ""_waypoints"", [""X_target"", ""Y_target"", ""X_map"", ""Y_map"", ""X_ekf"", ""Y_ekf""],
                    [x, y, self.map_pos.x, self.map_pos.y, self.p.x, self.p.y],
                    folder = folder)

    def csvLogMap(self, test_name, folder = ""tests""):
        """""" Log map position data. """"""
         
        self._logger.csv(test_name + ""_mappose"", [""X"", ""Y"", ""yaw""], [self.map_pos.x, self.map_pos.y, self.map_angle], folder = folder)

if __name__ == ""__main__"":
    import MD2
    from tester import Tester
    from math import pi
    
    class NavLocTest(Tester):
        """""" Run local navigation tests. """"""
        def __init__(self):
            Tester.__init__(self, ""NavLoc"")
            
            # flag for a jerky stop
            self.jerky = False
            
            # I'm a bit concerned about robot safety if we don't slow things down,
            # but I'm also worried it won't be an accurate test if we change the speed
            self.walking_speed = 1 # if not self.jerky else .5
            
            # linear test
            self.reached_goal = False
            
            # square test
            self.reached_corner = [False, False, False, False]
            self.cc_square = [(0,0), (1,0), (1,1), (0,1)]
            self.c_square = [(0,0), (1,0), (1,-1), (0, -1)]
            self.corner_counter = 0
        
            # set up the logger output file
            self.test_name = ""path""
        
            # set up points on map
            point_ids = MD2.points
            locations = MD2.locations
            neighbors = MD2.neighbors
        
            # set map location of the landmark
            landmarks = MD2.landmarks
            landmark_positions = MD2.landmark_pos
            landmark_orientations = MD2.landmark_orient
        
            self.navloc = NavLoc(point_ids, locations, neighbors,landmarks, landmark_positions, landmark_orientations, jerky = self.jerky, walking_speed = self.walking_speed)
        
            # set the destinations
            self.destination = [self.navloc.floorplan.graph['T'].location, self.navloc.floorplan.graph['R'].location]

        def main(self):
            """""" The test currently being run. """"""
            #self.testCCsquare(1)
            #self.testCsquare(1)
            #self.testLine(1.5)
            self.testPath()
            self.navloc.csvLogEKF(self.test_name)
            self.navloc.csvLogMap(self.test_name)
            self.navloc.csvLogTransform(self.test_name)
            self.navloc.csvLogRawTags(self.test_name)
            self.navloc.csvLogOdomTags(self.test_name)
            #self.navloc.takePathToDest(1.5,0)

        def initFile(self, filename):
            """""" Write the first line of our outgoing file (variable names). """"""
            self.test_name = filename + (""jerky"" if self.jerky else ""smooth"")
        
        def logArrival(self, name, x, y):
            self.logger.info(""Arrived at "" + str((x, y)) + "" (map position is "" +
                str((self.navloc.map_pos.x, self.navloc.map_pos.y)) + "")"")
            self.navloc.csvLogArrival(self.test_name, x, y)
            
        def testPath(self):
            """""" Attempt to navigation between two offices""""""
            if not self.reached_corner[0]:
                self.reached_corner[0] = self.navloc.takePathToDest(self.destination[0].x, self.destination[0].y)
                if self.reached_corner[0]:
                    self.logArrival(""office 1"", self.destination[0].x, self.destination[0].y)
                    
            elif self.navloc.takePathToDest(self.destination[1].x, self.destination[1].y):
                self.reached_corner[0] = False
                self.logArrival(""office 2"", self.destination[1].x, self.destination[1].y)
        
        def testLine(self, length):
            """""" Test behavior with a simple line. 
            
            Args:
                length (float): Length of the desired line (in meters).
            """"""
            if self.test_name is None:
                self.initFile(""line"")
            
            if not self.reached_corner[0]:
                self.reached_corner[0] = self.navloc.goToPosition(0, 0)
                if self.reached_corner[0]:
                    self.logArrival(""home"", 0, 0)
        
            elif self.navloc.goToPosition(length, 0):
                self.reached_corner[0] = False
                self.logArrival(""endpoint"", length, 0)
    
        def testCCsquare(self, length):
            """""" Test a counter clockwise square. 
            
            Args:
                length (float): Length of the desired line (in meters).
            """"""
            if self.test_name is None:
                self.initFile(""counterclockwise"")
            
            self.testSquare(length, self.cc_square)
        
        def testCsquare(self, length):
            """""" Test a clockwise square. 
            
            Args:
                length (float): Length of the desired line (in meters).
            """"""
            if self.test_name is None:
                self.initFile(""clockwise"")
            
            self.testSquare(length, self.c_square)
    
        def testSquare(self, length, corners):
            """""" Test behavior with a simple square. 
            
            Args:
                length (float): Length of the sides of the square (in meters).
            """"""
            # test a simple square
            if not self.reached_corner[self.corner_counter]:
                self.reached_corner[self.corner_counter] = self.navloc.goToPosition(corners[self.corner_counter][0]*length, corners[self.corner_counter][1]*length)
            
            else:
                self.logArrival(""corner "" + str(self.corner_counter), corners[self.corner_counter][0]*length, corners[self.corner_counter][1]*length)
                if self.corner_counter == len(self.reached_corner) - 1:
                    self.reached_corner = [False] * len(self.reached_corner)
                self.corner_counter = (self.corner_counter + 1) % len(self.reached_corner)
    
        def shutdown(self):
            """""" Kill all behavioral test processes. """"""
            self.navloc.shutdown(self.rate)
            Tester.shutdown(self)
        
    NavLocTest().run()/n/n/n",0
125,125,9725ca3005f492cb5c10e7ba0cce29ed76f57daa,"/navloc.py/n/n"""""" Navigation and localization
    
Author:
    Annaleah Ernst
""""""
import tf
import rospy
import numpy as np

from copy import deepcopy
from geometry_msgs.msg import Pose, Point, Quaternion
from math import sin, cos, pi
from time import time

from localization import Localization
from logger import Logger
from navigation import Navigation

class NavLoc(Navigation, Localization):
    """""" Navigate and localize on a map.
    
    Args:
        point_ids (set): Unique identifier for each waypoint in the graph.
        locations (dict): Point_ids mapped to tuples representing locations.
        neighbors (dict): Point_ids mapped to lists containing other point_ids representing 
            the current node's neighbors.
        landmark_ids (set): Unique identifier for each landmark in the graph.
        landmark_positions (dict): Map AprilTag landmark ids to their absolute
            position on the floorplan.
        landmark_angles (dict): Map AprilTag landmark ids to their absolute
            position on the floorplan. This specifies the angle of rotation of the landmark in the 
            xy plane; ie, how much has its horizontal vector deviated from the x axis.
        jerky (bool, optional): If true, robot will not decelerate, but stop abruptly.
            Defaults to False.
        walking_speed (float, optional): Percentage of maximum speed, magnitude between 0 and 1.
                Values with magnitude greater than 1 will be ignored.
    
    Attributes:
        tags (geometry_msgs.msg.PoseStamped dict): A dict of all the AprilTags currently in view in 
            their raw form.
        tags_odom (geometry_msgs.msg.PoseStamped dict): Same as above, but in the odometry frame.
        floorplan (FloorPlan): The map of the current space as a floorplan.
        p (geometry_msgs.msg.Point): The position of the robot in the ekf odometry frame according to
            the robot_pose_ekf package.
        q (geometry_msgs.msg.Quaternion): The orientation of the robot in the ekf odometry frame
            according the the robot_pose_ekf package.
        angle (float): The angle (in radians) that the robot is from 0 in the ekf odometry frame. 
            Between -pi and pi
        map_pos (geometry_msgs.msg.Point): The position of the robot in the map frame.
        map_angle (float): The angle (in radians) of the robot in the map frame.
    """"""
    
    def __init__(self, point_ids, locations, neighbors, landmark_ids, landmark_positions, landmark_angles, jerky = False, walking_speed = 1):
        
        # create map position
        self.map_pos = Point()
        self.map_angle = 0
        
        # create a path variable so that we can navigate via waypoints
        self._path = None
    
        # initialize what we're inheriting from
        Localization.__init__(self, point_ids, locations, neighbors, landmark_ids, landmark_positions, landmark_angles)
        Navigation.__init__(self, jerky = jerky, walking_speed = walking_speed)

        self._logger = Logger(""NavLoc"")
    
        # give ourselves a second to see if there's a nearby AR tag
        timer = time()
        while time() - timer < 0.5:
            pass
    
    def _ekfCallback(self, data):
        """""" Process robot_pose_ekf data. """"""
        
        # get the ekf data
        Navigation._ekfCallback(self, data)
        
        # compute map data
        self.map_pos = self.transformPoint(self.p, ""odom"", ""map"")
        self.map_angle = self.transformAngle(self.angle, ""odom"", ""map"")
    
    def _handleObstacle(self, turn_delta):
        """""" Handle obstacle and reset path if necessary. """"""
        
        if Navigation._handleObstacle(self, turn_delta):
            self._path = None
            return True
            
        return False
    
    def goToOrientation(self, angle):
        """""" Go to orientation in the map frame. """"""
        return Navigation.goToOrientation(self, self.transformAngle(angle, ""map"", ""odom""))
    
    def takePathToDest(self, x, y):
        """""" Go the target pos via waypoints from the floorplan. 
        
        Args:
            x (float): The destination x coord in the map frame.
            y (float): The destination y coord in the map frame.
        """"""
        
        # we currently aren't on a mission, or we've been interrupted
        if self._path is None:
            self._path = self.floorplan.getShortestPath(self.map_pos, Point(x,y,0))
        
        # we've arrived a waypoint on our path to destination
        if self.goToPosition(self._path[0].x, self._path[0].y):
            self._logger.info(""Arrived at waypoint "" + str((self._path[0].x, self._path[0].y)) + "" (map position is "" +
                str((self.map_pos.x, self.map_pos.y)) + "")"")
            self._path.pop(0)
            
        # we've cleared out the traversal path, so we've reached our goal
        if not self._path:
            self._path = None
            self._logger.debug(""no path!"")
            return True
        
        # we're still on our way to the destination
        return False
    
    def goToPosition(self, x, y):
        """""" Go to position x, y, in the map frame""""""
        transformed_point = self.transformPoint(Point(x, y, 0), ""map"", ""odom"")
        return Navigation.goToPosition(self, transformed_point.x, transformed_point.y)

    def csvLogArrival(self, test_name, x, y, folder = ""tests""):
        """""" Log the arrival of the robot at a waypoint. """"""
        
        self._logger.csv(test_name + ""_waypoints"", [""X_target"", ""Y_target"", ""X_map"", ""Y_map"", ""X_ekf"", ""Y_ekf""],
                    [x, y, self.map_pos.x, self.map_pos.y, self.p.x, self.p.y],
                    folder = folder)

    def csvLogMap(self, test_name, folder = ""tests""):
        """""" Log map position data. """"""
         
        self._logger.csv(test_name + ""_mappose"", [""X"", ""Y"", ""yaw""], [self.map_pos.x, self.map_pos.y, self.map_angle], folder = folder)

if __name__ == ""__main__"":
    import MD2
    from tester import Tester
    from math import pi
    
    class NavLocTest(Tester):
        """""" Run local navigation tests. """"""
        def __init__(self):
            Tester.__init__(self, ""NavLoc"")
            
            # flag for a jerky stop
            self.jerky = False
            
            # I'm a bit concerned about robot safety if we don't slow things down,
            # but I'm also worried it won't be an accurate test if we change the speed
            self.walking_speed = 1 # if not self.jerky else .5
            
            # linear test
            self.reached_goal = False
            
            # square test
            self.reached_corner = [False, False, False, False]
            self.cc_square = [(0,0), (1,0), (1,1), (0,1)]
            self.c_square = [(0,0), (1,0), (1,-1), (0, -1)]
            self.corner_counter = 0
        
            # set up the logger output file
            self.test_name = ""path""
        
            # set up points on map
            point_ids = MD2.points
            locations = MD2.locations
            neighbors = MD2.neighbors
        
            # set map location of the landmark
            landmarks = MD2.landmarks
            landmark_positions = MD2.landmark_pos
            landmark_orientations = MD2.landmark_orient
        
            self.navloc = NavLoc(point_ids, locations, neighbors,landmarks, landmark_positions, landmark_orientations, jerky = self.jerky, walking_speed = self.walking_speed)
        
            # set the destinations
            self.destination = [self.navloc.floorplan.graph['T'].location, self.navloc.floorplan.graph['R'].location]

        def main(self):
            """""" The test currently being run. """"""
            #self.testCCsquare(1)
            #self.testCsquare(1)
            #self.testLine(1.5)
            self.testPath()
            self.navloc.csvLogEKF(self.test_name)
            self.navloc.csvLogMap(self.test_name)
            self.navloc.csvLogTransform(self.test_name)
            self.navloc.csvLogRawTags(self.test_name)
            self.navloc.csvLogOdomTags(self.test_name)
            #self.navloc.takePathToDest(1.5,0)

        def initFile(self, filename):
            """""" Write the first line of our outgoing file (variable names). """"""
            self.test_name = filename + (""jerky"" if self.jerky else ""smooth"")
        
        def logArrival(self, name, x, y):
            self.logger.info(""Arrived at "" + str((x, y)) + "" (map position is "" +
                str((self.navloc.map_pos.x, self.navloc.map_pos.y)) + "")"")
            self.navloc.csvLogArrival(self.test_name, x, y)
            
        def testPath(self):
            """""" Attempt to navigation between two offices""""""
            if not self.reached_corner[0]:
                self.reached_corner[0] = self.navloc.takePathToDest(self.destination[0].x, self.destination[0].y)
                if self.reached_corner[0]:
                    self.logArrival(""office 1"", self.destination[0].x, self.destination[0].y)
                    
            elif self.navloc.takePathToDest(self.destination[1].x, self.destination[1].y):
                self.reached_corner[0] = False
                self.logArrival(""office 2"", self.destination[1].x, self.destination[1].y)
        
        def testLine(self, length):
            """""" Test behavior with a simple line. 
            
            Args:
                length (float): Length of the desired line (in meters).
            """"""
            if self.test_name is None:
                self.initFile(""line"")
            
            if not self.reached_corner[0]:
                self.reached_corner[0] = self.navloc.goToPosition(0, 0)
                if self.reached_corner[0]:
                    self.logArrival(""home"", 0, 0)
        
            elif self.navloc.goToPosition(length, 0):
                self.reached_corner[0] = False
                self.logArrival(""endpoint"", length, 0)
    
        def testCCsquare(self, length):
            """""" Test a counter clockwise square. 
            
            Args:
                length (float): Length of the desired line (in meters).
            """"""
            if self.test_name is None:
                self.initFile(""counterclockwise"")
            
            self.testSquare(length, self.cc_square)
        
        def testCsquare(self, length):
            """""" Test a clockwise square. 
            
            Args:
                length (float): Length of the desired line (in meters).
            """"""
            if self.test_name is None:
                self.initFile(""clockwise"")
            
            self.testSquare(length, self.c_square)
    
        def testSquare(self, length, corners):
            """""" Test behavior with a simple square. 
            
            Args:
                length (float): Length of the sides of the square (in meters).
            """"""
            # test a simple square
            if not self.reached_corner[self.corner_counter]:
                self.reached_corner[self.corner_counter] = self.navloc.goToPosition(corners[self.corner_counter][0]*length, corners[self.corner_counter][1]*length)
            
            else:
                self.logArrival(""corner "" + str(self.corner_counter), corners[self.corner_counter][0]*length, corners[self.corner_counter][1]*length)
                if self.corner_counter == len(self.reached_corner) - 1:
                    self.reached_corner = [False] * len(self.reached_corner)
                self.corner_counter = (self.corner_counter + 1) % len(self.reached_corner)
    
        def shutdown(self):
            """""" Kill all behavioral test processes. """"""
            self.navloc.shutdown(self.rate)
            Tester.shutdown(self)
        
    NavLocTest().run()/n/n/n",1
