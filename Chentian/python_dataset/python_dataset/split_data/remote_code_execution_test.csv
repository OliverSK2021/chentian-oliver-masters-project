,Unnamed: 0,id,code,label
16,16,e09ec28786aa04bb7a6459fec6294bbb9368671a,"pep8speaks/helpers.py/n/n# -*- coding: utf-8 -*-

import base64
import collections
import datetime
import hmac
import json
import os
import re
import subprocess
import time

import psycopg2
import requests
import unidiff
import yaml
from flask import abort


def update_users(repository):
    """"""Update users of the integration in the database""""""
    if os.environ.get(""OVER_HEROKU"", False) is not False:
        # Check if repository exists in database
        query = r""INSERT INTO Users (repository, created_at) VALUES ('{}', now());"" \
                """".format(repository)

        try:
            cursor.execute(query)
            conn.commit()
        except psycopg2.IntegrityError:  # If already exists
            conn.rollback()


def follow_user(user):
    """"""Follow the user of the service""""""
    headers = {
        ""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""],
        ""Content-Length"": ""0"",
    }
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    url = ""https://api.github.com/user/following/{}""
    url = url.format(user)
    r = requests.put(url, headers=headers, auth=auth)


def update_dict(base, head):
    """"""
    Recursively merge or update dict-like objects.
    >>> update({'k1': 1}, {'k1': {'k2': {'k3': 3}}})

    Source : http://stackoverflow.com/a/32357112/4698026
    """"""
    for key, value in head.items():
        if key in base:
            if isinstance(base, collections.Mapping):
                if isinstance(value, collections.Mapping):
                    base[key] = update_dict(base.get(key, {}), value)
                else:
                    base[key] = head[key]
            else:
                base = {key: head[key]}
    return base


def match_webhook_secret(request):
    """"""Match the webhook secret sent from GitHub""""""
    if os.environ.get(""OVER_HEROKU"", False) is not False:
        header_signature = request.headers.get('X-Hub-Signature')
        if header_signature is None:
            abort(403)
        sha_name, signature = header_signature.split('=')
        if sha_name != 'sha1':
            abort(501)
        mac = hmac.new(os.environ[""GITHUB_PAYLOAD_SECRET""].encode(), msg=request.data,
                       digestmod=""sha1"")
        if not hmac.compare_digest(str(mac.hexdigest()), str(signature)):
            abort(403)
    return True


def check_pythonic_pr(data):
    """"""
    Return True if the PR contains at least one Python file
    """"""
    files = list(get_files_involved_in_pr(data).keys())
    pythonic = False
    for file in files:
        if file[-3:] == '.py':
            pythonic = True
            break

    return pythonic


def get_config(data):
    """"""
    Get .pep8speaks.yml config file from the repository and return
    the config dictionary
    """"""

    # Default configuration parameters
    config = {
        ""message"": {
            ""opened"": {
                ""header"": """",
                ""footer"": """"
            },
            ""updated"": {
                ""header"": """",
                ""footer"": """"
            }
        },
        ""scanner"": {""diff_only"": False},
        ""pycodestyle"": {
            ""ignore"": [],
            ""max-line-length"": 79,
            ""count"": False,
            ""first"": False,
            ""show-pep8"": False,
            ""filename"": [],
            ""exclude"": [],
            ""select"": [],
            ""show-source"": False,
            ""statistics"": False,
            ""hang-closing"": False,
        },
        ""no_blank_comment"": True,
        ""only_mention_files_with_errors"": True,
    }

    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])

    # Configuration file
    url = ""https://raw.githubusercontent.com/{}/{}/.pep8speaks.yml""

    url = url.format(data[""repository""], data[""after_commit_hash""])
    r = requests.get(url, headers=headers, auth=auth)
    if r.status_code == 200:
        try:
            new_config = yaml.load(r.text)
            # overloading the default configuration with the one specified
            config = update_dict(config, new_config)
        except yaml.YAMLError:  # Bad YAML file
            pass

    # Create pycodestyle command line arguments
    arguments = []
    confs = config[""pycodestyle""]
    for key, value in confs.items():
        if value:  # Non empty
            if isinstance(value, int):
                if isinstance(value, bool):
                    arguments.append(""--{}"".format(key))
                else:
                    arguments.append(""--{}={}"".format(key, value))
            elif isinstance(value, list):
                arguments.append(""--{}={}"".format(key, ','.join(value)))
    config[""pycodestyle_cmd_config""] = ' {arguments}'.format(arguments=' '.join(arguments))

    # pycodestyle is case-sensitive
    config[""pycodestyle""][""ignore""] = [e.upper() for e in list(config[""pycodestyle""][""ignore""])]

    return config


def get_files_involved_in_pr(data):
    """"""
    Return a list of file names modified/added in the PR
    """"""
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    diff_headers = headers.copy()
    diff_headers[""Accept""] = ""application/vnd.github.VERSION.diff""
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    repository = data[""repository""]
    after_commit_hash = data[""after_commit_hash""]
    author = data[""author""]
    diff_url = ""https://api.github.com/repos/{}/pulls/{}""
    diff_url = diff_url.format(repository, str(data[""pr_number""]))
    r = requests.get(diff_url, headers=diff_headers, auth=auth)
    patch = unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding)

    files = {}

    for patchset in patch:
        file = patchset.target_file[1:]
        files[file] = []
        for hunk in patchset:
            for line in hunk.target_lines():
                if line.is_added:
                    files[file].append(line.target_line_no)

    return files


def get_python_files_involved_in_pr(data):
    files = get_files_involved_in_pr(data)
    for file in list(files.keys()):
        if file[-3:] != "".py"":
            del files[file]

    return files


def run_pycodestyle(data, config):
    """"""
    Run pycodestyle script on the files and update the data
    dictionary
    """"""
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    repository = data[""repository""]
    after_commit_hash = data[""after_commit_hash""]
    author = data[""author""]

    # Run pycodestyle
    ## All the python files with additions
    # A dictionary with filename paired with list of new line numbers
    py_files = get_python_files_involved_in_pr(data)

    for file in py_files:
        filename = file[1:]
        url = ""https://raw.githubusercontent.com/{}/{}/{}""
        url = url.format(repository, after_commit_hash, file)
        r = requests.get(url, headers=headers, auth=auth)
        with open(""file_to_check.py"", 'w+', encoding=r.encoding) as file_to_check:
            file_to_check.write(r.text)

        # Use the command line here
        cmd = 'pycodestyle {config[pycodestyle_cmd_config]} file_to_check.py'.format(
            config=config)
        proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
        stdout, _ = proc.communicate()
        data[""extra_results""][filename] = stdout.decode(r.encoding).splitlines()

        # Put only relevant errors in the data[""results""] dictionary
        data[""results""][filename] = []
        for error in list(data[""extra_results""][filename]):
            if re.search(""^file_to_check.py:\d+:\d+:\s[WE]\d+\s.*"", error):
                data[""results""][filename].append(error.replace(""file_to_check.py"", filename))
                data[""extra_results""][filename].remove(error)

        ## Remove errors in case of diff_only = True
        ## which are caused in the whole file
        for error in list(data[""results""][filename]):
            if config[""scanner""][""diff_only""]:
                if not int(error.split("":"")[1]) in py_files[file]:
                    data[""results""][filename].remove(error)

        ## Store the link to the file
        url = ""https://github.com/{}/blob/{}{}""
        data[filename + ""_link""] = url.format(repository, after_commit_hash, file)
        os.remove(""file_to_check.py"")


def prepare_comment(request, data, config):
    """"""Construct the string of comment i.e. its header, body and footer""""""
    author = data[""author""]
    # Write the comment body
    ## Header
    comment_header = """"
    if request.json[""action""] == ""opened"":
        if config[""message""][""opened""][""header""] == """":
            comment_header = ""Hello @"" + author + ""! Thanks for submitting the PR.\n\n""
        else:
            comment_header = config[""message""][""opened""][""header""] + ""\n\n""
    elif request.json[""action""] in [""synchronize"", ""reopened""]:
        if config[""message""][""updated""][""header""] == """":
            comment_header = ""Hello @"" + author + ""! Thanks for updating the PR.\n\n""
        else:
            comment_header = config[""message""][""updated""][""header""] + ""\n\n""

    ## Body
    ERROR = False  # Set to True when any pep8 error exists
    comment_body = []
    for file, issues in data[""results""].items():
        if len(issues) == 0:
            if not config[""only_mention_files_with_errors""]:
                comment_body.append(
                    "" - There are no PEP8 issues in the""
                    "" file [`{0}`]({1}) !"".format(file, data[file + ""_link""]))
        else:
            ERROR = True
            comment_body.append(
                "" - In the file [`{0}`]({1}), following ""
                ""are the PEP8 issues :\n"".format(file, data[file + ""_link""]))
            for issue in issues:
                ## Replace filename with L
                error_string = issue.replace(file + "":"", ""Line "")

                ## Link error codes to search query
                error_string_list = error_string.split("" "")
                code = error_string_list[2]
                code_url = ""https://duckduckgo.com/?q=pep8%20{0}"".format(code)
                error_string_list[2] = ""[{0}]({1})"".format(code, code_url)

                ## Link line numbers in the file
                line, col = error_string_list[1][:-1].split("":"")
                line_url = data[file + ""_link""] + ""#L"" + line
                error_string_list[1] = ""[{0}:{1}]({2}):"".format(line, col, line_url)
                error_string = "" "".join(error_string_list)
                error_string = error_string.replace(""Line ["", ""[Line "")
                comment_body.append(""\n> {0}"".format(error_string))

        comment_body.append(""\n\n"")
        if len(data[""extra_results""][file]) > 0:
            comment_body.append("" - Complete extra results for this file :\n\n"")
            comment_body.append(""> "" + """".join(data[""extra_results""][file]))
            comment_body.append(""---\n\n"")

    if config[""only_mention_files_with_errors""] and not ERROR:
        comment_body.append(""Cheers ! There are no PEP8 issues in this Pull Request. :beers: "")


    comment_body = ''.join(comment_body)


    ## Footer
    comment_footer = []
    if request.json[""action""] == ""opened"":
        comment_footer.append(config[""message""][""opened""][""footer""])
    elif request.json[""action""] in [""synchronize"", ""reopened""]:
        comment_footer.append(config[""message""][""updated""][""footer""])

    comment_footer = ''.join(comment_footer)

    return comment_header, comment_body, comment_footer, ERROR


def comment_permission_check(data, comment):
    """"""Check for quite and resume status or duplicate comments""""""
    PERMITTED_TO_COMMENT = True
    repository = data[""repository""]
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])

    # Check for duplicate comment
    url = ""https://api.github.com/repos/{}/issues/{}/comments""
    url = url.format(repository, str(data[""pr_number""]))
    comments = requests.get(url, headers=headers, auth=auth).json()

    # Get the last comment by the bot
    last_comment = """"
    for old_comment in reversed(comments):
        if old_comment[""user""][""id""] == 24736507:  # ID of @pep8speaks
            last_comment = old_comment[""body""]
            break

    """"""
    # Disabling this because only a single comment is made per PR
    text1 = ''.join(BeautifulSoup(markdown(comment)).findAll(text=True))
    text2 = ''.join(BeautifulSoup(markdown(last_comment)).findAll(text=True))
    if text1 == text2.replace(""submitting"", ""updating""):
        PERMITTED_TO_COMMENT = False
    """"""

    # Check if the bot is asked to keep quiet
    for old_comment in reversed(comments):
        if '@pep8speaks' in old_comment['body']:
            if 'resume' in old_comment['body'].lower():
                break
            elif 'quiet' in old_comment['body'].lower():
                PERMITTED_TO_COMMENT = False


    return PERMITTED_TO_COMMENT


def create_or_update_comment(data, comment):
    comment_mode = None
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])

    query = ""https://api.github.com/repos/{}/issues/{}/comments""
    query = query.format(data[""repository""], str(data[""pr_number""]))
    comments = requests.get(query, headers=headers, auth=auth).json()

    # Get the last comment id by the bot
    last_comment_id = None
    for old_comment in comments:
        if old_comment[""user""][""id""] == 24736507:  # ID of @pep8speaks
            last_comment_id = old_comment[""id""]
            break

    if last_comment_id is None:  # Create a new comment
        response = requests.post(query, json={""body"": comment}, headers=headers, auth=auth)
        data[""comment_response""] = response.json()
    else:  # Update the last comment
        utc_time = datetime.datetime.utcnow()
        time_now = utc_time.strftime(""%B %d, %Y at %H:%M Hours UTC"")
        comment += ""\n\n##### Comment last updated on {}""
        comment = comment.format(time_now)

        query = ""https://api.github.com/repos/{}/issues/comments/{}""
        query = query.format(data[""repository""], str(last_comment_id))
        response = requests.patch(query, json={""body"": comment}, headers=headers, auth=auth)


def autopep8(data, config):
    # Run pycodestyle

    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    r = requests.get(data[""diff_url""], headers=headers, auth=auth)
    ## All the python files with additions
    patch = unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding)

    # A dictionary with filename paired with list of new line numbers
    py_files = {}

    for patchset in patch:
        if patchset.target_file[-3:] == '.py':
            py_file = patchset.target_file[1:]
            py_files[py_file] = []
            for hunk in patchset:
                for line in hunk.target_lines():
                    if line.is_added:
                        py_files[py_file].append(line.target_line_no)

    # Ignore errors and warnings specified in the config file
    to_ignore = "","".join(config[""pycodestyle""][""ignore""])
    arg_to_ignore = """"
    if len(to_ignore) > 0:
        arg_to_ignore = ""--ignore "" + to_ignore

    for file in py_files:
        filename = file[1:]
        url = ""https://raw.githubusercontent.com/{}/{}/{}""
        url = url.format(data[""repository""], data[""sha""], file)
        r = requests.get(url, headers=headers, auth=auth)
        with open(""file_to_fix.py"", 'w+', encoding=r.encoding) as file_to_fix:
            file_to_fix.write(r.text)

        cmd = 'autopep8 file_to_fix.py --diff {arg_to_ignore}'.format(
            arg_to_ignore=arg_to_ignore)
        proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
        stdout, _ = proc.communicate()
        data[""diff""][filename] = stdout.decode(r.encoding)

        # Fix the errors
        data[""diff""][filename] = data[""diff""][filename].replace(""file_to_check.py"", filename)
        data[""diff""][filename] = data[""diff""][filename].replace(""\\"", ""\\\\"")

        ## Store the link to the file
        url = ""https://github.com/{}/blob/{}{}""
        data[filename + ""_link""] = url.format(data[""repository""], data[""sha""], file)
        os.remove(""file_to_fix.py"")


def create_gist(data, config):
    """"""Create gists for diff files""""""
    REQUEST_JSON = {}
    REQUEST_JSON[""public""] = True
    REQUEST_JSON[""files""] = {}
    REQUEST_JSON[""description""] = ""In response to @{0}'s comment : {1}"".format(
        data[""reviewer""], data[""review_url""])

    for file, diffs in data[""diff""].items():
        if len(diffs) != 0:
            REQUEST_JSON[""files""][file.split(""/"")[-1] + "".diff""] = {
                ""content"": diffs
            }

    # Call github api to create the gist
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    url = ""https://api.github.com/gists""
    res = requests.post(url, json=REQUEST_JSON, headers=headers, auth=auth).json()
    data[""gist_response""] = res
    data[""gist_url""] = res[""html_url""]


def delete_if_forked(data):
    FORKED = False
    url = ""https://api.github.com/user/repos""
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    r = requests.get(url, headers=headers, auth=auth)
    for repo in r.json():
        if repo[""description""]:
            if data[""target_repo_fullname""] in repo[""description""]:
                FORKED = True
                r = requests.delete(""https://api.github.com/repos/""
                                ""{}"".format(repo[""full_name""]),
                                headers=headers, auth=auth)
    return FORKED


def fork_for_pr(data):
    FORKED = False
    url = ""https://api.github.com/repos/{}/forks""
    url = url.format(data[""target_repo_fullname""])
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    r = requests.post(url, headers=headers, auth=auth)
    if r.status_code == 202:
        data[""fork_fullname""] = r.json()[""full_name""]
        FORKED = True
    else:
        data[""error""] = ""Unable to fork""
    return FORKED


def update_fork_desc(data):
    # Check if forked (takes time)
    url = ""https://api.github.com/repos/{}"".format(data[""fork_fullname""])
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    r = requests.get(url, headers=headers, auth=auth)
    ATTEMPT = 0
    while(r.status_code != 200):
        time.sleep(5)
        r = requests.get(url, headers=headers, auth=auth)
        ATTEMPT += 1
        if ATTEMPT > 10:
            data[""error""] = ""Forking is taking more than usual time""
            break

    full_name = data[""target_repo_fullname""]
    author, name = full_name.split(""/"")
    request_json = {
        ""name"": name,
        ""description"": ""Forked from @{}'s {}"".format(author, full_name)
    }
    r = requests.patch(url, data=json.dumps(request_json), headers=headers, auth=auth)
    if r.status_code != 200:
        data[""error""] = ""Could not update description of the fork""


def create_new_branch(data):
    url = ""https://api.github.com/repos/{}/git/refs/heads""
    url = url.format(data[""fork_fullname""])
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    sha = None
    r = requests.get(url, headers=headers, auth=auth)
    for ref in r.json():
        if ref[""ref""].split(""/"")[-1] == data[""target_repo_branch""]:
            sha = ref[""object""][""sha""]

    url = ""https://api.github.com/repos/{}/git/refs""
    url = url.format(data[""fork_fullname""])
    data[""new_branch""] = ""{}-pep8-patch"".format(data[""target_repo_branch""])
    request_json = {
        ""ref"": ""refs/heads/{}"".format(data[""new_branch""]),
        ""sha"": sha,
    }
    r = requests.post(url, json=request_json, headers=headers, auth=auth)

    if r.status_code != 200:
        data[""error""] = ""Could not create new branch in the fork""


def autopep8ify(data, config):
    # Run pycodestyle
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    r = requests.get(data[""diff_url""], headers=headers, auth=auth)

    ## All the python files with additions
    patch = unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding)

    # A dictionary with filename paired with list of new line numbers
    py_files = {}

    for patchset in patch:
        if patchset.target_file[-3:] == '.py':
            py_file = patchset.target_file[1:]
            py_files[py_file] = []
            for hunk in patchset:
                for line in hunk.target_lines():
                    if line.is_added:
                        py_files[py_file].append(line.target_line_no)

    # Ignore errors and warnings specified in the config file
    to_ignore = "","".join(config[""pycodestyle""][""ignore""])
    arg_to_ignore = """"
    if len(to_ignore) > 0:
        arg_to_ignore = ""--ignore "" + to_ignore

    for file in py_files:
        filename = file[1:]
        url = ""https://raw.githubusercontent.com/{}/{}/{}""
        url = url.format(data[""repository""], data[""sha""], file)
        r = requests.get(url, headers=headers, auth=auth)
        with open(""file_to_fix.py"", 'w+', encoding=r.encoding) as file_to_fix:
            file_to_fix.write(r.text)

        cmd = 'autopep8 file_to_fix.py {arg_to_ignore}'.format(
            arg_to_ignore=arg_to_ignore)
        proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
        stdout, _ = proc.communicate()
        data[""results""][filename] = stdout.decode(r.encoding)

        os.remove(""file_to_fix.py"")


def commit(data):
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])

    fullname = data.get(""fork_fullname"")

    for file, new_file in data[""results""].items():
        url = ""https://api.github.com/repos/{}/contents/{}""
        url = url.format(fullname, file)
        params = {""ref"": data[""new_branch""]}
        r = requests.get(url, params=params, headers=headers, auth=auth)
        sha_blob = r.json().get(""sha"")
        params[""path""] = file
        content_code = base64.b64encode(new_file.encode()).decode(""utf-8"")
        request_json = {
            ""path"": file,
            ""message"": ""Fix pep8 errors in {}"".format(file),
            ""content"": content_code,
            ""sha"": sha_blob,
            ""branch"": data.get(""new_branch""),
        }
        r = requests.put(url, json=request_json, headers=headers, auth=auth)


def create_pr(data):
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    url = ""https://api.github.com/repos/{}/pulls""
    url = url.format(data[""target_repo_fullname""])
    request_json = {
        ""title"": ""Fix pep8 errors"",
        ""head"": ""pep8speaks:{}"".format(data[""new_branch""]),
        ""base"": data[""target_repo_branch""],
        ""body"": ""The changes are suggested by autopep8"",
    }
    r = requests.post(url, json=request_json, headers=headers, auth=auth)
    if r.status_code == 201:
        data[""pr_url""] = r.json()[""html_url""]
    else:
        data[""error""] = ""Pull request could not be created""
/n/n/n",0
17,17,e09ec28786aa04bb7a6459fec6294bbb9368671a,"/pep8speaks/helpers.py/n/n# -*- coding: utf-8 -*-

import base64
import collections
import datetime
import hmac
import json
import os
import re
import subprocess
import time

import psycopg2
import requests
import unidiff
import yaml
from flask import abort


def update_users(repository):
    """"""Update users of the integration in the database""""""
    if os.environ.get(""OVER_HEROKU"", False) is not False:
        # Check if repository exists in database
        query = r""INSERT INTO Users (repository, created_at) VALUES ('{}', now());"" \
                """".format(repository)

        try:
            cursor.execute(query)
            conn.commit()
        except psycopg2.IntegrityError:  # If already exists
            conn.rollback()


def follow_user(user):
    """"""Follow the user of the service""""""
    headers = {
        ""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""],
        ""Content-Length"": ""0"",
    }
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    url = ""https://api.github.com/user/following/{}""
    url = url.format(user)
    r = requests.put(url, headers=headers, auth=auth)


def update_dict(base, head):
    """"""
    Recursively merge or update dict-like objects.
    >>> update({'k1': 1}, {'k1': {'k2': {'k3': 3}}})

    Source : http://stackoverflow.com/a/32357112/4698026
    """"""
    for key, value in head.items():
        if isinstance(base, collections.Mapping):
            if isinstance(value, collections.Mapping):
                base[key] = update_dict(base.get(key, {}), value)
            else:
                base[key] = head[key]
        else:
            base = {key: head[key]}
    return base


def match_webhook_secret(request):
    """"""Match the webhook secret sent from GitHub""""""
    if os.environ.get(""OVER_HEROKU"", False) is not False:
        header_signature = request.headers.get('X-Hub-Signature')
        if header_signature is None:
            abort(403)
        sha_name, signature = header_signature.split('=')
        if sha_name != 'sha1':
            abort(501)
        mac = hmac.new(os.environ[""GITHUB_PAYLOAD_SECRET""].encode(), msg=request.data,
                       digestmod=""sha1"")
        if not hmac.compare_digest(str(mac.hexdigest()), str(signature)):
            abort(403)
    return True


def check_pythonic_pr(data):
    """"""
    Return True if the PR contains at least one Python file
    """"""
    files = list(get_files_involved_in_pr(data).keys())
    pythonic = False
    for file in files:
        if file[-3:] == '.py':
            pythonic = True
            break

    return pythonic


def get_config(data):
    """"""
    Get .pep8speaks.yml config file from the repository and return
    the config dictionary
    """"""

    # Default configuration parameters
    config = {
        ""message"": {
            ""opened"": {
                ""header"": """",
                ""footer"": """"
            },
            ""updated"": {
                ""header"": """",
                ""footer"": """"
            }
        },
        ""scanner"": {""diff_only"": False},
        ""pycodestyle"": {
            ""ignore"": [],
            ""max-line-length"": 79,
            ""count"": False,
            ""first"": False,
            ""show-pep8"": False,
            ""filename"": [],
            ""exclude"": [],
            ""select"": [],
            ""show-source"": False,
            ""statistics"": False,
            ""hang-closing"": False,
        },
        ""no_blank_comment"": True,
        ""only_mention_files_with_errors"": True,
    }

    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])

    # Configuration file
    url = ""https://raw.githubusercontent.com/{}/{}/.pep8speaks.yml""

    url = url.format(data[""repository""], data[""after_commit_hash""])
    r = requests.get(url, headers=headers, auth=auth)
    if r.status_code == 200:
        try:
            new_config = yaml.load(r.text)
            # overloading the default configuration with the one specified
            config = update_dict(config, new_config)
        except yaml.YAMLError:  # Bad YAML file
            pass

    # Create pycodestyle command line arguments
    arguments = []
    confs = config[""pycodestyle""]
    for key, value in confs.items():
        if value:  # Non empty
            if isinstance(value, int):
                if isinstance(value, bool):
                    arguments.append(""--{}"".format(key))
                else:
                    arguments.append(""--{}={}"".format(key, value))
            elif isinstance(value, list):
                arguments.append(""--{}={}"".format(key, ','.join(value)))
    config[""pycodestyle_cmd_config""] = ' {arguments}'.format(arguments=' '.join(arguments))

    # pycodestyle is case-sensitive
    config[""pycodestyle""][""ignore""] = [e.upper() for e in list(config[""pycodestyle""][""ignore""])]

    return config


def get_files_involved_in_pr(data):
    """"""
    Return a list of file names modified/added in the PR
    """"""
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    diff_headers = headers.copy()
    diff_headers[""Accept""] = ""application/vnd.github.VERSION.diff""
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    repository = data[""repository""]
    after_commit_hash = data[""after_commit_hash""]
    author = data[""author""]
    diff_url = ""https://api.github.com/repos/{}/pulls/{}""
    diff_url = diff_url.format(repository, str(data[""pr_number""]))
    r = requests.get(diff_url, headers=diff_headers, auth=auth)
    patch = unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding)

    files = {}

    for patchset in patch:
        file = patchset.target_file[1:]
        files[file] = []
        for hunk in patchset:
            for line in hunk.target_lines():
                if line.is_added:
                    files[file].append(line.target_line_no)

    return files


def get_python_files_involved_in_pr(data):
    files = get_files_involved_in_pr(data)
    for file in list(files.keys()):
        if file[-3:] != "".py"":
            del files[file]

    return files


def run_pycodestyle(data, config):
    """"""
    Run pycodestyle script on the files and update the data
    dictionary
    """"""
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    repository = data[""repository""]
    after_commit_hash = data[""after_commit_hash""]
    author = data[""author""]

    # Run pycodestyle
    ## All the python files with additions
    # A dictionary with filename paired with list of new line numbers
    py_files = get_python_files_involved_in_pr(data)

    for file in py_files:
        filename = file[1:]
        url = ""https://raw.githubusercontent.com/{}/{}/{}""
        url = url.format(repository, after_commit_hash, file)
        r = requests.get(url, headers=headers, auth=auth)
        with open(""file_to_check.py"", 'w+', encoding=r.encoding) as file_to_check:
            file_to_check.write(r.text)

        # Use the command line here
        cmd = 'pycodestyle {config[pycodestyle_cmd_config]} file_to_check.py'.format(
            config=config)
        proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
        stdout, _ = proc.communicate()
        data[""extra_results""][filename] = stdout.decode(r.encoding).splitlines()

        # Put only relevant errors in the data[""results""] dictionary
        data[""results""][filename] = []
        for error in list(data[""extra_results""][filename]):
            if re.search(""^file_to_check.py:\d+:\d+:\s[WE]\d+\s.*"", error):
                data[""results""][filename].append(error.replace(""file_to_check.py"", filename))
                data[""extra_results""][filename].remove(error)

        ## Remove errors in case of diff_only = True
        ## which are caused in the whole file
        for error in list(data[""results""][filename]):
            if config[""scanner""][""diff_only""]:
                if not int(error.split("":"")[1]) in py_files[file]:
                    data[""results""][filename].remove(error)

        ## Store the link to the file
        url = ""https://github.com/{}/blob/{}{}""
        data[filename + ""_link""] = url.format(repository, after_commit_hash, file)
        os.remove(""file_to_check.py"")


def prepare_comment(request, data, config):
    """"""Construct the string of comment i.e. its header, body and footer""""""
    author = data[""author""]
    # Write the comment body
    ## Header
    comment_header = """"
    if request.json[""action""] == ""opened"":
        if config[""message""][""opened""][""header""] == """":
            comment_header = ""Hello @"" + author + ""! Thanks for submitting the PR.\n\n""
        else:
            comment_header = config[""message""][""opened""][""header""] + ""\n\n""
    elif request.json[""action""] in [""synchronize"", ""reopened""]:
        if config[""message""][""updated""][""header""] == """":
            comment_header = ""Hello @"" + author + ""! Thanks for updating the PR.\n\n""
        else:
            comment_header = config[""message""][""updated""][""header""] + ""\n\n""

    ## Body
    ERROR = False  # Set to True when any pep8 error exists
    comment_body = []
    for file, issues in data[""results""].items():
        if len(issues) == 0:
            if not config[""only_mention_files_with_errors""]:
                comment_body.append(
                    "" - There are no PEP8 issues in the""
                    "" file [`{0}`]({1}) !"".format(file, data[file + ""_link""]))
        else:
            ERROR = True
            comment_body.append(
                "" - In the file [`{0}`]({1}), following ""
                ""are the PEP8 issues :\n"".format(file, data[file + ""_link""]))
            for issue in issues:
                ## Replace filename with L
                error_string = issue.replace(file + "":"", ""Line "")

                ## Link error codes to search query
                error_string_list = error_string.split("" "")
                code = error_string_list[2]
                code_url = ""https://duckduckgo.com/?q=pep8%20{0}"".format(code)
                error_string_list[2] = ""[{0}]({1})"".format(code, code_url)

                ## Link line numbers in the file
                line, col = error_string_list[1][:-1].split("":"")
                line_url = data[file + ""_link""] + ""#L"" + line
                error_string_list[1] = ""[{0}:{1}]({2}):"".format(line, col, line_url)
                error_string = "" "".join(error_string_list)
                error_string = error_string.replace(""Line ["", ""[Line "")
                comment_body.append(""\n> {0}"".format(error_string))

        comment_body.append(""\n\n"")
        if len(data[""extra_results""][file]) > 0:
            comment_body.append("" - Complete extra results for this file :\n\n"")
            comment_body.append(""> "" + """".join(data[""extra_results""][file]))
            comment_body.append(""---\n\n"")

    if config[""only_mention_files_with_errors""] and not ERROR:
        comment_body.append(""Cheers ! There are no PEP8 issues in this Pull Request. :beers: "")


    comment_body = ''.join(comment_body)


    ## Footer
    comment_footer = []
    if request.json[""action""] == ""opened"":
        comment_footer.append(config[""message""][""opened""][""footer""])
    elif request.json[""action""] in [""synchronize"", ""reopened""]:
        comment_footer.append(config[""message""][""updated""][""footer""])

    comment_footer = ''.join(comment_footer)

    return comment_header, comment_body, comment_footer, ERROR


def comment_permission_check(data, comment):
    """"""Check for quite and resume status or duplicate comments""""""
    PERMITTED_TO_COMMENT = True
    repository = data[""repository""]
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])

    # Check for duplicate comment
    url = ""https://api.github.com/repos/{}/issues/{}/comments""
    url = url.format(repository, str(data[""pr_number""]))
    comments = requests.get(url, headers=headers, auth=auth).json()

    # Get the last comment by the bot
    last_comment = """"
    for old_comment in reversed(comments):
        if old_comment[""user""][""id""] == 24736507:  # ID of @pep8speaks
            last_comment = old_comment[""body""]
            break

    """"""
    # Disabling this because only a single comment is made per PR
    text1 = ''.join(BeautifulSoup(markdown(comment)).findAll(text=True))
    text2 = ''.join(BeautifulSoup(markdown(last_comment)).findAll(text=True))
    if text1 == text2.replace(""submitting"", ""updating""):
        PERMITTED_TO_COMMENT = False
    """"""

    # Check if the bot is asked to keep quiet
    for old_comment in reversed(comments):
        if '@pep8speaks' in old_comment['body']:
            if 'resume' in old_comment['body'].lower():
                break
            elif 'quiet' in old_comment['body'].lower():
                PERMITTED_TO_COMMENT = False


    return PERMITTED_TO_COMMENT


def create_or_update_comment(data, comment):
    comment_mode = None
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])

    query = ""https://api.github.com/repos/{}/issues/{}/comments""
    query = query.format(data[""repository""], str(data[""pr_number""]))
    comments = requests.get(query, headers=headers, auth=auth).json()

    # Get the last comment id by the bot
    last_comment_id = None
    for old_comment in comments:
        if old_comment[""user""][""id""] == 24736507:  # ID of @pep8speaks
            last_comment_id = old_comment[""id""]
            break

    if last_comment_id is None:  # Create a new comment
        response = requests.post(query, json={""body"": comment}, headers=headers, auth=auth)
        data[""comment_response""] = response.json()
    else:  # Update the last comment
        utc_time = datetime.datetime.utcnow()
        time_now = utc_time.strftime(""%B %d, %Y at %H:%M Hours UTC"")
        comment += ""\n\n##### Comment last updated on {}""
        comment = comment.format(time_now)

        query = ""https://api.github.com/repos/{}/issues/comments/{}""
        query = query.format(data[""repository""], str(last_comment_id))
        response = requests.patch(query, json={""body"": comment}, headers=headers, auth=auth)


def autopep8(data, config):
    # Run pycodestyle

    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    r = requests.get(data[""diff_url""], headers=headers, auth=auth)
    ## All the python files with additions
    patch = unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding)

    # A dictionary with filename paired with list of new line numbers
    py_files = {}

    for patchset in patch:
        if patchset.target_file[-3:] == '.py':
            py_file = patchset.target_file[1:]
            py_files[py_file] = []
            for hunk in patchset:
                for line in hunk.target_lines():
                    if line.is_added:
                        py_files[py_file].append(line.target_line_no)

    # Ignore errors and warnings specified in the config file
    to_ignore = "","".join(config[""pycodestyle""][""ignore""])
    arg_to_ignore = """"
    if len(to_ignore) > 0:
        arg_to_ignore = ""--ignore "" + to_ignore

    for file in py_files:
        filename = file[1:]
        url = ""https://raw.githubusercontent.com/{}/{}/{}""
        url = url.format(data[""repository""], data[""sha""], file)
        r = requests.get(url, headers=headers, auth=auth)
        with open(""file_to_fix.py"", 'w+', encoding=r.encoding) as file_to_fix:
            file_to_fix.write(r.text)

        cmd = 'autopep8 file_to_fix.py --diff {arg_to_ignore}'.format(
            arg_to_ignore=arg_to_ignore)
        proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
        stdout, _ = proc.communicate()
        data[""diff""][filename] = stdout.decode(r.encoding)

        # Fix the errors
        data[""diff""][filename] = data[""diff""][filename].replace(""file_to_check.py"", filename)
        data[""diff""][filename] = data[""diff""][filename].replace(""\\"", ""\\\\"")

        ## Store the link to the file
        url = ""https://github.com/{}/blob/{}{}""
        data[filename + ""_link""] = url.format(data[""repository""], data[""sha""], file)
        os.remove(""file_to_fix.py"")


def create_gist(data, config):
    """"""Create gists for diff files""""""
    REQUEST_JSON = {}
    REQUEST_JSON[""public""] = True
    REQUEST_JSON[""files""] = {}
    REQUEST_JSON[""description""] = ""In response to @{0}'s comment : {1}"".format(
        data[""reviewer""], data[""review_url""])

    for file, diffs in data[""diff""].items():
        if len(diffs) != 0:
            REQUEST_JSON[""files""][file.split(""/"")[-1] + "".diff""] = {
                ""content"": diffs
            }

    # Call github api to create the gist
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    url = ""https://api.github.com/gists""
    res = requests.post(url, json=REQUEST_JSON, headers=headers, auth=auth).json()
    data[""gist_response""] = res
    data[""gist_url""] = res[""html_url""]


def delete_if_forked(data):
    FORKED = False
    url = ""https://api.github.com/user/repos""
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    r = requests.get(url, headers=headers, auth=auth)
    for repo in r.json():
        if repo[""description""]:
            if data[""target_repo_fullname""] in repo[""description""]:
                FORKED = True
                r = requests.delete(""https://api.github.com/repos/""
                                ""{}"".format(repo[""full_name""]),
                                headers=headers, auth=auth)
    return FORKED


def fork_for_pr(data):
    FORKED = False
    url = ""https://api.github.com/repos/{}/forks""
    url = url.format(data[""target_repo_fullname""])
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    r = requests.post(url, headers=headers, auth=auth)
    if r.status_code == 202:
        data[""fork_fullname""] = r.json()[""full_name""]
        FORKED = True
    else:
        data[""error""] = ""Unable to fork""
    return FORKED


def update_fork_desc(data):
    # Check if forked (takes time)
    url = ""https://api.github.com/repos/{}"".format(data[""fork_fullname""])
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    r = requests.get(url, headers=headers, auth=auth)
    ATTEMPT = 0
    while(r.status_code != 200):
        time.sleep(5)
        r = requests.get(url, headers=headers, auth=auth)
        ATTEMPT += 1
        if ATTEMPT > 10:
            data[""error""] = ""Forking is taking more than usual time""
            break

    full_name = data[""target_repo_fullname""]
    author, name = full_name.split(""/"")
    request_json = {
        ""name"": name,
        ""description"": ""Forked from @{}'s {}"".format(author, full_name)
    }
    r = requests.patch(url, data=json.dumps(request_json), headers=headers, auth=auth)
    if r.status_code != 200:
        data[""error""] = ""Could not update description of the fork""


def create_new_branch(data):
    url = ""https://api.github.com/repos/{}/git/refs/heads""
    url = url.format(data[""fork_fullname""])
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    sha = None
    r = requests.get(url, headers=headers, auth=auth)
    for ref in r.json():
        if ref[""ref""].split(""/"")[-1] == data[""target_repo_branch""]:
            sha = ref[""object""][""sha""]

    url = ""https://api.github.com/repos/{}/git/refs""
    url = url.format(data[""fork_fullname""])
    data[""new_branch""] = ""{}-pep8-patch"".format(data[""target_repo_branch""])
    request_json = {
        ""ref"": ""refs/heads/{}"".format(data[""new_branch""]),
        ""sha"": sha,
    }
    r = requests.post(url, json=request_json, headers=headers, auth=auth)

    if r.status_code != 200:
        data[""error""] = ""Could not create new branch in the fork""


def autopep8ify(data, config):
    # Run pycodestyle
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    r = requests.get(data[""diff_url""], headers=headers, auth=auth)

    ## All the python files with additions
    patch = unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding)

    # A dictionary with filename paired with list of new line numbers
    py_files = {}

    for patchset in patch:
        if patchset.target_file[-3:] == '.py':
            py_file = patchset.target_file[1:]
            py_files[py_file] = []
            for hunk in patchset:
                for line in hunk.target_lines():
                    if line.is_added:
                        py_files[py_file].append(line.target_line_no)

    # Ignore errors and warnings specified in the config file
    to_ignore = "","".join(config[""pycodestyle""][""ignore""])
    arg_to_ignore = """"
    if len(to_ignore) > 0:
        arg_to_ignore = ""--ignore "" + to_ignore

    for file in py_files:
        filename = file[1:]
        url = ""https://raw.githubusercontent.com/{}/{}/{}""
        url = url.format(data[""repository""], data[""sha""], file)
        r = requests.get(url, headers=headers, auth=auth)
        with open(""file_to_fix.py"", 'w+', encoding=r.encoding) as file_to_fix:
            file_to_fix.write(r.text)

        cmd = 'autopep8 file_to_fix.py {arg_to_ignore}'.format(
            arg_to_ignore=arg_to_ignore)
        proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
        stdout, _ = proc.communicate()
        data[""results""][filename] = stdout.decode(r.encoding)

        os.remove(""file_to_fix.py"")


def commit(data):
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])

    fullname = data.get(""fork_fullname"")

    for file, new_file in data[""results""].items():
        url = ""https://api.github.com/repos/{}/contents/{}""
        url = url.format(fullname, file)
        params = {""ref"": data[""new_branch""]}
        r = requests.get(url, params=params, headers=headers, auth=auth)
        sha_blob = r.json().get(""sha"")
        params[""path""] = file
        content_code = base64.b64encode(new_file.encode()).decode(""utf-8"")
        request_json = {
            ""path"": file,
            ""message"": ""Fix pep8 errors in {}"".format(file),
            ""content"": content_code,
            ""sha"": sha_blob,
            ""branch"": data.get(""new_branch""),
        }
        r = requests.put(url, json=request_json, headers=headers, auth=auth)


def create_pr(data):
    headers = {""Authorization"": ""token "" + os.environ[""GITHUB_TOKEN""]}
    auth = (os.environ[""BOT_USERNAME""], os.environ[""BOT_PASSWORD""])
    url = ""https://api.github.com/repos/{}/pulls""
    url = url.format(data[""target_repo_fullname""])
    request_json = {
        ""title"": ""Fix pep8 errors"",
        ""head"": ""pep8speaks:{}"".format(data[""new_branch""]),
        ""base"": data[""target_repo_branch""],
        ""body"": ""The changes are suggested by autopep8"",
    }
    r = requests.post(url, json=request_json, headers=headers, auth=auth)
    if r.status_code == 201:
        data[""pr_url""] = r.json()[""html_url""]
    else:
        data[""error""] = ""Pull request could not be created""
/n/n/n",1
0,0,9b7805119938343fcac9dc929d8882f1d97cf14a,"vuedj/configtitania/views.py/n/nfrom django.shortcuts import render
from django.http import HttpResponse, JsonResponse
from django.views.decorators.csrf import csrf_exempt

from rest_framework.renderers import JSONRenderer
from rest_framework.parsers import JSONParser
from rest_framework.response import Response
from rest_framework import viewsets
from rest_framework.decorators import list_route
from flask import escape

from .models import BoxDetails, RegisteredServices
from .serializers import BoxDetailsSerializer, RegisteredServicesSerializer

import common, sqlite3, subprocess, NetworkManager, crypt, pwd, getpass, spwd

# fetch network AP details
nm = NetworkManager.NetworkManager
wlans = [d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)]

def get_osversion():
    """"""
    PRETTY_NAME of your Titania os (in lowercase).
    """"""
    with open(""/etc/os-release"") as f:
        osfilecontent = f.read().split(""\n"")
        # $PRETTY_NAME is at the 5th position
        version = osfilecontent[4].split('=')[1].strip('\""')
        return version

def get_allconfiguredwifi():
    """"""
    nmcli con | grep 802-11-wireless
    """"""
    ps = subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0]
    wifirows = ps.split('\n')
    wifi = []
    for row in wifirows:
        name = row.split(':')
        print(name)
        wifi.append(name[0])
    return wifi

def get_allAPs():
    """"""
    nmcli con | grep 802-11-wireless
    """"""
    ps = subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0]
    wifirows = ps.split('\n')
    wifi = []
    for row in wifirows:
        entry = row.split(':')
        print(entry)
        wifi.append(entry)
    return wifi
    # wifi_aps = []   
    # for dev in wlans:
    #     for ap in dev.AccessPoints:
    #         wifi_aps.append(ap.Ssid)
    # return wifi_aps

def add_user(username, password):
    encPass = crypt.crypt(password,""22"")
    #subprocess escapes the username stopping code injection
    subprocess.call(['useradd','-G','docker,wheel','-p',encPass,username])

def add_newWifiConn(wifiname, wifipass):
    print(wlans)
    wlan0 = wlans[0]
    print(wlan0)
    print(wifiname)
    # get selected ap as currentwifi
    for dev in wlans:
        for ap in dev.AccessPoints:
            if ap.Ssid == wifiname:
                currentwifi = ap
    print(currentwifi)
    # params to set password
    params = {
            ""802-11-wireless"": {
                ""security"": ""802-11-wireless-security"",
            },
            ""802-11-wireless-security"": {
                ""key-mgmt"": ""wpa-psk"",
                ""psk"": wifipass
            },
        }
    conn = nm.AddAndActivateConnection(params, wlan0, currentwifi)        

def delete_WifiConn(wifiap):
    """"""
    nmcli connection delete id <connection name>
    """"""
    ps = subprocess.Popen(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE)
    print(ps)

def edit_WifiConn(wifiname, wifipass):
    ps = subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE)
    print(ps)
    print(wlans)
    wlan0 = wlans[0]
    print(wlan0)
    print(wifiname)
    # get selected ap as currentwifi
    for dev in wlans:
        for ap in dev.AccessPoints:
            if ap.Ssid == wifiname:
                currentwifi = ap
    # params to set password
    params = {
            ""802-11-wireless"": {
                ""security"": ""802-11-wireless-security"",
            },
            ""802-11-wireless-security"": {
                ""key-mgmt"": ""wpa-psk"",
                ""psk"": wifipass
            },
        }
    conn = nm.AddAndActivateConnection(params, wlan0, currentwifi) 
    return       

@csrf_exempt
def handle_config(request):
    """"""
    List all code snippets, or create a new snippet.
    """""" 
    if request.method == 'POST':
        action = request.POST.get(""_action"")
        print(action)
        if action == 'registerService':
            request_name = request.POST.get(""name"")
            request_address = request.POST.get(""address"")
            request_icon = request.POST.get(""icon"")
            print(request_name)
            print(request_address)
            print(request_icon)
            setServiceDetails = RegisteredServices.objects.get_or_create(name=request_name,address=request_address,icon=request_icon)
            return JsonResponse({""STATUS"":""SUCCESS""}, safe=False)
        elif action == 'getSchema':
            schema = get_osversion()
            return JsonResponse({""version_info"":schema}, safe=False)
        elif action == 'getIfConfigured':
            print(action)
            queryset = BoxDetails.objects.all()
            serializer = BoxDetailsSerializer(queryset, many=True)
            return JsonResponse(serializer.data, safe=False)
        elif action == 'loadDependencies':
            print(action)
            queryset = RegisteredServices.objects.all()
            serializer = RegisteredServicesSerializer(queryset, many=True)
            return JsonResponse(serializer.data, safe=False)
        elif action == 'getAllAPs':
            wifi_aps = get_allAPs()
            return JsonResponse(wifi_aps, safe=False)
        elif action == 'saveUserDetails':
            print(action)
            boxname = escape(request.POST.get(""boxname""))
            username = escape(request.POST.get(""username""))
            password = escape(request.POST.get(""password""))
            print(username)
            add_user(username,password)
            setBoxName = BoxDetails(boxname=boxname)
            setBoxName.save()
            # connect to wifi ap user selected
            wifi_pass = request.POST.get(""wifi_password"")
            wifi_name = request.POST.get(""wifi_ap"")
            if len(wifi_name) > 0:
                add_newWifiConn(wifi_name,wifi_pass)
            return JsonResponse({""STATUS"":""SUCCESS""}, safe=False)
        elif action == 'login':
            print(action)
            username = escape(request.POST.get(""username""))
            password = escape(request.POST.get(""password""))
            output=''
            """"""Tries to authenticate a user.
            Returns True if the authentication succeeds, else the reason
            (string) is returned.""""""
            try:
                enc_pwd = spwd.getspnam(username)[1]
                if enc_pwd in [""NP"", ""!"", """", None]:
                    output = ""User '%s' has no password set"" % username
                if enc_pwd in [""LK"", ""*""]:
                    output = ""account is locked""
                if enc_pwd == ""!!"":
                    output = ""password has expired""
                # Encryption happens here, the hash is stripped from the
                # enc_pwd and the algorithm id and salt are used to encrypt
                # the password.
                if crypt.crypt(password, enc_pwd) == enc_pwd:
                    output = ''
                else:
                    output = ""incorrect password""
            except KeyError:
                output = ""User '%s' not found"" % username
            if len(output) == 0:
                return JsonResponse({""username"":username}, safe=False)
            else:
                return JsonResponse(output, safe=False)
        elif action == 'logout':
            print(action)
            username = request.POST.get(""username"")
            print(username+' ')
            queryset = User.objects.all().first()
            if username == queryset.username:
                return JsonResponse({""STATUS"":""SUCCESS"", ""username"":queryset.username}, safe=False)
        elif action == 'getDashboardCards':
            print(action)
            con = sqlite3.connect(""dashboard.sqlite3"")
            cursor = con.cursor()
            cursor.execute(common.Q_DASHBOARD_CARDS)
            rows = cursor.fetchall()
            print(rows)
            return JsonResponse(rows, safe=False)
        elif action == 'getDashboardChart':
            print(action)
            con = sqlite3.connect(""dashboard.sqlite3"")
            cursor = con.cursor()
            cursor.execute(common.Q_GET_CONTAINER_ID)
            rows = cursor.fetchall()
            print(rows)
            finalset = []
            for row in rows:
                cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],])
                datasets = cursor.fetchall()
                print(datasets)
                data = {'container_name' : row[1], 'data': datasets}
                finalset.append(data)
            return JsonResponse(finalset, safe=False)
        elif action == 'getDockerOverview':
            print(action)
            con = sqlite3.connect(""dashboard.sqlite3"")
            cursor = con.cursor()
            cursor.execute(common.Q_GET_DOCKER_OVERVIEW)
            rows = cursor.fetchall()
            print(rows)
            finalset = []
            for row in rows:
                data = {'state': row[0], 'container_id': row[1], 'name': row[2],
                        'image': row[3], 'running_for': row[4],
                        'command': row[5], 'ports': row[6],
                        'status': row[7], 'networks': row[8]}
                finalset.append(data)
            return JsonResponse(finalset, safe=False)
        elif action == 'getContainerStats':
            print(action)
            con = sqlite3.connect(""dashboard.sqlite3"")
            cursor = con.cursor()
            cursor.execute(common.Q_GET_CONTAINER_ID)
            rows = cursor.fetchall()
            print(rows)
            finalset = []
            datasets_io = []
            datasets_mem = []
            datasets_perc = []
            for row in rows:
                datasets_io = []
                datasets_mem = []
                datasets_perc = []
                # values with % appended to them
                for iter in range(0,2):
                    cursor.execute(common.Q_GET_CONTAINER_STATS_CPU,[row[0],iter+1])
                    counter_val = cursor.fetchall()
                    datasets_perc.append(counter_val)
                # values w/o % appended to them
                for iter in range(2,4):
                    cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1])
                    counter_val = cursor.fetchall()
                    datasets_mem.append(counter_val)
                # values w/o % appended to them
                for iter in range(4,8):
                    cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1])
                    counter_val = cursor.fetchall()
                    datasets_io.append(counter_val)
                data = {'container_id': row[0], 'container_name' : row[1], 'data_io': datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc}
                finalset.append(data)
            return JsonResponse(finalset, safe=False)
        elif action == 'getThreads':
            print(action)
            rows = []
            ps = subprocess.Popen(['top', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0]
            processes = ps.decode().split('\n')
            # this specifies the number of splits, so the splitted lines
            # will have (nfields+1) elements
            nfields = len(processes[0].split()) - 1
            for row in processes[4:]:
                rows.append(row.split(None, nfields))
            return JsonResponse(rows, safe=False)
        elif action == 'getContainerTop':
            print(action)
            con = sqlite3.connect(""dashboard.sqlite3"")
            cursor = con.cursor()
            cursor.execute(common.Q_GET_CONTAINER_ID)
            rows = cursor.fetchall()
            resultset = []
            for i in rows:
                data = {}
                datasets = []
                ps = subprocess.Popen(['docker', 'top',i[0]], stdout=subprocess.PIPE).communicate()[0]
                processes = ps.decode().split('\n')
                # this specifies the number of splits, so the splitted lines
                # will have (nfields+1) elements
                nfields = len(processes[0].split()) - 1
                for p in processes[1:]:
                    datasets.append(p.split(None, nfields))
                data = {'container_id': i[0], 'container_name' : i[1], 'data': datasets}
                resultset.append(data)
            return JsonResponse(resultset, safe=False)
        elif action == 'getSettings':
            print(action)
            ps = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\n')[0]
            # sample ps 
            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run
            userlist = ps.split(':')[3].split(',')
            configuredwifi = get_allconfiguredwifi()
            wifi_aps = get_allAPs()
            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False)
        elif action == 'deleteUser':
            print(action)
            username = escape(request.POST.get(""user""))
            ps = subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate()
            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\n')[0]
            # sample ps 
            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run
            userlist = fetchusers.split(':')[3].split(',')
            configuredwifi = get_allconfiguredwifi()
            wifi_aps = get_allAPs()
            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deleteuser', 'endpoint': username}], safe=False)
        elif action == 'addNewUser':
            print(action)
            username = escape(request.POST.get(""username""))
            password = escape(request.POST.get(""password""))
            add_user(username,password)
            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\n')[0]
            # sample ps 
            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run
            userlist = fetchusers.split(':')[3].split(',')
            configuredwifi = get_allconfiguredwifi()
            wifi_aps = get_allAPs()
            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False)
        elif action == 'addWifi':
            print(action)
            # connect to wifi ap user selected
            wifi_pass = escape(request.POST.get(""wifi_password""))
            wifi_name = request.POST.get(""wifi_ap"")
            if len(wifi_name) > 0:
                add_newWifiConn(wifi_name,wifi_pass)
            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\n')[0]
            # sample ps 
            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run
            userlist = fetchusers.split(':')[3].split(',')
            configuredwifi = get_allconfiguredwifi()
            wifi_aps = get_allAPs()
            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False)
        elif action == 'deleteWifi':
            print(action)
            # connect to wifi ap user selected
            wifi_name = request.POST.get(""wifi"")
            delete_WifiConn(wifi_name)
            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\n')[0]
            # sample ps 
            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run
            userlist = fetchusers.split(':')[3].split(',')
            configuredwifi = get_allconfiguredwifi()
            wifi_aps = get_allAPs()
            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deletewifi', 'endpoint': wifi_name}], safe=False)
        elif action == 'editWifi':
            print(action)
            # connect to wifi ap user selected
            wifi_name = request.POST.get(""wifi_ap"")
            wifi_pass = escape(request.POST.get(""wifi_password""))
            edit_WifiConn(wifi_name,wifi_pass)
            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\n')[0]
            # sample ps 
            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run
            userlist = fetchusers.split(':')[3].split(',')
            configuredwifi = get_allconfiguredwifi()
            wifi_aps = get_allAPs()
            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'editwifi', 'endpoint': wifi_name}], safe=False)
        return JsonResponse(serializer.errors, status=400)

def index(request):
    return render(request, 'index.html')

class BoxDetailsViewSet(viewsets.ModelViewSet):
    queryset = BoxDetails.objects.all()
    serializer_class = BoxDetailsSerializer

class RegisteredServicesViewSet(viewsets.ModelViewSet):
    queryset = RegisteredServices.objects.all()
    serializer_class = RegisteredServicesSerializer    


/n/n/n",0
1,1,9b7805119938343fcac9dc929d8882f1d97cf14a,"/vuedj/configtitania/views.py/n/nfrom django.shortcuts import render
from django.http import HttpResponse, JsonResponse
from django.views.decorators.csrf import csrf_exempt

from rest_framework.renderers import JSONRenderer
from rest_framework.parsers import JSONParser
from rest_framework.response import Response
from rest_framework import viewsets
from rest_framework.decorators import list_route
from flask import escape

from .models import BoxDetails, RegisteredServices
from .serializers import BoxDetailsSerializer, RegisteredServicesSerializer

import common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass, spwd 

# fetch network AP details
nm = NetworkManager.NetworkManager
wlans = [d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)]

def get_osversion():
    """"""
    PRETTY_NAME of your Titania os (in lowercase).
    """"""
    with open(""/etc/os-release"") as f:
        osfilecontent = f.read().split(""\n"")
        # $PRETTY_NAME is at the 5th position
        version = osfilecontent[4].split('=')[1].strip('\""')
        return version

def get_allconfiguredwifi():
    """"""
    nmcli con | grep 802-11-wireless
    """"""
    ps = subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0]
    wifirows = ps.split('\n')
    wifi = []
    for row in wifirows:
        name = row.split(':')
        print(name)
        wifi.append(name[0])
    return wifi

def get_allAPs():
    """"""
    nmcli con | grep 802-11-wireless
    """"""
    ps = subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0]
    wifirows = ps.split('\n')
    wifi = []
    for row in wifirows:
        entry = row.split(':')
        print(entry)
        wifi.append(entry)
    return wifi
    # wifi_aps = []   
    # for dev in wlans:
    #     for ap in dev.AccessPoints:
    #         wifi_aps.append(ap.Ssid)
    # return wifi_aps

def add_user(username, password):
    encPass = crypt.crypt(password,""22"")
    os.system(""useradd -G docker,wheel -p ""+encPass+"" ""+username)

def add_newWifiConn(wifiname, wifipass):
    print(wlans)
    wlan0 = wlans[0]
    print(wlan0)
    print(wifiname)
    # get selected ap as currentwifi
    for dev in wlans:
        for ap in dev.AccessPoints:
            if ap.Ssid == wifiname:
                currentwifi = ap
    print(currentwifi)
    # params to set password
    params = {
            ""802-11-wireless"": {
                ""security"": ""802-11-wireless-security"",
            },
            ""802-11-wireless-security"": {
                ""key-mgmt"": ""wpa-psk"",
                ""psk"": wifipass
            },
        }
    conn = nm.AddAndActivateConnection(params, wlan0, currentwifi)        

def delete_WifiConn(wifiap):
    """"""
    nmcli connection delete id <connection name>
    """"""
    ps = subprocess.Popen(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE)
    print(ps)

def edit_WifiConn(wifiname, wifipass):
    ps = subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE)
    print(ps)
    print(wlans)
    wlan0 = wlans[0]
    print(wlan0)
    print(wifiname)
    # get selected ap as currentwifi
    for dev in wlans:
        for ap in dev.AccessPoints:
            if ap.Ssid == wifiname:
                currentwifi = ap
    # params to set password
    params = {
            ""802-11-wireless"": {
                ""security"": ""802-11-wireless-security"",
            },
            ""802-11-wireless-security"": {
                ""key-mgmt"": ""wpa-psk"",
                ""psk"": wifipass
            },
        }
    conn = nm.AddAndActivateConnection(params, wlan0, currentwifi) 
    return       

@csrf_exempt
def handle_config(request):
    """"""
    List all code snippets, or create a new snippet.
    """""" 
    if request.method == 'POST':
        action = request.POST.get(""_action"")
        print(action)
        if action == 'registerService':
            request_name = request.POST.get(""name"")
            request_address = request.POST.get(""address"")
            request_icon = request.POST.get(""icon"")
            print(request_name)
            print(request_address)
            print(request_icon)
            setServiceDetails = RegisteredServices.objects.get_or_create(name=request_name,address=request_address,icon=request_icon)
            return JsonResponse({""STATUS"":""SUCCESS""}, safe=False)
        elif action == 'getSchema':
            schema = get_osversion()
            return JsonResponse({""version_info"":schema}, safe=False)
        elif action == 'getIfConfigured':
            print(action)
            queryset = BoxDetails.objects.all()
            serializer = BoxDetailsSerializer(queryset, many=True)
            return JsonResponse(serializer.data, safe=False)
        elif action == 'loadDependencies':
            print(action)
            queryset = RegisteredServices.objects.all()
            serializer = RegisteredServicesSerializer(queryset, many=True)
            return JsonResponse(serializer.data, safe=False)
        elif action == 'getAllAPs':
            wifi_aps = get_allAPs()
            return JsonResponse(wifi_aps, safe=False)
        elif action == 'saveUserDetails':
            print(action)
            boxname = escape(request.POST.get(""boxname""))
            username = escape(request.POST.get(""username""))
            password = escape(request.POST.get(""password""))
            print(username)
            add_user(username,password)
            setBoxName = BoxDetails(boxname=boxname)
            setBoxName.save()
            # connect to wifi ap user selected
            wifi_pass = request.POST.get(""wifi_password"")
            wifi_name = request.POST.get(""wifi_ap"")
            if len(wifi_name) > 0:
                add_newWifiConn(wifi_name,wifi_pass)
            return JsonResponse({""STATUS"":""SUCCESS""}, safe=False)
        elif action == 'login':
            print(action)
            username = escape(request.POST.get(""username""))
            password = escape(request.POST.get(""password""))
            output=''
            """"""Tries to authenticate a user.
            Returns True if the authentication succeeds, else the reason
            (string) is returned.""""""
            try:
                enc_pwd = spwd.getspnam(username)[1]
                if enc_pwd in [""NP"", ""!"", """", None]:
                    output = ""User '%s' has no password set"" % username
                if enc_pwd in [""LK"", ""*""]:
                    output = ""account is locked""
                if enc_pwd == ""!!"":
                    output = ""password has expired""
                # Encryption happens here, the hash is stripped from the
                # enc_pwd and the algorithm id and salt are used to encrypt
                # the password.
                if crypt.crypt(password, enc_pwd) == enc_pwd:
                    output = ''
                else:
                    output = ""incorrect password""
            except KeyError:
                output = ""User '%s' not found"" % username
            if len(output) == 0:
                return JsonResponse({""username"":username}, safe=False)
            else:
                return JsonResponse(output, safe=False)
        elif action == 'logout':
            print(action)
            username = request.POST.get(""username"")
            print(username+' ')
            queryset = User.objects.all().first()
            if username == queryset.username:
                return JsonResponse({""STATUS"":""SUCCESS"", ""username"":queryset.username}, safe=False)
        elif action == 'getDashboardCards':
            print(action)
            con = sqlite3.connect(""dashboard.sqlite3"")
            cursor = con.cursor()
            cursor.execute(common.Q_DASHBOARD_CARDS)
            rows = cursor.fetchall()
            print(rows)
            return JsonResponse(rows, safe=False)
        elif action == 'getDashboardChart':
            print(action)
            con = sqlite3.connect(""dashboard.sqlite3"")
            cursor = con.cursor()
            cursor.execute(common.Q_GET_CONTAINER_ID)
            rows = cursor.fetchall()
            print(rows)
            finalset = []
            for row in rows:
                cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],])
                datasets = cursor.fetchall()
                print(datasets)
                data = {'container_name' : row[1], 'data': datasets}
                finalset.append(data)
            return JsonResponse(finalset, safe=False)
        elif action == 'getDockerOverview':
            print(action)
            con = sqlite3.connect(""dashboard.sqlite3"")
            cursor = con.cursor()
            cursor.execute(common.Q_GET_DOCKER_OVERVIEW)
            rows = cursor.fetchall()
            print(rows)
            finalset = []
            for row in rows:
                data = {'state': row[0], 'container_id': row[1], 'name': row[2],
                        'image': row[3], 'running_for': row[4],
                        'command': row[5], 'ports': row[6],
                        'status': row[7], 'networks': row[8]}
                finalset.append(data)
            return JsonResponse(finalset, safe=False)
        elif action == 'getContainerStats':
            print(action)
            con = sqlite3.connect(""dashboard.sqlite3"")
            cursor = con.cursor()
            cursor.execute(common.Q_GET_CONTAINER_ID)
            rows = cursor.fetchall()
            print(rows)
            finalset = []
            datasets_io = []
            datasets_mem = []
            datasets_perc = []
            for row in rows:
                datasets_io = []
                datasets_mem = []
                datasets_perc = []
                # values with % appended to them
                for iter in range(0,2):
                    cursor.execute(common.Q_GET_CONTAINER_STATS_CPU,[row[0],iter+1])
                    counter_val = cursor.fetchall()
                    datasets_perc.append(counter_val)
                # values w/o % appended to them
                for iter in range(2,4):
                    cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1])
                    counter_val = cursor.fetchall()
                    datasets_mem.append(counter_val)
                # values w/o % appended to them
                for iter in range(4,8):
                    cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1])
                    counter_val = cursor.fetchall()
                    datasets_io.append(counter_val)
                data = {'container_id': row[0], 'container_name' : row[1], 'data_io': datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc}
                finalset.append(data)
            return JsonResponse(finalset, safe=False)
        elif action == 'getThreads':
            print(action)
            rows = []
            ps = subprocess.Popen(['top', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0]
            processes = ps.decode().split('\n')
            # this specifies the number of splits, so the splitted lines
            # will have (nfields+1) elements
            nfields = len(processes[0].split()) - 1
            for row in processes[4:]:
                rows.append(row.split(None, nfields))
            return JsonResponse(rows, safe=False)
        elif action == 'getContainerTop':
            print(action)
            con = sqlite3.connect(""dashboard.sqlite3"")
            cursor = con.cursor()
            cursor.execute(common.Q_GET_CONTAINER_ID)
            rows = cursor.fetchall()
            resultset = []
            for i in rows:
                data = {}
                datasets = []
                ps = subprocess.Popen(['docker', 'top',i[0]], stdout=subprocess.PIPE).communicate()[0]
                processes = ps.decode().split('\n')
                # this specifies the number of splits, so the splitted lines
                # will have (nfields+1) elements
                nfields = len(processes[0].split()) - 1
                for p in processes[1:]:
                    datasets.append(p.split(None, nfields))
                data = {'container_id': i[0], 'container_name' : i[1], 'data': datasets}
                resultset.append(data)
            return JsonResponse(resultset, safe=False)
        elif action == 'getSettings':
            print(action)
            ps = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\n')[0]
            # sample ps 
            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run
            userlist = ps.split(':')[3].split(',')
            configuredwifi = get_allconfiguredwifi()
            wifi_aps = get_allAPs()
            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False)
        elif action == 'deleteUser':
            print(action)
            username = escape(request.POST.get(""user""))
            ps = subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate()
            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\n')[0]
            # sample ps 
            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run
            userlist = fetchusers.split(':')[3].split(',')
            configuredwifi = get_allconfiguredwifi()
            wifi_aps = get_allAPs()
            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deleteuser', 'endpoint': username}], safe=False)
        elif action == 'addNewUser':
            print(action)
            username = escape(request.POST.get(""username""))
            password = escape(request.POST.get(""password""))
            add_user(username,password)
            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\n')[0]
            # sample ps 
            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run
            userlist = fetchusers.split(':')[3].split(',')
            configuredwifi = get_allconfiguredwifi()
            wifi_aps = get_allAPs()
            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False)
        elif action == 'addWifi':
            print(action)
            # connect to wifi ap user selected
            wifi_pass = escape(request.POST.get(""wifi_password""))
            wifi_name = request.POST.get(""wifi_ap"")
            if len(wifi_name) > 0:
                add_newWifiConn(wifi_name,wifi_pass)
            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\n')[0]
            # sample ps 
            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run
            userlist = fetchusers.split(':')[3].split(',')
            configuredwifi = get_allconfiguredwifi()
            wifi_aps = get_allAPs()
            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False)
        elif action == 'deleteWifi':
            print(action)
            # connect to wifi ap user selected
            wifi_name = request.POST.get(""wifi"")
            delete_WifiConn(wifi_name)
            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\n')[0]
            # sample ps 
            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run
            userlist = fetchusers.split(':')[3].split(',')
            configuredwifi = get_allconfiguredwifi()
            wifi_aps = get_allAPs()
            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deletewifi', 'endpoint': wifi_name}], safe=False)
        elif action == 'editWifi':
            print(action)
            # connect to wifi ap user selected
            wifi_name = request.POST.get(""wifi_ap"")
            wifi_pass = escape(request.POST.get(""wifi_password""))
            edit_WifiConn(wifi_name,wifi_pass)
            fetchusers = subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\n')[0]
            # sample ps 
            # docker:x:992:pooja,asdasd,aaa,cow,dsds,priya,asdas,cowwwwww,ramm,asdasdasdasd,asdasdas,adam,run
            userlist = fetchusers.split(':')[3].split(',')
            configuredwifi = get_allconfiguredwifi()
            wifi_aps = get_allAPs()
            return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'editwifi', 'endpoint': wifi_name}], safe=False)
        return JsonResponse(serializer.errors, status=400)

def index(request):
    return render(request, 'index.html')

class BoxDetailsViewSet(viewsets.ModelViewSet):
    queryset = BoxDetails.objects.all()
    serializer_class = BoxDetailsSerializer

class RegisteredServicesViewSet(viewsets.ModelViewSet):
    queryset = RegisteredServices.objects.all()
    serializer_class = RegisteredServicesSerializer    


/n/n/n",1
84,84,42b020edfe6b23b245938d23ff7a0484333d6450,"evproxy.py/n/n# -*- coding: utf-8 -*-
# -*- mode: python -*-
import wzrpc
from sup.ticker import Ticker

class EvaluatorProxy:
    def __init__(self, ev_init, *args, **kvargs):
        super().__init__()
        self.ev_init = ev_init
        self.bind_kt_ticker = Ticker()
        self.bind_kt = 5

    def handle_evaluate(self, reqid, interface, method, data):
        domain, page = data
        self.p.log.info('Recvd page %s, working on', reqid)
        res = self.ev.solve_capage(domain, page)
        self.p.log.info('Done, sending answer: %s', res)
        self.p.send_success_rep(reqid, [v.encode('utf-8') for v in res])

    def send_keepalive(self):
        msg = self.p.wz.make_req_msg(b'Router', b'bind-keepalive', [],
            self.handle_keepalive_reply)
        msg.insert(0, b'')
        self.p.wz_sock.send_multipart(msg)

    def handle_keepalive_reply(self, reqid, seqnum, status, data):
        if status == wzrpc.status.success:
            self.p.log.debug('Keepalive was successfull')
        elif status == wzrpc.status.e_req_denied:
            self.p.log.warn('Keepalive status {0}, reauthentificating and rebinding'.
                format(wzrpc.name_status(status)))
            self.p.auth_requests()
            self.p.bind_methods()
        elif status == wzrpc.status.e_timeout:
            self.p.log.warn('Keepalive timeout')
        else:
            self.p.log.warn('Keepalive status {0}'.
                format(wzrpc.name_status(status)))

    def __call__(self, parent):
        self.p = parent
        self.p.wz_connect()
        self.p.wz_auth_requests = [
            (b'Router', b'auth-bind-route'),
            (b'Router', b'auth-unbind-route'),
            (b'Router', b'auth-set-route-type')]
        self.p.wz_bind_methods = [
            (b'Evaluator', b'evaluate', self.handle_evaluate, wzrpc.routetype.random)]
        self.p.auth_requests()
        self.p.bind_methods()
        self.ev = self.ev_init()
        self.bind_kt_ticker.tick()
        while self.p.running.is_set():
            self.p.poll()
            if self.bind_kt_ticker.elapsed(False) > self.bind_kt:
                self.bind_kt_ticker.tick()
                self.send_keepalive()
/n/n/nlib/wzrpc/wzbase.py/n/n# -*- coding: utf-8 -*-
# -*- mode: python -*-
from . import *

class WZBase(object):
    def make_error_msg(self, iden, status):
        msg = []
        if iden:
            msg.extend(iden)
            msg.append(b'')
        msg.append(header_struct.pack(wzstart, wzversion, msgtype.err))
        msg.append(error_struct.pack(status))
        return msg

    def parse_msg(self, iden, msg):
        if len(msg) == 0 or not msg[0].startswith(wzstart):
            raise WZENoWZ('Not a WZRPC message {0} from {1}'.format(msg, repr(iden)))
        try:
            hsize = header_struct.size # locals are faster
            wz, ver, type_ = header_struct.unpack(msg[0][:hsize])
        except Exception as e:
            raise
        if int(ver) != wzversion:
            raise WZEWrongVersion(iden, 'Wrong message version')
        if type_ == msgtype.req:
            unpacked = []
            for v in req_struct.unpack(msg[0][hsize:]):
                if type(v) == bytes:
                    v = v.partition(b'\0')[0]
                unpacked.append(v)
            return self._parse_req(iden, msg, *unpacked)
        elif type_ == msgtype.rep:
            unpacked = rep_struct.unpack(msg[0][hsize:])
            return self._parse_rep(iden, msg, *unpacked)
        elif type_ == msgtype.sig:
            unpacked = []
            for v in sig_struct.unpack(msg[0][hsize:]):
                if type(v) == bytes:
                    v = v.partition(b'\0')[0]
                unpacked.append(v)
            return self._parse_sig(iden, msg, *unpacked)
        elif type_ == msgtype.err:
            unpacked = error_struct.unpack(msg[0][hsize:])
            return self._parse_err(iden, msg, *unpacked)
        elif type_ == msgtype.nil:
            return self._handle_nil(iden, msg)
        else:
            raise WZEUnknownType(iden, 'Unknown message type')
        
    def parse_router_msg(self, frames):
        base, msg = split_frames(frames)
        return self.parse_msg(base[:-1], msg)
/n/n/nlib/wzrpc/wzhandler.py/n/n# -*- coding: utf-8 -*-
# -*- mode: python -*-
from . import *
from .wzbase import WZBase

class WZHandler(WZBase):
    def __init__(self):
        self.req_handlers = {}
        self.response_handlers = {}
        self.sig_handlers = {}
        self.iden_reqid_map = BijectiveSetMap()

    def set_req_handler(self, interface, method, fun):
        self.req_handlers[(interface, method)] = fun

    def set_response_handler(self, reqid, fun):
        self.response_handlers[reqid] = fun

    def set_sig_handler(self, interface, method, fun):
        self.sig_handlers[(interface, method)] = fun

    def del_req_handler(self, interface, method):
        del self.req_handlers[(interface, method)]

    def del_response_handler(self, reqid):
        del self.response_handlers[reqid]

    def del_sig_handler(self, interface, method):
        del self.sig_handlers[(interface, method)]

    def _parse_req(self, iden, msg, reqid, interface, method):
        try:
            handler = self.req_handlers[(interface, method)]
        except KeyError:
            try:
                handler = self.req_handlers[(interface, None)]
            except KeyError:
                raise WZENoReqHandler(iden, reqid,
                    'No req handler for %s,%s'%(interface, method))
        if iden:
            self.iden_reqid_map.add_value(tuple(iden), reqid)
        handler(reqid, interface, method, msg[1:])
        return ()

    def _parse_rep(self, iden, msg, reqid, seqnum, status):
        try:
            handler = self.response_handlers[reqid]
            if seqnum == 0:
                del self.response_handlers[reqid]
        except KeyError:
            raise WZENoHandler(iden, 'No rep handler for reqid')
        handler(reqid, seqnum, status, msg[1:])
        return ()

    def _parse_sig(self, iden, msg, interface, method):
        try:
            handler = self.sig_handlers[(interface, method)]
        except KeyError:
            raise WZENoHandler(iden, 'No handler for sig %s,%s'%(interface, method))
        handler(interface, method, msg[1:])
        return ()

    def make_req_msg(self, interface, method, args, fun, reqid=None):
        if not reqid:
            reqid = self.make_reqid()
        msg = make_req_msg(interface, method, args, reqid)
        self.set_response_handler(reqid, fun)
        return msg

    def make_router_req_msg(self, iden, interface, method, args, fun, reqid=None):
        msg = iden[:]
        msg.append(b'')
        msg.extend(self.make_req_msg(interface, method, args, fun, reqid))
        return msg

    def make_router_rep_msg(self, reqid, seqnum, status, answer):
        iden = self.iden_reqid_map.get_key(reqid)
        if seqnum == 0:
            self.iden_reqid_map.del_value(iden, reqid)
        msg = list(iden)
        msg.append(b'')
        msg.extend(make_rep_msg(reqid, seqnum, status, answer))
        return msg

    def get_iden(self, reqid):
        return self.iden_reqid_map.get_key(reqid)

    def get_reqids(self, iden):
        return self.iden_reqid_map.get_values(iden)

    def make_reqid(self):
        while True:
            reqid = random.randint(1, (2**64)-1)
            if reqid not in self.response_handlers:
                return reqid

    def make_auth_req_data(self, interface, method, key, reqid=None):
        if not reqid:
            reqid = self.make_reqid()
        args = [interface, method, make_auth_hash(interface, method, reqid, key)]
        return (b'Router', b'auth-request', args, reqid)

    def make_auth_bind_route_data(self, interface, method, key, reqid=None):
        if not reqid:
            reqid = self.make_reqid()
        args = [interface, method, make_auth_hash(interface, method, reqid, key)]
        return (b'Router', b'auth-bind-route', args, reqid)

    def make_auth_unbind_route_data(self, interface, method, key, reqid=None):
        if not reqid:
            reqid = self.make_reqid()
        args = [interface, method, make_auth_hash(interface, method, reqid, key)]
        return (b'Router', b'auth-unbind-route', args, reqid)

    def make_auth_set_route_type_data(self, interface, method, type_, key, reqid=None):
        if not reqid:
            reqid = self.make_reqid()
        args = [interface, method, struct.pack('!B', type_),
                make_auth_hash(interface, method, reqid, key)]
        return (b'Router', b'auth-set-route-type', args, reqid)

    def make_auth_clear_data(self, reqid=None):
        if not reqid:
            reqid = self.make_reqid()
        return (b'Router', b'auth-clear', [], reqid)

    def req_from_data(self, d, fun):
        return self.make_req_msg(d[0], d[1], d[2], fun, d[3])

    def _parse_err(self, iden, msg, status):
        pass

    def _handle_nil(self, iden, msg):
        pass
/n/n/nlib/wzworkers.py/n/nimport zmq
import threading, multiprocessing
import logging
from sup.ticker import Ticker
# from sup import split_frames
import wzrpc
import exceptions
from wzrpc.wzhandler import WZHandler
import wzauth_data

class WorkerInterrupt(Exception):
    '''Exception to raise when self.running is cleared'''
    def __init__(self):
        super().__init__('Worker was interrupted at runtime')

class Suspend(Exception):
    # if we need this at all.
    '''Exception to raise on suspend signal'''
    def __init__(self, interval, *args, **kvargs):
        self.interval = interval
        super().__init__(*args, **kvargs)

class Resume(Exception):
    '''Exception to raise when suspend sleep is interrupted'''

class WZWorkerBase:
    def __init__(self, wz_addr, fun, args=(), kvargs={},
            name=None, start_timer=None, poll_timeout=None,
            pargs=(), pkvargs={}):
        super().__init__(*pargs, **pkvargs)
        self.name = name if name else type(self).__name__
        self.start_timer = start_timer
        self.poll_timeout = poll_timeout if poll_timeout else 5*1000
        self.call = (fun, args, kvargs)

        self.wz_addr = wz_addr
        self.wz_auth_requests = []
        self.wz_bind_methods = []
        self.wz_poll_timeout = 30 * 1000
        self.wz_retry_timeout = 5

    def __sinit__(self):
        '''Initializes thread-local interface on startup'''
        self.log = logging.getLogger(self.name)
        self.running = threading.Event()
        self.sleep_ticker = Ticker()
        self.poller = zmq.Poller()

        s = self.ctx.socket(zmq.SUB)
        self.poller.register(s, zmq.POLLIN)
        s.setsockopt(zmq.IPV6, True)
        s.connect(self.sig_addr)
        s.setsockopt(zmq.SUBSCRIBE, b'GLOBAL')
        s.setsockopt(zmq.SUBSCRIBE, b'WZWorker')
        s.setsockopt(zmq.SUBSCRIBE, bytes(self.name, 'utf-8'))
        self.sig_sock = s

        s = self.ctx.socket(zmq.DEALER)
        self.poller.register(s, zmq.POLLIN)
        s.setsockopt(zmq.IPV6, True)
        self.wz_sock = s

        self.wz = WZHandler()

        def term_handler(i, m, d):
            self.log.info(
                'Termination signal %s recieved',
                repr((i, m, d)))
            self.term()
            raise WorkerInterrupt()
        self.wz.set_sig_handler(b'WZWorker', b'terminate', term_handler)

        def execute_handler(i, m, d):
            if len(d) < 1:
                return
            try:
                exec(d[0].decode('utf-8'))
            except Exception as e:
                self.log.exception(e)
        self.wz.set_sig_handler(b'WZWorker', b'execute', execute_handler)

        def suspend_handler(i, m, d):
            if len(d) != 1:
                self.log.waring('Suspend signal without a time recieved, ignoring')
            self.log.info('Suspend signal %s recieved', repr((i, m, d)))
            try:
                t = int(d[0])
                # raise Suspend(t)
                self.inter_sleep(t)
            except Resume as e:
                self.log.info(e)
            except Exception as e:
                self.log.error(e)
        self.wz.set_sig_handler(b'WZWorker', b'suspend', suspend_handler)

        def resume_handler(i, m, d):
            self.log.info('Resume signal %s recieved', repr((i, m, d)))
            raise Resume()
        self.wz.set_sig_handler(b'WZWorker', b'resume', resume_handler)

        self.running.set()

    def wz_connect(self):
        self.wz_sock.connect(self.wz_addr)

    def wz_wait_reply(self, fun, interface, method, data, reqid=None, timeout=None):
        s, p, t = self.wz_sock, self.poll, self.sleep_ticker
        timeout = timeout if timeout else self.wz_poll_timeout
        rs = wzrpc.RequestState(fun)
        msg = self.wz.make_req_msg(interface, method, data,
                                   rs.accept, reqid)
        msg.insert(0, b'')
        s.send_multipart(msg)
        t.tick()
        while self.running.is_set():
            p(timeout*1000)
            if rs.finished:
                if rs.retry:
                    self.inter_sleep(self.wz_retry_timeout)
                    msg = self.wz.make_req_msg(interface, method, data,
                        rs.accept, reqid)
                    msg.insert(0, b'')
                    s.send_multipart(msg)
                    rs.finished = False
                    rs.retry = False
                    continue
                return
            elapsed = t.elapsed(False)
            if elapsed >= timeout:
                t.tick()
                # Notify fun about the timeout
                rs.accept(None, 0, 255, [elapsed])
                # fun sets rs.retry = True if it wants to retry
        raise WorkerInterrupt()

    def wz_multiwait(self, requests):
        # TODO: rewrite the retry loop
        s, p, t = self.wz_sock, self.poll, self.sleep_ticker
        timeout = self.wz_poll_timeout
        rslist = []
        msgdict = {}
        for request in requests:
            rs = wzrpc.RequestState(request[0])
            rslist.append(rs)
            msg = self.wz.make_req_msg(request[1][0], request[1][1], request[1][2],
                                    rs.accept, request[1][3])
            msg.insert(0, b'')
            msgdict[rs] = msg
            s.send_multipart(msg)
        while self.running.is_set():
            flag = 0
            for rs in rslist:
                if rs.finished:
                    if not rs.retry:
                        del msgdict[rs]
                        continue
                    s.send_multipart(msgdict[rs])
                    rs.finished = False
                    rs.retry = False
                flag = 1
            if not flag:
                return
            # check rs before polling, since we don't want to notify finished one
            # about the timeout
            t.tick()
            p(timeout*1000)
            if t.elapsed(False) >= timeout:
                for rs in rslist:
                    if not rs.finished:
                        rs.accept(None, 0, 255, []) # Notify fun about the timeout
                        rs.finished = True # fun sets rs.retry = True if it wants to retry
        raise WorkerInterrupt()

    def auth_requests(self):
        for i, m in self.wz_auth_requests:
            def accept(that, reqid, seqnum, status, data):
                if status == wzrpc.status.success:
                    self.log.debug('Successfull auth for (%s, %s)', i, m)
                elif status == wzrpc.status.e_auth_wrong_hash:
                    raise exceptions.PermanentError(
                        'Cannot authentificate for ({0}, {1}), {2}: {3}'.\
                        format(i, m, wzrpc.name_status(status), repr(data)))
                elif wzrpc.status.e_timeout:
                    self.log.warn('Timeout {0}, retrying'.format(data[0]))
                    that.retry = True
                else:
                    self.log.warning('Recvd unknown reply for (%s, %s) %s: %s', i, m,
                        wzrpc.name_status(status), repr(data))
            self.wz_wait_reply(accept,
                *self.wz.make_auth_req_data(i, m, wzauth_data.request[i, m]))


    def bind_route(self, i, m, f):
        self.log.debug('Binding %s,%s route', i, m)
        def accept(that, reqid, seqnum, status, data):
            if status == wzrpc.status.success:
                self.wz.set_req_handler(i, m, f)
                self.log.debug('Succesfully binded route (%s, %s)', i, m)
            elif status == wzrpc.status.e_req_denied:
                self.log.warn('Status {0}, reauthentificating'.\
                    format(wzrpc.name_status(status)))
                self.auth_requests()
            elif wzrpc.status.e_timeout:
                self.log.warn('Timeout {0}, retrying'.format(data[0]))
                that.retry = True
            else:
                self.log.warn('Status {0}, retrying'.format(wzrpc.name_status(status)))
                that.retry = True
        return self.wz_wait_reply(accept,
                *self.wz.make_auth_bind_route_data(i, m, wzauth_data.bind_route[i, m]))

    def set_route_type(self, i, m, t):
        self.log.debug('Setting %s,%s type to %d', i, m, t)
        def accept(that, reqid, seqnum, status, data):
            if status == wzrpc.status.success:
                self.log.debug('Succesfully set route type for (%s, %s) to %s', i, m,
                    wzrpc.name_route_type(t))
            elif status == wzrpc.status.e_req_denied:
                self.log.warn('Status {0}, reauthentificating'.\
                    format(wzrpc.name_status(status)))
                self.auth_requests()
            else:
                self.log.warn('Status {0}, retrying'.format(wzrpc.name_status(status)))
                that.retry = True
        return self.wz_wait_reply(accept,
            *self.wz.make_auth_set_route_type_data(i, m, t,
                wzauth_data.set_route_type[i, m]))

    def unbind_route(self, i, m):
        if not (i, m) in self.wz.req_handlers:
            self.log.debug('Route %s,%s was not bound', i, m)
            return
        self.log.debug('Unbinding route %s,%s', i, m)
        self.wz.del_req_handler(i, m)
        def accept(that, reqid, seqnum, status, data):
            if status == wzrpc.status.success:
                self.log.debug('Route unbinded for (%s, %s)', i, m)
            else:
                self.log.warn('Status %s, passing', wzrpc.name_status(status))
        return self.wz_wait_reply(accept,
            *self.wz.make_auth_unbind_route_data(i, m, wzauth_data.bind_route[i, m]))

    def clear_auth(self):
        self.log.debug('Clearing our auth records')
        def accept(that, reqid, seqnum, status, data):
            if status == wzrpc.status.success:
                self.log.debug('Auth records on router were cleared')
            else:
                self.log.warn('Status %s, passing', wzrpc.name_status(status))
        return self.wz_wait_reply(accept, *self.wz.make_auth_clear_data())

    def bind_methods(self):
        for i, m, f, t in self.wz_bind_methods:
            self.set_route_type(i, m, t)
            self.bind_route(i, m, f)

    def unbind_methods(self):
        for i, m, f, t in self.wz_bind_methods:
            self.unbind_route(i, m)
        # self.clear_auth()

    def send_rep(self, reqid, seqnum, status, data):
        self.wz_sock.send_multipart(
            self.wz.make_router_rep_msg(reqid, seqnum, status, data))

    def send_success_rep(self, reqid, data):
        self.send_rep(reqid, 0, wzrpc.status.success, data)

    def send_error_rep(self, reqid, data):
        self.send_rep(reqid, 0, wzrpc.status.error, data)

    def send_wz_error(self, reqid, data, seqid=0):
        msg = self.wz.make_dealer_rep_msg(
            reqid, seqid, wzrpc.status.error, data)
        self.wz_sock.send_multipart(msg)

    def send_to_router(self, msg):
        msg.insert(0, b'')
        self.wz_sock.send_multipart(msg)
    
    # def bind_sig_route(self, routetype, interface, method, fun):
    #     self.log.info('Binding %s,%s as type %d signal route',
    #                   interface, method, routetype)
    #     self.wz.set_signal_handler(interface, method, fun)
    #     msg = self.wz.make_dealer_sig_msg(b'Router', b'bind-sig-route',
    #                                       [interface, method],
    #                                       self.accept_ok)
    #     self.wz_sock.send_multipart(msg)

    # def unbind_sig_route(self, interface, method):
    #     self.log.info('Deleting %s,%s signal route', interface, method)
    #     self.wz.del_signal_handler(interface, method)
    #     msg = self.wz.make_dealer_sig_msg(b'Router', b'unbind-sig-route',
    #                                       [interface, method],
    #                                       self.accept_ok)
    #     self.wz_sock.send_multipart(msg)

    def inter_sleep(self, timeout):
        self.sleep_ticker.tick()
        while self.sleep_ticker.elapsed(False) < timeout:
            try:
                self.poll(timeout * 1000)
            except Resume:
                return

    def poll(self, timeout=None):
        try:
            socks = dict(self.poller.poll(timeout if timeout is not None
                else self.poll_timeout))
        except zmq.ZMQError as e:
            self.log.error(e)
            return
        if socks.get(self.sig_sock) == zmq.POLLIN:
            # No special handling or same-socket replies are necessary for signals.
            # Backwards socket replies may be added here.
            frames = self.sig_sock.recv_multipart()
            try:
                self.wz.parse_msg(frames[0], frames[1:])
            except wzrpc.WZError as e:
                self.log.warn(e)
        if socks.get(self.wz_sock) == zmq.POLLIN:
            self.process_wz_msg(self.wz_sock.recv_multipart())
        return socks

    def process_wz_msg(self, frames):
        try:
            for nfr in self.wz.parse_router_msg(frames):
                # Send replies from the handler, for cases when its methods were rewritten
                self.wz_sock.send_multipart(nfr)
        except wzrpc.WZErrorRep as e:
            self.log.info(e)
            self.wz_sock.send_multipart(e.rep_msg)
        except wzrpc.WZError as e:
            self.log.warn(e)

    def run(self):
        self.__sinit__()
        if self.start_timer:
            self.inter_sleep(self.start_timer)
        if self.running:
            self.log.info('Starting')
            try:
                self.child = self.call[0](*self.call[1], **self.call[2])
                self.child(self)
            except WorkerInterrupt as e:
                self.log.warn(e)
            except Exception as e:
                self.log.exception(e)
            self.log.info('Terminating')
        else:
            self.log.info('Aborted')
        self.running.set() # wz_multiwait needs this to avoid another state check.
        self.unbind_methods()
        self.running.clear()
        self.wz_sock.close()
        self.sig_sock.close()

    def term(self):
        self.running.clear()


class WZWorkerThread(WZWorkerBase, threading.Thread):
    def start(self, ctx, sig_addr, *args, **kvargs):
        self.ctx = ctx
        self.sig_addr = sig_addr
        threading.Thread.start(self, *args, **kvargs)

class WZWorkerProcess(WZWorkerBase, multiprocessing.Process):
    def start(self, sig_addr, *args, **kvargs):
        self.sig_addr = sig_addr
        multiprocessing.Process.start(self, *args, **kvargs)

    def __sinit__(self):
        self.ctx = zmq.Context()
        super().__sinit__()
/n/n/nunistart.py/n/n#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# -*- mode: python -*-
import sys
if 'lib' not in sys.path:
    sys.path.append('lib')
import os, signal, logging, threading, re, traceback, time
import random
import zmq
from queue import Queue
import sup
import wzworkers as workers
from dataloader import DataLoader
from uniwipe import UniWipe
from wipeskel import *
import wzrpc
from beon import regexp
import pickle

from logging import config
from logconfig import logging_config
config.dictConfig(logging_config)
logger = logging.getLogger()

ctx = zmq.Context()
sig_addr = 'ipc://signals'
sig_sock = ctx.socket(zmq.PUB)
sig_sock.bind(sig_addr)

# Settings for you
domains = set() # d.witch_domains
targets = dict() # d.witch_targets
protected = set() # will be removed later
forums = dict() # target forums

# from lib import textgen
# with open('data.txt', 'rt') as f:
#     model = textgen.train(f.read())
# def mesasge():
#     while True:
#         s = textgen.generate_sentence(model)
#         try:
#             s.encode('cp1251')
#             break
#         except Exception:
#             continue
#     return s

def message():
    msg = []
    # msg.append('[video-youtube-'+
    #            random.choice(('3odl-KoNZwk', 'bu55q_3YtOY', '4YPiCeLwh5o',
    #                           'eSBybJGZoCU', 'ZtWTUt2RZh0', 'VXa9tXcMhXQ',))
    #            +']')
    msg.append('[image-original-none-http://simg4.gelbooru.com/'
               + '/images/db/1d/db1dfb62a40f5ced2043bb8966da9a98.png]')
    msg.append('     .')
    # msg.append('[video-youtube-'+random.choice(
    #     # ('WdDb_RId-xU', 'EFL1-fL-WtM', 'uAOoiIkFQq4',
    #     #  'eZO3K_4yceU', '1c1lT_HgJNo', 'WOkvVVaJ2Ks',
    #     #  'KYq90TEdxIE', 'rWBM2whL0bI', '0PDy_MKYo4A'))
    #     #('GabBLLOT6vw', 'qgvOpSquCAY', 'zUe-z9DZBNo', '4fCbfDEKZss', 'uIE-JgmkmdM'))
    #     ('42JQYPioVo4', 'jD6j072Ep1M', 'mPyF5ovoIVs', 'cEEi1BHycb0', 'PuA1Wf8nkxw',
    #      'ASJ9qlsPgHU', 'DP1ZDW9_xOo', 'bgSqH9LT-mI', ))
    # +']')
    # http://simg2.gelbooru.com//images/626/58ca1c9a8ffcdedd0e2eb6f33c9389cb7588f0d1.jpg
    # msg.append('Enjoy the view!')
    msg.append(str(random.randint(0, 9999999999)))
    return '\n'.join(msg)

def sbjfun():
    # return 'Out of the darkness we will rise, into the light we will dwell'
    return sup.randstr(1, 30)

# End
import argparse

parser = argparse.ArgumentParser(add_help=True)
parser.add_argument('--only-cache', '-C', action='store_true',
    help=""Disables any requests in DataLoader (includes Witch)"")
parser.add_argument('--no-shell', '-N', action='store_true',
    help=""Sleep instead of starting the shell"")
parser.add_argument('--tcount', '-t', type=int, default=10,
    help='WipeThread count')
parser.add_argument('--ecount', '-e', type=int, default=0,
    help='EvaluatorProxy count')
parser.add_argument('--upload-avatar', action='store_true', default=False,
    help='Upload random avatar after registration')
parser.add_argument('--av-dir', default='randav', help='Directory with avatars')
parser.add_argument('--rp-timeout', '-T', type=int, default=10,
    help='Default rp timeout in seconds')
parser.add_argument('--conlimit', type=int, default=3,
    help='http_request conlimit')
parser.add_argument('--noproxy-timeout', type=int, default=5,
    help='noproxy_rp timeout')

parser.add_argument('--caprate_minp', type=int, default=5,
    help='Cap rate minimum possible count for limit check')
parser.add_argument('--caprate_limit', type=float, default=0.8,
    help='Captcha rate limit')

parser.add_argument('--comment_successtimeout', type=float, default=0.8,
    help='Comment success timeout')
parser.add_argument('--topic_successtimeout', type=float, default=0.1,
    help='Topic success timeout')
parser.add_argument('--errortimeout', type=float, default=3,
    help='Error timeout')


parser.add_argument('--stop-on-closed', action='store_true', default=False,
    help='Forget about closed topics')
parser.add_argument('--die-on-neterror', action='store_true', default=False,
    help='Terminate spawn in case of too many NetErrors')

c = parser.parse_args()

# rps = {}

noproxy_rp = sup.net.RequestPerformer()
noproxy_rp.proxy = ''
noproxy_rp.timeout = c.noproxy_timeout
noproxy_rp.timeout = c.rp_timeout

# rps[''] = noproxy_rp

# Achtung: DataLoader probably isn't thread-safe.
d = DataLoader(noproxy_rp, c.only_cache)
c.router_addr = d.addrs['rpcrouter']
noproxy_rp.useragent = random.choice(d.ua_list)

def terminate():
    logger.info('Shutdown initiated')
    # send_passthrough([b'GLOBAL', b'WZWorker', b'terminate'])
    send_to_wm([b'GLOBAL', b'WZWorker', b'terminate'])
    for t in threading.enumerate():
        if isinstance(t, threading.Timer):
            t.cancel()
    # try:
    #     wm.term()
    #     wm.join()
    # except: # WM instance is not created yet.
    #     pass
    logger.info('Exiting')

def interrupt_handler(signal, frame):
    pass # Just do nothing

def terminate_handler(signal, frame):
    terminate()

signal.signal(signal.SIGINT, interrupt_handler)
signal.signal(signal.SIGTERM, terminate_handler)

def make_net(proxy, proxytype):
    # if proxy in rps:
    #     return rps[proxy]
    net = sup.net.RequestPerformer()
    net.proxy = proxy
    if proxytype == 'HTTP' or proxytype == 'HTTPS':
        net.proxy_type = sup.proxytype.http
    elif proxytype == 'SOCKS4':
        net.proxy_type = sup.proxytype.socks4
    elif proxytype == 'SOCKS5':
        net.proxy_type = sup.proxytype.socks5
    else:
        raise TypeError('Invalid proxytype %s' % proxytype)
    # rps[proxy] = net
    net.useragent = random.choice(d.ua_list)
    net.timeout = c.rp_timeout
    return net

# UniWipe patching start
def upload_avatar(self, ud):
    if ('avatar_uploaded' in ud[0] and
        ud[0]['avatar_uploaded'] is True):
        return
    files = []
    for sd in os.walk(c.av_dir):
        files.extend(sd[2])
    av = os.path.join(sd[0], random.choice(files))
    self.log.info('Uploading %s as new avatar', av)
    self.site.uploadavatar('0', av)
    ud[0]['avatar'] = av
    ud[0]['avatar_uploaded'] = True

from lib.mailinator import Mailinator
# from lib.tempmail import TempMail as Mailinator

# Move this to WipeManager
def create_spawn(proxy, proxytype, pc, uq=None):
    for domain in domains:
        if domain in targets:
            tlist = targets[domain]
        else:
            tlist = list()
            targets[domain] = tlist
        if domain in forums:
            fset = forums[domain]
        else:
            fset = set()
            forums[domain] = fset
        net = make_net(proxy, proxytype)
        net.cookiefname = (proxy if proxy else 'noproxy')+'_'+domain
        w = UniWipe(fset, tlist, sbjfun, message, pc, net, domain, Mailinator,
            uq(domain) if uq else None)
        w.stoponclose = c.stop_on_closed
        w.die_on_neterror = c.die_on_neterror
        w.caprate_minp = c.caprate_minp
        w.caprate_limit = c.caprate_limit
        w.conlimit = c.conlimit
        w.comment_successtimeout = 0.2
        if c.upload_avatar:
            w.hooks['post_login'].append(upload_avatar)
        yield w

# UniWipe patching end

class WipeManager:
    def __init__(self, config, *args, **kvargs):
        super().__init__(*args, **kvargs)
        self.newproxyfile = 'newproxies.txt'
        self.proxylist = set()
        self.c = config
        self.threads = []
        self.processes = []
        self.th_sa = 'inproc://wm-wth.sock'
        self.th_ba = 'inproc://wm-back.sock'
        self.pr_sa = 'ipc://wm-wpr.sock'
        self.pr_ba = 'ipc://wm-back.sock'
        self.userqueues = {}
        self.usersfile = 'wm_users.pickle'
        self.targetsfile = 'wm_targets.pickle'
        self.bumplimitfile = 'wm_bumplimit.pickle'

    def init_th_sock(self):
        self.log.info(
            'Initializing intraprocess signal socket %s', self.th_sa)
        self.th_sock = self.p.ctx.socket(zmq.PUB)
        self.th_sock.bind(self.th_sa)

    def init_th_back_sock(self):
        self.log.info(
            'Initializing intraprocess backward socket %s', self.th_ba)
        self.th_back_sock = self.p.ctx.socket(zmq.ROUTER)
        self.th_back_sock.bind(self.th_ba)

    def init_pr_sock(self):
        self.log.info(
            'Initializing interprocess signal socket %s', self.pr_sa)
        self.pr_sock = self.p.ctx.socket(zmq.PUB)
        self.pr_sock.bind(self.pr_sa)

    def init_pr_back_sock(self):
        self.log.info(
            'Initializing interprocess backward socket %s', self.pr_ba)
        self.pr_back_sock = self.p.ctx.socket(zmq.ROUTER)
        self.pr_back_sock.bind(self.pr_ba)

    def read_newproxies(self):
        if not os.path.isfile(self.newproxyfile):
            return
        newproxies = set()
        with open(self.newproxyfile, 'rt') as f:
            for line in f:
                try:
                    line = line.rstrip('\n')
                    proxypair = tuple(line.split(' '))
                    if len(proxypair) < 2:
                        self.log.warning('Line %s has too few spaces', line)
                        continue
                    if len(proxypair) > 2:
                        self.log.debug('Line %s has too much spaces', line)
                        proxypair = (proxypair[0], proxypair[1])
                    newproxies.add(proxypair)
                except Exception as e:
                    self.log.exception('Line %s raised exception %s', line, e)
        # os.unlink(self.newproxyfile)
        return newproxies.difference(self.proxylist)

    def add_spawns(self, proxypairs):
        while self.running.is_set():
            try:
                try:
                    proxypair = proxypairs.pop()
                except Exception:
                    return
                self.proxylist.add(proxypair)
                for spawn in create_spawn(proxypair[0], proxypair[1], self.pc,
                        self.get_userqueue):
                    self.log.info('Created spawn %s', spawn.name)
                    self.spawnqueue.put(spawn, False)
            except Exception as e:
                self.log.exception('Exception ""%s"" raised on create_spawn', e)

    def spawn_workers(self, wclass, count, args=(), kvargs={}):
        wname = str(wclass.__name__)
        self.log.info('Starting %s(s)', wname)
        if issubclass(wclass, workers.WZWorkerThread):
            type_ = 0
            if not hasattr(self, 'th_sock'):
                self.init_th_sock()
            if not hasattr(self, 'th_back_sock'):
                self.init_th_back_sock()
        elif issubclass(wclass, workers.WZWorkerProcess):
            type_ = 1
            if not hasattr(self, 'pr_sock'):
                self.init_pr_sock()
            if not hasattr(self, 'pr_back_sock'):
                self.init_pr_back_sock()
        else:
            raise Exception('Unknown wclass type')
        for i in range(count):
            if not self.running.is_set():
                break
            try:
                w = wclass(*args, name='.'.join(
                    (wname, ('pr{0}' if type_ else 'th{0}').format(i))),
                    **kvargs)
                if type_ == 0:
                    self.threads.append(w)
                    w.start(self.p.ctx, self.th_sa)
                elif type_ == 1:
                    self.processes.append(w)
                    w.start(self.pr_sa)
            except Exception as e:
                self.log.exception('Exception ""%s"" raised on %s spawn',
                                   e, wname)

    def spawn_nworkers(self, type_, fun, count, args=(), kvargs={}):
        wname = str(fun.__name__)
        self.log.info('Starting %s(s)', wname)
        if type_ == 0:
            if not hasattr(self, 'th_sock'):
                self.init_th_sock()
            if not hasattr(self, 'th_back_sock'):
                self.init_th_back_sock()
        elif type_ == 1:
            if not hasattr(self, 'pr_sock'):
                self.init_pr_sock()
            if not hasattr(self, 'pr_back_sock'):
                self.init_pr_back_sock()
        else:
            raise Exception('Unknown wclass type')
        for i in range(count):
            if not self.running.is_set():
                break
            try:
                if type_ == 0:
                    w = workers.WZWorkerThread(
                        self.c.router_addr, fun, args, kvargs,
                        name='.'.join((wname, 'th{0}'.format(i))))
                    self.threads.append(w)
                    w.start(self.p.ctx, self.th_sa)
                elif type_ == 1:
                    w = workers.WZWorkerProcess(self.c.router_addr, fun, args, kvargs,
                        name='.'.join((wname, 'pr{0}'.format(i))))
                    self.processes.append(w)
                    w.start(self.pr_sa)
            except Exception as e:
                self.log.exception('Exception ""%s"" raised on %s spawn',
                                   e, wname)

    def spawn_wipethreads(self):
        return self.spawn_nworkers(0, WipeThread, self.c.tcount,
                                  (self.pc, self.spawnqueue))

    def spawn_evaluators(self):
        self.log.info('Initializing Evaluator')
        from evproxy import EvaluatorProxy
        def ev_init():
            from lib.evaluators.PyQt4Evaluator import Evaluator
            return Evaluator()
        return self.spawn_nworkers(1, EvaluatorProxy, self.c.ecount,
                                  (ev_init,))

    def load_users(self):
        if not os.path.isfile(self.usersfile):
            return
        with open(self.usersfile, 'rb') as f:
            users = pickle.loads(f.read())
        try:
            for domain in users.keys():
                uq = Queue()
                for ud in users[domain]:
                    self.log.debug('Loaded user %s:%s', domain, ud['login'])
                    uq.put(ud)
                self.userqueues[domain] = uq
        except Exception as e:
            self.log.exception(e)
            self.log.error('Failed to load users')

    def save_users(self):
        users = {}
        for d, uq in self.userqueues.items():
            uqsize = uq.qsize()
            uds = []
            for i in range(uqsize):
                uds.append(uq.get(False))
            users[d] = uds
        with open(self.usersfile, 'wb') as f:
            f.write(pickle.dumps(users, pickle.HIGHEST_PROTOCOL))
        self.log.info('Saved users')

    def get_userqueue(self, domain):
        try:
            uq = self.userqueues[domain]
        except KeyError:
            self.log.info('Created userqueue for %s', domain)
            uq = Queue()
            self.userqueues[domain] = uq
        return uq

    def load_targets(self):
        fname = self.targetsfile
        if not os.path.isfile(fname):
            return
        with open(fname, 'rb') as f:
            data = pickle.loads(f.read())
        if 'targets' in data:
            self.log.debug('Target list was loaded')
            targets.update(data['targets'])
        if 'forums' in data:
            self.log.debug('Forum set was loaded')
            forums.update(data['forums'])
        if 'domains' in data:
            self.log.debug('Domain set was loaded')
            domains.update(data['domains'])
        if 'sets' in data:
            self.log.debug('Other sets were loaded')
            self.pc.sets.update(data['sets'])

    def load_bumplimit_set(self):
        if not os.path.isfile(self.bumplimitfile):
            return
        with open(self.bumplimitfile, 'rb') as f:
            self.pc.sets['bumplimit'].update(pickle.loads(f.read()))

    def save_targets(self):
        data = {
            'targets': targets,
            'forums': forums,
            'domains': domains,
            'sets': self.pc.sets,
        }
        with open(self.targetsfile, 'wb') as f:
            f.write(pickle.dumps(data, pickle.HIGHEST_PROTOCOL))

    def targets_from_witch(self):
        for t in d.witch_targets:
            if t['domain'] == 'beon.ru' and t['forum'] == 'anonymous':
                try:
                    add_target_exc(t['id'], t['user'])
                except ValueError:
                    pass

    def terminate(self):
        msg = [b'GLOBAL']
        msg.extend(wzrpc.make_sig_msg(b'WZWorker', b'terminate', []))
        if hasattr(self, 'th_sock'):
            self.th_sock.send_multipart(msg)
        if hasattr(self, 'pr_sock'):
            self.pr_sock.send_multipart(msg)

    def join_threads(self):
        for t in self.threads:
            t.join()

    def send_passthrough(self, interface, method, frames):
        msg = [frames[0]]
        msg.extend(wzrpc.make_sig_msg(frames[1], frames[2], frames[3:]))
        self.th_sock.send_multipart(msg)
        self.pr_sock.send_multipart(msg)

    def __call__(self, parent):
        self.p = parent
        self.log = parent.log
        self.inter_sleep = parent.inter_sleep
        self.running = parent.running
        self.p.sig_sock.setsockopt(zmq.SUBSCRIBE, b'WipeManager')
        self.p.wz.set_sig_handler(b'WipeManager', b'passthrough', self.send_passthrough)
        if self.c.tcount > 0:
            self.pc = ProcessContext(self.p.name, self.p.ctx,
                self.c.router_addr, noproxy_rp)
            self.spawnqueue = Queue()
            self.load_bumplimit_set()
            self.load_targets()
            self.load_users()
            self.spawn_wipethreads()
        if self.c.ecount > 0:
            self.spawn_evaluators()
        try:
            while self.running.is_set():
                # self.targets_from_witch()
                if self.c.tcount == 0:
                    self.inter_sleep(5)
                    continue
                self.pc.check_waiting()
                new = self.read_newproxies()
                if not new:
                    self.inter_sleep(5)
                    continue
                self.add_spawns(new)
        except WorkerInterrupt:
            pass
        except Exception as e:
            self.log.exception(e)
        self.terminate()
        self.join_threads()
        if self.c.tcount > 0:
            self.save_users()
            self.save_targets()

wm = workers.WZWorkerThread(c.router_addr, WipeManager, (c,),
    name='SpaghettiMonster')
wm.start(ctx, sig_addr)

def add_target(domain, id_, tuser=None):
    if domain not in targets:
        targets[domain] = []
    tlist = targets[domain]
    id_ = str(id_)
    tuser = tuser or ''
    t = (tuser, id_)
    logger.info('Appending %s to targets[%s]', repr(t), domain)
    tlist.append(t)

def remove_target(domain, id_, tuser=None):
    tlist = targets[domain]
    id_ = str(id_)
    tuser = tuser or ''
    t = (tuser, id_)
    logger.info('Removing %s from targets[%s]', repr(t), domain)
    tlist.remove(t)

def add_target_exc(domain, id_, tuser=None):
    if domain not in targets:
        targets[domain] = []
    tlist = targets[domain]
    id_ = str(id_)
    tuser = tuser or ''
    t = (tuser, id_)
    if t in protected:
        raise ValueError('%s is protected' % repr(t))
    if t not in tlist:
        logger.info('Appending %s to targets[%s]', repr(t), domain)
        tlist.append(t)

r_di = re.compile(regexp.f_udi)

def atfu(urls):
    for user, domain, id1, id2 in r_di.findall(urls):
        id_ = id1+id2
        add_target(domain, id_, user)

def rtfu(urls):
    for user, domain, id1, id2 in r_di.findall(urls):
        id_ = id1+id2
        remove_target(domain, id_, user)

def get_forum_id(name):
    id_ = d.bm_id_forum.get_key(name)
    int(id_, 10)  # id is int with base 10
    return id_

# def aftw(name):
#     id_ = get_forum_id(name)
#     logger.info('Appending %s (%s) to forums', name, id_)
#     forums.append(id_)

# def rffw(name):
#     id_ = get_forum_id(name)
#     logger.info('Removing %s (%s) from forums', name, id_)
#     forums.remove(id_)

# def aftw(name):
#     id_ = get_forum_id(name)
#     logger.info('Appending %s to forums', name)
#     forums.add(name)

# def rffw(name):
#     id_ = get_forum_id(name)
#     logger.info('Removing %s from forums', name)
#     forums.remove(name)

r_udf = re.compile(regexp.udf_prefix)

def affu(urls):
    for user, domain, forum in r_udf.findall(urls):
        if domain not in forums:
            forums[domain] = set()
        if len(forum) > 0:
            get_forum_id(forum)
        logger.info('Appending %s:%s to forums[%s]', user, forum, domain)
        forums[domain].add((user, forum))

def rffu(urls):
    for user, domain, forum in r_udf.findall(urls):
        if len(forum) > 0:
            get_forum_id(forum)
        logger.info('Removing %s:%s from forums[%s]', user, forum, domain)
        forums[domain].remove((user, forum))

def add_user(domain, login, passwd):
    uq = wm.get_userqueue(domain)
    uq.put({'login': login, 'passwd': passwd}, False)

def send_to_wm(frames):
    msg = [frames[0]]
    msg.extend(wzrpc.make_sig_msg(frames[1], frames[2], frames[3:]))
    sig_sock.send_multipart(msg)

def send_passthrough(frames):
    msg = [b'WipeManager']
    msg.extend(wzrpc.make_sig_msg(b'WipeManager', b'passthrough', frames))
    sig_sock.send_multipart(msg)

def get_pasted_lines(sentinel):
    'Yield pasted lines until the user enters the given sentinel value.'
    print(""Pasting code; enter '{0}' alone on the line to stop."".format(sentinel))
    while True:
        l = input(':')
        if l == sentinel:
            return
        else:
            yield l

def send_execute_to_wm(code):
    msg = [b'WipeManager']
    msg.extend((b'WZWorker', b'execute', code))
    send_to_wm(msg)

def send_execute_to_ev(code):
    msg = [b'EVProxy']
    msg.extend((b'WZWorker', b'execute', code))
    send_passthrough(msg)

def send_execute(name, code):
    msg = [name.encode('utf-8')]
    msg.extend((b'WZWorker', b'execute', code))
    send_passthrough(msg)

def pexecute_in(name):
    send_execute(name, '\n'.join(get_pasted_lines('--')).encode('utf-8'))

def pexecute_in_wm():
    send_execute_to_wm('\n'.join(get_pasted_lines('--')).encode('utf-8'))

def pexecute_in_ev():
    send_execute_to_ev('\n'.join(get_pasted_lines('--')).encode('utf-8'))

def drop_users():
    send_passthrough([b'WipeSkel', b'WipeSkel', b'drop-user'])

def log_spawn_name():
    send_passthrough([b'WipeThread', b'WipeThread', b'log-spawn-name'])

try:
    import IPython
    if c.no_shell:
        IPython.embed_kernel()
    else:
        IPython.embed()
except ImportError:
    # fallback shell
    if c.no_shell:
        while True:
            time.sleep(1)
    else:
        while True:
            try:
                exec(input('> '))
            except KeyboardInterrupt:
                print(""KeyboardInterrupt"")
            except SystemExit:
                break
            except:
                print(traceback.format_exc())

terminate()
/n/n/nuniwipe.py/n/n# -*- coding: utf-8 -*-
# -*- mode: python -*-
from sup.net import NetError
from wzworkers import WorkerInterrupt
from wipeskel import WipeSkel, WipeState, cstate
from beon import exc, regexp
from collections import ChainMap
import re

class UniWipe(WipeSkel):
    def __init__(self, forums, targets, sbjfun, msgfun, *args, **kvargs):
        self.sbjfun = sbjfun
        self.msgfun = msgfun
        self.forums = forums
        self.targets = (type(targets) == str and [('', targets)]
                        or type(targets) == tuple and list(targets)
                        or targets)
        super().__init__(*args, **kvargs)
        self.ignore_map = ChainMap(
            self.pc.sets['closed'], self.pc.sets['bumplimit'],
            self.pc.sets['bugged'], self.pc.sets['protected'],
            self.targets)

    def on_caprate_limit(self, rate):
        if not self.logined:
            self._capdata = (0, 0)
            return
        self.log.warning('Caprate limit reached, calling dologin() for now')
        self.dologin()
        # super().on_caprate_limit(rate)

    def comment_loop(self):
        for t in self.targets:
            self.schedule(self.add_comment, (t, self.msgfun()))
        if len(self.targets) == 0:
            self.schedule(self.scan_targets_loop)
        else:
            self.schedule(self.comment_loop)

    def add_comment(self, t, msg):
        # with cstate(self, WipeState.posting_comment):
        if True: # Just a placeholder
            try:
                # self.counter_tick()
                self.postmsg(t[1], msg, t[0])
            except exc.Success as e:
                self.counters['comments'] += 1
                self.w.sleep(self.comment_successtimeout)
            except exc.Antispam as e:
                self.w.sleep(self.comment_successtimeout)
                self.schedule(self.add_comment, (t, msg))
            except (exc.Closed, exc.UserDeny) as e:
                try:
                    self.targets.remove(t)
                except ValueError:
                    pass
                self.w.sleep(self.comment_successtimeout)
            except exc.Captcha as e:
                self.log.error('Too many wrong answers to CAPTCHA')
                self.schedule(self.add_comment, (t, msg))
            except exc.UnknownAnswer as e:
                self.log.warn('%s: %s', e, e.answer)
                self.schedule(self.add_comment, (t, msg))
            except exc.Wait5Min as e:
                self.schedule(self.add_comment, (t, msg))
                self.schedule_first(self.switch_user)
            except exc.EmptyAnswer as e:
                self.log.info('Removing %s from targets and adding to bugged', t)
                self.pc.sets['bugged'].add(t)
                try:
                    self.targets.remove(t)
                except ValueError as e:
                    pass
                self.w.sleep(self.errortimeout)
            except exc.TopicDoesNotExist as e:
                self.log.info('Removing %s from targets and adding to bugged', t)
                self.pc.sets['bugged'].add(t)
                try:
                    self.targets.remove(t)
                except ValueError as e:
                    pass
                self.w.sleep(self.errortimeout)
            except exc.TemporaryError as e:
                self.schedule(self.add_comment, (t, msg))
                self.w.sleep(self.errortimeout)
            except exc.PermanentError as e:
                try:
                    self.targets.remove(t)
                except ValueError as e:
                    pass
                self.w.sleep(self.errortimeout)
            except UnicodeDecodeError as e:
                self.log.exception(e)
                self.w.sleep(self.errortimeout)

    def forumwipe_loop(self):
        for f in self.forums.copy():
            self.counter_tick()
            try:
                self.addtopic(self.msgfun(), self.sbjfun(), f)
            except exc.Success as e:
                self.counters['topics'] += 1
                self.w.sleep(self.topic_successtimeout)
            except exc.Wait5Min as e:
                self.topic_successtimeout = self.topic_successtimeout + 0.1
                self.log.info('Wait5Min exc caught, topic_successtimeout + 0.1, cur: %f',
                    self.topic_successtimeout)
                self.w.sleep(self.topic_successtimeout)
            except exc.Captcha as e:
                self.log.error('Too many wrong answers to CAPTCHA')
                self.long_sleep(10)
            except exc.UnknownAnswer as e:
                self.log.warning('%s: %s', e, e.answer)
                self.w.sleep(self.errortimeout)
            except exc.PermanentError as e:
                self.log.error(e)
                self.w.sleep(self.errortimeout)
            except exc.TemporaryError as e:
                self.log.warn(e)
                self.w.sleep(self.errortimeout)

    def get_targets(self):
        found_count = 0
        for user, forum in self.forums:
            targets = []
            self.log.debug('Scanning first page of the forum %s:%s', user, forum)
            page = self.site.get_page('1', forum, user)
            rxp = re.compile(regexp.f_sub_id.format(user, self.site.domain, forum))
            found = set(map(lambda x: (user, x[0]+x[1]), rxp.findall(page)))
            for t in found:
                if t in self.ignore_map:
                    continue
                targets.append(t)
            lt = len(targets)
            found_count += lt
            if lt > 0:
                self.log.info('Found %d new targets in forum %s:%s', lt, user, forum)
            else:
                self.log.debug('Found no new targets in forum %s:%s', user, forum)
            self.targets.extend(targets)
        return found_count

    def scan_targets_loop(self):
        with cstate(self, WipeState.scanning_for_targets):
            while len(self.targets) == 0:
                c = self.get_targets()
                if c == 0:
                    self.log.info('No targets found at all, sleeping for 30 seconds')
                    self.long_sleep(30)
            self.schedule(self.comment_loop)
        if len(self.forums) == 0:
            self.schedule(self.wait_loop)

    def wait_loop(self):
        if len(self.targets) > 0:
            self.schedule(self.comment_loop)
            return
        if len(self.forums) == 0:
            with cstate(self, WipeState.waiting_for_targets):
                while len(self.forums) == 0:
                    # To prevent a busy loop.
                    self.counter_tick()
                    self.w.sleep(1)
        self.schedule(self.scan_targets_loop)

    def _run(self):
        self.schedule(self.dologin)
        self.schedule(self.wait_loop)
        self.schedule(self.counter_ticker.tick)
        try:
            self.perform_tasks()
        except NetError as e:
            self.log.error(e)
        except WorkerInterrupt as e:
            self.log.warning(e)
        except Exception as e:
            self.log.exception(e)
        self.return_user()
# tw_flag = False
# if len(self.targets) > 0:
#     with cstate(self, WipeState.posting_comment):
#         while len(self.targets) > 0:
#             self.threadwipe_loop()
#     if not tw_flag:
#         tw_flag = True
# if tw_flag:
#     # Sleep for topic_successtimeout after last comment
#     # to prevent a timeout spike
#     self.w.sleep(self.topic_successtimeout)
#     tw_flag = False
# with cstate(self, WipeState.posting_topic):
# self.forumwipe_loop()
/n/n/nwipeskel.py/n/n# -*- coding: utf-8 -*-
# -*- mode: python -*-
import logging, re
from queue import Queue, Empty
import zmq
import beon, sup, wzrpc
from beon import regexp
from wzworkers import WorkerInterrupt
from ocr import OCRError, PermOCRError, TempOCRError
from sup.ticker import Ticker
from userdata import short_wordsgen
from enum import Enum
from collections import Counter, deque

class ProcessContext:
    def __init__(self, name, ctx, wz_addr, noproxy_rp):
        self.log = logging.getLogger('.'.join((name, type(self).__name__)))
        self.zmq_ctx = ctx
        self.ticker = Ticker()
        self.sets = {}
        self.sets['waiting'] = dict()
        self.sets['pending'] = set()

        self.sets['targets'] = set()
        self.sets['closed'] = set()
        self.sets['bumplimit'] = set()
        self.sets['protected'] = set()
        self.sets['bugged'] = set()

        self.wz_addr = wz_addr
        self.noproxy_rp = noproxy_rp

    def make_wz_sock(self):
        self.log.debug('Initializing WZRPC socket')
        wz_sock = self.zmq_ctx.socket(zmq.DEALER)
        wz_sock.setsockopt(zmq.IPV6, True)
        wz_sock.connect(self.wz_addr)
        return wz_sock

    def check_waiting(self):
        elapsed = self.ticker.elapsed()
        waiting = self.sets['waiting']
        for k, v in waiting.copy().items():
            rem = v - elapsed
            if rem <= 0:
                del waiting[k]
                self.log.info('Removing %s from %s', k[0], k[1])
                try:
                    self.sets[k[1]].remove(k[0])
                except KeyError:
                    self.log.error('No %s in %s', k[0], k[1])
            else:
                waiting[k] = rem

    def add_waiting(self, sname, item, ttl):
        self.sets['waiting'][(item, sname)] = ttl

class WTState(Enum):
    null = 0
    starting = 2
    empty = 3
    sleeping = 4
    running = 5

class WipeState(Enum):
    null = 0
    starting = 2
    terminating = 3
    sleeping = 4
    running = 5

    logging_in = 6
    post_login_hooks = 7
    registering = 8
    pre_register_hooks = 9
    post_register_hooks = 10
    deobfuscating_capage = 11
    solving_captcha = 12
    reporting_code = 13

    operation = 50
    waiting_for_targets = 51
    scanning_for_targets = 52
    posting_comment = 53
    posting_topic = 54

class state:
    def __init__(self, defstate):
        self.defstate = defstate
        self.state = defstate

    def __call__(self, state):
        self.state = state
        return self

    def __enter__(self):
        pass

    def __exit__(self, exception_type, exception_value, traceback):
        self.state = self.defstate

    @property
    def name(self):
        return self.state.name

    @property
    def value(self):
        return self.state.value

class cstate:
    def __init__(self, obj, state):
        self.obj = obj
        self.backstate = obj.state
        self.newstate = state

    def __enter__(self):
        self.obj.log.info('Switching state to %s', repr(self.newstate))
        self.obj.state = self.newstate

    def __exit__(self, exception_type, exception_value, traceback):
        self.obj.log.info('Switching state to %s', repr(self.backstate))
        self.obj.state = self.backstate


class WipeThread:
    def __init__(self, pc, spawnqueue, *args, **kvargs):
        self.pc = pc
        self.spawnqueue = spawnqueue
        self.spawn = None
        self.state = WTState.null
        self.wz_reply = None

    def deobfuscate_capage(self, domain, page):
        result = []
        def accept(that, reqid, seqnum, status, data):
            if status == wzrpc.status.success or status == wzrpc.status.error:
                result.extend(map(lambda x: x.decode('utf-8'), data))
            elif status == wzrpc.status.e_req_denied:
                self.log.warn('Status {0}, reauthentificating'.
                    format(wzrpc.name_status(status)))
                self.p.auth_requests()
                that.retry = True
            elif status == wzrpc.status.e_timeout:
                self.log.warn('Timeout {0}, retrying'.format(data[0]))
                that.retry = True
            else:
                self.log.warn('Status {0}, retrying'.format(wzrpc.name_status(status)))
                that.retry = True
        self.p.wz_wait_reply(accept,
            b'Evaluator', b'evaluate', (domain.encode('utf-8'), page.encode('utf-8')),
            timeout=60)
        return tuple(result)

    def solve_captcha(self, img):
        result = []
        def accept(that, reqid, seqnum, status, data):
            if status == wzrpc.status.success or status == wzrpc.status.error:
                result.extend(map(lambda x:x.decode('utf-8'), data))
            elif status == wzrpc.status.e_req_denied:
                self.log.warn('Status {0}, reauthentificating'.\
                    format(wzrpc.name_status(status)))
                self.p.auth_requests()
                that.retry = True
            elif status == wzrpc.status.e_timeout:
                self.log.warn('Timeout {0}, retrying'.format(data[0]))
                that.retry = True
            else:
                self.log.warn('Status {0}, retrying'.format(wzrpc.name_status(status)))
                that.retry = True
        self.p.wz_wait_reply(accept,
            b'Solver', b'solve', (b'inbound', img), timeout=300)
        if len(result) == 2: # Lame and redundant check. Rewrite this part someday.
            return result
        else:
            raise OCRError('Solver returned error %s', result)
        return tuple(result)

    def report_code(self, cid, status):
        def accept(that, reqid, seqnum, status, data):
            if status == wzrpc.status.success:
                self.log.debug('Successfully reported captcha status')
            elif status == wzrpc.status.error:
                self.log.error('Solver returned error on report: %s', repr(data))
            elif status == wzrpc.status.e_req_denied:
                self.log.warn('Status {0}, reauthentificating'.\
                    format(wzrpc.name_status(status)))
                self.p.auth_requests()
            else:
                self.log.warn('Status {0}, retrying'.format(wzrpc.name_status(status)))
                that.retry = True
        self.p.wz_wait_reply(accept,
            b'Solver', b'report', (status.encode('utf-8'), cid.encode('utf-8')))

    def __call__(self, parent):
        self.p = parent
        self.log = parent.log
        self.running = parent.running
        self.sleep = parent.inter_sleep
        self.p.wz_auth_requests = [
            (b'Evaluator', b'evaluate'),
            (b'Solver', b'solve'),
            (b'Solver', b'report')]
        cst = cstate(self, WTState.starting)
        cst.__enter__()
        self.p.sig_sock.setsockopt(zmq.SUBSCRIBE, b'WipeThread')
        def handle_lsn(interface, method, data):
            if hasattr(self, 'spawn') and self.spawn:
                self.log.info('My current spawn is %s, state %s',
                    self.spawn.name, self.spawn.state.name)
            else:
                self.log.debug('Currently I do not have spawn')
        self.p.wz.set_sig_handler(b'WipeThread', b'log-spawn-name', handle_lsn)
        def handle_te(interface, method, data):
            if self.state is WTState.empty:
                self.p.term()
        self.p.wz.set_sig_handler(b'WipeThread', b'terminate-empty', handle_te)

        try:
            self.p.wz_connect()
            self.p.auth_requests()
        except WorkerInterrupt as e:
            self.log.error(e)
            return
        with cstate(self, WTState.empty):
            while self.running.is_set():
                try:
                    self.spawn = self.spawnqueue.get(False)
                except Empty:
                    self.sleep(1)
                    continue
                with cstate(self, WTState.running):
                    try:
                        self.spawn.run(self)
                    except WorkerInterrupt as e:
                        self.log.error(e)
                    except Exception as e:
                        self.log.exception('Spawn throwed exception %s, requesting new', e)
                    del self.spawn
                    self.spawn = None
                    self.spawnqueue.task_done()
        cst.__exit__(None, None, None)

class WipeSkel(object):
    reglimit = 10
    loglimit = 10
    conlimit = 3
    catrymax = 3
    _capdata = (0, 0)
    caprate = 0
    caprate_minp = 10
    caprate_limit = 0.9
    successtimeout = 1
    comment_successtimeout = 0
    topic_successtimeout = 0.8
    counter_report_interval = 60
    errortimeout = 3
    uqtimeout = 5  # Timeout for userqueue
    stoponclose = True
    die_on_neterror = False

    def __init__(self, pc, rp, domain, mrc, userqueue=None):
        self.pc = pc
        self.rp = rp
        self.state = WipeState.null
        self.site = beon.Beon(domain, self.http_request)
        self.name = '.'.join((
            type(self).__name__,
            self.rp.proxy.replace('.', '_') if self.rp.proxy
            else 'noproxy',
            self.site.domain.replace('.', '_')))
        self.rp.default_encoding = 'cp1251'
        self.rp.default_decoding = 'cp1251'
        self.rp.def_referer = self.site.ref  # Referer for net.py
        self.hooks = {
            'pre_register_new_user': [],
            'post_register_new_user': [],
            'post_login': [],
            'check_new_user': [],
        }
        self.counter_ticker = Ticker()
        self.counters = Counter()
        self.task_deque = deque()
        self.logined = False
        self.noproxy_rp = self.pc.noproxy_rp
        self.mrc = mrc
        if userqueue:
            self.userqueue = userqueue
        else:
            self.userqueue = Queue()

    def schedule(self, task, args=(), kvargs={}):
        self.task_deque.appendleft((task, args, kvargs))

    def schedule_first(self, task, args=(), kvargs={}):
        self.task_deque.append((task, args, kvargs))

    def perform_tasks(self):
        with cstate(self, WipeState.running):
            while self.w.running.is_set():
                self.counter_tick()
                try:
                    t = self.task_deque.pop()
                except IndexError:
                    return
                t[0](*t[1], **t[2])

    def long_sleep(self, time):
        time = int(time)
        with cstate(self, WipeState.sleeping):
            step = int(time/10 if time > 10 else 1)
            for s in range(0, time, step):
                self.w.sleep(step)
                self.counter_tick()

    def http_request(self, url, postdata=None, onlyjar=False, referer=None,
                     encoding=None, decoding=None):
        _conc = 0
        while self.w.running.is_set():
            _conc += 1
            try:
                return self.rp.http_req(
                    url, postdata, onlyjar, referer, encoding, decoding)
            except sup.NetError as e:
                if isinstance(e, sup.ConnError):
                    if self.die_on_neterror and _conc > self.conlimit:
                        raise
                    self.log.warn('%s, waiting. t: %s', e.args[0], _conc)
                    self.w.sleep(self.errortimeout)
                else:
                    self.log.error('%d %s', e.ec, e.args[0])
                    if self.die_on_neterror:
                        raise
                    else:
                        self.w.sleep(10)
        else:
            raise WorkerInterrupt()

    def gen_userdata(self):
        return short_wordsgen()

    def update_caprate(self, got):
        p, g = self._capdata
        p += 1
        if got is True:
            self.counters['captchas'] += 1
            g += 1
        if p >= 255:
            p = p/2
            g = g/2
        self._capdata = (p, g)
        self.caprate = g/p
        self.log.debug('Caprate: pos:%f got:%f rate:%f',
                       p, g, self.caprate)
        if (self.caprate_limit > 0
            and p > self.caprate_minp
            and self.caprate > self.caprate_limit):
            self.on_caprate_limit(self.caprate)
            # if self.getuser() == 'guest':
            #     self.log.info(""lol, we were trying to post from guest"")
            #     while not self.relogin(): self.w.sleep(self.errortimeout)
            # else:
            #     while not self.dologin(): self.w.sleep(self.errortimeout)

    def counter_tick(self):
        if self.counter_report_interval == 0:
            return
        e = self.counter_ticker.elapsed(False)
        if e > self.counter_report_interval:
            self.counter_ticker.tick()
            ccount = self.counters['comments']
            tcount = self.counters['topics']
            if ccount > 0:
                self.log.info('%d comments in %d seconds, %0.2f cps, %0.2f caprate',
                    ccount, e, ccount/e, self.caprate)
                self.counters['comments'] = 0
            if tcount > 0:
                self.log.info('%d topics in %d seconds, %0.2f tps, %0.2f caprate',
                    tcount, e, tcount/e, self.caprate)
                self.counters['topics'] = 0

    def on_caprate_limit(self, rate):
        if not self.logined:
            self._capdata = (0, 0)
            return
        self.log.warn('Caprate %f is over the limit', rate)
        raise Exception('Caprate limit reached')

    def captcha_wrapper(self, inc_fun, fin_fun, *args, **kvargs):
        # TODO: report codes after solving cycle instead of scheduling them.
        try:
            self.log.debug('captcha_wrapper: calling inc_fun %s', repr(inc_fun))
            self.log.error('captcha_wrapper: inc_fun returned %s',
                           repr(inc_fun(*args, **kvargs)))
        except beon.Success as e:
            self.update_caprate(False)
            raise
        except beon.Captcha as e:
            self.log.warn(e)
            _page = e.page
            _catry = e.catry
            # Don't update caprate with positives if not logined
            if self.logined is True:
                try:
                    user = self.find_login(_page)
                except beon.PermanentError:
                    self.log.debug(e)
                else:
                    if user != self.site.ud['login']:
                        self.log.warn('We were posting as %s, but our login is %s',
                                      user, self.site.ud['login'])
                        self.schedule_first(self.relogin)
                        return
            self.update_caprate(True)
            reports = []
            def r():
                if len(reports) > 0:
                    with cstate(self, WipeState.reporting_code):
                        for cid, status in reports:
                            self.report_code(cid, status)
                    reports.clear()
            while self.w.running.is_set():
                _requested_new = False
                try:
                    with cstate(self, WipeState.solving_captcha):
                        cahash, cacode, cid = self.solve_captcha(_page)
                except TempOCRError as e:
                    self.log.error('OCRError: %s, retrying', e)
                    self.w.sleep(self.errortimeout)
                    continue
                except OCRError as e:
                    self.log.error('OCRError: %s, requesting new captcha', e)
                    _requested_new = True
                    cahash, cacode, cid = e.cahash, '', None
                else:
                    self.log.info('code: %s', cacode)
                try:
                    self.log.debug('captcha_wrapper calling fin_fun %s', repr(fin_fun))
                    self.log.error('captcha_wrapper: fin_fun returned %s',
                        repr(fin_fun(cahash, cacode, *args, catry=_catry, **kvargs)))
                    break
                except beon.Success as e:
                    self.counters['captchas_solved'] += 1
                    if cid:
                        reports.append((cid, 'good'))
                    r()
                    raise
                except beon.Captcha as e:
                    _catry = e.catry
                    _page = e.page
                    if _requested_new:
                        self.log.warn('New captcha requested c:%d', _catry)
                        continue
                    self.log.warn('%s c:%d', e, _catry)
                    self.counters['captchas_wrong'] += 1
                    if cid:
                        reports.append((cid, 'bad'))
                    if _catry > self.catrymax:
                        r()
                        raise
                except Exception as e:
                    if cid:
                        reports.append((cid, 'bad'))
                    r()
                    raise

    def adaptive_timeout_wrapper(self, fun, *args, **kvargs):
        try:
            return fun(*args, **kvargs)
        except beon.Antispam as e:
            self.log.info('Antispam exc caught, successtimeout + 0.1, cur: %f',
                          self.successtimeout)
            self.successtimeout = self.successtimeout + 0.1
            raise

    def register_new_user(self):
        with cstate(self, WipeState.registering):
            _regcount = 0
            while self.w.running.is_set():
                self.w.p.poll(0)
                ud = self.gen_userdata()
                self.request_email(ud)
                for c in self.hooks['pre_register_new_user']:
                    c(self, ud)
                self.log.info('Generated new userdata: %s, registering', ud['login'])
                self.log.debug('Userdata: %s', repr(ud))
                try:
                    udc = ud.copy()
                    if 0 in udc:
                        del udc[0]
                    self.register(**udc)
                except beon.Success as e:
                    self.validate_email(ud)
                    for c in self.hooks['post_register_new_user']:
                        c(self, ud)
                    return ud
                except (beon.EmptyAnswer, beon.Wait5Min) as e:
                    self.log.error('%s, sleeping for 100 seconds', e)
                    self.long_sleep(100)
                except beon.Captcha as e:
                    self.log.error('Too much wrong answers to CAPTCHA')
                    continue
                except beon.UnknownAnswer as e:
                    _regcount += 1
                    if not _regcount < self.reglimit:
                        raise beon.RegRetryLimit('Cannot register new user')
                    self.log.error('%s, userdata may be invalid, retrying c:%d',
                                e, _regcount)
                    self.w.sleep(self.errortimeout)
            else:
                raise WorkerInterrupt()

    def get_new_user(self):
        ud = self.userqueue.get(True, self.uqtimeout)
        self.userqueue.task_done()
        for c in self.hooks['check_new_user']:
            c(self, ud)
        return ud

    def login(self, login, passwd, **kvargs):
        if not self.site.login_lock.acquire(False):
            with self.site.login_lock.acquire():
                return
        self.logined = False
        try:
            self.captcha_wrapper(self.site.logininc, self.site.loginfin,
                                 login, passwd, **kvargs)
        except beon.Success as e:
            self.logined = True
            self.counters['logged_in'] += 1
            self.log.info(e)
            raise
        finally:
            self.site.login_lock.release()

    def find_login(self, rec):
        try:
            return re.findall(regexp.var_login, rec)[0]
        except IndexError:
            raise beon.PermanentError('No users in here')

    def get_current_login(self):
        return self.find_login(self.site.get_page('1'))

    def dologin(self):
        '''Choose user, do login and return it.'''
        while self.w.running.is_set():
            self.site.ud = None
            try:
                self.site.ud = self.get_new_user()
            except Empty:
                self.log.info('No users in queue')
                self.site.ud = self.register_new_user()
                return
            try:
                with cstate(self, WipeState.logging_in):
                    self.login(self.site.ud['login'], self.site.ud['passwd'])
            except beon.Success as e:
                self.site.postuser = self.site.ud['login']
                self.site.postpass = self.site.ud['passwd']
                self.validate_email(self.site.ud)
                for c in self.hooks['post_login']:
                    c(self, self.site.ud)
                self.w.sleep(self.successtimeout)
                return
            except beon.Captcha as e:
                self.log.error('Too many wrong answers to CAPTCHA')
                self.schedule(self.long_sleep, (10,))
                self.schedule(self.dologin)
            except beon.InvalidLogin as e:
                self.log.error(""Invalid login, passing here"")
                self.schedule(self.dologin)
                self.w.sleep(self.errortimeout)
            except beon.TemporaryError as e:
                self.userqueue.put(self.site.ud)
                self.log.warn(e)
                self.schedule(self.dologin)
                self.w.sleep(self.errortimeout)
        # else:
        #     pending = len(self.pc.sets['pending'])
        #     self.log.warn(""No more logins here, %s pending.""%pending)
        #     if pending == 0: return False

    def relogin(self):
        '''Relogin with current user or do login'''
        if 'login' in self.site.ud:
            while self.w.running.is_set():
                try:
                    with cstate(self, WipeState.logging_in):
                        self.login(self.site.ud['login'], self.site.ud['passwd'])
                except beon.Success as e:
                    for c in self.hooks['post_login']:
                        c(self, self.site.ud)
                    self.w.sleep(self.successtimeout)
                    return
                except beon.InvalidLogin as e:
                    self.log.error(e)
                    self.w.sleep(self.errortimeout)
                    break
                except beon.TemporaryError as e:
                    self.log.warn(e)
                    self.w.sleep(self.errortimeout)
                    continue
        self.dologin()

    def request_email(self, ud):
        ud['email'] = self.mailrequester.gen_addr()
        ud[0]['email_service'] = type(self.mailrequester).__name__
        ud[0]['email_requested'] = False
        ud[0]['email_validated'] = False

    def validate_email(self, ud):
        if ('email' not in ud or
            'email_service' not in ud[0] or
            'email_requested' not in ud[0] or
            'email_validated' not in ud[0] or
            not ud[0]['email_service'] == type(self.mailrequester).__name__
            or ud[0]['email_validated'] is True):
            return
        if not ud[0]['email_requested']:
            try:
                self.site.validate_email_inc()
            except beon.Success as e:
                ud[0]['email_requested'] = True
                self.log.info(e)
        self.log.info('Requesting messages for %s', ud['email'])
        messages = self.mailrequester.get_messages(ud['email'])
        for msg in messages:
            if not msg['mail_from'].find('<reminder@{0}>'.format(self.site.domain)):
                continue
            h = re.findall(regexp.hashinmail.format(self.site.domain),
                msg['mail_html'])
            if len(h) > 0:
                try:
                    self.site.validate_email_fin(h[0])
                except beon.Success as e:
                    ud[0]['email_validated'] = True
                    self.log.info(e)

    def switch_user(self):
        '''Log in with new user, but return the previous one'''
        if 'login' in self.site.ud:
            self.log.info('Switching user %s', self.site.ud['login'])
            self.return_user()
        self.site.ud = self.register_new_user()

    def return_user(self, ud=None):
        if not ud:
            if (hasattr(self.site, 'ud') and self.site.ud):
                ud = self.site.ud
                self.site.ud = None
            else:
                return
        self.log.info('Returning user %s to userqueue', ud['login'])
        self.userqueue.put(ud, False)

    def postmsg(self, target, msg, tuser=None, **kvargs):
        tpair = (tuser, target)
        target = target.lstrip('0')
        try:
            try:
                self.site.ajax_addcomment(target, msg, tuser, **kvargs)
            except beon.Success as e:
                self.update_caprate(False)
                raise
            except beon.Redir as e:
                self.log.warn(e)
                self.log.warn('Using non-ajax addcomment')
                self.captcha_wrapper(self.site.addcomment, self.site.addcommentfin,
                                     target, msg, tuser, **kvargs)
        except beon.Success as e:
            self.counters['comments_added'] += 1
            self.log.debug(e)
            raise
        except beon.Antispam as e:
            self.counters['antispam'] += 1
            self.comment_successtimeout = self.comment_successtimeout + 0.1
            self.log.info('Antispam exc caught, comment_successtimeout + 0.1, cur: %f',
                self.comment_successtimeout)
            raise
        except beon.GuestDeny as e:
            self.counters['delogin'] += 1
            self.log.warn('%s, trying to log in', e)
            self.schedule_first(self.relogin)
            raise
        except beon.Bumplimit as e:
            self.log.info(e)
            self.pc.sets['bumplimit'].add(tpair)
            raise
        except (beon.Closed, beon.UserDeny) as e:
            self.pc.sets['closed'].add(tpair)
            if self.stoponclose:
                self.log.info(e)
                raise beon.PermClosed(""%s:%s is closed"", tpair, e.answer)
            else:
                self.log.info('%s, starting 300s remove timer', e)
                self.pc.add_waiting('closed', tpair, 300)
                raise
        except beon.Wait5Min as e:
            self.counters['wait5mincount'] += 1
            self.log.warn(e)
            raise
        except beon.TemporaryError as e:
            self.log.warn(e)
            raise
        except beon.PermanentError as e:
            self.log.error(e)
            raise

    def addtopic(self, msg, subj, forum='1', tuser=None, **kvargs):
        try:
            self.captcha_wrapper(self.site.addtopicinc, self.site.addtopicfin,
                                 msg, forum, subj, tuser, **kvargs)
        except beon.Success as e:
            self.counters['topics_added'] += 1
            self.log.debug(e)
            raise
        except beon.Wait5Min as e:
            self.counters['wait5min'] += 1
            raise
            # self._bancount += 1
            # if 'login' in self.site.ud:
            #     self.log.warn(e)
            #     self.log.warn('Trying to change user')
            #     self.pc.sets['pending'].add(self.site.ud['login'])
            #     self.pc.add_waiting('pending', self.site.ud['login'], 300)
            #     self.dologin()
            # else:
            #     raise
        except beon.GuestDeny as e:
            if 'login' not in self.site.ud:
                raise
            self.counters['delogin'] += 1
            self.log.warn('%s, trying to log in', e)
            self.schedule_first(self.dologin)
            raise

    def register(self, login, passwd, name, email, **kvargs):
        self.logined = False
        try:
            self.captcha_wrapper(self.site.reginc, self.site.regfin,
                                 login, passwd, name, email, **kvargs)
        except beon.Success as e:
            self.log.info(e)
            self.logined = True
            self.counters['users_registered'] += 1
            raise

    def solve_captcha(self, page):
        # with cstate(self, WipeState.deobfuscating_capage):
        self.log.info('Deobfuscating capage')
        capair = self.w.deobfuscate_capage(self.site.domain, page)
        self.log.info('Answer: %s', repr(capair))
        if len(capair) != 2:
            raise PermOCRError('Invalid answer from Evaluator')
        self.log.info('Downloading captcha image')
        try:
            img = self.http_request(capair[1])
        except sup.net.HTTPError as e:
            # check error code here
            self.log.error(e)
            raise PermOCRError('404 Not Found on caurl', cahash=capair[0])
        self.log.info('Sending captcha image to solver')
        try:
            result, cid = self.w.solve_captcha(img)
        except OCRError as e:
            e.cahash = capair[0]
            raise
        return capair[0], result, cid

    def report_code(self, cid, status):
        self.log.info('Reporting %s code for %s', status, cid)
        self.w.report_code(cid, status)
        self.counters['captcha_codes_reported'] += 1

    def run(self, caller):
        self.w = caller
        self.log = logging.getLogger(self.name)
        self.run_time = Ticker()
        cst = cstate(self, WipeState.starting)
        cst.__enter__()
        self.mailrequester = self.mrc(self.noproxy_rp, self.w.running, self.w.sleep)

        # Get our own logger here, or use worker's?
        self.log.info('Starting')
        self.run_time.tick()

        def drop_user_handler(interface, method, data):
            self.log.info('drop-user signal recieved')
            self.dologin()

        self.w.p.wz.set_sig_handler(b'WipeSkel', b'drop-user', drop_user_handler)

        self.w.p.sig_sock.setsockopt(zmq.SUBSCRIBE, b'WipeSkel')
        self.w.p.sig_sock.setsockopt(zmq.SUBSCRIBE, bytes(self.name, 'utf-8'))

        try:
            self._run()
        except Exception as e:
            self.log.exception(e)
        cst.__exit__(None, None, None)
        with cstate(self, WipeState.terminating):
            self.w.p.sig_sock.setsockopt(zmq.UNSUBSCRIBE, b'WipeSkel')
            self.w.p.sig_sock.setsockopt(zmq.UNSUBSCRIBE, bytes(self.name, 'utf-8'))
            self.w.p.wz.del_sig_handler(b'WipeSkel', b'drop-user')
            self.log.info(repr(self.counters))
        self.log.info('Terminating, runtime is %ds', self.run_time.elapsed(False))
/n/n/n",0
85,85,42b020edfe6b23b245938d23ff7a0484333d6450,"/evproxy.py/n/n# -*- coding: utf-8 -*-
# -*- mode: python -*-
import wzrpc
from sup.ticker import Ticker

class EvaluatorProxy:
    def __init__(self, ev_init, *args, **kvargs):
        super().__init__()
        self.ev_init = ev_init
        self.bind_kt_ticker = Ticker()
        self.bind_kt = 5

    def handle_evaluate(self, reqid, interface, method, data):
        domain, page = data
        self.p.log.info('Recvd page %s, working on', reqid)
        res = self.ev.solve_capage(domain, page)
        self.p.log.info('Done, sending answer: %s', res)
        self.p.send_success_rep(reqid, [v.encode('utf-8') for v in res])

    def send_keepalive(self):
        msg = self.p.wz.make_req_msg(b'Router', b'bind-keepalive', [],
            self.handle_keepalive_reply)
        msg.insert(0, b'')
        self.p.wz_sock.send_multipart(msg)

    def handle_keepalive_reply(self, reqid, seqnum, status, data):
        if status == wzrpc.status.success:
            self.p.log.debug('Keepalive was successfull')
        elif status == wzrpc.status.e_req_denied:
            self.p.log.warn('Keepalive status {0}, reauthentificating and rebinding'.
                format(wzrpc.name_status(status)))
            self.p.auth_requests()
            self.p.bind_methods()
        elif status == wzrpc.status.e_timeout:
            self.p.log.warn('Keepalive timeout')
        else:
            self.p.log.warn('Keepalive status {0}'.
                format(wzrpc.name_status(status)))

    def __call__(self, parent):
        self.p = parent
        self.p.wz_connect()
        self.p.wz_auth_requests = [
            (b'Router', b'auth-bind-route'),
            (b'Router', b'auth-unbind-route'),
            (b'Router', b'auth-set-route-type')]
        self.p.wz_bind_methods = [
            (b'Evaluator', b'evaluate', self.handle_evaluate, wzrpc.routetype.random)]
        self.p.auth_requests()
        self.p.bind_methods()
        self.ev = self.ev_init()
        self.bind_kt_ticker.tick()
        while self.p.running.is_set():
            socks = self.p.poll()
            if self.bind_kt_ticker.elapsed(False) > self.bind_kt:
                self.bind_kt_ticker.tick()
                self.send_keepalive()
/n/n/n/lib/wzrpc/wzhandler.py/n/n# -*- coding: utf-8 -*-
# -*- mode: python -*-
from . import *
from .wzbase import WZBase

class WZHandler(WZBase):
    def __init__(self):
        self.req_handlers = {}
        self.response_handlers = {}
        self.sig_handlers = {}
        self.iden_reqid_map = BijectiveSetMap()

    def set_req_handler(self, interface, method, fun):
        self.req_handlers[(interface, method)] = fun

    def set_response_handler(self, reqid, fun):
        self.response_handlers[reqid] = fun

    def set_sig_handler(self, interface, method, fun):
        self.sig_handlers[(interface, method)] = fun
    
    def del_req_handler(self, interface, method):
        del self.req_handlers[(interface, method)]

    def del_response_handler(self, reqid):
        del self.response_handlers[reqid]

    def del_sig_handler(self, interface, method):
        del self.sig_handlers[(interface, method)]

    def _parse_req(self, iden, msg, reqid, interface, method):
        try:
            handler = self.req_handlers[(interface, method)]
        except KeyError:
            try:
                handler = self.req_handlers[(interface, None)]
            except KeyError:
                raise WZENoReqHandler(iden, reqid,
                    'No req handler for %s,%s'%(interface, method))
        if iden:
            self.iden_reqid_map.add_value(tuple(iden), reqid)
        handler(reqid, interface, method, msg[1:])
        return ()

    def _parse_rep(self, iden, msg, reqid, seqnum, status):
        try:
            handler = self.response_handlers[reqid]
            if seqnum == 0:
                del self.response_handlers[reqid]
        except KeyError:
            raise WZENoHandler(iden, 'No rep handler for reqid')
        handler(reqid, seqnum, status, msg[1:])
        return ()

    def _parse_sig(self, iden, msg, interface, method):
        try:
            handler = self.sig_handlers[(interface, method)]
        except KeyError:
            raise WZENoHandler(iden, 'No handler for sig %s,%s'%(interface, method))
        handler(interface, method, msg[1:])
        return ()

    def make_req_msg(self, interface, method, args, fun, reqid=None):
        if not reqid:
            reqid = self.make_reqid()
        msg = make_req_msg(interface, method, args, reqid)
        self.set_response_handler(reqid, fun)
        return msg
    
    def make_router_req_msg(self, iden, interface, method, args, fun, reqid=None):
        msg = iden[:]
        msg.append(b'')
        msg.extend(self.make_req_msg(interface, method, args, fun, reqid))
        return msg
    
    def make_router_rep_msg(self, reqid, seqnum, status, answer):
        iden = self.iden_reqid_map.get_key(reqid)
        if seqnum == 0:
            self.iden_reqid_map.del_value(iden, reqid)
        msg = list(iden)
        msg.append(b'')
        msg.extend(make_rep_msg(reqid, seqnum, status, answer))
        return msg

    def get_iden(self, reqid):
        return self.iden_reqid_map.get_key(reqid)

    def get_reqids(self, iden):
        return self.iden_reqid_map.get_values(iden)

    def make_reqid(self):
        while True:
            reqid = random.randint(1, (2**64)-1)
            if not reqid in self.response_handlers:
                return reqid
        
    def make_auth_req_data(self, interface, method, key, reqid=None):
        if not reqid:
            reqid = self.make_reqid()
        args = [interface, method, make_auth_hash(interface, method, reqid, key)]
        return (b'Router', b'auth-request', args, reqid)

    def make_auth_bind_route_data(self, interface, method, key, reqid=None):
        if not reqid:
            reqid = self.make_reqid()
        args = [interface, method, make_auth_hash(interface, method, reqid, key)]        
        return (b'Router', b'auth-bind-route', args, reqid)

    def make_auth_unbind_route_data(self, interface, method, key, reqid=None):
        if not reqid:
            reqid = self.make_reqid()
        args = [interface, method, make_auth_hash(interface, method, reqid, key)]        
        return (b'Router', b'auth-unbind-route', args, reqid)

    def make_auth_set_route_type_data(self, interface, method, type_, key, reqid=None):
        if not reqid:
            reqid = self.make_reqid()
        args = [interface, method, struct.pack('!B', type_),
                make_auth_hash(interface, method, reqid, key)]
        return (b'Router', b'auth-set-route-type', args, reqid)

    def make_auth_clear_data(self, reqid=None):
        if not reqid:
            reqid = self.make_reqid()
        return (b'Router', b'auth-clear', [], reqid)

    def req_from_data(self, d, fun):
        return self.make_req_msg(d[0], d[1], d[2], fun, d[3])
  
    def _parse_err(self, iden, msg, status):
        pass

    def _handle_nil(self, iden, msg):
        pass
/n/n/n/lib/wzworkers.py/n/nimport zmq
import threading, multiprocessing
import logging
from sup.ticker import Ticker
# from sup import split_frames
import wzrpc
from wzrpc.wzhandler import WZHandler
import wzauth_data

class WorkerInterrupt(Exception):
    '''Exception to raise when self.running is cleared'''
    def __init__(self):
        super().__init__('Worker was interrupted at runtime')

class Suspend(Exception):
    # if we need this at all.
    '''Exception to raise on suspend signal'''
    def __init__(self, interval, *args, **kvargs):
        self.interval = interval
        super().__init__(*args, **kvargs)

class Resume(Exception):
    '''Exception to raise when suspend sleep is interrupted'''

class WZWorkerBase:
    def __init__(self, wz_addr, fun, args=(), kvargs={},
            name=None, start_timer=None, poll_timeout=None,
            pargs=(), pkvargs={}):
        super().__init__(*pargs, **pkvargs)
        self.name = name if name else type(self).__name__
        self.start_timer = start_timer
        self.poll_timeout = poll_timeout if poll_timeout else 5*1000
        self.call = (fun, args, kvargs)

        self.wz_addr = wz_addr
        self.wz_auth_requests = []
        self.wz_bind_methods = []
        self.wz_poll_timeout = 30

    def __sinit__(self):
        '''Initializes thread-local interface on startup'''
        self.log = logging.getLogger(self.name)
        self.running = threading.Event()
        self.sleep_ticker = Ticker()
        self.poller = zmq.Poller()

        s = self.ctx.socket(zmq.SUB)
        self.poller.register(s, zmq.POLLIN)
        s.setsockopt(zmq.IPV6, True)
        s.connect(self.sig_addr)
        s.setsockopt(zmq.SUBSCRIBE, b'GLOBAL')
        s.setsockopt(zmq.SUBSCRIBE, b'WZWorker')
        s.setsockopt(zmq.SUBSCRIBE, bytes(self.name, 'utf-8'))
        self.sig_sock = s

        s = self.ctx.socket(zmq.DEALER)
        self.poller.register(s, zmq.POLLIN)
        s.setsockopt(zmq.IPV6, True)
        self.wz_sock = s

        self.wz = WZHandler()

        def term_handler(interface, method, data):
            self.log.info(
                'Termination signal %s recieved',
                repr((interface, method, data)))
            self.term()
            raise WorkerInterrupt()
        self.wz.set_sig_handler(b'WZWorker', b'terminate', term_handler)

        def resumehandler(interface, method, data):
            self.log.info('Resume signal %s recieved',
                repr((interface, method, data)))
            raise Resume()

        self.wz.set_sig_handler(b'WZWorker', b'resume', term_handler)
        self.running.set()

    def wz_connect(self):
        self.wz_sock.connect(self.wz_addr)

    def wz_wait_reply(self, fun, interface, method, data, reqid=None, timeout=None):
        s, p, t, wz = self.wz_sock, self.poll, self.sleep_ticker, self.wz
        timeout = timeout if timeout else self.wz_poll_timeout
        rs = wzrpc.RequestState(fun)
        msg = self.wz.make_req_msg(interface, method, data,
                                   rs.accept, reqid)
        msg.insert(0, b'')
        s.send_multipart(msg)
        t.tick()
        while self.running.is_set():
            p(timeout*1000)
            if rs.finished:
                if rs.retry:
                    msg = self.wz.make_req_msg(interface, method, data,
                        rs.accept, reqid)
                    msg.insert(0, b'')
                    s.send_multipart(msg)
                    rs.finished = False
                    rs.retry = False
                    continue
                return
            elapsed = t.elapsed(False)
            if elapsed >= timeout:
                t.tick()
                # Notify fun about the timeout
                rs.accept(None, 0, 255, [elapsed])
                # fun sets rs.retry = True if it wants to retry
        raise WorkerInterrupt()
    
    def wz_multiwait(self, requests):
        # TODO: rewrite the retry loop
        s, p, t, wz = self.wz_sock, self.poll, self.sleep_ticker, self.wz
        timeout = self.wz_poll_timeout
        rslist = []
        msgdict = {}
        for request in requests:
            rs = wzrpc.RequestState(request[0])
            rslist.append(rs)
            msg = self.wz.make_req_msg(request[1][0], request[1][1], request[1][2],
                                    rs.accept, request[1][3])
            msg.insert(0, b'')
            msgdict[rs] = msg
            s.send_multipart(msg)
        while self.running.is_set():
            flag = 0
            for rs in rslist:
                if rs.finished:
                    if not rs.retry:
                        del msgdict[rs]
                        continue
                    s.send_multipart(msgdict[rs])
                    rs.finished = False
                    rs.retry = False
                flag = 1
            if not flag:
                return
            # check rs before polling, since we don't want to notify finished one
            # about the timeout
            t.tick()
            p(timeout*1000)
            if t.elapsed(False) >= timeout:
                for rs in rslist:
                    if not rs.finished:
                        rs.accept(None, 0, 255, []) # Notify fun about the timeout
                        rs.finished = True # fun sets rs.retry = True if it wants to retry
        raise WorkerInterrupt()

    def auth_requests(self):
        for i, m in self.wz_auth_requests:
            def accept(that, reqid, seqnum, status, data):
                if status == wzrpc.status.success:
                    self.log.debug('Successfull auth for (%s, %s)', i, m)
                elif status == wzrpc.status.e_auth_wrong_hash:
                    raise beon.PermanentError(
                        'Cannot authentificate for ({0}, {1}), {2}: {3}'.\
                        format(i, m, wzrpc.name_status(status), repr(data)))
                elif wzrpc.status.e_timeout:
                    self.log.warn('Timeout {0}, retrying'.format(data[0]))
                    that.retry = True
                else:
                    self.log.warning('Recvd unknown reply for (%s, %s) %s: %s', i, m,
                        wzrpc.name_status(status), repr(data))
            self.wz_wait_reply(accept,
                *self.wz.make_auth_req_data(i, m, wzauth_data.request[i, m]))


    def bind_route(self, i, m, f):
        self.log.debug('Binding %s,%s route', i, m)
        def accept(that, reqid, seqnum, status, data):
            if status == wzrpc.status.success:
                self.wz.set_req_handler(i, m, f)
                self.log.debug('Succesfully binded route (%s, %s)', i, m)
            elif status == wzrpc.status.e_req_denied:
                self.log.warn('Status {0}, reauthentificating'.\
                    format(wzrpc.name_status(status)))
                self.auth_requests()
            elif wzrpc.status.e_timeout:
                self.log.warn('Timeout {0}, retrying'.format(data[0]))
                that.retry = True
            else:
                self.log.warn('Status {0}, retrying'.format(wzrpc.name_status(status)))
                that.retry = True
        return self.wz_wait_reply(accept,
                *self.wz.make_auth_bind_route_data(i, m, wzauth_data.bind_route[i, m]))

    def set_route_type(self, i, m, t):
        self.log.debug('Setting %s,%s type to %d', i, m, t)
        def accept(that, reqid, seqnum, status, data):
            if status == wzrpc.status.success:
                self.log.debug('Succesfully set route type for (%s, %s) to %s', i, m,
                    wzrpc.name_route_type(t))
            elif status == wzrpc.status.e_req_denied:
                self.log.warn('Status {0}, reauthentificating'.\
                    format(wzrpc.name_status(status)))
                self.auth_requests()
            else:
                self.log.warn('Status {0}, retrying'.format(wzrpc.name_status(status)))
                that.retry = True
        return self.wz_wait_reply(accept,
            *self.wz.make_auth_set_route_type_data(i, m, t,
                wzauth_data.set_route_type[i, m]))

    def unbind_route(self, i, m):
        if not (i, m) in self.wz.req_handlers:
            self.log.debug('Route %s,%s was not bound', i, m)
            return
        self.log.debug('Unbinding route %s,%s', i, m)
        self.wz.del_req_handler(i, m)
        def accept(that, reqid, seqnum, status, data):
            if status == wzrpc.status.success:
                self.log.debug('Route unbinded for (%s, %s)', i, m)
            else:
                self.log.warn('Status %s, passing', wzrpc.name_status(status))
        return self.wz_wait_reply(accept,
            *self.wz.make_auth_unbind_route_data(i, m, wzauth_data.bind_route[i, m]))
    
    def clear_auth(self):
        self.log.debug('Clearing our auth records')
        def accept(that, reqid, seqnum, status, data):
            if status == wzrpc.status.success:
                self.log.debug('Auth records on router were cleared')
            else:
                self.log.warn('Status %s, passing', wzrpc.name_status(status))
        return self.wz_wait_reply(accept, *self.wz.make_auth_clear_data())

    def bind_methods(self):
        for i, m, f, t in self.wz_bind_methods:
            self.set_route_type(i, m, t)
            self.bind_route(i, m, f)
    
    def unbind_methods(self):  
        for i, m, f, t in self.wz_bind_methods:
            self.unbind_route(i, m)
        #self.clear_auth()

    def send_rep(self, reqid, seqnum, status, data):
        self.wz_sock.send_multipart(
            self.wz.make_router_rep_msg(reqid, seqnum, status, data))

    def send_success_rep(self, reqid, data):
        self.send_rep(reqid, 0, wzrpc.status.success, data)
    
    def send_error_rep(self, reqid, data):
        self.send_rep(reqid, 0, wzrpc.status.error, data)

    def send_wz_error(self, reqid, data, seqid=0):
        msg = self.wz.make_dealer_rep_msg(
            reqid, seqid, wzrpc.status.error, data)
        self.wz_sock.send_multipart(msg)
        
    def send_to_router(self, msg):
        msg.insert(0, b'')
        self.wz_sock.send_multipart(msg)
    
    # def bind_sig_route(self, routetype, interface, method, fun):
    #     self.log.info('Binding %s,%s as type %d signal route',
    #                   interface, method, routetype)
    #     self.wz.set_signal_handler(interface, method, fun)
    #     msg = self.wz.make_dealer_sig_msg(b'Router', b'bind-sig-route',
    #                                       [interface, method],
    #                                       self.accept_ok)
    #     self.wz_sock.send_multipart(msg)

    # def unbind_sig_route(self, interface, method):
    #     self.log.info('Deleting %s,%s signal route', interface, method)
    #     self.wz.del_signal_handler(interface, method)
    #     msg = self.wz.make_dealer_sig_msg(b'Router', b'unbind-sig-route',
    #                                       [interface, method],
    #                                       self.accept_ok)
    #     self.wz_sock.send_multipart(msg)

    def inter_sleep(self, timeout):
        self.sleep_ticker.tick()
        self.poll(timeout * 1000)
        while self.sleep_ticker.elapsed(False) < timeout:
            try:
                self.poll(timeout * 1000)
            except Resume as e:
                return

    def poll(self, timeout=None):
        try:
            socks = dict(self.poller.poll(timeout if timeout != None
                else self.poll_timeout))
        except zmq.ZMQError as e:
            self.log.error(e)
            return
        if socks.get(self.sig_sock) == zmq.POLLIN:
            # No special handling or same-socket replies are necessary for signals.
            # Backwards socket replies may be added here.
            frames = self.sig_sock.recv_multipart()
            try:
                self.wz.parse_msg(frames[0], frames[1:])
            except wzrpc.WZError as e:
                self.log.warn(e)
        if socks.get(self.wz_sock) == zmq.POLLIN:
            self.process_wz_msg(self.wz_sock.recv_multipart())
        return socks

    def process_wz_msg(self, frames):
        try:
            for nfr in self.wz.parse_router_msg(frames):
                # Send replies from the handler, for cases when it's methods were rewritten.
                self.wz_sock.send_multipart(nfr)
        except wzrpc.WZErrorRep as e:
            self.log.info(e)
            self.wz_sock.send_multipart(e.rep_msg)
        except wzrpc.WZError as e:
            self.log.warn(e)

    def run(self):
        self.__sinit__()
        if self.start_timer:
            self.inter_sleep(self.start_timer)
        if self.running:
            self.log.info('Starting')
            try:
                self.child = self.call[0](*self.call[1], **self.call[2])
                self.child(self)
            except WorkerInterrupt as e:
                self.log.warn(e)
            except Exception as e:
                self.log.exception(e)
            self.log.info('Terminating')
        else:
            self.log.info('Aborted')
        self.running.set() # wz_multiwait needs this to avoid another state check.
        self.unbind_methods()
        self.running.clear()
        self.wz_sock.close()
        self.sig_sock.close()
    
    def term(self):
        self.running.clear()


class WZWorkerThread(WZWorkerBase, threading.Thread):
    def start(self, ctx, sig_addr, *args, **kvargs):
        self.ctx = ctx
        self.sig_addr = sig_addr
        threading.Thread.start(self, *args, **kvargs)

class WZWorkerProcess(WZWorkerBase, multiprocessing.Process):
    def start(self, sig_addr, *args, **kvargs):
        self.sig_addr = sig_addr
        multiprocessing.Process.start(self, *args, **kvargs)
    
    def __sinit__(self):
        self.ctx = zmq.Context()
        super().__sinit__()
/n/n/n/unistart.py/n/n#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# -*- mode: python -*-
import sys
if 'lib' not in sys.path:
    sys.path.append('lib')
import os, signal, logging, threading, re, traceback, time
import random
import zmq
from queue import Queue
import sup
import wzworkers as workers
from dataloader import DataLoader
from uniwipe import UniWipe
from wipeskel import *
import wzrpc
from beon import regexp
import pickle

from logging import config
from logconfig import logging_config
config.dictConfig(logging_config)
logger = logging.getLogger()

ctx = zmq.Context()
sig_addr = 'ipc://signals'
sig_sock = ctx.socket(zmq.PUB)
sig_sock.bind(sig_addr)

# Settings for you
domains = set() # d.witch_domains
targets = dict() # d.witch_targets
protected = set() # will be removed later
forums = dict() # target forums

# from lib import textgen
# with open('data.txt', 'rt') as f:
#     model = textgen.train(f.read())
# def mesasge():
#     while True:
#         s = textgen.generate_sentence(model)
#         try:
#             s.encode('cp1251')
#             break
#         except Exception:
#             continue
#     return s

def message():
    msg = []
    # msg.append('[video-youtube-'+
    #            random.choice(('3odl-KoNZwk', 'bu55q_3YtOY', '4YPiCeLwh5o',
    #                           'eSBybJGZoCU', 'ZtWTUt2RZh0', 'VXa9tXcMhXQ',))
    #            +']')
    msg.append('[image-original-none-http://simg4.gelbooru.com/'
               + '/images/db/1d/db1dfb62a40f5ced2043bb8966da9a98.png]')
    msg.append('     .')
    # msg.append('[video-youtube-'+random.choice(
    #     # ('WdDb_RId-xU', 'EFL1-fL-WtM', 'uAOoiIkFQq4',
    #     #  'eZO3K_4yceU', '1c1lT_HgJNo', 'WOkvVVaJ2Ks',
    #     #  'KYq90TEdxIE', 'rWBM2whL0bI', '0PDy_MKYo4A'))
    #     #('GabBLLOT6vw', 'qgvOpSquCAY', 'zUe-z9DZBNo', '4fCbfDEKZss', 'uIE-JgmkmdM'))
    #     ('42JQYPioVo4', 'jD6j072Ep1M', 'mPyF5ovoIVs', 'cEEi1BHycb0', 'PuA1Wf8nkxw',
    #      'ASJ9qlsPgHU', 'DP1ZDW9_xOo', 'bgSqH9LT-mI', ))
    # +']')
    # http://simg2.gelbooru.com//images/626/58ca1c9a8ffcdedd0e2eb6f33c9389cb7588f0d1.jpg
    # msg.append('Enjoy the view!')
    msg.append(str(random.randint(0, 9999999999)))
    return '\n'.join(msg)

def sbjfun():
    # return 'Out of the darkness we will rise, into the light we will dwell'
    return sup.randstr(1, 30)

# End
import argparse

parser = argparse.ArgumentParser(add_help=True)
parser.add_argument('--only-cache', '-C', action='store_true',
    help=""Disables any requests in DataLoader (includes Witch)"")
parser.add_argument('--no-shell', '-N', action='store_true',
    help=""Sleep instead of starting the shell"")
parser.add_argument('--tcount', '-t', type=int, default=10,
    help='WipeThread count')
parser.add_argument('--ecount', '-e', type=int, default=0,
    help='EvaluatorProxy count')
parser.add_argument('--upload-avatar', action='store_true', default=False,
    help='Upload random avatar after registration')
parser.add_argument('--av-dir', default='randav', help='Directory with avatars')
parser.add_argument('--rp-timeout', '-T', type=int, default=10,
    help='Default rp timeout in seconds')
parser.add_argument('--conlimit', type=int, default=3,
    help='http_request conlimit')
parser.add_argument('--noproxy-timeout', type=int, default=5,
    help='noproxy_rp timeout')

parser.add_argument('--caprate_minp', type=int, default=5,
    help='Cap rate minimum possible count for limit check')
parser.add_argument('--caprate_limit', type=float, default=0.8,
    help='Captcha rate limit')

parser.add_argument('--comment_successtimeout', type=float, default=0.8,
    help='Comment success timeout')
parser.add_argument('--topic_successtimeout', type=float, default=0.1,
    help='Topic success timeout')
parser.add_argument('--errortimeout', type=float, default=3,
    help='Error timeout')


parser.add_argument('--stop-on-closed', action='store_true', default=False,
    help='Forget about closed topics')
parser.add_argument('--die-on-neterror', action='store_true', default=False,
    help='Terminate spawn in case of too many NetErrors')

c = parser.parse_args()

# rps = {}

noproxy_rp = sup.net.RequestPerformer()
noproxy_rp.proxy = ''
noproxy_rp.timeout = c.noproxy_timeout
noproxy_rp.timeout = c.rp_timeout

# rps[''] = noproxy_rp

# Achtung: DataLoader probably isn't thread-safe.
d = DataLoader(noproxy_rp, c.only_cache)
c.router_addr = d.addrs['rpcrouter']
noproxy_rp.useragent = random.choice(d.ua_list)

def terminate():
    logger.info('Shutdown initiated')
    # send_passthrough([b'GLOBAL', b'WZWorker', b'terminate'])
    send_to_wm([b'GLOBAL', b'WZWorker', b'terminate'])
    for t in threading.enumerate():
        if isinstance(t, threading.Timer):
            t.cancel()
    # try:
    #     wm.term()
    #     wm.join()
    # except: # WM instance is not created yet.
    #     pass
    logger.info('Exiting')

def interrupt_handler(signal, frame):
    pass # Just do nothing

def terminate_handler(signal, frame):
    terminate()

signal.signal(signal.SIGINT, interrupt_handler)
signal.signal(signal.SIGTERM, terminate_handler)

def make_net(proxy, proxytype):
    # if proxy in rps:
    #     return rps[proxy]
    net = sup.net.RequestPerformer()
    net.proxy = proxy
    if proxytype == 'HTTP' or proxytype == 'HTTPS':
        net.proxy_type = sup.proxytype.http
    elif proxytype == 'SOCKS4':
        net.proxy_type = sup.proxytype.socks4
    elif proxytype == 'SOCKS5':
        net.proxy_type = sup.proxytype.socks5
    else:
        raise TypeError('Invalid proxytype %s' % proxytype)
    # rps[proxy] = net
    net.useragent = random.choice(d.ua_list)
    net.timeout = c.rp_timeout
    return net

# UniWipe patching start
def upload_avatar(self, ud):
    if ('avatar_uploaded' in ud[0] and
        ud[0]['avatar_uploaded'] is True):
        return
    files = []
    for sd in os.walk(c.av_dir):
        files.extend(sd[2])
    av = os.path.join(sd[0], random.choice(files))
    self.log.info('Uploading %s as new avatar', av)
    self.site.uploadavatar('0', av)
    ud[0]['avatar'] = av
    ud[0]['avatar_uploaded'] = True

from lib.mailinator import Mailinator
# from lib.tempmail import TempMail as Mailinator

# Move this to WipeManager
def create_spawn(proxy, proxytype, pc, uq=None):
    for domain in domains:
        if domain in targets:
            tlist = targets[domain]
        else:
            tlist = list()
            targets[domain] = tlist
        if domain in forums:
            fset = forums[domain]
        else:
            fset = set()
            forums[domain] = fset
        net = make_net(proxy, proxytype)
        net.cookiefname = (proxy if proxy else 'noproxy')+'_'+domain
        w = UniWipe(fset, tlist, sbjfun, message, pc, net, domain, Mailinator,
            uq(domain) if uq else None)
        w.stoponclose = c.stop_on_closed
        w.die_on_neterror = c.die_on_neterror
        w.caprate_minp = c.caprate_minp
        w.caprate_limit = c.caprate_limit
        w.conlimit = c.conlimit
        w.comment_successtimeout = 0.2
        if c.upload_avatar:
            w.hooks['post_login'].append(upload_avatar)
        yield w

# UniWipe patching end

class WipeManager:
    def __init__(self, config, *args, **kvargs):
        super().__init__(*args, **kvargs)
        self.newproxyfile = 'newproxies.txt'
        self.proxylist = set()
        self.c = config
        self.threads = []
        self.processes = []
        self.th_sa = 'inproc://wm-wth.sock'
        self.th_ba = 'inproc://wm-back.sock'
        self.pr_sa = 'ipc://wm-wpr.sock'
        self.pr_ba = 'ipc://wm-back.sock'
        self.userqueues = {}
        self.usersfile = 'wm_users.pickle'
        self.targetsfile = 'wm_targets.pickle'
        self.bumplimitfile = 'wm_bumplimit.pickle'

    def init_th_sock(self):
        self.log.info(
            'Initializing intraprocess signal socket %s', self.th_sa)
        self.th_sock = self.p.ctx.socket(zmq.PUB)
        self.th_sock.bind(self.th_sa)

    def init_th_back_sock(self):
        self.log.info(
            'Initializing intraprocess backward socket %s', self.th_ba)
        self.th_back_sock = self.p.ctx.socket(zmq.ROUTER)
        self.th_back_sock.bind(self.th_ba)

    def init_pr_sock(self):
        self.log.info(
            'Initializing interprocess signal socket %s', self.pr_sa)
        self.pr_sock = self.p.ctx.socket(zmq.PUB)
        self.pr_sock.bind(self.pr_sa)

    def init_pr_back_sock(self):
        self.log.info(
            'Initializing interprocess backward socket %s', self.pr_ba)
        self.pr_back_sock = self.p.ctx.socket(zmq.ROUTER)
        self.pr_back_sock.bind(self.pr_ba)

    def read_newproxies(self):
        if not os.path.isfile(self.newproxyfile):
            return
        newproxies = set()
        with open(self.newproxyfile, 'rt') as f:
            for line in f:
                try:
                    line = line.rstrip('\n')
                    proxypair = tuple(line.split(' '))
                    if len(proxypair) < 2:
                        self.log.warning('Line %s has too few spaces', line)
                        continue
                    if len(proxypair) > 2:
                        self.log.debug('Line %s has too much spaces', line)
                        proxypair = (proxypair[0], proxypair[1])
                    newproxies.add(proxypair)
                except Exception as e:
                    self.log.exception('Line %s raised exception %s', line, e)
        # os.unlink(self.newproxyfile)
        return newproxies.difference(self.proxylist)

    def add_spawns(self, proxypairs):
        while self.running.is_set():
            try:
                try:
                    proxypair = proxypairs.pop()
                except Exception:
                    return
                self.proxylist.add(proxypair)
                for spawn in create_spawn(proxypair[0], proxypair[1], self.pc,
                        self.get_userqueue):
                    self.log.info('Created spawn %s', spawn.name)
                    self.spawnqueue.put(spawn, False)
            except Exception as e:
                self.log.exception('Exception ""%s"" raised on create_spawn', e)

    def spawn_workers(self, wclass, count, args=(), kvargs={}):
        wname = str(wclass.__name__)
        self.log.info('Starting %s(s)', wname)
        if issubclass(wclass, workers.WZWorkerThread):
            type_ = 0
            if not hasattr(self, 'th_sock'):
                self.init_th_sock()
            if not hasattr(self, 'th_back_sock'):
                self.init_th_back_sock()
        elif issubclass(wclass, workers.WZWorkerProcess):
            type_ = 1
            if not hasattr(self, 'pr_sock'):
                self.init_pr_sock()
            if not hasattr(self, 'pr_back_sock'):
                self.init_pr_back_sock()
        else:
            raise Exception('Unknown wclass type')
        for i in range(count):
            if not self.running.is_set():
                break
            try:
                w = wclass(*args, name='.'.join(
                    (wname, ('pr{0}' if type_ else 'th{0}').format(i))),
                    **kvargs)
                if type_ == 0:
                    self.threads.append(w)
                    w.start(self.p.ctx, self.th_sa)
                elif type_ == 1:
                    self.processes.append(w)
                    w.start(self.pr_sa)
            except Exception as e:
                self.log.exception('Exception ""%s"" raised on %s spawn',
                                   e, wname)

    def spawn_nworkers(self, type_, fun, count, args=(), kvargs={}):
        wname = str(fun.__name__)
        self.log.info('Starting %s(s)', wname)
        if type_ == 0:
            if not hasattr(self, 'th_sock'):
                self.init_th_sock()
            if not hasattr(self, 'th_back_sock'):
                self.init_th_back_sock()
        elif type_ == 1:
            if not hasattr(self, 'pr_sock'):
                self.init_pr_sock()
            if not hasattr(self, 'pr_back_sock'):
                self.init_pr_back_sock()
        else:
            raise Exception('Unknown wclass type')
        for i in range(count):
            if not self.running.is_set():
                break
            try:
                if type_ == 0:
                    w = workers.WZWorkerThread(
                        self.c.router_addr, fun, args, kvargs,
                        name='.'.join((wname, 'th{0}'.format(i))))
                    self.threads.append(w)
                    w.start(self.p.ctx, self.th_sa)
                elif type_ == 1:
                    w = workers.WZWorkerProcess(self.c.router_addr, fun, args, kvargs,
                        name='.'.join((wname, 'pr{0}'.format(i))))
                    self.processes.append(w)
                    w.start(self.pr_sa)
            except Exception as e:
                self.log.exception('Exception ""%s"" raised on %s spawn',
                                   e, wname)

    def spawn_wipethreads(self):
        return self.spawn_nworkers(0, WipeThread, self.c.tcount,
                                  (self.pc, self.spawnqueue))

    def spawn_evaluators(self):
        self.log.info('Initializing Evaluator')
        from evproxy import EvaluatorProxy
        def ev_init():
            from lib.evaluators.PyQt4Evaluator import Evaluator
            return Evaluator()
        return self.spawn_nworkers(1, EvaluatorProxy, self.c.ecount,
                                  (ev_init,))

    def load_users(self):
        if not os.path.isfile(self.usersfile):
            return
        with open(self.usersfile, 'rb') as f:
            users = pickle.loads(f.read())
        try:
            for domain in users.keys():
                uq = Queue()
                for ud in users[domain]:
                    self.log.debug('Loaded user %s:%s', domain, ud['login'])
                    uq.put(ud)
                self.userqueues[domain] = uq
        except Exception as e:
            self.log.exception(e)
            self.log.error('Failed to load users')

    def save_users(self):
        users = {}
        for d, uq in self.userqueues.items():
            uqsize = uq.qsize()
            uds = []
            for i in range(uqsize):
                uds.append(uq.get(False))
            users[d] = uds
        with open(self.usersfile, 'wb') as f:
            f.write(pickle.dumps(users, pickle.HIGHEST_PROTOCOL))
        self.log.info('Saved users')

    def get_userqueue(self, domain):
        try:
            uq = self.userqueues[domain]
        except KeyError:
            self.log.info('Created userqueue for %s', domain)
            uq = Queue()
            self.userqueues[domain] = uq
        return uq

    def load_targets(self):
        fname = self.targetsfile
        if not os.path.isfile(fname):
            return
        with open(fname, 'rb') as f:
            data = pickle.loads(f.read())
        if 'targets' in data:
            self.log.debug('Target list was loaded')
            targets.update(data['targets'])
        if 'forums' in data:
            self.log.debug('Forum set was loaded')
            forums.update(data['forums'])
        if 'domains' in data:
            self.log.debug('Domain set was loaded')
            domains.update(data['domains'])
        if 'sets' in data:
            self.log.debug('Other sets were loaded')
            self.pc.sets.update(data['sets'])

    def load_bumplimit_set(self):
        if not os.path.isfile(self.bumplimitfile):
            return
        with open(self.bumplimitfile, 'rb') as f:
            self.pc.sets['bumplimit'].update(pickle.loads(f.read()))

    def save_targets(self):
        data = {
            'targets': targets,
            'forums': forums,
            'domains': domains,
            'sets': self.pc.sets,
            }
        with open(self.targetsfile, 'wb') as f:
            f.write(pickle.dumps(data, pickle.HIGHEST_PROTOCOL))

    def targets_from_witch(self):
        for t in d.witch_targets:
            if t['domain'] == 'beon.ru' and t['forum'] == 'anonymous':
                try:
                    add_target_exc(t['id'], t['user'])
                except ValueError:
                    pass

    def terminate(self):
        msg = [b'GLOBAL']
        msg.extend(wzrpc.make_sig_msg(b'WZWorker', b'terminate', []))
        if hasattr(self, 'th_sock'):
            self.th_sock.send_multipart(msg)
        if hasattr(self, 'pr_sock'):
            self.pr_sock.send_multipart(msg)

    def join_threads(self):
        for t in self.threads:
            t.join()

    def send_passthrough(self, interface, method, frames):
        msg = [frames[0]]
        msg.extend(wzrpc.make_sig_msg(frames[1], frames[2], frames[3:]))
        self.th_sock.send_multipart(msg)
        self.pr_sock.send_multipart(msg)

    def __call__(self, parent):
        self.p = parent
        self.log = parent.log
        self.inter_sleep = parent.inter_sleep
        self.running = parent.running
        self.p.sig_sock.setsockopt(zmq.SUBSCRIBE, b'WipeManager')
        self.p.wz.set_sig_handler(b'WipeManager', b'passthrough', self.send_passthrough)
        if self.c.tcount > 0:
            self.pc = ProcessContext(self.p.name, self.p.ctx,
                self.c.router_addr, noproxy_rp)
            self.spawnqueue = Queue()
            self.load_bumplimit_set()
            self.load_targets()
            self.load_users()
            self.spawn_wipethreads()
        if self.c.ecount > 0:
            self.spawn_evaluators()
        try:
            while self.running.is_set():
                # self.targets_from_witch()
                if self.c.tcount == 0:
                    self.inter_sleep(5)
                    continue
                self.pc.check_waiting()
                new = self.read_newproxies()
                if not new:
                    self.inter_sleep(5)
                    continue
                self.add_spawns(new)
        except WorkerInterrupt:
            pass
        except Exception as e:
            self.log.exception(e)
        self.terminate()
        self.join_threads()
        if self.c.tcount > 0:
            self.save_users()
            self.save_targets()

wm = workers.WZWorkerThread(c.router_addr, WipeManager, (c,),
    name='SpaghettiMonster')
wm.start(ctx, sig_addr)

def add_target(domain, id_, tuser=None):
    if domain not in targets:
        targets[domain] = []
    tlist = targets[domain]
    id_ = str(id_)
    tuser = tuser or ''
    t = (tuser, id_)
    logger.info('Appending %s to targets[%s]', repr(t), domain)
    tlist.append(t)

def remove_target(domain, id_, tuser=None):
    tlist = targets[domain]
    id_ = str(id_)
    tuser = tuser or ''
    t = (tuser, id_)
    logger.info('Removing %s from targets[%s]', repr(t), domain)
    tlist.remove(t)

def add_target_exc(domain, id_, tuser=None):
    if domain not in targets:
        targets[domain] = []
    tlist = targets[domain]
    id_ = str(id_)
    tuser = tuser or ''
    t = (tuser, id_)
    if t in protected:
        raise ValueError('%s is protected' % repr(t))
    if t not in tlist:
        logger.info('Appending %s to targets[%s]', repr(t), domain)
        tlist.append(t)

r_di = re.compile(regexp.f_udi)

def atfu(urls):
    for user, domain, id1, id2 in r_di.findall(urls):
        id_ = id1+id2
        add_target(domain, id_, user)

def rtfu(urls):
    for user, domain, id1, id2 in r_di.findall(urls):
        id_ = id1+id2
        remove_target(domain, id_, user)

def get_forum_id(name):
    id_ = d.bm_id_forum.get_key(name)
    int(id_, 10)  # id is int with base 10
    return id_

# def aftw(name):
#     id_ = get_forum_id(name)
#     logger.info('Appending %s (%s) to forums', name, id_)
#     forums.append(id_)

# def rffw(name):
#     id_ = get_forum_id(name)
#     logger.info('Removing %s (%s) from forums', name, id_)
#     forums.remove(id_)

# def aftw(name):
#     id_ = get_forum_id(name)
#     logger.info('Appending %s to forums', name)
#     forums.add(name)

# def rffw(name):
#     id_ = get_forum_id(name)
#     logger.info('Removing %s from forums', name)
#     forums.remove(name)

r_udf = re.compile(regexp.udf_prefix)

def affu(urls):
    for user, domain, forum in r_udf.findall(urls):
        if domain not in forums:
            forums[domain] = set()
        if len(forum) > 0:
            get_forum_id(forum)
        logger.info('Appending %s:%s to forums[%s]', user, forum, domain)
        forums[domain].add((user, forum))

def rffu(urls):
    for user, domain, forum in r_udf.findall(urls):
        if len(forum) > 0:
            get_forum_id(forum)
        logger.info('Removing %s:%s from forums[%s]', user, forum, domain)
        forums[domain].remove((user, forum))

def add_user(domain, login, passwd):
    uq = wm.get_userqueue(domain)
    uq.put({'login': login, 'passwd': passwd}, False)

def send_to_wm(frames):
    msg = [frames[0]]
    msg.extend(wzrpc.make_sig_msg(frames[1], frames[2], frames[3:]))
    sig_sock.send_multipart(msg)

def send_passthrough(frames):
    msg = [b'WipeManager']
    msg.extend(wzrpc.make_sig_msg(b'WipeManager', b'passthrough', frames))
    sig_sock.send_multipart(msg)

def drop_users():
    send_passthrough([b'WipeSkel', b'WipeSkel', b'drop-user'])

def log_spawn_name():
    send_passthrough([b'WipeThread', b'WipeThread', b'log-spawn-name'])

if c.no_shell:
    while True:
        time.sleep(1)
else:
    try:
        import IPython
        IPython.embed()
    except ImportError:
        # fallback shell
        while True:
            try:
                exec(input('> '))
            except KeyboardInterrupt:
                print(""KeyboardInterrupt"")
            except SystemExit:
                break
            except:
                print(traceback.format_exc())

terminate()
/n/n/n/uniwipe.py/n/n# -*- coding: utf-8 -*-
# -*- mode: python -*-
from sup.net import NetError
from wzworkers import WorkerInterrupt
from wipeskel import WipeSkel, WipeState, cstate
from beon import exc, regexp
import re

class UniWipe(WipeSkel):
    def __init__(self, forums, targets, sbjfun, msgfun, *args, **kvargs):
        self.sbjfun = sbjfun
        self.msgfun = msgfun
        self.forums = forums
        self.targets = (type(targets) == str and [('', targets)]
                        or type(targets) == tuple and list(targets)
                        or targets)
        super().__init__(*args, **kvargs)

    def on_caprate_limit(self, rate):
        if not self.logined:
            self._capdata = (0, 0)
            return
        self.log.warning('Caprate limit reached, calling dologin() for now')
        self.dologin()
        # super().on_caprate_limit(rate)

    def comment_loop(self):
        for t in self.targets:
            self.schedule(self.add_comment, (t, self.msgfun()))
        if len(self.targets) == 0:
            self.schedule(self.scan_targets_loop)
        else:
            self.schedule(self.comment_loop)

    def add_comment(self, t, msg):
        # with cstate(self, WipeState.posting_comment):
        if True: # Just a placeholder
            try:
                # self.counter_tick()
                self.postmsg(t[1], msg, t[0])
            except exc.Success as e:
                self.counters['comments'] += 1
                self.w.sleep(self.comment_successtimeout)
            except exc.Antispam as e:
                self.w.sleep(self.comment_successtimeout)
                self.schedule(self.add_comment, (t, msg))
            except (exc.Closed, exc.UserDeny) as e:
                try:
                    self.targets.remove(t)
                except ValueError:
                    pass
                self.w.sleep(self.comment_successtimeout)
            except exc.Captcha as e:
                self.log.error('Too many wrong answers to CAPTCHA')
                self.schedule(self.add_comment, (t, msg))
            except exc.UnknownAnswer as e:
                self.log.warn('%s: %s', e, e.answer)
                self.schedule(self.add_comment, (t, msg))
            except exc.Wait5Min as e:
                self.schedule(self.add_comment, (t, msg))
                self.schedule_first(self.switch_user)
            except exc.EmptyAnswer as e:
                self.log.info('Removing %s from targets', t)
                try:
                    self.targets.remove(t)
                except ValueError as e:
                    pass
                self.w.sleep(self.errortimeout)
            except exc.TemporaryError as e:
                self.schedule(self.add_comment, (t, msg))
                self.w.sleep(self.errortimeout)
            except exc.PermanentError as e:
                try:
                    self.targets.remove(t)
                except ValueError as e:
                    pass
                self.w.sleep(self.errortimeout)
            except UnicodeDecodeError as e:
                self.log.exception(e)
                self.w.sleep(self.errortimeout)

    def forumwipe_loop(self):
        for f in self.forums:
            self.counter_tick()
            try:
                self.addtopic(self.msgfun(), self.sbjfun(), f)
            except exc.Success as e:
                self.counters['topics'] += 1
                self.w.sleep(self.topic_successtimeout)
            except exc.Wait5Min as e:
                self.topic_successtimeout = self.topic_successtimeout + 0.1
                self.log.info('Wait5Min exc caught, topic_successtimeout + 0.1, cur: %f',
                    self.topic_successtimeout)
                self.w.sleep(self.topic_successtimeout)
            except exc.Captcha as e:
                self.log.error('Too many wrong answers to CAPTCHA')
                self.long_sleep(10)
            except exc.UnknownAnswer as e:
                self.log.warning('%s: %s', e, e.answer)
                self.w.sleep(self.errortimeout)
            except exc.PermanentError as e:
                self.log.error(e)
                self.w.sleep(self.errortimeout)
            except exc.TemporaryError as e:
                self.log.warn(e)
                self.w.sleep(self.errortimeout)

    def get_targets(self):
        found_count = 0
        for user, forum in self.forums:
            targets = []
            self.log.debug('Scanning first page of the forum %s:%s', user, forum)
            page = self.site.get_page('1', forum, user)
            rxp = re.compile(regexp.f_sub_id.format(user, self.site.domain, forum))
            found = set(map(lambda x: (user, x[0]+x[1]), rxp.findall(page)))
            for t in found:
                if (t in self.pc.sets['closed']
                    or t in self.pc.sets['bumplimit']
                    or t in self.targets):
                    continue
                targets.append(t)
            lt = len(targets)
            found_count += lt
            if lt > 0:
                self.log.info('Found %d new targets in forum %s:%s', lt, user, forum)
            else:
                self.log.debug('Found no new targets in forum %s:%s', user, forum)
            self.targets.extend(targets)
        return found_count

    def scan_targets_loop(self):
        with cstate(self, WipeState.scanning_for_targets):
            while len(self.targets) == 0:
                c = self.get_targets()
                if c == 0:
                    self.log.info('No targets found at all, sleeping for 30 seconds')
                    self.long_sleep(30)
            self.schedule(self.comment_loop)
        if len(self.forums) == 0:
            self.schedule(self.wait_loop)

    def wait_loop(self):
        if len(self.targets) > 0:
            self.schedule(self.comment_loop)
            return
        if len(self.forums) == 0:
            with cstate(self, WipeState.waiting_for_targets):
                while len(self.forums) == 0:
                    # To prevent a busy loop.
                    self.counter_tick()
                    self.w.sleep(1)
        self.schedule(self.scan_targets_loop)

    def _run(self):
        self.schedule(self.dologin)
        self.schedule(self.wait_loop)
        self.schedule(self.counter_ticker.tick)
        try:
            self.perform_tasks()
        except NetError as e:
            self.log.error(e)
        except WorkerInterrupt as e:
            self.log.warning(e)
        except Exception as e:
            self.log.exception(e)
        self.return_user()
# tw_flag = False
# if len(self.targets) > 0:
#     with cstate(self, WipeState.posting_comment):
#         while len(self.targets) > 0:
#             self.threadwipe_loop()
#     if not tw_flag:
#         tw_flag = True
# if tw_flag:
#     # Sleep for topic_successtimeout after last comment
#     # to prevent a timeout spike
#     self.w.sleep(self.topic_successtimeout)
#     tw_flag = False
# with cstate(self, WipeState.posting_topic):
# self.forumwipe_loop()
/n/n/n",1
60,60,bb986000ed3cb222832e1e4535dd6316d32503f8,"tcms/core/ajax.py/n/n# -*- coding: utf-8 -*-
""""""
Shared functions for plan/case/run.

Most of these functions are use for Ajax.
""""""
import datetime
import json
from distutils.util import strtobool

from django import http
from django.db.models import Q, Count
from django.contrib.auth.models import User
from django.core import serializers
from django.core.exceptions import ObjectDoesNotExist
from django.apps import apps
from django.forms import ValidationError
from django.http import Http404
from django.http import HttpResponse
from django.shortcuts import render
from django.views.decorators.http import require_GET
from django.views.decorators.http import require_POST

from tcms.signals import POST_UPDATE_SIGNAL
from tcms.management.models import Component, Build, Version
from tcms.management.models import Priority
from tcms.management.models import Tag
from tcms.management.models import EnvGroup, EnvProperty, EnvValue
from tcms.testcases.models import TestCase, Bug
from tcms.testcases.models import Category
from tcms.testcases.models import TestCaseStatus, TestCaseTag
from tcms.testcases.views import plan_from_request_or_none
from tcms.testplans.models import TestPlan, TestCasePlan, TestPlanTag
from tcms.testruns.models import TestRun, TestCaseRun, TestCaseRunStatus, TestRunTag
from tcms.core.helpers.comments import add_comment
from tcms.core.utils.validations import validate_bug_id


def check_permission(request, ctype):
    perm = '%s.change_%s' % tuple(ctype.split('.'))
    if request.user.has_perm(perm):
        return True
    return False


def strip_parameters(request_dict, skip_parameters):
    parameters = {}
    for key, value in request_dict.items():
        if key not in skip_parameters and value:
            parameters[str(key)] = value

    return parameters


@require_GET
def info(request):
    """"""Ajax responder for misc information""""""

    objects = _InfoObjects(request=request, product_id=request.GET.get('product_id'))
    info_type = getattr(objects, request.GET.get('info_type'))

    if not info_type:
        return HttpResponse('Unrecognizable info-type')

    if request.GET.get('format') == 'ulli':
        field = request.GET.get('field', default='name')

        response_str = '<ul>'
        for obj_value in info_type().values(field):
            response_str += '<li>' + obj_value.get(field, None) + '</li>'
        response_str += '</ul>'

        return HttpResponse(response_str)

    return HttpResponse(serializers.serialize('json', info_type(), fields=('name', 'value')))


class _InfoObjects(object):

    def __init__(self, request, product_id=None):
        self.request = request
        try:
            self.product_id = int(product_id)
        except (ValueError, TypeError):
            self.product_id = 0

    def builds(self):
        try:
            is_active = strtobool(self.request.GET.get('is_active', default='False'))
        except (ValueError, TypeError):
            is_active = False

        return Build.objects.filter(product_id=self.product_id, is_active=is_active)

    def categories(self):
        return Category.objects.filter(product__id=self.product_id)

    def components(self):
        return Component.objects.filter(product__id=self.product_id)

    def env_groups(self):
        return EnvGroup.objects.all()

    def env_properties(self):
        if self.request.GET.get('env_group_id'):
            return EnvGroup.objects.get(id=self.request.GET['env_group_id']).property.all()
        return EnvProperty.objects.all()

    def env_values(self):
        return EnvValue.objects.filter(property__id=self.request.GET.get('env_property_id'))

    def users(self):
        query = strip_parameters(self.request.GET, skip_parameters=('info_type', 'field', 'format'))
        return User.objects.filter(**query)

    def versions(self):
        return Version.objects.filter(product__id=self.product_id)


def tags(request):
    """""" Get tags for TestPlan, TestCase or TestRun """"""

    tag_objects = _TagObjects(request)
    template_name, obj = tag_objects.get()

    q_tag = request.GET.get('tags')
    q_action = request.GET.get('a')

    if q_action:
        tag_actions = _TagActions(obj=obj, tag_name=q_tag)
        getattr(tag_actions, q_action)()

    all_tags = obj.tag.all().order_by('pk')
    test_plan_tags = TestPlanTag.objects.filter(
        tag__in=all_tags).values('tag').annotate(num_plans=Count('tag')).order_by('tag')
    test_case_tags = TestCaseTag.objects.filter(
        tag__in=all_tags).values('tag').annotate(num_cases=Count('tag')).order_by('tag')
    test_run_tags = TestRunTag.objects.filter(
        tag__in=all_tags).values('tag').annotate(num_runs=Count('tag')).order_by('tag')

    plan_counter = _TagCounter('num_plans', test_plan_tags)
    case_counter = _TagCounter('num_cases', test_case_tags)
    run_counter = _TagCounter('num_runs', test_run_tags)

    for tag in all_tags:
        tag.num_plans = plan_counter.calculate_tag_count(tag)
        tag.num_cases = case_counter.calculate_tag_count(tag)
        tag.num_runs = run_counter.calculate_tag_count(tag)

    context_data = {
        'tags': all_tags,
        'object': obj,
    }
    return render(request, template_name, context_data)


class _TagObjects(object):
    """""" Used for getting the chosen object(TestPlan, TestCase or TestRun) from the database """"""

    def __init__(self, request):
        """"""
        :param request: An HTTP GET request, containing the primary key
                        and the type of object to be selected
        :type request: HttpRequest
        """"""
        for obj in ['plan', 'case', 'run']:
            if request.GET.get(obj):
                self.object = obj
                self.object_pk = request.GET.get(obj)
                break

    def get(self):
        func = getattr(self, self.object)
        return func()

    def plan(self):
        return 'management/get_tag.html', TestPlan.objects.get(pk=self.object_pk)

    def case(self):
        return 'management/get_tag.html', TestCase.objects.get(pk=self.object_pk)

    def run(self):
        return 'run/get_tag.html', TestRun.objects.get(pk=self.object_pk)


class _TagActions(object):
    """""" Used for performing the 'add' and 'remove' actions on a given tag """"""

    def __init__(self, obj, tag_name):
        """"""
        :param obj: the object for which the tag actions would be performed
        :type obj: either a :class:`tcms.testplans.models.TestPlan`,
                          a :class:`tcms.testcases.models.TestCase` or
                          a :class:`tcms.testruns.models.TestRun`
        :param tag_name: The name of the tag to be manipulated
        :type tag_name: str
        """"""
        self.obj = obj
        self.tag_name = tag_name

    def add(self):
        tag, _ = Tag.objects.get_or_create(name=self.tag_name)
        self.obj.add_tag(tag)

    def remove(self):
        tag = Tag.objects.get(name=self.tag_name)
        self.obj.remove_tag(tag)


class _TagCounter(object):
    """""" Used for counting the number of times a tag is assigned to TestRun/TestCase/TestPlan """"""

    def __init__(self, key, test_tags):
        """"""
         :param key: either 'num_plans', 'num_cases', 'num_runs', depending on what you want count
         :type key: str
         :param test_tags: query set, containing the Tag->Object relationship, ordered by tag and
                            annotated by key
            e.g. TestPlanTag, TestCaseTag ot TestRunTag
         :type test_tags: QuerySet
        """"""
        self.key = key
        self.test_tags = iter(test_tags)
        self.counter = {'tag': 0}

    def calculate_tag_count(self, tag):
        """"""
        :param tag: the tag you do the counting for
        :type tag: :class:`tcms.management.models.Tag`
        :return: the number of times a tag is assigned to object
        :rtype: int
        """"""
        if self.counter['tag'] != tag.pk:
            try:
                self.counter = self.test_tags.__next__()
            except StopIteration:
                return 0

        if tag.pk == self.counter['tag']:
            return self.counter[self.key]
        return 0


def get_value_by_type(val, v_type):
    """"""
    Exampls:
    1. get_value_by_type('True', 'bool')
    (1, None)
    2. get_value_by_type('19860624 123059', 'datetime')
    (datetime.datetime(1986, 6, 24, 12, 30, 59), None)
    3. get_value_by_type('5', 'int')
    ('5', None)
    4. get_value_by_type('string', 'str')
    ('string', None)
    5. get_value_by_type('everything', 'None')
    (None, None)
    6. get_value_by_type('buggy', 'buggy')
    (None, 'Unsupported value type.')
    7. get_value_by_type('string', 'int')
    (None, ""invalid literal for int() with base 10: 'string'"")
    """"""
    value = error = None

    def get_time(time):
        date_time = datetime.datetime
        if time == 'NOW':
            return date_time.now()
        return date_time.strptime(time, '%Y%m%d %H%M%S')

    pipes = {
        # Temporary solution is convert all of data to str
        # 'bool': lambda x: x == 'True',
        'bool': lambda x: x == 'True' and 1 or 0,
        'datetime': get_time,
        'int': lambda x: str(int(x)),
        'str': lambda x: str(x),
        'None': lambda x: None,
    }
    pipe = pipes.get(v_type, None)
    if pipe is None:
        error = 'Unsupported value type.'
    else:
        try:
            value = pipe(val)
        except Exception as e:
            error = str(e)
    return value, error


def say_no(error_msg):
    ajax_response = {'rc': 1, 'response': error_msg}
    return HttpResponse(json.dumps(ajax_response))


def say_yes():
    return HttpResponse(json.dumps({'rc': 0, 'response': 'ok'}))


# Deprecated. Not flexible.
@require_POST
def update(request):
    """"""
    Generic approach to update a model,\n
    based on contenttype.
    """"""
    now = datetime.datetime.now()

    data = request.POST.copy()
    ctype = data.get(""content_type"")
    vtype = data.get('value_type', 'str')
    object_pk_str = data.get(""object_pk"")
    field = data.get('field')
    value = data.get('value')

    object_pk = [int(a) for a in object_pk_str.split(',')]

    if not field or not value or not object_pk or not ctype:
        return say_no(
            'Following fields are required - content_type, '
            'object_pk, field and value.')

    # Convert the value type
    # FIXME: Django bug here: update() keywords must be strings
    field = str(field)

    value, error = get_value_by_type(value, vtype)
    if error:
        return say_no(error)
    has_perms = check_permission(request, ctype)
    if not has_perms:
        return say_no('Permission Dinied.')

    model = apps.get_model(*ctype.split(""."", 1))
    targets = model._default_manager.filter(pk__in=object_pk)

    if not targets:
        return say_no('No record found')
    if not hasattr(targets[0], field):
        return say_no('%s has no field %s' % (ctype, field))

    if hasattr(targets[0], 'log_action'):
        for t in targets:
            try:
                t.log_action(
                    who=request.user,
                    action='Field %s changed from %s to %s.' % (
                        field, getattr(t, field), value
                    )
                )
            except (AttributeError, User.DoesNotExist):
                pass
    objects_update(targets, **{field: value})

    if hasattr(model, 'mail_scene'):
        mail_context = model.mail_scene(
            objects=targets, field=field, value=value, ctype=ctype,
            object_pk=object_pk,
        )
        if mail_context:
            from tcms.core.utils.mailto import mailto

            mail_context['context']['user'] = request.user
            try:
                mailto(**mail_context)
            except Exception:  # nosec:B110:try_except_pass
                pass

    # Special hacking for updating test case run status
    if ctype == 'testruns.testcaserun' and field == 'case_run_status':
        for t in targets:
            field = 'close_date'
            t.log_action(
                who=request.user,
                action='Field %s changed from %s to %s.' % (
                    field, getattr(t, field), now
                )
            )
            if t.tested_by != request.user:
                field = 'tested_by'
                t.log_action(
                    who=request.user,
                    action='Field %s changed from %s to %s.' % (
                        field, getattr(t, field), request.user
                    )
                )

            field = 'assignee'
            try:
                assignee = t.assginee
                if assignee != request.user:
                    t.log_action(
                        who=request.user,
                        action='Field %s changed from %s to %s.' % (
                            field, getattr(t, field), request.user
                        )
                    )
                    # t.assignee = request.user
                t.save()
            except (AttributeError, User.DoesNotExist):
                pass
        targets.update(close_date=now, tested_by=request.user)
    return say_yes()


@require_POST
def update_case_run_status(request):
    """"""
    Update Case Run status.
    """"""
    now = datetime.datetime.now()

    data = request.POST.copy()
    ctype = data.get(""content_type"")
    vtype = data.get('value_type', 'str')
    object_pk_str = data.get(""object_pk"")
    field = data.get('field')
    value = data.get('value')

    object_pk = [int(a) for a in object_pk_str.split(',')]

    if not field or not value or not object_pk or not ctype:
        return say_no(
            'Following fields are required - content_type, '
            'object_pk, field and value.')

    # Convert the value type
    # FIXME: Django bug here: update() keywords must be strings
    field = str(field)

    value, error = get_value_by_type(value, vtype)
    if error:
        return say_no(error)
    has_perms = check_permission(request, ctype)
    if not has_perms:
        return say_no('Permission Dinied.')

    model = apps.get_model(*ctype.split(""."", 1))
    targets = model._default_manager.filter(pk__in=object_pk)

    if not targets:
        return say_no('No record found')
    if not hasattr(targets[0], field):
        return say_no('%s has no field %s' % (ctype, field))

    if hasattr(targets[0], 'log_action'):
        for t in targets:
            try:
                t.log_action(
                    who=request.user,
                    action='Field {} changed from {} to {}.'.format(
                        field,
                        getattr(t, field),
                        TestCaseRunStatus.id_to_string(value),
                    )
                )
            except (AttributeError, User.DoesNotExist):
                pass
    objects_update(targets, **{field: value})

    if hasattr(model, 'mail_scene'):
        from tcms.core.utils.mailto import mailto

        mail_context = model.mail_scene(
            objects=targets, field=field, value=value, ctype=ctype,
            object_pk=object_pk,
        )
        if mail_context:
            mail_context['context']['user'] = request.user
            try:
                mailto(**mail_context)
            except Exception:  # nosec:B110:try_except_pass
                pass

    # Special hacking for updating test case run status
    if ctype == 'testruns.testcaserun' and field == 'case_run_status':
        for t in targets:
            field = 'close_date'
            t.log_action(
                who=request.user,
                action='Field %s changed from %s to %s.' % (
                    field, getattr(t, field), now
                )
            )
            if t.tested_by != request.user:
                field = 'tested_by'
                t.log_action(
                    who=request.user,
                    action='Field %s changed from %s to %s.' % (
                        field, getattr(t, field), request.user
                    )
                )

            field = 'assignee'
            try:
                assignee = t.assginee
                if assignee != request.user:
                    t.log_action(
                        who=request.user,
                        action='Field %s changed from %s to %s.' % (
                            field, getattr(t, field), request.user
                        )
                    )
                    # t.assignee = request.user
                t.save()
            except (AttributeError, User.DoesNotExist):
                pass
        targets.update(close_date=now, tested_by=request.user)

    return HttpResponse(json.dumps({'rc': 0, 'response': 'ok'}))


class ModelUpdateActions(object):
    """"""Abstract class defining interfaces to update a model properties""""""


class TestCaseUpdateActions(ModelUpdateActions):
    """"""Actions to update each possible proprety of TestCases

    Define your own method named _update_[property name] to hold specific
    update logic.
    """"""

    ctype = 'testcases.testcase'

    def __init__(self, request):
        self.request = request
        self.target_field = request.POST.get('target_field')
        self.new_value = request.POST.get('new_value')

    def get_update_action(self):
        return getattr(self, '_update_%s' % self.target_field, None)

    def update(self):
        has_perms = check_permission(self.request, self.ctype)
        if not has_perms:
            return say_no(""You don't have enough permission to update TestCases."")

        action = self.get_update_action()
        if action is not None:
            try:
                resp = action()
                self._sendmail()
            except ObjectDoesNotExist as err:
                return say_no(str(err))
            except Exception:
                # TODO: besides this message to users, what happening should be
                # recorded in the system log.
                return say_no('Update failed. Please try again or request '
                              'support from your organization.')
            else:
                if resp is None:
                    resp = say_yes()
                return resp
        return say_no('Not know what to update.')

    def get_update_targets(self):
        """"""Get selected cases to update their properties""""""
        case_ids = map(int, self.request.POST.getlist('case'))
        self._update_objects = TestCase.objects.filter(pk__in=case_ids)
        return self._update_objects

    def get_plan(self, pk_enough=True):
        try:
            return plan_from_request_or_none(self.request, pk_enough)
        except Http404:
            return None

    def _sendmail(self):
        mail_context = TestCase.mail_scene(objects=self._update_objects,
                                           field=self.target_field,
                                           value=self.new_value)
        if mail_context:
            from tcms.core.utils.mailto import mailto

            mail_context['context']['user'] = self.request.user
            try:
                mailto(**mail_context)
            except Exception:  # nosec:B110:try_except_pass
                pass

    def _update_priority(self):
        exists = Priority.objects.filter(pk=self.new_value).exists()
        if not exists:
            raise ObjectDoesNotExist('The priority you specified to change '
                                     'does not exist.')
        self.get_update_targets().update(**{str(self.target_field): self.new_value})

    def _update_default_tester(self):
        try:
            user = User.objects.get(Q(username=self.new_value) | Q(email=self.new_value))
        except User.DoesNotExist:
            raise ObjectDoesNotExist('Default tester not found!')
        self.get_update_targets().update(**{str(self.target_field): user.pk})

    def _update_case_status(self):
        try:
            new_status = TestCaseStatus.objects.get(pk=self.new_value)
        except TestCaseStatus.DoesNotExist:
            raise ObjectDoesNotExist('The status you choose does not exist.')

        update_object = self.get_update_targets()
        if not update_object:
            return say_no('No record(s) found')

        for testcase in update_object:
            if hasattr(testcase, 'log_action'):
                testcase.log_action(
                    who=self.request.user,
                    action='Field %s changed from %s to %s.' % (
                        self.target_field, testcase.case_status, new_status.name
                    )
                )
        update_object.update(**{str(self.target_field): self.new_value})

        # ###
        # Case is moved between Cases and Reviewing Cases tabs accoding to the
        # change of status. Meanwhile, the number of cases with each status
        # should be updated also.

        try:
            plan = plan_from_request_or_none(self.request)
        except Http404:
            return say_no(""No plan record found."")
        else:
            if plan is None:
                return say_no('No plan record found.')

        confirm_status_name = 'CONFIRMED'
        plan.run_case = plan.case.filter(case_status__name=confirm_status_name)
        plan.review_case = plan.case.exclude(case_status__name=confirm_status_name)
        run_case_count = plan.run_case.count()
        case_count = plan.case.count()
        # FIXME: why not calculate review_case_count or run_case_count by using
        # substraction, which saves one SQL query.
        review_case_count = plan.review_case.count()

        return http.JsonResponse({
            'rc': 0, 'response': 'ok',
            'run_case_count': run_case_count,
            'case_count': case_count,
            'review_case_count': review_case_count,
        })

    def _update_sortkey(self):
        try:
            sortkey = int(self.new_value)
            if sortkey < 0 or sortkey > 32300:
                return say_no('New sortkey is out of range [0, 32300].')
        except ValueError:
            return say_no('New sortkey is not an integer.')
        plan = plan_from_request_or_none(self.request, pk_enough=True)
        if plan is None:
            return say_no('No plan record found.')
        update_targets = self.get_update_targets()

        # ##
        # MySQL does not allow to exeucte UPDATE statement that contains
        # subquery querying from same table. In this case, OperationError will
        # be raised.
        offset = 0
        step_length = 500
        queryset_filter = TestCasePlan.objects.filter
        data = {self.target_field: sortkey}
        while 1:
            sub_cases = update_targets[offset:offset + step_length]
            case_pks = [case.pk for case in sub_cases]
            if len(case_pks) == 0:
                break
            queryset_filter(plan=plan, case__in=case_pks).update(**data)
            # Move to next batch of cases to change.
            offset += step_length

    def _update_reviewer(self):
        reviewers = User.objects.filter(username=self.new_value).values_list('pk', flat=True)
        if not reviewers:
            err_msg = 'Reviewer %s is not found' % self.new_value
            raise ObjectDoesNotExist(err_msg)
        self.get_update_targets().update(**{str(self.target_field): reviewers[0]})


# NOTE: what permission is necessary
# FIXME: find a good chance to map all TestCase property change request to this
@require_POST
def update_cases_default_tester(request):
    """"""Update default tester upon selected TestCases""""""
    proxy = TestCaseUpdateActions(request)
    return proxy.update()


update_cases_priority = update_cases_default_tester
update_cases_case_status = update_cases_default_tester
update_cases_sortkey = update_cases_default_tester
update_cases_reviewer = update_cases_default_tester


@require_POST
def comment_case_runs(request):
    """"""
    Add comment to one or more caseruns at a time.
    """"""
    data = request.POST.copy()
    comment = data.get('comment', None)
    if not comment:
        return say_no('Comments needed')
    run_ids = [i for i in data.get('run', '').split(',') if i]
    if not run_ids:
        return say_no('No runs selected.')
    runs = TestCaseRun.objects.filter(pk__in=run_ids).only('pk')
    if not runs:
        return say_no('No caserun found.')
    add_comment(runs, comment, request.user)
    return say_yes()


def clean_bug_form(request):
    """"""
    Verify the form data, return a tuple\n
    (None, ERROR_MSG) on failure\n
    or\n
    (data_dict, '') on success.\n
    """"""
    data = {}
    try:
        data['bugs'] = request.GET.get('bug_id', '').split(',')
        data['runs'] = map(int, request.GET.get('case_runs', '').split(','))
    except (TypeError, ValueError) as e:
        return (None, 'Please specify only integers for bugs, '
                      'caseruns(using comma to seperate IDs), '
                      'and bug_system. (DEBUG INFO: %s)' % str(e))

    data['bug_system_id'] = int(request.GET.get('bug_system_id', 1))

    if request.GET.get('a') not in ('add', 'remove'):
        return (None, 'Actions only allow ""add"" and ""remove"".')
    else:
        data['action'] = request.GET.get('a')
    data['bz_external_track'] = True if request.GET.get('bz_external_track',
                                                        False) else False

    return (data, '')


def update_bugs_to_caseruns(request):
    """"""
    Add one or more bugs to or remove that from\n
    one or more caserun at a time.
    """"""
    data, error = clean_bug_form(request)
    if error:
        return say_no(error)
    runs = TestCaseRun.objects.filter(pk__in=data['runs'])
    bug_system_id = data['bug_system_id']
    bug_ids = data['bugs']

    try:
        validate_bug_id(bug_ids, bug_system_id)
    except ValidationError as e:
        return say_no(str(e))

    bz_external_track = data['bz_external_track']
    action = data['action']
    try:
        if action == ""add"":
            for run in runs:
                for bug_id in bug_ids:
                    run.add_bug(bug_id=bug_id,
                                bug_system_id=bug_system_id,
                                bz_external_track=bz_external_track)
        else:
            bugs = Bug.objects.filter(bug_id__in=bug_ids)
            for run in runs:
                for bug in bugs:
                    if bug.case_run_id == run.pk:
                        run.remove_bug(bug.bug_id, run.pk)
    except Exception as e:
        return say_no(str(e))
    return say_yes()


def get_prod_related_objs(p_pks, target):
    """"""
    Get Component, Version, Category, and Build\n
    Return [(id, name), (id, name)]
    """"""
    ctypes = {
        'component': (Component, 'name'),
        'version': (Version, 'value'),
        'build': (Build, 'name'),
        'category': (Category, 'name'),
    }
    results = ctypes[target][0]._default_manager.filter(product__in=p_pks)
    attr = ctypes[target][1]
    results = [(r.pk, getattr(r, attr)) for r in results]
    return results


def get_prod_related_obj_json(request):
    """"""
    View for updating product drop-down\n
    in a Ajax way.
    """"""
    data = request.GET.copy()
    target = data.get('target', None)
    p_pks = data.get('p_ids', None)
    sep = data.get('sep', None)
    # py2.6: all(*values) => boolean ANDs
    if target and p_pks and sep:
        p_pks = [k for k in p_pks.split(sep) if k]
        res = get_prod_related_objs(p_pks, target)
    else:
        res = []
    return HttpResponse(json.dumps(res))


def objects_update(objects, **kwargs):
    objects.update(**kwargs)
    kwargs['instances'] = objects
    if objects.model.__name__ == TestCaseRun.__name__ and kwargs.get(
            'case_run_status', None):
        POST_UPDATE_SIGNAL.send(sender=None, **kwargs)
/n/n/ntcms/core/tests/test_views.py/n/n# -*- coding: utf-8 -*-

import json
from http import HTTPStatus
from urllib.parse import urlencode

from django import test
from django.conf import settings
from django.contrib.contenttypes.models import ContentType
from django.core import serializers
from django.urls import reverse
from django_comments.models import Comment

from tcms.management.models import Priority
from tcms.management.models import EnvGroup
from tcms.management.models import EnvProperty
from tcms.testcases.forms import TestCase
from tcms.testplans.models import TestPlan
from tcms.testruns.models import TestCaseRun
from tcms.testruns.models import TestCaseRunStatus
from tcms.tests import BaseCaseRun
from tcms.tests import BasePlanCase
from tcms.tests import remove_perm_from_user
from tcms.tests import user_should_have_perm
from tcms.tests.factories import UserFactory
from tcms.tests.factories import EnvGroupFactory
from tcms.tests.factories import EnvGroupPropertyMapFactory
from tcms.tests.factories import EnvPropertyFactory


class TestNavigation(test.TestCase):
    @classmethod
    def setUpTestData(cls):
        super(TestNavigation, cls).setUpTestData()
        cls.user = UserFactory(email='user+1@example.com')
        cls.user.set_password('testing')
        cls.user.save()

    def test_urls_for_emails_with_pluses(self):
        # test for https://github.com/Nitrate/Nitrate/issues/262
        # when email contains + sign it needs to be properly urlencoded
        # before passing it as query string argument to the search views
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.user.username,
            password='testing')
        response = self.client.get(reverse('iframe-navigation'))

        self.assertContains(response, urlencode({'people': self.user.email}))
        self.assertContains(response, urlencode({'author__email__startswith': self.user.email}))


class TestIndex(BaseCaseRun):
    def test_when_not_logged_in_index_page_redirects_to_login(self):
        response = self.client.get(reverse('core-views-index'))
        self.assertRedirects(
            response,
            reverse('tcms-login'),
            target_status_code=HTTPStatus.OK)

    def test_when_logged_in_index_page_redirects_to_dashboard(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')
        response = self.client.get(reverse('core-views-index'))
        self.assertRedirects(
            response,
            reverse('tcms-recent', args=[self.tester.username]),
            target_status_code=HTTPStatus.OK)


class TestCommentCaseRuns(BaseCaseRun):
    """"""Test case for ajax.comment_case_runs""""""

    @classmethod
    def setUpTestData(cls):
        super(TestCommentCaseRuns, cls).setUpTestData()
        cls.many_comments_url = reverse('ajax-comment_case_runs')

    def test_refuse_if_missing_comment(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(self.many_comments_url,
                                    {'run': [self.case_run_1.pk, self.case_run_2.pk]})
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': 'Comments needed'})

    def test_refuse_if_missing_no_case_run_pk(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(self.many_comments_url,
                                    {'comment': 'new comment', 'run': []})
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': 'No runs selected.'})

        response = self.client.post(self.many_comments_url,
                                    {'comment': 'new comment'})
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': 'No runs selected.'})

    def test_refuse_if_passed_case_run_pks_not_exist(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(self.many_comments_url,
                                    {'comment': 'new comment',
                                     'run': '99999998,1009900'})
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': 'No caserun found.'})

    def test_add_comment_to_case_runs(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        new_comment = 'new comment'
        response = self.client.post(
            self.many_comments_url,
            {'comment': new_comment,
             'run': ','.join([str(self.case_run_1.pk),
                              str(self.case_run_2.pk)])})
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 0, 'response': 'ok'})

        # Assert comments are added
        case_run_ct = ContentType.objects.get_for_model(TestCaseRun)

        for case_run_pk in (self.case_run_1.pk, self.case_run_2.pk):
            comments = Comment.objects.filter(object_pk=case_run_pk,
                                              content_type=case_run_ct)
            self.assertEqual(new_comment, comments[0].comment)
            self.assertEqual(self.tester, comments[0].user)


class TestUpdateObject(BasePlanCase):
    """"""Test case for update""""""

    @classmethod
    def setUpTestData(cls):
        super(TestUpdateObject, cls).setUpTestData()

        cls.permission = 'testplans.change_testplan'
        cls.update_url = reverse('ajax-update')

    def setUp(self):
        user_should_have_perm(self.tester, self.permission)

    def test_refuse_if_missing_permission(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        remove_perm_from_user(self.tester, self.permission)

        post_data = {
            'content_type': 'testplans.testplan',
            'object_pk': self.plan.pk,
            'field': 'is_active',
            'value': 'False',
            'value_type': 'bool'
        }

        response = self.client.post(self.update_url, post_data)

        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': 'Permission Dinied.'})

    def test_update_plan_is_active(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        post_data = {
            'content_type': 'testplans.testplan',
            'object_pk': self.plan.pk,
            'field': 'is_active',
            'value': 'False',
            'value_type': 'bool'
        }

        response = self.client.post(self.update_url, post_data)

        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 0, 'response': 'ok'})
        plan = TestPlan.objects.get(pk=self.plan.pk)
        self.assertFalse(plan.is_active)


class TestUpdateCaseRunStatus(BaseCaseRun):
    """"""Test case for update_case_run_status""""""

    @classmethod
    def setUpTestData(cls):
        super(TestUpdateCaseRunStatus, cls).setUpTestData()

        cls.permission = 'testruns.change_testcaserun'
        cls.update_url = reverse('ajax-update_case_run_status')

    def setUp(self):
        user_should_have_perm(self.tester, self.permission)

    def test_refuse_if_missing_permission(self):
        remove_perm_from_user(self.tester, self.permission)
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(self.update_url, {
            'content_type': 'testruns.testcaserun',
            'object_pk': self.case_run_1.pk,
            'field': 'case_run_status',
            'value': str(TestCaseRunStatus.objects.get(name='PAUSED').pk),
            'value_type': 'int',
        })

        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': 'Permission Dinied.'})

    def test_change_case_run_status(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(self.update_url, {
            'content_type': 'testruns.testcaserun',
            'object_pk': self.case_run_1.pk,
            'field': 'case_run_status',
            'value': str(TestCaseRunStatus.objects.get(name='PAUSED').pk),
            'value_type': 'int',
        })

        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 0, 'response': 'ok'})
        self.assertEqual(
            'PAUSED', TestCaseRun.objects.get(pk=self.case_run_1.pk).case_run_status.name)


class TestUpdateCasePriority(BasePlanCase):
    """"""Test case for update_cases_default_tester""""""

    @classmethod
    def setUpTestData(cls):
        super(TestUpdateCasePriority, cls).setUpTestData()

        cls.permission = 'testcases.change_testcase'
        cls.case_update_url = reverse('ajax-update_cases_default_tester')

    def setUp(self):
        user_should_have_perm(self.tester, self.permission)

    def test_refuse_if_missing_permission(self):
        remove_perm_from_user(self.tester, self.permission)
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(
            self.case_update_url,
            {
                'target_field': 'priority',
                'from_plan': self.plan.pk,
                'case': [self.case_1.pk, self.case_3.pk],
                'new_value': Priority.objects.get(value='P3').pk,
            })

        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': ""You don't have enough permission to ""
                                  ""update TestCases.""})

    def test_update_case_priority(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(
            self.case_update_url,
            {
                'target_field': 'priority',
                'from_plan': self.plan.pk,
                'case': [self.case_1.pk, self.case_3.pk],
                'new_value': Priority.objects.get(value='P3').pk,
            })

        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 0, 'response': 'ok'})

        for pk in (self.case_1.pk, self.case_3.pk):
            self.assertEqual('P3', TestCase.objects.get(pk=pk).priority.value)


class TestGetObjectInfo(BasePlanCase):
    """"""Test case for info view method""""""

    @classmethod
    def setUpTestData(cls):
        super(TestGetObjectInfo, cls).setUpTestData()

        cls.get_info_url = reverse('ajax-info')

        cls.group_nitrate = EnvGroupFactory(name='nitrate')
        cls.group_new = EnvGroupFactory(name='NewGroup')

        cls.property_os = EnvPropertyFactory(name='os')
        cls.property_python = EnvPropertyFactory(name='python')
        cls.property_django = EnvPropertyFactory(name='django')

        EnvGroupPropertyMapFactory(group=cls.group_nitrate,
                                   property=cls.property_os)
        EnvGroupPropertyMapFactory(group=cls.group_nitrate,
                                   property=cls.property_python)
        EnvGroupPropertyMapFactory(group=cls.group_new,
                                   property=cls.property_django)

    def test_get_env_properties(self):
        response = self.client.get(self.get_info_url, {'info_type': 'env_properties'})

        expected_json = json.loads(
            serializers.serialize(
                'json',
                EnvProperty.objects.all(),
                fields=('name', 'value')))
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            expected_json)

    def test_get_env_properties_by_group(self):
        response = self.client.get(self.get_info_url,
                                   {'info_type': 'env_properties',
                                    'env_group_id': self.group_new.pk})

        group = EnvGroup.objects.get(pk=self.group_new.pk)
        expected_json = json.loads(
            serializers.serialize(
                'json',
                group.property.all(),
                fields=('name', 'value')))
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            expected_json)
/n/n/ntcms/testcases/tests/test_form_views.py/n/n# -*- coding: utf-8 -*-

from django import test
from django.urls import reverse
from django.conf import settings

from tcms.testcases.forms import CaseAutomatedForm


class TestForm_AutomatedView(test.TestCase):
    def test_get_form(self):
        """"""Verify the view renders the expected HTML""""""
        response = self.client.get(reverse('testcases-form-automated'))
        form = CaseAutomatedForm()
        self.assertHTMLEqual(str(response.content, encoding=settings.DEFAULT_CHARSET), form.as_p())
/n/n/ntcms/testcases/urls/cases_urls.py/n/n# -*- coding: utf-8 -*-

from django.conf.urls import url

from .. import views

urlpatterns = [
    url(r'^new/$', views.new, name='testcases-new'),
    url(r'^$', views.all, name='testcases-all'),
    url(r'^search/$', views.search, name='testcases-search'),
    url(r'^load-more/$', views.load_more_cases),
    url(r'^ajax/$', views.ajax_search, name='testcases-ajax_search'),
    url(r'^form/automated/$', views.form_automated, name='testcases-form-automated'),
    url(r'^automated/$', views.automated, name='testcases-automated'),
    url(r'^component/$', views.component, name='testcases-component'),
    url(r'^category/$', views.category, name='testcases-category'),
    url(r'^clone/$', views.clone, name='testcases-clone'),
    url(r'^printable/$', views.printable, name='testcases-printable'),
    url(r'^export/$', views.export, name='testcases-export'),
]
/n/n/ntcms/testcases/views.py/n/n# -*- coding: utf-8 -*-

import datetime
import json
import itertools

from django.conf import settings
from django.contrib import messages
from django.contrib.auth.decorators import permission_required
from django.contrib.contenttypes.models import ContentType
from django.core.exceptions import ObjectDoesNotExist
from django.urls import reverse
from django.db.models import Count
from django.http import HttpResponseRedirect, HttpResponse, Http404
from django.shortcuts import get_object_or_404, render
from django.template.loader import render_to_string
from django.utils.translation import ugettext_lazy as _
from django.views.decorators.http import require_GET
from django.views.decorators.http import require_POST
from django.views.generic.base import TemplateView

from django_comments.models import Comment

from tcms.core.utils import form_errors_to_list
from tcms.core.logs.models import TCMSLogModel
from tcms.core.utils.raw_sql import RawSQL
from tcms.core.utils import DataTableResult
from tcms.search import remove_from_request_path
from tcms.search.order import order_case_queryset
from tcms.testcases import actions
from tcms.testcases import data
from tcms.testcases.models import TestCase, TestCaseStatus, \
    TestCasePlan, BugSystem, \
    Bug, TestCaseText, TestCaseComponent
from tcms.management.models import Priority, Tag
from tcms.testplans.models import TestPlan
from tcms.testruns.models import TestCaseRun
from tcms.testruns.models import TestCaseRunStatus
from tcms.testcases.forms import CaseAutomatedForm, NewCaseForm, \
    SearchCaseForm, EditCaseForm, CaseNotifyForm, \
    CloneCaseForm, CaseBugForm
from tcms.testplans.forms import SearchPlanForm
from tcms.utils.dict_utils import create_dict_from_query
from .fields import CC_LIST_DEFAULT_DELIMITER


TESTCASE_OPERATION_ACTIONS = (
    'search', 'sort', 'update',
    'remove',  # including remove tag from cases
    'add',  # including add tag to cases
    'change',
    'delete_cases',  # unlink cases from a TestPlan
)


# _____________________________________________________________________________
# helper functions


def plan_from_request_or_none(request, pk_enough=False):
    """"""Get TestPlan from REQUEST

    This method relies on the existence of from_plan within REQUEST.

    Arguments:
    - pk_enough: a choice for invoker to determine whether the ID is enough.
    """"""
    tp_id = request.POST.get(""from_plan"") or request.GET.get(""from_plan"")
    if tp_id:
        if pk_enough:
            try:
                tp = int(tp_id)
            except ValueError:
                tp = None
        else:
            tp = get_object_or_404(TestPlan, plan_id=tp_id)
    else:
        tp = None
    return tp


def update_case_email_settings(tc, n_form):
    """"""Update testcase's email settings.""""""

    tc.emailing.notify_on_case_update = n_form.cleaned_data[
        'notify_on_case_update']
    tc.emailing.notify_on_case_delete = n_form.cleaned_data[
        'notify_on_case_delete']
    tc.emailing.auto_to_case_author = n_form.cleaned_data[
        'author']
    tc.emailing.auto_to_case_tester = n_form.cleaned_data[
        'default_tester_of_case']
    tc.emailing.auto_to_run_manager = n_form.cleaned_data[
        'managers_of_runs']
    tc.emailing.auto_to_run_tester = n_form.cleaned_data[
        'default_testers_of_runs']
    tc.emailing.auto_to_case_run_assignee = n_form.cleaned_data[
        'assignees_of_case_runs']
    tc.emailing.save()

    default_tester = n_form.cleaned_data['default_tester_of_case']
    if (default_tester and tc.default_tester_id):
        tc.emailing.auto_to_case_tester = True

    # Continue to update CC list
    valid_emails = n_form.cleaned_data['cc_list']
    tc.emailing.update_cc_list(valid_emails)


def group_case_bugs(bugs):
    """"""Group bugs using bug_id.""""""
    bugs = itertools.groupby(bugs, lambda b: b.bug_id)
    bugs = [(pk, list(_bugs)) for pk, _bugs in bugs]
    return bugs


def create_testcase(request, form, tp):
    """"""Create testcase""""""
    tc = TestCase.create(author=request.user, values=form.cleaned_data)
    tc.add_text(case_text_version=1,
                author=request.user,
                action=form.cleaned_data['action'],
                effect=form.cleaned_data['effect'],
                setup=form.cleaned_data['setup'],
                breakdown=form.cleaned_data['breakdown'])

    # Assign the case to the plan
    if tp:
        tc.add_to_plan(plan=tp)

    # Add components into the case
    for component in form.cleaned_data['component']:
        tc.add_component(component=component)
    return tc


@require_GET
def form_automated(request):
    """"""
        Return HTML for the form which allows changing of automated status.
        Form submission is handled by automated() below.
    """"""
    form = CaseAutomatedForm()
    return HttpResponse(form.as_p())


@require_POST
@permission_required('testcases.change_testcase')
def automated(request):
    """"""Change the automated status for cases

    Parameters:
    - a: Actions
    - case: IDs for case_id
    - o_is_automated: Status for is_automated
    - o_is_automated_proposed: Status for is_automated_proposed

    Returns:
    - Serialized JSON

    """"""
    ajax_response = {'rc': 0, 'response': 'ok'}

    form = CaseAutomatedForm(request.POST)
    if form.is_valid():
        tcs = get_selected_testcases(request)

        if form.cleaned_data['a'] == 'change':
            if isinstance(form.cleaned_data['is_automated'], int):
                # FIXME: inconsistent operation updating automated property
                # upon TestCases. Other place to update property upon
                # TestCase via Model.save, that will trigger model
                #        singal handlers.
                tcs.update(is_automated=form.cleaned_data['is_automated'])
            if isinstance(form.cleaned_data['is_automated_proposed'], bool):
                tcs.update(is_automated_proposed=form.cleaned_data['is_automated_proposed'])
    else:
        ajax_response['rc'] = 1
        ajax_response['response'] = form_errors_to_list(form)

    return HttpResponse(json.dumps(ajax_response))


@permission_required('testcases.add_testcase')
def new(request, template_name='case/new.html'):
    """"""New testcase""""""
    tp = plan_from_request_or_none(request)
    # Initial the form parameters when write new case from plan
    if tp:
        default_form_parameters = {
            'product': tp.product_id,
            'is_automated': '0',
        }
    # Initial the form parameters when write new case directly
    else:
        default_form_parameters = {'is_automated': '0'}

    if request.method == ""POST"":
        form = NewCaseForm(request.POST)
        if request.POST.get('product'):
            form.populate(product_id=request.POST['product'])
        else:
            form.populate()

        if form.is_valid():
            tc = create_testcase(request, form, tp)

            class ReturnActions(object):
                def __init__(self, case, plan):
                    self.__all__ = ('_addanother', '_continue', '_returntocase', '_returntoplan')
                    self.case = case
                    self.plan = plan

                def _continue(self):
                    if self.plan:
                        return HttpResponseRedirect(
                            '%s?from_plan=%s' % (reverse('testcases-edit',
                                                         args=[self.case.case_id]),
                                                 self.plan.plan_id))

                    return HttpResponseRedirect(
                        reverse('testcases-edit', args=[tc.case_id]))

                def _addanother(self):
                    form = NewCaseForm(initial=default_form_parameters)

                    if tp:
                        form.populate(product_id=self.plan.product_id)

                    return form

                def _returntocase(self):
                    if self.plan:
                        return HttpResponseRedirect(
                            '%s?from_plan=%s' % (reverse('testcases-get',
                                                         args=[self.case.pk]),
                                                 self.plan.plan_id))

                    return HttpResponseRedirect(
                        reverse('testcases-get', args=[self.case.pk]))

                def _returntoplan(self):
                    if not self.plan:
                        raise Http404

                    return HttpResponseRedirect(
                        '%s#reviewcases' % reverse('test_plan_url_short',
                                                   args=[self.plan.pk]))

            # Genrate the instance of actions
            ras = ReturnActions(case=tc, plan=tp)
            for ra_str in ras.__all__:
                if request.POST.get(ra_str):
                    func = getattr(ras, ra_str)
                    break
            else:
                func = ras._returntocase

            # Get the function and return back
            result = func()
            if isinstance(result, HttpResponseRedirect):
                return result
            else:
                # Assume here is the form
                form = result

    # Initial NewCaseForm for submit
    else:
        tp = plan_from_request_or_none(request)
        form = NewCaseForm(initial=default_form_parameters)
        if tp:
            form.populate(product_id=tp.product_id)

    context_data = {
        'test_plan': tp,
        'form': form
    }
    return render(request, template_name, context_data)


def get_testcaseplan_sortkey_pk_for_testcases(plan, tc_ids):
    """"""Get each TestCase' sortkey and related TestCasePlan's pk""""""
    qs = TestCasePlan.objects.filter(case__in=tc_ids)
    if plan is not None:
        qs = qs.filter(plan__pk=plan.pk)
    qs = qs.values('pk', 'sortkey', 'case')
    return dict([(item['case'], {
        'testcaseplan_pk': item['pk'],
        'sortkey': item['sortkey']
    }) for item in qs])


def calculate_number_of_bugs_for_testcases(tc_ids):
    """"""Calculate the number of bugs for each TestCase

    Arguments:
    - tc_ids: a list of tuple of TestCases' IDs
    """"""
    qs = Bug.objects.filter(case__in=tc_ids)
    qs = qs.values('case').annotate(total_count=Count('pk'))
    return dict([(item['case'], item['total_count']) for item in qs])


def calculate_for_testcases(plan, testcases):
    """"""Calculate extra data for TestCases

    Attach TestCasePlan.sortkey, TestCasePlan.pk, and the number of bugs of
    each TestCase.

    Arguments:
    - plan: the TestPlan containing searched TestCases. None means testcases
      are not limited to a specific TestPlan.
    - testcases: a queryset of TestCases.
    """"""
    tc_ids = [tc.pk for tc in testcases]
    sortkey_tcpkan_pks = get_testcaseplan_sortkey_pk_for_testcases(
        plan, tc_ids)
    num_bugs = calculate_number_of_bugs_for_testcases(tc_ids)

    # FIXME: strongly recommended to upgrade to Python +2.6
    for tc in testcases:
        data = sortkey_tcpkan_pks.get(tc.pk, None)
        if data:
            setattr(tc, 'cal_sortkey', data['sortkey'])
        else:
            setattr(tc, 'cal_sortkey', None)
        if data:
            setattr(tc, 'cal_testcaseplan_pk', data['testcaseplan_pk'])
        else:
            setattr(tc, 'cal_testcaseplan_pk', None)
        setattr(tc, 'cal_num_bugs', num_bugs.get(tc.pk, None))

    return testcases


def get_case_status(template_type):
    """"""Get part or all TestCaseStatus according to template type""""""
    confirmed_status_name = 'CONFIRMED'
    if template_type == 'case':
        d_status = TestCaseStatus.objects.filter(name=confirmed_status_name)
    elif template_type == 'review_case':
        d_status = TestCaseStatus.objects.exclude(name=confirmed_status_name)
    else:
        d_status = TestCaseStatus.objects.all()
    return d_status


@require_POST
def build_cases_search_form(request, populate=None, plan=None):
    """"""Build search form preparing for quering TestCases""""""
    # Initial the form and template
    action = request.POST.get('a')
    if action in TESTCASE_OPERATION_ACTIONS:
        search_form = SearchCaseForm(request.POST)
        request.session['items_per_page'] = \
            request.POST.get('items_per_page', settings.DEFAULT_PAGE_SIZE)
    else:
        d_status = get_case_status(request.POST.get('template_type'))
        d_status_ids = d_status.values_list('pk', flat=True)
        items_per_page = request.session.get('items_per_page',
                                             settings.DEFAULT_PAGE_SIZE)
        search_form = SearchCaseForm(initial={
            'case_status': d_status_ids,
            'items_per_page': items_per_page})

    if populate:
        if request.POST.get('product'):
            search_form.populate(product_id=request.POST['product'])
        elif plan and plan.product_id:
            search_form.populate(product_id=plan.product_id)
        else:
            search_form.populate()

    return search_form


def paginate_testcases(request, testcases):
    """"""Paginate queried TestCases

    Arguments:
    - request: django's HttpRequest from which to get pagination data
    - testcases: an object queryset representing already queried TestCases

    Return value: return the queryset for chain call
    """"""
    DEFAULT_PAGE_INDEX = 1

    POST = request.POST
    page_index = int(POST.get('page_index', DEFAULT_PAGE_INDEX))
    page_size = int(POST.get('items_per_page',
                             request.session.get('items_per_page',
                                                 settings.DEFAULT_PAGE_SIZE)))
    offset = (page_index - 1) * page_size
    return testcases[offset:offset + page_size]


def sort_queried_testcases(request, testcases):
    """"""Sort querid TestCases according to sort key

    Arguments:
    - request: REQUEST object
    - testcases: object of QuerySet containing queried TestCases
    """"""
    order_by = request.POST.get('order_by', 'create_date')
    asc = bool(request.POST.get('asc', None))
    tcs = order_case_queryset(testcases, order_by, asc)
    # default sorted by sortkey
    tcs = tcs.order_by('testcaseplan__sortkey')
    # Resort the order
    # if sorted by 'sortkey'(foreign key field)
    case_sort_by = request.POST.get('case_sort_by')
    if case_sort_by:
        if case_sort_by not in ['sortkey', '-sortkey']:
            tcs = tcs.order_by(case_sort_by)
        elif case_sort_by == 'sortkey':
            tcs = tcs.order_by('testcaseplan__sortkey')
        else:
            tcs = tcs.order_by('-testcaseplan__sortkey')
    return tcs


def query_testcases_from_request(request, plan=None):
    """"""Query TestCases according to criterias coming within REQUEST

    Arguments:
    - request: the REQUEST object.
    - plan: instance of TestPlan to restrict only those TestCases belongs to
      the TestPlan. Can be None. As you know, query from all TestCases.
    """"""
    search_form = build_cases_search_form(request)

    action = request.POST.get('a')
    if action == 'initial':
        # todo: build_cases_search_form will also check TESTCASE_OPERATION_ACTIONS
        # and return slightly different values in case of initialization
        # move the check there and just execute the query here if the data
        # is valid
        d_status = get_case_status(request.POST.get('template_type'))
        tcs = TestCase.objects.filter(case_status__in=d_status)
    elif action in TESTCASE_OPERATION_ACTIONS and search_form.is_valid():
        tcs = TestCase.list(search_form.cleaned_data, plan)
    else:
        tcs = TestCase.objects.none()

    # Search the relationship
    if plan:
        tcs = tcs.filter(plan=plan)

    tcs = tcs.select_related('author',
                             'default_tester',
                             'case_status',
                             'priority',
                             'category',
                             'reviewer')
    return tcs, search_form


def get_selected_testcases(request):
    """"""Get selected TestCases from client side

    TestCases are selected in two cases. One is user selects part of displayed
    TestCases, where there should be at least one variable named case, whose
    value is the TestCase Id. Another one is user selects all TestCases based
    on previous filter criterias even through there are non-displayed ones. In
    this case, another variable selectAll appears in the REQUEST. Whatever its
    value is.

    If neither variables mentioned exists, empty query result is returned.

    Arguments:
    - request: REQUEST object.
    """"""
    REQ = request.POST or request.GET
    if REQ.get('selectAll', None):
        plan = plan_from_request_or_none(request)
        cases, _search_form = query_testcases_from_request(request, plan)
        return cases
    else:
        pks = [int(pk) for pk in REQ.getlist('case')]
        return TestCase.objects.filter(pk__in=pks)


def load_more_cases(request, template_name='plan/cases_rows.html'):
    """"""Loading more TestCases""""""
    plan = plan_from_request_or_none(request)
    cases = []
    selected_case_ids = []
    if plan is not None:
        cases, _search_form = query_testcases_from_request(request, plan)
        cases = sort_queried_testcases(request, cases)
        cases = paginate_testcases(request, cases)
        cases = calculate_for_testcases(plan, cases)
        selected_case_ids = [tc.pk for tc in cases]
    context_data = {
        'test_plan': plan,
        'test_cases': cases,
        'selected_case_ids': selected_case_ids,
        'case_status': TestCaseStatus.objects.all(),
    }
    return render(request, template_name, context_data)


def get_tags_from_cases(case_ids, plan=None):
    """"""Get all tags from test cases

    @param cases: an iterable object containing test cases' ids
    @type cases: list, tuple

    @param plan: TestPlan object

    @return: a list containing all found tags with id and name
    @rtype: list
    """"""
    query = Tag.objects.filter(case__in=case_ids).distinct().order_by('name')
    if plan:
        query = query.filter(case__plan=plan)

    return query


@require_POST
def all(request):
    """"""
    Generate the TestCase list for the UI tabs in TestPlan page view.

    POST Parameters:
    from_plan: Plan ID
       -- [number]: When the plan ID defined, it will build the case
    page in plan.

    """"""
    # Intial the plan in plan details page
    tp = plan_from_request_or_none(request)
    if not tp:
        messages.add_message(request,
                             messages.ERROR,
                             _('TestPlan not specified or does not exist'))
        return HttpResponseRedirect(reverse('core-views-index'))

    tcs, search_form = query_testcases_from_request(request, tp)
    tcs = sort_queried_testcases(request, tcs)
    total_cases_count = tcs.count()

    # Get the tags own by the cases
    ttags = get_tags_from_cases((case.pk for case in tcs), tp)

    tcs = paginate_testcases(request, tcs)

    # There are several extra information related to each TestCase to be shown
    # also. This step must be the very final one, because the calculation of
    # related data requires related TestCases' IDs, that is the queryset of
    # TestCases should be evaluated in advance.
    tcs = calculate_for_testcases(tp, tcs)

    # generating a query_url with order options
    #
    # FIXME: query_url is always equivlant to None&asc=True whatever what
    # criterias specified in filter form, or just with default filter
    # conditions during loading TestPlan page.
    query_url = remove_from_request_path(request, 'order_by')
    asc = bool(request.POST.get('asc', None))
    if asc:
        query_url = remove_from_request_path(query_url, 'asc')
    else:
        query_url = '%s&asc=True' % query_url

    context_data = {
        'test_cases': tcs,
        'test_plan': tp,
        'search_form': search_form,
        # selected_case_ids is used in template to decide whether or not this TestCase is selected
        'selected_case_ids': [test_case.pk for test_case in get_selected_testcases(request)],
        'case_status': TestCaseStatus.objects.all(),
        'priorities': Priority.objects.all(),
        'case_own_tags': ttags,
        'query_url': query_url,

        # Load more is a POST request, so POST parameters are required only.
        # Remember this for loading more cases with the same as criterias.
        'search_criterias': request.body.decode(),
        'total_cases_count': total_cases_count,
    }
    return render(request, 'plan/get_cases.html', context_data)


@require_GET
def search(request, template_name='case/all.html'):
    """"""
    generate the function of searching cases with search criteria
    """"""
    search_form = SearchCaseForm(request.GET)
    if request.GET.get('product'):
        search_form.populate(product_id=request.GET['product'])
    else:
        search_form.populate()

    context_data = {
        'search_form': search_form,
    }
    return render(request, template_name, context_data)


@require_GET
def ajax_search(request, template_name='case/common/json_cases.txt'):
    """"""Generate the case list in search case and case zone in plan
    """"""
    tp = plan_from_request_or_none(request)

    action = request.GET.get('a')

    # Initial the form and template
    if action in ('search', 'sort'):
        search_form = SearchCaseForm(request.GET)
    else:
        # Hacking for case plan
        confirmed_status_name = 'CONFIRMED'
        # 'c' is meaning component
        template_type = request.GET.get('template_type')
        if template_type == 'case':
            d_status = TestCaseStatus.objects.filter(name=confirmed_status_name)
        elif template_type == 'review_case':
            d_status = TestCaseStatus.objects.exclude(name=confirmed_status_name)
        else:
            d_status = TestCaseStatus.objects.all()

        d_status_ids = d_status.values_list('pk', flat=True)

        search_form = SearchCaseForm(initial={'case_status': d_status_ids})

    # Populate the form
    if request.GET.get('product'):
        search_form.populate(product_id=request.GET['product'])
    elif tp and tp.product_id:
        search_form.populate(product_id=tp.product_id)
    else:
        search_form.populate()

    # Query the database when search
    if action in ('search', 'sort') and search_form.is_valid():
        tcs = TestCase.list(search_form.cleaned_data)
    elif action == 'initial':
        tcs = TestCase.objects.filter(case_status__in=d_status)
    else:
        tcs = TestCase.objects.none()

    # Search the relationship
    if tp:
        tcs = tcs.filter(plan=tp)

    tcs = tcs.select_related(
        'author',
        'default_tester',
        'case_status',
        'priority',
        'category'
    ).only(
        'case_id',
        'summary',
        'create_date',
        'is_automated',
        'is_automated_proposed',
        'case_status__name',
        'category__name',
        'priority__value',
        'author__username',
        'default_tester__id',
        'default_tester__username'
    )
    tcs = tcs.extra(select={'num_bug': RawSQL.num_case_bugs, })

    # columnIndexNameMap is required for correct sorting behavior, 5 should be
    # product, but we use run.build.product
    column_names = [
        '',
        '',
        'case_id',
        'summary',
        'author__username',
        'default_tester__username',
        'is_automated',
        'case_status__name',
        'category__name',
        'priority__value',
        'create_date',
    ]
    return ajax_response(request, tcs, column_names, template_name)


def ajax_response(request, queryset, column_names, template_name):
    """"""json template for the ajax request for searching""""""
    dt = DataTableResult(request.GET, queryset, column_names)

    # todo: prepare the JSON with the response, consider using :
    # from django.template.defaultfilters import escapejs
    json_result = render_to_string(
        template_name,
        dt.get_response_data(),
        request=request)
    return HttpResponse(json_result, content_type='application/json')


class SimpleTestCaseView(TemplateView, data.TestCaseViewDataMixin):
    """"""Simple read-only TestCase View used in TestPlan page""""""

    template_name = 'case/get_details.html'

    # NOTES: what permission is proper for this request?
    def get(self, request, case_id):
        self.case_id = case_id
        self.review_mode = request.GET.get('review_mode')
        return super(SimpleTestCaseView, self).get(request, case_id)

    def get_case(self):
        cases = TestCase.objects.filter(pk=self.case_id).only('notes')
        cases = list(cases.iterator())
        return cases[0] if cases else None

    def get_context_data(self, **kwargs):
        data = super(SimpleTestCaseView, self).get_context_data(**kwargs)

        case = self.get_case()
        data['test_case'] = case
        if case is not None:
            data.update({
                'review_mode': self.review_mode,
                'test_case_text': case.latest_text(),
                'logs': self.get_case_logs(case),
                'components': case.component.only('name'),
                'tags': case.tag.only('name'),
                'case_comments': self.get_case_comments(case),
            })

        return data


class TestCaseCaseRunListPaneView(TemplateView):
    """"""Display case runs list when expand a plan from case page""""""

    template_name = 'case/get_case_runs_by_plan.html'

    # FIXME: what permission here?
    def get(self, request, case_id):
        self.case_id = case_id

        plan_id = self.request.GET.get('plan_id', None)
        self.plan_id = int(plan_id) if plan_id is not None else None

        this_cls = TestCaseCaseRunListPaneView
        return super(this_cls, self).get(request, case_id)

    def get_case_runs(self):
        qs = TestCaseRun.objects.filter(case=self.case_id,
                                        run__plan=self.plan_id)
        qs = qs.values(
            'pk', 'case_id', 'run_id', 'case_text_version',
            'close_date', 'sortkey',
            'tested_by__username', 'assignee__username',
            'run__plan_id', 'run__summary',
            'case__category__name', 'case__priority__value',
            'case_run_status__name',
        ).order_by('pk')
        return qs

    def get_comments_count(self, caserun_ids):
        ct = ContentType.objects.get_for_model(TestCaseRun)
        qs = Comment.objects.filter(content_type=ct,
                                    object_pk__in=caserun_ids,
                                    site_id=settings.SITE_ID,
                                    is_removed=False)
        qs = qs.values('object_pk').annotate(comment_count=Count('pk'))
        result = {}
        for item in qs.iterator():
            result[int(item['object_pk'])] = item['comment_count']
        return result

    def get_context_data(self, **kwargs):
        this_cls = TestCaseCaseRunListPaneView
        data = super(this_cls, self).get_context_data(**kwargs)

        case_runs = self.get_case_runs()

        # Get the number of each caserun's comments, and put the count into
        # comments query result.
        caserun_ids = [item['pk'] for item in case_runs]
        comments_count = self.get_comments_count(caserun_ids)
        for case_run in case_runs:
            case_run['comments_count'] = comments_count.get(case_run['pk'], 0)

        data.update({
            'case_runs': case_runs,
        })
        return data


class TestCaseSimpleCaseRunView(TemplateView, data.TestCaseRunViewDataMixin):
    """"""Display caserun information in Case Runs tab in case page

    This view only shows notes, comments and logs simply. So, call it simple.
    """"""

    template_name = 'case/get_details_case_case_run.html'

    # what permission here?
    def get(self, request, case_id):
        try:
            self.caserun_id = int(request.GET.get('case_run_id', None))
        except (TypeError, ValueError):
            raise Http404

        this_cls = TestCaseSimpleCaseRunView
        return super(this_cls, self).get(request, case_id)

    def get_caserun(self):
        try:
            return TestCaseRun.objects.filter(
                pk=self.caserun_id).only('notes')[0]
        except IndexError:
            raise Http404

    def get_context_data(self, **kwargs):
        this_cls = TestCaseSimpleCaseRunView
        data = super(this_cls, self).get_context_data(**kwargs)

        caserun = self.get_caserun()
        logs = self.get_case_run_logs(caserun)
        comments = self.get_case_run_comments(caserun)

        data.update({
            'test_caserun': caserun,
            'logs': logs.iterator(),
            'comments': comments.iterator(),
        })
        return data


class TestCaseCaseRunDetailPanelView(TemplateView,
                                     data.TestCaseViewDataMixin,
                                     data.TestCaseRunViewDataMixin):
    """"""Display case run detail in run page""""""

    template_name = 'case/get_details_case_run.html'

    def get(self, request, case_id):
        self.case_id = case_id
        try:
            self.caserun_id = int(request.GET.get('case_run_id'))
            self.case_text_version = int(request.GET.get('case_text_version'))
        except (TypeError, ValueError):
            raise Http404

        this_cls = TestCaseCaseRunDetailPanelView
        return super(this_cls, self).get(request, case_id)

    def get_context_data(self, **kwargs):
        this_cls = TestCaseCaseRunDetailPanelView
        data = super(this_cls, self).get_context_data(**kwargs)

        try:
            qs = TestCase.objects.filter(pk=self.case_id)
            qs = qs.prefetch_related('component',
                                     'tag').only('pk')
            case = qs[0]

            qs = TestCaseRun.objects.filter(pk=self.caserun_id).order_by('pk')
            case_run = qs[0]
        except IndexError:
            raise Http404

        # Data of TestCase
        test_case_text = case.get_text_with_version(self.case_text_version)

        # Data of TestCaseRun
        caserun_comments = self.get_case_run_comments(case_run)
        caserun_logs = self.get_case_run_logs(case_run)

        caserun_status = TestCaseRunStatus.objects.values('pk', 'name')
        caserun_status = caserun_status.order_by('sortkey')
        bugs = group_case_bugs(case_run.case.get_bugs().order_by('bug_id'))

        data.update({
            'test_case': case,
            'test_case_text': test_case_text,

            'test_case_run': case_run,
            'comments_count': len(caserun_comments),
            'caserun_comments': caserun_comments,
            'caserun_logs': caserun_logs,
            'test_case_run_status': caserun_status,
            'grouped_case_bugs': bugs,
        })

        return data


def get(request, case_id):
    """"""Get the case content""""""
    # Get the case
    try:
        tc = TestCase.objects.select_related(
            'author', 'default_tester',
            'category', 'category',
            'priority', 'case_status').get(case_id=case_id)
    except ObjectDoesNotExist:
        raise Http404

    # Get the test plans
    tps = tc.plan.select_related('author', 'product', 'type').all()

    # log
    log_id = str(case_id)
    logs = TCMSLogModel.get_logs_for_model(TestCase, log_id)

    logs = itertools.groupby(logs, lambda l: l.date)
    logs = [(day, list(log_actions)) for day, log_actions in logs]
    try:
        tp = tps.get(pk=request.GET.get('from_plan', 0))
    except (TestPlan.DoesNotExist, ValueError):
        # ValueError is raised when from_plan is empty string
        # not viewing TC from a Plan or specified Plan does not exist (e.g. broken link)
        tp = None

    # Get the test case runs
    tcrs = tc.case_run.select_related(
        'run', 'tested_by',
        'assignee', 'case',
        'case', 'case_run_status').all()
    tcrs = tcrs.extra(select={
        'num_bug': RawSQL.num_case_run_bugs,
    }).order_by('run__plan')
    runs_ordered_by_plan = itertools.groupby(tcrs, lambda t: t.run.plan)
    # FIXME: Just don't know why Django template does not evaluate a generator,
    # and had to evaluate the groupby generator manually like below.
    runs_ordered_by_plan = [(k, list(v)) for k, v in runs_ordered_by_plan]
    case_run_plans = [k for k, v in runs_ordered_by_plan]
    # Get the specific test case run
    if request.GET.get('case_run_id'):
        tcr = tcrs.get(pk=request.GET['case_run_id'])
    else:
        tcr = None
    case_run_plan_id = request.GET.get('case_run_plan_id', None)
    if case_run_plan_id:
        for item in runs_ordered_by_plan:
            if item[0].pk == int(case_run_plan_id):
                case_runs_by_plan = item[1]
                break
            else:
                continue
    else:
        case_runs_by_plan = None

    # Get the case texts
    tc_text = tc.get_text_with_version(request.GET.get('case_text_version'))

    grouped_case_bugs = tcr and group_case_bugs(tcr.case.get_bugs())
    # Render the page
    context_data = {
        'logs': logs,
        'test_case': tc,
        'test_plan': tp,
        'test_plans': tps,
        'test_case_runs': tcrs,
        'case_run_plans': case_run_plans,
        'test_case_runs_by_plan': case_runs_by_plan,
        'test_case_run': tcr,
        'grouped_case_bugs': grouped_case_bugs,
        'test_case_text': tc_text,
        'test_case_status': TestCaseStatus.objects.all(),
        'test_case_run_status': TestCaseRunStatus.objects.all(),
        'bug_trackers': BugSystem.objects.all(),
    }
    return render(request, 'case/get.html', context_data)


@require_POST
def printable(request, template_name='case/printable.html'):
    """"""
        Create the printable copy for plan/case.
        Only CONFIRMED TestCases are printed when printing a TestPlan!
    """"""
    # search only by case PK. Used when printing selected cases
    case_ids = request.POST.getlist('case')
    case_filter = {'case__in': case_ids}

    test_plan = None
    # plan_pk is passed from the TestPlan.printable function
    # but it doesn't pass IDs of individual cases to be printed
    if not case_ids:
        plan_pk = request.POST.get('plan', 0)
        try:
            test_plan = TestPlan.objects.get(pk=plan_pk)
            # search cases from a TestPlan, used when printing entire plan
            case_filter = {
                'case__plan': plan_pk,
                'case__case_status': TestCaseStatus.objects.get(name='CONFIRMED').pk,
            }
        except (ValueError, TestPlan.DoesNotExist):
            test_plan = None

    tcs = create_dict_from_query(
        TestCaseText.objects.filter(**case_filter).values(
            'case_id', 'case__summary', 'setup', 'action', 'effect', 'breakdown'
        ).order_by('case_id', '-case_text_version'),
        'case_id',
        True
    )

    context_data = {
        'test_plan': test_plan,
        'test_cases': tcs,
    }
    return render(request, template_name, context_data)


@require_POST
def export(request, template_name='case/export.xml'):
    """"""Export the plan""""""
    case_pks = request.POST.getlist('case')
    context_data = {
        'data_generator': generator_proxy(case_pks),
    }

    response = render(request, template_name, context_data)

    response['Content-Disposition'] = \
        'attachment; filename=tcms-testcases-%s.xml' % datetime.datetime.now().strftime('%Y-%m-%d')
    return response


def generator_proxy(case_pks):
    metas = TestCase.objects.filter(
        pk__in=case_pks
    ).exclude(
        case_status__name='DISABLED'
    ).values(
        'case_id', 'summary', 'is_automated', 'notes',
        'priority__value', 'case_status__name',
        'author__email', 'default_tester__email',
        'category__name')

    component_dict = create_dict_from_query(
        TestCaseComponent.objects.filter(
            case__in=case_pks
        ).values(
            'case_id', 'component_id', 'component__name', 'component__product__name'
        ).order_by('case_id'),
        'case_id'
    )

    tag_dict = create_dict_from_query(
        TestCase.objects.filter(
            pk__in=case_pks
        ).values('case_id', 'tag__name').order_by('case_id'),
        'case_id'
    )

    plan_text_dict = create_dict_from_query(
        TestCaseText.objects.filter(
            case__in=case_pks
        ).values(
            'case_id', 'setup', 'action', 'effect', 'breakdown'
        ).order_by('case_id', '-case_text_version'),
        'case_id',
        True
    )

    for meta in metas:
        case_id = meta['case_id']
        c_meta = component_dict.get(case_id, None)
        if c_meta:
            meta['c_meta'] = c_meta

        tag = tag_dict.get(case_id, None)
        if tag:
            meta['tag'] = tag

        plan_text = plan_text_dict.get(case_id, None)
        if plan_text:
            meta['latest_text'] = plan_text

        yield meta


def update_testcase(request, tc, tc_form):
    """"""Updating information of specific TestCase

    This is called by views.edit internally. Don't call this directly.

    Arguments:
    - tc: instance of a TestCase being updated
    - tc_form: instance of django.forms.Form, holding validated data.
    """"""

    # Modify the contents
    fields = ['summary',
              'case_status',
              'category',
              'priority',
              'notes',
              'is_automated',
              'is_automated_proposed',
              'script',
              'arguments',
              'extra_link',
              'requirement',
              'alias']

    for field in fields:
        if getattr(tc, field) != tc_form.cleaned_data[field]:
            tc.log_action(request.user,
                          'Case %s changed from %s to %s in edit page.' % (
                              field, getattr(tc, field),
                              tc_form.cleaned_data[field]
                          ))
            setattr(tc, field, tc_form.cleaned_data[field])
    try:
        if tc.default_tester != tc_form.cleaned_data['default_tester']:
            tc.log_action(
                request.user,
                'Case default tester changed from %s to %s in edit page.' % (
                    tc.default_tester_id and tc.default_tester,
                    tc_form.cleaned_data['default_tester']
                ))
            tc.default_tester = tc_form.cleaned_data['default_tester']
    except ObjectDoesNotExist:
        pass
    tc.update_tags(tc_form.cleaned_data.get('tag'))
    try:
        fields_text = ['action', 'effect', 'setup', 'breakdown']
        latest_text = tc.latest_text()

        for field in fields_text:
            form_cleaned = tc_form.cleaned_data[field]
            if not (getattr(latest_text, field) or form_cleaned):
                continue
            if getattr(latest_text, field) != form_cleaned:
                tc.log_action(
                    request.user,
                    ' Case %s changed from %s to %s in edit page.' % (
                        field, getattr(latest_text, field) or None,
                        form_cleaned or None
                    ))
    except ObjectDoesNotExist:
        pass

    # FIXME: Bug here, timedelta from form cleaned data need to convert.
    tc.estimated_time = tc_form.cleaned_data['estimated_time']
    # IMPORTANT! tc.current_user is an instance attribute,
    # added so that in post_save, current logged-in user info
    # can be accessed.
    # Instance attribute is usually not a desirable solution.
    tc.current_user = request.user
    tc.save()


@permission_required('testcases.change_testcase')
def edit(request, case_id, template_name='case/edit.html'):
    """"""Edit case detail""""""
    try:
        tc = TestCase.objects.select_related().get(case_id=case_id)
    except ObjectDoesNotExist:
        raise Http404

    tp = plan_from_request_or_none(request)

    if request.method == ""POST"":
        form = EditCaseForm(request.POST)
        if request.POST.get('product'):
            form.populate(product_id=request.POST['product'])
        elif tp:
            form.populate(product_id=tp.product_id)
        else:
            form.populate()

        n_form = CaseNotifyForm(request.POST)

        if form.is_valid() and n_form.is_valid():

            update_testcase(request, tc, form)

            tc.add_text(author=request.user,
                        action=form.cleaned_data['action'],
                        effect=form.cleaned_data['effect'],
                        setup=form.cleaned_data['setup'],
                        breakdown=form.cleaned_data['breakdown'])

            # Notification
            update_case_email_settings(tc, n_form)

            # Returns
            if request.POST.get('_continue'):
                return HttpResponseRedirect('%s?from_plan=%s' % (
                    reverse('testcases-edit', args=[case_id, ]),
                    request.POST.get('from_plan', None),
                ))

            if request.POST.get('_continuenext'):
                if not tp:
                    raise Http404

                # find out test case list which belong to the same
                # classification
                confirm_status_name = 'CONFIRMED'
                if tc.case_status.name == confirm_status_name:
                    pk_list = tp.case.filter(
                        case_status__name=confirm_status_name)
                else:
                    pk_list = tp.case.exclude(
                        case_status__name=confirm_status_name)
                pk_list = list(pk_list.defer('case_id').values_list('pk', flat=True))
                pk_list.sort()

                # Get the previous and next case
                p_tc, n_tc = tc.get_previous_and_next(pk_list=pk_list)
                return HttpResponseRedirect('%s?from_plan=%s' % (
                    reverse('testcases-edit', args=[n_tc.pk, ]),
                    tp.pk,
                ))

            if request.POST.get('_returntoplan'):
                if not tp:
                    raise Http404
                confirm_status_name = 'CONFIRMED'
                if tc.case_status.name == confirm_status_name:
                    return HttpResponseRedirect('%s#testcases' % (
                        reverse('test_plan_url_short', args=[tp.pk, ]),
                    ))
                else:
                    return HttpResponseRedirect('%s#reviewcases' % (
                        reverse('test_plan_url_short', args=[tp.pk, ]),
                    ))

            return HttpResponseRedirect('%s?from_plan=%s' % (
                reverse('testcases-get', args=[case_id, ]),
                request.POST.get('from_plan', None),
            ))

    else:
        tctxt = tc.latest_text()
        # Notification form initial
        n_form = CaseNotifyForm(initial={
            'notify_on_case_update': tc.emailing.notify_on_case_update,
            'notify_on_case_delete': tc.emailing.notify_on_case_delete,
            'author': tc.emailing.auto_to_case_author,
            'default_tester_of_case': tc.emailing.auto_to_case_tester,
            'managers_of_runs': tc.emailing.auto_to_run_manager,
            'default_testers_of_runs': tc.emailing.auto_to_run_tester,
            'assignees_of_case_runs': tc.emailing.auto_to_case_run_assignee,
            'cc_list': CC_LIST_DEFAULT_DELIMITER.join(
                tc.emailing.get_cc_list()),
        })
        default_tester = tc.default_tester_id and tc.default_tester.\
            email or None
        form = EditCaseForm(initial={
            'summary': tc.summary,
            'default_tester': default_tester,
            'requirement': tc.requirement,
            'is_automated': tc.get_is_automated_form_value(),
            'is_automated_proposed': tc.is_automated_proposed,
            'script': tc.script,
            'arguments': tc.arguments,
            'extra_link': tc.extra_link,
            'alias': tc.alias,
            'case_status': tc.case_status_id,
            'priority': tc.priority_id,
            'product': tc.category.product_id,
            'category': tc.category_id,
            'notes': tc.notes,
            'component': [c.pk for c in tc.component.all()],
            'estimated_time': tc.estimated_time,
            'setup': tctxt.setup,
            'action': tctxt.action,
            'effect': tctxt.effect,
            'breakdown': tctxt.breakdown,
            'tag': ','.join(tc.tag.values_list('name', flat=True)),
        })

        form.populate(product_id=tc.category.product_id)

    context_data = {
        'test_case': tc,
        'test_plan': tp,
        'form': form,
        'notify_form': n_form,
    }
    return render(request, template_name, context_data)


def text_history(request, case_id, template_name='case/history.html'):
    """"""View test plan text history""""""

    tc = get_object_or_404(TestCase, case_id=case_id)
    tp = plan_from_request_or_none(request)
    tctxts = tc.text.values('case_id',
                            'case_text_version',
                            'author__email',
                            'create_date').order_by('-case_text_version')

    context_data = {
        'testplan': tp,
        'testcase': tc,
        'test_case_texts': tctxts.iterator(),
    }

    try:
        case_text_version = int(request.GET.get('case_text_version'))
        text_to_show = tc.text.filter(case_text_version=case_text_version)
        text_to_show = text_to_show.values('action',
                                           'effect',
                                           'setup',
                                           'breakdown')

        context_data.update({
            'select_case_text_version': case_text_version,
            'text_to_show': text_to_show.iterator(),
        })
    except (TypeError, ValueError):
        # If case_text_version is not a valid number, no text to display for a
        # selected text history
        pass

    return render(request, template_name, context_data)


@permission_required('testcases.add_testcase')
def clone(request, template_name='case/clone.html'):
    """"""Clone one case or multiple case into other plan or plans""""""

    request_data = getattr(request, request.method)

    if 'selectAll' not in request_data and 'case' not in request_data:
        messages.add_message(request,
                             messages.ERROR,
                             _('At least one TestCase is required'))
        # redirect back where we came from
        return HttpResponseRedirect(request.META.get('HTTP_REFERER', '/'))

    tp_src = plan_from_request_or_none(request)
    tp = None
    search_plan_form = SearchPlanForm()

    # Do the clone action
    if request.method == 'POST':
        clone_form = CloneCaseForm(request.POST)
        clone_form.populate(case_ids=request.POST.getlist('case'))

        if clone_form.is_valid():
            tcs_src = clone_form.cleaned_data['case']
            for tc_src in tcs_src:
                if clone_form.cleaned_data['copy_case']:
                    tc_dest = TestCase.objects.create(
                        is_automated=tc_src.is_automated,
                        is_automated_proposed=tc_src.is_automated_proposed,
                        script=tc_src.script,
                        arguments=tc_src.arguments,
                        extra_link=tc_src.extra_link,
                        summary=tc_src.summary,
                        requirement=tc_src.requirement,
                        alias=tc_src.alias,
                        estimated_time=tc_src.estimated_time,
                        case_status=TestCaseStatus.get_PROPOSED(),
                        category=tc_src.category,
                        priority=tc_src.priority,
                        notes=tc_src.notes,
                        author=clone_form.cleaned_data[
                            'maintain_case_orignal_author'] and
                        tc_src.author or request.user,
                        default_tester=clone_form.cleaned_data[
                            'maintain_case_orignal_default_tester'] and
                        tc_src.author or request.user,
                    )

                    for tp in clone_form.cleaned_data['plan']:
                        # copy a case and keep origin case's sortkey
                        if tp_src:
                            try:
                                tcp = TestCasePlan.objects.get(plan=tp_src,
                                                               case=tc_src)
                                sortkey = tcp.sortkey
                            except ObjectDoesNotExist:
                                sortkey = tp.get_case_sortkey()
                        else:
                            sortkey = tp.get_case_sortkey()

                        tp.add_case(tc_dest, sortkey)

                    tc_dest.add_text(
                        author=clone_form.cleaned_data[
                            'maintain_case_orignal_author'] and
                        tc_src.author or request.user,
                        create_date=tc_src.latest_text().create_date,
                        action=tc_src.latest_text().action,
                        effect=tc_src.latest_text().effect,
                        setup=tc_src.latest_text().setup,
                        breakdown=tc_src.latest_text().breakdown
                    )

                    for tag in tc_src.tag.all():
                        tc_dest.add_tag(tag=tag)
                else:
                    tc_dest = tc_src
                    tc_dest.author = \
                        clone_form.cleaned_data[
                            'maintain_case_orignal_author'] \
                        and tc_src.author or request.user
                    tc_dest.default_tester = \
                        clone_form.cleaned_data[
                            'maintain_case_orignal_default_tester'] \
                        and tc_src.author or request.user
                    tc_dest.save()
                    for tp in clone_form.cleaned_data['plan']:
                        # create case link and keep origin plan's sortkey
                        if tp_src:
                            try:
                                tcp = TestCasePlan.objects.get(plan=tp_src,
                                                               case=tc_dest)
                                sortkey = tcp.sortkey
                            except ObjectDoesNotExist:
                                sortkey = tp.get_case_sortkey()
                        else:
                            sortkey = tp.get_case_sortkey()

                        tp.add_case(tc_dest, sortkey)

                # Add the cases to plan
                for tp in clone_form.cleaned_data['plan']:
                    # Clone the categories to new product
                    if clone_form.cleaned_data['copy_case']:
                        try:
                            tc_category = tp.product.category.get(
                                name=tc_src.category.name
                            )
                        except ObjectDoesNotExist:
                            tc_category = tp.product.category.create(
                                name=tc_src.category.name,
                                description=tc_src.category.description,
                            )

                        tc_dest.category = tc_category
                        tc_dest.save()
                        del tc_category

                    # Clone the components to new product
                    if clone_form.cleaned_data['copy_component'] and \
                            clone_form.cleaned_data['copy_case']:
                        for component in tc_src.component.all():
                            try:
                                new_c = tp.product.component.get(
                                    name=component.name
                                )
                            except ObjectDoesNotExist:
                                new_c = tp.product.component.create(
                                    name=component.name,
                                    initial_owner=request.user,
                                    description=component.description,
                                )

                            tc_dest.add_component(new_c)

            # Detect the number of items and redirect to correct one
            cases_count = len(clone_form.cleaned_data['case'])
            plans_count = len(clone_form.cleaned_data['plan'])

            if cases_count == 1 and plans_count == 1:
                return HttpResponseRedirect('%s?from_plan=%s' % (
                    reverse('testcases-get', args=[tc_dest.pk, ]),
                    tp.pk
                ))

            if cases_count == 1:
                return HttpResponseRedirect(
                    reverse('testcases-get', args=[tc_dest.pk, ])
                )

            if plans_count == 1:
                return HttpResponseRedirect(
                    reverse('test_plan_url_short', args=[tp.pk, ])
                )

            # Otherwise it will prompt to user the clone action is successful.
            messages.add_message(request,
                                 messages.SUCCESS,
                                 _('TestCase cloning was successful'))
            return HttpResponseRedirect(reverse('plans-all'))
    else:
        selected_cases = get_selected_testcases(request)
        # Initial the clone case form
        clone_form = CloneCaseForm(initial={
            'case': selected_cases,
            'copy_case': False,
            'maintain_case_orignal_author': False,
            'maintain_case_orignal_default_tester': False,
            'copy_component': True,
        })
        clone_form.populate(case_ids=selected_cases)

    # Generate search plan form
    if request_data.get('from_plan'):
        tp = TestPlan.objects.get(plan_id=request_data['from_plan'])
        search_plan_form = SearchPlanForm(
            initial={'product': tp.product_id, 'is_active': True})
        search_plan_form.populate(product_id=tp.product_id)

    submit_action = request_data.get('submit', None)
    context_data = {
        'test_plan': tp,
        'search_form': search_plan_form,
        'clone_form': clone_form,
        'submit_action': submit_action,
    }
    return render(request, template_name, context_data)


@require_POST
@permission_required('testcases.add_testcasecomponent')
def component(request):
    """"""
    Management test case components
    """"""
    # FIXME: It will update product/category/component at one time so far.
    # We may disconnect the component from case product in future.
    cas = actions.ComponentActions(request)
    action = request.POST.get('a', 'render_form')
    func = getattr(cas, action.lower())
    return func()


@require_POST
@permission_required('testcases.add_testcasecomponent')
def category(request):
    """"""Management test case categories""""""
    # FIXME: It will update product/category/component at one time so far.
    # We may disconnect the component from case product in future.
    cas = actions.CategoryActions(request)
    func = getattr(cas, request.POST.get('a', 'render_form').lower())
    return func()


@permission_required('testcases.add_testcaseattachment')
def attachment(request, case_id, template_name='case/attachment.html'):
    """"""Manage test case attachments""""""

    tc = get_object_or_404(TestCase, case_id=case_id)
    tp = plan_from_request_or_none(request)

    context_data = {
        'testplan': tp,
        'testcase': tc,
        'limit': settings.FILE_UPLOAD_MAX_SIZE,
    }
    return render(request, template_name, context_data)


def get_log(request, case_id, template_name=""management/get_log.html""):
    """"""Get the case log""""""
    tc = get_object_or_404(TestCase, case_id=case_id)

    context_data = {
        'object': tc
    }
    return render(request, template_name, context_data)


@permission_required('testcases.change_bug')
def bug(request, case_id, template_name='case/get_bug.html'):
    """"""Process the bugs for cases""""""
    # FIXME: Rewrite these codes for Ajax.Request
    tc = get_object_or_404(TestCase, case_id=case_id)

    class CaseBugActions(object):
        __all__ = ['get_form', 'render', 'add', 'remove']

        def __init__(self, request, case, template_name):
            self.request = request
            self.case = case
            self.template_name = template_name

        def render_form(self):
            form = CaseBugForm(initial={
                'case': self.case,
            })
            if request.GET.get('type') == 'table':
                return HttpResponse(form.as_table())

            return HttpResponse(form.as_p())

        def render(self, response=None):
            context_data = {
                'test_case': self.case,
                'response': response
            }
            return render(request, template_name, context_data)

        def add(self):
            # FIXME: It's may use ModelForm.save() method here.
            #        Maybe in future.
            if not self.request.user.has_perm('testcases.add_bug'):
                return self.render(response='Permission denied.')

            form = CaseBugForm(request.GET)
            if not form.is_valid():
                errors = []
                for field_name, error_messages in form.errors.items():
                    for item in error_messages:
                        errors.append(item)
                response = '\n'.join(errors)
                return self.render(response=response)

            try:
                self.case.add_bug(
                    bug_id=form.cleaned_data['bug_id'],
                    bug_system_id=form.cleaned_data['bug_system'].pk,
                    summary=form.cleaned_data['summary'],
                    description=form.cleaned_data['description'],
                )
            except Exception as e:
                return self.render(response=str(e))

            return self.render()

        def remove(self):
            if not request.user.has_perm('testcases.delete_bug'):
                return self.render(response='Permission denied.')

            try:
                self.case.remove_bug(request.GET.get('id'), request.GET.get('run_id'))
            except ObjectDoesNotExist as error:
                return self.render(response=error)

            return self.render()

    case_bug_actions = CaseBugActions(
        request=request,
        case=tc,
        template_name=template_name
    )

    if not request.GET.get('handle') in case_bug_actions.__all__:
        return case_bug_actions.render(response='Unrecognizable actions')

    func = getattr(case_bug_actions, request.GET['handle'])
    return func()


@require_GET
def plan(request, case_id):
    """"""Add and remove plan in plan tab""""""
    tc = get_object_or_404(TestCase, case_id=case_id)
    if request.GET.get('a'):
        # Search the plans from database
        if not request.GET.getlist('plan_id'):
            context_data = {
                'message': 'The case must specific one plan at leaset for '
                           'some action',
            }
            return render(
                request,
                'case/get_plan.html',
                context_data)

        tps = TestPlan.objects.filter(pk__in=request.GET.getlist('plan_id'))

        if not tps:
            context_data = {
                'testplans': tps,
                'message': 'The plan id are not exist in database at all.'
            }
            return render(
                request,
                'case/get_plan.html',
                context_data)

        # Add case plan action
        if request.GET['a'] == 'add':
            if not request.user.has_perm('testcases.add_testcaseplan'):
                context_data = {
                    'test_case': tc,
                    'test_plans': tps,
                    'message': 'Permission denied',
                }
                return render(
                    request,
                    'case/get_plan.html',
                    context_data)

            for tp in tps:
                tc.add_to_plan(tp)

        # Remove case plan action
        if request.GET['a'] == 'remove':
            if not request.user.has_perm('testcases.change_testcaseplan'):
                context_data = {
                    'test_case': tc,
                    'test_plans': tps,
                    'message': 'Permission denied',
                }
                return render(
                    request,
                    'case/get_plan.html',
                    context_data)

            for tp in tps:
                tc.remove_plan(tp)

    tps = tc.plan.all()
    tps = tps.select_related('author',
                             'type',
                             'product')

    context_data = {
        'test_case': tc,
        'test_plans': tps,
    }
    return render(
        request,
        'case/get_plan.html',
        context_data)
/n/n/ntcms/urls.py/n/n# -*- coding: utf-8 -*-

from django.conf import settings
from django.conf.urls import include, url
from django.conf.urls.static import static
from django.contrib import admin
from django.views.i18n import JavaScriptCatalog

from grappelli import urls as grappelli_urls
from attachments import urls as attachments_urls
from modernrpc.core import JSONRPC_PROTOCOL
from modernrpc.core import XMLRPC_PROTOCOL
from modernrpc.views import RPCEntryPoint
from tinymce import urls as tinymce_urls
from tcms.core import ajax
from tcms.core import views as core_views
from tcms.core.contrib.comments import views as comments_views
from tcms.core.contrib.linkreference import views as linkreference_views
from tcms.profiles import urls as profiles_urls
from tcms.testplans import urls as testplans_urls
from tcms.testcases import urls as testcases_urls
from tcms.testruns import urls as testruns_urls
from tcms.testruns import views as testruns_views
from tcms.management import views as management_views
from tcms.report import urls as report_urls
from tcms.search import advance_search


urlpatterns = [
    # iframe navigation workaround
    url(r'^navigation/', core_views.navigation, name='iframe-navigation'),

    url(r'^grappelli/', include(grappelli_urls)),
    url(r'^admin/', admin.site.urls),

    url(r'^attachments/', include(attachments_urls, namespace='attachments')),
    url(r'^tinymce/', include(tinymce_urls)),

    # Index and static zone
    url(r'^$', core_views.index, name='core-views-index'),
    url(r'^xml-rpc/', RPCEntryPoint.as_view(protocol=XMLRPC_PROTOCOL), name='xml-rpc'),
    url(r'^json-rpc/$', RPCEntryPoint.as_view(protocol=JSONRPC_PROTOCOL)),

    # Ajax call responder
    url(r'^ajax/update/$', ajax.update, name='ajax-update'),
    url(r'^ajax/update/case-status/$', ajax.update_cases_case_status),
    url(r'^ajax/update/case-run-status$', ajax.update_case_run_status,
        name='ajax-update_case_run_status'),
    url(r'^ajax/update/cases-priority/$', ajax.update_cases_priority),
    url(r'^ajax/update/cases-default-tester/$', ajax.update_cases_default_tester,
        name='ajax-update_cases_default_tester'),
    url(r'^ajax/update/cases-reviewer/$', ajax.update_cases_reviewer),
    url(r'^ajax/update/cases-sortkey/$', ajax.update_cases_sortkey),
    url(r'^ajax/get-prod-relate-obj/$', ajax.get_prod_related_obj_json),
    url(r'^management/getinfo/$', ajax.info, name='ajax-info'),
    url(r'^management/tags/$', ajax.tags, name='ajax-tags'),

    # comments
    url(r'^comments/post/', comments_views.post, name='comments-post'),
    url(r'^comments/delete/', comments_views.delete, name='comments-delete'),

    # Account information zone, such as login method
    url(r'^accounts/', include(profiles_urls)),

    # Testplans zone
    url(r'^plan/', include(testplans_urls.plan_urls)),
    url(r'^plans/', include(testplans_urls.plans_urls)),

    # Testcases zone
    url(r'^case/', include(testcases_urls.case_urls)),
    url(r'^cases/', include(testcases_urls.cases_urls)),

    # Testruns zone
    url(r'^run/', include(testruns_urls.run_urls)),
    url(r'^runs/', include(testruns_urls.runs_urls)),

    url(r'^caseruns/$', testruns_views.caseruns),
    url(r'^caserun/(?P<case_run_id>\d+)/bug/$', testruns_views.bug, name='testruns-bug'),
    url(r'^caserun/comment-many/', ajax.comment_case_runs, name='ajax-comment_case_runs'),
    url(r'^caserun/update-bugs-for-many/', ajax.update_bugs_to_caseruns),

    url(r'^linkref/add/$', linkreference_views.add, name='linkref-add'),
    url(r'^linkref/remove/(?P<link_id>\d+)/$', linkreference_views.remove),

    # Management zone
    url(r'^environment/groups/$', management_views.environment_groups,
        name='mgmt-environment_groups'),
    url(r'^environment/group/edit/$', management_views.environment_group_edit,
        name='mgmt-environment_group_edit'),
    url(r'^environment/properties/$', management_views.environment_properties,
        name='mgmt-environment_properties'),
    url(r'^environment/properties/values/$', management_views.environment_property_values,
        name='mgmt-environment_property_values'),

    # Report zone
    url(r'^report/', include(report_urls)),

    # Advance search
    url(r'^advance-search/$', advance_search, name='advance_search'),

    # TODO: do we need this at all ???
    # Using admin js without admin permission
    # https://docs.djangoproject.com/en/1.11/topics/i18n/translation/#django.views.i18n.JavaScriptCatalog
    url(r'^jsi18n/$', JavaScriptCatalog.as_view()),
]

# Debug zone

if settings.DEBUG:
    urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)

    try:
        import debug_toolbar

        urlpatterns += [
            url(r'^__debug__/', include(debug_toolbar.urls)),
        ]
    # in case we're trying to debug in production
    # and debug_toolbar is not installed
    except ImportError:
        pass

# Overwrite default 500 handler
# More details could see django.core.urlresolvers._resolve_special()
handler500 = 'tcms.core.views.error.server_error'
/n/n/n",0
61,61,bb986000ed3cb222832e1e4535dd6316d32503f8,"/tcms/core/ajax.py/n/n# -*- coding: utf-8 -*-
""""""
Shared functions for plan/case/run.

Most of these functions are use for Ajax.
""""""
import datetime
import sys
import json
from distutils.util import strtobool

from django import http
from django.db.models import Q, Count
from django.contrib.auth.models import User
from django.core import serializers
from django.core.exceptions import ObjectDoesNotExist
from django.apps import apps
from django.forms import ValidationError
from django.http import Http404
from django.http import HttpResponse
from django.shortcuts import render
from django.views.decorators.http import require_GET
from django.views.decorators.http import require_POST

from tcms.signals import POST_UPDATE_SIGNAL
from tcms.management.models import Component, Build, Version
from tcms.management.models import Priority
from tcms.management.models import Tag
from tcms.management.models import EnvGroup, EnvProperty, EnvValue
from tcms.testcases.models import TestCase, Bug
from tcms.testcases.models import Category
from tcms.testcases.models import TestCaseStatus, TestCaseTag
from tcms.testcases.views import plan_from_request_or_none
from tcms.testplans.models import TestPlan, TestCasePlan, TestPlanTag
from tcms.testruns.models import TestRun, TestCaseRun, TestCaseRunStatus, TestRunTag
from tcms.core.helpers.comments import add_comment
from tcms.core.utils.validations import validate_bug_id


def check_permission(request, ctype):
    perm = '%s.change_%s' % tuple(ctype.split('.'))
    if request.user.has_perm(perm):
        return True
    return False


def strip_parameters(request_dict, skip_parameters):
    parameters = {}
    for key, value in request_dict.items():
        if key not in skip_parameters and value:
            parameters[str(key)] = value

    return parameters


@require_GET
def info(request):
    """"""Ajax responder for misc information""""""

    objects = _InfoObjects(request=request, product_id=request.GET.get('product_id'))
    info_type = getattr(objects, request.GET.get('info_type'))

    if not info_type:
        return HttpResponse('Unrecognizable info-type')

    if request.GET.get('format') == 'ulli':
        field = request.GET.get('field', default='name')

        response_str = '<ul>'
        for obj_value in info_type().values(field):
            response_str += '<li>' + obj_value.get(field, None) + '</li>'
        response_str += '</ul>'

        return HttpResponse(response_str)

    return HttpResponse(serializers.serialize('json', info_type(), fields=('name', 'value')))


class _InfoObjects(object):

    def __init__(self, request, product_id=None):
        self.request = request
        try:
            self.product_id = int(product_id)
        except (ValueError, TypeError):
            self.product_id = 0

    def builds(self):
        try:
            is_active = strtobool(self.request.GET.get('is_active', default='False'))
        except (ValueError, TypeError):
            is_active = False

        return Build.objects.filter(product_id=self.product_id, is_active=is_active)

    def categories(self):
        return Category.objects.filter(product__id=self.product_id)

    def components(self):
        return Component.objects.filter(product__id=self.product_id)

    def env_groups(self):
        return EnvGroup.objects.all()

    def env_properties(self):
        if self.request.GET.get('env_group_id'):
            return EnvGroup.objects.get(id=self.request.GET['env_group_id']).property.all()
        return EnvProperty.objects.all()

    def env_values(self):
        return EnvValue.objects.filter(property__id=self.request.GET.get('env_property_id'))

    def users(self):
        query = strip_parameters(self.request.GET, skip_parameters=('info_type', 'field', 'format'))
        return User.objects.filter(**query)

    def versions(self):
        return Version.objects.filter(product__id=self.product_id)


@require_GET
def form(request):
    """"""Response get form ajax call, most using in dialog""""""

    # The parameters in internal_parameters will delete from parameters
    internal_parameters = ['app_form', 'format']
    parameters = strip_parameters(request.GET, internal_parameters)
    q_app_form = request.GET.get('app_form')
    q_format = request.GET.get('format')
    if not q_format:
        q_format = 'p'

    if not q_app_form:
        return HttpResponse('Unrecognizable app_form')

    # Get the form
    q_app, q_form = q_app_form.split('.')[0], q_app_form.split('.')[1]
    exec('from tcms.%s.forms import %s as form' % (q_app, q_form))
    __import__('tcms.%s.forms' % q_app)
    q_app_module = sys.modules['tcms.%s.forms' % q_app]
    form_class = getattr(q_app_module, q_form)
    form_params = form_class(initial=parameters)

    # Generate the HTML and reponse
    html = getattr(form_params, 'as_' + q_format)
    return HttpResponse(html())


def tags(request):
    """""" Get tags for TestPlan, TestCase or TestRun """"""

    tag_objects = _TagObjects(request)
    template_name, obj = tag_objects.get()

    q_tag = request.GET.get('tags')
    q_action = request.GET.get('a')

    if q_action:
        tag_actions = _TagActions(obj=obj, tag_name=q_tag)
        getattr(tag_actions, q_action)()

    all_tags = obj.tag.all().order_by('pk')
    test_plan_tags = TestPlanTag.objects.filter(
        tag__in=all_tags).values('tag').annotate(num_plans=Count('tag')).order_by('tag')
    test_case_tags = TestCaseTag.objects.filter(
        tag__in=all_tags).values('tag').annotate(num_cases=Count('tag')).order_by('tag')
    test_run_tags = TestRunTag.objects.filter(
        tag__in=all_tags).values('tag').annotate(num_runs=Count('tag')).order_by('tag')

    plan_counter = _TagCounter('num_plans', test_plan_tags)
    case_counter = _TagCounter('num_cases', test_case_tags)
    run_counter = _TagCounter('num_runs', test_run_tags)

    for tag in all_tags:
        tag.num_plans = plan_counter.calculate_tag_count(tag)
        tag.num_cases = case_counter.calculate_tag_count(tag)
        tag.num_runs = run_counter.calculate_tag_count(tag)

    context_data = {
        'tags': all_tags,
        'object': obj,
    }
    return render(request, template_name, context_data)


class _TagObjects(object):
    """""" Used for getting the chosen object(TestPlan, TestCase or TestRun) from the database """"""

    def __init__(self, request):
        """"""
        :param request: An HTTP GET request, containing the primary key
                        and the type of object to be selected
        :type request: HttpRequest
        """"""
        for obj in ['plan', 'case', 'run']:
            if request.GET.get(obj):
                self.object = obj
                self.object_pk = request.GET.get(obj)
                break

    def get(self):
        func = getattr(self, self.object)
        return func()

    def plan(self):
        return 'management/get_tag.html', TestPlan.objects.get(pk=self.object_pk)

    def case(self):
        return 'management/get_tag.html', TestCase.objects.get(pk=self.object_pk)

    def run(self):
        return 'run/get_tag.html', TestRun.objects.get(pk=self.object_pk)


class _TagActions(object):
    """""" Used for performing the 'add' and 'remove' actions on a given tag """"""

    def __init__(self, obj, tag_name):
        """"""
        :param obj: the object for which the tag actions would be performed
        :type obj: either a :class:`tcms.testplans.models.TestPlan`,
                          a :class:`tcms.testcases.models.TestCase` or
                          a :class:`tcms.testruns.models.TestRun`
        :param tag_name: The name of the tag to be manipulated
        :type tag_name: str
        """"""
        self.obj = obj
        self.tag_name = tag_name

    def add(self):
        tag, _ = Tag.objects.get_or_create(name=self.tag_name)
        self.obj.add_tag(tag)

    def remove(self):
        tag = Tag.objects.get(name=self.tag_name)
        self.obj.remove_tag(tag)


class _TagCounter(object):
    """""" Used for counting the number of times a tag is assigned to TestRun/TestCase/TestPlan """"""

    def __init__(self, key, test_tags):
        """"""
         :param key: either 'num_plans', 'num_cases', 'num_runs', depending on what you want count
         :type key: str
         :param test_tags: query set, containing the Tag->Object relationship, ordered by tag and
                            annotated by key
            e.g. TestPlanTag, TestCaseTag ot TestRunTag
         :type test_tags: QuerySet
        """"""
        self.key = key
        self.test_tags = iter(test_tags)
        self.counter = {'tag': 0}

    def calculate_tag_count(self, tag):
        """"""
        :param tag: the tag you do the counting for
        :type tag: :class:`tcms.management.models.Tag`
        :return: the number of times a tag is assigned to object
        :rtype: int
        """"""
        if self.counter['tag'] != tag.pk:
            try:
                self.counter = self.test_tags.__next__()
            except StopIteration:
                return 0

        if tag.pk == self.counter['tag']:
            return self.counter[self.key]
        return 0


def get_value_by_type(val, v_type):
    """"""
    Exampls:
    1. get_value_by_type('True', 'bool')
    (1, None)
    2. get_value_by_type('19860624 123059', 'datetime')
    (datetime.datetime(1986, 6, 24, 12, 30, 59), None)
    3. get_value_by_type('5', 'int')
    ('5', None)
    4. get_value_by_type('string', 'str')
    ('string', None)
    5. get_value_by_type('everything', 'None')
    (None, None)
    6. get_value_by_type('buggy', 'buggy')
    (None, 'Unsupported value type.')
    7. get_value_by_type('string', 'int')
    (None, ""invalid literal for int() with base 10: 'string'"")
    """"""
    value = error = None

    def get_time(time):
        date_time = datetime.datetime
        if time == 'NOW':
            return date_time.now()
        return date_time.strptime(time, '%Y%m%d %H%M%S')

    pipes = {
        # Temporary solution is convert all of data to str
        # 'bool': lambda x: x == 'True',
        'bool': lambda x: x == 'True' and 1 or 0,
        'datetime': get_time,
        'int': lambda x: str(int(x)),
        'str': lambda x: str(x),
        'None': lambda x: None,
    }
    pipe = pipes.get(v_type, None)
    if pipe is None:
        error = 'Unsupported value type.'
    else:
        try:
            value = pipe(val)
        except Exception as e:
            error = str(e)
    return value, error


def say_no(error_msg):
    ajax_response = {'rc': 1, 'response': error_msg}
    return HttpResponse(json.dumps(ajax_response))


def say_yes():
    return HttpResponse(json.dumps({'rc': 0, 'response': 'ok'}))


# Deprecated. Not flexible.
@require_POST
def update(request):
    """"""
    Generic approach to update a model,\n
    based on contenttype.
    """"""
    now = datetime.datetime.now()

    data = request.POST.copy()
    ctype = data.get(""content_type"")
    vtype = data.get('value_type', 'str')
    object_pk_str = data.get(""object_pk"")
    field = data.get('field')
    value = data.get('value')

    object_pk = [int(a) for a in object_pk_str.split(',')]

    if not field or not value or not object_pk or not ctype:
        return say_no(
            'Following fields are required - content_type, '
            'object_pk, field and value.')

    # Convert the value type
    # FIXME: Django bug here: update() keywords must be strings
    field = str(field)

    value, error = get_value_by_type(value, vtype)
    if error:
        return say_no(error)
    has_perms = check_permission(request, ctype)
    if not has_perms:
        return say_no('Permission Dinied.')

    model = apps.get_model(*ctype.split(""."", 1))
    targets = model._default_manager.filter(pk__in=object_pk)

    if not targets:
        return say_no('No record found')
    if not hasattr(targets[0], field):
        return say_no('%s has no field %s' % (ctype, field))

    if hasattr(targets[0], 'log_action'):
        for t in targets:
            try:
                t.log_action(
                    who=request.user,
                    action='Field %s changed from %s to %s.' % (
                        field, getattr(t, field), value
                    )
                )
            except (AttributeError, User.DoesNotExist):
                pass
    objects_update(targets, **{field: value})

    if hasattr(model, 'mail_scene'):
        mail_context = model.mail_scene(
            objects=targets, field=field, value=value, ctype=ctype,
            object_pk=object_pk,
        )
        if mail_context:
            from tcms.core.utils.mailto import mailto

            mail_context['context']['user'] = request.user
            try:
                mailto(**mail_context)
            except Exception:  # nosec:B110:try_except_pass
                pass

    # Special hacking for updating test case run status
    if ctype == 'testruns.testcaserun' and field == 'case_run_status':
        for t in targets:
            field = 'close_date'
            t.log_action(
                who=request.user,
                action='Field %s changed from %s to %s.' % (
                    field, getattr(t, field), now
                )
            )
            if t.tested_by != request.user:
                field = 'tested_by'
                t.log_action(
                    who=request.user,
                    action='Field %s changed from %s to %s.' % (
                        field, getattr(t, field), request.user
                    )
                )

            field = 'assignee'
            try:
                assignee = t.assginee
                if assignee != request.user:
                    t.log_action(
                        who=request.user,
                        action='Field %s changed from %s to %s.' % (
                            field, getattr(t, field), request.user
                        )
                    )
                    # t.assignee = request.user
                t.save()
            except (AttributeError, User.DoesNotExist):
                pass
        targets.update(close_date=now, tested_by=request.user)
    return say_yes()


@require_POST
def update_case_run_status(request):
    """"""
    Update Case Run status.
    """"""
    now = datetime.datetime.now()

    data = request.POST.copy()
    ctype = data.get(""content_type"")
    vtype = data.get('value_type', 'str')
    object_pk_str = data.get(""object_pk"")
    field = data.get('field')
    value = data.get('value')

    object_pk = [int(a) for a in object_pk_str.split(',')]

    if not field or not value or not object_pk or not ctype:
        return say_no(
            'Following fields are required - content_type, '
            'object_pk, field and value.')

    # Convert the value type
    # FIXME: Django bug here: update() keywords must be strings
    field = str(field)

    value, error = get_value_by_type(value, vtype)
    if error:
        return say_no(error)
    has_perms = check_permission(request, ctype)
    if not has_perms:
        return say_no('Permission Dinied.')

    model = apps.get_model(*ctype.split(""."", 1))
    targets = model._default_manager.filter(pk__in=object_pk)

    if not targets:
        return say_no('No record found')
    if not hasattr(targets[0], field):
        return say_no('%s has no field %s' % (ctype, field))

    if hasattr(targets[0], 'log_action'):
        for t in targets:
            try:
                t.log_action(
                    who=request.user,
                    action='Field {} changed from {} to {}.'.format(
                        field,
                        getattr(t, field),
                        TestCaseRunStatus.id_to_string(value),
                    )
                )
            except (AttributeError, User.DoesNotExist):
                pass
    objects_update(targets, **{field: value})

    if hasattr(model, 'mail_scene'):
        from tcms.core.utils.mailto import mailto

        mail_context = model.mail_scene(
            objects=targets, field=field, value=value, ctype=ctype,
            object_pk=object_pk,
        )
        if mail_context:
            mail_context['context']['user'] = request.user
            try:
                mailto(**mail_context)
            except Exception:  # nosec:B110:try_except_pass
                pass

    # Special hacking for updating test case run status
    if ctype == 'testruns.testcaserun' and field == 'case_run_status':
        for t in targets:
            field = 'close_date'
            t.log_action(
                who=request.user,
                action='Field %s changed from %s to %s.' % (
                    field, getattr(t, field), now
                )
            )
            if t.tested_by != request.user:
                field = 'tested_by'
                t.log_action(
                    who=request.user,
                    action='Field %s changed from %s to %s.' % (
                        field, getattr(t, field), request.user
                    )
                )

            field = 'assignee'
            try:
                assignee = t.assginee
                if assignee != request.user:
                    t.log_action(
                        who=request.user,
                        action='Field %s changed from %s to %s.' % (
                            field, getattr(t, field), request.user
                        )
                    )
                    # t.assignee = request.user
                t.save()
            except (AttributeError, User.DoesNotExist):
                pass
        targets.update(close_date=now, tested_by=request.user)

    return HttpResponse(json.dumps({'rc': 0, 'response': 'ok'}))


class ModelUpdateActions(object):
    """"""Abstract class defining interfaces to update a model properties""""""


class TestCaseUpdateActions(ModelUpdateActions):
    """"""Actions to update each possible proprety of TestCases

    Define your own method named _update_[property name] to hold specific
    update logic.
    """"""

    ctype = 'testcases.testcase'

    def __init__(self, request):
        self.request = request
        self.target_field = request.POST.get('target_field')
        self.new_value = request.POST.get('new_value')

    def get_update_action(self):
        return getattr(self, '_update_%s' % self.target_field, None)

    def update(self):
        has_perms = check_permission(self.request, self.ctype)
        if not has_perms:
            return say_no(""You don't have enough permission to update TestCases."")

        action = self.get_update_action()
        if action is not None:
            try:
                resp = action()
                self._sendmail()
            except ObjectDoesNotExist as err:
                return say_no(str(err))
            except Exception:
                # TODO: besides this message to users, what happening should be
                # recorded in the system log.
                return say_no('Update failed. Please try again or request '
                              'support from your organization.')
            else:
                if resp is None:
                    resp = say_yes()
                return resp
        return say_no('Not know what to update.')

    def get_update_targets(self):
        """"""Get selected cases to update their properties""""""
        case_ids = map(int, self.request.POST.getlist('case'))
        self._update_objects = TestCase.objects.filter(pk__in=case_ids)
        return self._update_objects

    def get_plan(self, pk_enough=True):
        try:
            return plan_from_request_or_none(self.request, pk_enough)
        except Http404:
            return None

    def _sendmail(self):
        mail_context = TestCase.mail_scene(objects=self._update_objects,
                                           field=self.target_field,
                                           value=self.new_value)
        if mail_context:
            from tcms.core.utils.mailto import mailto

            mail_context['context']['user'] = self.request.user
            try:
                mailto(**mail_context)
            except Exception:  # nosec:B110:try_except_pass
                pass

    def _update_priority(self):
        exists = Priority.objects.filter(pk=self.new_value).exists()
        if not exists:
            raise ObjectDoesNotExist('The priority you specified to change '
                                     'does not exist.')
        self.get_update_targets().update(**{str(self.target_field): self.new_value})

    def _update_default_tester(self):
        try:
            user = User.objects.get(Q(username=self.new_value) | Q(email=self.new_value))
        except User.DoesNotExist:
            raise ObjectDoesNotExist('Default tester not found!')
        self.get_update_targets().update(**{str(self.target_field): user.pk})

    def _update_case_status(self):
        try:
            new_status = TestCaseStatus.objects.get(pk=self.new_value)
        except TestCaseStatus.DoesNotExist:
            raise ObjectDoesNotExist('The status you choose does not exist.')

        update_object = self.get_update_targets()
        if not update_object:
            return say_no('No record(s) found')

        for testcase in update_object:
            if hasattr(testcase, 'log_action'):
                testcase.log_action(
                    who=self.request.user,
                    action='Field %s changed from %s to %s.' % (
                        self.target_field, testcase.case_status, new_status.name
                    )
                )
        update_object.update(**{str(self.target_field): self.new_value})

        # ###
        # Case is moved between Cases and Reviewing Cases tabs accoding to the
        # change of status. Meanwhile, the number of cases with each status
        # should be updated also.

        try:
            plan = plan_from_request_or_none(self.request)
        except Http404:
            return say_no(""No plan record found."")
        else:
            if plan is None:
                return say_no('No plan record found.')

        confirm_status_name = 'CONFIRMED'
        plan.run_case = plan.case.filter(case_status__name=confirm_status_name)
        plan.review_case = plan.case.exclude(case_status__name=confirm_status_name)
        run_case_count = plan.run_case.count()
        case_count = plan.case.count()
        # FIXME: why not calculate review_case_count or run_case_count by using
        # substraction, which saves one SQL query.
        review_case_count = plan.review_case.count()

        return http.JsonResponse({
            'rc': 0, 'response': 'ok',
            'run_case_count': run_case_count,
            'case_count': case_count,
            'review_case_count': review_case_count,
        })

    def _update_sortkey(self):
        try:
            sortkey = int(self.new_value)
            if sortkey < 0 or sortkey > 32300:
                return say_no('New sortkey is out of range [0, 32300].')
        except ValueError:
            return say_no('New sortkey is not an integer.')
        plan = plan_from_request_or_none(self.request, pk_enough=True)
        if plan is None:
            return say_no('No plan record found.')
        update_targets = self.get_update_targets()

        # ##
        # MySQL does not allow to exeucte UPDATE statement that contains
        # subquery querying from same table. In this case, OperationError will
        # be raised.
        offset = 0
        step_length = 500
        queryset_filter = TestCasePlan.objects.filter
        data = {self.target_field: sortkey}
        while 1:
            sub_cases = update_targets[offset:offset + step_length]
            case_pks = [case.pk for case in sub_cases]
            if len(case_pks) == 0:
                break
            queryset_filter(plan=plan, case__in=case_pks).update(**data)
            # Move to next batch of cases to change.
            offset += step_length

    def _update_reviewer(self):
        reviewers = User.objects.filter(username=self.new_value).values_list('pk', flat=True)
        if not reviewers:
            err_msg = 'Reviewer %s is not found' % self.new_value
            raise ObjectDoesNotExist(err_msg)
        self.get_update_targets().update(**{str(self.target_field): reviewers[0]})


# NOTE: what permission is necessary
# FIXME: find a good chance to map all TestCase property change request to this
@require_POST
def update_cases_default_tester(request):
    """"""Update default tester upon selected TestCases""""""
    proxy = TestCaseUpdateActions(request)
    return proxy.update()


update_cases_priority = update_cases_default_tester
update_cases_case_status = update_cases_default_tester
update_cases_sortkey = update_cases_default_tester
update_cases_reviewer = update_cases_default_tester


@require_POST
def comment_case_runs(request):
    """"""
    Add comment to one or more caseruns at a time.
    """"""
    data = request.POST.copy()
    comment = data.get('comment', None)
    if not comment:
        return say_no('Comments needed')
    run_ids = [i for i in data.get('run', '').split(',') if i]
    if not run_ids:
        return say_no('No runs selected.')
    runs = TestCaseRun.objects.filter(pk__in=run_ids).only('pk')
    if not runs:
        return say_no('No caserun found.')
    add_comment(runs, comment, request.user)
    return say_yes()


def clean_bug_form(request):
    """"""
    Verify the form data, return a tuple\n
    (None, ERROR_MSG) on failure\n
    or\n
    (data_dict, '') on success.\n
    """"""
    data = {}
    try:
        data['bugs'] = request.GET.get('bug_id', '').split(',')
        data['runs'] = map(int, request.GET.get('case_runs', '').split(','))
    except (TypeError, ValueError) as e:
        return (None, 'Please specify only integers for bugs, '
                      'caseruns(using comma to seperate IDs), '
                      'and bug_system. (DEBUG INFO: %s)' % str(e))

    data['bug_system_id'] = int(request.GET.get('bug_system_id', 1))

    if request.GET.get('a') not in ('add', 'remove'):
        return (None, 'Actions only allow ""add"" and ""remove"".')
    else:
        data['action'] = request.GET.get('a')
    data['bz_external_track'] = True if request.GET.get('bz_external_track',
                                                        False) else False

    return (data, '')


def update_bugs_to_caseruns(request):
    """"""
    Add one or more bugs to or remove that from\n
    one or more caserun at a time.
    """"""
    data, error = clean_bug_form(request)
    if error:
        return say_no(error)
    runs = TestCaseRun.objects.filter(pk__in=data['runs'])
    bug_system_id = data['bug_system_id']
    bug_ids = data['bugs']

    try:
        validate_bug_id(bug_ids, bug_system_id)
    except ValidationError as e:
        return say_no(str(e))

    bz_external_track = data['bz_external_track']
    action = data['action']
    try:
        if action == ""add"":
            for run in runs:
                for bug_id in bug_ids:
                    run.add_bug(bug_id=bug_id,
                                bug_system_id=bug_system_id,
                                bz_external_track=bz_external_track)
        else:
            bugs = Bug.objects.filter(bug_id__in=bug_ids)
            for run in runs:
                for bug in bugs:
                    if bug.case_run_id == run.pk:
                        run.remove_bug(bug.bug_id, run.pk)
    except Exception as e:
        return say_no(str(e))
    return say_yes()


def get_prod_related_objs(p_pks, target):
    """"""
    Get Component, Version, Category, and Build\n
    Return [(id, name), (id, name)]
    """"""
    ctypes = {
        'component': (Component, 'name'),
        'version': (Version, 'value'),
        'build': (Build, 'name'),
        'category': (Category, 'name'),
    }
    results = ctypes[target][0]._default_manager.filter(product__in=p_pks)
    attr = ctypes[target][1]
    results = [(r.pk, getattr(r, attr)) for r in results]
    return results


def get_prod_related_obj_json(request):
    """"""
    View for updating product drop-down\n
    in a Ajax way.
    """"""
    data = request.GET.copy()
    target = data.get('target', None)
    p_pks = data.get('p_ids', None)
    sep = data.get('sep', None)
    # py2.6: all(*values) => boolean ANDs
    if target and p_pks and sep:
        p_pks = [k for k in p_pks.split(sep) if k]
        res = get_prod_related_objs(p_pks, target)
    else:
        res = []
    return HttpResponse(json.dumps(res))


def objects_update(objects, **kwargs):
    objects.update(**kwargs)
    kwargs['instances'] = objects
    if objects.model.__name__ == TestCaseRun.__name__ and kwargs.get(
            'case_run_status', None):
        POST_UPDATE_SIGNAL.send(sender=None, **kwargs)
/n/n/n/tcms/core/tests/test_views.py/n/n# -*- coding: utf-8 -*-

import json
from http import HTTPStatus
from urllib.parse import urlencode

from django import test
from django.conf import settings
from django.contrib.contenttypes.models import ContentType
from django.core import serializers
from django.urls import reverse
from django_comments.models import Comment

from tcms.management.models import Priority
from tcms.management.models import EnvGroup
from tcms.management.models import EnvProperty
from tcms.testcases.forms import CaseAutomatedForm
from tcms.testcases.forms import TestCase
from tcms.testplans.models import TestPlan
from tcms.testruns.models import TestCaseRun
from tcms.testruns.models import TestCaseRunStatus
from tcms.tests import BaseCaseRun
from tcms.tests import BasePlanCase
from tcms.tests import remove_perm_from_user
from tcms.tests import user_should_have_perm
from tcms.tests.factories import UserFactory
from tcms.tests.factories import EnvGroupFactory
from tcms.tests.factories import EnvGroupPropertyMapFactory
from tcms.tests.factories import EnvPropertyFactory


class TestNavigation(test.TestCase):
    @classmethod
    def setUpTestData(cls):
        super(TestNavigation, cls).setUpTestData()
        cls.user = UserFactory(email='user+1@example.com')
        cls.user.set_password('testing')
        cls.user.save()

    def test_urls_for_emails_with_pluses(self):
        # test for https://github.com/Nitrate/Nitrate/issues/262
        # when email contains + sign it needs to be properly urlencoded
        # before passing it as query string argument to the search views
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.user.username,
            password='testing')
        response = self.client.get(reverse('iframe-navigation'))

        self.assertContains(response, urlencode({'people': self.user.email}))
        self.assertContains(response, urlencode({'author__email__startswith': self.user.email}))


class TestIndex(BaseCaseRun):
    def test_when_not_logged_in_index_page_redirects_to_login(self):
        response = self.client.get(reverse('core-views-index'))
        self.assertRedirects(
            response,
            reverse('tcms-login'),
            target_status_code=HTTPStatus.OK)

    def test_when_logged_in_index_page_redirects_to_dashboard(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')
        response = self.client.get(reverse('core-views-index'))
        self.assertRedirects(
            response,
            reverse('tcms-recent', args=[self.tester.username]),
            target_status_code=HTTPStatus.OK)


class TestCommentCaseRuns(BaseCaseRun):
    """"""Test case for ajax.comment_case_runs""""""

    @classmethod
    def setUpTestData(cls):
        super(TestCommentCaseRuns, cls).setUpTestData()
        cls.many_comments_url = reverse('ajax-comment_case_runs')

    def test_refuse_if_missing_comment(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(self.many_comments_url,
                                    {'run': [self.case_run_1.pk, self.case_run_2.pk]})
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': 'Comments needed'})

    def test_refuse_if_missing_no_case_run_pk(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(self.many_comments_url,
                                    {'comment': 'new comment', 'run': []})
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': 'No runs selected.'})

        response = self.client.post(self.many_comments_url,
                                    {'comment': 'new comment'})
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': 'No runs selected.'})

    def test_refuse_if_passed_case_run_pks_not_exist(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(self.many_comments_url,
                                    {'comment': 'new comment',
                                     'run': '99999998,1009900'})
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': 'No caserun found.'})

    def test_add_comment_to_case_runs(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        new_comment = 'new comment'
        response = self.client.post(
            self.many_comments_url,
            {'comment': new_comment,
             'run': ','.join([str(self.case_run_1.pk),
                              str(self.case_run_2.pk)])})
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 0, 'response': 'ok'})

        # Assert comments are added
        case_run_ct = ContentType.objects.get_for_model(TestCaseRun)

        for case_run_pk in (self.case_run_1.pk, self.case_run_2.pk):
            comments = Comment.objects.filter(object_pk=case_run_pk,
                                              content_type=case_run_ct)
            self.assertEqual(new_comment, comments[0].comment)
            self.assertEqual(self.tester, comments[0].user)


class TestUpdateObject(BasePlanCase):
    """"""Test case for update""""""

    @classmethod
    def setUpTestData(cls):
        super(TestUpdateObject, cls).setUpTestData()

        cls.permission = 'testplans.change_testplan'
        cls.update_url = reverse('ajax-update')

    def setUp(self):
        user_should_have_perm(self.tester, self.permission)

    def test_refuse_if_missing_permission(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        remove_perm_from_user(self.tester, self.permission)

        post_data = {
            'content_type': 'testplans.testplan',
            'object_pk': self.plan.pk,
            'field': 'is_active',
            'value': 'False',
            'value_type': 'bool'
        }

        response = self.client.post(self.update_url, post_data)

        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': 'Permission Dinied.'})

    def test_update_plan_is_active(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        post_data = {
            'content_type': 'testplans.testplan',
            'object_pk': self.plan.pk,
            'field': 'is_active',
            'value': 'False',
            'value_type': 'bool'
        }

        response = self.client.post(self.update_url, post_data)

        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 0, 'response': 'ok'})
        plan = TestPlan.objects.get(pk=self.plan.pk)
        self.assertFalse(plan.is_active)


class TestUpdateCaseRunStatus(BaseCaseRun):
    """"""Test case for update_case_run_status""""""

    @classmethod
    def setUpTestData(cls):
        super(TestUpdateCaseRunStatus, cls).setUpTestData()

        cls.permission = 'testruns.change_testcaserun'
        cls.update_url = reverse('ajax-update_case_run_status')

    def setUp(self):
        user_should_have_perm(self.tester, self.permission)

    def test_refuse_if_missing_permission(self):
        remove_perm_from_user(self.tester, self.permission)
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(self.update_url, {
            'content_type': 'testruns.testcaserun',
            'object_pk': self.case_run_1.pk,
            'field': 'case_run_status',
            'value': str(TestCaseRunStatus.objects.get(name='PAUSED').pk),
            'value_type': 'int',
        })

        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': 'Permission Dinied.'})

    def test_change_case_run_status(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(self.update_url, {
            'content_type': 'testruns.testcaserun',
            'object_pk': self.case_run_1.pk,
            'field': 'case_run_status',
            'value': str(TestCaseRunStatus.objects.get(name='PAUSED').pk),
            'value_type': 'int',
        })

        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 0, 'response': 'ok'})
        self.assertEqual(
            'PAUSED', TestCaseRun.objects.get(pk=self.case_run_1.pk).case_run_status.name)


class TestGetForm(test.TestCase):
    """"""Test case for form""""""

    def test_get_form(self):
        response = self.client.get(reverse('ajax-form'),
                                   {'app_form': 'testcases.CaseAutomatedForm'})
        form = CaseAutomatedForm()
        self.assertHTMLEqual(str(response.content, encoding=settings.DEFAULT_CHARSET), form.as_p())


class TestUpdateCasePriority(BasePlanCase):
    """"""Test case for update_cases_default_tester""""""

    @classmethod
    def setUpTestData(cls):
        super(TestUpdateCasePriority, cls).setUpTestData()

        cls.permission = 'testcases.change_testcase'
        cls.case_update_url = reverse('ajax-update_cases_default_tester')

    def setUp(self):
        user_should_have_perm(self.tester, self.permission)

    def test_refuse_if_missing_permission(self):
        remove_perm_from_user(self.tester, self.permission)
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(
            self.case_update_url,
            {
                'target_field': 'priority',
                'from_plan': self.plan.pk,
                'case': [self.case_1.pk, self.case_3.pk],
                'new_value': Priority.objects.get(value='P3').pk,
            })

        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 1, 'response': ""You don't have enough permission to ""
                                  ""update TestCases.""})

    def test_update_case_priority(self):
        self.client.login(  # nosec:B106:hardcoded_password_funcarg
            username=self.tester.username,
            password='password')

        response = self.client.post(
            self.case_update_url,
            {
                'target_field': 'priority',
                'from_plan': self.plan.pk,
                'case': [self.case_1.pk, self.case_3.pk],
                'new_value': Priority.objects.get(value='P3').pk,
            })

        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            {'rc': 0, 'response': 'ok'})

        for pk in (self.case_1.pk, self.case_3.pk):
            self.assertEqual('P3', TestCase.objects.get(pk=pk).priority.value)


class TestGetObjectInfo(BasePlanCase):
    """"""Test case for info view method""""""

    @classmethod
    def setUpTestData(cls):
        super(TestGetObjectInfo, cls).setUpTestData()

        cls.get_info_url = reverse('ajax-info')

        cls.group_nitrate = EnvGroupFactory(name='nitrate')
        cls.group_new = EnvGroupFactory(name='NewGroup')

        cls.property_os = EnvPropertyFactory(name='os')
        cls.property_python = EnvPropertyFactory(name='python')
        cls.property_django = EnvPropertyFactory(name='django')

        EnvGroupPropertyMapFactory(group=cls.group_nitrate,
                                   property=cls.property_os)
        EnvGroupPropertyMapFactory(group=cls.group_nitrate,
                                   property=cls.property_python)
        EnvGroupPropertyMapFactory(group=cls.group_new,
                                   property=cls.property_django)

    def test_get_env_properties(self):
        response = self.client.get(self.get_info_url, {'info_type': 'env_properties'})

        expected_json = json.loads(
            serializers.serialize(
                'json',
                EnvProperty.objects.all(),
                fields=('name', 'value')))
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            expected_json)

    def test_get_env_properties_by_group(self):
        response = self.client.get(self.get_info_url,
                                   {'info_type': 'env_properties',
                                    'env_group_id': self.group_new.pk})

        group = EnvGroup.objects.get(pk=self.group_new.pk)
        expected_json = json.loads(
            serializers.serialize(
                'json',
                group.property.all(),
                fields=('name', 'value')))
        self.assertJSONEqual(
            str(response.content, encoding=settings.DEFAULT_CHARSET),
            expected_json)
/n/n/n",1
4,4,269b8c87afc149911af3ae63b3ccbfc77ffb223d,"hyperion/hyperion.py/n/n#! /usr/bin/env python
from libtmux import Server
from yaml import load, dump
from setupParser import Loader
from DepTree import Node, dep_resolve, CircularReferenceException
import logging
import os
import socket
import argparse
from psutil import Process
from subprocess import call
from graphviz import Digraph
from enum import Enum
from time import sleep

import sys
from PyQt4 import QtGui
import hyperGUI

FORMAT = ""%(asctime)s: %(name)s [%(levelname)s]:\t%(message)s""

logging.basicConfig(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S')
TMP_SLAVE_DIR = ""/tmp/Hyperion/slave/components""
TMP_COMP_DIR = ""/tmp/Hyperion/components""
TMP_LOG_PATH = ""/tmp/Hyperion/log""

BASE_DIR = os.path.dirname(__file__)
SCRIPT_CLONE_PATH = (""%s/scripts/start_named_clone_session.sh"" % BASE_DIR)


class CheckState(Enum):
    RUNNING = 0
    STOPPED = 1
    STOPPED_BUT_SUCCESSFUL = 2
    STARTED_BY_HAND = 3
    DEP_FAILED = 4


class ControlCenter:

    def __init__(self, configfile=None):
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)
        self.configfile = configfile
        self.nodes = {}
        self.server = []
        self.host_list = []

        if configfile:
            self.load_config(configfile)
            self.session_name = self.config[""name""]

            # Debug write resulting yaml file
            with open('debug-result.yml', 'w') as outfile:
                dump(self.config, outfile, default_flow_style=False)
            self.logger.debug(""Loading config was successful"")

            self.server = Server()

            if self.server.has_session(self.session_name):
                self.session = self.server.find_where({
                    ""session_name"": self.session_name
                })

                self.logger.info('found running session by name ""%s"" on server' % self.session_name)
            else:
                self.logger.info('starting new session by name ""%s"" on server' % self.session_name)
                self.session = self.server.new_session(
                    session_name=self.session_name,
                    window_name=""Main""
                )
        else:
            self.config = None

    ###################
    # Setup
    ###################
    def load_config(self, filename=""default.yaml""):
        with open(filename) as data_file:
            self.config = load(data_file, Loader)

    def init(self):
        if not self.config:
            self.logger.error("" Config not loaded yet!"")

        else:
            for group in self.config['groups']:
                for comp in group['components']:
                    self.logger.debug(""Checking component '%s' in group '%s' on host '%s'"" %
                                      (comp['name'], group['name'], comp['host']))

                    if comp['host'] != ""localhost"" and not self.run_on_localhost(comp):
                        self.copy_component_to_remote(comp, comp['name'], comp['host'])

            # Remove duplicate hosts
            self.host_list = list(set(self.host_list))

            self.set_dependencies(True)

    def set_dependencies(self, exit_on_fail):
        for group in self.config['groups']:
            for comp in group['components']:
                self.nodes[comp['name']] = Node(comp)

        # Add a pseudo node that depends on all other nodes, to get a starting point to be able to iterate through all
        # nodes with simple algorithms
        master_node = Node({'name': 'master_node'})
        for name in self.nodes:
            node = self.nodes.get(name)

            # Add edges from each node to pseudo node
            master_node.addEdge(node)

            # Add edges based on dependencies specified in the configuration
            if ""depends"" in node.component:
                for dep in node.component['depends']:
                    if dep in self.nodes:
                        node.addEdge(self.nodes[dep])
                    else:
                        self.logger.error(""Unmet dependency: '%s' for component '%s'!"" % (dep, node.comp_name))
                        if exit_on_fail:
                            exit(1)
        self.nodes['master_node'] = master_node

        # Test if starting all components is possible
        try:
            node = self.nodes.get('master_node')
            res = []
            unres = []
            dep_resolve(node, res, unres)
            dep_string = """"
            for node in res:
                if node is not master_node:
                    dep_string = ""%s -> %s"" % (dep_string, node.comp_name)
            self.logger.debug(""Dependency tree for start all: %s"" % dep_string)
        except CircularReferenceException as ex:
            self.logger.error(""Detected circular dependency reference between %s and %s!"" % (ex.node1, ex.node2))
            if exit_on_fail:
                exit(1)

    def copy_component_to_remote(self, infile, comp, host):
        self.host_list.append(host)

        self.logger.debug(""Saving component to tmp"")
        tmp_comp_path = ('%s/%s.yaml' % (TMP_COMP_DIR, comp))
        ensure_dir(tmp_comp_path)
        with open(tmp_comp_path, 'w') as outfile:
            dump(infile, outfile, default_flow_style=False)

        self.logger.debug('Copying component ""%s"" to remote host ""%s""' % (comp, host))
        cmd = (""ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml"" %
               (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp))
        self.logger.debug(cmd)
        send_main_session_command(self.session, cmd)

    ###################
    # Stop
    ###################
    def stop_component(self, comp):
        if comp['host'] != 'localhost' and not self.run_on_localhost(comp):
            self.logger.debug(""Stopping remote component '%s' on host '%s'"" % (comp['name'], comp['host']))
            self.stop_remote_component(comp['name'], comp['host'])
        else:
            window = find_window(self.session, comp['name'])

            if window:
                self.logger.debug(""window '%s' found running"" % comp['name'])
                self.logger.info(""Shutting down window..."")
                kill_window(window)
                self.logger.info(""... done!"")

    def stop_remote_component(self, comp_name, host):
        # invoke Hyperion in slave mode on each remote host
        cmd = (""ssh %s 'hyperion --config %s/%s.yaml slave --kill'"" % (host, TMP_SLAVE_DIR, comp_name))
        self.logger.debug(""Run cmd:\n%s"" % cmd)
        send_main_session_command(self.session, cmd)

    ###################
    # Start
    ###################
    def start_component(self, comp):

        node = self.nodes.get(comp['name'])
        res = []
        unres = []
        dep_resolve(node, res, unres)
        for node in res:
            self.logger.debug(""node name '%s' vs. comp name '%s'"" % (node.comp_name, comp['name']))
            if node.comp_name != comp['name']:
                self.logger.debug(""Checking and starting %s"" % node.comp_name)
                state = self.check_component(node.component)
                if (state is CheckState.STOPPED_BUT_SUCCESSFUL or
                        state is CheckState.STARTED_BY_HAND or
                        state is CheckState.RUNNING):
                    self.logger.debug(""Component %s is already running, skipping to next in line"" % comp['name'])
                else:
                    self.logger.debug(""Start component '%s' as dependency of '%s'"" % (node.comp_name, comp['name']))
                    self.start_component_without_deps(node.component)

                    tries = 0
                    while True:
                        self.logger.debug(""Checking %s resulted in checkstate %s"" % (node.comp_name, state))
                        state = self.check_component(node.component)
                        if (state is not CheckState.RUNNING or
                           state is not CheckState.STOPPED_BUT_SUCCESSFUL):
                            break
                        if tries > 100:
                            return False
                        tries = tries + 1
                        sleep(.5)

        self.logger.debug(""All dependencies satisfied, starting '%s'"" % (comp['name']))
        state = self.check_component(node.component)
        if (state is CheckState.STARTED_BY_HAND or
                state is CheckState.RUNNING):
            self.logger.debug(""Component %s is already running. Skipping start"" % comp['name'])
        else:
            self.start_component_without_deps(comp)
        return True

    def start_component_without_deps(self, comp):
        if comp['host'] != 'localhost' and not self.run_on_localhost(comp):
            self.logger.debug(""Starting remote component '%s' on host '%s'"" % (comp['name'], comp['host']))
            self.start_remote_component(comp['name'], comp['host'])
        else:
            log_file = (""%s/%s"" % (TMP_LOG_PATH, comp['name']))
            window = find_window(self.session, comp['name'])

            if window:
                self.logger.debug(""Restarting '%s' in old window"" % comp['name'])
                start_window(window, comp['cmd'][0]['start'], log_file, comp['name'])
            else:
                self.logger.info(""creating window '%s'"" % comp['name'])
                window = self.session.new_window(comp['name'])
                start_window(window, comp['cmd'][0]['start'], log_file, comp['name'])

    def start_remote_component(self, comp_name, host):
        # invoke Hyperion in slave mode on each remote host
        cmd = (""ssh %s 'hyperion --config %s/%s.yaml slave'"" % (host, TMP_SLAVE_DIR, comp_name))
        self.logger.debug(""Run cmd:\n%s"" % cmd)
        send_main_session_command(self.session, cmd)

    ###################
    # Check
    ###################
    def check_component(self, comp):
        if self.run_on_localhost(comp):
            return check_component(comp, self.session, self.logger)
        else:
            self.logger.debug(""Starting remote check"")
            cmd = ""ssh %s 'hyperion --config %s/%s.yaml slave -c'"" % (comp['host'], TMP_SLAVE_DIR, comp['name'])
            ret = call(cmd, shell=True)
            return CheckState(ret)

    ###################
    # Dependency management
    ###################
    def get_dep_list(self, comp):
        node = self.nodes.get(comp['name'])
        res = []
        unres = []
        dep_resolve(node, res, unres)
        res.remove(node)

        return res

    ###################
    # Host related checks
    ###################
    def is_localhost(self, hostname):
        try:
            hn_out = socket.gethostbyname(hostname)
            if hn_out == '127.0.0.1' or hn_out == '::1':
                self.logger.debug(""Host '%s' is localhost"" % hostname)
                return True
            else:
                self.logger.debug(""Host '%s' is not localhost"" % hostname)
                return False
        except socket.gaierror:
            sys.exit(""Host '%s' is unknown! Update your /etc/hosts file!"" % hostname)

    def run_on_localhost(self, comp):
        return self.is_localhost(comp['host'])

    ###################
    # TMUX
    ###################
    def kill_remote_session_by_name(self, name, host):
        cmd = ""ssh -t %s 'tmux kill-session -t %s'"" % (host, name)
        send_main_session_command(self.session, cmd)

    def start_clone_session(self, comp_name, session_name):
        cmd = ""%s '%s' '%s'"" % (SCRIPT_CLONE_PATH, session_name, comp_name)
        send_main_session_command(self.session, cmd)

    def start_remote_clone_session(self, comp_name, session_name, hostname):
        remote_cmd = (""%s '%s' '%s'"" % (SCRIPT_CLONE_PATH, session_name, comp_name))
        cmd = ""ssh %s 'bash -s' < %s"" % (hostname, remote_cmd)
        send_main_session_command(self.session, cmd)

    ###################
    # Visualisation
    ###################
    def draw_graph(self):
        deps = Digraph(""Deps"", strict=True)
        deps.graph_attr.update(rankdir=""BT"")
        try:
            node = self.nodes.get('master_node')

            for current in node.depends_on:
                deps.node(current.comp_name)

                res = []
                unres = []
                dep_resolve(current, res, unres)
                for node in res:
                    if ""depends"" in node.component:
                        for dep in node.component['depends']:
                            if dep not in self.nodes:
                                deps.node(dep, color=""red"")
                                deps.edge(node.comp_name, dep, ""missing"", color=""red"")
                            elif node.comp_name is not ""master_node"":
                                deps.edge(node.comp_name, dep)

        except CircularReferenceException as ex:
            self.logger.error(""Detected circular dependency reference between %s and %s!"" % (ex.node1, ex.node2))
            deps.edge(ex.node1, ex.node2, ""circular error"", color=""red"")
            deps.edge(ex.node2, ex.node1, color=""red"")

        deps.view()


class SlaveLauncher:

    def __init__(self, configfile=None, kill_mode=False, check_mode=False):
        self.kill_mode = kill_mode
        self.check_mode = check_mode
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)
        self.config = None
        self.session = None
        if kill_mode:
            self.logger.info(""started slave with kill mode"")
        if check_mode:
            self.logger.info(""started slave with check mode"")
        self.server = Server()

        if self.server.has_session(""slave-session""):
            self.session = self.server.find_where({
                ""session_name"": ""slave-session""
            })

            self.logger.info('found running slave session on server')
        elif not kill_mode and not check_mode:
            self.logger.info('starting new slave session on server')
            self.session = self.server.new_session(
                session_name=""slave-session""
            )

        else:
            self.logger.info(""No slave session found on server. Aborting"")
            exit(CheckState.STOPPED)

        if configfile:
            self.load_config(configfile)
            self.window_name = self.config['name']
            self.flag_path = (""/tmp/Hyperion/slaves/%s"" % self.window_name)
            self.log_file = (""/tmp/Hyperion/log/%s"" % self.window_name)
            ensure_dir(self.log_file)
        else:
            self.logger.error(""No slave component config provided"")

    def load_config(self, filename=""default.yaml""):
        with open(filename) as data_file:
            self.config = load(data_file, Loader)

    def init(self):
        if not self.config:
            self.logger.error("" Config not loaded yet!"")
        elif not self.session:
            self.logger.error("" Init aborted. No session was found!"")
        else:
            self.logger.debug(self.config)
            window = find_window(self.session, self.window_name)

            if window:
                self.logger.debug(""window '%s' found running"" % self.window_name)
                if self.kill_mode:
                    self.logger.info(""Shutting down window..."")
                    kill_window(window)
                    self.logger.info(""... done!"")
            elif not self.kill_mode:
                self.logger.info(""creating window '%s'"" % self.window_name)
                window = self.session.new_window(self.window_name)
                start_window(window, self.config['cmd'][0]['start'], self.log_file, self.window_name)

            else:
                self.logger.info(""There is no component running by the name '%s'. Exiting kill mode"" %
                                 self.window_name)

    def run_check(self):
        if not self.config:
            self.logger.error("" Config not loaded yet!"")
            exit(CheckState.STOPPED.value)
        elif not self.session:
            self.logger.error("" Init aborted. No session was found!"")
            exit(CheckState.STOPPED.value)

        check_state = check_component(self.config, self.session, self.logger)
        exit(check_state.value)

###################
# Component Management
###################
def run_component_check(comp):
    if call(comp['cmd'][1]['check'], shell=True) == 0:
        return True
    else:
        return False


def check_component(comp, session, logger):
    logger.debug(""Running component check for %s"" % comp['name'])
    check_available = len(comp['cmd']) > 1 and 'check' in comp['cmd'][1]
    window = find_window(session, comp['name'])
    if window:
        pid = get_window_pid(window)
        logger.debug(""Found window pid: %s"" % pid)

        # May return more child pids if logging is done via tee (which then was started twice in the window too)
        procs = []
        for entry in pid:
            procs.extend(Process(entry).children(recursive=True))
        pids = [p.pid for p in procs]
        logger.debug(""Window is running %s child processes"" % len(pids))

        # TODO: Investigate minimum process number on hosts
        # TODO: Change this when more logging options are introduced
        if len(pids) < 2:
            logger.debug(""Main window process has finished. Running custom check if available"")
            if check_available and run_component_check(comp):
                logger.debug(""Process terminated but check was successful"")
                return CheckState.STOPPED_BUT_SUCCESSFUL
            else:
                logger.debug(""Check failed or no check available: returning false"")
                return CheckState.STOPPED
        elif check_available and run_component_check(comp):
            logger.debug(""Check succeeded"")
            return CheckState.RUNNING
        elif not check_available:
            logger.debug(""No custom check specified and got sufficient pid amount: returning true"")
            return CheckState.RUNNING
        else:
            logger.debug(""Check failed: returning false"")
            return CheckState.STOPPED
    else:
        logger.debug(""%s window is not running. Running custom check"" % comp['name'])
        if check_available and run_component_check(comp):
            logger.debug(""Component was not started by Hyperion, but the check succeeded"")
            return CheckState.STARTED_BY_HAND
        else:
            logger.debug(""Window not running and no check command is available or it failed: returning false"")
            return CheckState.STOPPED


def get_window_pid(window):
    r = window.cmd('list-panes',
                   ""-F #{pane_pid}"")
    return [int(p) for p in r.stdout]

###################
# TMUX
###################
def kill_session_by_name(server, name):
    session = server.find_where({
        ""session_name"": name
    })
    session.kill_session()


def kill_window(window):
    window.cmd(""send-keys"", """", ""C-c"")
    window.kill_window()


def start_window(window, cmd, log_file, comp_name):
    setup_log(window, log_file, comp_name)
    window.cmd(""send-keys"", cmd, ""Enter"")


def find_window(session, window_name):
    window = session.find_where({
        ""window_name"": window_name
    })
    return window


def send_main_session_command(session, cmd):
    window = find_window(session, ""Main"")
    window.cmd(""send-keys"", cmd, ""Enter"")

###################
# Logging
###################
def setup_log(window, file, comp_name):
    clear_log(file)
    # Reroute stderr to log file
    window.cmd(""send-keys"", ""exec 2> >(exec tee -i -a '%s')"" % file, ""Enter"")
    # Reroute stdin to log file
    window.cmd(""send-keys"", ""exec 1> >(exec tee -i -a '%s')"" % file, ""Enter"")
    window.cmd(""send-keys"", ('echo ""#Hyperion component start: %s\n$(date)""' % comp_name), ""Enter"")


def clear_log(file_path):
    if os.path.isfile(file_path):
        os.remove(file_path)


def ensure_dir(file_path):
    directory = os.path.dirname(file_path)
    if not os.path.exists(directory):
        os.makedirs(directory)

###################
# Startup
###################
def main():
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.DEBUG)
    parser = argparse.ArgumentParser()

    # Create top level parser
    parser.add_argument(""--config"", '-c', type=str,
                        default='test.yaml',
                        help=""YAML config file. see sample-config.yaml. Default: test.yaml"")
    subparsers = parser.add_subparsers(dest=""cmd"")

    # Create parser for the editor command
    subparser_editor = subparsers.add_parser('edit', help=""Launches the editor to edit or create new systems and ""
                                                          ""components"")
    # Create parser for the run command
    subparser_run = subparsers.add_parser('run', help=""Launches the setup specified by the --config argument"")
    # Create parser for validator
    subparser_val = subparsers.add_parser('validate', help=""Validate the setup specified by the --config argument"")

    subparser_remote = subparsers.add_parser('slave', help=""Run a component locally without controlling it. The ""
                                                           ""control is taken care of the remote master invoking ""
                                                           ""this command.\nIf run with the --kill flag, the ""
                                                           ""passed component will be killed"")

    subparser_val.add_argument(""--visual"", help=""Generate and show a graph image"", action=""store_true"")

    remote_mutex = subparser_remote.add_mutually_exclusive_group(required=False)

    remote_mutex.add_argument('-k', '--kill', help=""switch to kill mode"", action=""store_true"")
    remote_mutex.add_argument('-c', '--check', help=""Run a component check"", action=""store_true"")

    args = parser.parse_args()
    logger.debug(args)

    if args.cmd == 'edit':
        logger.debug(""Launching editor mode"")

    elif args.cmd == 'run':
        logger.debug(""Launching runner mode"")

        cc = ControlCenter(args.config)
        cc.init()
        start_gui(cc)

    elif args.cmd == 'validate':
        logger.debug(""Launching validation mode"")
        cc = ControlCenter(args.config)
        if args.visual:
            cc.set_dependencies(False)
            cc.draw_graph()
        else:
            cc.set_dependencies(True)

    elif args.cmd == 'slave':
        logger.debug(""Launching slave mode"")
        sl = SlaveLauncher(args.config, args.kill, args.check)

        if args.check:
            sl.run_check()
        else:
            sl.init()


###################
# GUI
###################
def start_gui(control_center):
    app = QtGui.QApplication(sys.argv)
    main_window = QtGui.QMainWindow()
    ui = hyperGUI.UiMainWindow()
    ui.ui_init(main_window, control_center)
    main_window.show()
    sys.exit(app.exec_())
/n/n/n",0
5,5,269b8c87afc149911af3ae63b3ccbfc77ffb223d,"/hyperion/hyperion.py/n/n#! /usr/bin/env python
from libtmux import Server
from yaml import load, dump
from setupParser import Loader
from DepTree import Node, dep_resolve, CircularReferenceException
import logging
import os
import socket
import argparse
from psutil import Process
from subprocess import call
from graphviz import Digraph
from enum import Enum
from time import sleep

import sys
from PyQt4 import QtGui
import hyperGUI

FORMAT = ""%(asctime)s: %(name)s [%(levelname)s]:\t%(message)s""

logging.basicConfig(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S')
TMP_SLAVE_DIR = ""/tmp/Hyperion/slave/components""
TMP_COMP_DIR = ""/tmp/Hyperion/components""
TMP_LOG_PATH = ""/tmp/Hyperion/log""

BASE_DIR = os.path.dirname(__file__)
SCRIPT_CLONE_PATH = (""%s/scripts/start_named_clone_session.sh"" % BASE_DIR)


class CheckState(Enum):
    RUNNING = 0
    STOPPED = 1
    STOPPED_BUT_SUCCESSFUL = 2
    STARTED_BY_HAND = 3
    DEP_FAILED = 4


class ControlCenter:

    def __init__(self, configfile=None):
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)
        self.configfile = configfile
        self.nodes = {}
        self.server = []
        self.host_list = []

        if configfile:
            self.load_config(configfile)
            self.session_name = self.config[""name""]

            # Debug write resulting yaml file
            with open('debug-result.yml', 'w') as outfile:
                dump(self.config, outfile, default_flow_style=False)
            self.logger.debug(""Loading config was successful"")

            self.server = Server()

            if self.server.has_session(self.session_name):
                self.session = self.server.find_where({
                    ""session_name"": self.session_name
                })

                self.logger.info('found running session by name ""%s"" on server' % self.session_name)
            else:
                self.logger.info('starting new session by name ""%s"" on server' % self.session_name)
                self.session = self.server.new_session(
                    session_name=self.session_name,
                    window_name=""Main""
                )
        else:
            self.config = None

    ###################
    # Setup
    ###################
    def load_config(self, filename=""default.yaml""):
        with open(filename) as data_file:
            self.config = load(data_file, Loader)

    def init(self):
        if not self.config:
            self.logger.error("" Config not loaded yet!"")

        else:
            for group in self.config['groups']:
                for comp in group['components']:
                    self.logger.debug(""Checking component '%s' in group '%s' on host '%s'"" %
                                      (comp['name'], group['name'], comp['host']))

                    if comp['host'] != ""localhost"" and not self.run_on_localhost(comp):
                        self.copy_component_to_remote(comp, comp['name'], comp['host'])

            # Remove duplicate hosts
            self.host_list = list(set(self.host_list))

            self.set_dependencies(True)

    def set_dependencies(self, exit_on_fail):
        for group in self.config['groups']:
            for comp in group['components']:
                self.nodes[comp['name']] = Node(comp)

        # Add a pseudo node that depends on all other nodes, to get a starting point to be able to iterate through all
        # nodes with simple algorithms
        master_node = Node({'name': 'master_node'})
        for name in self.nodes:
            node = self.nodes.get(name)

            # Add edges from each node to pseudo node
            master_node.addEdge(node)

            # Add edges based on dependencies specified in the configuration
            if ""depends"" in node.component:
                for dep in node.component['depends']:
                    if dep in self.nodes:
                        node.addEdge(self.nodes[dep])
                    else:
                        self.logger.error(""Unmet dependency: '%s' for component '%s'!"" % (dep, node.comp_name))
                        if exit_on_fail:
                            exit(1)
        self.nodes['master_node'] = master_node

        # Test if starting all components is possible
        try:
            node = self.nodes.get('master_node')
            res = []
            unres = []
            dep_resolve(node, res, unres)
            dep_string = """"
            for node in res:
                if node is not master_node:
                    dep_string = ""%s -> %s"" % (dep_string, node.comp_name)
            self.logger.debug(""Dependency tree for start all: %s"" % dep_string)
        except CircularReferenceException as ex:
            self.logger.error(""Detected circular dependency reference between %s and %s!"" % (ex.node1, ex.node2))
            if exit_on_fail:
                exit(1)

    def copy_component_to_remote(self, infile, comp, host):
        self.host_list.append(host)

        self.logger.debug(""Saving component to tmp"")
        tmp_comp_path = ('%s/%s.yaml' % (TMP_COMP_DIR, comp))
        ensure_dir(tmp_comp_path)
        with open(tmp_comp_path, 'w') as outfile:
            dump(infile, outfile, default_flow_style=False)

        self.logger.debug('Copying component ""%s"" to remote host ""%s""' % (comp, host))
        cmd = (""ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml"" %
               (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp))
        self.logger.debug(cmd)
        send_main_session_command(self.session, cmd)

    ###################
    # Stop
    ###################
    def stop_component(self, comp):
        if comp['host'] != 'localhost' and not self.run_on_localhost(comp):
            self.logger.debug(""Stopping remote component '%s' on host '%s'"" % (comp['name'], comp['host']))
            self.stop_remote_component(comp['name'], comp['host'])
        else:
            window = find_window(self.session, comp['name'])

            if window:
                self.logger.debug(""window '%s' found running"" % comp['name'])
                self.logger.info(""Shutting down window..."")
                kill_window(window)
                self.logger.info(""... done!"")

    def stop_remote_component(self, comp_name, host):
        # invoke Hyperion in slave mode on each remote host
        cmd = (""ssh %s 'hyperion --config %s/%s.yaml slave --kill'"" % (host, TMP_SLAVE_DIR, comp_name))
        self.logger.debug(""Run cmd:\n%s"" % cmd)
        send_main_session_command(self.session, cmd)

    ###################
    # Start
    ###################
    def start_component(self, comp):

        node = self.nodes.get(comp['name'])
        res = []
        unres = []
        dep_resolve(node, res, unres)
        for node in res:
            self.logger.debug(""node name '%s' vs. comp name '%s'"" % (node.comp_name, comp['name']))
            if node.comp_name != comp['name']:
                self.logger.debug(""Checking and starting %s"" % node.comp_name)
                state = self.check_component(node.component)
                if (state is CheckState.STOPPED_BUT_SUCCESSFUL or
                        state is CheckState.STARTED_BY_HAND or
                        state is CheckState.RUNNING):
                    self.logger.debug(""Component %s is already running, skipping to next in line"" % comp['name'])
                else:
                    self.logger.debug(""Start component '%s' as dependency of '%s'"" % (node.comp_name, comp['name']))
                    self.start_component_without_deps(node.component)

                    tries = 0
                    while True:
                        self.logger.debug(""Checking %s resulted in checkstate %s"" % (node.comp_name, state))
                        state = self.check_component(node.component)
                        if (state is not CheckState.RUNNING or
                           state is not CheckState.STOPPED_BUT_SUCCESSFUL):
                            break
                        if tries > 100:
                            return False
                        tries = tries + 1
                        sleep(.5)

        self.logger.debug(""All dependencies satisfied, starting '%s'"" % (comp['name']))
        state = self.check_component(node.component)
        if (state is CheckState.STARTED_BY_HAND or
                state is CheckState.RUNNING):
            self.logger.debug(""Component %s is already running. Skipping start"" % comp['name'])
        else:
            self.start_component_without_deps(comp)
        return True

    def start_component_without_deps(self, comp):
        if comp['host'] != 'localhost' and not self.run_on_localhost(comp):
            self.logger.debug(""Starting remote component '%s' on host '%s'"" % (comp['name'], comp['host']))
            self.start_remote_component(comp['name'], comp['host'])
        else:
            log_file = (""%s/%s"" % (TMP_LOG_PATH, comp['name']))
            window = find_window(self.session, comp['name'])

            if window:
                self.logger.debug(""Restarting '%s' in old window"" % comp['name'])
                start_window(window, comp['cmd'][0]['start'], log_file, comp['name'])
            else:
                self.logger.info(""creating window '%s'"" % comp['name'])
                window = self.session.new_window(comp['name'])
                start_window(window, comp['cmd'][0]['start'], log_file, comp['name'])

    def start_remote_component(self, comp_name, host):
        # invoke Hyperion in slave mode on each remote host
        cmd = (""ssh %s 'hyperion --config %s/%s.yaml slave'"" % (host, TMP_SLAVE_DIR, comp_name))
        self.logger.debug(""Run cmd:\n%s"" % cmd)
        send_main_session_command(self.session, cmd)

    ###################
    # Check
    ###################
    def check_component(self, comp):
        return check_component(comp, self.session, self.logger)

    ###################
    # Dependency management
    ###################
    def get_dep_list(self, comp):
        node = self.nodes.get(comp['name'])
        res = []
        unres = []
        dep_resolve(node, res, unres)
        res.remove(node)

        return res

    ###################
    # Host related checks
    ###################
    def is_localhost(self, hostname):
        try:
            hn_out = socket.gethostbyname(hostname)
            if hn_out == '127.0.0.1' or hn_out == '::1':
                self.logger.debug(""Host '%s' is localhost"" % hostname)
                return True
            else:
                self.logger.debug(""Host '%s' is not localhost"" % hostname)
                return False
        except socket.gaierror:
            sys.exit(""Host '%s' is unknown! Update your /etc/hosts file!"" % hostname)

    def run_on_localhost(self, comp):
        return self.is_localhost(comp['host'])

    ###################
    # TMUX
    ###################
    def kill_remote_session_by_name(self, name, host):
        cmd = ""ssh -t %s 'tmux kill-session -t %s'"" % (host, name)
        send_main_session_command(self.session, cmd)

    def start_clone_session(self, comp_name, session_name):
        cmd = ""%s '%s' '%s'"" % (SCRIPT_CLONE_PATH, session_name, comp_name)
        send_main_session_command(self.session, cmd)

    def start_remote_clone_session(self, comp_name, session_name, hostname):
        remote_cmd = (""%s '%s' '%s'"" % (SCRIPT_CLONE_PATH, session_name, comp_name))
        cmd = ""ssh %s 'bash -s' < %s"" % (hostname, remote_cmd)
        send_main_session_command(self.session, cmd)

    ###################
    # Visualisation
    ###################
    def draw_graph(self):
        deps = Digraph(""Deps"", strict=True)
        deps.graph_attr.update(rankdir=""BT"")
        try:
            node = self.nodes.get('master_node')

            for current in node.depends_on:
                deps.node(current.comp_name)

                res = []
                unres = []
                dep_resolve(current, res, unres)
                for node in res:
                    if ""depends"" in node.component:
                        for dep in node.component['depends']:
                            if dep not in self.nodes:
                                deps.node(dep, color=""red"")
                                deps.edge(node.comp_name, dep, ""missing"", color=""red"")
                            elif node.comp_name is not ""master_node"":
                                deps.edge(node.comp_name, dep)

        except CircularReferenceException as ex:
            self.logger.error(""Detected circular dependency reference between %s and %s!"" % (ex.node1, ex.node2))
            deps.edge(ex.node1, ex.node2, ""circular error"", color=""red"")
            deps.edge(ex.node2, ex.node1, color=""red"")

        deps.view()


class SlaveLauncher:

    def __init__(self, configfile=None, kill_mode=False, check_mode=False):
        self.kill_mode = kill_mode
        self.check_mode = check_mode
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)
        self.config = None
        self.session = None
        if kill_mode:
            self.logger.info(""started slave with kill mode"")
        if check_mode:
            self.logger.info(""started slave with check mode"")
        self.server = Server()

        if self.server.has_session(""slave-session""):
            self.session = self.server.find_where({
                ""session_name"": ""slave-session""
            })

            self.logger.info('found running slave session on server')
        elif not kill_mode and not check_mode:
            self.logger.info('starting new slave session on server')
            self.session = self.server.new_session(
                session_name=""slave-session""
            )

        else:
            self.logger.info(""No slave session found on server. Aborting"")
            exit(CheckState.STOPPED)

        if configfile:
            self.load_config(configfile)
            self.window_name = self.config['name']
            self.flag_path = (""/tmp/Hyperion/slaves/%s"" % self.window_name)
            self.log_file = (""/tmp/Hyperion/log/%s"" % self.window_name)
            ensure_dir(self.log_file)
        else:
            self.logger.error(""No slave component config provided"")

    def load_config(self, filename=""default.yaml""):
        with open(filename) as data_file:
            self.config = load(data_file, Loader)

    def init(self):
        if not self.config:
            self.logger.error("" Config not loaded yet!"")
        elif not self.session:
            self.logger.error("" Init aborted. No session was found!"")
        else:
            self.logger.debug(self.config)
            window = find_window(self.session, self.window_name)

            if window:
                self.logger.debug(""window '%s' found running"" % self.window_name)
                if self.kill_mode:
                    self.logger.info(""Shutting down window..."")
                    kill_window(window)
                    self.logger.info(""... done!"")
            elif not self.kill_mode:
                self.logger.info(""creating window '%s'"" % self.window_name)
                window = self.session.new_window(self.window_name)
                start_window(window, self.config['cmd'][0]['start'], self.log_file, self.window_name)

            else:
                self.logger.info(""There is no component running by the name '%s'. Exiting kill mode"" %
                                 self.window_name)

    def run_check(self):
        if not self.config:
            self.logger.error("" Config not loaded yet!"")
            exit(CheckState.STOPPED.value)
        elif not self.session:
            self.logger.error("" Init aborted. No session was found!"")
            exit(CheckState.STOPPED.value)

        check_state = check_component(self.config, self.session, self.logger)
        exit(check_state.value)

###################
# Component Management
###################
def run_component_check(comp):
    if call(comp['cmd'][1]['check'], shell=True) == 0:
        return True
    else:
        return False


def check_component(comp, session, logger):
    logger.debug(""Running component check for %s"" % comp['name'])
    check_available = len(comp['cmd']) > 1 and 'check' in comp['cmd'][1]
    window = find_window(session, comp['name'])
    if window:
        pid = get_window_pid(window)
        logger.debug(""Found window pid: %s"" % pid)

        # May return more child pids if logging is done via tee (which then was started twice in the window too)
        procs = []
        for entry in pid:
            procs.extend(Process(entry).children(recursive=True))
        pids = [p.pid for p in procs]
        logger.debug(""Window is running %s child processes"" % len(pids))

        # Two processes are tee logging
        # TODO: Change this when more logging options are introduced
        if len(pids) < 3:
            logger.debug(""Main window process has finished. Running custom check if available"")
            if check_available and run_component_check(comp):
                logger.debug(""Process terminated but check was successful"")
                return CheckState.STOPPED_BUT_SUCCESSFUL
            else:
                logger.debug(""Check failed or no check available: returning false"")
                return CheckState.STOPPED
        elif check_available and run_component_check(comp):
            logger.debug(""Check succeeded"")
            return CheckState.RUNNING
        elif not check_available:
            logger.debug(""No custom check specified and got sufficient pid amount: returning true"")
            return CheckState.RUNNING
        else:
            logger.debug(""Check failed: returning false"")
            return CheckState.STOPPED
    else:
        logger.debug(""%s window is not running. Running custom check"" % comp['name'])
        if check_available and run_component_check(comp):
            logger.debug(""Component was not started by Hyperion, but the check succeeded"")
            return CheckState.STARTED_BY_HAND
        else:
            logger.debug(""Window not running and no check command is available or it failed: returning false"")
            return CheckState.STOPPED


def get_window_pid(window):
    r = window.cmd('list-panes',
                   ""-F #{pane_pid}"")
    return [int(p) for p in r.stdout]

###################
# TMUX
###################
def kill_session_by_name(server, name):
    session = server.find_where({
        ""session_name"": name
    })
    session.kill_session()


def kill_window(window):
    window.cmd(""send-keys"", """", ""C-c"")
    window.kill_window()


def start_window(window, cmd, log_file, comp_name):
    setup_log(window, log_file, comp_name)
    window.cmd(""send-keys"", cmd, ""Enter"")


def find_window(session, window_name):
    window = session.find_where({
        ""window_name"": window_name
    })
    return window


def send_main_session_command(session, cmd):
    window = find_window(session, ""Main"")
    window.cmd(""send-keys"", cmd, ""Enter"")


###################
# Logging
###################
def setup_log(window, file, comp_name):
    clear_log(file)
    # Reroute stderr to log file
    window.cmd(""send-keys"", ""exec 2> >(exec tee -i -a '%s')"" % file, ""Enter"")
    # Reroute stdin to log file
    window.cmd(""send-keys"", ""exec 1> >(exec tee -i -a '%s')"" % file, ""Enter"")
    window.cmd(""send-keys"", ('echo ""#Hyperion component start: %s\n$(date)""' % comp_name), ""Enter"")


def clear_log(file_path):
    if os.path.isfile(file_path):
        os.remove(file_path)


def ensure_dir(file_path):
    directory = os.path.dirname(file_path)
    if not os.path.exists(directory):
        os.makedirs(directory)

###################
# Startup
###################
def main():
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.DEBUG)
    parser = argparse.ArgumentParser()

    # Create top level parser
    parser.add_argument(""--config"", '-c', type=str,
                        default='test.yaml',
                        help=""YAML config file. see sample-config.yaml. Default: test.yaml"")
    subparsers = parser.add_subparsers(dest=""cmd"")

    # Create parser for the editor command
    subparser_editor = subparsers.add_parser('edit', help=""Launches the editor to edit or create new systems and ""
                                                          ""components"")
    # Create parser for the run command
    subparser_run = subparsers.add_parser('run', help=""Launches the setup specified by the --config argument"")
    # Create parser for validator
    subparser_val = subparsers.add_parser('validate', help=""Validate the setup specified by the --config argument"")

    subparser_remote = subparsers.add_parser('slave', help=""Run a component locally without controlling it. The ""
                                                           ""control is taken care of the remote master invoking ""
                                                           ""this command.\nIf run with the --kill flag, the ""
                                                           ""passed component will be killed"")

    subparser_val.add_argument(""--visual"", help=""Generate and show a graph image"", action=""store_true"")

    remote_mutex = subparser_remote.add_mutually_exclusive_group(required=False)

    remote_mutex.add_argument('-k', '--kill', help=""switch to kill mode"", action=""store_true"")
    remote_mutex.add_argument('-c', '--check', help=""Run a component check"", action=""store_true"")

    args = parser.parse_args()
    logger.debug(args)

    if args.cmd == 'edit':
        logger.debug(""Launching editor mode"")

    elif args.cmd == 'run':
        logger.debug(""Launching runner mode"")

        cc = ControlCenter(args.config)
        cc.init()
        start_gui(cc)

    elif args.cmd == 'validate':
        logger.debug(""Launching validation mode"")
        cc = ControlCenter(args.config)
        if args.visual:
            cc.set_dependencies(False)
            cc.draw_graph()
        else:
            cc.set_dependencies(True)

    elif args.cmd == 'slave':
        logger.debug(""Launching slave mode"")
        sl = SlaveLauncher(args.config, args.kill, args.check)

        if args.check:
            sl.run_check()
        else:
            sl.init()


###################
# GUI
###################
def start_gui(control_center):
    app = QtGui.QApplication(sys.argv)
    main_window = QtGui.QMainWindow()
    ui = hyperGUI.UiMainWindow()
    ui.ui_init(main_window, control_center)
    main_window.show()
    sys.exit(app.exec_())
/n/n/n",1
76,76,9d9b01839cf3639e59d29c27e70688bdbf44db96,"classes.py/n/n""""""
classes.py - Base classes for PyLink IRC Services.

This module contains the base classes used by PyLink, including threaded IRC
connections and objects used to represent IRC servers, users, and channels.

Here be dragons.
""""""

import threading
import time
import socket
import ssl
import hashlib
from copy import deepcopy
import inspect
import re
from collections import defaultdict, deque
import ipaddress

try:
    import ircmatch
except ImportError:
    raise ImportError(""PyLink requires ircmatch to function; please install it and try again."")

from . import world, utils, structures, conf, __version__
from .log import *

### Exceptions

class ProtocolError(RuntimeError):
    pass

### Internal classes (users, servers, channels)

class Irc(utils.DeprecatedAttributesObject):
    """"""Base IRC object for PyLink.""""""

    def __init__(self, netname, proto, conf):
        """"""
        Initializes an IRC object. This takes 3 variables: the network name
        (a string), the name of the protocol module to use for this connection,
        and a configuration object.
        """"""
        self.deprecated_attributes = {
            'conf': 'Deprecated since 1.2; consider switching to conf.conf',
            'botdata': ""Deprecated since 1.2; consider switching to conf.conf['bot']"",
        }

        self.loghandlers = []
        self.name = netname
        self.conf = conf
        self.sid = None
        self.serverdata = conf['servers'][netname]
        self.botdata = conf['bot']
        self.protoname = proto.__name__.split('.')[-1]  # Remove leading pylinkirc.protocols.
        self.proto = proto.Class(self)
        self.pingfreq = self.serverdata.get('pingfreq') or 90
        self.pingtimeout = self.pingfreq * 2

        self.queue = deque()

        self.connected = threading.Event()
        self.aborted = threading.Event()
        self.reply_lock = threading.RLock()

        self.pingTimer = None

        # Sets the multiplier for autoconnect delay (grows with time).
        self.autoconnect_active_multiplier = 1

        self.initVars()

        if world.testing:
            # HACK: Don't thread if we're running tests.
            self.connect()
        else:
            self.connection_thread = threading.Thread(target=self.connect,
                                                      name=""Listener for %s"" %
                                                      self.name)
            self.connection_thread.start()

    def logSetup(self):
        """"""
        Initializes any channel loggers defined for the current network.
        """"""
        try:
            channels = conf.conf['logging']['channels'][self.name]
        except KeyError:  # Not set up; just ignore.
            return

        log.debug('(%s) Setting up channel logging to channels %r', self.name,
                  channels)

        if not self.loghandlers:
            # Only create handlers if they haven't already been set up.

            for channel, chandata in channels.items():
                # Fetch the log level for this channel block.
                level = None
                if chandata is not None:
                    level = chandata.get('loglevel')

                handler = PyLinkChannelLogger(self, channel, level=level)
                self.loghandlers.append(handler)
                log.addHandler(handler)

    def initVars(self):
        """"""
        (Re)sets an IRC object to its default state. This should be called when
        an IRC object is first created, and on every reconnection to a network.
        """"""
        self.pingfreq = self.serverdata.get('pingfreq') or 90
        self.pingtimeout = self.pingfreq * 3

        self.pseudoclient = None
        self.lastping = time.time()

        self.queue.clear()

        # Internal variable to set the place and caller of the last command (in PM
        # or in a channel), used by fantasy command support.
        self.called_by = None
        self.called_in = None

        # Intialize the server, channel, and user indexes to be populated by
        # our protocol module. For the server index, we can add ourselves right
        # now.
        self.servers = {}
        self.users = {}
        self.channels = structures.KeyedDefaultdict(IrcChannel)

        # This sets the list of supported channel and user modes: the default
        # RFC1459 modes are implied. Named modes are used here to make
        # protocol-independent code easier to write, as mode chars vary by
        # IRCd.
        # Protocol modules should add to and/or replace this with what their
        # protocol supports. This can be a hardcoded list or something
        # negotiated on connect, depending on the nature of their protocol.
        self.cmodes = {'op': 'o', 'secret': 's', 'private': 'p',
                       'noextmsg': 'n', 'moderated': 'm', 'inviteonly': 'i',
                       'topiclock': 't', 'limit': 'l', 'ban': 'b',
                       'voice': 'v', 'key': 'k',
                       # This fills in the type of mode each mode character is.
                       # A-type modes are list modes (i.e. bans, ban exceptions, etc.),
                       # B-type modes require an argument to both set and unset,
                       #   but there can only be one value at a time
                       #   (i.e. cmode +k).
                       # C-type modes require an argument to set but not to unset
                       #   (one sets ""+l limit"" and # ""-l""),
                       # and D-type modes take no arguments at all.
                       '*A': 'b',
                       '*B': 'k',
                       '*C': 'l',
                       '*D': 'imnpstr'}
        self.umodes = {'invisible': 'i', 'snomask': 's', 'wallops': 'w',
                       'oper': 'o',
                       '*A': '', '*B': '', '*C': '', '*D': 'iosw'}

        # This max nick length starts off as the config value, but may be
        # overwritten later by the protocol module if such information is
        # received. It defaults to 30.
        self.maxnicklen = self.serverdata.get('maxnicklen', 30)

        # Defines a list of supported prefix modes.
        self.prefixmodes = {'o': '@', 'v': '+'}

        # Defines the uplink SID (to be filled in by protocol module).
        self.uplink = None
        self.start_ts = int(time.time())

        # Set up channel logging for the network
        self.logSetup()

    def processQueue(self):
        """"""Loop to process outgoing queue data.""""""
        while not self.aborted.is_set():
            if self.queue:  # Only process if there's data.
                data = self.queue.popleft()
                self._send(data)
            throttle_time = self.serverdata.get('throttle_time', 0.005)
            self.aborted.wait(throttle_time)
        log.debug('(%s) Stopping queue thread as aborted is set', self.name)

    def connect(self):
        """"""
        Runs the connect loop for the IRC object. This is usually called by
        __init__ in a separate thread to allow multiple concurrent connections.
        """"""
        while True:

            self.aborted.clear()
            self.initVars()

            try:
                self.proto.validateServerConf()
            except AssertionError as e:
                log.exception(""(%s) Configuration error: %s"", self.name, e)
                return

            ip = self.serverdata[""ip""]
            port = self.serverdata[""port""]
            checks_ok = True
            try:
                # Set the socket type (IPv6 or IPv4).
                stype = socket.AF_INET6 if self.serverdata.get(""ipv6"") else socket.AF_INET

                # Creat the socket.
                self.socket = socket.socket(stype)
                self.socket.setblocking(0)

                # Set the socket bind if applicable.
                if 'bindhost' in self.serverdata:
                    self.socket.bind((self.serverdata['bindhost'], 0))

                # Set the connection timeouts. Initial connection timeout is a
                # lot smaller than the timeout after we've connected; this is
                # intentional.
                self.socket.settimeout(self.pingfreq)

                # Resolve hostnames if it's not an IP address already.
                old_ip = ip
                ip = socket.getaddrinfo(ip, port, stype)[0][-1][0]
                log.debug('(%s) Resolving address %s to %s', self.name, old_ip, ip)

                # Enable SSL if set to do so. This requires a valid keyfile and
                # certfile to be present.
                self.ssl = self.serverdata.get('ssl')
                if self.ssl:
                    log.info('(%s) Attempting SSL for this connection...', self.name)
                    certfile = self.serverdata.get('ssl_certfile')
                    keyfile = self.serverdata.get('ssl_keyfile')

                    context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
                    # Disable SSLv2 and SSLv3 - these are insecure
                    context.options |= ssl.OP_NO_SSLv2
                    context.options |= ssl.OP_NO_SSLv3

                    if certfile and keyfile:
                        try:
                            context.load_cert_chain(certfile, keyfile)
                        except OSError:
                             log.exception('(%s) Caught OSError trying to '
                                           'initialize the SSL connection; '
                                           'are ""ssl_certfile"" and '
                                           '""ssl_keyfile"" set correctly?',
                                           self.name)
                             checks_ok = False

                    self.socket = context.wrap_socket(self.socket)

                log.info(""Connecting to network %r on %s:%s"", self.name, ip, port)
                self.socket.connect((ip, port))
                self.socket.settimeout(self.pingtimeout)

                # If SSL was enabled, optionally verify the certificate
                # fingerprint for some added security. I don't bother to check
                # the entire certificate for validity, since most IRC networks
                # self-sign their certificates anyways.
                if self.ssl and checks_ok:
                    peercert = self.socket.getpeercert(binary_form=True)

                    # Hash type is configurable using the ssl_fingerprint_type
                    # value, and defaults to sha256.
                    hashtype = self.serverdata.get('ssl_fingerprint_type', 'sha256').lower()

                    try:
                        hashfunc = getattr(hashlib, hashtype)
                    except AttributeError:
                        log.error('(%s) Unsupported SSL certificate fingerprint type %r given, disconnecting...',
                                  self.name, hashtype)
                        checks_ok = False
                    else:
                        fp = hashfunc(peercert).hexdigest()
                        expected_fp = self.serverdata.get('ssl_fingerprint')

                        if expected_fp and checks_ok:
                            if fp != expected_fp:
                                # SSL Fingerprint doesn't match; break.
                                log.error('(%s) Uplink\'s SSL certificate '
                                          'fingerprint (%s) does not match the '
                                          'one configured: expected %r, got %r; '
                                          'disconnecting...', self.name, hashtype,
                                          expected_fp, fp)
                                checks_ok = False
                            else:
                                log.info('(%s) Uplink SSL certificate fingerprint '
                                         '(%s) verified: %r', self.name, hashtype,
                                         fp)
                        else:
                            log.info('(%s) Uplink\'s SSL certificate fingerprint (%s) '
                                     'is %r. You can enhance the security of your '
                                     'link by specifying this in a ""ssl_fingerprint""'
                                     ' option in your server block.', self.name,
                                     hashtype, fp)

                if checks_ok:

                    self.queue_thread = threading.Thread(name=""Queue thread for %s"" % self.name,
                                                         target=self.processQueue, daemon=True)
                    self.queue_thread.start()

                    self.sid = self.serverdata.get(""sid"")
                    # All our checks passed, get the protocol module to connect and run the listen
                    # loop. This also updates any SID values should the protocol module do so.
                    self.proto.connect()

                    log.info('(%s) Enumerating our own SID %s', self.name, self.sid)
                    host = self.hostname()

                    self.servers[self.sid] = IrcServer(None, host, internal=True,
                            desc=self.serverdata.get('serverdesc')
                            or conf.conf['bot']['serverdesc'])

                    log.info('(%s) Starting ping schedulers....', self.name)
                    self.schedulePing()
                    log.info('(%s) Server ready; listening for data.', self.name)
                    self.autoconnect_active_multiplier = 1  # Reset any extra autoconnect delays
                    self.run()
                else:  # Configuration error :(
                    log.error('(%s) A configuration error was encountered '
                              'trying to set up this connection. Please check'
                              ' your configuration file and try again.',
                              self.name)
            # self.run() or the protocol module it called raised an exception, meaning we've disconnected!
            # Note: socket.error, ConnectionError, IOError, etc. are included in OSError since Python 3.3,
            # so we don't need to explicitly catch them here.
            # We also catch SystemExit here as a way to abort out connection threads properly, and stop the
            # IRC connection from freezing instead.
            except (OSError, RuntimeError, SystemExit) as e:
                log.error('(%s) Disconnected from IRC: %s: %s',
                          self.name, type(e).__name__, str(e))

            self.disconnect()

            # If autoconnect is enabled, loop back to the start. Otherwise,
            # return and stop.
            autoconnect = self.serverdata.get('autoconnect')

            # Sets the autoconnect growth multiplier (e.g. a value of 2 multiplies the autoconnect
            # time by 2 on every failure, etc.)
            autoconnect_multiplier = self.serverdata.get('autoconnect_multiplier', 2)
            autoconnect_max = self.serverdata.get('autoconnect_max', 1800)
            # These values must at least be 1.
            autoconnect_multiplier = max(autoconnect_multiplier, 1)
            autoconnect_max = max(autoconnect_max, 1)

            log.debug('(%s) Autoconnect delay set to %s seconds.', self.name, autoconnect)
            if autoconnect is not None and autoconnect >= 1:
                log.debug('(%s) Multiplying autoconnect delay %s by %s.', self.name, autoconnect, self.autoconnect_active_multiplier)
                autoconnect *= self.autoconnect_active_multiplier
                # Add a cap on the max. autoconnect delay, so that we don't go on forever...
                autoconnect = min(autoconnect, autoconnect_max)

                log.info('(%s) Going to auto-reconnect in %s seconds.', self.name, autoconnect)
                # Continue when either self.aborted is set or the autoconnect time passes.
                # Compared to time.sleep(), this allows us to stop connections quicker if we
                # break while while for autoconnect.
                self.aborted.clear()
                self.aborted.wait(autoconnect)

                # Store in the local state what the autoconnect multiplier currently is.
                self.autoconnect_active_multiplier *= autoconnect_multiplier

                if self not in world.networkobjects.values():
                    log.debug('Stopping stale connect loop for old connection %r', self.name)
                    return

            else:
                log.info('(%s) Stopping connect loop (autoconnect value %r is < 1).', self.name, autoconnect)
                return

    def disconnect(self):
        """"""Handle disconnects from the remote server.""""""
        was_successful = self.connected.is_set()
        log.debug('(%s) disconnect: got %s for was_successful state', self.name, was_successful)

        log.debug('(%s) disconnect: Clearing self.connected state.', self.name)
        self.connected.clear()

        log.debug('(%s) Removing channel logging handlers due to disconnect.', self.name)
        while self.loghandlers:
            log.removeHandler(self.loghandlers.pop())

        try:
            log.debug('(%s) disconnect: Shutting down socket.', self.name)
            self.socket.shutdown(socket.SHUT_RDWR)
        except:  # Socket timed out during creation; ignore
            pass

        self.socket.close()

        if self.pingTimer:
            log.debug('(%s) Canceling pingTimer at %s due to disconnect() call', self.name, time.time())
            self.pingTimer.cancel()

        log.debug('(%s) disconnect: Setting self.aborted to True.', self.name)
        self.aborted.set()

        # Internal hook signifying that a network has disconnected.
        self.callHooks([None, 'PYLINK_DISCONNECT', {'was_successful': was_successful}])

        log.debug('(%s) disconnect: Clearing state via initVars().', self.name)
        self.initVars()

    def run(self):
        """"""Main IRC loop which listens for messages.""""""
        # Some magic below cause this to work, though anything that's
        # not encoded in UTF-8 doesn't work very well.
        buf = b""""
        data = b""""
        while not self.aborted.is_set():

            try:
                data = self.socket.recv(2048)
            except OSError:
                # Suppress socket read warnings from lingering recv() calls if
                # we've been told to shutdown.
                if self.aborted.is_set():
                    return
                raise

            buf += data
            if not data:
                log.error('(%s) No data received, disconnecting!', self.name)
                return
            elif (time.time() - self.lastping) > self.pingtimeout:
                log.error('(%s) Connection timed out.', self.name)
                return
            while b'\n' in buf:
                line, buf = buf.split(b'\n', 1)
                line = line.strip(b'\r')
                # FIXME: respect other encodings?
                line = line.decode(""utf-8"", ""replace"")
                self.runline(line)

    def runline(self, line):
        """"""Sends a command to the protocol module.""""""
        log.debug(""(%s) <- %s"", self.name, line)
        try:
            hook_args = self.proto.handle_events(line)
        except Exception:
            log.exception('(%s) Caught error in handle_events, disconnecting!', self.name)
            log.error('(%s) The offending line was: <- %s', self.name, line)
            self.aborted.set()
            return
        # Only call our hooks if there's data to process. Handlers that support
        # hooks will return a dict of parsed arguments, which can be passed on
        # to plugins and the like. For example, the JOIN handler will return
        # something like: {'channel': '#whatever', 'users': ['UID1', 'UID2',
        # 'UID3']}, etc.
        if hook_args is not None:
            self.callHooks(hook_args)

        return hook_args

    def callHooks(self, hook_args):
        """"""Calls a hook function with the given hook args.""""""
        numeric, command, parsed_args = hook_args
        # Always make sure TS is sent.
        if 'ts' not in parsed_args:
            parsed_args['ts'] = int(time.time())
        hook_cmd = command
        hook_map = self.proto.hook_map

        # If the hook name is present in the protocol module's hook_map, then we
        # should set the hook name to the name that points to instead.
        # For example, plugins will read SETHOST as CHGHOST, EOS (end of sync)
        # as ENDBURST, etc.
        if command in hook_map:
            hook_cmd = hook_map[command]

        # However, individual handlers can also return a 'parse_as' key to send
        # their payload to a different hook. An example of this is ""/join 0""
        # being interpreted as leaving all channels (PART).
        hook_cmd = parsed_args.get('parse_as') or hook_cmd

        log.debug('(%s) Raw hook data: [%r, %r, %r] received from %s handler '
                  '(calling hook %s)', self.name, numeric, hook_cmd, parsed_args,
                  command, hook_cmd)

        # Iterate over registered hook functions, catching errors accordingly.
        for hook_func in world.hooks[hook_cmd]:
            try:
                log.debug('(%s) Calling hook function %s from plugin ""%s""', self.name,
                          hook_func, hook_func.__module__)
                hook_func(self, numeric, command, parsed_args)
            except Exception:
                # We don't want plugins to crash our servers...
                log.exception('(%s) Unhandled exception caught in hook %r from plugin ""%s""',
                              self.name, hook_func, hook_func.__module__)
                log.error('(%s) The offending hook data was: %s', self.name,
                          hook_args)
                continue

    def _send(self, data):
        """"""Sends raw text to the uplink server.""""""
        # Safeguard against newlines in input!! Otherwise, each line gets
        # treated as a separate command, which is particularly nasty.
        data = data.replace('\n', ' ')
        data = data.encode(""utf-8"") + b""\n""
        stripped_data = data.decode(""utf-8"").strip(""\n"")
        log.debug(""(%s) -> %s"", self.name, stripped_data)

        try:
            self.socket.send(data)
        except (OSError, AttributeError):
            log.debug(""(%s) Dropping message %r; network isn't connected!"", self.name, stripped_data)

    def send(self, data, queue=True):
        """"""send() wrapper with optional queueing support.""""""
        if queue:
            self.queue.append(data)
        else:
            self._send(data)

    def schedulePing(self):
        """"""Schedules periodic pings in a loop.""""""
        self.proto.ping()

        self.pingTimer = threading.Timer(self.pingfreq, self.schedulePing)
        self.pingTimer.daemon = True
        self.pingTimer.name = 'Ping timer loop for %s' % self.name
        self.pingTimer.start()

        log.debug('(%s) Ping scheduled at %s', self.name, time.time())

    def __repr__(self):
        return ""<classes.Irc object for %r>"" % self.name

    ### General utility functions
    def callCommand(self, source, text):
        """"""
        Calls a PyLink bot command. source is the caller's UID, and text is the
        full, unparsed text of the message.
        """"""
        world.services['pylink'].call_cmd(self, source, text)

    def msg(self, target, text, notice=None, source=None, loopback=True):
        """"""Handy function to send messages/notices to clients. Source
        is optional, and defaults to the main PyLink client if not specified.""""""
        if not text:
            return

        if not (source or self.pseudoclient):
            # No explicit source set and our main client wasn't available; abort.
            return
        source = source or self.pseudoclient.uid

        if notice:
            self.proto.notice(source, target, text)
            cmd = 'PYLINK_SELF_NOTICE'
        else:
            self.proto.message(source, target, text)
            cmd = 'PYLINK_SELF_PRIVMSG'

        if loopback:
            # Determines whether we should send a hook for this msg(), to relay things like services
            # replies across relay.
            self.callHooks([source, cmd, {'target': target, 'text': text}])

    def _reply(self, text, notice=None, source=None, private=None, force_privmsg_in_private=False,
            loopback=True):
        """"""
        Core of the reply() function - replies to the last caller in the right context
        (channel or PM).
        """"""
        if private is None:
            # Allow using private replies as the default, if no explicit setting was given.
            private = conf.conf['bot'].get(""prefer_private_replies"")

        # Private reply is enabled, or the caller was originally a PM
        if private or (self.called_in in self.users):
            if not force_privmsg_in_private:
                # For private replies, the default is to override the notice=True/False argument,
                # and send replies as notices regardless. This is standard behaviour for most
                # IRC services, but can be disabled if force_privmsg_in_private is given.
                notice = True
            target = self.called_by
        else:
            target = self.called_in

        self.msg(target, text, notice=notice, source=source, loopback=loopback)

    def reply(self, *args, **kwargs):
        """"""
        Replies to the last caller in the right context (channel or PM).

        This function wraps around _reply() and can be monkey-patched in a thread-safe manner
        to temporarily redirect plugin output to another target.
        """"""
        with self.reply_lock:
            self._reply(*args, **kwargs)

    def error(self, text, **kwargs):
        """"""Replies with an error to the last caller in the right context (channel or PM).""""""
        # This is a stub to alias error to reply
        self.reply(""Error: %s"" % text, **kwargs)

    def toLower(self, text):
        """"""Returns a lowercase representation of text based on the IRC object's
        casemapping (rfc1459 or ascii).""""""
        if self.proto.casemapping == 'rfc1459':
            text = text.replace('{', '[')
            text = text.replace('}', ']')
            text = text.replace('|', '\\')
            text = text.replace('~', '^')
        # Encode the text as bytes first, and then lowercase it so that only ASCII characters are
        # changed. Unicode in channel names, etc. is case sensitive because IRC is just that old of
        # a protocol!!!
        return text.encode().lower().decode()

    def parseModes(self, target, args):
        """"""Parses a modestring list into a list of (mode, argument) tuples.
        ['+mitl-o', '3', 'person'] => [('+m', None), ('+i', None), ('+t', None), ('+l', '3'), ('-o', 'person')]
        """"""
        # http://www.irc.org/tech_docs/005.html
        # A = Mode that adds or removes a nick or address to a list. Always has a parameter.
        # B = Mode that changes a setting and always has a parameter.
        # C = Mode that changes a setting and only has a parameter when set.
        # D = Mode that changes a setting and never has a parameter.

        if type(args) == str:
            # If the modestring was given as a string, split it into a list.
            args = args.split()

        assert args, 'No valid modes were supplied!'
        usermodes = not utils.isChannel(target)
        prefix = ''
        modestring = args[0]
        args = args[1:]
        if usermodes:
            log.debug('(%s) Using self.umodes for this query: %s', self.name, self.umodes)

            if target not in self.users:
                log.debug('(%s) Possible desync! Mode target %s is not in the users index.', self.name, target)
                return []  # Return an empty mode list

            supported_modes = self.umodes
            oldmodes = self.users[target].modes
        else:
            log.debug('(%s) Using self.cmodes for this query: %s', self.name, self.cmodes)

            supported_modes = self.cmodes
            oldmodes = self.channels[target].modes
        res = []
        for mode in modestring:
            if mode in '+-':
                prefix = mode
            else:
                if not prefix:
                    prefix = '+'
                arg = None
                log.debug('Current mode: %s%s; args left: %s', prefix, mode, args)
                try:
                    if mode in self.prefixmodes and not usermodes:
                        # We're setting a prefix mode on someone (e.g. +o user1)
                        log.debug('Mode %s: This mode is a prefix mode.', mode)
                        arg = args.pop(0)
                        # Convert nicks to UIDs implicitly; most IRCds will want
                        # this already.
                        arg = self.nickToUid(arg) or arg
                        if arg not in self.users:  # Target doesn't exist, skip it.
                            log.debug('(%s) Skipping setting mode ""%s %s""; the '
                                      'target doesn\'t seem to exist!', self.name,
                                      mode, arg)
                            continue
                    elif mode in (supported_modes['*A'] + supported_modes['*B']):
                        # Must have parameter.
                        log.debug('Mode %s: This mode must have parameter.', mode)
                        arg = args.pop(0)
                        if prefix == '-':
                            if mode in supported_modes['*B'] and arg == '*':
                                # Charybdis allows unsetting +k without actually
                                # knowing the key by faking the argument when unsetting
                                # as a single ""*"".
                                # We'd need to know the real argument of +k for us to
                                # be able to unset the mode.
                                oldarg = dict(oldmodes).get(mode)
                                if oldarg:
                                    # Set the arg to the old one on the channel.
                                    arg = oldarg
                                    log.debug(""Mode %s: coersing argument of '*' to %r."", mode, arg)

                            log.debug('(%s) parseModes: checking if +%s %s is in old modes list: %s', self.name, mode, arg, oldmodes)

                            if (mode, arg) not in oldmodes:
                                # Ignore attempts to unset bans that don't exist.
                                log.debug(""(%s) parseModes(): ignoring removal of non-existent list mode +%s %s"", self.name, mode, arg)
                                continue

                    elif prefix == '+' and mode in supported_modes['*C']:
                        # Only has parameter when setting.
                        log.debug('Mode %s: Only has parameter when setting.', mode)
                        arg = args.pop(0)
                except IndexError:
                    log.warning('(%s/%s) Error while parsing mode %r: mode requires an '
                                'argument but none was found. (modestring: %r)',
                                self.name, target, mode, modestring)
                    continue  # Skip this mode; don't error out completely.
                res.append((prefix + mode, arg))
        return res

    def applyModes(self, target, changedmodes):
        """"""Takes a list of parsed IRC modes, and applies them on the given target.

        The target can be either a channel or a user; this is handled automatically.""""""
        usermodes = not utils.isChannel(target)
        log.debug('(%s) Using usermodes for this query? %s', self.name, usermodes)

        try:
            if usermodes:
                old_modelist = self.users[target].modes
                supported_modes = self.umodes
            else:
                old_modelist = self.channels[target].modes
                supported_modes = self.cmodes
        except KeyError:
            log.warning('(%s) Possible desync? Mode target %s is unknown.', self.name, target)
            return

        modelist = set(old_modelist)
        log.debug('(%s) Applying modes %r on %s (initial modelist: %s)', self.name, changedmodes, target, modelist)
        for mode in changedmodes:
            # Chop off the +/- part that parseModes gives; it's meaningless for a mode list.
            try:
                real_mode = (mode[0][1], mode[1])
            except IndexError:
                real_mode = mode

            if not usermodes:
                # We only handle +qaohv for now. Iterate over every supported mode:
                # if the IRCd supports this mode and it is the one being set, add/remove
                # the person from the corresponding prefix mode list (e.g. c.prefixmodes['op']
                # for ops).
                for pmode, pmodelist in self.channels[target].prefixmodes.items():
                    if pmode in self.cmodes and real_mode[0] == self.cmodes[pmode]:
                        log.debug('(%s) Initial prefixmodes list: %s', self.name, pmodelist)
                        if mode[0][0] == '+':
                            pmodelist.add(mode[1])
                        else:
                            pmodelist.discard(mode[1])

                        log.debug('(%s) Final prefixmodes list: %s', self.name, pmodelist)

                if real_mode[0] in self.prefixmodes:
                    # Don't add prefix modes to IrcChannel.modes; they belong in the
                    # prefixmodes mapping handled above.
                    log.debug('(%s) Not adding mode %s to IrcChannel.modes because '
                              'it\'s a prefix mode.', self.name, str(mode))
                    continue

            if mode[0][0] != '-':
                # We're adding a mode
                existing = [m for m in modelist if m[0] == real_mode[0] and m[1] != real_mode[1]]
                if existing and real_mode[1] and real_mode[0] not in self.cmodes['*A']:
                    # The mode we're setting takes a parameter, but is not a list mode (like +beI).
                    # Therefore, only one version of it can exist at a time, and we must remove
                    # any old modepairs using the same letter. Otherwise, we'll get duplicates when,
                    # for example, someone sets mode ""+l 30"" on a channel already set ""+l 25"".
                    log.debug('(%s) Old modes for mode %r exist on %s, removing them: %s',
                              self.name, real_mode, target, str(existing))
                    [modelist.discard(oldmode) for oldmode in existing]
                modelist.add(real_mode)
                log.debug('(%s) Adding mode %r on %s', self.name, real_mode, target)
            else:
                log.debug('(%s) Removing mode %r on %s', self.name, real_mode, target)
                # We're removing a mode
                if real_mode[1] is None:
                    # We're removing a mode that only takes arguments when setting.
                    # Remove all mode entries that use the same letter as the one
                    # we're unsetting.
                    for oldmode in modelist.copy():
                        if oldmode[0] == real_mode[0]:
                            modelist.discard(oldmode)
                else:
                    modelist.discard(real_mode)
        log.debug('(%s) Final modelist: %s', self.name, modelist)
        try:
            if usermodes:
                self.users[target].modes = modelist
            else:
                self.channels[target].modes = modelist
        except KeyError:
            log.warning(""(%s) Invalid MODE target %s (usermodes=%s)"", self.name, target, usermodes)

    @staticmethod
    def _flip(mode):
        """"""Flips a mode character.""""""
        # Make it a list first, strings don't support item assignment
        mode = list(mode)
        if mode[0] == '-':  # Query is something like ""-n""
            mode[0] = '+'  # Change it to ""+n""
        elif mode[0] == '+':
            mode[0] = '-'
        else:  # No prefix given, assume +
            mode.insert(0, '-')
        return ''.join(mode)

    def reverseModes(self, target, modes, oldobj=None):
        """"""Reverses/Inverts the mode string or mode list given.

        Optionally, an oldobj argument can be given to look at an earlier state of
        a channel/user object, e.g. for checking the op status of a mode setter
        before their modes are processed and added to the channel state.

        This function allows both mode strings or mode lists. Example uses:
            ""+mi-lk test => ""-mi+lk test""
            ""mi-k test => ""-mi+k test""
            [('+m', None), ('+r', None), ('+l', '3'), ('-o', 'person')
             => {('-m', None), ('-r', None), ('-l', None), ('+o', 'person')})
            {('s', None), ('+o', 'whoever') => {('-s', None), ('-o', 'whoever')})
        """"""
        origtype = type(modes)
        # If the query is a string, we have to parse it first.
        if origtype == str:
            modes = self.parseModes(target, modes.split("" ""))
        # Get the current mode list first.
        if utils.isChannel(target):
            c = oldobj or self.channels[target]
            oldmodes = c.modes.copy()
            possible_modes = self.cmodes.copy()
            # For channels, this also includes the list of prefix modes.
            possible_modes['*A'] += ''.join(self.prefixmodes)
            for name, userlist in c.prefixmodes.items():
                try:
                    oldmodes.update([(self.cmodes[name], u) for u in userlist])
                except KeyError:
                    continue
        else:
            oldmodes = self.users[target].modes
            possible_modes = self.umodes
        newmodes = []
        log.debug('(%s) reverseModes: old/current mode list for %s is: %s', self.name,
                   target, oldmodes)
        for char, arg in modes:
            # Mode types:
            # A = Mode that adds or removes a nick or address to a list. Always has a parameter.
            # B = Mode that changes a setting and always has a parameter.
            # C = Mode that changes a setting and only has a parameter when set.
            # D = Mode that changes a setting and never has a parameter.
            mchar = char[-1]
            if mchar in possible_modes['*B'] + possible_modes['*C']:
                # We need to find the current mode list, so we can reset arguments
                # for modes that have arguments. For example, setting +l 30 on a channel
                # that had +l 50 set should give ""+l 30"", not ""-l"".
                oldarg = [m for m in oldmodes if m[0] == mchar]
                if oldarg:  # Old mode argument for this mode existed, use that.
                    oldarg = oldarg[0]
                    mpair = ('+%s' % oldarg[0], oldarg[1])
                else:  # Not found, flip the mode then.
                    # Mode takes no arguments when unsetting.
                    if mchar in possible_modes['*C'] and char[0] != '-':
                        arg = None
                    mpair = (self._flip(char), arg)
            else:
                mpair = (self._flip(char), arg)
            if char[0] != '-' and (mchar, arg) in oldmodes:
                # Mode is already set.
                log.debug(""(%s) reverseModes: skipping reversing '%s %s' with %s since we're ""
                          ""setting a mode that's already set."", self.name, char, arg, mpair)
                continue
            elif char[0] == '-' and (mchar, arg) not in oldmodes and mchar in possible_modes['*A']:
                # We're unsetting a prefixmode that was never set - don't set it in response!
                # Charybdis lacks verification for this server-side.
                log.debug(""(%s) reverseModes: skipping reversing '%s %s' with %s since it ""
                          ""wasn't previously set."", self.name, char, arg, mpair)
                continue
            newmodes.append(mpair)

        log.debug('(%s) reverseModes: new modes: %s', self.name, newmodes)
        if origtype == str:
            # If the original query is a string, send it back as a string.
            return self.joinModes(newmodes)
        else:
            return set(newmodes)

    @staticmethod
    def joinModes(modes, sort=False):
        """"""Takes a list of (mode, arg) tuples in parseModes() format, and
        joins them into a string.

        See testJoinModes in tests/test_utils.py for some examples.""""""
        prefix = '+'  # Assume we're adding modes unless told otherwise
        modelist = ''
        args = []

        # Sort modes alphabetically like a conventional IRCd.
        if sort:
            modes = sorted(modes)

        for modepair in modes:
            mode, arg = modepair
            assert len(mode) in (1, 2), ""Incorrect length of a mode (received %r)"" % mode
            try:
                # If the mode has a prefix, use that.
                curr_prefix, mode = mode
            except ValueError:
                # If not, the current prefix stays the same; move on to the next
                # modepair.
                pass
            else:
                # If the prefix of this mode isn't the same as the last one, add
                # the prefix to the modestring. This prevents '+nt-lk' from turning
                # into '+n+t-l-k' or '+ntlk'.
                if prefix != curr_prefix:
                    modelist += curr_prefix
                    prefix = curr_prefix
            modelist += mode
            if arg is not None:
                args.append(arg)
        if not modelist.startswith(('+', '-')):
            # Our starting mode didn't have a prefix with it. Assume '+'.
            modelist = '+' + modelist
        if args:
            # Add the args if there are any.
            modelist += ' %s' % ' '.join(args)
        return modelist

    @classmethod
    def wrapModes(cls, modes, limit, max_modes_per_msg=0):
        """"""
        Takes a list of modes and wraps it across multiple lines.
        """"""
        strings = []

        # This process is slightly trickier than just wrapping arguments, because modes create
        # positional arguments that can't be separated from its character.
        queued_modes = []
        total_length = 0

        last_prefix = '+'
        orig_modes = modes.copy()
        modes = list(modes)
        while modes:
            # PyLink mode lists come in the form [('+t', None), ('-b', '*!*@someone'), ('+l', 3)]
            # The +/- part is optional depending on context, and should either:
            # 1) The prefix of the last mode.
            # 2) + (adding modes), if no prefix was ever given
            next_mode = modes.pop(0)

            modechar, arg = next_mode
            prefix = modechar[0]
            if prefix not in '+-':
                prefix = last_prefix
                # Explicitly add the prefix to the mode character to prevent
                # ambiguity when passing it to joinModes().
                modechar = prefix + modechar
                # XXX: because tuples are immutable, we have to replace the entire modepair..
                next_mode = (modechar, arg)

            # Figure out the length that the next mode will add to the buffer. If we're changing
            # from + to - (setting to removing modes) or vice versa, we'll need two characters
            # (""+"" or ""-"") plus the mode char itself.
            next_length = 1
            if prefix != last_prefix:
                next_length += 1

            # Replace the last_prefix with the current one for the next iteration.
            last_prefix = prefix

            if arg:
                # This mode has an argument, so add the length of that and a space.
                next_length += 1
                next_length += len(arg)

            assert next_length <= limit, \
                ""wrapModes: Mode %s is too long for the given length %s"" % (next_mode, limit)

            # Check both message length and max. modes per msg if enabled.
            if (next_length + total_length) <= limit and ((not max_modes_per_msg) or len(queued_modes) < max_modes_per_msg):
                # We can fit this mode in the next message; add it.
                total_length += next_length
                log.debug('wrapModes: Adding mode %s to queued modes', str(next_mode))
                queued_modes.append(next_mode)
                log.debug('wrapModes: queued modes: %s', queued_modes)
            else:
                # Otherwise, create a new message by joining the previous queue.
                # Then, add our current mode.
                strings.append(cls.joinModes(queued_modes))
                queued_modes.clear()

                log.debug('wrapModes: cleared queue (length %s) and now adding %s', limit, str(next_mode))
                queued_modes.append(next_mode)
                total_length = next_length
        else:
            # Everything fit in one line, so just use that.
            strings.append(cls.joinModes(queued_modes))

        log.debug('wrapModes: returning %s for %s', strings, orig_modes)
        return strings

    def version(self):
        """"""
        Returns a detailed version string including the PyLink daemon version,
        the protocol module in use, and the server hostname.
        """"""
        fullversion = 'PyLink-%s. %s :[protocol:%s]' % (__version__, self.hostname(), self.protoname)
        return fullversion

    def hostname(self):
        """"""
        Returns the server hostname used by PyLink on the given server.
        """"""
        return self.serverdata.get('hostname', world.fallback_hostname)

    ### State checking functions
    def nickToUid(self, nick):
        """"""Looks up the UID of a user with the given nick, if one is present.""""""
        nick = self.toLower(nick)
        for k, v in self.users.copy().items():
            if self.toLower(v.nick) == nick:
                return k

    def isInternalClient(self, numeric):
        """"""
        Returns whether the given client numeric (UID) is a PyLink client.
        """"""
        sid = self.getServer(numeric)
        if sid and self.servers[sid].internal:
            return True
        return False

    def isInternalServer(self, sid):
        """"""Returns whether the given SID is an internal PyLink server.""""""
        return (sid in self.servers and self.servers[sid].internal)

    def getServer(self, numeric):
        """"""Finds the SID of the server a user is on.""""""
        userobj = self.users.get(numeric)
        if userobj:
            return userobj.server

    def isManipulatableClient(self, uid):
        """"""
        Returns whether the given user is marked as an internal, manipulatable
        client. Usually, automatically spawned services clients should have this
        set True to prevent interactions with opers (like mode changes) from
        causing desyncs.
        """"""
        return self.isInternalClient(uid) and self.users[uid].manipulatable

    def getServiceBot(self, uid):
        """"""
        Checks whether the given UID is a registered service bot. If True,
        returns the cooresponding ServiceBot object.
        """"""
        userobj = self.users.get(uid)
        if not userobj:
            return False

        # Look for the ""service"" attribute in the IrcUser object, if one exists.
        try:
            sname = userobj.service
            # Warn if the service name we fetched isn't a registered service.
            if sname not in world.services.keys():
                log.warning(""(%s) User %s / %s had a service bot record to a service that doesn't ""
                            ""exist (%s)!"", self.name, uid, userobj.nick, sname)
            return world.services.get(sname)
        except AttributeError:
            return False

    def getHostmask(self, user, realhost=False, ip=False):
        """"""
        Returns the hostmask of the given user, if present. If the realhost option
        is given, return the real host of the user instead of the displayed host.
        If the ip option is given, return the IP address of the user (this overrides
        realhost).""""""
        userobj = self.users.get(user)

        try:
            nick = userobj.nick
        except AttributeError:
            nick = '<unknown-nick>'

        try:
            ident = userobj.ident
        except AttributeError:
            ident = '<unknown-ident>'

        try:
            if ip:
                host = userobj.ip
            elif realhost:
                host = userobj.realhost
            else:
                host = userobj.host
        except AttributeError:
            host = '<unknown-host>'

        return '%s!%s@%s' % (nick, ident, host)

    def getFriendlyName(self, entityid):
        """"""
        Returns the friendly name of a SID or UID (server name for SIDs, nick for UID).
        """"""
        if entityid in self.servers:
            return self.servers[entityid].name
        elif entityid in self.users:
            return self.users[entityid].nick
        else:
            raise KeyError(""Unknown UID/SID %s"" % entityid)

    def getFullNetworkName(self):
        """"""
        Returns the full network name (as defined by the ""netname"" option), or the
        short network name if that isn't defined.
        """"""
        return self.serverdata.get('netname', self.name)

    def isOper(self, uid, allowAuthed=True, allowOper=True):
        """"""
        Returns whether the given user has operator status on PyLink. This can be achieved
        by either identifying to PyLink as admin (if allowAuthed is True),
        or having user mode +o set (if allowOper is True). At least one of
        allowAuthed or allowOper must be True for this to give any meaningful
        results.
        """"""
        if uid in self.users:
            if allowOper and (""o"", None) in self.users[uid].modes:
                return True
            elif allowAuthed and self.users[uid].account:
                return True
        return False

    def checkAuthenticated(self, uid, allowAuthed=True, allowOper=True):
        """"""
        Checks whether the given user has operator status on PyLink, raising
        NotAuthorizedError and logging the access denial if not.
        """"""
        log.warning(""(%s) Irc.checkAuthenticated() is deprecated as of PyLink 1.2 and may be ""
                    ""removed in a future relase. Consider migrating to the PyLink Permissions API."",
                    self.name)
        lastfunc = inspect.stack()[1][3]
        if not self.isOper(uid, allowAuthed=allowAuthed, allowOper=allowOper):
            log.warning('(%s) Access denied for %s calling %r', self.name,
                        self.getHostmask(uid), lastfunc)
            raise utils.NotAuthorizedError(""You are not authenticated!"")
        return True

    def matchHost(self, glob, target, ip=True, realhost=True):
        """"""
        Checks whether the given host, or given UID's hostmask matches the given nick!user@host
        glob.

        If the target given is a UID, and the 'ip' or 'realhost' options are True, this will also
        match against the target's IP address and real host, respectively.

        This function respects IRC casemappings (rfc1459 and ascii). If the given target is a UID,
        and the 'ip' option is enabled, the host portion of the glob is also matched as a CIDR
        range.
        """"""
        # Get the corresponding casemapping value used by ircmatch.
        if self.proto.casemapping == 'rfc1459':
            casemapping = 0
        else:
            casemapping = 1

        # Try to convert target into a UID. If this fails, it's probably a hostname.
        target = self.nickToUid(target) or target

        # Prepare a list of hosts to check against.
        if target in self.users:
            if glob.startswith(('$', '!$')):
                # !$exttarget inverts the given match.
                invert = glob.startswith('!$')

                # Exttargets start with $. Skip regular ban matching and find the matching ban handler.
                glob = glob.lstrip('$!')
                exttargetname = glob.split(':', 1)[0]
                handler = world.exttarget_handlers.get(exttargetname)

                if handler:
                    # Handler exists. Return what it finds.
                    result = handler(self, glob, target)
                    log.debug('(%s) Got %s from exttarget %s in matchHost() glob $%s for target %s',
                              self.name, result, exttargetname, glob, target)
                    if invert:  # Anti-exttarget was specified.
                        result = not result
                    return result
                else:
                    log.debug('(%s) Unknown exttarget %s in matchHost() glob $%s', self.name,
                              exttargetname, glob)
                    return False

            hosts = {self.getHostmask(target)}

            if ip:
                hosts.add(self.getHostmask(target, ip=True))

                # HACK: support CIDR hosts in the hosts portion
                try:
                    header, cidrtarget = glob.split('@', 1)
                    log.debug('(%s) Processing CIDRs for %s (full host: %s)', self.name,
                              cidrtarget, glob)
                    # Try to parse the host portion as a CIDR range
                    network = ipaddress.ip_network(cidrtarget)

                    log.debug('(%s) Found CIDR for %s, replacing target host with IP %s', self.name,
                              realhost, target)
                    real_ip = self.users[target].ip
                    if ipaddress.ip_address(real_ip) in network:
                        # If the CIDR matches, hack around the host matcher by pretending that
                        # the lookup target was the IP and not the CIDR range!
                        glob = '@'.join((header, real_ip))
                except ValueError:
                    pass

            if realhost:
                hosts.add(self.getHostmask(target, realhost=True))

        else:  # We were given a host, use that.
            hosts = [target]

        # Iterate over the hosts to match using ircmatch.
        for host in hosts:
            if ircmatch.match(casemapping, glob, host):
                return True

        return False

class IrcUser():
    """"""PyLink IRC user class.""""""
    def __init__(self, nick, ts, uid, server, ident='null', host='null',
                 realname='PyLink dummy client', realhost='null',
                 ip='0.0.0.0', manipulatable=False, opertype='IRC Operator'):
        self.nick = nick
        self.ts = ts
        self.uid = uid
        self.ident = ident
        self.host = host
        self.realhost = realhost
        self.ip = ip
        self.realname = realname
        self.modes = set()  # Tracks user modes
        self.server = server

        # Tracks PyLink identification status
        self.account = ''

        # Tracks oper type (for display only)
        self.opertype = opertype

        # Tracks external services identification status
        self.services_account = ''

        # Tracks channels the user is in
        self.channels = set()

        # Tracks away message status
        self.away = ''

        # This sets whether the client should be marked as manipulatable.
        # Plugins like bots.py's commands should take caution against
        # manipulating these ""protected"" clients, to prevent desyncs and such.
        # For ""serious"" service clients, this should always be False.
        self.manipulatable = manipulatable

    def __repr__(self):
        return 'IrcUser(%s/%s)' % (self.uid, self.nick)

class IrcServer():
    """"""PyLink IRC server class.

    uplink: The SID of this IrcServer instance's uplink. This is set to None
            for the main PyLink PseudoServer!
    name: The name of the server.
    internal: Whether the server is an internal PyLink PseudoServer.
    """"""

    def __init__(self, uplink, name, internal=False, desc=""(None given)""):
        self.uplink = uplink
        self.users = set()
        self.internal = internal
        self.name = name.lower()
        self.desc = desc

    def __repr__(self):
        return 'IrcServer(%s)' % self.name

class IrcChannel():
    """"""PyLink IRC channel class.""""""
    def __init__(self, name=None):
        # Initialize variables, such as the topic, user list, TS, who's opped, etc.
        self.users = set()
        self.modes = set()
        self.topic = ''
        self.ts = int(time.time())
        self.prefixmodes = {'op': set(), 'halfop': set(), 'voice': set(),
                            'owner': set(), 'admin': set()}

        # Determines whether a topic has been set here or not. Protocol modules
        # should set this.
        self.topicset = False

        # Saves the channel name (may be useful to plugins, etc.)
        self.name = name

    def __repr__(self):
        return 'IrcChannel(%s)' % self.name

    def removeuser(self, target):
        """"""Removes a user from a channel.""""""
        for s in self.prefixmodes.values():
            s.discard(target)
        self.users.discard(target)

    def deepcopy(self):
        """"""Returns a deep copy of the channel object.""""""
        return deepcopy(self)

    def isVoice(self, uid):
        """"""Returns whether the given user is voice in the channel.""""""
        return uid in self.prefixmodes['voice']

    def isHalfop(self, uid):
        """"""Returns whether the given user is halfop in the channel.""""""
        return uid in self.prefixmodes['halfop']

    def isOp(self, uid):
        """"""Returns whether the given user is op in the channel.""""""
        return uid in self.prefixmodes['op']

    def isAdmin(self, uid):
        """"""Returns whether the given user is admin (&) in the channel.""""""
        return uid in self.prefixmodes['admin']

    def isOwner(self, uid):
        """"""Returns whether the given user is owner (~) in the channel.""""""
        return uid in self.prefixmodes['owner']

    def isVoicePlus(self, uid):
        """"""Returns whether the given user is voice or above in the channel.""""""
        # If the user has any prefix mode, it has to be voice or greater.
        return bool(self.getPrefixModes(uid))

    def isHalfopPlus(self, uid):
        """"""Returns whether the given user is halfop or above in the channel.""""""
        for mode in ('halfop', 'op', 'admin', 'owner'):
            if uid in self.prefixmodes[mode]:
                return True
        return False

    def isOpPlus(self, uid):
        """"""Returns whether the given user is op or above in the channel.""""""
        for mode in ('op', 'admin', 'owner'):
            if uid in self.prefixmodes[mode]:
                return True
        return False

    @staticmethod
    def sortPrefixes(key):
        """"""
        Implements a sorted()-compatible sorter for prefix modes, giving each one a
        numeric value.
        """"""
        values = {'owner': 100, 'admin': 10, 'op': 5, 'halfop': 4, 'voice': 3}

        # Default to highest value (1000) for unknown modes, should we choose to
        # support them.
        return values.get(key, 1000)

    def getPrefixModes(self, uid, prefixmodes=None):
        """"""Returns a list of all named prefix modes the given user has in the channel.

        Optionally, a prefixmodes argument can be given to look at an earlier state of
        the channel's prefix modes mapping, e.g. for checking the op status of a mode
        setter before their modes are processed and added to the channel state.
        """"""

        if uid not in self.users:
            raise KeyError(""User %s does not exist or is not in the channel"" % uid)

        result = []
        prefixmodes = prefixmodes or self.prefixmodes

        for mode, modelist in prefixmodes.items():
            if uid in modelist:
                result.append(mode)

        return sorted(result, key=self.sortPrefixes)

class Protocol():
    """"""Base Protocol module class for PyLink.""""""
    def __init__(self, irc):
        self.irc = irc
        self.casemapping = 'rfc1459'
        self.hook_map = {}

        # Lock for updateTS to make sure only one thread can change the channel TS at one time.
        self.ts_lock = threading.Lock()

        # Lists required conf keys for the server block.
        self.conf_keys = {'ip', 'port', 'hostname', 'sid', 'sidrange', 'protocol', 'sendpass',
                          'recvpass'}

        # Defines a set of PyLink protocol capabilities
        self.protocol_caps = set()

    def validateServerConf(self):
        """"""Validates that the server block given contains the required keys.""""""
        for k in self.conf_keys:
            assert k in self.irc.serverdata, ""Missing option %r in server block for network %s."" % (k, self.irc.name)

        port = self.irc.serverdata['port']
        assert type(port) == int and 0 < port < 65535, ""Invalid port %r for network %s"" % (port, self.irc.name)

    @staticmethod
    def parseArgs(args):
        """"""
        Parses a string or list of of RFC1459-style arguments, where "":"" may
        be used for multi-word arguments that last until the end of a line.
        """"""
        if isinstance(args, str):
            args = args.split(' ')

        real_args = []
        for idx, arg in enumerate(args):
            if arg.startswith(':') and idx != 0:
                # "":"" is used to begin multi-word arguments that last until the end of the message.
                # Use list splicing here to join them into one argument, and then add it to our list of args.
                joined_arg = ' '.join(args[idx:])[1:]  # Cut off the leading : as well
                real_args.append(joined_arg)
                break
            real_args.append(arg)

        return real_args

    def hasCap(self, capab):
        """"""
        Returns whether this protocol module instance has the requested capability.
        """"""
        return capab.lower() in self.protocol_caps

    def removeClient(self, numeric):
        """"""Internal function to remove a client from our internal state.""""""
        for c, v in self.irc.channels.copy().items():
            v.removeuser(numeric)
            # Clear empty non-permanent channels.
            if not (self.irc.channels[c].users or ((self.irc.cmodes.get('permanent'), None) in self.irc.channels[c].modes)):
                del self.irc.channels[c]
            assert numeric not in v.users, ""IrcChannel's removeuser() is broken!""

        sid = self.irc.getServer(numeric)
        log.debug('Removing client %s from self.irc.users', numeric)
        del self.irc.users[numeric]
        log.debug('Removing client %s from self.irc.servers[%s].users', numeric, sid)
        self.irc.servers[sid].users.discard(numeric)

    def updateTS(self, sender, channel, their_ts, modes=[]):
        """"""
        Merges modes of a channel given the remote TS and a list of modes.
        """"""

        # Okay, so the situation is that we have 6 possible TS/sender combinations:

        #                       | our TS lower | TS equal | their TS lower
        # mode origin is us     |   OVERWRITE  |   MERGE  |    IGNORE
        # mode origin is uplink |    IGNORE    |   MERGE  |   OVERWRITE

        def _clear():
            log.debug(""(%s) Clearing local modes from channel %s due to TS change"", self.irc.name,
                      channel)
            self.irc.channels[channel].modes.clear()
            for p in self.irc.channels[channel].prefixmodes.values():
                for user in p.copy():
                    if not self.irc.isInternalClient(user):
                        p.discard(user)

        def _apply():
            if modes:
                log.debug(""(%s) Applying modes on channel %s (TS ok)"", self.irc.name,
                          channel)
                self.irc.applyModes(channel, modes)

        # Use a lock so only one thread can change a channel's TS at once: this prevents race
        # conditions from desyncing the channel list.
        with self.ts_lock:
            our_ts = self.irc.channels[channel].ts
            assert type(our_ts) == int, ""Wrong type for our_ts (expected int, got %s)"" % type(our_ts)
            assert type(their_ts) == int, ""Wrong type for their_ts (expected int, got %s)"" % type(their_ts)

            # Check if we're the mode sender based on the UID / SID given.
            our_mode = self.irc.isInternalClient(sender) or self.irc.isInternalServer(sender)

            log.debug(""(%s/%s) our_ts: %s; their_ts: %s; is the mode origin us? %s"", self.irc.name,
                      channel, our_ts, their_ts, our_mode)

            if their_ts == our_ts:
                log.debug(""(%s/%s) remote TS of %s is equal to our %s; mode query %s"",
                          self.irc.name, channel, their_ts, our_ts, modes)
                # Their TS is equal to ours. Merge modes.
                _apply()

            elif (their_ts < our_ts):
                if their_ts < 750000:
                    log.warning('(%s) Possible desync? Not setting bogus TS %s on channel %s', self.irc.name, their_ts, channel)
                else:
                    log.debug('(%s) Resetting channel TS of %s from %s to %s (remote has lower TS)',
                              self.irc.name, channel, our_ts, their_ts)
                    self.irc.channels[channel].ts = their_ts

                # Remote TS was lower and we're receiving modes. Clear the modelist and apply theirs.

                _clear()
                _apply()

    def _getSid(self, sname):
        """"""Returns the SID of a server with the given name, if present.""""""
        name = sname.lower()
        for k, v in self.irc.servers.items():
            if v.name.lower() == name:
                return k
        else:
            return sname  # Fall back to given text instead of None

    def _getUid(self, target):
        """"""Converts a nick argument to its matching UID. This differs from irc.nickToUid()
        in that it returns the original text instead of None, if no matching nick is found.""""""
        target = self.irc.nickToUid(target) or target
        return target

    @classmethod
    def parsePrefixedArgs(cls, args):
        """"""Similar to parseArgs(), but stripping leading colons from the first argument
        of a line (usually the sender field).""""""
        args = cls.parseArgs(args)
        args[0] = args[0].split(':', 1)[1]
        return args

    def _squit(self, numeric, command, args):
        """"""Handles incoming SQUITs.""""""

        split_server = self._getSid(args[0])

        # Normally we'd only need to check for our SID as the SQUIT target, but Nefarious
        # actually uses the uplink server as the SQUIT target.
        # <- ABAAE SQ nefarious.midnight.vpn 0 :test
        if split_server in (self.irc.sid, self.irc.uplink):
            raise ProtocolError('SQUIT received: (reason: %s)' % args[-1])

        affected_users = []
        affected_nicks = defaultdict(list)
        log.debug('(%s) Splitting server %s (reason: %s)', self.irc.name, split_server, args[-1])

        if split_server not in self.irc.servers:
            log.warning(""(%s) Tried to split a server (%s) that didn't exist!"", self.irc.name, split_server)
            return

        # Prevent RuntimeError: dictionary changed size during iteration
        old_servers = self.irc.servers.copy()
        old_channels = self.irc.channels.copy()

        # Cycle through our list of servers. If any server's uplink is the one that is being SQUIT,
        # remove them and all their users too.
        for sid, data in old_servers.items():
            if data.uplink == split_server:
                log.debug('Server %s also hosts server %s, removing those users too...', split_server, sid)
                # Recursively run SQUIT on any other hubs this server may have been connected to.
                args = self._squit(sid, 'SQUIT', [sid, ""0"",
                                   ""PyLink: Automatically splitting leaf servers of %s"" % sid])
                affected_users += args['users']

        for user in self.irc.servers[split_server].users.copy():
            affected_users.append(user)
            nick = self.irc.users[user].nick

            # Nicks affected is channel specific for SQUIT:. This makes Clientbot's SQUIT relaying
            # much easier to implement.
            for name, cdata in old_channels.items():
                if user in cdata.users:
                    affected_nicks[name].append(nick)

            log.debug('Removing client %s (%s)', user, nick)
            self.removeClient(user)

        serverdata = self.irc.servers[split_server]
        sname = serverdata.name
        uplink = serverdata.uplink

        del self.irc.servers[split_server]
        log.debug('(%s) Netsplit affected users: %s', self.irc.name, affected_users)

        return {'target': split_server, 'users': affected_users, 'name': sname,
                'uplink': uplink, 'nicks': affected_nicks, 'serverdata': serverdata,
                'channeldata': old_channels}

    @staticmethod
    def parseCapabilities(args, fallback=''):
        """"""
        Parses a string of capabilities in the 005 / RPL_ISUPPORT format.
        """"""

        if type(args) == str:
            args = args.split(' ')

        caps = {}
        for cap in args:
            try:
                # Try to split it as a KEY=VALUE pair.
                key, value = cap.split('=', 1)
            except ValueError:
                key = cap
                value = fallback
            caps[key] = value

        return caps

    @staticmethod
    def parsePrefixes(args):
        """"""
        Separates prefixes field like ""(qaohv)~&@%+"" into a dict mapping mode characters to mode
        prefixes.
        """"""
        prefixsearch = re.search(r'\(([A-Za-z]+)\)(.*)', args)
        return dict(zip(prefixsearch.group(1), prefixsearch.group(2)))

    def handle_error(self, numeric, command, args):
        """"""Handles ERROR messages - these mean that our uplink has disconnected us!""""""
        raise ProtocolError('Received an ERROR, disconnecting!')
/n/n/nplugins/networks.py/n/n""""""Networks plugin - allows you to manipulate connections to various configured networks.""""""
import importlib
import types

from pylinkirc import utils, world, conf, classes
from pylinkirc.log import log
from pylinkirc.coremods import control, permissions

@utils.add_cmd
def disconnect(irc, source, args):
    """"""<network>

    Disconnects the network <network>. When all networks are disconnected, PyLink will automatically exit.

    To reconnect a network disconnected using this command, use REHASH to reload the networks list.""""""
    permissions.checkPermissions(irc, source, ['networks.disconnect'])
    try:
        netname = args[0]
        network = world.networkobjects[netname]
    except IndexError:  # No argument given.
        irc.error('Not enough arguments (needs 1: network name (case sensitive)).')
        return
    except KeyError:  # Unknown network.
        irc.error('No such network ""%s"" (case sensitive).' % netname)
        return
    irc.reply(""Done. If you want to reconnect this network, use the 'rehash' command."")

    control.remove_network(network)

@utils.add_cmd
def autoconnect(irc, source, args):
    """"""<network> <seconds>

    Sets the autoconnect time for <network> to <seconds>.
    You can disable autoconnect for a network by setting <seconds> to a negative value.""""""
    permissions.checkPermissions(irc, source, ['networks.autoconnect'])
    try:
        netname = args[0]
        seconds = float(args[1])
        network = world.networkobjects[netname]
    except IndexError:  # Arguments not given.
        irc.error('Not enough arguments (needs 2: network name (case sensitive), autoconnect time (in seconds)).')
        return
    except KeyError:  # Unknown network.
        irc.error('No such network ""%s"" (case sensitive).' % netname)
        return
    except ValueError:
        irc.error('Invalid argument ""%s"" for <seconds>.' % seconds)
        return
    network.serverdata['autoconnect'] = seconds
    irc.reply(""Done."")

remote_parser = utils.IRCParser()
remote_parser.add_argument('network')
remote_parser.add_argument('--service', type=str, default='pylink')
remote_parser.add_argument('command', nargs=utils.IRCParser.REMAINDER)
@utils.add_cmd
def remote(irc, source, args):
    """"""<network> [--service <service name>] <command>

    Runs <command> on the remote network <network>. Plugin responses sent using irc.reply() are
    supported and returned here, but others are dropped due to protocol limitations.""""""
    permissions.checkPermissions(irc, source, ['networks.remote'])

    args = remote_parser.parse_args(args)
    netname = args.network

    if netname == irc.name:
        # This would actually throw _remote_reply() into a loop, so check for it here...
        # XXX: properly fix this.
        irc.error(""Cannot remote-send a command to the local network; use a normal command!"")
        return

    try:
        remoteirc = world.networkobjects[netname]
    except KeyError:  # Unknown network.
        irc.error('No such network ""%s"" (case sensitive).' % netname)
        return

    if args.service not in world.services:
        irc.error('Unknown service %r.' % args.service)
        return

    # Force remoteirc.called_in to something private in order to prevent
    # accidental information leakage from replies.
    remoteirc.called_in = remoteirc.called_by = remoteirc.pseudoclient.uid

    # Set the identification override to the caller's account.
    remoteirc.pseudoclient.account = irc.users[source].account

    def _remote_reply(placeholder_self, text, **kwargs):
        """"""
        reply() rerouter for the 'remote' command.
        """"""
        assert irc.name != placeholder_self.name, \
            ""Refusing to route reply back to the same "" \
            ""network, as this would cause a recursive loop""
        log.debug('(%s) networks.remote: re-routing reply %r from network %s', irc.name,
                  text, placeholder_self.name)

        # Override the source option to make sure the source is valid on the local network.
        if 'source' in kwargs:
            del kwargs['source']
        irc.reply(text, source=irc.pseudoclient.uid, **kwargs)

    old_reply = remoteirc._reply

    with remoteirc.reply_lock:
        try:  # Remotely call the command (use the PyLink client as a dummy user).
            # Override the remote irc.reply() to send replies HERE.
            log.debug('(%s) networks.remote: overriding reply() of IRC object %s', irc.name, netname)
            remoteirc._reply = types.MethodType(_remote_reply, remoteirc)
            world.services[args.service].call_cmd(remoteirc, remoteirc.pseudoclient.uid,
                                                  ' '.join(args.command))
        finally:
            # Restore the original remoteirc.reply()
            log.debug('(%s) networks.remote: restoring reply() of IRC object %s', irc.name, netname)
            remoteirc._reply = old_reply
            # Remove the identification override after we finish.
            remoteirc.pseudoclient.account = ''

@utils.add_cmd
def reloadproto(irc, source, args):
    """"""<protocol module name>

    Reloads the given protocol module without restart. You will have to manually disconnect and reconnect any network using the module for changes to apply.""""""
    permissions.checkPermissions(irc, source, ['networks.reloadproto'])
    try:
        name = args[0]
    except IndexError:
        irc.error('Not enough arguments (needs 1: protocol module name)')
        return

    proto = utils.getProtocolModule(name)
    importlib.reload(proto)

    irc.reply(""Done. You will have to manually disconnect and reconnect any network using the %r module for changes to apply."" % name)
/n/n/n",0
77,77,9d9b01839cf3639e59d29c27e70688bdbf44db96,"/plugins/networks.py/n/n""""""Networks plugin - allows you to manipulate connections to various configured networks.""""""
import importlib
import types

from pylinkirc import utils, world, conf, classes
from pylinkirc.log import log
from pylinkirc.coremods import control, permissions

@utils.add_cmd
def disconnect(irc, source, args):
    """"""<network>

    Disconnects the network <network>. When all networks are disconnected, PyLink will automatically exit.

    To reconnect a network disconnected using this command, use REHASH to reload the networks list.""""""
    permissions.checkPermissions(irc, source, ['networks.disconnect'])
    try:
        netname = args[0]
        network = world.networkobjects[netname]
    except IndexError:  # No argument given.
        irc.error('Not enough arguments (needs 1: network name (case sensitive)).')
        return
    except KeyError:  # Unknown network.
        irc.error('No such network ""%s"" (case sensitive).' % netname)
        return
    irc.reply(""Done. If you want to reconnect this network, use the 'rehash' command."")

    control.remove_network(network)

@utils.add_cmd
def autoconnect(irc, source, args):
    """"""<network> <seconds>

    Sets the autoconnect time for <network> to <seconds>.
    You can disable autoconnect for a network by setting <seconds> to a negative value.""""""
    permissions.checkPermissions(irc, source, ['networks.autoconnect'])
    try:
        netname = args[0]
        seconds = float(args[1])
        network = world.networkobjects[netname]
    except IndexError:  # Arguments not given.
        irc.error('Not enough arguments (needs 2: network name (case sensitive), autoconnect time (in seconds)).')
        return
    except KeyError:  # Unknown network.
        irc.error('No such network ""%s"" (case sensitive).' % netname)
        return
    except ValueError:
        irc.error('Invalid argument ""%s"" for <seconds>.' % seconds)
        return
    network.serverdata['autoconnect'] = seconds
    irc.reply(""Done."")

remote_parser = utils.IRCParser()
remote_parser.add_argument('network')
remote_parser.add_argument('--service', type=str, default='pylink')
remote_parser.add_argument('command', nargs=utils.IRCParser.REMAINDER)
@utils.add_cmd
def remote(irc, source, args):
    """"""<network> [--service <service name>] <command>

    Runs <command> on the remote network <network>. Plugin responses sent using irc.reply() are
    supported and returned here, but others are dropped due to protocol limitations.""""""
    permissions.checkPermissions(irc, source, ['networks.remote'])

    args = remote_parser.parse_args(args)
    netname = args.network

    if netname == irc.name:
        # This would actually throw _remote_reply() into a loop, so check for it here...
        # XXX: properly fix this.
        irc.error(""Cannot remote-send a command to the local network; use a normal command!"")
        return

    try:
        remoteirc = world.networkobjects[netname]
    except KeyError:  # Unknown network.
        irc.error('No such network ""%s"" (case sensitive).' % netname)
        return

    if args.service not in world.services:
        irc.error('Unknown service %r.' % args.service)
        return

    # Force remoteirc.called_in to something private in order to prevent
    # accidental information leakage from replies.
    remoteirc.called_in = remoteirc.called_by = remoteirc.pseudoclient.uid

    # Set the identification override to the caller's account.
    remoteirc.pseudoclient.account = irc.users[source].account

    def _remote_reply(placeholder_self, text, **kwargs):
        """"""
        reply() rerouter for the 'remote' command.
        """"""
        assert irc.name != placeholder_self.name, \
            ""Refusing to route reply back to the same "" \
            ""network, as this would cause a recursive loop""
        log.debug('(%s) networks.remote: re-routing reply %r from network %s', irc.name,
                  text, placeholder_self.name)

        # Override the source option to make sure the source is valid on the local network.
        if 'source' in kwargs:
            del kwargs['source']
        irc.reply(text, source=irc.pseudoclient.uid, **kwargs)

    old_reply = remoteirc.reply

    with remoteirc.reply_lock:
        try:  # Remotely call the command (use the PyLink client as a dummy user).
            # Override the remote irc.reply() to send replies HERE.
            log.debug('(%s) networks.remote: overriding reply() of IRC object %s', irc.name, netname)
            remoteirc.reply = types.MethodType(_remote_reply, remoteirc)
            world.services[args.service].call_cmd(remoteirc, remoteirc.pseudoclient.uid,
                                                  ' '.join(args.command))
        finally:
            # Restore the original remoteirc.reply()
            log.debug('(%s) networks.remote: restoring reply() of IRC object %s', irc.name, netname)
            remoteirc.reply = old_reply
            # Remove the identification override after we finish.
            remoteirc.pseudoclient.account = ''

@utils.add_cmd
def reloadproto(irc, source, args):
    """"""<protocol module name>

    Reloads the given protocol module without restart. You will have to manually disconnect and reconnect any network using the module for changes to apply.""""""
    permissions.checkPermissions(irc, source, ['networks.reloadproto'])
    try:
        name = args[0]
    except IndexError:
        irc.error('Not enough arguments (needs 1: protocol module name)')
        return

    proto = utils.getProtocolModule(name)
    importlib.reload(proto)

    irc.reply(""Done. You will have to manually disconnect and reconnect any network using the %r module for changes to apply."" % name)
/n/n/n",1
