,Unnamed: 0,id,code,label
188,188,ef6a4d5639653ecfe27fd2335752fc98e7352075,"gfui/backends/Timescaledb/timescaledb.py/n/nfrom gfui.backends.default import Backend
import psycopg2
from gfui.chartgraph import Graph, Table
import re
import ipaddress
import os

class Timescaledb_backend(Backend):
    def __init__(self, OPTIONS):
        super().__init__()
        self.required_opts = ['SQL_SERVER', 'SQL_USERNAME', 'SQL_DB']
        self.parse_options(OPTIONS)
        self.columns = {}

        pw = os.environ.get(""SQL_PASSWORD"")
        if not pw:
            pw = self.OPTIONS['SQL_PASSWORD']

        self.db = psycopg2.connect(
            ""dbname={0} user={1} password={2} host={3}"".format(
                self.OPTIONS['SQL_DB'],
                self.OPTIONS['SQL_USERNAME'],
                pw,
                self.OPTIONS['SQL_SERVER']
            )
        )

        self.schema = Schema()

        self.filters = []

    def get_columns(self):
        return self.schema.get_columns()

    def add_filter(self, op, value):
        self.schema.add_filter(value, op)

    def get_int_columns(self):
        return self.schema.get_int_columns()

    def flow_table(self, limit=10):
        db = self.db
        self.schema.limit = limit
        FLOWS = self.schema.flows()

        cursor = self.schema.query(db, FLOWS)
        r = cursor.fetchall()
        t = Table()
        t = t.table_from_rows(r, self.schema.column_order)
        return t

    def topn_sum_graph(self, field, sum_by, limit=10):
        db = self.db
        self.schema.limit = limit
        FLOWS_PER_IP = self.schema.topn_sum(field, sum_by)

        cursor = db.cursor()
        cursor.execute(FLOWS_PER_IP)
        r = cursor.fetchall()
        g = Graph()
        g.name = ""TopN {0}"".format(field)
        g.set_headers([
            field,
            ""Total""
        ])
        g.graph_from_rows(r, 0)
        return g

class Column:
    """"""
    Column

    Column handling class.
    Governs how query strings are built and helper functons for returned data.
    """"""
    def __init__(self, name, display_name=None):
        self.name = name
        self.display_name = display_name
        self.type = 'text'
        self.filter_string = None

    def get_display_name(self):
        return self.display_name

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        if self.filter_string:
            self.filter_string = self.filter_string + ""AND {2} {0} \""{1}\"""".format(op, value, self.name)
        else:
            self.filter_string = ""{2} {0} \""{1}\"""".format(op, value, self.name)

class IP4Column(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = ""ip""

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        s = value.split(""/"")
        if len(s) > 1:
            self.filter_string = ""({0} << '{1}'"".format(self.name, value)
        else:
            self.filter_string = ""{0} = '{1}'"".format(self.name, value)

        return self.filter_string

class IP6Column(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = ""ip6""

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        s = value.split(""/"")
        if len(s) > 1:
            ip = ipaddress.ip_network(value, strict=False)
            start_ip = ip.network_address
            end_ip = ip.broadcast_address
            self.filter_string = ""({0} > {1} AND {0} < {2})"".format(self.name, int(start_ip), int(end_ip))
        else:
            ip = ipaddress.ip_address(value)
            self.filter_string = ""{0} = {1}"".format(self.name, int(ip))

        return self.filter_string

class IntColumn(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = 'int'

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        self.filter_string = ""{0} = {1}"".format(self.name, value)
        return self.filter_string

class PortColumn(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = 'port'

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        self.filter_string = ""{0} = %s"".format(self.name, value)
        return self.filter_string

class Coalesce:
    def __init__(self, name, columns, filter_func, display_name):
        """"""
        Coalesce
        Select from a list of columns whatever is not null
        :param columns (List): Column objects
        """"""
        self.name = name
        self.columns = columns
        # We assume that the passed columns are of roughly the same type
        self.type = columns[0].type
        self.column_selects = []
        for c in columns:
            self.column_selects.append(c.select())

        self.filter_string = None
        self.filter_func = filter_func
        self.display_name = display_name

    def get_display_name(self):
        return self.display_name

    def select(self):
        fields = "", "".join(self.column_selects)
        return ""COALESCE({0}) AS {1}"".format(fields, self.name)

    def filter(self, value, op=None):
        self.filter_string = self.filter_func(value, op)

class Schema:
    """"""
    Schema

    Defines the backend schema
    Changes to the backend (naming, etc.) should be reflected here.
    """"""
    def __init__(self):
        # Default
        self.limit = 10

        self.column_order = [
            ""last_switched"",
            ""src_ip"",
            ""src_port"",
            ""dst_ip"",
            ""dst_port"",
            ""in_bytes"",
        ]
        src_ip_col = IP4Column(""src_ip"", ""Source IP"")
        src_ipv6_col = IP6Column(""src_ipv6"", ""Source IPv6"")
        dst_ip_col = IP4Column(""dst_ip"", ""Destination IP"")
        dst_ipv6_col = IP6Column(""dst_ipv6"", ""DestinationIPv6"")

        self.filter_val_list = []

        # Columns
        self.columns = {
            ""last_switched"": Column(""last_switched"", ""Last Switched""),
            ""src_ip"": Coalesce(""src_c_ip"", [src_ip_col, src_ipv6_col], src_ip_col.filter, ""Source IP""),
            ""src_port"": PortColumn(""src_port"", ""Source Port""),
            ""dst_ip"": Coalesce(""dst_c_ip"", [dst_ip_col, dst_ipv6_col], dst_ip_col.filter, ""Destination IP""),
            ""dst_port"": PortColumn(""dst_port"", ""Destination Port""),
            ""in_bytes"": IntColumn(""in_bytes"", ""Input bytes""),
            ""in_pkts"": IntColumn(""in_pkts"", ""Input Packets""),
        }

        # Supported queries
        self.QUERIES = {
            ""TOPN"": self.topn
        }

        self.filters = []

        self.filter_map = {
            ""(\d+\-\d+\-\d+)"": ""last_switched"",
            ""src (\d+\.\d+\.\d+\.\d+\/\d+|\d+\.\d+\.\d+\.\d+)"": ""src_ip"",
            ""dst (\d+\.\d+\.\d+\.\d+\/\d+|\d+\.\d+\.\d+\.\d+)"": ""dst_ip"",
            ""src ([0-9]+)($|\s)"": ""src_port"",
            ""dst ([0-9]+)($|\s)"": ""dst_port"",
        }

    def add_filter(self, value, op=""=""):
        for regex, column in self.filter_map.items():
            if re.search(regex, value):
                m = re.search(regex, value)
                v = m.group(1)
                self.columns[column].filter(v, op)
                self.filter_val_list.append(v)

    def build_filter_string(self):
        s = 'WHERE '
        l = []
        for c in self.columns.values():
            if c.filter_string:
                l.append(c.filter_string)

        if len(l) > 0:
            return s + "" AND "".join(l)
        else:
            return ''

    def get_columns(self):
        result = {}
        for col_name, col in self.columns.items():
            result[col_name] = col.get_display_name()

        return result

    def get_int_columns(self):
        result = {}
        for col_name, col in self.columns.items():
            if col.type is ""int"":
                result[col_name] = col.get_display_name()

        return result

    def topn(self, column):
        count = ""last_switched""
        q = """"""
        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC
        """""".format(self.columns[column].select(), count, self.build_filter_string())
        return self.query_boilerplate(q)

    def topn_sum(self, column, sum_by):
        q = """"""
        SELECT {0}, sum({1}) AS c FROM goflow_records {2} GROUP BY {3} ORDER BY c DESC
        """""".format(self.columns[column].select(), sum_by, self.build_filter_string(), self.columns[column].name)
        return self.query_boilerplate(q)

    def flows(self):
        c = []
        for col in self.column_order:
            c.append(self.columns[col].select())
        q = """"""
        SELECT {1} FROM goflow_records {0} ORDER BY last_switched DESC
        """""".format(self.build_filter_string(), "", "".join(c))
        return self.query_boilerplate(q)

    def query_boilerplate(self, q):
        q = q + """"""LIMIT {0}"""""".format(self.limit)
        return q

    def query(self, db, q):
        cursor = db.cursor()
        cursor.execute(q, self.filter_val_list)
        return cursor/n/n/n",0
189,189,ef6a4d5639653ecfe27fd2335752fc98e7352075,"/gfui/backends/Timescaledb/timescaledb.py/n/nfrom gfui.backends.default import Backend
import psycopg2
from gfui.chartgraph import Graph, Table
import re
import ipaddress
import os

class Timescaledb_backend(Backend):
    def __init__(self, OPTIONS):
        super().__init__()
        self.required_opts = ['SQL_SERVER', 'SQL_USERNAME', 'SQL_DB']
        self.parse_options(OPTIONS)
        self.columns = {}

        pw = os.environ.get(""SQL_PASSWORD"")
        if not pw:
            pw = self.OPTIONS['SQL_PASSWORD']

        self.db = psycopg2.connect(
            ""dbname={0} user={1} password={2} host={3}"".format(
                self.OPTIONS['SQL_DB'],
                self.OPTIONS['SQL_USERNAME'],
                pw,
                self.OPTIONS['SQL_SERVER']
            )
        )

        self.schema = Schema()

        self.filters = []

    def get_columns(self):
        return self.schema.get_columns()

    def add_filter(self, op, value):
        self.schema.add_filter(value, op)

    def get_int_columns(self):
        return self.schema.get_int_columns()

    def flow_table(self, limit=10):
        db = self.db
        self.schema.limit = limit
        FLOWS = self.schema.flows()

        cursor = db.cursor()
        cursor.execute(FLOWS)
        r = cursor.fetchall()
        t = Table()
        t = t.table_from_rows(r, self.schema.column_order)
        return t

    def topn_sum_graph(self, field, sum_by, limit=10):
        db = self.db
        self.schema.limit = limit
        FLOWS_PER_IP = self.schema.topn_sum(field, sum_by)

        cursor = db.cursor()
        cursor.execute(FLOWS_PER_IP)
        r = cursor.fetchall()
        g = Graph()
        g.name = ""TopN {0}"".format(field)
        g.set_headers([
            field,
            ""Total""
        ])
        g.graph_from_rows(r, 0)
        return g

class Column:
    """"""
    Column

    Column handling class.
    Governs how query strings are built and helper functons for returned data.
    """"""
    def __init__(self, name, display_name=None):
        self.name = name
        self.display_name = display_name
        self.type = 'text'
        self.filter_string = None

    def get_display_name(self):
        return self.display_name

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        if self.filter_string:
            self.filter_string = self.filter_string + ""AND {2} {0} \""{1}\"""".format(op, value, self.name)
        else:
            self.filter_string = ""{2} {0} \""{1}\"""".format(op, value, self.name)

class IP4Column(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = ""ip""

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        s = value.split(""/"")
        if len(s) > 1:
            self.filter_string = ""({0} << '{1}'"".format(self.name, value)
        else:
            self.filter_string = ""{0} = '{1}'"".format(self.name, value)

        return self.filter_string

class IP6Column(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = ""ip6""

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        s = value.split(""/"")
        if len(s) > 1:
            ip = ipaddress.ip_network(value, strict=False)
            start_ip = ip.network_address
            end_ip = ip.broadcast_address
            self.filter_string = ""({0} > {1} AND {0} < {2})"".format(self.name, int(start_ip), int(end_ip))
        else:
            ip = ipaddress.ip_address(value)
            self.filter_string = ""{0} = {1}"".format(self.name, int(ip))

        return self.filter_string

class IntColumn(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = 'int'

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        self.filter_string = ""{0} = {1}"".format(self.name, value)
        return self.filter_string

class PortColumn(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = 'port'

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        self.filter_string = ""{0} = {1}"".format(self.name, value)
        return self.filter_string

class Coalesce:
    def __init__(self, name, columns, filter_func, display_name):
        """"""
        Coalesce
        Select from a list of columns whatever is not null
        :param columns (List): Column objects
        """"""
        self.name = name
        self.columns = columns
        # We assume that the passed columns are of roughly the same type
        self.type = columns[0].type
        self.column_selects = []
        for c in columns:
            self.column_selects.append(c.select())

        self.filter_string = None
        self.filter_func = filter_func
        self.display_name = display_name

    def get_display_name(self):
        return self.display_name

    def select(self):
        fields = "", "".join(self.column_selects)
        return ""COALESCE({0}) AS {1}"".format(fields, self.name)

    def filter(self, value, op=None):
        self.filter_string = self.filter_func(value, op)

class Schema:
    """"""
    Schema

    Defines the backend schema
    Changes to the backend (naming, etc.) should be reflected here.
    """"""
    def __init__(self):
        # Default
        self.limit = 10

        self.column_order = [
            ""last_switched"",
            ""src_ip"",
            ""src_port"",
            ""dst_ip"",
            ""dst_port"",
            ""in_bytes"",
        ]
        src_ip_col = IP4Column(""src_ip"", ""Source IP"")
        src_ipv6_col = IP6Column(""src_ipv6"", ""Source IPv6"")
        dst_ip_col = IP4Column(""dst_ip"", ""Destination IP"")
        dst_ipv6_col = IP6Column(""dst_ipv6"", ""DestinationIPv6"")

        # Filter tuples are filter values
        self.filter_tuples = ()

        # Columns
        self.columns = {
            ""last_switched"": Column(""last_switched"", ""Last Switched""),
            ""src_ip"": Coalesce(""src_c_ip"", [src_ip_col, src_ipv6_col], src_ip_col.filter, ""Source IP""),
            ""src_port"": PortColumn(""src_port"", ""Source Port""),
            ""dst_ip"": Coalesce(""dst_c_ip"", [dst_ip_col, dst_ipv6_col], dst_ip_col.filter, ""Destination IP""),
            ""dst_port"": PortColumn(""dst_port"", ""Destination Port""),
            ""in_bytes"": IntColumn(""in_bytes"", ""Input bytes""),
            ""in_pkts"": IntColumn(""in_pkts"", ""Input Packets""),
        }

        # Supported queries
        self.QUERIES = {
            ""TOPN"": self.topn
        }

        self.filters = []

        self.filter_map = {
            ""(\d+\-\d+\-\d+)"": ""last_switched"",
            ""src (\d+\.\d+\.\d+\.\d+\/\d+|\d+\.\d+\.\d+\.\d+)"": ""src_ip"",
            ""dst (\d+\.\d+\.\d+\.\d+\/\d+|\d+\.\d+\.\d+\.\d+)"": ""dst_ip"",
            ""src ([0-9]+)($|\s)"": ""src_port"",
            ""dst ([0-9]+)($|\s)"": ""dst_port"",
        }

    def add_filter(self, value, op=""=""):
        for regex, column in self.filter_map.items():
            if re.search(regex, value):
                m = re.search(regex, value)
                v = m.group(1)
                self.columns[column].filter(v, op)

    def build_filter_string(self):
        s = 'WHERE '
        l = []
        for c in self.columns.values():
            if c.filter_string:
                l.append(c.filter_string)

        if len(l) > 0:
            return s + "" AND "".join(l)
        else:
            return ''

    def get_columns(self):
        result = {}
        for col_name, col in self.columns.items():
            result[col_name] = col.get_display_name()

        return result

    def get_int_columns(self):
        result = {}
        for col_name, col in self.columns.items():
            if col.type is ""int"":
                result[col_name] = col.get_display_name()

        return result

    def topn(self, column):
        count = ""last_switched""
        q = """"""
        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC
        """""".format(self.columns[column].select(), count, self.build_filter_string())
        return self.query_boilerplate(q)

    def topn_sum(self, column, sum_by):
        q = """"""
        SELECT {0}, sum({1}) AS c FROM goflow_records {2} GROUP BY {3} ORDER BY c DESC
        """""".format(self.columns[column].select(), sum_by, self.build_filter_string(), self.columns[column].name)
        return self.query_boilerplate(q)

    def flows(self):
        c = []
        for col in self.column_order:
            c.append(self.columns[col].select())
        q = """"""
        SELECT {1} FROM goflow_records {0} ORDER BY last_switched DESC
        """""".format(self.build_filter_string(), "", "".join(c))
        return self.query_boilerplate(q)

    def query_boilerplate(self, q):
        q = q + """"""LIMIT {0}"""""".format(self.limit)
        return q

    def query(self, db, q):
        cursor = db.cursor()
        cursor.execute(q, self.filter_tuples)/n/n/n",1
48,48,307587cc00d2290a433bf74bd305aecffcbb05a2,"wins/views/flat_csv.py/n/nimport collections
import csv
import functools
import io
import zipfile
from operator import attrgetter
import mimetypes

from django.conf import settings
from django.core.exceptions import ValidationError
from django.db import connection, models
from django.http import HttpResponse, StreamingHttpResponse
from django.utils.decorators import method_decorator
from django.utils.timezone import now
from django.views.decorators.gzip import gzip_page

from rest_framework import permissions
from rest_framework.views import APIView

from alice.authenticators import IsDataTeamServer
from ..constants import BREAKDOWN_TYPES
from ..models import Advisor, Breakdown, CustomerResponse, Notification, Win
from ..serializers import CustomerResponseSerializer, WinSerializer
from users .models import User


class CSVView(APIView):
    """""" Endpoint returning CSV of all Win data, with foreign keys flattened """"""

    permission_classes = (permissions.IsAdminUser,)
    # cache for speed
    win_fields = WinSerializer().fields
    customerresponse_fields = CustomerResponseSerializer().fields
    IGNORE_FIELDS = ['responded', 'sent', 'country_name', 'updated',
                     'complete', 'type', 'type_display',
                     'export_experience_display', 'location']

    def __init__(self, **kwargs):
        # cache some stuff to make flat CSV. like prefetch but works easily
        # with .values()
        self.users_map = {u.id: u for u in User.objects.all()}
        prefetch_tables = [
            ('advisors', Advisor),
            ('breakdowns', Breakdown),
            ('confirmations', CustomerResponse),
            ('notifications', Notification),
        ]
        self.table_maps = {}
        for table, model in prefetch_tables:
            prefetch_map = collections.defaultdict(list)
            instances = model.objects.all()
            if table == 'notifications':
                instances = instances.filter(type='c').order_by('created')
            for instance in instances:
                prefetch_map[instance.win_id].append(instance)
            self.table_maps[table] = prefetch_map
        super().__init__(**kwargs)

    def _extract_breakdowns(self, win):
        """""" Return list of 10 tuples, 5 for export, 5 for non-export """"""

        breakdowns = self.table_maps['breakdowns'][win['id']]
        retval = []
        for db_val, name in BREAKDOWN_TYPES:

            # get breakdowns of given type sorted by year
            type_breakdowns = [b for b in breakdowns if b.type == db_val]
            type_breakdowns = sorted(type_breakdowns, key=attrgetter('year'))

            # we currently solicit 5 years worth of breakdowns, but historic
            # data may have no input for some years
            for index in range(5):
                try:
                    breakdown = ""{0}: £{1:,}"".format(
                        type_breakdowns[index].year,
                        type_breakdowns[index].value,
                    )
                except IndexError:
                    breakdown = None

                retval.append((
                    ""{0} breakdown {1}"".format(name, index + 1),
                    breakdown,
                ))

        return retval

    def _confirmation(self, win):
        """""" Add fields for confirmation """"""

        if win['id'] in self.table_maps['confirmations']:
            confirmation = self.table_maps['confirmations'][win['id']][0]
        else:
            confirmation = None

        values = [
            ('customer response recieved',
             self._val_to_str(bool(confirmation)))
        ]
        for field_name in self.customerresponse_fields:
            if field_name in ['win']:
                continue

            model_field = self._get_customerresponse_field(field_name)
            if confirmation:
                if model_field.choices:
                    display_fn = getattr(
                        confirmation, ""get_{0}_display"".format(field_name)
                    )
                    value = display_fn()
                else:
                    value = getattr(confirmation, field_name)
            else:
                value = ''

            model_field_name = model_field.verbose_name or model_field.name
            if model_field_name == 'created':
                csv_field_name = 'date response received'
                if value:
                    value = value.date()  # just want date
            else:
                csv_field_name = model_field_name

            values.append((csv_field_name, self._val_to_str(value)))
        return values

    def _get_model_field(self, model, name):
        return next(
            filter(lambda field: field.name == name, model._meta.fields)
        )

    @functools.lru_cache(None)
    def _get_customerresponse_field(self, name):
        """""" Get field specified in CustomerResponse model """"""
        return self._get_model_field(CustomerResponse, name)

    @functools.lru_cache(None)
    def _get_win_field(self, name):
        """""" Get field specified in Win model """"""
        return self._get_model_field(Win, name)

    def _val_to_str(self, val):
        if val is True:
            return 'Yes'
        elif val is False:
            return 'No'
        elif val is None:
            return ''
        else:
            return str(val)

    @functools.lru_cache(None)
    def _choices_dict(self, choices):
        return dict(choices)

    def _get_win_data(self, win):
        """""" Take Win dict, return ordered dict of {name -> value} """"""

        # want consistent ordering so CSVs are always same format
        win_data = collections.OrderedDict()

        # local fields
        for field_name in self.win_fields:
            if field_name in self.IGNORE_FIELDS:
                continue

            model_field = self._get_win_field(field_name)
            if field_name == 'user':
                value = str(self.users_map[win['user_id']])
            elif field_name == 'created':
                value = win[field_name].date()  # don't care about time
            elif field_name == 'cdms_reference':
                # numeric cdms reference numbers should be prefixed with
                # an apostrophe to make excel interpret them as text
                value = win[field_name]
                try:
                    int(value)
                except ValueError:
                    pass
                else:
                    if value.startswith('0'):
                        value = ""'"" + value
            else:
                value = win[field_name]
            # if it is a choicefield, do optimized lookup of the display value
            if model_field.choices and value:
                try:
                    value = self._choices_dict(model_field.choices)[value]
                except KeyError as e:
                    if model_field.attname == 'hvc':
                        value = value
                    else:
                        raise e
            else:
                comma_fields = [
                    'total_expected_export_value',
                    'total_expected_non_export_value',
                    'total_expected_odi_value',
                ]
                if field_name in comma_fields:
                    value = ""£{:,}"".format(value)

            model_field_name = model_field.verbose_name or model_field.name
            win_data[model_field_name] = self._val_to_str(value)

        # remote fields
        win_data['contributing advisors/team'] = (
            ', '.join(map(str, self.table_maps['advisors'][win['id']]))
        )

        # get customer email sent & date
        notifications = self.table_maps['notifications'][win['id']]
        # old Wins do not have notifications
        email_sent = bool(notifications or win['complete'])
        win_data['customer email sent'] = self._val_to_str(email_sent)
        if notifications:
            win_data['customer email date'] = str(
                notifications[0].created.date())
        elif win['complete']:
            win_data['customer email date'] = '[manual]'
        else:
            win_data['customer email date'] = ''

        win_data.update(self._extract_breakdowns(win))
        win_data.update(self._confirmation(win))

        return win_data

    def _make_flat_wins_csv(self, deleted=False):
        """""" Make CSV of all Wins, with non-local data flattened """"""

        if deleted:
            wins = Win.objects.inactive()
        else:
            wins = Win.objects.all()

        if deleted:
            # ignore users should show up in normal CSV
            wins = wins.exclude(
                user__email__in=settings.IGNORE_USERS
            )

        wins = wins.values()

        win_datas = [self._get_win_data(win) for win in wins]
        stringio = io.StringIO()
        stringio.write(u'\ufeff')
        if win_datas:
            csv_writer = csv.DictWriter(stringio, win_datas[0].keys())
            csv_writer.writeheader()
            for win_data in win_datas:
                csv_writer.writerow(win_data)
        return stringio.getvalue()

    def _make_user_csv(self):
        users = User.objects.all()
        user_dicts = [
            {'name': u.name, 'email': u.email, 'joined': u.date_joined}
            for u in users
        ]
        stringio = io.StringIO()
        csv_writer = csv.DictWriter(stringio, user_dicts[0].keys())
        csv_writer.writeheader()
        for user_dict in user_dicts:
            csv_writer.writerow(user_dict)
        return stringio.getvalue()

    def _make_plain_csv(self, table):
        """""" Get CSV of table """"""

        stringio = io.StringIO()
        cursor = connection.cursor()
        cursor.execute(""select * from wins_{};"".format(table))
        csv_writer = csv.writer(stringio)
        header = [i[0] for i in cursor.description]
        csv_writer.writerow(header)
        csv_writer.writerows(cursor)
        return stringio.getvalue()

    def get(self, request, format=None):
        bytesio = io.BytesIO()
        zf = zipfile.ZipFile(bytesio, 'w')
        for table in ['customerresponse', 'notification', 'advisor']:
            csv_str = self._make_plain_csv(table)
            zf.writestr(table + 's.csv', csv_str)
        full_csv_str = self._make_flat_wins_csv()
        zf.writestr('wins_complete.csv', full_csv_str)
        full_csv_del_str = self._make_flat_wins_csv(deleted=True)
        zf.writestr('wins_deleted_complete.csv', full_csv_del_str)
        user_csv_str = self._make_user_csv()
        zf.writestr('users.csv', user_csv_str)
        zf.close()
        return HttpResponse(bytesio.getvalue(), content_type=mimetypes.types_map['.csv'])


class Echo(object):
    """"""An object that implements just the write method of the file-like
    interface.
    """"""

    def write(self, value):
        """"""Write the value by returning it, instead of storing in a buffer.""""""
        return value


@method_decorator(gzip_page, name='dispatch')
class CompleteWinsCSVView(CSVView):

    permission_classes = (IsDataTeamServer,)

    def _make_flat_wins_csv(self, deleted=False):
        """""" Make CSV of all Wins, with non-local data flattened """"""

        if deleted:
            wins = Win.objects.inactive()
        else:
            wins = Win.objects.all()

        if deleted:
            # ignore users should show up in normal CSV
            wins = wins.exclude(
                user__email__in=settings.IGNORE_USERS
            )

        wins = wins.values()

        for win in wins:
            yield self._get_win_data(win)

    def _make_flat_wins_csv_stream(self, win_data_generator):
        stringio = Echo()
        yield stringio.write(u'\ufeff')
        first = next(win_data_generator)
        csv_writer = csv.DictWriter(stringio, first.keys())
        header = dict(zip(first.keys(), first.keys()))
        yield csv_writer.writerow(header)
        yield csv_writer.writerow(first)

        for win_data in win_data_generator:
            yield csv_writer.writerow(win_data)

    def streaming_response(self, filename):
        resp = StreamingHttpResponse(
            self._make_flat_wins_csv_stream(self._make_flat_wins_csv()),
            content_type=mimetypes.types_map['.csv'],
        )
        resp['Content-Disposition'] = f'attachent; filename={filename}'
        return resp

    def get(self, request, format=None):
        return self.streaming_response(f'wins_complete_{now().isoformat()}.csv')


@method_decorator(gzip_page, name='dispatch')
class CurrentFinancialYearWins(CompleteWinsCSVView):

    # permission_classes = (permissions.IsAdminUser,)
    end_date = None

    def _make_flat_wins_csv(self, **kwargs):
        """"""
        Make CSV of all completed Wins till now for this financial year, with non-local data flattened
        remove all rows where:
        1. total expected export value = 0 and total non export value = 0 and total odi value = 0
        2. date created = today (not necessary if this task runs before end of the day for next day download)
        3. customer email sent is False / No
        4. Customer response received is not from this financial year
        Note that this view removes win, notification and customer response entries
        that might have been made inactive in duecourse
        """"""
        with connection.cursor() as cursor:
            if self.end_date:
                cursor.execute(""SELECT id FROM wins_completed_wins_fy where created <= %s"", (self.end_date,))
            else:
                cursor.execute(""SELECT id FROM wins_completed_wins_fy"")
            ids = cursor.fetchall()

        wins = Win.objects.filter(id__in=[id[0] for id in ids]).values()

        for win in wins:
            yield self._get_win_data(win)

    def get(self, request, format=None):
        end_str = request.GET.get(""end"", None)
        if end_str:
            try:
                self.end_date = models.DateField().to_python(end_str)
            except ValidationError:
                self.end_date = None

        return self.streaming_response(f'wins_current_fy_{now().isoformat()}.csv')
/n/n/n",0
49,49,307587cc00d2290a433bf74bd305aecffcbb05a2,"/wins/views/flat_csv.py/n/nimport collections
import csv
import functools
import io
import zipfile
from operator import attrgetter
import mimetypes

from django.conf import settings
from django.core.exceptions import ValidationError
from django.db import connection, models
from django.http import HttpResponse, StreamingHttpResponse
from django.utils.decorators import method_decorator
from django.utils.timezone import now
from django.views.decorators.gzip import gzip_page

from rest_framework import permissions
from rest_framework.views import APIView

from alice.authenticators import IsDataTeamServer
from ..constants import BREAKDOWN_TYPES
from ..models import Advisor, Breakdown, CustomerResponse, Notification, Win
from ..serializers import CustomerResponseSerializer, WinSerializer
from users .models import User


class CSVView(APIView):
    """""" Endpoint returning CSV of all Win data, with foreign keys flattened """"""

    permission_classes = (permissions.IsAdminUser,)
    # cache for speed
    win_fields = WinSerializer().fields
    customerresponse_fields = CustomerResponseSerializer().fields
    IGNORE_FIELDS = ['responded', 'sent', 'country_name', 'updated',
                     'complete', 'type', 'type_display',
                     'export_experience_display', 'location']

    def __init__(self, **kwargs):
        # cache some stuff to make flat CSV. like prefetch but works easily
        # with .values()
        self.users_map = {u.id: u for u in User.objects.all()}
        prefetch_tables = [
            ('advisors', Advisor),
            ('breakdowns', Breakdown),
            ('confirmations', CustomerResponse),
            ('notifications', Notification),
        ]
        self.table_maps = {}
        for table, model in prefetch_tables:
            prefetch_map = collections.defaultdict(list)
            instances = model.objects.all()
            if table == 'notifications':
                instances = instances.filter(type='c').order_by('created')
            for instance in instances:
                prefetch_map[instance.win_id].append(instance)
            self.table_maps[table] = prefetch_map
        super().__init__(**kwargs)

    def _extract_breakdowns(self, win):
        """""" Return list of 10 tuples, 5 for export, 5 for non-export """"""

        breakdowns = self.table_maps['breakdowns'][win['id']]
        retval = []
        for db_val, name in BREAKDOWN_TYPES:

            # get breakdowns of given type sorted by year
            type_breakdowns = [b for b in breakdowns if b.type == db_val]
            type_breakdowns = sorted(type_breakdowns, key=attrgetter('year'))

            # we currently solicit 5 years worth of breakdowns, but historic
            # data may have no input for some years
            for index in range(5):
                try:
                    breakdown = ""{0}: £{1:,}"".format(
                        type_breakdowns[index].year,
                        type_breakdowns[index].value,
                    )
                except IndexError:
                    breakdown = None

                retval.append((
                    ""{0} breakdown {1}"".format(name, index + 1),
                    breakdown,
                ))

        return retval

    def _confirmation(self, win):
        """""" Add fields for confirmation """"""

        if win['id'] in self.table_maps['confirmations']:
            confirmation = self.table_maps['confirmations'][win['id']][0]
        else:
            confirmation = None

        values = [
            ('customer response recieved',
             self._val_to_str(bool(confirmation)))
        ]
        for field_name in self.customerresponse_fields:
            if field_name in ['win']:
                continue

            model_field = self._get_customerresponse_field(field_name)
            if confirmation:
                if model_field.choices:
                    display_fn = getattr(
                        confirmation, ""get_{0}_display"".format(field_name)
                    )
                    value = display_fn()
                else:
                    value = getattr(confirmation, field_name)
            else:
                value = ''

            model_field_name = model_field.verbose_name or model_field.name
            if model_field_name == 'created':
                csv_field_name = 'date response received'
                if value:
                    value = value.date()  # just want date
            else:
                csv_field_name = model_field_name

            values.append((csv_field_name, self._val_to_str(value)))
        return values

    def _get_model_field(self, model, name):
        return next(
            filter(lambda field: field.name == name, model._meta.fields)
        )

    @functools.lru_cache(None)
    def _get_customerresponse_field(self, name):
        """""" Get field specified in CustomerResponse model """"""
        return self._get_model_field(CustomerResponse, name)

    @functools.lru_cache(None)
    def _get_win_field(self, name):
        """""" Get field specified in Win model """"""
        return self._get_model_field(Win, name)

    def _val_to_str(self, val):
        if val is True:
            return 'Yes'
        elif val is False:
            return 'No'
        elif val is None:
            return ''
        else:
            return str(val)

    @functools.lru_cache(None)
    def _choices_dict(self, choices):
        return dict(choices)

    def _get_win_data(self, win):
        """""" Take Win dict, return ordered dict of {name -> value} """"""

        # want consistent ordering so CSVs are always same format
        win_data = collections.OrderedDict()

        # local fields
        for field_name in self.win_fields:
            if field_name in self.IGNORE_FIELDS:
                continue

            model_field = self._get_win_field(field_name)
            if field_name == 'user':
                value = str(self.users_map[win['user_id']])
            elif field_name == 'created':
                value = win[field_name].date()  # don't care about time
            elif field_name == 'cdms_reference':
                # numeric cdms reference numbers should be prefixed with
                # an apostrophe to make excel interpret them as text
                value = win[field_name]
                try:
                    int(value)
                except ValueError:
                    pass
                else:
                    if value.startswith('0'):
                        value = ""'"" + value
            else:
                value = win[field_name]
            # if it is a choicefield, do optimized lookup of the display value
            if model_field.choices and value:
                try:
                    value = self._choices_dict(model_field.choices)[value]
                except KeyError as e:
                    if model_field.attname == 'hvc':
                        value = value
                    else:
                        raise e
            else:
                comma_fields = [
                    'total_expected_export_value',
                    'total_expected_non_export_value',
                    'total_expected_odi_value',
                ]
                if field_name in comma_fields:
                    value = ""£{:,}"".format(value)

            model_field_name = model_field.verbose_name or model_field.name
            win_data[model_field_name] = self._val_to_str(value)

        # remote fields
        win_data['contributing advisors/team'] = (
            ', '.join(map(str, self.table_maps['advisors'][win['id']]))
        )

        # get customer email sent & date
        notifications = self.table_maps['notifications'][win['id']]
        # old Wins do not have notifications
        email_sent = bool(notifications or win['complete'])
        win_data['customer email sent'] = self._val_to_str(email_sent)
        if notifications:
            win_data['customer email date'] = str(
                notifications[0].created.date())
        elif win['complete']:
            win_data['customer email date'] = '[manual]'
        else:
            win_data['customer email date'] = ''

        win_data.update(self._extract_breakdowns(win))
        win_data.update(self._confirmation(win))

        return win_data

    def _make_flat_wins_csv(self, deleted=False):
        """""" Make CSV of all Wins, with non-local data flattened """"""

        if deleted:
            wins = Win.objects.inactive()
        else:
            wins = Win.objects.all()

        if deleted:
            # ignore users should show up in normal CSV
            wins = wins.exclude(
                user__email__in=settings.IGNORE_USERS
            )

        wins = wins.values()

        win_datas = [self._get_win_data(win) for win in wins]
        stringio = io.StringIO()
        stringio.write(u'\ufeff')
        if win_datas:
            csv_writer = csv.DictWriter(stringio, win_datas[0].keys())
            csv_writer.writeheader()
            for win_data in win_datas:
                csv_writer.writerow(win_data)
        return stringio.getvalue()

    def _make_user_csv(self):
        users = User.objects.all()
        user_dicts = [
            {'name': u.name, 'email': u.email, 'joined': u.date_joined}
            for u in users
        ]
        stringio = io.StringIO()
        csv_writer = csv.DictWriter(stringio, user_dicts[0].keys())
        csv_writer.writeheader()
        for user_dict in user_dicts:
            csv_writer.writerow(user_dict)
        return stringio.getvalue()

    def _make_plain_csv(self, table):
        """""" Get CSV of table """"""

        stringio = io.StringIO()
        cursor = connection.cursor()
        cursor.execute(""select * from wins_{};"".format(table))
        csv_writer = csv.writer(stringio)
        header = [i[0] for i in cursor.description]
        csv_writer.writerow(header)
        csv_writer.writerows(cursor)
        return stringio.getvalue()

    def get(self, request, format=None):
        bytesio = io.BytesIO()
        zf = zipfile.ZipFile(bytesio, 'w')
        for table in ['customerresponse', 'notification', 'advisor']:
            csv_str = self._make_plain_csv(table)
            zf.writestr(table + 's.csv', csv_str)
        full_csv_str = self._make_flat_wins_csv()
        zf.writestr('wins_complete.csv', full_csv_str)
        full_csv_del_str = self._make_flat_wins_csv(deleted=True)
        zf.writestr('wins_deleted_complete.csv', full_csv_del_str)
        user_csv_str = self._make_user_csv()
        zf.writestr('users.csv', user_csv_str)
        zf.close()
        return HttpResponse(bytesio.getvalue(), content_type=mimetypes.types_map['.csv'])


class Echo(object):
    """"""An object that implements just the write method of the file-like
    interface.
    """"""

    def write(self, value):
        """"""Write the value by returning it, instead of storing in a buffer.""""""
        return value


@method_decorator(gzip_page, name='dispatch')
class CompleteWinsCSVView(CSVView):

    permission_classes = (IsDataTeamServer,)

    def _make_flat_wins_csv(self, deleted=False):
        """""" Make CSV of all Wins, with non-local data flattened """"""

        if deleted:
            wins = Win.objects.inactive()
        else:
            wins = Win.objects.all()

        if deleted:
            # ignore users should show up in normal CSV
            wins = wins.exclude(
                user__email__in=settings.IGNORE_USERS
            )

        wins = wins.values()

        for win in wins:
            yield self._get_win_data(win)

    def _make_flat_wins_csv_stream(self, win_data_generator):
        stringio = Echo()
        yield stringio.write(u'\ufeff')
        first = next(win_data_generator)
        csv_writer = csv.DictWriter(stringio, first.keys())
        header = dict(zip(first.keys(), first.keys()))
        yield csv_writer.writerow(header)
        yield csv_writer.writerow(first)

        for win_data in win_data_generator:
            yield csv_writer.writerow(win_data)

    def streaming_response(self, filename):
        resp = StreamingHttpResponse(
            self._make_flat_wins_csv_stream(self._make_flat_wins_csv()),
            content_type=mimetypes.types_map['.csv'],
        )
        resp['Content-Disposition'] = f'attachent; filename={filename}'
        return resp

    def get(self, request, format=None):
        return self.streaming_response(f'wins_complete_{now().isoformat()}.csv')


@method_decorator(gzip_page, name='dispatch')
class CurrentFinancialYearWins(CompleteWinsCSVView):

    # permission_classes = (permissions.IsAdminUser,)
    end_date = None

    def _make_flat_wins_csv(self, **kwargs):
        """"""
        Make CSV of all completed Wins till now for this financial year, with non-local data flattened
        remove all rows where:
        1. total expected export value = 0 and total non export value = 0 and total odi value = 0
        2. date created = today (not necessary if this task runs before end of the day for next day download)
        3. customer email sent is False / No
        4. Customer response received is not from this financial year
        Note that this view removes win, notification and customer response entries
        that might have been made inactive in duecourse
        """"""
        sql_str = ""SELECT id FROM wins_completed_wins_fy""
        if self.end_date:
            sql_str = f""{sql_str} where created <= '{self.end_date.strftime('%m-%d-%Y')}'""

        with connection.cursor() as cursor:
            cursor.execute(sql_str)
            ids = cursor.fetchall()

        wins = Win.objects.filter(id__in=[id[0] for id in ids]).values()

        for win in wins:
            yield self._get_win_data(win)

    def get(self, request, format=None):
        end_str = request.GET.get(""end"", None)
        if end_str:
            try:
                self.end_date = models.DateField().to_python(end_str)
            except ValidationError:
                self.end_date = None

        return self.streaming_response(f'wins_current_fy_{now().isoformat()}.csv')
/n/n/n",1
184,184,ad02c932f85c0f4ed6c1e561efc5edc163347806,"app/__init__.py/n/n# Flask create app

# Author: P8ul
# https://github.com/p8ul

from flask import Flask
from .migrations.db import db


def create_app(config_filename):
    app = Flask(__name__)
    app.config.from_object(config_filename)

    with app.app_context():
        pass

    """""" Basic Routes """"""

    # register our blueprints
    configure_blueprints(app)

    # register extensions
    configure_extensions()

    return app


def configure_blueprints(app):
    """"""Configure blueprints .""""""
    from .questions.api.v1.view import question_blueprint
    from .home.views import home_blueprint
    from .auth.api.v1.view import auth_blueprint
    from .answers.api.v1.view import answers_blueprint
    from .votes.api.v1.view import votes_blueprint
    from .comments.api.v1.view import comments_blueprint

    app_blueprints = [
        answers_blueprint,
        question_blueprint,
        auth_blueprint,
        votes_blueprint,
        comments_blueprint,
        home_blueprint
    ]

    for bp in app_blueprints:
        app.register_blueprint(bp)


def configure_extensions():
    db.test()


if __name__ == ""__main__"":
    app = create_app(""config"")
    app.run(debug=True)
/n/n/napp/answers/api/v1/view.py/n/n# APIs Resources

# Author: P8ul
# https://github.com/p8ul

from flask import Blueprint, request, make_response, jsonify, session
from flask.views import MethodView
from ...models import Table
from ....utils import jwt_required

answers_blueprint = Blueprint('answers', __name__)


class CreateAPIView(MethodView):
    """""" Update Instance api resource """"""

    @jwt_required
    def put(self, question_id=None, answer_id=None):
        data = request.get_json(force=True)
        data['question_id'] = question_id
        data['answer_id'] = answer_id
        data['user_id'] = session.get('user_id')

        response = Table(data).update()
        if response == 200:
            response_object = {
                'status': 'success',
                'message': 'Update successful'
            }
            return make_response(jsonify(response_object)), 200
        if response == 302:
            response_object = {
                'status': 'fail',
                'message': 'Please provide correct answer and question id'
            }
            return make_response(jsonify(response_object)), 400
        if response == 203:
            response_object = {
                'status': 'fail',
                'message': 'Unauthorized request.'
            }
            return make_response(jsonify(response_object)), 401

        else:
            response_object = {
                'status': 'fail',
                'message': 'Please provide correct answer and question id'
            }
            return make_response(jsonify(response_object)), 400

    @jwt_required
    def post(self, question_id=None):
        # get the post data
        data = request.get_json(force=True)
        data['question_id'] = question_id
        data['user_id'] = session.get('user_id')
        answer = Table(data)
        response = answer.save()
        if response:
            response_object = {
                'status': 'success',
                'message': response
            }
            return make_response(jsonify(response_object)), 201

        response_object = {
            'status': 'fail',
            'message': 'Unknown question id. Try a different id.'
        }
        return make_response(jsonify(response_object)), 400


class ListAPIView(MethodView):
    """"""
    List API Resource
    """"""
    @jwt_required
    def get(self, answer_id=None):
        data = dict()
        data['answer_id'] = answer_id
        data['user_id'] = session.get('user_id')
        if answer_id:
            results = Table(data).filter_by()
            if len(results) < 1:
                response_object = {
                    'results': 'Answer not found', 'status': 'fail'
                }
                return make_response(jsonify(response_object)), 404
            response_object = {
                'results': results, 'status': 'success'
            }
            return (jsonify(response_object)), 200
        response_object = {'results': Table(data).query(), 'status': 'success'}
        return (jsonify(response_object)), 200


# Define the API resources
create_view = CreateAPIView.as_view('create_api')
list_view = ListAPIView.as_view('list_api')

# Add Rules for API Endpoints
answers_blueprint.add_url_rule(
    '/api/v1/questions/<string:question_id>/answers',
    view_func=create_view,
    methods=['POST']
)

answers_blueprint.add_url_rule(
    '/api/v1/questions/<string:question_id>/answers/<string:answer_id>',
    view_func=create_view,
    methods=['PUT']
)

answers_blueprint.add_url_rule(
    '/api/v1/questions/answers',
    view_func=list_view,
    methods=['GET']
)

answers_blueprint.add_url_rule(
    '/api/v1/questions/answers/<string:answer_id>',
    view_func=list_view,
    methods=['GET']
)
/n/n/napp/answers/models.py/n/n# Custom Model

# Author: P8ul
# https://github.com/p8ul

""""""
    This class will connect to a Database and perform crud actions
    Has relevant getters, setters & mutation methods
""""""

import psycopg2
import psycopg2.extensions
from psycopg2.extras import RealDictCursor
from config import BaseConfig
from ..utils import db_config


class Table:
    def __init__(self, data={}):
        self.config = db_config(BaseConfig.DATABASE_URI)
        self.table = 'answers'
        self.answer_body = data.get('answer_body')
        self.question_id = data.get('question_id')
        self.answer_id = data.get('answer_id')
        self.accepted = data.get('accepted')
        self.user_id = data.get('user_id')

    def save(self):
        """"""
        Creates an answer record in answers table
        :return: None of inserted record
        """"""
        con, response = psycopg2.connect(**self.config), None
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            query = ""INSERT INTO answers (user_id, answer_body, question_id) VALUES (%s, %s, %s) RETURNING *; ""
            cur.execute(query, (self.user_id, self.answer_body, self.question_id))
            con.commit()
            response = cur.fetchone()
        except Exception as e:
            print(e)
        con.close()
        return response

    def query(self):
        """"""
        Fetch all records from a answers table
        :return: list: query set
        """"""
        con = psycopg2.connect(**self.config)
        cur = con.cursor(cursor_factory=RealDictCursor)
        cur.execute(
            """""" SELECT *, ( SELECT  count(*) from votes 
                WHERE votes.answer_id=answers.answer_id AND vote=true ) as upVotes,
                ( SELECT count(*) from votes WHERE votes.answer_id=answers.answer_id
                AND vote=false ) as downVotes FROM  answers
            """"""
        )
        queryset_list = cur.fetchall()
        con.close()
        return queryset_list

    def filter_by(self):
        """"""
        Select a column(s) from answer table
        :return: list: queryset list
        """"""
        try:
            con = psycopg2.connect(**self.config)
            cur = con.cursor(cursor_factory=RealDictCursor)
            query = ""SELECT * FROM answers WHERE answer_id=%s""
            cur.execute(query, self.answer_id)
            queryset_list = cur.fetchall()
            con.close()
            return queryset_list
        except:
            return []

    def question_author(self):
        con = psycopg2.connect(**self.config)
        try:
            cur = con.cursor(cursor_factory=RealDictCursor)
            query = ""SELECT user_id FROM questions WHERE question_id=%s""
            cur.execute(query, self.question_id)
            return cur.fetchall()

        except Exception as e:
            print(e)
        con.close()
        return False

    def answer_author(self):
        try:
            con = psycopg2.connect(**self.config)
            cur = con.cursor(cursor_factory=RealDictCursor)
            query = ""SELECT user_id FROM answers WHERE answer_id=%s""
            cur.execute(query, self.answer_id)
            queryset_list = cur.fetchall()
            con.close()
            return queryset_list
        except Exception as e:
            return False

    def update(self):
        try:
            answer_author = self.answer_author()[0].get('user_id')
            question_author = self.question_author()[0].get('user_id')
            # current user is the answer author
            if answer_author == self.user_id:
                # update answer
                response = 200 if self.update_answer() else 304
                return response

            # current user is question author
            elif question_author == self.user_id:
                # mark it as accepted
                response = self.update_accept_field()
                response = 200 if response else 304
                return response

            # other users
            else:
                return 203
        except:
            return 404

    def update_accept_field(self):
        """"""
        Update an answer column
        :return: bool:
        """"""
        con, result = psycopg2.connect(**self.config), True
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            query = ""UPDATE answers SET accepted=%s WHERE answer_id=%s AND question_id=%s""
            cur.execute(query, (self.accepted, self.answer_id, self.question_id))
            con.commit()
        except Exception as e:
            print(e)
            result = False
        con.close()
        return result

    def update_answer(self):
        """"""
        Update an answer column
        :return: bool:
        """"""
        con = psycopg2.connect(**self.config)
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            query = ""UPDATE answers SET answer_body=%s WHERE answer_id=%s""
            cur.execute(query, (self.answer_body, self.answer_id))
            con.commit()
        except Exception as e:
            print(e)
            con.close()
            return False
        con.close()
        return True

    def delete(self):
        pass



/n/n/napp/answers/test/base.py/n/nimport unittest

from ... import create_app
app = create_app(""config.TestConfig"")


class BaseTestCase(unittest.TestCase):
    """"""A base test case.""""""
    def create_app(self):
        app.config.from_object('config.TestConfig')
        return app

    def setUp(self):
        # method to invoke before each test.
        self.client = app.test_client()
        self.data = {
            'username': 'Paul',
            'email': 'pkinuthia10@gmail.com',
            'password': 'password'
        }
        """""" Login to get a JWT token """"""
        self.client.post('/api/v1/auth/signup', json=self.data)
        response = self.client.post('/api/v1/auth/login', json=self.data)
        self.token = response.get_json().get('auth_token')
        self.user_id = str(response.get_json()['id'])

    def tearDown(self):
        # method to invoke after each test.
        pass
/n/n/napp/answers/test/test_answer_model.py/n/n# APIs Testing

# Author: P8ul
# https://github.com/p8ul

import unittest
from ...test.base import BaseTestCase
from ..models import Table

table = Table()


class FlaskTestCase(BaseTestCase):

    """""" Test question model  """"""
    def test_question_model(self):
        query = table.query()
        self.assertIsInstance(query, type([]))

    def test_model_filter(self):
        query = table.filter_by()
        self.assertEqual(query, [])

    def test_model_save(self):
        query = table.save()
        self.assertEqual(query, None)

    def test_model_update(self):
        query = table.update()
        self.assertEqual(query, 404)

    def test_model_delete(self):
        query = table.delete()
        self.assertEqual(query, None)

    def test_model_question_author(self):
        query = table.question_author()
        self.assertEqual(query, False)

    def test_model_answer_author(self):
        query = table.answer_author()
        self.assertEqual(query, False)

    def test_model_accept(self):
        query = table.update_accept_field()
        self.assertEqual(query, True)

    def test_model_update_answer(self):
        query = table.update_answer()
        self.assertEqual(query, True)

    def test_model_init(self):
        keys = table.config.keys()
        self.assertIn(list(keys)[0], ['password', 'user', 'database', 'host'])
        self.assertEqual(len(list(keys)), 4)


if __name__ == '__main__':
    unittest.main()
/n/n/napp/answers/test/test_answers_apis.py/n/n# APIs Testing

# Author: P8ul
# https://github.com/p8ul

import unittest
from ...test.base import BaseTestCase


class FlaskTestCase(BaseTestCase):

    """""" Test List answers api """"""
    def test_list_answers(self):
        response = self.client.get(
            '/api/v1/questions/answers',
            headers={'Authorization': 'JWT ' + self.token}
        )
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.get_json()['status'], 'success')

    """""" Test answers CRUD api """"""
    def test_post_update(self):
        """""" Initialize test data """"""
        data = {
            'title': 'Test title',
            'body': 'Test body',
            'answer_body': 'Test answer',
            'user': self.user_id
        }

        """""" Add test question""""""
        self.client.post(
            '/api/v1/questions/', json=data,
            headers={'Authorization': 'JWT ' + self.token}
        )

        response = self.client.get(
            '/api/v1/questions/',
            headers={'Authorization': 'JWT ' + self.token}
        )
        question_id = response.get_json().get('results')[0].get('question_id')

        """""" Test post answer """"""
        response = self.client.post(
            '/api/v1/questions/'+str(question_id)+'/answers', json=data,
            headers={'Authorization': 'JWT ' + self.token}
        )

        """""" Test status """"""
        self.assertEqual(response.status_code, 201)

        """""" Test if a question is created """"""
        self.assertEqual(response.get_json()['status'], 'success')


if __name__ == '__main__':
    unittest.main()
/n/n/napp/auth/api/v1/view.py/n/nfrom flask import Blueprint, request, make_response, jsonify, session
from flask.views import MethodView
from flask_bcrypt import Bcrypt
from ...models import Table
from ....utils import jwt_required, encode_auth_token
from ...validatons import validate_user_details

# globals b_crypt
b_crypt = Bcrypt()
auth_blueprint = Blueprint('auth', __name__)


class RegisterAPI(MethodView):
    """""" User Signup API Resource """"""
    def post(self):
        # get the post data
        data = request.get_json(force=True)
        data['user_id'] = session.get('user_id')
        # check if user already exists
        errors = validate_user_details(data)
        if len(errors) > 0:
            response_object = {
                'status': 'fail', 'errors': errors
            }
            return make_response(jsonify(response_object)), 401
        user = Table(data).filter_by_email()
        if not user:
            try:
                user = Table(data).save()
                auth_token = encode_auth_token(user.get('id')).decode()
                response_object = {
                    'status': 'success',
                    'message': 'Successfully registered.',
                    'id': user.get('id'), 'auth_token': auth_token
                }
                return make_response(jsonify(response_object)), 201
            except Exception as e:
                print(e)
                response_object = {
                    'status': 'fail', 'message': 'Some error occurred. Please try again.'
                }
                return make_response(jsonify(response_object)), 401
        else:
            response_object = {
                'status': 'fail', 'message': 'User already exists. Please Log in.',
            }
            return make_response(jsonify(response_object)), 202

    def delete(self, user_id=None):
        data = request.get_json(force=True)
        data['user_id'] = user_id
        Table(data).delete()
        response_object = {
            'status': 'success', 'message': 'User deleted successfully.',
        }
        return make_response(jsonify(response_object)), 200


class LoginAPI(MethodView):
    """""" User Login API Resource """"""
    def post(self):
        data = request.get_json(force=True)
        data['user_id'] = session.get('user_id')
        try:
            user = Table(data).filter_by_email()
            if len(user) >= 1 and data.get('password'):
                if b_crypt.check_password_hash(user[0].get('password'), data.get('password')):
                    auth_token = encode_auth_token(user[0].get('user_id'))
                else:
                    response_object = {'status': 'fail', 'message': 'Password or email do not match.'}
                    return make_response(jsonify(response_object)), 401
                try:
                    if auth_token:
                        response_object = {
                            'status': 'success', 'id': user[0].get('user_id'),
                            'message': 'Successfully logged in.',
                            'auth_token': auth_token.decode()
                        }
                        return make_response(jsonify(response_object)), 200
                except Exception as e:
                    return {""message"": 'Error decoding token'}, 401
            else:
                response_object = {'status': 'fail', 'message': 'User does not exist.'}
                return make_response(jsonify(response_object)), 404
        except Exception as e:
            print(e)
            response_object = {'status': 'fail', 'message': 'Try again'}
            return make_response(jsonify(response_object)), 500


class UserListAPI(MethodView):
    """""" User List Api Resource """"""
    @jwt_required
    def get(self, user_id=None):
        if user_id:
            user = Table({""user_id"": user_id}).filter_by()
            if len(user) < 1:
                response_object = {
                    'results': 'User not found',
                    'status': 'fail'
                }
                return make_response(jsonify(response_object)), 404
            response_object = {
                'results': user,
                'status': 'success'
            }
            return (jsonify(response_object)), 200

        response_object = {
            'results': Table().query(),
            'status': 'success'
        }
        return (jsonify(response_object)), 200


class LogoutAPI(MethodView):
    """""" Logout Resource """"""
    def post(self):
        # get auth token
        auth_header = request.headers.get('Authorization')
        return auth_header


# Define the API resources
registration_view = RegisterAPI.as_view('register_api')
login_view = LoginAPI.as_view('login_api')
user_view = UserListAPI.as_view('user_api')
logout_view = LogoutAPI.as_view('logout_api')

# Add Rules for API Endpoints
auth_blueprint.add_url_rule(
    '/api/v1/auth/signup',
    view_func=registration_view,
    methods=['POST']
)

# Add Rules for API Endpoints
auth_blueprint.add_url_rule(
    '/api/v1/auth/delete',
    view_func=registration_view,
    methods=['DELETE']
)
auth_blueprint.add_url_rule(
    '/api/v1/auth/login',
    view_func=login_view,
    methods=['POST']
)
auth_blueprint.add_url_rule(
    '/api/v1/auth/users',
    view_func=user_view,
    methods=['GET']
)
auth_blueprint.add_url_rule(
    '/api/v1/auth/users/<string:user_id>',
    view_func=user_view,
    methods=['GET']
)
auth_blueprint.add_url_rule(
    '/api/v1/auth/logout',
    view_func=logout_view,
    methods=['POST']
)
/n/n/napp/auth/models.py/n/n# Custom Model

# Author: P8ul
# https://github.com/p8ul

""""""
    This class will act as a table in a Database
    Has relevant getters, setters & mutation methods
""""""
import psycopg2
import psycopg2.extras
from psycopg2.extras import RealDictCursor
from flask_bcrypt import Bcrypt
from config import BaseConfig
from ..utils import db_config


class Table:
    def __init__(self, data={}):
        self.config = db_config(BaseConfig.DATABASE_URI)
        self.table, self.email = 'users', data.get('email')
        self.username = data.get('username')
        self.user_id = data.get('user_id')
        self.b_crypt = Bcrypt()
        if data.get('password'):
            self.password = self.b_crypt.generate_password_hash(data.get('password')).decode('utf-8')

    def query(self):
        con = psycopg2.connect(**self.config)
        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)
        cur.execute(""select * from {}"".format(self.table))
        queryset_list = cur.fetchall()
        con.close()
        return [item for item in queryset_list]

    def filter_by(self):
        con, queryset_list = psycopg2.connect(**self.config), None
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            cur.execute(""select * from {} WHERE user_id='{}'"".format(self.table, self.user_id))
            queryset_list = cur.fetchall()
        except Exception as e:
            print(e)
        con.close()
        return queryset_list

    def filter_by_email(self):
        con, queryset_list = psycopg2.connect(**self.config), None
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            cur.execute(""select * from {} WHERE email='{}'"".format(self.table, self.email))
            queryset_list = cur.fetchall()
        except Exception as e:
            print(e)
        con.close()
        return queryset_list

    def update(self):
        pass

    def delete(self):
        con = psycopg2.connect(**self.config)
        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)
        try:
            query = ""DELETE FROM users WHERE email=%s""
            cur.execute(query, self.email)
            con.commit()
            con.close()
        except Exception as e:
            print(e)
            con.close()
            return False
        return True

    def save(self):
        con, response = psycopg2.connect(**self.config), None
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            query = ""INSERT INTO users (username, email, password) values(%s, %s, %s) RETURNING *""
            cur.execute(query, (self.username, self.email, self.password))
            con.commit()
            response = cur.fetchone()
        except Exception as e:
            print(e)
        con.close()
        return response
/n/n/napp/auth/test/test_model.py/n/nfrom .base import BaseTestCase
from ..models import Table


class FlaskTestCase(BaseTestCase):

    """""" Test signup api """"""
    def test_model_crud(self):
        table = Table(self.data)
        # Test Create
        instance = table.save()
        assert instance.get('email') == self.data.get('email')

        # Test query
        isinstance(table.query(), type([]))
/n/n/napp/auth/test/test_user_validation.py/n/nfrom .base import BaseTestCase
from ..validatons import validate_user_details


class FlaskTestCase(BaseTestCase):

    """""" Test user details validation """"""
    def test_model_crud(self):
        data = {""email"": """", 'password': ''}
        # Test Create
        instance = validate_user_details(data)
        assert instance.get('email') == 'Invalid email. Please enter a valid email'

/n/n/napp/auth/validatons.py/n/nfrom ..utils import valid_email


def validate_user_details(data):
    errors = {}
    if not valid_email(data.get('email')):
        errors['email'] = 'Invalid email. Please enter a valid email'
    if not data.get('email'):
        errors['password'] = 'Password required'
    return errors
/n/n/napp/comments/api/v1/view.py/n/nfrom flask import Blueprint, request, make_response, jsonify
from flask.views import MethodView
from ...models import Table
from ....utils import jwt_required

comments_blueprint = Blueprint('comments', __name__)


class ListAPIView(MethodView):
    """""" Update Instance api resource """"""

    @jwt_required
    def post(self, answer_id=None):
        data = request.get_json(force=True)
        data['answer_id'] = answer_id
        response = Table(data).save()
        if response:
            response_object = {
                'status': 'success',
                'message': 'Your comment was successful'
            }
            return make_response(jsonify(response_object)), 201

        response_object = {
            'status': 'fail',
            'message': 'Some error occurred. Please try again.'
        }
        return make_response(jsonify(response_object)), 400


# Define the API resources
comment_view = ListAPIView.as_view('comment_api')

# Add Rules for API Endpoints
comments_blueprint.add_url_rule(
    '/api/v1/questions/answers/comment/<string:answer_id>',
    view_func=comment_view,
    methods=['POST']
)
/n/n/napp/comments/models.py/n/n""""""
    Author: P8ul
    https://github.com/p8ul

    This class will connect to a Database and perform crud actions
    Has relevant getters, setters & mutation methods
""""""
import psycopg2
import psycopg2.extensions
from psycopg2.extras import RealDictCursor
from flask import session
from config import BaseConfig
from ..utils import db_config


class Table:
    def __init__(self, data={}):
        self.config = db_config(BaseConfig.DATABASE_URI)
        self.table = 'comments'
        self.answer_id = data.get('answer_id')
        self.question_id = data.get('question_id')
        self.comment_body = data.get('comment_body')

    def save(self):
        """"""
        Insert a comment in comments table
        :return: True if record values are inserted successfully else false
        """"""
        con = psycopg2.connect(**self.config)
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            query = ""INSERT INTO comments(user_id, answer_id, comment_body) values(%s, %s, %s) ""
            cur.execute(query, (session.get('user_id'), self.answer_id, self.comment_body))
            con.commit()
        except Exception as e:
            print(e)
            con.close()
            return False
        return True
/n/n/napp/comments/test/__init__.py/n/n/n/n/napp/comments/test/test_comment_api.py/n/n# APIs Testing

# Author: P8ul
# https://github.com/p8ul

import unittest
from ...test.base import BaseTestCase


class FlaskTestCase(BaseTestCase):

    """""" Test List comment api """"""
    def test_comments_api(self):
        response = self.client.post(
            '/api/v1/questions/answers/comment/3', data=self.data,
            headers={'Authorization': 'JWT ' + self.token}
        )
        assert response.status_code == 400


if __name__ == '__main__':
    unittest.main()
/n/n/napp/comments/test/test_comment_model.py/n/n# APIs Testing

# Author: P8ul
# https://github.com/p8ul

import unittest
from ...test.base import BaseTestCase
from ..models import Table

table = Table()


class FlaskTestCase(BaseTestCase):

    """""" Test votes model  """"""
    def test_model_save(self):
        query = table.save()
        self.assertEqual(query, False)

    def test_model_init(self):
        keys = table.config.keys()
        self.assertIn(list(keys)[0], ['password', 'user', 'database', 'host'])
        self.assertEqual(len(list(keys)), 4)


if __name__ == '__main__':
    unittest.main()
/n/n/napp/migrations/db.py/n/nimport psycopg2
import psycopg2.extras

from .initial1 import migrations
from config import BaseConfig
from ..utils import db_config


class Database:
    def __init__(self, config):
        self.config = db_config(config)
        self.database = self.config.get('database')

    def test(self):
        con = psycopg2.connect(**self.config)
        con.autocommit = True
        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)
        cur.execute(""select * from pg_database where datname = %(database_name)s"", {'database_name': self.database})
        databases = cur.fetchall()
        if len(databases) > 0:
            print("" * Database {} exists"".format(self.database))
            for command in migrations:
                try:
                    cur.execute(command)
                    con.commit()
                except Exception as e:
                    print(e)
        else:
            print("" * Database {} does not exists"".format(self.database))
        con.close()


db = Database(BaseConfig.DATABASE_URI)
/n/n/napp/postman/document.py/n/nimport json
from urllib.parse import urlparse


class ApiDocumentGen:
    def __init__(self, file):
        self.file = file
        self.data = {}
        self.name = ''
        self.description = ''
        self.domain = ''
        self.api_version = '/api/v1'
        self.output_file = 'apiary.apid'
        self.file_format = 'FORMAT: 1A'
        self.requests = []
        self.get_data()
        self.data_out()

    def get_data(self):
        with open(self.file, encoding='utf-8') as f:
            self.data = json.loads(f.read())
        self.name = self.data['name']
        self.description = self.data['description']
        self.get_url_info()

    def data_out(self):
        # write document introduction
        doc = open(self.output_file, 'w+')
        doc.write(self.file_format + '\n')
        doc.write('HOST: ' + self.domain + '\n\n')
        doc.write('# ' + self.name + '\n\n')
        doc.write(self.description)
        doc.close()

        for request in self.data.get('requests'):
            self.process_requests(request)

    def process_requests(self, request):
        url = urlparse(request.get('url'))
        path = url.path.replace(self.api_version, '')
        self.domain, description = url, request.get('description')
        method, name = request.get('method'), request.get('name')
        content_type = 'application/json'
        collection_name = '## ' + name + ' [' + path + ']\n'
        title = '### ' + name + ' [' + method + ']'
        req = '+ Request (' + content_type + ')'
        resp = '+ Response 201 (' + content_type + ')'

        doc = open(self.output_file, 'a')
        doc.write(collection_name + '\n\n')
        doc.write(title + '\n')
        doc.write(description + '\n\n')
        if method == ""POST"":
            doc.write(req + '\n\n')
            json_data = json.loads(request.get('rawModeData'))
            json.dump(json_data, doc, indent=8, sort_keys=True, ensure_ascii=False)
            doc.write('\n\n\n')

        doc.write(resp + '\n\n\n')
        doc.close()

    def get_url_info(self):
        url = self.data.get('requests')[0].get('url')
        domain = urlparse(url)
        self.domain = url.replace(domain.path, '') + self.api_version


if __name__ == ""__main__"":
    app = ApiDocumentGen('data.json')
    # app.main()

/n/n/napp/questions/api/v1/view.py/n/n# APIs Resources

# Author: P8ul
# https://github.com/p8ul

from flask import Blueprint, request, make_response, jsonify, session
from flask.views import MethodView
from ...models import Table
from ....utils import jwt_required

question_blueprint = Blueprint('questions', __name__)


class CreateAPIView(MethodView):
    """"""
    Create API Resource
    """"""
    @jwt_required
    def post(self):
        # get the post data
        data = request.get_json(force=True)
        data['user_id'] = session.get('user_id')
        row = Table(data).save()
        if row:
            response_object = {
                'status': 'success',
                'results': row
            }
            return make_response(jsonify(response_object)), 201

        response_object = {
            'status': 'fail',
            'message': 'Some error occurred. Please try again.'
        }
        return make_response(jsonify(response_object)), 401

    """""" UPDATE QUESTION """"""
    @jwt_required
    def put(self, question_id=None):
        # get the post data
        data = request.get_json(force=True)
        data['question_id'] = question_id
        data['user_id'] = session.get('user_id')
        result = Table(data).update()
        if result:
            response_object = {
                'status': 'success',
                'results': data
            }
            return make_response(jsonify(response_object)), 201

        response_object = {
            'status': 'fail',
            'message': 'Some error occurred. Please try again.'
        }
        return make_response(jsonify(response_object)), 401

    """""" DELETE QUESTION """"""
    @jwt_required
    def delete(self, question_id=None):
        data = dict()
        data['user_id'], data['question_id'] = session.get('user_id'), question_id
        response = Table(data).delete()
        if response == 401:
            response_object = {
                'status': 'fail',
                'message': 'Unauthorized, You cannot delete this question!.'
            }
            return make_response(jsonify(response_object)), 401
        if response == 404:
            response_object = {'status': 'fail', 'message': 'Some error occurred. Question Not Found!.'}
            return make_response(jsonify(response_object)), 404
        if not response:
            response_object = {
                'status': 'fail',
                'message': 'Some error occurred. Please try again.'
            }
            return make_response(jsonify(response_object)), 400
        response_object = {
            'status': 'success',
            'message': 'Question deleted successfully'
        }
        return make_response(jsonify(response_object)), 200


class ListAPIView(MethodView):
    """""" List API Resource """"""
    @jwt_required
    def get(self, instance_id=None, user_id=None):
        data = dict()
        data['question_id'], data['user_id'] = instance_id, session.get('user_id')
        if user_id:
            results = Table({}).filter_by_user()
            if results:
                response_object = {'results': results, 'status': 'success'}
                return make_response(jsonify(response_object)), 200
        if instance_id:
            results = Table(data).filter_by()
            if not results:
                response_object = {'status': 'fail', 'message': 'Bad request.'}
                return make_response(jsonify(response_object)), 400
            if len(results) < 1:
                response_object = {'results': 'Question not found', 'status': 'error'}
                return make_response(jsonify(response_object)), 404
            response_object = {'results': results, 'status': 'success'}
            return make_response(jsonify(response_object)), 200
        response_object = {
            'results': Table({'q': request.args.get('q')}).query(), 'status': 'success'
        }
        return (jsonify(response_object)), 200


class UserQuestionsListAPIView(MethodView):
    """"""
    List API Resource
    """"""
    @jwt_required
    def get(self, user):
        data = {'user_id': session.get('user_id')}
        results = Table(data).filter_by_user()
        if results:
            response_object = {'results': results, 'status': 'success'}
            return (jsonify(response_object)), 200

        response_object = {'results': 'Bad Request'}
        return (jsonify(response_object)), 400


# Define the API resources
create_view = CreateAPIView.as_view('create_api')
list_view = ListAPIView.as_view('list_api')
user_questions_list_view = ListAPIView.as_view('user_questions_api')

# Add Rules for API Endpoints
question_blueprint.add_url_rule(
    '/api/v1/questions/',
    view_func=create_view,
    methods=['POST']
)

question_blueprint.add_url_rule(
    '/api/v1/questions/<string:question_id>',
    view_func=create_view,
    methods=['DELETE']
)

question_blueprint.add_url_rule(
    '/api/v1/questions/<string:question_id>',
    view_func=create_view,
    methods=['PUT']
)

question_blueprint.add_url_rule(
    '/api/v1/questions/',
    view_func=list_view,
    methods=['GET']
)

question_blueprint.add_url_rule(
    '/api/v1/questions/user/<string:user_id>',
    view_func=user_questions_list_view,
    methods=['GET']
)

question_blueprint.add_url_rule(
    '/api/v1/questions/<string:instance_id>',
    view_func=list_view,
    methods=['GET']
)
/n/n/napp/questions/models.py/n/n# Custom Model

# Author: P8ul
# https://github.com/p8ul

""""""
    This class will connect to a Database and perform crud actions
    Has relevant getters, setters & mutation methods
""""""
import psycopg2
import psycopg2.extensions
from psycopg2.extras import RealDictCursor
from config import BaseConfig
from ..utils import db_config


class Table:
    def __init__(self, data={}):
        self.config = db_config(BaseConfig.DATABASE_URI)
        self.table, self.title = 'questions', data.get('title')
        self.body, self.q = data.get('body'), data.get('q')
        self.question_id = data.get('question_id')
        self.user_id = data.get('user_id')

    def save(self):
        """""" Create a question record in questions table
        :return: None or record values
        """"""
        con = psycopg2.connect(**self.config)
        cur, response = con.cursor(cursor_factory=RealDictCursor), None
        try:
            query = ""INSERT INTO questions (title, body, user_id) VALUES (%s, %s, %s) RETURNING *""
            cur.execute(query, (self.title, self.body, self.user_id))
            con.commit()
            response = cur.fetchone()
        except Exception as e:
            print(e)
        con.close()
        return response

    def query(self):
        """"""Query the data in question table :return: list: query set list""""""
        con, queryset_list = psycopg2.connect(**self.config), None
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            if not self.q:
                cur.execute(
                    "" SELECT *,( SELECT count(*) FROM ""
                    ""answers WHERE answers.question_id=questions.question_id ) as ""
                    ""answers_count FROM questions ""
                    "" ORDER BY questions.created_at DESC""
                )
            else:
                query = ""SELECT *, ( SELECT count(*) FROM answers WHERE ""
                query += "" answers.question_id=questions.question_id ) as answers_count ""
                query += "" FROM questions WHERE  body LIKE %s OR title LIKE %s  ""
                query += "" ORDER BY questions.created_at""
                cur.execute(query, (self.q, self.q))
            queryset_list = cur.fetchall()
        except Exception as e:
            print(e)
        con.close()
        return queryset_list

    def filter_by(self):
        """"""
        Selects a question by id
        :return: False if record is not found else query list of found record
        """"""
        con, queryset_list = psycopg2.connect(**self.config), None
        cur = con.cursor(cursor_factory=RealDictCursor)
        cur2 = con.cursor(cursor_factory=RealDictCursor)
        try:

            query = """""" SELECT * FROM questions WHERE questions.question_id=%s ORDER BY questions.created_at""""""
            cur.execute(query % self.question_id)
            questions_queryset_list = cur.fetchall()
            cur2.execute(""SELECT * FROM answers WHERE answers.question_id=%s"" % self.question_id)
            answers_queryset_list = cur2.fetchall()
            queryset_list = {
                'question': questions_queryset_list,
                'answers': answers_queryset_list
            }
        except Exception as e:
            print(e)
        con.close()
        return queryset_list

    def filter_by_user(self):
        """"""
        Selects question for specific user:default filters by current logged in user
        :return: False if record is not found else query list of found record
        """"""
        con, queryset_list = psycopg2.connect(**self.config), None
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            cur.execute(
                """""" SELECT * FROM questions 
                    WHERE questions.user_id="""""" + self.user_id + """""" ORDER BY questions.created_at """"""
            )
            questions_queryset_list = cur.fetchall()
            queryset_list = {'question': questions_queryset_list}
        except Exception as e:
            print(e)
        con.close()
        return queryset_list

    def update(self):
        """"""
        Update an question column
        :return: bool:
        """"""
        con, result = psycopg2.connect(**self.config), True
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            query = ""UPDATE questions SET title=%s, body=%s WHERE question_id=%s""
            cur.execute(query, (self.title, self.body, self.question_id))
            con.commit()
        except Exception as e:
            print(e)
            result = False
        con.close()
        return result

    def record_exists(self):
        """"""
        checks whether a question was asked by the user
        :return: bool: False if record is not found else True
        """"""
        con, exists = psycopg2.connect(**self.config), False
        cur, queryset_list = con.cursor(cursor_factory=RealDictCursor), None
        try:
            query = ""SELECT question_id, user_id FROM questions WHERE question_id=%s AND user_id=%s""
            cur.execute(query, (self.question_id, self.user_id))
            queryset_list = cur.fetchall()
            con.close()
            exists = True if len(queryset_list) > 1 else False
        except Exception as e:
            print(e)
        return exists

    def delete(self):
        """""" Delete a table records
        :return: bool
        """"""
        con = psycopg2.connect(**self.config)
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            exist = self.filter_by()['question']
            if not len(exist) > 0:
                return 404
            if not self.record_exists():
                return 401
            cur.execute(""DELETE from {} WHERE {}= '{}'"".format(self.table, 'question_id', self.question_id))
            con.commit()
        except Exception as e:
            print(e)
            con.close()
            return False
        con.close()
        return True
/n/n/napp/questions/test/test_question_model.py/n/n# APIs Testing

# Author: P8ul
# https://github.com/p8ul

import unittest
from ...test.base import BaseTestCase
from ..models import Table

table = Table()


class FlaskTestCase(BaseTestCase):

    """""" Test question model  """"""
    def test_question_model(self):
        query = table.query()
        self.assertIsInstance(query, type([]))

    def test_model_filter(self):
        query = table.filter_by()
        self.assertEqual(query, None)

    def test_model_filter_user(self):
        query = table.filter_by_user()
        self.assertEqual(query, None)

    def test_model_save(self):
        query = table.save()
        self.assertEqual(query, None)

    def test_model_update(self):
        query = table.update()
        self.assertEqual(query, True)

    def test_model_delete(self):
        query = table.delete()
        self.assertEqual(query, False)

    def test_model_init(self):
        keys = table.config.keys()
        self.assertIn(list(keys)[0], ['password', 'user', 'database', 'host'])
        self.assertEqual(len(list(keys)), 4)


if __name__ == '__main__':
    unittest.main()
/n/n/napp/questions/test/test_questions_apis.py/n/n# APIs Testing

# Author: P8ul
# https://github.com/p8ul

import unittest
from ...test.base import BaseTestCase


class FlaskTestCase(BaseTestCase):

    """""" Test List questions api """"""
    def test_list_questions(self):
        response = self.client.get(
            '/api/v1/questions/',
            headers={'Authorization': 'JWT ' + self.token}
        )
        assert response.status_code == 200
        assert response.get_json()['status'] == 'success'

    """""" Test retrieve questions api """"""
    def test_retrieve_question(self):
        response = self.client.get(
            '/api/v1/questions/1',
            headers={'Authorization': 'JWT ' + self.token}
        )
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.get_json()['status'], 'success')

    """""" Test retrieve questions api """"""
    def test_post_update(self):
        """""" Initialize test data """"""
        data = {
            'title': 'Test title',
            'body': 'Test body',
            'user': self.user_id
        }

        """""" Post request""""""
        response = self.client.post(
            '/api/v1/questions/', json=data,
            headers={'Authorization': 'JWT ' + self.token}
        )

        """""" Test status """"""
        self.assertEqual(response.status_code, 201)

        """""" Test if a question is created """"""
        self.assertEqual(response.get_json()['status'], 'success')


if __name__ == '__main__':
    unittest.main()
/n/n/napp/test/base.py/n/nimport unittest

from .. import create_app
app = create_app(""config.TestConfig"")


class BaseTestCase(unittest.TestCase):
    """"""A base test case.""""""

    def create_app(self):
        app.config.from_object('config.TestConfig')
        return app

    def setUp(self):
        # method to invoke before each test.
        self.client = app.test_client()
        self.data = {
            'username': 'Paul',
            'email': 'pkinuthia10@gmail.com',
            'password': 'password'
        }
        """""" Login to get a JWT token """"""
        self.client.post('/api/v1/auth/signup', json=self.data)
        response = self.client.post('/api/v1/auth/login', json=self.data)
        self.token = response.get_json().get('auth_token')
        self.user_id = str(response.get_json()['id'])

    def tearDown(self):
        # method to invoke after each test.
        pass
/n/n/napp/utils.py/n/nfrom urllib.parse import urlparse
import datetime
import os
import re
from functools import wraps
from flask import request, make_response, jsonify, session
import jwt


def jwt_required(f):
    """""" Ensure jwt token is provided and valid
        :param f: function to decorated
        :return: decorated function
    """"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        try:
            auth_header = request.headers.get('Authorization').split(' ')[-1]
        except Exception as e:
            print(e)
            return make_response(jsonify({""message"": 'Unauthorized. Please login'})), 401
        result = decode_auth_token(auth_header)
        try:
            if int(result):
                pass
        except Exception as e:
            print(e)
            return make_response(jsonify({""message"": result})), 401
        return f(*args, **kwargs)
    return decorated_function


def encode_auth_token(user_id):
    """"""
    Encodes a payload to generate JWT Token
    :param user_id: Logged in user Id
    :return: JWT token
    :TODO add secret key to app configuration
    """"""
    payload = {
        'exp': datetime.datetime.utcnow() + datetime.timedelta(days=31, seconds=30),
        'iat': datetime.datetime.utcnow(),
        'sub': user_id
    }
    return jwt.encode(
        payload,
        'SECRET_KEY',
        algorithm='HS256'
    )


def decode_auth_token(auth_token):
    """""" Validates the auth token
    :param auth_token:
    :return: integer|string
    """"""
    try:
        payload = jwt.decode(auth_token, 'SECRET_KEY', algorithm='HS256')
        session['user_id'] = str(payload.get('sub'))
        return payload['sub']
    except jwt.ExpiredSignatureError:
        return 'Token Signature expired. Please log in again.'
    except jwt.InvalidTokenError:
        return 'Invalid token. Please log in again.'


def db_config(database_uri):
    """""" This function extracts postgres url
    and return database login information
    :param database_uri: database Configuration uri
    :return: database login information
    """"""
    if os.environ.get('DATABASE_URI'):
        database_uri = os.environ.get('DATABASE_URI')

    result = urlparse(database_uri)
    config = {
        'database': result.path[1:],
        'user': result.username,
        'password': result.password,
        'host': result.hostname
    }
    return config


def valid_email(email):
    """"""  Validate email """"""
    return re.match(r'^.+@([?)[a-zA-Z0-9-.])+.([a-zA-Z]{2,3}|[0-9]{1,3})(]?)$', email)
/n/n/napp/votes/api/v1/view.py/n/nfrom flask import Blueprint, request, make_response, jsonify, session
from flask.views import MethodView
from ...models import Table
from ....utils import jwt_required

votes_blueprint = Blueprint('votes', __name__)


class VoteAPIView(MethodView):
    """""" Update Instance api resource """"""

    @jwt_required
    def post(self, answer_id=None):
        data = request.get_json(force=True)
        data['answer_id'] = answer_id
        data['user_id'] = session.get('user_id')
        response = Table(data).vote()
        if response:
            response_object = {
                'status': 'success',
                'message': 'Your vote was successful'
            }
            return make_response(jsonify(response_object)), 201

        response_object = {
            'status': 'fail',
            'message': 'Some error occurred. Please try again.'
        }
        return make_response(jsonify(response_object)), 400


# Define the API resources
vote_view = VoteAPIView.as_view('vote_api')

# Add Rules for API Endpoints
votes_blueprint.add_url_rule(
    '/api/v1/questions/answers/vote/<string:answer_id>',
    view_func=vote_view,
    methods=['POST']
)
/n/n/napp/votes/models.py/n/n""""""
    Author: P8ul
    https://github.com/p8ul

    This class will connect to a Database and perform crud actions
    Has relevant getters, setters & mutation methods
""""""
import psycopg2
import psycopg2.extensions
from psycopg2.extras import RealDictCursor
from config import BaseConfig
from ..utils import db_config


class Table:
    def __init__(self, data={}):
        self.config = db_config(BaseConfig.DATABASE_URI)
        self.table, self.answer_id = 'votes', data.get('answer_id')
        self.vote_value, self.user_id = data.get('vote'), data.get('user_id')

    def vote_exists(self):
        """"""
        Checks if vote for a particular answer
        is voted by current user
        :return: True if vote exist else False
        """"""
        con = psycopg2.connect(**self.config)
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            query = ""SELECT user_id, vote_id FROM votes WHERE answer_id=%s AND user_id=%s""
            cur.execute(query, (self.answer_id, self.user_id))
            queryset_list = cur.fetchall()
            con.close()
            if len(queryset_list) < 1:
                return False
            return True
        except Exception as e:
            print(e)
            con.close()
            return False

    def create_vote(self):
        """"""
        Insert a vote in votes table
        :return: True if record values are inserted successfully else false
        """"""
        con = psycopg2.connect(**self.config)
        cur = con.cursor(cursor_factory=RealDictCursor)
        try:
            query = ""INSERT INTO votes(user_id, answer_id, vote) VALUES(%s, %s, %s)""
            cur.execute(query, (self.user_id, self.answer_id, self.vote_value))
            con.commit()
        except Exception as e:
            print(e)
            con.close()
            return False
        return True

    def update_vote(self):
        """"""
        Modify record from votes table
        :return:
        """"""
        if not self.answer_id:
            return False
        try:
            con = psycopg2.connect(**self.config)
            cur = con.cursor(cursor_factory=RealDictCursor)
            query = ""UPDATE votes SET vote=%s WHERE answer_id=%s AND user_id=%s""
            cur.execute(query, (self.vote_value, self.answer_id, self.user_id))
            con.commit()
        except Exception as e:
            print(e)
            con.close()
            return False
        return True

    def vote(self):
        """"""
        Switch bus for updating or creating a vote
        :return: bool: True if transaction is
                       completed successfully else false
        """"""
        if self.vote_exists():
            return self.update_vote()
        return self.create_vote()

    def delete(self):
        pass

    def save(self):
        pass
/n/n/napp/votes/test/__init__.py/n/n/n/n/napp/votes/test/test_vote_apis.py/n/n# APIs Testing

# Author: P8ul
# https://github.com/p8ul

import unittest
from ...test.base import BaseTestCase


class FlaskTestCase(BaseTestCase):

    """""" Test List votes api """"""
    def test_votes_api(self):
        response = self.client.post(
            '/api/v1/questions/answers/vote/1', data=self.data,
            headers={'Authorization': 'JWT ' + self.token}
        )
        assert response.status_code == 400


if __name__ == '__main__':
    unittest.main()
/n/n/napp/votes/test/test_vote_model.py/n/n# APIs Testing

# Author: P8ul
# https://github.com/p8ul

import unittest
from ...test.base import BaseTestCase
from ..models import Table

table = Table()

class FlaskTestCase(BaseTestCase):

    """""" Test votes model  """"""
    def test_model_save(self):
        query = table.save()
        self.assertEqual(query, None)

    def test_model_delete(self):
        query = table.delete()
        self.assertEqual(query, None)

    def test_model_vote_exist(self):
        query = table.vote_exists()
        self.assertEqual(query, None)

    def test_model_vote_exist(self):
        query = table.vote()
        self.assertEqual(query, False)

    def test_model_update_vote(self):
        query = table.update_vote()
        self.assertEqual(query, False)

    def test_model_create_vote(self):
        query = table.create_vote()
        self.assertEqual(query, False)

    def test_model_init(self):
        keys = table.config.keys()
        self.assertIn(list(keys)[0], ['password', 'user', 'database', 'host'])
        self.assertEqual(len(list(keys)), 4)


if __name__ == '__main__':
    unittest.main()
/n/n/nconfig.py/n/n### Configuration file

# Author: P8ul Kinuthia
# https://github.com/p8ul

import os


# default config
class BaseConfig(object):
    basedir = os.path.abspath(os.path.dirname(__file__))
    # DATABASE_URI = ""postgres://tvhuxucdtigrin:fc7e1f53efe5f81b6a6d3dacad8f79605cd0973d0ae5efa5ac29b3976b48f938@ec2-54-83-13-119.compute-1.amazonaws.com:5432/d393cevo034f77""
    DATABASE_URI = ""postgresql://stack:stack@127.0.0.1:5432/stack""
    DEBUG = True
    SECRET_KEY = '\xbf\xb0\x11\xb1\xcd\xf9\xba\x8bp\x0c...'


class TestConfig(BaseConfig):
    DEBUG = True
    TESTING = True
    WTF_CSRF_ENABLED = False
    DATABASE_URI = 'sqlite:///:memory:'


class DevelopmentConfig(BaseConfig):
    DEBUG = True


class ProductionConfig(BaseConfig):
    DEBUG = True/n/n/nmanage.py/n/n# Flask app

# Author: P8ul
# https://github.com/p8ul

from app import create_app
app = create_app(""config.BaseConfig"")

if __name__ == ""__main__"":
    app.run(debug=True)
/n/n/n",0
185,185,ad02c932f85c0f4ed6c1e561efc5edc163347806,"/app/__init__.py/n/n# Flask create app

# Author: P8ul
# https://github.com/p8ul

from flask import Flask
from .migrations.db import db


def create_app(config_filename):
    app = Flask(__name__)
    app.config.from_object(config_filename)

    with app.app_context():
        pass

    """""" Basic Routes """"""

    # register our blueprints
    configure_blueprints(app)

    # register extensions
    configure_extensions()

    return app


def configure_blueprints(app):
    """"""Configure blueprints .""""""
    from app.questions.api.v1.view import question_blueprint
    from .home.views import home_blueprint
    from .auth.api.v1.view import auth_blueprint
    from .answers.api.v1.view import answers_blueprint
    from .votes.api.v1.view import votes_blueprint
    from .comments.api.v1.view import comments_blueprint

    app_blueprints = [
        answers_blueprint,
        question_blueprint,
        auth_blueprint,
        votes_blueprint,
        comments_blueprint,
        home_blueprint
    ]

    for bp in app_blueprints:
        app.register_blueprint(bp)


def configure_extensions():
    db.test()


if __name__ == ""__main__"":
    app = create_app(""config"")
    app.run(debug=True)
/n/n/n/app/answers/api/v1/view.py/n/n# APIs Resources

# Author: P8ul
# https://github.com/p8ul

from flask import Blueprint, request, make_response, jsonify
from flask.views import MethodView
from ...models import Table
from ....utils import jwt_required

answers_blueprint = Blueprint('answers', __name__)


class CreateAPIView(MethodView):
    """""" Update Instance api resource """"""

    @jwt_required
    def put(self, question_id=None, answer_id=None):
        data = request.get_json(force=True)
        response = Table.update(question_id, answer_id, data)
        if response == 200:
            response_object = {
                'status': 'success',
                'message': 'Update successful'
            }
            return make_response(jsonify(response_object)), 200
        if response == 302:
            response_object = {
                'status': 'fail',
                'message': 'Please provide correct answer and question id'
            }
            return make_response(jsonify(response_object)), 400
        if response == 203:
            response_object = {
                'status': 'fail',
                'message': 'Unauthorized request.'
            }
            return make_response(jsonify(response_object)), 401

        else:
            response_object = {
                'status': 'fail',
                'message': 'Please provide correct answer and question id'
            }
            return make_response(jsonify(response_object)), 400


    """"""
    Create API Resource
    """"""
    @jwt_required
    def post(self, question_id=None):
        # get the post data
        post_data = request.get_json(force=True)
        response = Table.save(str(question_id), data=post_data)
        if response:
            response_object = {
                'status': 'success',
                'message': response
            }
            return make_response(jsonify(response_object)), 201

        response_object = {
            'status': 'fail',
            'message': 'Unknown question id. Try a different id.'
        }
        return make_response(jsonify(response_object)), 400


class ListAPIView(MethodView):
    """"""
    List API Resource
    """"""
    @jwt_required
    def get(self, instance_id=None, user_id=None):
        if instance_id:
            query = {
                'instance_id': instance_id,
                'user_id': user_id
            }
            results = Table.filter_by(**query)
            if len(results) < 1:
                response_object = {
                    'results': 'Instance not found',
                    'status': 'error'
                }
                return make_response(jsonify(response_object)), 404
            response_object = {
                'results': results,
                'status': 'success'
            }
            return (jsonify(response_object)), 200

        response_object = {
            'results': Table.query(),
            'status': 'success'
        }
        return (jsonify(response_object)), 200


# Define the API resources
create_view = CreateAPIView.as_view('create_api')
list_view = ListAPIView.as_view('list_api')

# Add Rules for API Endpoints
answers_blueprint.add_url_rule(
    '/api/v1/questions/<int:question_id>/answers',
    view_func=create_view,
    methods=['POST']
)

answers_blueprint.add_url_rule(
    '/api/v1/questions/<string:question_id>/answers/<string:answer_id>',
    view_func=create_view,
    methods=['PUT']
)

answers_blueprint.add_url_rule(
    '/api/v1/questions/answers',
    view_func=list_view,
    methods=['GET']
)
/n/n/n/app/answers/test/base.py/n/nimport unittest

from ... import create_app
app = create_app(""config.TestConfig"")


class BaseTestCase(unittest.TestCase):
    """"""A base test case.""""""
    def create_app(self):
        app.config.from_object('config.TestConfig')
        return app

    def setUp(self):
        # method to invoke before each test.
        self.client = app.test_client()
        self.data = {
            'username': 'Paul',
            'email': 'pkinuthia10@gmail.com',
            'password': 'password'
        }
        """""" Login to get a JWT token """"""
        self.client.post('/api/v1/auth/signup', json=self.data)
        response = self.client.post('/api/v1/auth/login', json=self.data)
        self.token = response.get_json().get('auth_token')
        self.user_id = str(response.get_json()['id'])

    def tearDown(self):
        # method to invoke after each test.
        pass
/n/n/n/app/answers/test/test_basics.py/n/n# APIs Testing

# Author: P8ul Kinuthia
# https://github.com/p8ul

import unittest
from .base import BaseTestCase


class FlaskTestCase(BaseTestCase):

    """""" Test List answers api """"""
    def test_list_answers(self):
        response = self.client.get(
            '/api/v1/questions/answers',
            headers={'Authorization': 'JWT ' + self.token}
        )
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.get_json()['status'], 'success')

    """""" Test answers CRUD api """"""
    def test_post_update(self):
        """""" Initialize test data """"""
        data = {
            'title': 'Test title',
            'body': 'Test body',
            'answer_body': 'Test answer',
            'user': self.user_id
        }

        """""" Add test question""""""
        self.client.post(
            '/api/v1/questions/', json=data,
            headers={'Authorization': 'JWT ' + self.token}
        )

        response = self.client.get(
            '/api/v1/questions/',
            headers={'Authorization': 'JWT ' + self.token}
        )
        question_id = response.get_json().get('results')[0].get('question_id')

        """""" Test post answer """"""
        response = self.client.post(
            '/api/v1/questions/'+str(question_id)+'/answers', json=data,
            headers={'Authorization': 'JWT ' + self.token}
        )

        """""" Test status """"""
        self.assertEqual(response.status_code, 201)

        """""" Test if a question is created """"""
        self.assertEqual(response.get_json()['status'], 'success')


if __name__ == '__main__':
    unittest.main()
/n/n/n/app/auth/api/v1/view.py/n/nfrom flask import Blueprint, request, make_response, jsonify
from flask.views import MethodView
from ...models import Table
from ....utils import jwt_required, encode_auth_token

auth_blueprint = Blueprint('auth', __name__)


class RegisterAPI(MethodView):
    """"""
    User Signup API Resource
    """"""

    def post(self):
        # get the post data
        post_data = request.get_json(force=True)
        # check if user already exists
        user = Table.filter_by(post_data.get('email'))
        if not user:
            try:
                user = Table.save(data=post_data)
                # generate the auth token
                auth_token = encode_auth_token(user.get('id')).decode()
                response_object = {
                    'status': 'success',
                    'message': 'Successfully registered.',
                    'id': user.get('id'),
                    'auth_token': auth_token
                }
                return make_response(jsonify(response_object)), 201
            except Exception as e:
                print(e)
                response_object = {
                    'status': 'fail',
                    'message': 'Some error occurred. Please try again.'
                }
                return make_response(jsonify(response_object)), 401
        else:
            response_object = {
                'status': 'fail',
                'message': 'User already exists. Please Log in.',
            }
            return make_response(jsonify(response_object)), 202

    def delete(self, user_id=None):
        post_data = request.get_json(force=True)
        Table.delete(user_id, post_data)
        response_object = {
            'status': 'success',
            'message': 'User deleted successfully.',
        }
        return make_response(jsonify(response_object)), 200


class LoginAPI(MethodView):
    """""" User Login API Resource """"""
    def post(self):
        # get the post data
        post_data = request.get_json(force=True)
        try:
            # fetch the user data
            user = Table.filter_by(email=post_data.get('email'))
            if len(user) >= 1 and post_data.get('password'):
                if str(user[0][3]) == str(post_data.get('password')):
                    auth_token = encode_auth_token(user[0][0])
                else:
                    response_object = {
                        'status': 'fail',
                        'message': 'Password or email do not match.'
                    }
                    return make_response(jsonify(response_object)), 401
                try:
                    if auth_token:
                        response_object = {
                            'status': 'success',
                            'id': user[0][0],
                            'message': 'Successfully logged in.',
                            'auth_token': auth_token.decode()
                        }
                        return make_response(jsonify(response_object)), 200
                except Exception as e:
                    print(e)
                    return {""message"": 'Error decoding token'}, 401
            else:
                response_object = {
                    'status': 'fail',
                    'message': 'User does not exist.'
                }
                return make_response(jsonify(response_object)), 404
        except Exception as e:
            print(e)
            response_object = {
                'status': 'fail',
                'message': 'Try again'
            }
            return make_response(jsonify(response_object)), 500


class UserListAPI(MethodView):
    """""" User List Api Resource """"""
    @jwt_required
    def get(self, user_id=None):
        if user_id:
            user = Table.filter_by(email=None, user_id=user_id)
            if len(user) < 1:
                response_object = {
                    'results': 'User not found',
                    'status': 'fail'
                }
                return make_response(jsonify(response_object)), 404
            response_object = {
                'results': user,
                'status': 'success'
            }
            return (jsonify(response_object)), 200

        response_object = {
            'results': Table.query(),
            'status': 'success'
        }
        return (jsonify(response_object)), 200


class LogoutAPI(MethodView):
    """""" Logout Resource """"""
    def post(self):
        # get auth token
        auth_header = request.headers.get('Authorization')
        return auth_header


# Define the API resources
registration_view = RegisterAPI.as_view('register_api')
login_view = LoginAPI.as_view('login_api')
user_view = UserListAPI.as_view('user_api')
logout_view = LogoutAPI.as_view('logout_api')

# Add Rules for API Endpoints
auth_blueprint.add_url_rule(
    '/api/v1/auth/signup',
    view_func=registration_view,
    methods=['POST']
)

# Add Rules for API Endpoints
auth_blueprint.add_url_rule(
    '/api/v1/auth/delete',
    view_func=registration_view,
    methods=['DELETE']
)
auth_blueprint.add_url_rule(
    '/api/v1/auth/login',
    view_func=login_view,
    methods=['POST']
)
auth_blueprint.add_url_rule(
    '/api/v1/auth/users',
    view_func=user_view,
    methods=['GET']
)
auth_blueprint.add_url_rule(
    '/api/v1/auth/users/<string:user_id>',
    view_func=user_view,
    methods=['GET']
)
auth_blueprint.add_url_rule(
    '/api/v1/auth/logout',
    view_func=logout_view,
    methods=['POST']
)
/n/n/n/app/auth/test/test_model.py/n/nfrom .base import BaseTestCase
from ..models import Table


class FlaskTestCase(BaseTestCase):

    """""" Test signup api """"""
    def test_model_crud(self):
        # Test Create
        instance = Table.save(self.data)
        assert instance == self.data

        # Test query
        isinstance(Table.query(), type([]))
/n/n/n/app/comments/api/v1/view.py/n/nfrom flask import Blueprint, request, make_response, jsonify
from flask.views import MethodView
from ...models import Table
from ....utils import jwt_required

comments_blueprint = Blueprint('comments', __name__)


class ListAPIView(MethodView):
    """""" Update Instance api resource """"""

    @jwt_required
    def post(self, answer_id=None):
        post_data = request.get_json(force=True)
        response = Table.save(answer_id, data=post_data)
        if response:
            response_object = {
                'status': 'success',
                'message': 'Your comment was successful'
            }
            return make_response(jsonify(response_object)), 201

        response_object = {
            'status': 'fail',
            'message': 'Some error occurred. Please try again.'
        }
        return make_response(jsonify(response_object)), 400


# Define the API resources
comment_view = ListAPIView.as_view('comment_api')

# Add Rules for API Endpoints
comments_blueprint.add_url_rule(
    '/api/v1/questions/answers/comment/<string:answer_id>',
    view_func=comment_view,
    methods=['POST']
)
/n/n/n/app/migrations/db.py/n/nimport psycopg2
import psycopg2.extras

from .initial1 import migrations
from config import BaseConfig
from ..utils import db_config


class Database:
    def __init__(self, config):
        self.config = db_config(config)
        self.database = self.config.get('database')

    def test(self):
        con = psycopg2.connect(**self.config)
        con.autocommit = True

        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)
        cur.execute(""select * from pg_database where datname = %(database_name)s"", {'database_name': self.database})
        databases = cur.fetchall()
        if len(databases) > 0:
            print("" * Database {} exists"".format(self.database))
            for command in migrations:
                try:
                    cur.execute(command)
                    con.commit()
                except Exception as e:
                    print(e)
        else:
            print("" * Database {} does not exists"".format(self.database))
        con.close()


db = Database(BaseConfig.SQLALCHEMY_DATABASE_URI)
/n/n/n",1
100,100,069700fb4beec79182fff3c556e9cccce3230d6f,"forumdb.py/n/n# ""Database code"" for the DB Forum.

import psycopg2
import datetime

def get_posts():
  """"""Return all posts from the 'database', most recent first.""""""
  conn = psycopg2.connect(""dbname=forum"")
  cursor = conn.cursor()
  cursor.execute(""select content, time from posts order by time desc"")
  all_posts = cursor.fetchall()
  conn.close()
  return all_posts

def add_post(content):
  """"""Add a post to the 'database' with the current timestamp.""""""
  conn = psycopg2.connect(""dbname=forum"")
  cursor = conn.cursor()
  one_post = content
  cursor.execute(""insert into posts values (%s)"", (one_post,))
  conn.commit()
  conn.close()
/n/n/n",0
101,101,069700fb4beec79182fff3c556e9cccce3230d6f,"/forumdb.py/n/n# ""Database code"" for the DB Forum.

import psycopg2
import datetime

def get_posts():
  """"""Return all posts from the 'database', most recent first.""""""
  conn = psycopg2.connect(""dbname=forum"")
  cursor = conn.cursor()
  cursor.execute(""select content, time from posts order by time desc"")
  all_posts = cursor.fetchall()
  conn.close()
  return all_posts

def add_post(content):
  """"""Add a post to the 'database' with the current timestamp.""""""
  conn = psycopg2.connect(""dbname=forum"")
  cursor = conn.cursor()
  cursor.execute(""insert into posts values ('%s')"" % content)
  conn.commit()
  conn.close()
/n/n/n",1
88,88,4bad3673debf0b9491b520f0e22e9186af78c375,"bar.py/n/nimport subprocess
import shlex
import os
import signal
from helper import path_dict, path_number_of_files, pdf_stats, pdf_date_format_to_datetime
import json
from functools import wraps
from urllib.parse import urlparse

from flask import Flask, render_template, flash, redirect, url_for, session, request, logging
from flask_mysqldb import MySQL
from wtforms import Form, StringField, TextAreaField, PasswordField, validators
from passlib.hash import sha256_crypt
import time

app = Flask(__name__)
app.secret_key = 'Aj""$7PE#>3AC6W]`STXYLz*[G\gQWA'


# Config MySQL
app.config['MYSQL_HOST'] = 'localhost'
app.config['MYSQL_USER'] = 'root'
app.config['MYSQL_PASSWORD'] = 'mountain'
app.config['MYSQL_DB'] = 'bar'
app.config['MYSQL_CURSORCLASS'] = 'DictCursor'

# init MySQL
mysql = MySQL(app)

# CONSTANTS
WGET_DATA_PATH = 'data'
PDF_TO_PROCESS = 10
MAX_CRAWLING_DURATION = 60 # 15 minutes
WAIT_AFTER_CRAWLING = 1000


# Helper Function

# Check if user logged in
def is_logged_in(f):
    @wraps(f)
    def wrap(*args, **kwargs):
        if 'logged_in' in session:
            return f(*args, **kwargs)
        else:
            flash('Unauthorized, Please login', 'danger')
            return redirect(url_for('login'))
    return wrap


# Index
@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST': #FIXME I didn't handle security yet !! make sure only logged-in people can execute

        # User can type in url
        # The url will then get parsed to extract domain, while the crawler starts at url.

        # Get Form Fields and save
        url = request.form['url']
        parsed = urlparse(url)

        session['domain'] = parsed.netloc
        session['url'] = url

        # TODO use WTForms to get validation

        return redirect(url_for('crawling'))

    return render_template('home.html')


# Crawling
@app.route('/crawling')
@is_logged_in
def crawling():
    # STEP 0: TimeKeeping
    session['crawl_start_time'] = time.time()

    # STEP 1: Prepare WGET command
    url = session.get('url', None)

    command = shlex.split(""timeout %d wget -r -A pdf %s"" % (MAX_CRAWLING_DURATION, url,)) #FIXME timeout remove
    #command = shlex.split(""wget -r -A pdf %s"" % (url,))

    #TODO use celery
    #TODO give feedback how wget is doing

    #TODO https://stackoverflow.com/questions/15041620/how-to-continuously-display-python-output-in-a-webpage

    # STEP 2: Execute command in subdirectory
    process = subprocess.Popen(command, cwd=WGET_DATA_PATH)
    session['crawl_process_id'] = process.pid

    return render_template('crawling.html', max_crawling_duration=MAX_CRAWLING_DURATION)


# End Crawling Manual
@app.route('/crawling/end')
@is_logged_in
def end_crawling():

    # STEP 1: Kill crawl process
    p_id = session.get('crawl_process_id', None)
    os.kill(p_id, signal.SIGTERM)

    session['crawl_process_id'] = -1

    # STEP 2: TimeKeeping
    crawl_start_time = session.get('crawl_start_time', None)
    session['crawl_total_time'] = time.time() - crawl_start_time

    # STEP 3: Successful interruption
    flash('You successfully interrupted the crawler', 'success')

    return render_template('end_crawling.html')


# End Crawling Automatic
@app.route('/crawling/autoend')
@is_logged_in
def autoend_crawling():

    # STEP 0: Check if already interrupted
    p_id = session.get('crawl_process_id', None)
    if p_id < 0:
        return ""process already killed""
    else:
        # STEP 1: Kill crawl process
        os.kill(p_id, signal.SIGTERM)

        # STEP 2: TimeKeeping
        crawl_start_time = session.get('crawl_start_time', None)
        session['crawl_total_time'] = time.time() - crawl_start_time

        # STEP 3: Successful interruption
        flash('Time Limit reached - Crawler interrupted automatically', 'success')

        return redirect(url_for(""table_detection""))


# Start table detection
@app.route('/table_detection')
@is_logged_in
def table_detection():
    return render_template('table_detection.html', wait=WAIT_AFTER_CRAWLING)


# About
@app.route('/about')
def about():
    return render_template('about.html')


# PDF processing
@app.route('/processing')
@is_logged_in
def processing():

    # STEP 0: Time keeping
    proc_start_time = time.time()

    domain = session.get('domain', None)
    if domain == None:
        pass
        # TODO think of bad cases

    path = ""data/%s"" % (domain,)

    # STEP 1: Call Helper function to create Json string

    # FIXME workaround to weird file system bug with latin/ cp1252 encoding..
    # https://stackoverflow.com/questions/35959580/non-ascii-file-name-issue-with-os-walk works
    # https://stackoverflow.com/questions/2004137/unicodeencodeerror-on-joining-file-name doesn't work
    hierarchy_dict = path_dict(path)  # adding ur does not work as expected either
    hierarchy_json = json.dumps(hierarchy_dict, sort_keys=True, indent=4)  # , encoding='cp1252' not needed in python3

    # FIXME remove all session stores

    # STEP 2: Call helper function to count number of pdf files
    n_files = path_number_of_files(path)
    session['n_files'] = n_files

    # STEP 3: Extract tables from pdf's
    stats, n_error, n_success = pdf_stats(path, PDF_TO_PROCESS)

    # STEP 4: Save stats
    session['n_error'] = n_error
    session['n_success'] = n_success
    stats_json = json.dumps(stats, sort_keys=True, indent=4)
    session['stats'] = stats_json

    # STEP 5: Time Keeping
    proc_over_time = time.time()
    proc_total_time = proc_over_time - proc_start_time

    # STEP 6: Save query in DB
    # Create cursor
    cur = mysql.connection.cursor()

    # Execute query
    cur.execute(""""""INSERT INTO Crawls(cid, crawl_date, pdf_crawled, pdf_processed, process_errors, domain, url, hierarchy, 
                stats, crawl_total_time, proc_total_time) VALUES(NULL, NULL, %s ,%s, %s, %s, %s, %s, %s, %s, %s)"""""",
                (n_files, n_success, n_error, domain, session.get('url', None), hierarchy_json,
                stats_json, session.get('crawl_total_time', None), proc_total_time))

    # Commit to DB
    mysql.connection.commit()

    # Close connection
    cur.close()

    return render_template('processing.html', n_files=n_success, domain=domain, cid=0)

# Last Crawl Statistics
@app.route('/statistics')
@is_logged_in
def statistics():
    # Create cursor
    cur = mysql.connection.cursor()

    # Get user by username
    cur.execute(""""""SELECT cid FROM Crawls WHERE crawl_date = (SELECT max(crawl_date) FROM Crawls)"""""")

    result = cur.fetchone()

    # Close connection
    cur.close()

    if result:
        cid_last_crawl = result[""cid""]
        return redirect(url_for(""cid_statistics"", cid=cid_last_crawl))
    else:
        flash(""There are no statistics to display, please start a new query and wait for it to complete."", ""danger"")
        return redirect(url_for(""index""))


# CID specific Statistics
@app.route('/statistics/<int:cid>')
@is_logged_in
def cid_statistics(cid):

    # STEP 1: retrieve all saved stats from DB
    # Create cursor
    cur = mysql.connection.cursor()

    result = cur.execute(""""""SELECT * FROM Crawls WHERE cid = %s"""""", (cid,))
    crawl = cur.fetchall()[0]

    # Close connection
    cur.close();

    print(session.get('stats', None))
    print(crawl['stats'])

    # STEP 2: do some processing to retrieve interesting info from stats
    json_stats = json.loads(crawl['stats'])
    json_hierarchy = json.loads(crawl['hierarchy'])

    stats_items = json_stats.items()
    n_tables = sum([subdict['n_tables_pages'] for filename, subdict in stats_items])
    n_rows = sum([subdict['n_table_rows'] for filename, subdict in stats_items])

    medium_tables = sum([subdict['table_sizes']['medium'] for filename, subdict in stats_items])
    small_tables = sum([subdict['table_sizes']['small'] for filename, subdict in stats_items])
    large_tables = sum([subdict['table_sizes']['large'] for filename, subdict in stats_items])

    # Find some stats about creation dates
    creation_dates_pdf = [subdict['creation_date'] for filename, subdict in stats_items]
    creation_dates = list(map(lambda str : pdf_date_format_to_datetime(str), creation_dates_pdf))

    if len(creation_dates) > 0:
        oldest_pdf = min(creation_dates)
        most_recent_pdf = max(creation_dates)
    else:
        oldest_pdf = ""None""
        most_recent_pdf = ""None""

    return render_template('statistics.html', n_files=crawl['pdf_crawled'], n_success=crawl['pdf_processed'],
                           n_tables=n_tables, n_rows=n_rows, n_errors=crawl['process_errors'], domain=crawl['domain'],
                           small_tables=small_tables, medium_tables=medium_tables,
                           large_tables=large_tables, stats=json_stats, hierarchy=json_hierarchy,
                           end_time=crawl['crawl_date'], crawl_total_time=round(crawl['crawl_total_time'] / 60.0, 1),
                           proc_total_time=round(crawl['proc_total_time'] / 60.0, 1),
                           oldest_pdf=oldest_pdf, most_recent_pdf=most_recent_pdf)


class RegisterForm(Form):
    name = StringField('Name', [validators.Length(min=1, max=50)])
    username = StringField('Username', [validators.Length(min=4, max=25)])
    email = StringField('Email', [validators.Length(min=6, max=50)])
    password = PasswordField('Password', [validators.DataRequired(),
                                          validators.EqualTo('confirm', message='Passwords do not match')])
    confirm = PasswordField('Confirm Password')


# Register
@app.route('/register', methods=['GET', 'POST'])
def register():
    form = RegisterForm(request.form)
    if request.method == 'POST' and form.validate():
        name = form.name.data
        email = form.email.data
        username = form.username.data
        password = sha256_crypt.encrypt(str(form.password.data))

        # Create cursor
        cur = mysql.connection.cursor()

        # Execute query
        cur.execute(""INSERT INTO Users(name, email, username, password) VALUES(%s, %s, %s, %s)"",
                    (name, email, username, password))

        # Commit to DB
        mysql.connection.commit()

        # Close connection
        cur.close()

        flash('You are now registered and can log in', 'success')

        return redirect(url_for('login'))

    return render_template('register.html', form=form)


# User login
@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        # Get Form Fields
        username = request.form['username']
        password_candidate = request.form['password']

        # Create cursor
        cur = mysql.connection.cursor()

        # Get user by username
        result = cur.execute(""""""SELECT * FROM Users WHERE username = %s"""""", [username])

        # Note: apparently this is safe from SQL injections see
        # https://stackoverflow.com/questions/7929364/python-best-practice-and-securest-to-connect-to-mysql-and-execute-queries/7929438#7929438

        if result > 0:
            # Get stored hash
            data = cur.fetchone() # FIXME why is username not primary key
            password = data['password']

            # Compare passwords
            if sha256_crypt.verify(password_candidate, password): # FIXME how does sha256 work?

                # Check was successful -> create session variables
                session['logged_in'] = True
                session['username'] = username

                flash('You are now logged in', 'success')
                return redirect(url_for('index'))
            else:
                error = 'Invalid login'
                return render_template('login.html', error=error)

        else:
            error = 'Username not found'
            return render_template('login.html', error=error)

        # Close connection
        cur.close() # FIXME shouldn't that happen before return?

    return render_template('login.html')


# Delete Crawl
@app.route('/delete_crawl', methods=['POST'])
@is_logged_in
def delete_crawl():

        # Get Form Fields
        cid = request.form['cid']

        # Create cursor
        cur = mysql.connection.cursor()

        # Get user by username
        result = cur.execute(""""""DELETE FROM Crawls WHERE cid = %s"""""" (cid,))

        # Commit to DB
        mysql.connection.commit()

        # Close connection
        cur.close()

        # FIXME check if successfull first, return message
        flash('Crawl successfully removed', 'success')

        return redirect(url_for('dashboard'))


# Logout
@app.route('/logout')
@is_logged_in
def logout():
    session.clear()
    flash('You are now logged out', 'success')
    return redirect(url_for('login'))


# Dashboard
@app.route('/dashboard')
@is_logged_in
def dashboard():

    # Create cursor
    cur = mysql.connection.cursor()

    # Get Crawls
    result = cur.execute(""""""SELECT cid, crawl_date, pdf_crawled, pdf_processed, domain, url FROM Crawls"""""")

    crawls = cur.fetchall()

    if result > 0:
        return render_template('dashboard.html', crawls=crawls)
    else:
        msg = 'No Crawls Found'
        return render_template('dashboard.html', msg=msg)

    # Close connection FIXME is this code executed
    cur.close()


if __name__ == '__main__':
    app.secret_key='Aj""$7PE#>3AC6W]`STXYLz*[G\gQWA'
    app.run(debug=True)
    #app.run(host='0.0.0.0')

/n/n/n",0
89,89,4bad3673debf0b9491b520f0e22e9186af78c375,"/bar.py/n/nimport subprocess
import shlex
import os
import signal
from helper import path_dict, path_number_of_files, pdf_stats, pdf_date_format_to_datetime
import json
from functools import wraps
from urllib.parse import urlparse

from flask import Flask, render_template, flash, redirect, url_for, session, request, logging
from flask_mysqldb import MySQL
from wtforms import Form, StringField, TextAreaField, PasswordField, validators
from passlib.hash import sha256_crypt
import time

app = Flask(__name__)
app.secret_key = 'Aj""$7PE#>3AC6W]`STXYLz*[G\gQWA'


# Config MySQL
app.config['MYSQL_HOST'] = 'localhost'
app.config['MYSQL_USER'] = 'root'
app.config['MYSQL_PASSWORD'] = 'mountain'
app.config['MYSQL_DB'] = 'bar'
app.config['MYSQL_CURSORCLASS'] = 'DictCursor'

# init MySQL
mysql = MySQL(app)

# CONSTANTS
WGET_DATA_PATH = 'data'
PDF_TO_PROCESS = 10
MAX_CRAWLING_DURATION = 60 # 15 minutes
WAIT_AFTER_CRAWLING = 1000


# Helper Function

# Check if user logged in
def is_logged_in(f):
    @wraps(f)
    def wrap(*args, **kwargs):
        if 'logged_in' in session:
            return f(*args, **kwargs)
        else:
            flash('Unauthorized, Please login', 'danger')
            return redirect(url_for('login'))
    return wrap


# Index
@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST': #FIXME I didn't handle security yet !! make sure only logged-in people can execute

        # User can type in url
        # The url will then get parsed to extract domain, while the crawler starts at url.

        # Get Form Fields and save
        url = request.form['url']
        parsed = urlparse(url)

        session['domain'] = parsed.netloc
        session['url'] = url

        # TODO use WTForms to get validation

        return redirect(url_for('crawling'))

    return render_template('home.html')


# Crawling
@app.route('/crawling')
@is_logged_in
def crawling():
    # STEP 0: TimeKeeping
    session['crawl_start_time'] = time.time()

    # STEP 1: Prepare WGET command
    url = session.get('url', None)

    command = shlex.split(""timeout %d wget -r -A pdf %s"" % (MAX_CRAWLING_DURATION, url,)) #FIXME timeout remove
    #command = shlex.split(""wget -r -A pdf %s"" % (url,))

    #TODO use celery
    #TODO give feedback how wget is doing

    #TODO https://stackoverflow.com/questions/15041620/how-to-continuously-display-python-output-in-a-webpage

    # STEP 2: Execute command in subdirectory
    process = subprocess.Popen(command, cwd=WGET_DATA_PATH)
    session['crawl_process_id'] = process.pid

    return render_template('crawling.html', max_crawling_duration=MAX_CRAWLING_DURATION)


# End Crawling Manual
@app.route('/crawling/end')
@is_logged_in
def end_crawling():

    # STEP 1: Kill crawl process
    p_id = session.get('crawl_process_id', None)
    os.kill(p_id, signal.SIGTERM)

    session['crawl_process_id'] = -1

    # STEP 2: TimeKeeping
    crawl_start_time = session.get('crawl_start_time', None)
    session['crawl_total_time'] = time.time() - crawl_start_time

    # STEP 3: Successful interruption
    flash('You successfully interrupted the crawler', 'success')

    return render_template('end_crawling.html')


# End Crawling Automatic
@app.route('/crawling/autoend')
@is_logged_in
def autoend_crawling():

    # STEP 0: Check if already interrupted
    p_id = session.get('crawl_process_id', None)
    if p_id < 0:
        return ""process already killed""
    else:
        # STEP 1: Kill crawl process
        os.kill(p_id, signal.SIGTERM)

        # STEP 2: TimeKeeping
        crawl_start_time = session.get('crawl_start_time', None)
        session['crawl_total_time'] = time.time() - crawl_start_time

        # STEP 3: Successful interruption
        flash('Time Limit reached - Crawler interrupted automatically', 'success')

        return redirect(url_for(""table_detection""))


# Start table detection
@app.route('/table_detection')
@is_logged_in
def table_detection():
    return render_template('table_detection.html', wait=WAIT_AFTER_CRAWLING)


# About
@app.route('/about')
def about():
    return render_template('about.html')


# PDF processing
@app.route('/processing')
@is_logged_in
def processing():

    # STEP 0: Time keeping
    proc_start_time = time.time()

    domain = session.get('domain', None)
    if domain == None:
        pass
        # TODO think of bad cases

    path = ""data/%s"" % (domain,)

    # STEP 1: Call Helper function to create Json string

    # FIXME workaround to weird file system bug with latin/ cp1252 encoding..
    # https://stackoverflow.com/questions/35959580/non-ascii-file-name-issue-with-os-walk works
    # https://stackoverflow.com/questions/2004137/unicodeencodeerror-on-joining-file-name doesn't work
    hierarchy_dict = path_dict(path)  # adding ur does not work as expected either
    hierarchy_json = json.dumps(hierarchy_dict, sort_keys=True, indent=4)  # , encoding='cp1252' not needed in python3

    # FIXME remove all session stores

    # STEP 2: Call helper function to count number of pdf files
    n_files = path_number_of_files(path)
    session['n_files'] = n_files

    # STEP 3: Extract tables from pdf's
    stats, n_error, n_success = pdf_stats(path, PDF_TO_PROCESS)

    # STEP 4: Save stats
    session['n_error'] = n_error
    session['n_success'] = n_success
    stats_json = json.dumps(stats, sort_keys=True, indent=4)
    session['stats'] = stats_json

    # STEP 5: Time Keeping
    proc_over_time = time.time()
    proc_total_time = proc_over_time - proc_start_time

    # STEP 6: Save query in DB
    # Create cursor
    cur = mysql.connection.cursor()

    # Execute query
    cur.execute(""INSERT INTO Crawls(cid, crawl_date, pdf_crawled, pdf_processed, process_errors, domain, url, hierarchy, stats, crawl_total_time, proc_total_time) VALUES(NULL, NULL, %s ,%s, %s, %s, %s, %s, %s, %s, %s)"",
                (n_files, n_success, n_error, domain, session.get('url', None), hierarchy_json, stats_json, session.get('crawl_total_time', None), proc_total_time))

    # Commit to DB
    mysql.connection.commit()

    # Close connection
    cur.close()

    return render_template('processing.html', n_files=n_success, domain=domain, cid=0)

# Last Crawl Statistics
@app.route('/statistics')
@is_logged_in
def statistics():
    # Create cursor
    cur = mysql.connection.cursor()

    # Get user by username
    cur.execute(""SELECT cid FROM Crawls WHERE crawl_date = (SELECT max(crawl_date) FROM Crawls)"")

    result = cur.fetchone()

    # Close connection
    cur.close()

    if result:
        cid_last_crawl = result[""cid""]
        return redirect(url_for(""cid_statistics"", cid=cid_last_crawl))
    else:
        flash(""There are no statistics to display, please start a new query and wait for it to complete."", ""danger"")
        return redirect(url_for(""index""))


# CID specific Statistics
@app.route('/statistics/<int:cid>')
@is_logged_in
def cid_statistics(cid):

    # STEP 1: retrieve all saved stats from DB
    # Create cursor
    cur = mysql.connection.cursor()

    result = cur.execute('SELECT * FROM Crawls WHERE cid = %s' % cid)
    crawl = cur.fetchall()[0]

    # Close connection
    cur.close();

    print(session.get('stats', None))
    print(crawl['stats'])

    # STEP 2: do some processing to retrieve interesting info from stats
    json_stats = json.loads(crawl['stats'])
    json_hierarchy = json.loads(crawl['hierarchy'])

    stats_items = json_stats.items()
    n_tables = sum([subdict['n_tables_pages'] for filename, subdict in stats_items])
    n_rows = sum([subdict['n_table_rows'] for filename, subdict in stats_items])

    medium_tables = sum([subdict['table_sizes']['medium'] for filename, subdict in stats_items])
    small_tables = sum([subdict['table_sizes']['small'] for filename, subdict in stats_items])
    large_tables = sum([subdict['table_sizes']['large'] for filename, subdict in stats_items])

    # Find some stats about creation dates
    creation_dates_pdf = [subdict['creation_date'] for filename, subdict in stats_items]
    creation_dates = list(map(lambda str : pdf_date_format_to_datetime(str), creation_dates_pdf))

    if len(creation_dates) > 0:
        oldest_pdf = min(creation_dates)
        most_recent_pdf = max(creation_dates)
    else:
        oldest_pdf = ""None""
        most_recent_pdf = ""None""

    return render_template('statistics.html', n_files=crawl['pdf_crawled'], n_success=crawl['pdf_processed'],
                           n_tables=n_tables, n_rows=n_rows, n_errors=crawl['process_errors'], domain=crawl['domain'],
                           small_tables=small_tables, medium_tables=medium_tables,
                           large_tables=large_tables, stats=json_stats, hierarchy=json_hierarchy,
                           end_time=crawl['crawl_date'], crawl_total_time=round(crawl['crawl_total_time'] / 60.0, 1),
                           proc_total_time=round(crawl['proc_total_time'] / 60.0, 1),
                           oldest_pdf=oldest_pdf, most_recent_pdf=most_recent_pdf)


class RegisterForm(Form):
    name = StringField('Name', [validators.Length(min=1, max=50)])
    username = StringField('Username', [validators.Length(min=4, max=25)])
    email = StringField('Email', [validators.Length(min=6, max=50)])
    password = PasswordField('Password', [validators.DataRequired(),
                                          validators.EqualTo('confirm', message='Passwords do not match')])
    confirm = PasswordField('Confirm Password')


# Register
@app.route('/register', methods=['GET', 'POST'])
def register():
    form = RegisterForm(request.form)
    if request.method == 'POST' and form.validate():
        name = form.name.data
        email = form.email.data
        username = form.username.data
        password = sha256_crypt.encrypt(str(form.password.data))

        # Create cursor
        cur = mysql.connection.cursor()

        # Execute query
        cur.execute(""INSERT INTO Users(name, email, username, password) VALUES(%s, %s, %s, %s)"",
                    (name, email, username, password))

        # Commit to DB
        mysql.connection.commit()

        # Close connection
        cur.close()

        flash('You are now registered and can log in', 'success')

        return redirect(url_for('login'))

    return render_template('register.html', form=form)


# User login
@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        # Get Form Fields
        username = request.form['username'] # FIXME SQL_injection danger?
        password_candidate = request.form['password']

        # Create cursor
        cur = mysql.connection.cursor()

        # Get user by username
        result = cur.execute(""SELECT * FROM Users WHERE username = %s"", [username])

        if result > 0:
            # Get stored hash
            data = cur.fetchone() # FIXME fucking stupid username is not primary key
            password = data['password']

            # Compare passwords
            if sha256_crypt.verify(password_candidate, password): # FIXME how does sha256 work?

                # Check was successful -> create session variables
                session['logged_in'] = True
                session['username'] = username

                flash('You are now logged in', 'success')
                return redirect(url_for('index'))
            else:
                error = 'Invalid login'
                return render_template('login.html', error=error)

        else:
            error = 'Username not found'
            return render_template('login.html', error=error)

        # Close connection
        cur.close() # FIXME shouldn't that happen before return?

    return render_template('login.html')


# Delete Crawl
@app.route('/delete_crawl', methods=['POST'])
@is_logged_in
def delete_crawl():

        # Get Form Fields
        cid = request.form['cid']

        # Create cursor
        cur = mysql.connection.cursor()

        # Get user by username
        result = cur.execute(""DELETE FROM Crawls WHERE cid = %s"" % cid)

        # Commit to DB
        mysql.connection.commit()

        # Close connection
        cur.close()

        # FIXME check if successfull first, return message
        flash('Crawl successfully removed', 'success')

        return redirect(url_for('dashboard'))


# Logout
@app.route('/logout')
@is_logged_in
def logout():
    session.clear()
    flash('You are now logged out', 'success')
    return redirect(url_for('login'))


# Dashboard
@app.route('/dashboard')
@is_logged_in
def dashboard():

    # Create cursor
    cur = mysql.connection.cursor()

    # Get Crawls
    result = cur.execute(""SELECT cid, crawl_date, pdf_crawled, pdf_processed, domain, url FROM Crawls"")

    crawls = cur.fetchall()

    if result > 0:
        return render_template('dashboard.html', crawls=crawls)
    else:
        msg = 'No Crawls Found'
        return render_template('dashboard.html', msg=msg)

    # Close connection FIXME is this code executed
    cur.close()


if __name__ == '__main__':
    app.secret_key='Aj""$7PE#>3AC6W]`STXYLz*[G\gQWA'
    app.run(debug=True)
    #app.run(host='0.0.0.0')

/n/n/n",1
82,82,071497f90bcf7336c44e135d5ef4bd87898fa8d0,"app.py/n/n#!/usr/bin/env python2.7

import sys
import os

# Flask Import
from flask import Flask , request , redirect , render_template , url_for 
from flask import jsonify , abort , make_response 
import MySQLdb

# Toekn and URL check import
from check_encode import random_token , url_check
from display_list import list_data

from sql_table import mysql_table

# Config import
import config

# Import Loggers
import logging
from logging.handlers import RotatingFileHandler
from time import strftime
import traceback

# Setting UTF-8 encoding

reload(sys)
sys.setdefaultencoding('UTF-8')
os.putenv('LANG', 'en_US.UTF-8')
os.putenv('LC_ALL', 'en_US.UTF-8')

app = Flask(__name__)
app.config.from_object('config')

shorty_host = config.domain

# MySQL configurations

host = config.host
user = config.user
passwrd = config.passwrd
db = config.db

@app.route('/analytics/<short_url>')
def analytics(short_url):

	info_fetch , counter_fetch , browser_fetch , platform_fetch = list_data(short_url)
	return render_template(""data.html"" , host = shorty_host,info = info_fetch ,counter = counter_fetch ,\
	 browser = browser_fetch , platform = platform_fetch)


@app.route('/' , methods=['GET' , 'POST'])
def index():

	conn = MySQLdb.connect(host , user , passwrd, db)
	cursor = conn.cursor()
	
	# Return the full table to displat on index.
	list_sql = ""SELECT * FROM WEB_URL;""
	cursor.execute(list_sql)
	result_all_fetch = cursor.fetchall()

		
	if request.method == 'POST':
		og_url = request.form.get('url_input')
		custom_suff = request.form.get('url_custom')
		tag_url = request.form.get('url_tag')
		if custom_suff == '':
			token_string =  random_token()
		else:
			token_string = custom_suff
		if og_url != '':
			if url_check(og_url) == True:
				
				# Check's for existing suffix 
				check_row = ""SELECT S_URL FROM WEB_URL WHERE S_URL = %s FOR UPDATE""
				cursor.execute(check_row,(token_string,))
				check_fetch = cursor.fetchone()

				if (check_fetch is None):
					insert_row = """"""
						INSERT INTO WEB_URL(URL , S_URL , TAG) VALUES( %s, %s , %s)
						""""""
					result_cur = cursor.execute(insert_row ,(og_url , token_string , tag_url,))
					conn.commit()
					conn.close()
					e = ''
					return render_template('index.html' ,shorty_url = shorty_host+token_string , error = e )
				else:
					e = ""The Custom suffix already exists . Please use another suffix or leave it blank for random suffix.""
					return render_template('index.html' ,table = result_all_fetch, host = shorty_host,error = e)
			else:
				e = ""URL entered doesn't seem valid , Enter a valid URL.""
				return render_template('index.html' ,table = result_all_fetch, host = shorty_host,error = e)

		else:
			e = ""Enter a URL.""
			return render_template('index.html' , table = result_all_fetch, host = shorty_host,error = e)
	else:	
		e = ''
		return render_template('index.html',table = result_all_fetch ,host = shorty_host, error = e )
	
# Rerouting funciton	

@app.route('/<short_url>')
def reroute(short_url):

	conn = MySQLdb.connect(host , user , passwrd, db)
	cursor = conn.cursor()
	platform = request.user_agent.platform
	browser =  request.user_agent.browser
	counter = 1

	# Platform , Browser vars
	
	browser_dict = {'firefox': 0 , 'chrome':0 , 'safari':0 , 'other':0}
	platform_dict = {'windows':0 , 'iphone':0 , 'android':0 , 'linux':0 , 'macos':0 , 'other':0}

	# Analytics
	if browser in browser_dict:
		browser_dict[browser] += 1
	else:								
		browser_dict['other'] += 1
	
	if platform in platform_dict.iterkeys():
		platform_dict[platform] += 1
	else:
		platform_dict['other'] += 1
			
	cursor.execute(""SELECT URL FROM WEB_URL WHERE S_URL = %s;"" ,(short_url,) )

	try:
		new_url = cursor.fetchone()[0]
		print new_url
		# Update Counters 
		
		counter_sql = ""\
				UPDATE {tn} SET COUNTER = COUNTER + {og_counter} , CHROME = CHROME + {og_chrome} , FIREFOX = FIREFOX+{og_firefox} ,\
				SAFARI = SAFARI+{og_safari} , OTHER_BROWSER =OTHER_BROWSER+ {og_oth_brow} , ANDROID = ANDROID +{og_andr} , IOS = IOS +{og_ios},\
				WINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = %s;"".\
				format(tn = ""WEB_URL"" , og_counter = counter , og_chrome = browser_dict['chrome'] , og_firefox = browser_dict['firefox'],\
				og_safari = browser_dict['safari'] , og_oth_brow = browser_dict['other'] , og_andr = platform_dict['android'] , og_ios = platform_dict['iphone'] ,\
				og_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'])
		res_update = cursor.execute(counter_sql, (short_url, ))
		conn.commit()
		conn.close()

		return redirect(new_url)

	except Exception as e:
		e = ""Something went wrong.Please try again.""
		return render_template('404.html') ,404

# Search results
@app.route('/search' ,  methods=['GET' , 'POST'])
def search():
	s_tag = request.form.get('search_url')
	if s_tag == """":
		return render_template('index.html', error = ""Please enter a search term"")
	else:
		conn = MySQLdb.connect(host , user , passwrd, db)
		cursor = conn.cursor()
		
		search_tag_sql = ""SELECT * FROM WEB_URL WHERE TAG = %s"" 
		cursor.execute(search_tag_sql , (s_tag, ) )
		search_tag_fetch = cursor.fetchall()
		conn.close()
		return render_template('search.html' , host = shorty_host , search_tag = s_tag , table = search_tag_fetch )


@app.after_request
def after_request(response):
	timestamp = strftime('[%Y-%b-%d %H:%M]')
	logger.error('%s %s %s %s %s %s',timestamp , request.remote_addr , \
				request.method , request.scheme , request.full_path , response.status)
	return response


@app.errorhandler(Exception)
def exceptions(e):
	tb = traceback.format_exc()
	timestamp = strftime('[%Y-%b-%d %H:%M]')
	logger.error('%s %s %s %s %s 5xx INTERNAL SERVER ERROR\n%s',
        timestamp, request.remote_addr, request.method,
        request.scheme, request.full_path, tb)
	return make_response(e , 405)

if __name__ == '__main__':

	# Logging handler
	handler = RotatingFileHandler('shorty.log' , maxBytes=100000 , backupCount = 3)
	logger = logging.getLogger('tdm')
	logger.setLevel(logging.ERROR)
	logger.addHandler(handler)
	app.run(host='127.0.0.1' , port=5000)

/n/n/n",0
83,83,071497f90bcf7336c44e135d5ef4bd87898fa8d0,"/app.py/n/n#!/usr/bin/env python2.7

import sys
import os

# Flask Import
from flask import Flask , request , redirect , render_template , url_for 
from flask import jsonify , abort , make_response 
import MySQLdb

# Toekn and URL check import
from check_encode import random_token , url_check
from display_list import list_data

from sql_table import mysql_table

# Config import
import config

# Import Loggers
import logging
from logging.handlers import RotatingFileHandler
from time import strftime
import traceback

# Setting UTF-8 encoding

reload(sys)
sys.setdefaultencoding('UTF-8')
os.putenv('LANG', 'en_US.UTF-8')
os.putenv('LC_ALL', 'en_US.UTF-8')

app = Flask(__name__)
app.config.from_object('config')

shorty_host = config.domain

# MySQL configurations

host = config.host
user = config.user
passwrd = config.passwrd
db = config.db

@app.route('/analytics/<short_url>')
def analytics(short_url):

	info_fetch , counter_fetch , browser_fetch , platform_fetch = list_data(short_url)
	return render_template(""data.html"" , host = shorty_host,info = info_fetch ,counter = counter_fetch ,\
	 browser = browser_fetch , platform = platform_fetch)


@app.route('/' , methods=['GET' , 'POST'])
def index():

	conn = MySQLdb.connect(host , user , passwrd, db)
	cursor = conn.cursor()
	
	# Return the full table to displat on index.
	list_sql = ""SELECT * FROM WEB_URL;""
	cursor.execute(list_sql)
	result_all_fetch = cursor.fetchall()

		
	if request.method == 'POST':
		og_url = request.form.get('url_input')
		custom_suff = request.form.get('url_custom')
		tag_url = request.form.get('url_tag')
		if custom_suff == '':
			token_string =  random_token()
		else:
			token_string = custom_suff
		if og_url != '':
			if url_check(og_url) == True:
				
				# Check's for existing suffix 
				check_row = ""SELECT S_URL FROM WEB_URL WHERE S_URL = %s FOR UPDATE""
				cursor.execute(check_row,(token_string,))
				check_fetch = cursor.fetchone()

				if (check_fetch is None):
					insert_row = """"""
						INSERT INTO WEB_URL(URL , S_URL , TAG) VALUES( %s, %s , %s)
						""""""
					result_cur = cursor.execute(insert_row ,(og_url , token_string , tag_url,))
					conn.commit()
					conn.close()
					e = ''
					return render_template('index.html' ,shorty_url = shorty_host+token_string , error = e )
				else:
					e = ""The Custom suffix already exists . Please use another suffix or leave it blank for random suffix.""
					return render_template('index.html' ,table = result_all_fetch, host = shorty_host,error = e)
			else:
				e = ""URL entered doesn't seem valid , Enter a valid URL.""
				return render_template('index.html' ,table = result_all_fetch, host = shorty_host,error = e)

		else:
			e = ""Enter a URL.""
			return render_template('index.html' , table = result_all_fetch, host = shorty_host,error = e)
	else:	
		e = ''
		return render_template('index.html',table = result_all_fetch ,host = shorty_host, error = e )
	
# Rerouting funciton	

@app.route('/<short_url>')
def reroute(short_url):

	conn = MySQLdb.connect(host , user , passwrd, db)
	cursor = conn.cursor()
	platform = request.user_agent.platform
	browser =  request.user_agent.browser
	counter = 1

	# Platform , Browser vars
	
	browser_dict = {'firefox': 0 , 'chrome':0 , 'safari':0 , 'other':0}
	platform_dict = {'windows':0 , 'iphone':0 , 'android':0 , 'linux':0 , 'macos':0 , 'other':0}

	# Analytics
	if browser in browser_dict:
		browser_dict[browser] += 1
	else:								
		browser_dict['other'] += 1
	
	if platform in platform_dict.iterkeys():
		platform_dict[platform] += 1
	else:
		platform_dict['other'] += 1
			
	cursor.execute(""SELECT URL FROM WEB_URL WHERE S_URL = %s;"" ,(short_url,) )

	try:
		new_url = cursor.fetchone()[0]
		print new_url
		# Update Counters 
		
		counter_sql = ""\
				UPDATE {tn} SET COUNTER = COUNTER + {og_counter} , CHROME = CHROME + {og_chrome} , FIREFOX = FIREFOX+{og_firefox} ,\
				SAFARI = SAFARI+{og_safari} , OTHER_BROWSER =OTHER_BROWSER+ {og_oth_brow} , ANDROID = ANDROID +{og_andr} , IOS = IOS +{og_ios},\
				WINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = '{surl}';"".\
				format(tn = ""WEB_URL"" , og_counter = counter , og_chrome = browser_dict['chrome'] , og_firefox = browser_dict['firefox'],\
				og_safari = browser_dict['safari'] , og_oth_brow = browser_dict['other'] , og_andr = platform_dict['android'] , og_ios = platform_dict['iphone'] ,\
				og_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'] ,\
				surl = short_url)
		res_update = cursor.execute(counter_sql)
		conn.commit()
		conn.close()

		return redirect(new_url)

	except Exception as e:
		e = ""Something went wrong.Please try again.""
		return render_template('404.html') ,404

# Search results
@app.route('/search' ,  methods=['GET' , 'POST'])
def search():
	s_tag = request.form.get('search_url')
	if s_tag == """":
		return render_template('index.html', error = ""Please enter a search term"")
	else:
		conn = MySQLdb.connect(host , user , passwrd, db)
		cursor = conn.cursor()
		
		search_tag_sql = ""SELECT * FROM WEB_URL WHERE TAG = %s"" 
		cursor.execute(search_tag_sql , (s_tag, ) )
		search_tag_fetch = cursor.fetchall()
		conn.close()
		return render_template('search.html' , host = shorty_host , search_tag = s_tag , table = search_tag_fetch )


@app.after_request
def after_request(response):
	timestamp = strftime('[%Y-%b-%d %H:%M]')
	logger.error('%s %s %s %s %s %s',timestamp , request.remote_addr , \
				request.method , request.scheme , request.full_path , response.status)
	return response


@app.errorhandler(Exception)
def exceptions(e):
	tb = traceback.format_exc()
	timestamp = strftime('[%Y-%b-%d %H:%M]')
	logger.error('%s %s %s %s %s 5xx INTERNAL SERVER ERROR\n%s',
        timestamp, request.remote_addr, request.method,
        request.scheme, request.full_path, tb)
	return make_response(e , 405)

if __name__ == '__main__':

	# Logging handler
	handler = RotatingFileHandler('shorty.log' , maxBytes=100000 , backupCount = 3)
	logger = logging.getLogger('tdm')
	logger.setLevel(logging.ERROR)
	logger.addHandler(handler)
	app.run(host='127.0.0.1' , port=5000)

/n/n/n",1
26,26,6ce60806ca8a44d8a8b37050539e2b2f9a54b847,"bandit/plugins/injection_sql.py/n/n# -*- coding:utf-8 -*-
#
# Copyright 2014 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

r""""""
============================
B608: Test for SQL injection
============================

An SQL injection attack consists of insertion or ""injection"" of a SQL query via
the input data given to an application. It is a very common attack vector. This
plugin test looks for strings that resemble SQL statements that are involved in
some form of string building operation. For example:

 - ""SELECT %s FROM derp;"" % var
 - ""SELECT thing FROM "" + tab
 - ""SELECT "" + val + "" FROM "" + tab + ...
 - ""SELECT {} FROM derp;"".format(var)

Unless care is taken to sanitize and control the input data when building such
SQL statement strings, an injection attack becomes possible. If strings of this
nature are discovered, a LOW confidence issue is reported. In order to boost
result confidence, this plugin test will also check to see if the discovered
string is in use with standard Python DBAPI calls `execute` or `executemany`.
If so, a MEDIUM issue is reported. For example:

 - cursor.execute(""SELECT %s FROM derp;"" % var)


:Example:

.. code-block:: none

    >> Issue: Possible SQL injection vector through string-based query
    construction.
       Severity: Medium   Confidence: Low
       Location: ./examples/sql_statements_without_sql_alchemy.py:4
    3 query = ""DELETE FROM foo WHERE id = '%s'"" % identifier
    4 query = ""UPDATE foo SET value = 'b' WHERE id = '%s'"" % identifier
    5

.. seealso::

 - https://www.owasp.org/index.php/SQL_Injection
 - https://security.openstack.org/guidelines/dg_parameterize-database-queries.html  # noqa

.. versionadded:: 0.9.0

""""""

import ast
import re

import bandit
from bandit.core import test_properties as test
from bandit.core import utils

SIMPLE_SQL_RE = re.compile(
    r'(select\s.*from\s|'
    r'delete\s+from\s|'
    r'insert\s+into\s.*values\s|'
    r'update\s.*set\s)',
    re.IGNORECASE | re.DOTALL,
)


def _check_string(data):
    return SIMPLE_SQL_RE.search(data) is not None


def _evaluate_ast(node):
    wrapper = None
    statement = ''

    if isinstance(node.parent, ast.BinOp):
        out = utils.concat_string(node, node.parent)
        wrapper = out[0].parent
        statement = out[1]
    elif (isinstance(node.parent, ast.Attribute)
          and node.parent.attr == 'format'):
        statement = node.s
        # Hierarchy for """".format() is Wrapper -> Call -> Attribute -> Str
        wrapper = node.parent.parent.parent

    if isinstance(wrapper, ast.Call):  # wrapped in ""execute"" call?
        names = ['execute', 'executemany']
        name = utils.get_called_name(wrapper)
        return (name in names, statement)
    else:
        return (False, statement)


@test.checks('Str')
@test.test_id('B608')
def hardcoded_sql_expressions(context):
    val = _evaluate_ast(context.node)
    if _check_string(val[1]):
        return bandit.Issue(
            severity=bandit.MEDIUM,
            confidence=bandit.MEDIUM if val[0] else bandit.LOW,
            text=""Possible SQL injection vector through string-based ""
                 ""query construction.""
        )
/n/n/nexamples/sql_statements.py/n/nimport sqlalchemy

# bad
query = ""SELECT * FROM foo WHERE id = '%s'"" % identifier
query = ""INSERT INTO foo VALUES ('a', 'b', '%s')"" % value
query = ""DELETE FROM foo WHERE id = '%s'"" % identifier
query = ""UPDATE foo SET value = 'b' WHERE id = '%s'"" % identifier
query = """"""WITH cte AS (SELECT x FROM foo)
SELECT x FROM cte WHERE x = '%s'"""""" % identifier
# bad alternate forms
query = ""SELECT * FROM foo WHERE id = '"" + identifier + ""'""
query = ""SELECT * FROM foo WHERE id = '{}'"".format(identifier)

# bad
cur.execute(""SELECT * FROM foo WHERE id = '%s'"" % identifier)
cur.execute(""INSERT INTO foo VALUES ('a', 'b', '%s')"" % value)
cur.execute(""DELETE FROM foo WHERE id = '%s'"" % identifier)
cur.execute(""UPDATE foo SET value = 'b' WHERE id = '%s'"" % identifier)
# bad alternate forms
cur.execute(""SELECT * FROM foo WHERE id = '"" + identifier + ""'"")
cur.execute(""SELECT * FROM foo WHERE id = '{}'"".format(identifier))

# good
cur.execute(""SELECT * FROM foo WHERE id = '%s'"", identifier)
cur.execute(""INSERT INTO foo VALUES ('a', 'b', '%s')"", value)
cur.execute(""DELETE FROM foo WHERE id = '%s'"", identifier)
cur.execute(""UPDATE foo SET value = 'b' WHERE id = '%s'"", identifier)

# bug: https://bugs.launchpad.net/bandit/+bug/1479625
def a():
    def b():
        pass
    return b

a()(""SELECT %s FROM foo"" % val)

# real world false positives
choices=[('server_list', _(""Select from active instances""))]
print(""delete from the cache as the first argument"")
/n/n/ntests/functional/test_functional.py/n/n# -*- coding:utf-8 -*-
#
# Copyright 2014 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

import os

import six
import testtools

from bandit.core import config as b_config
from bandit.core import constants as C
from bandit.core import manager as b_manager
from bandit.core import metrics
from bandit.core import test_set as b_test_set


class FunctionalTests(testtools.TestCase):

    '''Functional tests for bandit test plugins.

    This set of tests runs bandit against each example file in turn
    and records the score returned. This is compared to a known good value.
    When new tests are added to an example the expected result should be
    adjusted to match.
    '''

    def setUp(self):
        super(FunctionalTests, self).setUp()
        # NOTE(tkelsey): bandit is very sensitive to paths, so stitch
        # them up here for the testing environment.
        #
        path = os.path.join(os.getcwd(), 'bandit', 'plugins')
        b_conf = b_config.BanditConfig()
        self.b_mgr = b_manager.BanditManager(b_conf, 'file')
        self.b_mgr.b_conf._settings['plugins_dir'] = path
        self.b_mgr.b_ts = b_test_set.BanditTestSet(config=b_conf)

    def run_example(self, example_script, ignore_nosec=False):
        '''A helper method to run the specified test

        This method runs the test, which populates the self.b_mgr.scores
        value. Call this directly if you need to run a test, but do not
        need to test the resulting scores against specified values.
        :param example_script: Filename of an example script to test
        '''
        path = os.path.join(os.getcwd(), 'examples', example_script)
        self.b_mgr.ignore_nosec = ignore_nosec
        self.b_mgr.discover_files([path], True)
        self.b_mgr.run_tests()

    def check_example(self, example_script, expect, ignore_nosec=False):
        '''A helper method to test the scores for example scripts.

        :param example_script: Filename of an example script to test
        :param expect: dict with expected counts of issue types
        '''
        # reset scores for subsequent calls to check_example
        self.b_mgr.scores = []
        self.run_example(example_script, ignore_nosec=ignore_nosec)
        expected = 0
        result = 0
        for test_scores in self.b_mgr.scores:
            for score_type in test_scores:
                self.assertIn(score_type, expect)
                for rating in expect[score_type]:
                    expected += (
                        expect[score_type][rating] * C.RANKING_VALUES[rating]
                    )
                result += sum(test_scores[score_type])
        self.assertEqual(expected, result)

    def check_metrics(self, example_script, expect):
        '''A helper method to test the metrics being returned.

        :param example_script: Filename of an example script to test
        :param expect: dict with expected values of metrics
        '''
        self.b_mgr.metrics = metrics.Metrics()
        self.b_mgr.scores = []
        self.run_example(example_script)

        # test general metrics (excludes issue counts)
        m = self.b_mgr.metrics.data
        for k in expect:
            if k != 'issues':
                self.assertEqual(expect[k], m['_totals'][k])
        # test issue counts
        if 'issues' in expect:
            for (criteria, default) in C.CRITERIA:
                for rank in C.RANKING:
                    label = '{0}.{1}'.format(criteria, rank)
                    expected = 0
                    if expect['issues'].get(criteria, None).get(rank, None):
                        expected = expect['issues'][criteria][rank]
                    self.assertEqual(expected, m['_totals'][label])

    def test_binding(self):
        '''Test the bind-to-0.0.0.0 example.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'MEDIUM': 1}}
        self.check_example('binding.py', expect)

    def test_crypto_md5(self):
        '''Test the `hashlib.md5` example.'''
        expect = {'SEVERITY': {'MEDIUM': 11},
                  'CONFIDENCE': {'HIGH': 11}}
        self.check_example('crypto-md5.py', expect)

    def test_ciphers(self):
        '''Test the `Crypto.Cipher` example.'''
        expect = {'SEVERITY': {'HIGH': 13},
                  'CONFIDENCE': {'HIGH': 13}}
        self.check_example('ciphers.py', expect)

    def test_cipher_modes(self):
        '''Test for insecure cipher modes.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('cipher-modes.py', expect)

    def test_eval(self):
        '''Test the `eval` example.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('eval.py', expect)

    def test_mark_safe(self):
        '''Test the `mark_safe` example.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('mark_safe.py', expect)

    def test_exec(self):
        '''Test the `exec` example.'''
        filename = 'exec-{}.py'
        if six.PY2:
            filename = filename.format('py2')
            expect = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'HIGH': 2}}
        else:
            filename = filename.format('py3')
            expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example(filename, expect)

    def test_exec_as_root(self):
        '''Test for the `run_as_root=True` keyword argument.'''
        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'MEDIUM': 5}}
        self.check_example('exec-as-root.py', expect)

    def test_hardcoded_passwords(self):
        '''Test for hard-coded passwords.'''
        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'MEDIUM': 7}}
        self.check_example('hardcoded-passwords.py', expect)

    def test_hardcoded_tmp(self):
        '''Test for hard-coded /tmp, /var/tmp, /dev/shm.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'MEDIUM': 3}}
        self.check_example('hardcoded-tmp.py', expect)

    def test_httplib_https(self):
        '''Test for `httplib.HTTPSConnection`.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('httplib_https.py', expect)

    def test_imports_aliases(self):
        '''Test the `import X as Y` syntax.'''
        expect = {
            'SEVERITY': {'LOW': 4, 'MEDIUM': 5, 'HIGH': 0},
            'CONFIDENCE': {'HIGH': 9}
        }
        self.check_example('imports-aliases.py', expect)

    def test_imports_from(self):
        '''Test the `from X import Y` syntax.'''
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('imports-from.py', expect)

    def test_imports_function(self):
        '''Test the `__import__` function.'''
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('imports-function.py', expect)

    def test_telnet_usage(self):
        '''Test for `import telnetlib` and Telnet.* calls.'''
        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('telnetlib.py', expect)

    def test_ftp_usage(self):
        '''Test for `import ftplib` and FTP.* calls.'''
        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('ftplib.py', expect)

    def test_imports(self):
        '''Test for dangerous imports.'''
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('imports.py', expect)

    def test_mktemp(self):
        '''Test for `tempfile.mktemp`.'''
        expect = {'SEVERITY': {'MEDIUM': 4}, 'CONFIDENCE': {'HIGH': 4}}
        self.check_example('mktemp.py', expect)

    def test_nonsense(self):
        '''Test that a syntactically invalid module is skipped.'''
        self.run_example('nonsense.py')
        self.assertEqual(1, len(self.b_mgr.skipped))

    def test_okay(self):
        '''Test a vulnerability-free file.'''
        expect = {'SEVERITY': {}, 'CONFIDENCE': {}}
        self.check_example('okay.py', expect)

    def test_os_chmod(self):
        '''Test setting file permissions.'''
        filename = 'os-chmod-{}.py'
        if six.PY2:
            filename = filename.format('py2')
        else:
            filename = filename.format('py3')
        expect = {
            'SEVERITY': {'MEDIUM': 2, 'HIGH': 8},
            'CONFIDENCE': {'MEDIUM': 1, 'HIGH': 9}
        }
        self.check_example(filename, expect)

    def test_os_exec(self):
        '''Test for `os.exec*`.'''
        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}
        self.check_example('os-exec.py', expect)

    def test_os_popen(self):
        '''Test for `os.popen`.'''
        expect = {'SEVERITY': {'LOW': 8, 'MEDIUM': 0, 'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 9}}
        self.check_example('os-popen.py', expect)

    def test_os_spawn(self):
        '''Test for `os.spawn*`.'''
        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}
        self.check_example('os-spawn.py', expect)

    def test_os_startfile(self):
        '''Test for `os.startfile`.'''
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'MEDIUM': 3}}
        self.check_example('os-startfile.py', expect)

    def test_os_system(self):
        '''Test for `os.system`.'''
        expect = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('os_system.py', expect)

    def test_pickle(self):
        '''Test for the `pickle` module.'''
        expect = {
            'SEVERITY': {'LOW': 2, 'MEDIUM': 6},
            'CONFIDENCE': {'HIGH': 8}
        }
        self.check_example('pickle_deserialize.py', expect)

    def test_popen_wrappers(self):
        '''Test the `popen2` and `commands` modules.'''
        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}
        self.check_example('popen_wrappers.py', expect)

    def test_random_module(self):
        '''Test for the `random` module.'''
        expect = {'SEVERITY': {'LOW': 6}, 'CONFIDENCE': {'HIGH': 6}}
        self.check_example('random_module.py', expect)

    def test_requests_ssl_verify_disabled(self):
        '''Test for the `requests` library skipping verification.'''
        expect = {'SEVERITY': {'HIGH': 7}, 'CONFIDENCE': {'HIGH': 7}}
        self.check_example('requests-ssl-verify-disabled.py', expect)

    def test_skip(self):
        '''Test `#nosec` and `#noqa` comments.'''
        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'HIGH': 5}}
        self.check_example('skip.py', expect)

    def test_ignore_skip(self):
        '''Test --ignore-nosec flag.'''
        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}
        self.check_example('skip.py', expect, ignore_nosec=True)

    def test_sql_statements(self):
        '''Test for SQL injection through string building.'''
        expect = {
            'SEVERITY': {'MEDIUM': 14},
            'CONFIDENCE': {'LOW': 8, 'MEDIUM': 6}}
        self.check_example('sql_statements.py', expect)

    def test_ssl_insecure_version(self):
        '''Test for insecure SSL protocol versions.'''
        expect = {
            'SEVERITY': {'LOW': 1, 'MEDIUM': 10, 'HIGH': 7},
            'CONFIDENCE': {'LOW': 0, 'MEDIUM': 11, 'HIGH': 7}
        }
        self.check_example('ssl-insecure-version.py', expect)

    def test_subprocess_shell(self):
        '''Test for `subprocess.Popen` with `shell=True`.'''
        expect = {
            'SEVERITY': {'HIGH': 3, 'MEDIUM': 1, 'LOW': 14},
            'CONFIDENCE': {'HIGH': 17, 'LOW': 1}
        }
        self.check_example('subprocess_shell.py', expect)

    def test_urlopen(self):
        '''Test for dangerous URL opening.'''
        expect = {'SEVERITY': {'MEDIUM': 14}, 'CONFIDENCE': {'HIGH': 14}}
        self.check_example('urlopen.py', expect)

    def test_utils_shell(self):
        '''Test for `utils.execute*` with `shell=True`.'''
        expect = {
            'SEVERITY': {'LOW': 5},
            'CONFIDENCE': {'HIGH': 5}
        }
        self.check_example('utils-shell.py', expect)

    def test_wildcard_injection(self):
        '''Test for wildcard injection in shell commands.'''
        expect = {
            'SEVERITY': {'HIGH': 4, 'MEDIUM': 0, 'LOW': 10},
            'CONFIDENCE': {'MEDIUM': 5, 'HIGH': 9}
        }
        self.check_example('wildcard-injection.py', expect)

    def test_yaml(self):
        '''Test for `yaml.load`.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('yaml_load.py', expect)

    def test_jinja2_templating(self):
        '''Test jinja templating for potential XSS bugs.'''
        expect = {
            'SEVERITY': {'HIGH': 4},
            'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}
        }
        self.check_example('jinja2_templating.py', expect)

    def test_secret_config_option(self):
        '''Test for `secret=True` in Oslo's config.'''
        expect = {
            'SEVERITY': {'LOW': 1, 'MEDIUM': 2},
            'CONFIDENCE': {'MEDIUM': 3}
        }
        self.check_example('secret-config-option.py', expect)

    def test_mako_templating(self):
        '''Test Mako templates for XSS.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('mako_templating.py', expect)

    def test_xml(self):
        '''Test xml vulnerabilities.'''
        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}
        self.check_example('xml_etree_celementtree.py', expect)

        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 2},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 2}}
        self.check_example('xml_expatbuilder.py', expect)

        expect = {'SEVERITY': {'LOW': 3, 'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}}
        self.check_example('xml_lxml.py', expect)

        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},
                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}
        self.check_example('xml_pulldom.py', expect)

        expect = {'SEVERITY': {'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 1}}
        self.check_example('xml_xmlrpc.py', expect)

        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}
        self.check_example('xml_etree_elementtree.py', expect)

        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 1}}
        self.check_example('xml_expatreader.py', expect)

        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},
                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}
        self.check_example('xml_minidom.py', expect)

        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 6},
                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 6}}
        self.check_example('xml_sax.py', expect)

    def test_httpoxy(self):
        '''Test httpoxy vulnerability.'''
        expect = {'SEVERITY': {'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 1}}
        self.check_example('httpoxy_cgihandler.py', expect)
        self.check_example('httpoxy_twisted_script.py', expect)
        self.check_example('httpoxy_twisted_directory.py', expect)

    def test_asserts(self):
        '''Test catching the use of assert.'''
        expect = {'SEVERITY': {'LOW': 1},
                  'CONFIDENCE': {'HIGH': 1}}
        self.check_example('assert.py', expect)

    def test_paramiko_injection(self):
        '''Test paramiko command execution.'''
        expect = {'SEVERITY': {'MEDIUM': 2},
                  'CONFIDENCE': {'MEDIUM': 2}}
        self.check_example('paramiko_injection.py', expect)

    def test_partial_path(self):
        '''Test process spawning with partial file paths.'''
        expect = {'SEVERITY': {'LOW': 11},
                  'CONFIDENCE': {'HIGH': 11}}

        self.check_example('partial_path_process.py', expect)

    def test_try_except_continue(self):
        '''Test try, except, continue detection.'''
        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']
                    if x.__name__ == 'try_except_continue'))

        test._config = {'check_typed_exception': True}
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('try_except_continue.py', expect)

        test._config = {'check_typed_exception': False}
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('try_except_continue.py', expect)

    def test_try_except_pass(self):
        '''Test try, except pass detection.'''
        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']
                     if x.__name__ == 'try_except_pass'))

        test._config = {'check_typed_exception': True}
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('try_except_pass.py', expect)

        test._config = {'check_typed_exception': False}
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('try_except_pass.py', expect)

    def test_metric_gathering(self):
        expect = {
            'nosec': 2, 'loc': 7,
            'issues': {'CONFIDENCE': {'HIGH': 5}, 'SEVERITY': {'LOW': 5}}
        }
        self.check_metrics('skip.py', expect)
        expect = {
            'nosec': 0, 'loc': 4,
            'issues': {'CONFIDENCE': {'HIGH': 2}, 'SEVERITY': {'LOW': 2}}
        }
        self.check_metrics('imports.py', expect)

    def test_weak_cryptographic_key(self):
        '''Test for weak key sizes.'''
        expect = {
            'SEVERITY': {'MEDIUM': 8, 'HIGH': 6},
            'CONFIDENCE': {'HIGH': 14}
        }
        self.check_example('weak_cryptographic_key_sizes.py', expect)

    def test_multiline_code(self):
        '''Test issues in multiline statements return code as expected.'''
        self.run_example('multiline_statement.py')
        self.assertEqual(0, len(self.b_mgr.skipped))
        self.assertEqual(1, len(self.b_mgr.files_list))
        self.assertTrue(self.b_mgr.files_list[0].endswith(
                        'multiline_statement.py'))

        issues = self.b_mgr.get_issue_list()
        self.assertEqual(2, len(issues))
        self.assertTrue(
            issues[0].fname.endswith('examples/multiline_statement.py')
        )

        self.assertEqual(1, issues[0].lineno)
        self.assertEqual(list(range(1, 3)), issues[0].linerange)
        self.assertIn('subprocess', issues[0].get_code())
        self.assertEqual(5, issues[1].lineno)
        self.assertEqual(list(range(3, 6 + 1)), issues[1].linerange)
        self.assertIn('shell=True', issues[1].get_code())

    def test_code_line_numbers(self):
        self.run_example('binding.py')
        issues = self.b_mgr.get_issue_list()

        code_lines = issues[0].get_code().splitlines()
        lineno = issues[0].lineno
        self.assertEqual(""%i "" % (lineno - 1), code_lines[0][:2])
        self.assertEqual(""%i "" % (lineno), code_lines[1][:2])
        self.assertEqual(""%i "" % (lineno + 1), code_lines[2][:2])

    def test_flask_debug_true(self):
        expect = {
            'SEVERITY': {'HIGH': 1},
            'CONFIDENCE': {'MEDIUM': 1}
        }
        self.check_example('flask_debug.py', expect)

    def test_nosec(self):
        expect = {
            'SEVERITY': {},
            'CONFIDENCE': {}
        }
        self.check_example('nosec.py', expect)

    def test_baseline_filter(self):
        issue_text = ('A Flask app appears to be run with debug=True, which '
                      'exposes the Werkzeug debugger and allows the execution '
                      'of arbitrary code.')
        json = """"""{
          ""results"": [
            {
              ""code"": ""..."",
              ""filename"": ""%s/examples/flask_debug.py"",
              ""issue_confidence"": ""MEDIUM"",
              ""issue_severity"": ""HIGH"",
              ""issue_text"": ""%s"",
              ""line_number"": 10,
              ""line_range"": [
                10
              ],
              ""test_name"": ""flask_debug_true"",
              ""test_id"": ""B201""
            }
          ]
        }
        """""" % (os.getcwd(), issue_text)

        self.b_mgr.populate_baseline(json)
        self.run_example('flask_debug.py')
        self.assertEqual(1, len(self.b_mgr.baseline))
        self.assertEqual({}, self.b_mgr.get_issue_list())

    def test_blacklist_input(self):
        expect = {
            'SEVERITY': {'HIGH': 1},
            'CONFIDENCE': {'HIGH': 1}
        }
        self.check_example('input.py', expect)
/n/n/n",0
27,27,6ce60806ca8a44d8a8b37050539e2b2f9a54b847,"/examples/sql_statements.py/n/nimport sqlalchemy

# bad
query = ""SELECT * FROM foo WHERE id = '%s'"" % identifier
query = ""INSERT INTO foo VALUES ('a', 'b', '%s')"" % value
query = ""DELETE FROM foo WHERE id = '%s'"" % identifier
query = ""UPDATE foo SET value = 'b' WHERE id = '%s'"" % identifier
query = """"""WITH cte AS (SELECT x FROM foo)
SELECT x FROM cte WHERE x = '%s'"""""" % identifier

# bad
cur.execute(""SELECT * FROM foo WHERE id = '%s'"" % identifier)
cur.execute(""INSERT INTO foo VALUES ('a', 'b', '%s')"" % value)
cur.execute(""DELETE FROM foo WHERE id = '%s'"" % identifier)
cur.execute(""UPDATE foo SET value = 'b' WHERE id = '%s'"" % identifier)

# good
cur.execute(""SELECT * FROM foo WHERE id = '%s'"", identifier)
cur.execute(""INSERT INTO foo VALUES ('a', 'b', '%s')"", value)
cur.execute(""DELETE FROM foo WHERE id = '%s'"", identifier)
cur.execute(""UPDATE foo SET value = 'b' WHERE id = '%s'"", identifier)

# bad
query = ""SELECT "" + val + "" FROM "" + val +"" WHERE id = "" + val

# bad
cur.execute(""SELECT "" + val + "" FROM "" + val +"" WHERE id = "" + val)


# bug: https://bugs.launchpad.net/bandit/+bug/1479625
def a():
    def b():
        pass
    return b

a()(""SELECT %s FROM foo"" % val)

# real world false positives
choices=[('server_list', _(""Select from active instances""))]
print(""delete from the cache as the first argument"")
/n/n/n/tests/functional/test_functional.py/n/n# -*- coding:utf-8 -*-
#
# Copyright 2014 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the ""License""); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

import os

import six
import testtools

from bandit.core import config as b_config
from bandit.core import constants as C
from bandit.core import manager as b_manager
from bandit.core import metrics
from bandit.core import test_set as b_test_set


class FunctionalTests(testtools.TestCase):

    '''Functional tests for bandit test plugins.

    This set of tests runs bandit against each example file in turn
    and records the score returned. This is compared to a known good value.
    When new tests are added to an example the expected result should be
    adjusted to match.
    '''

    def setUp(self):
        super(FunctionalTests, self).setUp()
        # NOTE(tkelsey): bandit is very sensitive to paths, so stitch
        # them up here for the testing environment.
        #
        path = os.path.join(os.getcwd(), 'bandit', 'plugins')
        b_conf = b_config.BanditConfig()
        self.b_mgr = b_manager.BanditManager(b_conf, 'file')
        self.b_mgr.b_conf._settings['plugins_dir'] = path
        self.b_mgr.b_ts = b_test_set.BanditTestSet(config=b_conf)

    def run_example(self, example_script, ignore_nosec=False):
        '''A helper method to run the specified test

        This method runs the test, which populates the self.b_mgr.scores
        value. Call this directly if you need to run a test, but do not
        need to test the resulting scores against specified values.
        :param example_script: Filename of an example script to test
        '''
        path = os.path.join(os.getcwd(), 'examples', example_script)
        self.b_mgr.ignore_nosec = ignore_nosec
        self.b_mgr.discover_files([path], True)
        self.b_mgr.run_tests()

    def check_example(self, example_script, expect, ignore_nosec=False):
        '''A helper method to test the scores for example scripts.

        :param example_script: Filename of an example script to test
        :param expect: dict with expected counts of issue types
        '''
        # reset scores for subsequent calls to check_example
        self.b_mgr.scores = []
        self.run_example(example_script, ignore_nosec=ignore_nosec)
        expected = 0
        result = 0
        for test_scores in self.b_mgr.scores:
            for score_type in test_scores:
                self.assertIn(score_type, expect)
                for rating in expect[score_type]:
                    expected += (
                        expect[score_type][rating] * C.RANKING_VALUES[rating]
                    )
                result += sum(test_scores[score_type])
        self.assertEqual(expected, result)

    def check_metrics(self, example_script, expect):
        '''A helper method to test the metrics being returned.

        :param example_script: Filename of an example script to test
        :param expect: dict with expected values of metrics
        '''
        self.b_mgr.metrics = metrics.Metrics()
        self.b_mgr.scores = []
        self.run_example(example_script)

        # test general metrics (excludes issue counts)
        m = self.b_mgr.metrics.data
        for k in expect:
            if k != 'issues':
                self.assertEqual(expect[k], m['_totals'][k])
        # test issue counts
        if 'issues' in expect:
            for (criteria, default) in C.CRITERIA:
                for rank in C.RANKING:
                    label = '{0}.{1}'.format(criteria, rank)
                    expected = 0
                    if expect['issues'].get(criteria, None).get(rank, None):
                        expected = expect['issues'][criteria][rank]
                    self.assertEqual(expected, m['_totals'][label])

    def test_binding(self):
        '''Test the bind-to-0.0.0.0 example.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'MEDIUM': 1}}
        self.check_example('binding.py', expect)

    def test_crypto_md5(self):
        '''Test the `hashlib.md5` example.'''
        expect = {'SEVERITY': {'MEDIUM': 11},
                  'CONFIDENCE': {'HIGH': 11}}
        self.check_example('crypto-md5.py', expect)

    def test_ciphers(self):
        '''Test the `Crypto.Cipher` example.'''
        expect = {'SEVERITY': {'HIGH': 13},
                  'CONFIDENCE': {'HIGH': 13}}
        self.check_example('ciphers.py', expect)

    def test_cipher_modes(self):
        '''Test for insecure cipher modes.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('cipher-modes.py', expect)

    def test_eval(self):
        '''Test the `eval` example.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('eval.py', expect)

    def test_mark_safe(self):
        '''Test the `mark_safe` example.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('mark_safe.py', expect)

    def test_exec(self):
        '''Test the `exec` example.'''
        filename = 'exec-{}.py'
        if six.PY2:
            filename = filename.format('py2')
            expect = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'HIGH': 2}}
        else:
            filename = filename.format('py3')
            expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example(filename, expect)

    def test_exec_as_root(self):
        '''Test for the `run_as_root=True` keyword argument.'''
        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'MEDIUM': 5}}
        self.check_example('exec-as-root.py', expect)

    def test_hardcoded_passwords(self):
        '''Test for hard-coded passwords.'''
        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'MEDIUM': 7}}
        self.check_example('hardcoded-passwords.py', expect)

    def test_hardcoded_tmp(self):
        '''Test for hard-coded /tmp, /var/tmp, /dev/shm.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'MEDIUM': 3}}
        self.check_example('hardcoded-tmp.py', expect)

    def test_httplib_https(self):
        '''Test for `httplib.HTTPSConnection`.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('httplib_https.py', expect)

    def test_imports_aliases(self):
        '''Test the `import X as Y` syntax.'''
        expect = {
            'SEVERITY': {'LOW': 4, 'MEDIUM': 5, 'HIGH': 0},
            'CONFIDENCE': {'HIGH': 9}
        }
        self.check_example('imports-aliases.py', expect)

    def test_imports_from(self):
        '''Test the `from X import Y` syntax.'''
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('imports-from.py', expect)

    def test_imports_function(self):
        '''Test the `__import__` function.'''
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('imports-function.py', expect)

    def test_telnet_usage(self):
        '''Test for `import telnetlib` and Telnet.* calls.'''
        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('telnetlib.py', expect)

    def test_ftp_usage(self):
        '''Test for `import ftplib` and FTP.* calls.'''
        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('ftplib.py', expect)

    def test_imports(self):
        '''Test for dangerous imports.'''
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('imports.py', expect)

    def test_mktemp(self):
        '''Test for `tempfile.mktemp`.'''
        expect = {'SEVERITY': {'MEDIUM': 4}, 'CONFIDENCE': {'HIGH': 4}}
        self.check_example('mktemp.py', expect)

    def test_nonsense(self):
        '''Test that a syntactically invalid module is skipped.'''
        self.run_example('nonsense.py')
        self.assertEqual(1, len(self.b_mgr.skipped))

    def test_okay(self):
        '''Test a vulnerability-free file.'''
        expect = {'SEVERITY': {}, 'CONFIDENCE': {}}
        self.check_example('okay.py', expect)

    def test_os_chmod(self):
        '''Test setting file permissions.'''
        filename = 'os-chmod-{}.py'
        if six.PY2:
            filename = filename.format('py2')
        else:
            filename = filename.format('py3')
        expect = {
            'SEVERITY': {'MEDIUM': 2, 'HIGH': 8},
            'CONFIDENCE': {'MEDIUM': 1, 'HIGH': 9}
        }
        self.check_example(filename, expect)

    def test_os_exec(self):
        '''Test for `os.exec*`.'''
        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}
        self.check_example('os-exec.py', expect)

    def test_os_popen(self):
        '''Test for `os.popen`.'''
        expect = {'SEVERITY': {'LOW': 8, 'MEDIUM': 0, 'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 9}}
        self.check_example('os-popen.py', expect)

    def test_os_spawn(self):
        '''Test for `os.spawn*`.'''
        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}
        self.check_example('os-spawn.py', expect)

    def test_os_startfile(self):
        '''Test for `os.startfile`.'''
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'MEDIUM': 3}}
        self.check_example('os-startfile.py', expect)

    def test_os_system(self):
        '''Test for `os.system`.'''
        expect = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('os_system.py', expect)

    def test_pickle(self):
        '''Test for the `pickle` module.'''
        expect = {
            'SEVERITY': {'LOW': 2, 'MEDIUM': 6},
            'CONFIDENCE': {'HIGH': 8}
        }
        self.check_example('pickle_deserialize.py', expect)

    def test_popen_wrappers(self):
        '''Test the `popen2` and `commands` modules.'''
        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}
        self.check_example('popen_wrappers.py', expect)

    def test_random_module(self):
        '''Test for the `random` module.'''
        expect = {'SEVERITY': {'LOW': 6}, 'CONFIDENCE': {'HIGH': 6}}
        self.check_example('random_module.py', expect)

    def test_requests_ssl_verify_disabled(self):
        '''Test for the `requests` library skipping verification.'''
        expect = {'SEVERITY': {'HIGH': 7}, 'CONFIDENCE': {'HIGH': 7}}
        self.check_example('requests-ssl-verify-disabled.py', expect)

    def test_skip(self):
        '''Test `#nosec` and `#noqa` comments.'''
        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'HIGH': 5}}
        self.check_example('skip.py', expect)

    def test_ignore_skip(self):
        '''Test --ignore-nosec flag.'''
        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}
        self.check_example('skip.py', expect, ignore_nosec=True)

    def test_sql_statements(self):
        '''Test for SQL injection through string building.'''
        expect = {
            'SEVERITY': {'MEDIUM': 12},
            'CONFIDENCE': {'LOW': 7, 'MEDIUM': 5}}
        self.check_example('sql_statements.py', expect)

    def test_ssl_insecure_version(self):
        '''Test for insecure SSL protocol versions.'''
        expect = {
            'SEVERITY': {'LOW': 1, 'MEDIUM': 10, 'HIGH': 7},
            'CONFIDENCE': {'LOW': 0, 'MEDIUM': 11, 'HIGH': 7}
        }
        self.check_example('ssl-insecure-version.py', expect)

    def test_subprocess_shell(self):
        '''Test for `subprocess.Popen` with `shell=True`.'''
        expect = {
            'SEVERITY': {'HIGH': 3, 'MEDIUM': 1, 'LOW': 14},
            'CONFIDENCE': {'HIGH': 17, 'LOW': 1}
        }
        self.check_example('subprocess_shell.py', expect)

    def test_urlopen(self):
        '''Test for dangerous URL opening.'''
        expect = {'SEVERITY': {'MEDIUM': 14}, 'CONFIDENCE': {'HIGH': 14}}
        self.check_example('urlopen.py', expect)

    def test_utils_shell(self):
        '''Test for `utils.execute*` with `shell=True`.'''
        expect = {
            'SEVERITY': {'LOW': 5},
            'CONFIDENCE': {'HIGH': 5}
        }
        self.check_example('utils-shell.py', expect)

    def test_wildcard_injection(self):
        '''Test for wildcard injection in shell commands.'''
        expect = {
            'SEVERITY': {'HIGH': 4, 'MEDIUM': 0, 'LOW': 10},
            'CONFIDENCE': {'MEDIUM': 5, 'HIGH': 9}
        }
        self.check_example('wildcard-injection.py', expect)

    def test_yaml(self):
        '''Test for `yaml.load`.'''
        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}
        self.check_example('yaml_load.py', expect)

    def test_jinja2_templating(self):
        '''Test jinja templating for potential XSS bugs.'''
        expect = {
            'SEVERITY': {'HIGH': 4},
            'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}
        }
        self.check_example('jinja2_templating.py', expect)

    def test_secret_config_option(self):
        '''Test for `secret=True` in Oslo's config.'''
        expect = {
            'SEVERITY': {'LOW': 1, 'MEDIUM': 2},
            'CONFIDENCE': {'MEDIUM': 3}
        }
        self.check_example('secret-config-option.py', expect)

    def test_mako_templating(self):
        '''Test Mako templates for XSS.'''
        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('mako_templating.py', expect)

    def test_xml(self):
        '''Test xml vulnerabilities.'''
        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}
        self.check_example('xml_etree_celementtree.py', expect)

        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 2},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 2}}
        self.check_example('xml_expatbuilder.py', expect)

        expect = {'SEVERITY': {'LOW': 3, 'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}}
        self.check_example('xml_lxml.py', expect)

        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},
                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}
        self.check_example('xml_pulldom.py', expect)

        expect = {'SEVERITY': {'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 1}}
        self.check_example('xml_xmlrpc.py', expect)

        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}
        self.check_example('xml_etree_elementtree.py', expect)

        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 1}}
        self.check_example('xml_expatreader.py', expect)

        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},
                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}
        self.check_example('xml_minidom.py', expect)

        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 6},
                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 6}}
        self.check_example('xml_sax.py', expect)

    def test_httpoxy(self):
        '''Test httpoxy vulnerability.'''
        expect = {'SEVERITY': {'HIGH': 1},
                  'CONFIDENCE': {'HIGH': 1}}
        self.check_example('httpoxy_cgihandler.py', expect)
        self.check_example('httpoxy_twisted_script.py', expect)
        self.check_example('httpoxy_twisted_directory.py', expect)

    def test_asserts(self):
        '''Test catching the use of assert.'''
        expect = {'SEVERITY': {'LOW': 1},
                  'CONFIDENCE': {'HIGH': 1}}
        self.check_example('assert.py', expect)

    def test_paramiko_injection(self):
        '''Test paramiko command execution.'''
        expect = {'SEVERITY': {'MEDIUM': 2},
                  'CONFIDENCE': {'MEDIUM': 2}}
        self.check_example('paramiko_injection.py', expect)

    def test_partial_path(self):
        '''Test process spawning with partial file paths.'''
        expect = {'SEVERITY': {'LOW': 11},
                  'CONFIDENCE': {'HIGH': 11}}

        self.check_example('partial_path_process.py', expect)

    def test_try_except_continue(self):
        '''Test try, except, continue detection.'''
        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']
                    if x.__name__ == 'try_except_continue'))

        test._config = {'check_typed_exception': True}
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('try_except_continue.py', expect)

        test._config = {'check_typed_exception': False}
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('try_except_continue.py', expect)

    def test_try_except_pass(self):
        '''Test try, except pass detection.'''
        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']
                     if x.__name__ == 'try_except_pass'))

        test._config = {'check_typed_exception': True}
        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}
        self.check_example('try_except_pass.py', expect)

        test._config = {'check_typed_exception': False}
        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}
        self.check_example('try_except_pass.py', expect)

    def test_metric_gathering(self):
        expect = {
            'nosec': 2, 'loc': 7,
            'issues': {'CONFIDENCE': {'HIGH': 5}, 'SEVERITY': {'LOW': 5}}
        }
        self.check_metrics('skip.py', expect)
        expect = {
            'nosec': 0, 'loc': 4,
            'issues': {'CONFIDENCE': {'HIGH': 2}, 'SEVERITY': {'LOW': 2}}
        }
        self.check_metrics('imports.py', expect)

    def test_weak_cryptographic_key(self):
        '''Test for weak key sizes.'''
        expect = {
            'SEVERITY': {'MEDIUM': 8, 'HIGH': 6},
            'CONFIDENCE': {'HIGH': 14}
        }
        self.check_example('weak_cryptographic_key_sizes.py', expect)

    def test_multiline_code(self):
        '''Test issues in multiline statements return code as expected.'''
        self.run_example('multiline_statement.py')
        self.assertEqual(0, len(self.b_mgr.skipped))
        self.assertEqual(1, len(self.b_mgr.files_list))
        self.assertTrue(self.b_mgr.files_list[0].endswith(
                        'multiline_statement.py'))

        issues = self.b_mgr.get_issue_list()
        self.assertEqual(2, len(issues))
        self.assertTrue(
            issues[0].fname.endswith('examples/multiline_statement.py')
        )

        self.assertEqual(1, issues[0].lineno)
        self.assertEqual(list(range(1, 3)), issues[0].linerange)
        self.assertIn('subprocess', issues[0].get_code())
        self.assertEqual(5, issues[1].lineno)
        self.assertEqual(list(range(3, 6 + 1)), issues[1].linerange)
        self.assertIn('shell=True', issues[1].get_code())

    def test_code_line_numbers(self):
        self.run_example('binding.py')
        issues = self.b_mgr.get_issue_list()

        code_lines = issues[0].get_code().splitlines()
        lineno = issues[0].lineno
        self.assertEqual(""%i "" % (lineno - 1), code_lines[0][:2])
        self.assertEqual(""%i "" % (lineno), code_lines[1][:2])
        self.assertEqual(""%i "" % (lineno + 1), code_lines[2][:2])

    def test_flask_debug_true(self):
        expect = {
            'SEVERITY': {'HIGH': 1},
            'CONFIDENCE': {'MEDIUM': 1}
        }
        self.check_example('flask_debug.py', expect)

    def test_nosec(self):
        expect = {
            'SEVERITY': {},
            'CONFIDENCE': {}
        }
        self.check_example('nosec.py', expect)

    def test_baseline_filter(self):
        issue_text = ('A Flask app appears to be run with debug=True, which '
                      'exposes the Werkzeug debugger and allows the execution '
                      'of arbitrary code.')
        json = """"""{
          ""results"": [
            {
              ""code"": ""..."",
              ""filename"": ""%s/examples/flask_debug.py"",
              ""issue_confidence"": ""MEDIUM"",
              ""issue_severity"": ""HIGH"",
              ""issue_text"": ""%s"",
              ""line_number"": 10,
              ""line_range"": [
                10
              ],
              ""test_name"": ""flask_debug_true"",
              ""test_id"": ""B201""
            }
          ]
        }
        """""" % (os.getcwd(), issue_text)

        self.b_mgr.populate_baseline(json)
        self.run_example('flask_debug.py')
        self.assertEqual(1, len(self.b_mgr.baseline))
        self.assertEqual({}, self.b_mgr.get_issue_list())

    def test_blacklist_input(self):
        expect = {
            'SEVERITY': {'HIGH': 1},
            'CONFIDENCE': {'HIGH': 1}
        }
        self.check_example('input.py', expect)
/n/n/n",1
38,38,b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c,"addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _

class pos_close_statement(osv.osv_memory):
    _name = 'pos.close.statement'
    _description = 'Close Statements'

    def close_statement(self, cr, uid, ids, context):
        """"""
             Close the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Dictionary
        """"""
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        statement_obj = self.pool.get('account.bank.statement')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if not ids:
                raise osv.except_osv(_('Message'), _('Journals are already closed'))
            else:
                list_statement.append(ids[0])
                if not journal.check_dtls:
                    statement_obj.button_confirm_cash(cr, uid, ids, context)

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id
        return {
                'domain': ""[('id','in',"" + str(list_statement) + "")]"",
                'name': 'Close Statements',
                'view_type': 'form',
                'view_mode': 'tree,form',
                'res_model': 'account.bank.statement',
                'views': [(id2, 'tree'),(id3, 'form')],
                'type': 'ir.actions.act_window'}

pos_close_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/naddons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _
import time

class pos_open_statement(osv.osv_memory):
    _name = 'pos.open.statement'
    _description = 'Open Statements'

    def open_statement(self, cr, uid, ids, context):
        """"""
             Open the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Directory
        """"""
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        statement_obj = self.pool.get('account.bank.statement')
        sequence_obj = self.pool.get('ir.sequence')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if len(ids):
                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for ""%s"". \n Please close the cashbox related to. ' %(journal.name)))
            
            number = ''
            if journal.sequence_id:
                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)
            else:
                number = sequence_obj.get(cr, uid, 'account.bank.statement')
            
            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,
                                                          'company_id': company_id,
                                                          'user_id': uid,
                                                          'state': 'open',
                                                          'name': number,
                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),
                                                      })
            statement_obj.button_open(cr, uid, [statement_id], context)

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id

        return {
            'domain': ""[('state','=','open')]"",
            'name': 'Open Statement',
            'view_type': 'form',
            'view_mode': 'tree,form',
            'res_model': 'account.bank.statement',
            'views': [(id2, 'tree'),(id3, 'form')],
            'type': 'ir.actions.act_window'
}
pos_open_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n",0
39,39,b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c,"/addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _

class pos_close_statement(osv.osv_memory):
    _name = 'pos.close.statement'
    _description = 'Close Statements'

    def close_statement(self, cr, uid, ids, context):
        """"""
             Close the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Dictionary
        """"""
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        statement_obj = self.pool.get('account.bank.statement')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        cr.execute("""""" select id from account_journal
                            where auto_cash='True' and type='cash'
                            and id in (%s)"""""" %(','.join(map(lambda x: ""'"" + str(x) + ""'"", j_ids))))
        journal_ids = map(lambda x1: x1[0], cr.fetchall())

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if not ids:
                raise osv.except_osv(_('Message'), _('Journals are already closed'))
            else:
                list_statement.append(ids[0])
                if not journal.check_dtls:
                    statement_obj.button_confirm_cash(cr, uid, ids, context)
    #        if not list_statement:
    #            return {}
    #        model_data_ids = mod_obj.search(cr, uid,[('model','=','ir.ui.view'),('name','=','view_bank_statement_tree')], context=context)
    #        resource_id = mod_obj.read(cr, uid, model_data_ids, fields=['res_id'], context=context)[0]['res_id']

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id
        return {
                'domain': ""[('id','in',"" + str(list_statement) + "")]"",
                'name': 'Close Statements',
                'view_type': 'form',
                'view_mode': 'tree,form',
                'res_model': 'account.bank.statement',
                'views': [(id2, 'tree'),(id3, 'form')],
                'type': 'ir.actions.act_window'}

pos_close_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n/addons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _
import time

class pos_open_statement(osv.osv_memory):
    _name = 'pos.open.statement'
    _description = 'Open Statements'

    def open_statement(self, cr, uid, ids, context):
        """"""
             Open the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Directory
        """"""
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        statement_obj = self.pool.get('account.bank.statement')
        sequence_obj = self.pool.get('ir.sequence')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        cr.execute("""""" select id from account_journal
                            where auto_cash='True' and type='cash'
                            and id in (%s)"""""" %(','.join(map(lambda x: ""'"" + str(x) + ""'"", j_ids))))
        journal_ids = map(lambda x1: x1[0], cr.fetchall())

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if len(ids):
                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for ""%s"". \n Please close the cashbox related to. ' %(journal.name)))
            
#            cr.execute("""""" Select id from account_bank_statement
#                                    where journal_id =%d
#                                    and company_id =%d
#                                    order by id desc limit 1"""""" %(journal.id, company_id))
#            st_id = cr.fetchone()
            
            number = ''
            if journal.sequence_id:
                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)
            else:
                number = sequence_obj.get(cr, uid, 'account.bank.statement')
            
            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,
                                                          'company_id': company_id,
                                                          'user_id': uid,
                                                          'state': 'open',
                                                          'name': number,
                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),
                                                      })
            statement_obj.button_open(cr, uid, [statement_id], context)

    #            period = statement_obj._get_period(cr, uid, context) or None
    #            cr.execute(""INSERT INTO account_bank_statement(journal_id,company_id,user_id,state,name, period_id,date) VALUES(%d,%d,%d,'open','%s',%d,'%s')""%(journal.id, company_id, uid, number, period, time.strftime('%Y-%m-%d %H:%M:%S')))
    #            cr.commit()
    #            cr.execute(""select id from account_bank_statement where journal_id=%d and company_id=%d and user_id=%d and state='open' and name='%s'""%(journal.id, company_id, uid, number))
    #            statement_id = cr.fetchone()[0]
    #            print ""statement_id"",statement_id
    #            if st_id:
    #                statemt_id = statement_obj.browse(cr, uid, st_id[0])
    #                list_statement.append(statemt_id.id)
    #                if statemt_id and statemt_id.ending_details_ids:
    #                    statement_obj.write(cr, uid, [statement_id], {
    #                        'balance_start': statemt_id.balance_end,
    #                        'state': 'open',
    #                    })
    #                    if statemt_id.ending_details_ids:
    #                        for i in statemt_id.ending_details_ids:
    #                            c = statement_obj.create(cr, uid, {
    #                                'pieces': i.pieces,
    #                                'number': i.number,
    #                                'starting_id': statement_id,
    #                            })
        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id

        return {
#           'domain': ""[('id','in', [""+','.join(map(str,list_statement))+""])]"",
            'domain': ""[('state','=','open')]"",
            'name': 'Open Statement',
            'view_type': 'form',
            'view_mode': 'tree,form',
            'res_model': 'account.bank.statement',
            'views': [(id2, 'tree'),(id3, 'form')],
            'type': 'ir.actions.act_window'
}
pos_open_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n",1
2,2,f020853c54a1851f196d7fd8897c4620bccf9f6c,"ckan/models/package.py/n/nimport sqlobject

try:
    # vdm >= 0.2
    import vdm.sqlobject.base as vdmbase
    from vdm.sqlobject.base import State
except:
    # vdm == 0.1
    import vdm.base as vdmbase
    from vdm.base import State

# American spelling ...
class License(sqlobject.SQLObject):

    class sqlmeta:
        _defaultOrder = 'name'

    name = sqlobject.UnicodeCol(alternateID=True)
    packages = sqlobject.MultipleJoin('Package')


class PackageRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Package', cascade=True)
    title = sqlobject.UnicodeCol(default=None)
    url = sqlobject.UnicodeCol(default=None)
    download_url = sqlobject.UnicodeCol(default=None)
    license = sqlobject.ForeignKey('License', default=None)
    notes = sqlobject.UnicodeCol(default=None)


class TagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Tag', cascade=True)


class PackageTagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('PackageTag', cascade=True)


class Package(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    
    name = sqlobject.UnicodeCol(alternateID=True)

    # should be attribute_name, module_name, module_object
    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]

    def add_tag_by_name(self, tagname):
        try:
            tag = self.revision.model.tags.get(tagname)
        except: # TODO: make this specific
            tag = self.transaction.model.tags.create(name=tagname)
        self.tags.create(tag=tag)


class Tag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = TagRevision

    name = sqlobject.UnicodeCol(alternateID=True)
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)

    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]

    @classmethod
    def search_by_name(self, text_query):
        text_query = str(text_query) # SQLObject chokes on unicode.
        return self.select(self.q.name.contains(text_query.lower()))


class PackageTag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageTagRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    m2m = []

    package = sqlobject.ForeignKey('Package', cascade=True)
    tag = sqlobject.ForeignKey('Tag', cascade=True)

    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',
            unique=True)

/n/n/n",0
3,3,f020853c54a1851f196d7fd8897c4620bccf9f6c,"/ckan/models/package.py/n/nimport sqlobject

try:
    # vdm >= 0.2
    import vdm.sqlobject.base as vdmbase
    from vdm.sqlobject.base import State
except:
    # vdm == 0.1
    import vdm.base as vdmbase
    from vdm.base import State

# American spelling ...
class License(sqlobject.SQLObject):

    class sqlmeta:
        _defaultOrder = 'name'

    name = sqlobject.UnicodeCol(alternateID=True)
    packages = sqlobject.MultipleJoin('Package')


class PackageRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Package', cascade=True)
    title = sqlobject.UnicodeCol(default=None)
    url = sqlobject.UnicodeCol(default=None)
    download_url = sqlobject.UnicodeCol(default=None)
    license = sqlobject.ForeignKey('License', default=None)
    notes = sqlobject.UnicodeCol(default=None)


class TagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Tag', cascade=True)


class PackageTagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('PackageTag', cascade=True)


class Package(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    
    name = sqlobject.UnicodeCol(alternateID=True)

    # should be attribute_name, module_name, module_object
    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]

    def add_tag_by_name(self, tagname):
        try:
            tag = self.revision.model.tags.get(tagname)
        except: # TODO: make this specific
            tag = self.transaction.model.tags.create(name=tagname)
        self.tags.create(tag=tag)


class Tag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = TagRevision

    name = sqlobject.UnicodeCol(alternateID=True)
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)

    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]

    @classmethod
    def search_by_name(self, text_query):
        text_query_str = str(text_query) # SQLObject chokes on unicode.
        # Todo: Change to use SQLObject statement objects.
        sql_query = ""UPPER(tag.name) LIKE UPPER('%%%s%%')"" % text_query_str
        return self.select(sql_query)


class PackageTag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageTagRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    m2m = []

    package = sqlobject.ForeignKey('Package', cascade=True)
    tag = sqlobject.ForeignKey('Tag', cascade=True)

    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',
            unique=True)

/n/n/n",1
150,150,2158db051408e0d66210a99b17c121be008e20b6,"flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-
import sys
import logging
import sqlalchemy as sa

from . import filters
from sqlalchemy.orm import joinedload
from sqlalchemy.exc import IntegrityError
from sqlalchemy import func
from sqlalchemy.orm.properties import SynonymProperty

from ..base import BaseInterface
from ..group import GroupByDateYear, GroupByDateMonth, GroupByCol
from ..mixins import FileColumn, ImageColumn
from ...filemanager import FileManager, ImageManager
from ..._compat import as_unicode
from ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \
    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY

log = logging.getLogger(__name__)


def _include_filters(obj):
    for key in filters.__all__:
        if not hasattr(obj, key):
            setattr(obj, key, getattr(filters, key))


class SQLAInterface(BaseInterface):
    """"""
    SQLAModel
    Implements SQLA support methods for views
    """"""
    session = None

    filter_converter_class = filters.SQLAFilterConverter

    def __init__(self, obj, session=None):
        _include_filters(self)
        self.list_columns = dict()
        self.list_properties = dict()

        self.session = session
        # Collect all SQLA columns and properties
        for prop in sa.orm.class_mapper(obj).iterate_properties:
            if type(prop) != SynonymProperty:
                self.list_properties[prop.key] = prop
        for col_name in obj.__mapper__.columns.keys():
            if col_name in self.list_properties:
                self.list_columns[col_name] = obj.__mapper__.columns[col_name]
        super(SQLAInterface, self).__init__(obj)

    @property
    def model_name(self):
        """"""
            Returns the models class name
            useful for auto title on views
        """"""
        return self.obj.__name__

    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):
        if filters:
            query = filters.apply_all(query)
        if order_column != '':
            # if Model has custom decorator **renders('<COL_NAME>')**
            # this decorator will add a property to the method named *_col_name*
            if hasattr(self.obj, order_column):
                if hasattr(getattr(self.obj, order_column), '_col_name'):
                    order_column = getattr(getattr(self.obj, order_column), '_col_name')
            query = query.order_by(""%s %s"" % (order_column, order_direction))
        return query

    def query(self, filters=None, order_column='', order_direction='',
              page=None, page_size=None):
        """"""
            QUERY
            :param filters:
                dict with filters {<col_name>:<value,...}
            :param order_column:
                name of the column to order
            :param order_direction:
                the direction to order <'asc'|'desc'>
            :param page:
                the current page
            :param page_size:
                the current page size

        """"""
        query = self.session.query(self.obj)
        if len(order_column.split('.')) >= 2:
            tmp_order_column = ''
            for join_relation in order_column.split('.')[:-1]:
                model_relation = self.get_related_model(join_relation)
                query = query.join(model_relation)
                # redefine order column name, because relationship can have a different name
                # from the related table name.
                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'
            order_column = tmp_order_column + order_column.split('.')[-1]
        query_count = self.session.query(func.count('*')).select_from(self.obj)

        query_count = self._get_base_query(query=query_count,
                                           filters=filters)
        query = self._get_base_query(query=query,
                                     filters=filters,
                                     order_column=order_column,
                                     order_direction=order_direction)

        count = query_count.scalar()

        if page:
            query = query.offset(page * page_size)
        if page_size:
            query = query.limit(page_size)

        return count, query.all()

    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByCol(group_by, 'Group by')
        return group.apply(query_result)

    def query_month_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByDateMonth(group_by, 'Group by Month')
        return group.apply(query_result)

    def query_year_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group_year = GroupByDateYear(group_by, 'Group by Year')
        return group_year.apply(query_result)

    """"""
    -----------------------------------------
         FUNCTIONS for Testing TYPES
    -----------------------------------------
    """"""

    def is_image(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, ImageColumn)
        except:
            return False

    def is_file(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, FileColumn)
        except:
            return False

    def is_string(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.String)
        except:
            return False

    def is_text(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Text)
        except:
            return False

    def is_integer(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Integer)
        except:
            return False

    def is_numeric(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)
        except:
            return False

    def is_float(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Float)
        except:
            return False

    def is_boolean(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)
        except:
            return False

    def is_date(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Date)
        except:
            return False

    def is_datetime(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)
        except:
            return False

    def is_relation(self, col_name):
        try:
            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)
        except:
            return False

    def is_relation_many_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOONE'
        except:
            return False

    def is_relation_many_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOMANY'
        except:
            return False

    def is_relation_one_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOONE'
        except:
            return False

    def is_relation_one_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOMANY'
        except:
            return False

    def is_nullable(self, col_name):
        if self.is_relation_many_to_one(col_name):
            col = self.get_relation_fk(col_name)
            return col.nullable
        try:
            return self.list_columns[col_name].nullable
        except:
            return False

    def is_unique(self, col_name):
        try:
            return self.list_columns[col_name].unique
        except:
            return False

    def is_pk(self, col_name):
        try:
            return self.list_columns[col_name].primary_key
        except:
            return False

    def is_fk(self, col_name):
        try:
            return self.list_columns[col_name].foreign_keys
        except:
            return False

    def get_max_length(self, col_name):
        try:
            col = self.list_columns[col_name]
            if col.type.length:
                return col.type.length
            else:
                return -1
        except:
            return -1

    """"""
    -------------------------------
     FUNCTIONS FOR CRUD OPERATIONS
    -------------------------------
    """"""

    def add(self, item):
        try:
            self.session.add(item)
            self.session.commit()
            self.message = (as_unicode(self.add_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.add_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def edit(self, item):
        try:
            self.session.merge(item)
            self.session.commit()
            self.message = (as_unicode(self.edit_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete(self, item):
        try:
            self._delete_files(item)
            self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete_all(self, items):
        try:
            for item in items:
                self._delete_files(item)
                self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    """"""
    -----------------------
     FILE HANDLING METHODS
    -----------------------
    """"""

    def _add_files(self, this_request, item):
        fm = FileManager()
        im = ImageManager()
        for file_col in this_request.files:
            if self.is_file(file_col):
                fm.save_file(this_request.files[file_col], getattr(item, file_col))
        for file_col in this_request.files:
            if self.is_image(file_col):
                im.save_file(this_request.files[file_col], getattr(item, file_col))

    def _delete_files(self, item):
        for file_col in self.get_file_column_list():
            if self.is_file(file_col):
                if getattr(item, file_col):
                    fm = FileManager()
                    fm.delete_file(getattr(item, file_col))
        for file_col in self.get_image_column_list():
            if self.is_image(file_col):
                if getattr(item, file_col):
                    im = ImageManager()
                    im.delete_file(getattr(item, file_col))

    """"""
    ------------------------------
     FUNCTIONS FOR RELATED MODELS
    ------------------------------
    """"""

    def get_col_default(self, col_name):
        default = getattr(self.list_columns[col_name], 'default', None)
        if default is not None:
            value = getattr(default, 'arg', None)
            if value is not None:
                if getattr(default, 'is_callable', False):
                    return lambda: default.arg(None)
                else:
                    if not getattr(default, 'is_scalar', True):
                        return None
                return value

    def get_related_model(self, col_name):
        return self.list_properties[col_name].mapper.class_

    def query_model_relation(self, col_name):
        model = self.get_related_model(col_name)
        return self.session.query(model).all()

    def get_related_interface(self, col_name):
        return self.__class__(self.get_related_model(col_name), self.session)

    def get_related_obj(self, col_name, value):
        rel_model = self.get_related_model(col_name)
        return self.session.query(rel_model).get(value)

    def get_related_fks(self, related_views):
        return [view.datamodel.get_related_fk(self.obj) for view in related_views]

    def get_related_fk(self, model):
        for col_name in self.list_properties.keys():
            if self.is_relation(col_name):
                if model == self.get_related_model(col_name):
                    return col_name

    """"""
    ------------- 
     GET METHODS
    -------------
    """"""

    def get_columns_list(self):
        """"""
            Returns all model's columns on SQLA properties
        """"""
        return list(self.list_properties.keys())

    def get_user_columns_list(self):
        """"""
            Returns all model's columns except pk or fk
        """"""
        ret_lst = list()
        for col_name in self.get_columns_list():
            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):
                ret_lst.append(col_name)
        return ret_lst

    # TODO get different solution, more integrated with filters
    def get_search_columns_list(self):
        ret_lst = list()
        for col_name in self.get_columns_list():
            if not self.is_relation(col_name):
                tmp_prop = self.get_property_first_col(col_name).name
                if (not self.is_pk(tmp_prop)) and \
                        (not self.is_fk(tmp_prop)) and \
                        (not self.is_image(col_name)) and \
                        (not self.is_file(col_name)) and \
                        (not self.is_boolean(col_name)):
                    ret_lst.append(col_name)
            else:
                ret_lst.append(col_name)
        return ret_lst

    def get_order_columns_list(self, list_columns=None):
        """"""
            Returns the columns that can be ordered

            :param list_columns: optional list of columns name, if provided will
                use this list only.
        """"""
        ret_lst = list()
        list_columns = list_columns or self.get_columns_list()
        for col_name in list_columns:
            if not self.is_relation(col_name):
                if hasattr(self.obj, col_name):
                    if (not hasattr(getattr(self.obj, col_name), '__call__') or
                            hasattr(getattr(self.obj, col_name), '_col_name')):
                        ret_lst.append(col_name)
                else:
                    ret_lst.append(col_name)
        return ret_lst

    def get_file_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]

    def get_image_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]

    def get_property_first_col(self, col_name):
        # support for only one col for pk and fk
        return self.list_properties[col_name].columns[0]

    def get_relation_fk(self, col_name):
        # support for only one col for pk and fk
        return list(self.list_properties[col_name].local_columns)[0]

    def get(self, id, filters=None):
        if filters:
            query = query = self.session.query(self.obj)
            _filters = filters.copy()
            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)
            query = self._get_base_query(query=query, filters=_filters)
            return query.first()
        return self.session.query(self.obj).get(id)

    def get_pk_name(self):
        for col_name in self.list_columns.keys():
            if self.is_pk(col_name):
                return col_name


""""""
    For Retro-Compatibility
""""""
SQLModel = SQLAInterface
/n/n/nflask_appbuilder/urltools.py/n/nimport re
from flask import request


class Stack(object):
    """"""
        Stack data structure will not insert
        equal sequential data
    """"""
    def __init__(self, list=None, size=5):
        self.size = size
        self.data = list or []

    def push(self, item):
        if self.data:
            if item != self.data[len(self.data) - 1]:
                self.data.append(item)
        else:
            self.data.append(item)
        if len(self.data) > self.size:
            self.data.pop(0)

    def pop(self):
        if len(self.data) == 0:
            return None
        return self.data.pop(len(self.data) - 1)

    def to_json(self):
        return self.data


def get_group_by_args():
    """"""
        Get page arguments for group by
    """"""
    group_by = request.args.get('group_by')
    if not group_by: group_by = ''
    return group_by


def get_page_args():
    """"""
        Get page arguments, returns a dictionary
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>

    """"""
    pages = {}
    for arg in request.args:
        re_match = re.findall('page_(.*)', arg)
        if re_match:
            pages[re_match[0]] = int(request.args.get(arg))
    return pages


def get_page_size_args():
    """"""
        Get page size arguments, returns an int
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>

    """"""
    page_sizes = {}
    for arg in request.args:
        re_match = re.findall('psize_(.*)', arg)
        if re_match:
            page_sizes[re_match[0]] = int(request.args.get(arg))
    return page_sizes


def get_order_args():
    """"""
        Get order arguments, return a dictionary
        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }

        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'

    """"""
    orders = {}
    for arg in request.args:
        re_match = re.findall('_oc_(.*)', arg)
        if re_match:
            order_direction = request.args.get('_od_' + re_match[0])
            if order_direction in ('asc', 'desc'):
                orders[re_match[0]] = (request.args.get(arg), order_direction)
    return orders


def get_filter_args(filters):
    filters.clear_filters()
    for arg in request.args:
        re_match = re.findall('_flt_(\d)_(.*)', arg)
        if re_match:
            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))
/n/n/n",0
151,151,2158db051408e0d66210a99b17c121be008e20b6,"/flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-
import sys
import logging
import sqlalchemy as sa

from . import filters
from sqlalchemy.orm import joinedload
from sqlalchemy.exc import IntegrityError
from sqlalchemy import func
from sqlalchemy.orm.properties import SynonymProperty

from ..base import BaseInterface
from ..group import GroupByDateYear, GroupByDateMonth, GroupByCol
from ..mixins import FileColumn, ImageColumn
from ...filemanager import FileManager, ImageManager
from ..._compat import as_unicode
from ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \
    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY

log = logging.getLogger(__name__)


def _include_filters(obj):
    for key in filters.__all__:
        if not hasattr(obj, key):
            setattr(obj, key, getattr(filters, key))


class SQLAInterface(BaseInterface):
    """"""
    SQLAModel
    Implements SQLA support methods for views
    """"""
    session = None

    filter_converter_class = filters.SQLAFilterConverter

    def __init__(self, obj, session=None):
        _include_filters(self)
        self.list_columns = dict()
        self.list_properties = dict()

        self.session = session
        # Collect all SQLA columns and properties
        for prop in sa.orm.class_mapper(obj).iterate_properties:
            if type(prop) != SynonymProperty:
                self.list_properties[prop.key] = prop
        for col_name in obj.__mapper__.columns.keys():
            if col_name in self.list_properties:
                self.list_columns[col_name] = obj.__mapper__.columns[col_name]
        super(SQLAInterface, self).__init__(obj)

    @property
    def model_name(self):
        """"""
            Returns the models class name
            useful for auto title on views
        """"""
        return self.obj.__name__

    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):
        if filters:
            query = filters.apply_all(query)
        if order_column != '':
            # if Model has custom decorator **renders('<COL_NAME>')**
            # this decorator will add a property to the method named *_col_name*
            if hasattr(self.obj, order_column):
                if hasattr(getattr(self.obj, order_column), '_col_name'):
                    order_column = getattr(getattr(self.obj, order_column), '_col_name')
            query = query.order_by(order_column + ' ' + order_direction)
        return query

    def query(self, filters=None, order_column='', order_direction='',
              page=None, page_size=None):
        """"""
            QUERY
            :param filters:
                dict with filters {<col_name>:<value,...}
            :param order_column:
                name of the column to order
            :param order_direction:
                the direction to order <'asc'|'desc'>
            :param page:
                the current page
            :param page_size:
                the current page size

        """"""
        query = self.session.query(self.obj)
        if len(order_column.split('.')) >= 2:
            tmp_order_column = ''
            for join_relation in order_column.split('.')[:-1]:
                model_relation = self.get_related_model(join_relation)
                query = query.join(model_relation)
                # redefine order column name, because relationship can have a different name
                # from the related table name.
                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'
            order_column = tmp_order_column + order_column.split('.')[-1]
        query_count = self.session.query(func.count('*')).select_from(self.obj)

        query_count = self._get_base_query(query=query_count,
                                           filters=filters)
        query = self._get_base_query(query=query,
                                     filters=filters,
                                     order_column=order_column,
                                     order_direction=order_direction)

        count = query_count.scalar()

        if page:
            query = query.offset(page * page_size)
        if page_size:
            query = query.limit(page_size)

        return count, query.all()

    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByCol(group_by, 'Group by')
        return group.apply(query_result)

    def query_month_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group = GroupByDateMonth(group_by, 'Group by Month')
        return group.apply(query_result)

    def query_year_group(self, group_by='', filters=None):
        query = self.session.query(self.obj)
        query = self._get_base_query(query=query, filters=filters)
        query_result = query.all()
        group_year = GroupByDateYear(group_by, 'Group by Year')
        return group_year.apply(query_result)

    """"""
    -----------------------------------------
         FUNCTIONS for Testing TYPES
    -----------------------------------------
    """"""

    def is_image(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, ImageColumn)
        except:
            return False

    def is_file(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, FileColumn)
        except:
            return False

    def is_string(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.String)
        except:
            return False

    def is_text(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Text)
        except:
            return False

    def is_integer(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Integer)
        except:
            return False

    def is_numeric(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)
        except:
            return False

    def is_float(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Float)
        except:
            return False

    def is_boolean(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)
        except:
            return False

    def is_date(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.Date)
        except:
            return False

    def is_datetime(self, col_name):
        try:
            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)
        except:
            return False

    def is_relation(self, col_name):
        try:
            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)
        except:
            return False

    def is_relation_many_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOONE'
        except:
            return False

    def is_relation_many_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'MANYTOMANY'
        except:
            return False

    def is_relation_one_to_one(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOONE'
        except:
            return False

    def is_relation_one_to_many(self, col_name):
        try:
            if self.is_relation(col_name):
                return self.list_properties[col_name].direction.name == 'ONETOMANY'
        except:
            return False

    def is_nullable(self, col_name):
        if self.is_relation_many_to_one(col_name):
            col = self.get_relation_fk(col_name)
            return col.nullable
        try:
            return self.list_columns[col_name].nullable
        except:
            return False

    def is_unique(self, col_name):
        try:
            return self.list_columns[col_name].unique
        except:
            return False

    def is_pk(self, col_name):
        try:
            return self.list_columns[col_name].primary_key
        except:
            return False

    def is_fk(self, col_name):
        try:
            return self.list_columns[col_name].foreign_keys
        except:
            return False

    def get_max_length(self, col_name):
        try:
            col = self.list_columns[col_name]
            if col.type.length:
                return col.type.length
            else:
                return -1
        except:
            return -1

    """"""
    -------------------------------
     FUNCTIONS FOR CRUD OPERATIONS
    -------------------------------
    """"""

    def add(self, item):
        try:
            self.session.add(item)
            self.session.commit()
            self.message = (as_unicode(self.add_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.add_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def edit(self, item):
        try:
            self.session.merge(item)
            self.session.commit()
            self.message = (as_unicode(self.edit_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete(self, item):
        try:
            self._delete_files(item)
            self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    def delete_all(self, items):
        try:
            for item in items:
                self._delete_files(item)
                self.session.delete(item)
            self.session.commit()
            self.message = (as_unicode(self.delete_row_message), 'success')
            return True
        except IntegrityError as e:
            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')
            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))
            self.session.rollback()
            return False
        except Exception as e:
            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')
            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))
            self.session.rollback()
            return False

    """"""
    -----------------------
     FILE HANDLING METHODS
    -----------------------
    """"""

    def _add_files(self, this_request, item):
        fm = FileManager()
        im = ImageManager()
        for file_col in this_request.files:
            if self.is_file(file_col):
                fm.save_file(this_request.files[file_col], getattr(item, file_col))
        for file_col in this_request.files:
            if self.is_image(file_col):
                im.save_file(this_request.files[file_col], getattr(item, file_col))

    def _delete_files(self, item):
        for file_col in self.get_file_column_list():
            if self.is_file(file_col):
                if getattr(item, file_col):
                    fm = FileManager()
                    fm.delete_file(getattr(item, file_col))
        for file_col in self.get_image_column_list():
            if self.is_image(file_col):
                if getattr(item, file_col):
                    im = ImageManager()
                    im.delete_file(getattr(item, file_col))

    """"""
    ------------------------------
     FUNCTIONS FOR RELATED MODELS
    ------------------------------
    """"""

    def get_col_default(self, col_name):
        default = getattr(self.list_columns[col_name], 'default', None)
        if default is not None:
            value = getattr(default, 'arg', None)
            if value is not None:
                if getattr(default, 'is_callable', False):
                    return lambda: default.arg(None)
                else:
                    if not getattr(default, 'is_scalar', True):
                        return None
                return value

    def get_related_model(self, col_name):
        return self.list_properties[col_name].mapper.class_

    def query_model_relation(self, col_name):
        model = self.get_related_model(col_name)
        return self.session.query(model).all()

    def get_related_interface(self, col_name):
        return self.__class__(self.get_related_model(col_name), self.session)

    def get_related_obj(self, col_name, value):
        rel_model = self.get_related_model(col_name)
        return self.session.query(rel_model).get(value)

    def get_related_fks(self, related_views):
        return [view.datamodel.get_related_fk(self.obj) for view in related_views]

    def get_related_fk(self, model):
        for col_name in self.list_properties.keys():
            if self.is_relation(col_name):
                if model == self.get_related_model(col_name):
                    return col_name

    """"""
    ------------- 
     GET METHODS
    -------------
    """"""

    def get_columns_list(self):
        """"""
            Returns all model's columns on SQLA properties
        """"""
        return list(self.list_properties.keys())

    def get_user_columns_list(self):
        """"""
            Returns all model's columns except pk or fk
        """"""
        ret_lst = list()
        for col_name in self.get_columns_list():
            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):
                ret_lst.append(col_name)
        return ret_lst

    # TODO get different solution, more integrated with filters
    def get_search_columns_list(self):
        ret_lst = list()
        for col_name in self.get_columns_list():
            if not self.is_relation(col_name):
                tmp_prop = self.get_property_first_col(col_name).name
                if (not self.is_pk(tmp_prop)) and \
                        (not self.is_fk(tmp_prop)) and \
                        (not self.is_image(col_name)) and \
                        (not self.is_file(col_name)) and \
                        (not self.is_boolean(col_name)):
                    ret_lst.append(col_name)
            else:
                ret_lst.append(col_name)
        return ret_lst

    def get_order_columns_list(self, list_columns=None):
        """"""
            Returns the columns that can be ordered

            :param list_columns: optional list of columns name, if provided will
                use this list only.
        """"""
        ret_lst = list()
        list_columns = list_columns or self.get_columns_list()
        for col_name in list_columns:
            if not self.is_relation(col_name):
                if hasattr(self.obj, col_name):
                    if (not hasattr(getattr(self.obj, col_name), '__call__') or
                            hasattr(getattr(self.obj, col_name), '_col_name')):
                        ret_lst.append(col_name)
                else:
                    ret_lst.append(col_name)
        return ret_lst

    def get_file_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]

    def get_image_column_list(self):
        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]

    def get_property_first_col(self, col_name):
        # support for only one col for pk and fk
        return self.list_properties[col_name].columns[0]

    def get_relation_fk(self, col_name):
        # support for only one col for pk and fk
        return list(self.list_properties[col_name].local_columns)[0]

    def get(self, id, filters=None):
        if filters:
            query = query = self.session.query(self.obj)
            _filters = filters.copy()
            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)
            query = self._get_base_query(query=query, filters=_filters)
            return query.first()
        return self.session.query(self.obj).get(id)

    def get_pk_name(self):
        for col_name in self.list_columns.keys():
            if self.is_pk(col_name):
                return col_name


""""""
    For Retro-Compatibility
""""""
SQLModel = SQLAInterface
/n/n/n/flask_appbuilder/urltools.py/n/nimport re
from flask import request


class Stack(object):
    """"""
        Stack data structure will not insert
        equal sequential data
    """"""
    def __init__(self, list=None, size=5):
        self.size = size
        self.data = list or []

    def push(self, item):
        if self.data:
            if item != self.data[len(self.data) - 1]:
                self.data.append(item)
        else:
            self.data.append(item)
        if len(self.data) > self.size:
            self.data.pop(0)

    def pop(self):
        if len(self.data) == 0:
            return None
        return self.data.pop(len(self.data) - 1)

    def to_json(self):
        return self.data

def get_group_by_args():
    """"""
        Get page arguments for group by
    """"""
    group_by = request.args.get('group_by')
    if not group_by: group_by = ''
    return group_by

def get_page_args():
    """"""
        Get page arguments, returns a dictionary
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>

    """"""
    pages = {}
    for arg in request.args:
        re_match = re.findall('page_(.*)', arg)
        if re_match:
            pages[re_match[0]] = int(request.args.get(arg))
    return pages

def get_page_size_args():
    """"""
        Get page size arguments, returns an int
        { <VIEW_NAME>: PAGE_NUMBER }

        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>

    """"""
    page_sizes = {}
    for arg in request.args:
        re_match = re.findall('psize_(.*)', arg)
        if re_match:
            page_sizes[re_match[0]] = int(request.args.get(arg))
    return page_sizes

def get_order_args():
    """"""
        Get order arguments, return a dictionary
        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }

        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'

    """"""
    orders = {}
    for arg in request.args:
        re_match = re.findall('_oc_(.*)', arg)
        if re_match:
            orders[re_match[0]] = (request.args.get(arg), request.args.get('_od_' + re_match[0]))
    return orders

def get_filter_args(filters):
    filters.clear_filters()
    for arg in request.args:
        re_match = re.findall('_flt_(\d)_(.*)', arg)
        if re_match:
            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))
/n/n/n",1
4,4,f020853c54a1851f196d7fd8897c4620bccf9f6c,"ckan/models/package.py/n/nimport sqlobject

try:
    # vdm >= 0.2
    import vdm.sqlobject.base as vdmbase
    from vdm.sqlobject.base import State
except:
    # vdm == 0.1
    import vdm.base as vdmbase
    from vdm.base import State

# American spelling ...
class License(sqlobject.SQLObject):

    class sqlmeta:
        _defaultOrder = 'name'

    name = sqlobject.UnicodeCol(alternateID=True)
    packages = sqlobject.MultipleJoin('Package')


class PackageRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Package', cascade=True)
    title = sqlobject.UnicodeCol(default=None)
    url = sqlobject.UnicodeCol(default=None)
    download_url = sqlobject.UnicodeCol(default=None)
    license = sqlobject.ForeignKey('License', default=None)
    notes = sqlobject.UnicodeCol(default=None)


class TagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Tag', cascade=True)


class PackageTagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('PackageTag', cascade=True)


class Package(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    
    name = sqlobject.UnicodeCol(alternateID=True)

    # should be attribute_name, module_name, module_object
    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]

    def add_tag_by_name(self, tagname):
        try:
            tag = self.revision.model.tags.get(tagname)
        except: # TODO: make this specific
            tag = self.transaction.model.tags.create(name=tagname)
        self.tags.create(tag=tag)


class Tag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = TagRevision

    name = sqlobject.UnicodeCol(alternateID=True)
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)

    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]

    @classmethod
    def search_by_name(self, text_query):
        text_query = str(text_query) # SQLObject chokes on unicode.
        return self.select(self.q.name.contains(text_query.lower()))


class PackageTag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageTagRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    m2m = []

    package = sqlobject.ForeignKey('Package', cascade=True)
    tag = sqlobject.ForeignKey('Tag', cascade=True)

    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',
            unique=True)

/n/n/n",0
5,5,f020853c54a1851f196d7fd8897c4620bccf9f6c,"/ckan/models/package.py/n/nimport sqlobject

try:
    # vdm >= 0.2
    import vdm.sqlobject.base as vdmbase
    from vdm.sqlobject.base import State
except:
    # vdm == 0.1
    import vdm.base as vdmbase
    from vdm.base import State

# American spelling ...
class License(sqlobject.SQLObject):

    class sqlmeta:
        _defaultOrder = 'name'

    name = sqlobject.UnicodeCol(alternateID=True)
    packages = sqlobject.MultipleJoin('Package')


class PackageRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Package', cascade=True)
    title = sqlobject.UnicodeCol(default=None)
    url = sqlobject.UnicodeCol(default=None)
    download_url = sqlobject.UnicodeCol(default=None)
    license = sqlobject.ForeignKey('License', default=None)
    notes = sqlobject.UnicodeCol(default=None)


class TagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('Tag', cascade=True)


class PackageTagRevision(vdmbase.ObjectRevisionSQLObject):

    base = sqlobject.ForeignKey('PackageTag', cascade=True)


class Package(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    
    name = sqlobject.UnicodeCol(alternateID=True)

    # should be attribute_name, module_name, module_object
    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]

    def add_tag_by_name(self, tagname):
        try:
            tag = self.revision.model.tags.get(tagname)
        except: # TODO: make this specific
            tag = self.transaction.model.tags.create(name=tagname)
        self.tags.create(tag=tag)


class Tag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = TagRevision

    name = sqlobject.UnicodeCol(alternateID=True)
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)

    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]

    @classmethod
    def search_by_name(self, text_query):
        text_query_str = str(text_query) # SQLObject chokes on unicode.
        # Todo: Change to use SQLObject statement objects.
        sql_query = ""UPPER(tag.name) LIKE UPPER('%%%s%%')"" % text_query_str
        return self.select(sql_query)


class PackageTag(vdmbase.VersionedDomainObject):

    sqlobj_version_class = PackageTagRevision
    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)
    m2m = []

    package = sqlobject.ForeignKey('Package', cascade=True)
    tag = sqlobject.ForeignKey('Tag', cascade=True)

    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',
            unique=True)

/n/n/n",1
164,164,91513ef7bbe60014dacab709be582eb0b10fcaab,"crapo_tests/models/crm_stage.py/n/n""""""
©2019
License: AGPL-3

@author: C. Guychard (Article 714)

""""""


from odoo import models, api
from psycopg2.sql import SQL, Identifier
from odoo.addons.base_crapo_workflow.mixins import (
    crapo_automata_mixins,
)  # pylint: disable=odoo-addons-relative-import


class CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):
    _inherit = ""crm.stage""
    _state_for_model = ""crm.lead""

    def write(self, values):
        if len(self) == 1:
            if ""crapo_state"" not in values and not self.crapo_state:
                if ""name"" in values:
                    vals = {""name"": values[""name""]}
                else:
                    vals = {""name"": self.name}
                mystate = self._compute_related_state(vals)
                values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).write(values)

    @api.model
    def create(self, values):
        if ""crapo_state"" not in values and not self.crapo_state:
            if ""name"" in values:
                vals = {""name"": values[""name""]}
            mystate = self._compute_related_state(vals)
            values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).create(values)

    @api.model_cr_context
    def _init_column(self, column_name):
        """""" Initialize the value of the given column for existing rows.
            Overridden here because we need to wrap existing stages in
            a new crapo_state for each stage (including a default automaton)
        """"""
        if column_name not in [""crapo_state""]:
            super(CrmStageWithMixin, self)._init_column(column_name)
        else:
            default_compute = self._compute_related_state
            query = SQL(
                ""SELECT id, name FROM {} WHERE {} is NULL"".format(
                    Identifier(self._table), Identifier(column_name)
                )
            )
            self.env.cr.execute(query)
            stages = self.env.cr.fetchall()

            for stage in stages:
                default_value = default_compute(values={""name"": stage[1]})
                query = SQL(
                    ""UPDATE {} SET {}=%s WHERE id = %s"".format(
                        Identifier(self._table), Identifier(column_name)
                    )
                )
                self.env.cr.execute(query, (default_value.id, stage[0]))
/n/n/n",0
165,165,91513ef7bbe60014dacab709be582eb0b10fcaab,"/crapo_tests/models/crm_stage.py/n/n""""""
©2019
License: AGPL-3

@author: C. Guychard (Article 714)

""""""


from odoo import models, api
from odoo.addons.base_crapo_workflow.mixins import (
    crapo_automata_mixins,
)  # pylint: disable=odoo-addons-relative-import


class CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):
    _inherit = ""crm.stage""
    _state_for_model = ""crm.lead""

    def write(self, values):
        if len(self) == 1:
            if ""crapo_state"" not in values and not self.crapo_state:
                if ""name"" in values:
                    vals = {""name"": values[""name""]}
                else:
                    vals = {""name"": self.name}
                mystate = self._compute_related_state(vals)
                values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).write(values)

    @api.model
    def create(self, values):
        if ""crapo_state"" not in values and not self.crapo_state:
            if ""name"" in values:
                vals = {""name"": values[""name""]}
            mystate = self._compute_related_state(vals)
            values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).create(values)

    @api.model_cr_context
    def _init_column(self, column_name):
        """""" Initialize the value of the given column for existing rows.
            Overridden here because we need to wrap existing stages in
            a new crapo_state for each stage (including a default automaton)
        """"""
        if column_name not in [""crapo_state""]:
            super(CrmStageWithMixin, self)._init_column(column_name)
        else:
            default_compute = self._compute_related_state

            self.env.cr.execute(
                ""SELECT id, name FROM %s WHERE %s is NULL"",
                (self._table, column_name),
            )
            stages = self.env.cr.fetchall()

            for stage in stages:
                default_value = default_compute(values={""name"": stage[1]})

                self.env.cr.execute(
                    ""UPDATE %s SET %s=%s WHERE id = %s"",
                    (self._table, column_name, default_value.id, stage[0]),
                )
/n/n/n",1
30,30,b0b9410c36bce2e946d48695d9a0eca31b11c15a,"klassifikation/rest/db.py/n/nfrom enum import Enum

import psycopg2
from psycopg2.extras import DateTimeTZRange
from psycopg2.extensions import adapt as psyco_adapt

from jinja2 import Template
from jinja2 import Environment, FileSystemLoader

from settings import DATABASE, DB_USER
from db_helpers import get_attribute_fields, get_attribute_names
from db_helpers import get_state_names

""""""
    Jinja2 Environment
""""""

jinja_env = Environment(loader=FileSystemLoader('./templates/sql'))

def adapt(value):
    # return psyco_adapt(value)
    # Damn you, character encoding!
    return str(psyco_adapt(value.encode('utf-8'))).decode('utf-8')

jinja_env.filters['adapt'] = adapt

""""""
    GENERAL FUNCTION AND CLASS DEFINITIONS
""""""



def get_connection():
    """"""Handle all intricacies of connecting to Postgres.""""""
    connection = psycopg2.connect(""dbname={0} user={1}"".format(DATABASE,
                                                               DB_USER))
    connection.autocommit = True
    return connection


def get_authenticated_user():
    """"""Return hardcoded UUID until we get real authentication in place.""""""
    return ""615957e8-4aa1-4319-a787-f1f7ad6b5e2c""


def convert_attributes(attributes):
    ""Convert attributes from dictionary to list in correct order.""
    for attr_name in attributes:
        current_attr_periods = attributes[attr_name]
        converted_attr_periods = []
        for attr_period in current_attr_periods:
            field_names = get_attribute_fields(attr_name)
            attr_value_list = [
                attr_period[f] if f in attr_period else None
                for f in field_names
                ]
            converted_attr_periods.append(attr_value_list)
        attributes[attr_name] = converted_attr_periods
    return attributes


class Livscyklus(Enum):
    OPSTAAET = 'Opstaaet'
    IMPORTERET = 'Importeret'
    PASSIVERET = 'Passiveret'
    SLETTET = 'Slettet'
    RETTET = 'Rettet'


""""""
    GENERAL SQL GENERATION.

    All of these functions generate bits of SQL to use in complete statements.
    At some point, we might want to factor them to an ""sql_helpers.py"" module.
""""""


def sql_state_array(state, periods, class_name):
    """"""Return an SQL array of type <state>TilsType.""""""
    t = jinja_env.get_template('state_array.sql')
    sql = t.render(class_name=class_name, state_name=state,
                   state_periods=periods)
    return sql


def sql_attribute_array(attribute, periods):
    """"""Return an SQL array of type <attribute>AttrType[].""""""
    t = jinja_env.get_template('attribute_array.sql')
    sql = t.render(attribute_name=attribute, attribute_periods=periods)
    return sql


def sql_relations_array(class_name, relations):
    """"""Return an SQL array of type <class_name>RelationType[].""""""
    t = jinja_env.get_template('relations_array.sql')
    sql = t.render(class_name=class_name, relations=relations)
    return sql


def sql_convert_registration(states, attributes, relations, class_name):
    """"""Convert input JSON to the SQL arrays we need.""""""
    sql_states = []
    for s in get_state_names(class_name):
        periods = states[s] if s in states else []
        sql_states.append(
            sql_state_array(s, periods, class_name)
        )

    sql_attributes = []
    for a in get_attribute_names(class_name):
        periods = attributes[a] if a in attributes else []
        sql_attributes.append(
            sql_attribute_array(a, periods)
        )

    sql_relations = sql_relations_array(class_name, relations)

    return (sql_states, sql_attributes, sql_relations)


""""""
    GENRAL OBJECT RELATED FUNCTIONS
""""""


def object_exists(class_name, uuid):
    """"""Check if an object with this class name and UUID exists already.""""""
    sql = ""select (%s IN (SELECT DISTINCT facet_id from facet_registrering))""
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute(sql, (uuid,))
    result = cursor.fetchone()[0]
    
    return result


def create_or_import_object(class_name, note, attributes, states, relations,
                            uuid=None):
    """"""Create a new object by calling the corresponding stored procedure.

    Create a new object by calling actual_state_create_or_import_{class_name}.
    It is necessary to map the parameters to our custom PostgreSQL data types.
    """"""

    # Data from the BaseRegistration.
    # Do not supply date, that is generated by the DB.
    life_cycle_code = (Livscyklus.OPSTAAET.value if uuid is None
                       else Livscyklus.IMPORTERET.value)
    user_ref = get_authenticated_user()

    attributes = convert_attributes(attributes)
    (
        sql_states, sql_attributes, sql_relations
    ) = sql_convert_registration(states, attributes, relations, class_name)
    sql_template = jinja_env.get_template('create_object.sql')
    sql = sql_template.render(
        class_name=class_name,
        uuid=uuid,
        life_cycle_code=life_cycle_code,
        user_ref=user_ref,
        note=note,
        states=sql_states,
        attributes=sql_attributes,
        relations=sql_relations)
    # Call Postgres! Return OK or not accordingly
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute(sql)
    output = cursor.fetchone()
    print output
    return output[0]


def delete_object(class_name, note, uuid):
    """"""Delete object by using the stored procedure.
    
    Deleting is the same as updating with the life cycle code ""Slettet"".
    """"""

    user_ref = get_authenticated_user()
    life_cycle_code = Livscyklus.SLETTET.value
    sql_template = jinja_env.get_template('passivate_or_delete_object.sql')
    sql = sql_template.render(
        class_name=class_name,
        uuid=uuid,
        life_cycle_code=life_cycle_code,
        user_ref=user_ref,
        note=note
    )
    # Call Postgres! Return OK or not accordingly
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute(sql)
    output = cursor.fetchone()
    print output
    return output[0]

def passivate_object(class_name, note, uuid):
    """"""Passivate object by calling the stored procedure.""""""

    user_ref = get_authenticated_user()
    life_cycle_code = Livscyklus.PASSIVERET.value
    sql_template = jinja_env.get_template('passivate_or_delete_object.sql')
    sql = sql_template.render(
        class_name=class_name,
        uuid=uuid,
        life_cycle_code=life_cycle_code,
        user_ref=user_ref,
        note=note
    )
    # Call PostgreSQL
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute(sql)
    output = cursor.fetchone()
    print output
    return output[0]


def update_object(class_name, note, attributes, states, relations, uuid=None):
    """"""Update object with the partial data supplied.""""""
    life_cycle_code = Livscyklus.RETTET.value
    user_ref = get_authenticated_user()

    attributes = convert_attributes(attributes)
    (
        sql_states, sql_attributes, sql_relations
    ) = sql_convert_registration(states, attributes, relations, class_name)

    sql_template = jinja_env.get_template('update_object.sql')
    sql = sql_template.render(
        class_name=class_name,
        uuid=uuid,
        life_cycle_code=life_cycle_code,
        user_ref=user_ref,
        note=note,
        states=sql_states,
        attributes=sql_attributes,
        relations=sql_relations)
    # Call PostgreSQL
    conn = get_connection()
    cursor = conn.cursor()
    try:
        cursor.execute(sql)
        output = cursor.fetchone()
        print output
    except psycopg2.DataError:
        # Thrown when no changes
        pass
    return uuid


def list_objects(class_name, uuid, virkning_fra, virkning_til,
                 registreret_fra, registreret_til):
    """"""List objects with the given uuids, optionally filtering by the given
    virkning and registering periods.""""""

    assert isinstance(uuid, list)

    sql_template = jinja_env.get_template('list_objects.sql')
    sql = sql_template.render(
        class_name=class_name
    )

    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute(sql, {
        'uuid': uuid,
        'registrering_tstzrange': DateTimeTZRange(registreret_fra,
                                                  registreret_til),
        'virkning_tstzrange': DateTimeTZRange(virkning_fra, virkning_til)
    })
    output = cursor.fetchone()
    return output
/n/n/nklassifikation/rest/oio_rest.py/n/n
from flask import jsonify, request
import db


# Just a helper during debug
def j(t): return jsonify(output=t)


class OIOStandardHierarchy(object):
    """"""Implement API for entire hierarchy.""""""

    _classes = []

    @classmethod
    def setup_api(cls, flask, base_url):
        """"""Set up API for the classes included in the hierarchy.

        Note that version number etc. may have to be added to the URL.""""""
        for c in cls._classes:
            c.create_api(cls._name, flask, base_url)


class OIORestObject(object):
    """"""
    Implement an OIO object - manage access to database layer for this object.

    This class is intended to be subclassed, but not to be initialized.
    """"""

    @classmethod
    def create_object(cls):
        """"""
        CREATE object, generate new UUID.
        """"""
        if not request.json:
            return jsonify({'uuid': None}), 400
        note = request.json.get(""Note"", """")
        attributes = request.json.get(""Attributter"", {})
        states = request.json.get(""Tilstande"", {})
        relations = request.json.get(""Relationer"", {})
        uuid = db.create_or_import_object(cls.__name__, note, attributes,
                                          states, relations)
        return jsonify({'uuid': uuid}), 201

    @classmethod
    def get_objects(cls):
        """"""
        LIST or SEARCH facets, depending on parameters.
        """"""
        virkning_fra = request.args.get('virkningFra', None)
        virkning_til = request.args.get('virkningTil', None)
        registreret_fra = request.args.get('registreretFra', None)
        registreret_til = request.args.get('registreretTil', None)

        # TODO: Implement search

        uuid = request.args.get('uuid', None)
        if uuid is None:
            # This is not allowed, but we let the DB layer throw an exception
            uuid = []
        else:
            uuid = uuid.split(',')

        results = db.list_objects(cls.__name__, uuid, virkning_fra,
                                 virkning_til, registreret_fra,
                                 registreret_til)
        if results is None:
            results = []
        # TODO: Return JSON object key should be based on class name,
        # e.g. {""Facetter"": [..]}, not {""results"": [..]}
        # TODO: Include Return value
        return jsonify({'results': results})

    @classmethod
    def get_object(cls, uuid):
        """"""
        READ a facet, return as JSON.
        """"""
        return j(""Hent {0} fra databasen og returner som JSON"".format(uuid))

    @classmethod
    def put_object(cls, uuid):
        """"""
        UPDATE, IMPORT or PASSIVIZE an  object.
        """"""
        if not request.json:
            return jsonify({'uuid': None}), 400
        # Get most common parameters if available.
        note = request.json.get(""Note"", """")
        attributes = request.json.get(""Attributter"", {})
        states = request.json.get(""Tilstande"", {})
        relations = request.json.get(""Relationer"", {})

        if not db.object_exists(cls.__name__, uuid):
            # Do import.
            result = db.create_or_import_object(cls.__name__, note, attributes,
                                                states, relations, uuid)
            # TODO: When connected to DB, use result properly.
            return j(u""Importeret {0}: {1}"".format(cls.__name__, uuid)), 200
        else:
            ""Edit or passivate.""
            if (request.json.get('livscyklus', '').lower() == 'passiv'):
                # Passivate
                db.passivate_object(
                        cls.__name__, note, uuid
                )
                return j(
                            u""Passiveret {0}: {1}"".format(cls.__name__, uuid)
                        ), 200
            else:
                # Edit/change
                result = db.update_object(cls.__name__, note, attributes,
                                          states, relations, uuid)
                return j(u""Opdateret {0}: {1}"".format(cls.__name__, uuid)), 200
        return j(u""Forkerte parametre!""), 405

    @classmethod
    def delete_object(cls, uuid):
        # Delete facet
        #import pdb; pdb.set_trace()
        note = request.json.get(""Note"", """")
        class_name = cls.__name__
        result = db.delete_object(class_name, note, uuid)

        return j(""Slettet {0}: {1}"".format(class_name, uuid)), 200

    @classmethod
    def create_api(cls, hierarchy, flask, base_url):
        """"""Set up API with correct database access functions.""""""
        hierarchy = hierarchy.lower()
        class_name = cls.__name__.lower()
        class_url = u""{0}/{1}/{2}"".format(base_url,
                                          hierarchy,
                                          cls.__name__.lower())
        uuid_regex = (
            ""[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}"" +
            ""-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}""
        )
        object_url = u'{0}/<regex(""{1}""):uuid>'.format(
            class_url,
            uuid_regex
        )

        flask.add_url_rule(class_url, u'_'.join([cls.__name__, 'get_objects']),
                           cls.get_objects, methods=['GET'])

        flask.add_url_rule(object_url, u'_'.join([cls.__name__, 'get_object']),
                           cls.get_object, methods=['GET'])

        flask.add_url_rule(object_url, u'_'.join([cls.__name__, 'put_object']),
                           cls.put_object, methods=['PUT'])

        flask.add_url_rule(
            class_url, u'_'.join([cls.__name__, 'create_object']),
            cls.create_object, methods=['POST']
        )

        flask.add_url_rule(
            object_url, u'_'.join([cls.__name__, 'delete_object']),
            cls.delete_object, methods=['DELETE']
        )
/n/n/n",0
31,31,b0b9410c36bce2e946d48695d9a0eca31b11c15a,"/klassifikation/rest/db.py/n/nfrom enum import Enum

import psycopg2
from psycopg2.extras import DateTimeTZRange
from jinja2 import Template

from settings import DATABASE, DB_USER
from db_helpers import get_attribute_fields, get_attribute_names
from db_helpers import get_state_names

""""""
    GENERAL FUNCTION AND CLASS DEFINITIONS
""""""


def get_connection():
    """"""Handle all intricacies of connecting to Postgres.""""""
    connection = psycopg2.connect(""dbname={0} user={1}"".format(DATABASE,
                                                               DB_USER))
    connection.autocommit = True
    return connection


def get_authenticated_user():
    """"""Return hardcoded UUID until we get real authentication in place.""""""
    return ""615957e8-4aa1-4319-a787-f1f7ad6b5e2c""


def convert_attributes(attributes):
    ""Convert attributes from dictionary to list in correct order.""
    for attr_name in attributes:
        current_attr_periods = attributes[attr_name]
        converted_attr_periods = []
        for attr_period in current_attr_periods:
            field_names = get_attribute_fields(attr_name)
            attr_value_list = [
                attr_period[f] if f in attr_period else None
                for f in field_names
                ]
            converted_attr_periods.append(attr_value_list)
        attributes[attr_name] = converted_attr_periods
    return attributes


class Livscyklus(Enum):
    OPSTAAET = 'Opstaaet'
    IMPORTERET = 'Importeret'
    PASSIVERET = 'Passiveret'
    SLETTET = 'Slettet'
    RETTET = 'Rettet'


""""""
    GENERAL SQL GENERATION.

    All of these functions generate bits of SQL to use in complete statements.
    At some point, we might want to factor them to an ""sql_helpers.py"" module.
""""""


def sql_state_array(state, periods, class_name):
    """"""Return an SQL array of type <state>TilsType.""""""
    with open('templates/sql/state_array.sql', 'r') as f:
        raw_sql = f.read()
    t = Template(raw_sql)
    sql = t.render(class_name=class_name, state_name=state,
                   state_periods=periods)
    return sql


def sql_attribute_array(attribute, periods):
    """"""Return an SQL array of type <attribute>AttrType[].""""""
    with open('templates/sql/attribute_array.sql', 'r') as f:
        raw_sql = f.read()
    t = Template(raw_sql)
    sql = t.render(attribute_name=attribute, attribute_periods=periods)
    return sql


def sql_relations_array(class_name, relations):
    """"""Return an SQL array of type <class_name>RelationType[].""""""
    with open('templates/sql/relations_array.sql', 'r') as f:
        raw_sql = f.read()
    t = Template(raw_sql)
    sql = t.render(class_name=class_name, relations=relations)
    return sql


def sql_convert_registration(states, attributes, relations, class_name):
    """"""Convert input JSON to the SQL arrays we need.""""""
    sql_states = []
    for s in get_state_names(class_name):
        periods = states[s] if s in states else []
        sql_states.append(
            sql_state_array(s, periods, class_name)
        )

    sql_attributes = []
    for a in get_attribute_names(class_name):
        periods = attributes[a] if a in attributes else []
        sql_attributes.append(
            sql_attribute_array(a, periods)
        )

    sql_relations = sql_relations_array(class_name, relations)

    return (sql_states, sql_attributes, sql_relations)


""""""
    GENRAL OBJECT RELATED FUNCTIONS
""""""


def object_exists(class_name, uuid):
    """"""Check if an object with this class name and UUID exists already.""""""
    sql = ""select (%s IN (SELECT DISTINCT facet_id from facet_registrering))""
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute(sql, (uuid,))
    result = cursor.fetchone()[0]
    
    return result


def create_or_import_object(class_name, note, attributes, states, relations,
                            uuid=None):
    """"""Create a new object by calling the corresponding stored procedure.

    Create a new object by calling actual_state_create_or_import_{class_name}.
    It is necessary to map the parameters to our custom PostgreSQL data types.
    """"""

    # Data from the BaseRegistration.
    # Do not supply date, that is generated by the DB.
    life_cycle_code = (Livscyklus.OPSTAAET.value if uuid is None
                       else Livscyklus.IMPORTERET.value)
    user_ref = get_authenticated_user()

    attributes = convert_attributes(attributes)
    (
        sql_states, sql_attributes, sql_relations
    ) = sql_convert_registration(states, attributes, relations, class_name)
    with open('templates/sql/create_object.sql', 'r') as f:
        sql_raw = f.read()
    sql_template = Template(sql_raw)
    sql = sql_template.render(
        class_name=class_name,
        uuid=uuid,
        life_cycle_code=life_cycle_code,
        user_ref=user_ref,
        note=note,
        states=sql_states,
        attributes=sql_attributes,
        relations=sql_relations)
    # Call Postgres! Return OK or not accordingly
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute(sql)
    output = cursor.fetchone()
    print output
    return output[0]


def delete_object(class_name, note, uuid):
    """"""Delete object by using the stored procedure.
    
    Deleting is the same as updating with the life cycle code ""Slettet"".
    """"""

    user_ref = get_authenticated_user()
    life_cycle_code = Livscyklus.SLETTET.value
    with open('templates/sql/passivate_or_delete_object.sql', 'r') as f:
        sql_raw = f.read()
    sql_template = Template(sql_raw)
    sql = sql_template.render(
        class_name=class_name,
        uuid=uuid,
        life_cycle_code=life_cycle_code,
        user_ref=user_ref,
        note=note
    )
    # Call Postgres! Return OK or not accordingly
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute(sql)
    output = cursor.fetchone()
    print output
    return output[0]

def passivate_object(class_name, note, uuid):
    """"""Passivate object by calling the stored procedure.""""""

    user_ref = get_authenticated_user()
    life_cycle_code = Livscyklus.PASSIVERET.value
    with open('templates/sql/passivate_or_delete_object.sql', 'r') as f:
        sql_raw = f.read()
    sql_template = Template(sql_raw)
    sql = sql_template.render(
        class_name=class_name,
        uuid=uuid,
        life_cycle_code=life_cycle_code,
        user_ref=user_ref,
        note=note
    )
    # Call PostgreSQL
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute(sql)
    output = cursor.fetchone()
    print output
    return output[0]


def update_object(class_name, note, attributes, states, relations, uuid=None):
    """"""Update object with the partial data supplied.""""""
    life_cycle_code = Livscyklus.RETTET.value
    user_ref = get_authenticated_user()

    attributes = convert_attributes(attributes)
    (
        sql_states, sql_attributes, sql_relations
    ) = sql_convert_registration(states, attributes, relations, class_name)

    with open('templates/sql/update_object.sql', 'r') as f:
        sql_raw = f.read()
    sql_template = Template(sql_raw)
    sql = sql_template.render(
        class_name=class_name,
        uuid=uuid,
        life_cycle_code=life_cycle_code,
        user_ref=user_ref,
        note=note,
        states=sql_states,
        attributes=sql_attributes,
        relations=sql_relations)
    # Call PostgreSQL
    conn = get_connection()
    cursor = conn.cursor()
    try:
        cursor.execute(sql)
        output = cursor.fetchone()
        print output
    except psycopg2.DataError:
        # Thrown when no changes
        pass
    return uuid


def list_objects(class_name, uuid, virkning_fra, virkning_til,
                 registreret_fra, registreret_til):
    """"""List objects with the given uuids, optionally filtering by the given
    virkning and registering periods.""""""

    assert isinstance(uuid, list)

    with open('templates/sql/list_objects.sql', 'r') as f:
        sql_raw = f.read()
    sql_template = Template(sql_raw)
    sql = sql_template.render(
        class_name=class_name
    )

    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute(sql, {
        'uuid': uuid,
        'registrering_tstzrange': DateTimeTZRange(registreret_fra,
                                                  registreret_til),
        'virkning_tstzrange': DateTimeTZRange(virkning_fra, virkning_til)
    })
    output = cursor.fetchone()
    return output
/n/n/n/klassifikation/rest/oio_rest.py/n/n
from flask import jsonify, request
import db


# Just a helper during debug
def j(t): return jsonify(output=t)


class OIOStandardHierarchy(object):
    """"""Implement API for entire hierarchy.""""""

    _classes = []

    @classmethod
    def setup_api(cls, flask, base_url):
        """"""Set up API for the classes included in the hierarchy.

        Note that version number etc. may have to be added to the URL.""""""
        for c in cls._classes:
            c.create_api(cls._name, flask, base_url)


class OIORestObject(object):
    """"""
    Implement an OIO object - manage access to database layer for this object.

    This class is intended to be subclassed, but not to be initialized.
    """"""

    @classmethod
    def create_object(cls):
        """"""
        CREATE object, generate new UUID.
        """"""
        if not request.json:
            abort(400)
        note = request.json.get(""Note"", """")
        attributes = request.json.get(""Attributter"", {})
        states = request.json.get(""Tilstande"", {})
        relations = request.json.get(""Relationer"", {})
        uuid = db.create_or_import_object(cls.__name__, note, attributes,
                                          states, relations)
        return jsonify({'uuid': uuid}), 201

    @classmethod
    def get_objects(cls):
        """"""
        LIST or SEARCH facets, depending on parameters.
        """"""
        virkning_fra = request.args.get('virkningFra', None)
        virkning_til = request.args.get('virkningTil', None)
        registreret_fra = request.args.get('registreretFra', None)
        registreret_til = request.args.get('registreretTil', None)

        # TODO: Implement search

        uuid = request.args.get('uuid', None)
        if uuid is None:
            # This is not allowed, but we let the DB layer throw an exception
            uuid = []
        else:
            uuid = uuid.split(',')

        results = db.list_objects(cls.__name__, uuid, virkning_fra,
                                 virkning_til, registreret_fra,
                                 registreret_til)
        if results is None:
            results = []
        # TODO: Return JSON object key should be based on class name,
        # e.g. {""Facetter"": [..]}, not {""results"": [..]}
        # TODO: Include Return value
        return jsonify({'results': results})

    @classmethod
    def get_object(cls, uuid):
        """"""
        READ a facet, return as JSON.
        """"""
        return j(""Hent {0} fra databasen og returner som JSON"".format(uuid))

    @classmethod
    def put_object(cls, uuid):
        """"""
        UPDATE, IMPORT or PASSIVIZE an  object.
        """"""
        if not request.json:
            abort(400)
        # Get most common parameters if available.
        note = request.json.get(""Note"", """")
        attributes = request.json.get(""Attributter"", {})
        states = request.json.get(""Tilstande"", {})
        relations = request.json.get(""Relationer"", {})

        if not db.object_exists(cls.__name__, uuid):
            # Do import.
            result = db.create_or_import_object(cls.__name__, note, attributes,
                                                states, relations, uuid)
            # TODO: When connected to DB, use result properly.
            return j(u""Importeret {0}: {1}"".format(cls.__name__, uuid)), 200
        else:
            ""Edit or passivate.""
            if (request.json.get('livscyklus', '').lower() == 'passiv'):
                # Passivate
                db.passivate_object(
                        cls.__name__, note, uuid
                )
                return j(
                            u""Passiveret {0}: {1}"".format(cls.__name__, uuid)
                        ), 200
            else:
                # Edit/change
                result = db.update_object(cls.__name__, note, attributes,
                                          states, relations, uuid)
                return j(u""Opdateret {0}: {1}"".format(cls.__name__, uuid)), 200
        return j(u""Forkerte parametre!""), 405

    @classmethod
    def delete_object(cls, uuid):
        # Delete facet
        #import pdb; pdb.set_trace()
        note = request.json.get(""Note"", """")
        class_name = cls.__name__
        result = db.delete_object(class_name, note, uuid)

        return j(""Slettet {0}: {1}"".format(class_name, uuid)), 200

    @classmethod
    def create_api(cls, hierarchy, flask, base_url):
        """"""Set up API with correct database access functions.""""""
        hierarchy = hierarchy.lower()
        class_name = cls.__name__.lower()
        class_url = u""{0}/{1}/{2}"".format(base_url,
                                          hierarchy,
                                          cls.__name__.lower())
        uuid_regex = (
            ""[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}"" +
            ""-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}""
        )
        object_url = u'{0}/<regex(""{1}""):uuid>'.format(
            class_url,
            uuid_regex
        )

        flask.add_url_rule(class_url, u'_'.join([cls.__name__, 'get_objects']),
                           cls.get_objects, methods=['GET'])

        flask.add_url_rule(object_url, u'_'.join([cls.__name__, 'get_object']),
                           cls.get_object, methods=['GET'])

        flask.add_url_rule(object_url, u'_'.join([cls.__name__, 'put_object']),
                           cls.put_object, methods=['PUT'])

        flask.add_url_rule(
            class_url, u'_'.join([cls.__name__, 'create_object']),
            cls.create_object, methods=['POST']
        )

        flask.add_url_rule(
            object_url, u'_'.join([cls.__name__, 'delete_object']),
            cls.delete_object, methods=['DELETE']
        )
/n/n/n",1
124,124,5329d91f9e569c95184053c8e7ef596949c33ce9,"modules/comment.py/n/nfrom modules import sql


class Comment:
    def __init__(self,conn):
        self.conn=conn;
    
    def getCommentsByUser(self,userid):
        sqlText=""select comment from comments order by date desc where userid=%s""
        params=[userid]
        result=sql.queryDB(self.conn,sqlText,params)
        return result;
    
    def getCommentsByPostid(self,postid,userid):
        sqlText=""select (select Count(*) from comment_like where \
        comments.commentid = comment_like.commentid) as like,(select Count(*) \
                from comment_like where comments.commentid = \
                comment_like.commentid and comment_like.userid=%s) as \
                flag,commentid,name,comment from users,comments where \
                users.userid=comments.userid and postid=%s order by date desc;""
        params=[userid,postid]
        result=sql.queryDB(self.conn,sqlText,params)
        return result;

    def getCommentsLike(self,commentid):
        sqlText=""select userid from comment_like where commentid=%s""
        params=[commentid]
        result=sql.queryDB(self.conn,sqlText,params)
        return result;
	
    def insertData(self,comment,userid,postid):
        sqlText=""insert into comments(comment,userid,date,postid) \
        values(%s,%s,current_timestamp(0),%s);""
        params=[comment,userid,postid]
        result=sql.insertDB(self.conn,sqlText,params)
        return result;

    def deleteComment(self,commentid):
        sqlText=""delete from comments where commentid=%s""
        params=[commentid]
        result=sql.deleteDB(self.conn,sqlText,params)
        return result;

    def likeComments(self,commentid,userid):
        sqlText=""insert into comment_like values(%s,%s);""
        params=[userid,commentid]
        result=sql.insertDB(self.conn,sqlText,params)
        return result;

    def dislikeComments(self,commentid,userid):
        sqlText=""delete from comment_like where commentid=%s and userid=%s;""
        params=[commentid,userid]
        result=sql.deleteDB(self.conn,sqlText,params)
        return result;



/n/n/nmodules/post.py/n/nfrom modules import sql


class Post:
    def __init__(self,conn):
        self.conn=conn;

    def getAllPosts(self,userid):
        sqlText=""select users.name,post.comment,post.postid,(select Count(*) from post_like \
                where post.postid = post_like.postid) as like,\
                (select Count(*) from post_like where post.postid =post_like.postid \
                and post_like.userid=%s) as flag from users,post \
                where post.userid=users.userid and (post.userid in \
                (select friendid from friends where userid =%s) or post.userid=%s)\
                order by post.date desc;""
        params=[userid,userid,userid]
        result=sql.queryDB(self.conn,sqlText,params)
        return result;
    
    def getPostsByPostid(self,postid):
        sqlText=""select users.name,post.comment from users,post where \
                users.userid=post.userid and post.postid=%s""
        params=[postid]
        result=sql.queryDB(self.conn,sqlText,params)
        return result;
    
    def getPostLike(self,postid):
        sqlText=""select userid from post_like where postid=%s""
        params=[postid]
        result=sql.queryDB(self.conn,sqlText,params)
        return result;

    def likePost(self,postid,userid):
        sqlText=""insert into post_like values(%s,%s);""
        params=[postid,userid]
        result=sql.insertDB(self.conn,sqlText,params)
        return result;

    def dislikePost(self,postid,userid):
        sqlText=""delete from post_like where postid=%s and userid=%s;""
        params=[postid,userid]
        result=sql.deleteDB(self.conn,sqlText,params)
        return result;

    def insertData(self,userid,post):
        sqlText=""insert into post(userid,date,comment) \
                values(%s,current_timestamp(0),%s);""
        params=[userid,post];
        result=sql.insertDB(self.conn,sqlText,params)
        return result;


    def deletePost(self,postid):
        sqlText=""delete from post where post.postid=%s""
        params=[postid]
        result=sql.deleteDB(self.conn,sqlText,params)
        return result;
/n/n/nmodules/sql.py/n/nimport psycopg2



#链接数据库
def connectDB(dbname,uname,psw):
    conn=psycopg2.connect(database=dbname,user=uname,password=psw,host=""127.0.0.1"",port=""5432"")
    return conn


#查询数据库
def queryDB(conn,sql_select,params):
    print(""query data"")
    cur=conn.cursor()
    try:
        cur.execute(sql_select,params)
        rows=cur.fetchall()
    except Exception as err:
        closeDB(conn)
        print(err)
    else:
        return rows



#插入数据
def insertDB(conn,sql_insert,params):
    cur=conn.cursor()
    try:
        cur.execute(sql_insert,params)
        conn.commit()
    except Exception as err:
        closeDB(conn)
        print(err)
    else: 
        print(""insert data successfull"")

#delete data
def deleteDB(conn,sql_delete,params):
    cur=conn.cursor()
    try:
        cur.execute(sql_delete,params)
        conn.commit()
    except Exception as err:
        closeDB(conn)
        print(err)
    else: 
        print(""delete data successfull"")


#update data
def updateDB(conn,sql_update,params):
    cur=conn.cursor()
    try:
        cur.execute(sql_update,params)
        conn.commit()
    except Exception as err:
        closeDB(conn)
        print(err)
    else: 
        print(""update data successfull"")



#关闭链接
def closeDB(conn):
    conn.close()



/n/n/nmodules/users.py/n/nfrom modules import sql

class Users:
    def __init__(self,conn=None,name=None,password=None,email=None,country=None):
        self.name=name
        self.password=password
        self.email=email
        self.country=country
        self.conn=conn

    def clean(self):
        self.name=None;
        self.password=None;
        self.email=None;
        self.count=None;
 

    def userLogin(self):

        sqlName=""select count(*) from users where name=%s and password=%s;""
        params = [self.name,self.password]
        checkName=sql.queryDB(self.conn,sqlName,params)
        result=checkName[0][0]
        if result == 0:
            self.clean()
            return False
        else:
            return True


    def userApply(self):
        sql_insert=""insert into \
                users(name,password,email,country,inscription_date) \
                values(%s,%s,%s,%s,current_timestamp(0));""

        sqlName=""select count(*) from users where name=%s;""
        params = [self.name]
        checkName=sql.queryDB(self.conn,sqlName,params)
        #no name
        if checkName[0][0] == 0:
            params.extend([self.password,self.email,self.country])
            sql.insertDB(self.conn,sql_insert,params)
            return True
        else:
            return False

    def getUserID(self):
        sqlName=""select userid from users where name=%s;""
        params = [self.name]
        userid=sql.queryDB(self.conn,sqlName,params)
        return userid[0][0];

    def getAllPosts(self):
        sqlText=""select comment from post where userid=%s order by date;""
        params = [self.userid]
        allposts=sql.queryDB(self.conn,sqlName,params)
        return allposts;


    def getAllComments(self):
        sqlText=""select comment from comments where userid=%s order by date;""
        params = [self.userid]
        allposts=sql.queryDB(self.conn,sqlText,params)
        return allposts;

    def getAllInformation(self,userid):
        sqlText=""select name,password,email,country from users where userid=%s;""
        params = [userid]
        information=sql.queryDB(self.conn,sqlText,params)
        return information;


    def modifyUserInfo(self,userid,flag):
        sqlText=""update users \
                set name=%s,password=%s,email=%s,country=%s where userid=%s;""
        if(flag==1): 
            sqlName=""select count(*) from users where name=%s;""
            params = [self.name]
            checkName=sql.queryDB(self.conn,sqlName,params)
            #no name
            if checkName[0][0] == 0:
                params.extend([self.password,self.email,self.country,userid])
                sql.updateDB(self.conn,sqlText,params)
                return True
            else:
                return False
        else:
            params=[self.name,self.password,self.email,self.country,userid]
            sql.updateDB(self.conn,sqlText,params)
            return True;

    def followFriends(self,userid,friendid):
        sqlText=""insert into friends values(%s,%s);""
        params=[friendid,userid]
        result=sql.insertDB(self.conn,sqlText,params)
        return result;

    def cancelFollow(self,userid,friendid):
        sqlText=""delete from friends where userid=%d and friendid=%s;""
        params=[userid,friendid]
        result=sql.deleteDB(self.conn,sqlText,params)
        return result;

    def getUsers(self,userid):
        sqlText=""select userid,name,country,(select Count(*) from friends \
                where users.userid=friends.friendid and friends.userid=%s) as follow \
                from users;""
        params=[userid]
        result=sql.queryDB(self.conn,sqlText,params)
        return result;


    def getUsersByName(self,userid,username):
        sqlText=""select userid,name,country,(select Count(*) from friends \
                where users.userid=friends.friendid and friends.userid=%s) as follow \
                from users where users.name~%s;""
        params=[userid,username]
        result=sql.queryDB(self.conn,sqlText,params)
        return result;







/n/n/n",0
125,125,5329d91f9e569c95184053c8e7ef596949c33ce9,"/modules/comment.py/n/nfrom modules import sql


class Comment:
    def __init__(self,conn):
        self.conn=conn;
    
    def getCommentsByUser(self,userid):
        sqlText=""select comment from comments order by date desc where userid=%d""%(userid)
        result=sql.queryDB(self.conn,sqlText)
        return result;
    
    def getCommentsByPostid(self,postid,userid):
        sqlText=""select (select Count(*) from comment_like where comments.commentid = comment_like.commentid) as like,(select Count(*) from comment_like where comments.commentid = comment_like.commentid and comment_like.userid=%d) as flag,commentid,name,comment from users,comments where users.userid=comments.userid and postid=%d order by date desc;""%(userid,postid)
        result=sql.queryDB(self.conn,sqlText)
        return result;

    def getCommentsLike(self,commentid):
        sqlText=""select userid from comment_like where commentid=%d""%(commentid)
        result=sql.queryDB(self.conn,sqlText)
        return result;
	
    def insertData(self,comment,userid,postid):
        sqlText=""insert into comments(comment,userid,date,postid) values('%s',%d,current_timestamp(0),%d);""%(comment,userid,postid)
        result=sql.insertDB(self.conn,sqlText)
        return result;

    def deleteComment(self,commentid):
        sqlText=""delete from comments where commentid=%d""%(commentid)
        result=sql.deleteDB(self.conn,sqlText)
        return result;

    def likeComments(self,commentid,userid):
        sqlText=""insert into comment_like values(%d,%d);""%(userid,commentid)
        result=sql.insertDB(self.conn,sqlText)
        return result;

    def dislikeComments(self,commentid,userid):
        sqlText=""delete from comment_like where commentid=%d and userid=%d;""%(commentid,userid)
        result=sql.deleteDB(self.conn,sqlText)
        return result;



/n/n/n/modules/post.py/n/nfrom modules import sql


class Post:
    def __init__(self,conn):
        self.conn=conn;

    def getAllPosts(self,userid):
        sqlText=""select users.name,post.comment,post.postid,(select Count(*) from post_like \
                where post.postid = post_like.postid) as like,\
                (select Count(*) from post_like where post.postid =post_like.postid \
                and post_like.userid=%d) as flag from users,post \
                where post.userid=users.userid and (post.userid in \
                (select friendid from friends where userid =%d) or post.userid=%d )\
                order by post.date desc;""%(userid,userid,userid)
        result=sql.queryDB(self.conn,sqlText)
        return result;
    
    def getPostsByPostid(self,postid):
        sqlText=""select users.name,post.comment from users,post where \
                users.userid=post.userid and post.postid=%d""%(postid)
        result=sql.queryDB(self.conn,sqlText)
        return result;
    
    def getPostLike(self,postid):
        sqlText=""select userid from post_like where postid=%d""%(postid)
        result=sql.queryDB(self.conn,sqlText)
        return result;

    def likePost(self,postid,userid):
        sqlText=""insert into post_like values(%d,%d);""%(postid,userid)
        result=sql.insertDB(self.conn,sqlText)
        return result;

    def dislikePost(self,postid,userid):
        sqlText=""delete from post_like where postid=%d and userid=%d;""%(postid,userid)
        result=sql.deleteDB(self.conn,sqlText)
        return result;

    def insertData(self,userid,post):
        sqlText=""insert into post(userid,date,comment) \
                values(%d,current_timestamp(0),'%s');""%(userid,post);
        result=sql.insertDB(self.conn,sqlText)
        return result;


    def deletePost(self,postid):
        sqlText=""delete from post where post.postid=%d""%(postid)
        result=sql.deleteDB(self.conn,sqlText)
        return result;
/n/n/n/modules/sql.py/n/nimport psycopg2



#链接数据库
def connectDB(dbname,uname,psw):
    #conn=psycopg2.connect(database=""test"",user=""lishaomin"",password=""19931004"",host=""127.0.0.1"",port=""5432"")
    conn=psycopg2.connect(database=dbname,user=uname,password=psw,host=""127.0.0.1"",port=""5432"")
    return conn


#查询数据库
def queryDB(conn,sql_select):
    print(""query data"")
    cur=conn.cursor()
    #sql_select=""select * from users;""
    cur.execute(sql_select)
    rows=cur.fetchall()
    #for row in rows:
    #print (""user:%s""%(row[1]))
    return rows



#插入数据
def insertDB(conn,sql_insert):
    cur=conn.cursor()
    result=cur.execute(sql_insert)
    conn.commit()
    print(""insert data successfull"")
    return result

#delete data
def deleteDB(conn,sql_delete):
    cur=conn.cursor()
    result=cur.execute(sql_delete)
    conn.commit()
    print(""delete data successfull"")
    return result


#update data
def updateDB(conn,sql_update):
    cur=conn.cursor()
    result=cur.execute(sql_update)
    conn.commit()
    print(""update data successfull"")
    return result


#关闭链接
def closeDB(conn):
    conn.close()



/n/n/n/modules/users.py/n/nfrom modules import sql

class Users:
    def __init__(self,conn=None,name=None,password=None,email=None,country=None):
        self.name=name
        self.password=password
        self.email=email
        self.country=country
        self.conn=conn

    def clean(self):
        self.name=None;
        self.password=None;
        self.email=None;
        self.count=None;
 

    def userLogin(self):

        sqlName=""select count(*) from users where name='%s' and \
                password='%s';""%(self.name,self.password)
        checkName=sql.queryDB(self.conn,sqlName)

        result=checkName[0][0]
        if result == 0:
            self.clean()
            return False
        else:
            return True


    def userApply(self):
        t_sql_insert=""insert into \
                users(name,password,email,country,inscription_date) \
                values('{name}','{psw}','{email}','{country}',current_timestamp(0));""
        sql_insert=t_sql_insert.format(name=self.name,psw=self.password,\
                email=self.email,country=self.country)

        sqlName=""select count(*) from users where name='%s';""%(self.name)
        checkName=sql.queryDB(self.conn,sqlName)
    
        #no name
        if checkName[0][0] == 0:
            sql.insertDB(self.conn,sql_insert)
            return True
        else:
            return False

    def getUserID(self):
        sqlName=""select userid from users where name='%s';""%(self.name)
        userid=sql.queryDB(self.conn,sqlName)
        return userid[0][0];

    def getAllPosts(self):
        sqlText=""select comment from post where userid=%d order by date;""
        allposts=sql.queryDB(self.conn,sqlText)
        return allposts;


    def getAllComments(self):
        sqlText=""select comment from comments where userid=%d order by date;""
        allposts=sql.queryDB(self.conn,sqlText)
        return allposts;

    def getAllInformation(self,userid):
        sqlText=""select name,password,email,country from users where userid=%d;""%(userid)
        information=sql.queryDB(self.conn,sqlText)
        return information;


    def modifyUserInfo(self,userid,flag):
        sqlText=""update users \
                set name='%s',password='%s',email='%s',country='%s' \
                where userid='%d';""%(self.name,self.password,self.email,self.country,userid)
        if(flag==1): 
            sqlName=""select count(*) from users where name='%s';""%(self.name)
            checkName=sql.queryDB(self.conn,sqlName)
            #no name
            if checkName[0][0] == 0:
                sql.updateDB(self.conn,sqlText)
                return True
            else:
                return False
        else:
            sql.updateDB(self.conn,sqlText)
            return True;

    def followFriends(self,userid,friendid):
        sqlText=""insert into friends values(%d,%d);""%(friendid,userid)
        result=sql.insertDB(self.conn,sqlText)
        return result;

    def cancelFollow(self,userid,friendid):
        sqlText=""delete from friends where userid=%d and friendid=%d;""%(userid,friendid)
        result=sql.deleteDB(self.conn,sqlText)
        return result;

    def getUsers(self,userid):
        sqlText=""select userid,name,country,(select Count(*) from friends \
                where users.userid=friends.friendid and friends.userid=%d) as follow \
                from users;""%(userid)
        result=sql.queryDB(self.conn,sqlText)
        return result;


    def getUsersByName(self,userid,username):
        sqlText=""select userid,name,country,(select Count(*) from friends \
                where users.userid=friends.friendid and friends.userid=%d) as follow \
                from users where users.name='%s';""%(userid,username)
        result=sql.queryDB(self.conn,sqlText)
        return result;







/n/n/n",1
12,12,ad9fef5f416ef31eb3fdf7c1774434092fd6a52c,"sabnzbd/database.py/n/n#!/usr/bin/python -OO
# Copyright 2008-2017 The SABnzbd-Team <team@sabnzbd.org>
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

""""""
sabnzbd.database - Database Support
""""""

try:
    import sqlite3
except:
    try:
        import pysqlite2.dbapi2 as sqlite3
    except:
        pass

import os
import time
import zlib
import logging
import sys
import threading

import sabnzbd
import sabnzbd.cfg
from sabnzbd.constants import DB_HISTORY_NAME, STAGES
from sabnzbd.encoding import unicoder
from sabnzbd.bpsmeter import this_week, this_month
from sabnzbd.decorators import synchronized
from sabnzbd.misc import get_all_passwords, int_conv

DB_LOCK = threading.RLock()


def convert_search(search):
    """""" Convert classic wildcard to SQL wildcard """"""
    if not search:
        # Default value
        search = ''
    else:
        # Allow * for wildcard matching and space
        search = search.replace('*', '%').replace(' ', '%')

    # Allow ^ for start of string and $ for end of string
    if search and search.startswith('^'):
        search = search.replace('^', '')
        search += '%'
    elif search and search.endswith('$'):
        search = search.replace('$', '')
        search = '%' + search
    else:
        search = '%' + search + '%'
    return search


class HistoryDB(object):
    """""" Class to access the History database
        Each class-instance will create an access channel that
        can be used in one thread.
        Each thread needs its own class-instance!
    """"""
    # These class attributes will be accessed directly because
    # they need to be shared by all instances
    db_path = None        # Will contain full path to history database
    done_cleaning = False # Ensure we only do one Vacuum per session

    @synchronized(DB_LOCK)
    def __init__(self):
        """""" Determine databse path and create connection """"""
        self.con = self.c = None
        if not HistoryDB.db_path:
            HistoryDB.db_path = os.path.join(sabnzbd.cfg.admin_dir.get_path(), DB_HISTORY_NAME)
        self.connect()


    def connect(self):
        """""" Create a connection to the database """"""
        create_table = not os.path.exists(HistoryDB.db_path)
        self.con = sqlite3.connect(HistoryDB.db_path)
        self.con.row_factory = dict_factory
        self.c = self.con.cursor()
        if create_table:
            self.create_history_db()
        elif not HistoryDB.done_cleaning:
            # Run VACUUM on sqlite
            # When an object (table, index, or trigger) is dropped from the database, it leaves behind empty space
            # http://www.sqlite.org/lang_vacuum.html
            HistoryDB.done_cleaning = True
            self.execute('VACUUM')

        self.execute('PRAGMA user_version;')
        try:
            version = self.c.fetchone()['user_version']
        except TypeError:
            version = 0
        if version < 1:
            # Add any missing columns added since first DB version
            # Use ""and"" to stop when database has been reset due to corruption
            _ = self.execute('PRAGMA user_version = 1;') and \
                self.execute('ALTER TABLE ""history"" ADD COLUMN series TEXT;') and \
                self.execute('ALTER TABLE ""history"" ADD COLUMN md5sum TEXT;')
        if version < 2:
            # Add any missing columns added since second DB version
            # Use ""and"" to stop when database has been reset due to corruption
            _ = self.execute('PRAGMA user_version = 2;') and \
                self.execute('ALTER TABLE ""history"" ADD COLUMN password TEXT;')


    def execute(self, command, args=(), save=False):
        ''' Wrapper for executing SQL commands '''
        for tries in xrange(5, 0, -1):
            try:
                if args and isinstance(args, tuple):
                    self.c.execute(command, args)
                else:
                    self.c.execute(command)
                if save:
                    self.save()
                return True
            except:
                error = str(sys.exc_value)
                if tries >= 0 and 'is locked' in error:
                    logging.debug('Database locked, wait and retry')
                    time.sleep(0.5)
                    continue
                elif 'readonly' in error:
                    logging.error(T('Cannot write to History database, check access rights!'))
                    # Report back success, because there's no recovery possible
                    return True
                elif 'not a database' in error or 'malformed' in error or 'duplicate column name' in error:
                    logging.error(T('Damaged History database, created empty replacement'))
                    logging.info(""Traceback: "", exc_info=True)
                    self.close()
                    try:
                        os.remove(HistoryDB.db_path)
                    except:
                        pass
                    self.connect()
                    # Return False in case of ""duplicate column"" error
                    # because the column addition in connect() must be terminated
                    return 'duplicate column name' not in error
                else:
                    logging.error(T('SQL Command Failed, see log'))
                    logging.info(""SQL: %s"", command)
                    logging.info(""Arguments: %s"", repr(args))
                    logging.info(""Traceback: "", exc_info=True)
                    try:
                        self.con.rollback()
                    except:
                        logging.debug(""Rollback Failed:"", exc_info=True)
            return False

    def create_history_db(self):
        """""" Create a new (empty) database file """"""
        self.execute(""""""
        CREATE TABLE ""history"" (
            ""id"" INTEGER PRIMARY KEY,
            ""completed"" INTEGER NOT NULL,
            ""name"" TEXT NOT NULL,
            ""nzb_name"" TEXT NOT NULL,
            ""category"" TEXT,
            ""pp"" TEXT,
            ""script"" TEXT,
            ""report"" TEXT,
            ""url"" TEXT,
            ""status"" TEXT,
            ""nzo_id"" TEXT,
            ""storage"" TEXT,
            ""path"" TEXT,
            ""script_log"" BLOB,
            ""script_line"" TEXT,
            ""download_time"" INTEGER,
            ""postproc_time"" INTEGER,
            ""stage_log"" TEXT,
            ""downloaded"" INTEGER,
            ""completeness"" INTEGER,
            ""fail_message"" TEXT,
            ""url_info"" TEXT,
            ""bytes"" INTEGER,
            ""meta"" TEXT,
            ""series"" TEXT,
            ""md5sum"" TEXT,
            ""password"" TEXT
        )
        """""")
        self.execute('PRAGMA user_version = 2;')

    def save(self):
        """""" Save database to disk """"""
        try:
            self.con.commit()
        except:
            logging.error(T('SQL Commit Failed, see log'))
            logging.info(""Traceback: "", exc_info=True)

    def close(self):
        """""" Close database connection """"""
        try:
            self.c.close()
            self.con.close()
        except:
            logging.error(T('Failed to close database, see log'))
            logging.info(""Traceback: "", exc_info=True)

    def remove_completed(self, search=None):
        """""" Remove all completed jobs from the database, optional with `search` pattern """"""
        search = convert_search(search)
        logging.info('Removing all completed jobs from history')
        return self.execute(""""""DELETE FROM history WHERE name LIKE ? AND status = 'Completed'"""""", (search,), save=True)

    def get_failed_paths(self, search=None):
        """""" Return list of all storage paths of failed jobs (may contain non-existing or empty paths) """"""
        search = convert_search(search)
        fetch_ok = self.execute(""""""SELECT path FROM history WHERE name LIKE ? AND status = 'Failed'"""""", (search,))
        if fetch_ok:
            return [item.get('path') for item in self.c.fetchall()]
        else:
            return []

    def remove_failed(self, search=None):
        """""" Remove all failed jobs from the database, optional with `search` pattern """"""
        search = convert_search(search)
        logging.info('Removing all failed jobs from history')
        return self.execute(""""""DELETE FROM history WHERE name LIKE ? AND status = 'Failed'"""""", (search,), save=True)

    def remove_history(self, jobs=None):
        """""" Remove all jobs in the list `jobs`, empty list will remove all completed jobs """"""
        if jobs is None:
            self.remove_completed()
        else:
            if not isinstance(jobs, list):
                jobs = [jobs]

            for job in jobs:
                self.execute(""""""DELETE FROM history WHERE nzo_id=?"""""", (job,))
                logging.info('Removing job %s from history', job)

        self.save()

    def auto_history_purge(self):
        """""" Remove history items based on the configured history-retention """"""
        if sabnzbd.cfg.history_retention() == ""0"":
            return

        if sabnzbd.cfg.history_retention() == ""-1"":
            # Delete all non-failed ones
            self.remove_completed()

        if ""d"" in sabnzbd.cfg.history_retention():
            # How many days to keep?
            days_to_keep = int_conv(sabnzbd.cfg.history_retention().strip()[:-1])
            seconds_to_keep = int(time.time()) - days_to_keep*3600*24
            if days_to_keep > 0:
                logging.info('Removing completed jobs older than %s days from history', days_to_keep)
                return self.execute(""""""DELETE FROM history WHERE status = 'Completed' AND completed < ?"""""", (seconds_to_keep,), save=True)
        else:
            # How many to keep?
            to_keep = int_conv(sabnzbd.cfg.history_retention())
            if to_keep > 0:
                logging.info('Removing all but last %s completed jobs from history', to_keep)
                return self.execute(""""""DELETE FROM history WHERE id NOT IN ( SELECT id FROM history WHERE status = 'Completed' ORDER BY completed DESC LIMIT ? )"""""", (to_keep,), save=True)


    def add_history_db(self, nzo, storage, path, postproc_time, script_output, script_line):
        """""" Add a new job entry to the database """"""
        t = build_history_info(nzo, storage, path, postproc_time, script_output, script_line)

        if self.execute(""""""INSERT INTO history (completed, name, nzb_name, category, pp, script, report,
        url, status, nzo_id, storage, path, script_log, script_line, download_time, postproc_time, stage_log,
        downloaded, completeness, fail_message, url_info, bytes, series, md5sum, password)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)"""""", t):
            self.save()
        logging.info('Added job %s to history', nzo.final_name)

    def fetch_history(self, start=None, limit=None, search=None, failed_only=0, categories=None):
        """""" Return records for specified jobs """"""
        command_args = [convert_search(search)]

        post = ''
        if categories:
            categories = ['*' if c == 'Default' else c for c in categories]
            post = "" AND (CATEGORY = ?""
            post += "" OR CATEGORY = ? "" * (len(categories)-1)
            post += "")""
            command_args.extend(categories)
        if failed_only:
            post += ' AND STATUS = ""Failed""'

        cmd = 'SELECT COUNT(*) FROM history WHERE name LIKE ?'
        res = self.execute(cmd + post, tuple(command_args))
        total_items = -1
        if res:
            try:
                total_items = self.c.fetchone().get('COUNT(*)')
            except AttributeError:
                pass

        if not start:
            start = 0
        if not limit:
            limit = total_items

        command_args.extend([start, limit])
        cmd = 'SELECT * FROM history WHERE name LIKE ?'
        fetch_ok = self.execute(cmd + post + ' ORDER BY completed desc LIMIT ?, ?', tuple(command_args))

        if fetch_ok:
            items = self.c.fetchall()
        else:
            items = []

        fetched_items = len(items)

        # Unpack the single line stage log
        # Stage Name is separated by ::: stage lines by ; and stages by \r\n
        items = [unpack_history_info(item) for item in items]

        return (items, fetched_items, total_items)

    def have_episode(self, series, season, episode):
        """""" Check whether History contains this series episode """"""
        total = 0
        series = series.lower().replace('.', ' ').replace('_', ' ').replace('  ', ' ')
        if series and season and episode:
            pattern = '%s/%s/%s' % (series, season, episode)
            res = self.execute(""select count(*) from History WHERE series = ? AND STATUS != 'Failed'"", (pattern,))
            if res:
                try:
                    total = self.c.fetchone().get('count(*)')
                except AttributeError:
                    pass
        return total > 0

    def have_md5sum(self, md5sum):
        """""" Check whether this md5sum already in History """"""
        total = 0
        res = self.execute(""select count(*) from History WHERE md5sum = ? AND STATUS != 'Failed'"", (md5sum,))
        if res:
            try:
                total = self.c.fetchone().get('count(*)')
            except AttributeError:
                pass
        return total > 0

    def get_history_size(self):
        """""" Returns the total size of the history and
            amounts downloaded in the last month and week
        """"""
        # Total Size of the history
        total = 0
        if self.execute('''SELECT sum(bytes) FROM history'''):
            try:
                total = self.c.fetchone().get('sum(bytes)')
            except AttributeError:
                pass

        # Amount downloaded this month
        # r = time.gmtime(time.time())
        # month_timest = int(time.mktime((r.tm_year, r.tm_mon, 0, 0, 0, 1, r.tm_wday, r.tm_yday, r.tm_isdst)))
        month_timest = int(this_month(time.time()))

        month = 0
        if self.execute('''SELECT sum(bytes) FROM history WHERE ""completed"">?''', (month_timest,)):
            try:
                month = self.c.fetchone().get('sum(bytes)')
            except AttributeError:
                pass

        # Amount downloaded this week
        week_timest = int(this_week(time.time()))

        week = 0
        if self.execute('''SELECT sum(bytes) FROM history WHERE ""completed"">?''', (week_timest,)):
            try:
                week = self.c.fetchone().get('sum(bytes)')
            except AttributeError:
                pass

        return (total, month, week)

    def get_script_log(self, nzo_id):
        """""" Return decompressed log file """"""
        data = ''
        t = (nzo_id,)
        if self.execute('SELECT script_log FROM history WHERE nzo_id=?', t):
            try:
                data = zlib.decompress(self.c.fetchone().get('script_log'))
            except:
                pass
        return data

    def get_name(self, nzo_id):
        """""" Return name of the job `nzo_id` """"""
        t = (nzo_id,)
        name = ''
        if self.execute('SELECT name FROM history WHERE nzo_id=?', t):
            try:
                name = self.c.fetchone().get('name')
            except AttributeError:
                pass
        return name

    def get_path(self, nzo_id):
        """""" Return the `incomplete` path of the job `nzo_id` """"""
        t = (nzo_id,)
        path = ''
        if self.execute('SELECT path FROM history WHERE nzo_id=?', t):
            try:
                path = self.c.fetchone().get('path')
            except AttributeError:
                pass
        return path

    def get_other(self, nzo_id):
        """""" Return additional data for job `nzo_id` """"""
        t = (nzo_id,)
        if self.execute('SELECT * FROM history WHERE nzo_id=?', t):
            try:
                items = self.c.fetchall()[0]
                dtype = items.get('report')
                url = items.get('url')
                pp = items.get('pp')
                script = items.get('script')
                cat = items.get('category')
            except (AttributeError, IndexError):
                return '', '', '', '', ''
        return dtype, url, pp, script, cat


def dict_factory(cursor, row):
    """""" Return a dictionary for the current database position """"""
    d = {}
    for idx, col in enumerate(cursor.description):
        d[col[0]] = row[idx]
    return d


_PP_LOOKUP = {0: '', 1: 'R', 2: 'U', 3: 'D'}
def build_history_info(nzo, storage='', downpath='', postproc_time=0, script_output='', script_line=''):
    """""" Collects all the information needed for the database """"""

    if not downpath:
        downpath = nzo.downpath
    path = decode_factory(downpath)
    storage = decode_factory(storage)
    script_line = decode_factory(script_line)

    flagRepair, flagUnpack, flagDelete = nzo.repair_opts
    nzo_info = decode_factory(nzo.nzo_info)

    url = decode_factory(nzo.url)

    completed = int(time.time())
    name = decode_factory(nzo.final_name)

    nzb_name = decode_factory(nzo.filename)
    category = decode_factory(nzo.cat)
    pp = _PP_LOOKUP.get(sabnzbd.opts_to_pp(flagRepair, flagUnpack, flagDelete), 'X')
    script = decode_factory(nzo.script)
    status = decode_factory(nzo.status)
    nzo_id = nzo.nzo_id
    bytes = nzo.bytes_downloaded

    if script_output:
        # Compress the output of the script
        script_log = sqlite3.Binary(zlib.compress(script_output))
        #
    else:
        script_log = ''

    download_time = decode_factory(nzo_info.get('download_time', 0))

    downloaded = nzo.bytes_downloaded
    completeness = 0
    fail_message = decode_factory(nzo.fail_msg)
    url_info = nzo_info.get('details', '') or nzo_info.get('more_info', '')

    # Get the dictionary containing the stages and their unpack process
    stages = decode_factory(nzo.unpack_info)
    # Pack the dictionary up into a single string
    # Stage Name is separated by ::: stage lines by ; and stages by \r\n
    lines = []
    for key, results in stages.iteritems():
        lines.append('%s:::%s' % (key, ';'.join(results)))
    stage_log = '\r\n'.join(lines)

    # Reuse the old 'report' column to indicate a URL-fetch
    report = 'future' if nzo.futuretype else ''

    # Analyze series info only when job is finished
    series = u''
    if postproc_time:
        seriesname, season, episode, dummy = sabnzbd.newsunpack.analyse_show(nzo.final_name)
        if seriesname and season and episode:
            series = u'%s/%s/%s' % (seriesname.lower(), season, episode)

    # See whatever the first password was, for the Retry
    password = ''
    passwords = get_all_passwords(nzo)
    if passwords:
        password = passwords[0]

    return (completed, name, nzb_name, category, pp, script, report, url, status, nzo_id, storage, path,
            script_log, script_line, download_time, postproc_time, stage_log, downloaded, completeness,
            fail_message, url_info, bytes, series, nzo.md5sum, password)



def unpack_history_info(item):
    """""" Expands the single line stage_log from the DB
        into a python dictionary for use in the history display
    """"""
    # Stage Name is separated by ::: stage lines by ; and stages by \r\n
    lst = item['stage_log']
    if lst:
        try:
            lines = lst.split('\r\n')
        except:
            logging.error(T('Invalid stage logging in history for %s') + ' (\\r\\n)', unicoder(item['name']))
            logging.debug('Lines: %s', lst)
            lines = []
        lst = [None for x in STAGES]
        for line in lines:
            stage = {}
            try:
                key, logs = line.split(':::')
            except:
                logging.debug('Missing key:::logs ""%s""', line)
                key = line
                logs = ''
            stage['name'] = key
            stage['actions'] = []
            try:
                logs = logs.split(';')
            except:
                logging.error(T('Invalid stage logging in history for %s') + ' (;)', unicoder(item['name']))
                logging.debug('Logs: %s', logs)
                logs = []
            for log in logs:
                stage['actions'].append(log)
            try:
                lst[STAGES[key]] = stage
            except KeyError:
                lst.append(stage)
        # Remove unused stages
        item['stage_log'] = [x for x in lst if x is not None]

    if item['script_log']:
        item['script_log'] = ''
    # The action line is only available for items in the postproc queue
    if 'action_line' not in item:
        item['action_line'] = ''
    return item


def midnight_history_purge():
    logging.info('Scheduled history purge')
    history_db = HistoryDB()
    history_db.auto_history_purge()
    history_db.close()


def decode_factory(text):
    """""" Recursively looks through the supplied argument
        and converts and text to Unicode
    """"""
    if isinstance(text, str):
        return unicoder(text)

    elif isinstance(text, list):
        new_text = []
        for t in text:
            new_text.append(decode_factory(t))
        return new_text

    elif isinstance(text, dict):
        new_text = {}
        for key in text:
            new_text[key] = decode_factory(text[key])
        return new_text
    else:
        return text
/n/n/n",0
13,13,ad9fef5f416ef31eb3fdf7c1774434092fd6a52c,"/sabnzbd/database.py/n/n#!/usr/bin/python -OO
# Copyright 2008-2017 The SABnzbd-Team <team@sabnzbd.org>
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

""""""
sabnzbd.database - Database Support
""""""

try:
    import sqlite3
except:
    try:
        import pysqlite2.dbapi2 as sqlite3
    except:
        pass

import os
import time
import zlib
import logging
import sys
import threading

import sabnzbd
import sabnzbd.cfg
from sabnzbd.constants import DB_HISTORY_NAME, STAGES
from sabnzbd.encoding import unicoder
from sabnzbd.bpsmeter import this_week, this_month
from sabnzbd.decorators import synchronized
from sabnzbd.misc import get_all_passwords, int_conv

DB_LOCK = threading.RLock()


def convert_search(search):
    """""" Convert classic wildcard to SQL wildcard """"""
    if not search:
        # Default value
        search = ''
    else:
        # Allow * for wildcard matching and space
        search = search.replace('*', '%').replace(' ', '%')

    # Allow ^ for start of string and $ for end of string
    if search and search.startswith('^'):
        search = search.replace('^', '')
        search += '%'
    elif search and search.endswith('$'):
        search = search.replace('$', '')
        search = '%' + search
    else:
        search = '%' + search + '%'
    return search


class HistoryDB(object):
    """""" Class to access the History database
        Each class-instance will create an access channel that
        can be used in one thread.
        Each thread needs its own class-instance!
    """"""
    # These class attributes will be accessed directly because
    # they need to be shared by all instances
    db_path = None        # Will contain full path to history database
    done_cleaning = False # Ensure we only do one Vacuum per session

    @synchronized(DB_LOCK)
    def __init__(self):
        """""" Determine databse path and create connection """"""
        self.con = self.c = None
        if not HistoryDB.db_path:
            HistoryDB.db_path = os.path.join(sabnzbd.cfg.admin_dir.get_path(), DB_HISTORY_NAME)
        self.connect()


    def connect(self):
        """""" Create a connection to the database """"""
        create_table = not os.path.exists(HistoryDB.db_path)
        self.con = sqlite3.connect(HistoryDB.db_path)
        self.con.row_factory = dict_factory
        self.c = self.con.cursor()
        if create_table:
            self.create_history_db()
        elif not HistoryDB.done_cleaning:
            # Run VACUUM on sqlite
            # When an object (table, index, or trigger) is dropped from the database, it leaves behind empty space
            # http://www.sqlite.org/lang_vacuum.html
            HistoryDB.done_cleaning = True
            self.execute('VACUUM')

        self.execute('PRAGMA user_version;')
        try:
            version = self.c.fetchone()['user_version']
        except TypeError:
            version = 0
        if version < 1:
            # Add any missing columns added since first DB version
            # Use ""and"" to stop when database has been reset due to corruption
            _ = self.execute('PRAGMA user_version = 1;') and \
                self.execute('ALTER TABLE ""history"" ADD COLUMN series TEXT;') and \
                self.execute('ALTER TABLE ""history"" ADD COLUMN md5sum TEXT;')
        if version < 2:
            # Add any missing columns added since second DB version
            # Use ""and"" to stop when database has been reset due to corruption
            _ = self.execute('PRAGMA user_version = 2;') and \
                self.execute('ALTER TABLE ""history"" ADD COLUMN password TEXT;')


    def execute(self, command, args=(), save=False):
        ''' Wrapper for executing SQL commands '''
        for tries in xrange(5, 0, -1):
            try:
                if args and isinstance(args, tuple):
                    self.c.execute(command, args)
                else:
                    self.c.execute(command)
                if save:
                    self.save()
                return True
            except:
                error = str(sys.exc_value)
                if tries >= 0 and 'is locked' in error:
                    logging.debug('Database locked, wait and retry')
                    time.sleep(0.5)
                    continue
                elif 'readonly' in error:
                    logging.error(T('Cannot write to History database, check access rights!'))
                    # Report back success, because there's no recovery possible
                    return True
                elif 'not a database' in error or 'malformed' in error or 'duplicate column name' in error:
                    logging.error(T('Damaged History database, created empty replacement'))
                    logging.info(""Traceback: "", exc_info=True)
                    self.close()
                    try:
                        os.remove(HistoryDB.db_path)
                    except:
                        pass
                    self.connect()
                    # Return False in case of ""duplicate column"" error
                    # because the column addition in connect() must be terminated
                    return 'duplicate column name' not in error
                else:
                    logging.error(T('SQL Command Failed, see log'))
                    logging.debug(""SQL: %s"", command)
                    logging.info(""Traceback: "", exc_info=True)
                    try:
                        self.con.rollback()
                    except:
                        logging.debug(""Rollback Failed:"", exc_info=True)
            return False

    def create_history_db(self):
        """""" Create a new (empty) database file """"""
        self.execute(""""""
        CREATE TABLE ""history"" (
            ""id"" INTEGER PRIMARY KEY,
            ""completed"" INTEGER NOT NULL,
            ""name"" TEXT NOT NULL,
            ""nzb_name"" TEXT NOT NULL,
            ""category"" TEXT,
            ""pp"" TEXT,
            ""script"" TEXT,
            ""report"" TEXT,
            ""url"" TEXT,
            ""status"" TEXT,
            ""nzo_id"" TEXT,
            ""storage"" TEXT,
            ""path"" TEXT,
            ""script_log"" BLOB,
            ""script_line"" TEXT,
            ""download_time"" INTEGER,
            ""postproc_time"" INTEGER,
            ""stage_log"" TEXT,
            ""downloaded"" INTEGER,
            ""completeness"" INTEGER,
            ""fail_message"" TEXT,
            ""url_info"" TEXT,
            ""bytes"" INTEGER,
            ""meta"" TEXT,
            ""series"" TEXT,
            ""md5sum"" TEXT,
            ""password"" TEXT
        )
        """""")
        self.execute('PRAGMA user_version = 2;')

    def save(self):
        """""" Save database to disk """"""
        try:
            self.con.commit()
        except:
            logging.error(T('SQL Commit Failed, see log'))
            logging.info(""Traceback: "", exc_info=True)

    def close(self):
        """""" Close database connection """"""
        try:
            self.c.close()
            self.con.close()
        except:
            logging.error(T('Failed to close database, see log'))
            logging.info(""Traceback: "", exc_info=True)

    def remove_completed(self, search=None):
        """""" Remove all completed jobs from the database, optional with `search` pattern """"""
        search = convert_search(search)
        logging.info('Removing all completed jobs from history')
        return self.execute(""""""DELETE FROM history WHERE name LIKE ? AND status = 'Completed'"""""", (search,), save=True)

    def get_failed_paths(self, search=None):
        """""" Return list of all storage paths of failed jobs (may contain non-existing or empty paths) """"""
        search = convert_search(search)
        fetch_ok = self.execute(""""""SELECT path FROM history WHERE name LIKE ? AND status = 'Failed'"""""", (search,))
        if fetch_ok:
            return [item.get('path') for item in self.c.fetchall()]
        else:
            return []

    def remove_failed(self, search=None):
        """""" Remove all failed jobs from the database, optional with `search` pattern """"""
        search = convert_search(search)
        logging.info('Removing all failed jobs from history')
        return self.execute(""""""DELETE FROM history WHERE name LIKE ? AND status = 'Failed'"""""", (search,), save=True)

    def remove_history(self, jobs=None):
        """""" Remove all jobs in the list `jobs`, empty list will remove all completed jobs """"""
        if jobs is None:
            self.remove_completed()
        else:
            if not isinstance(jobs, list):
                jobs = [jobs]

            for job in jobs:
                self.execute(""""""DELETE FROM history WHERE nzo_id=?"""""", (job,))
                logging.info('Removing job %s from history', job)

        self.save()

    def auto_history_purge(self):
        """""" Remove history items based on the configured history-retention """"""
        if sabnzbd.cfg.history_retention() == ""0"":
            return

        if sabnzbd.cfg.history_retention() == ""-1"":
            # Delete all non-failed ones
            self.remove_completed()

        if ""d"" in sabnzbd.cfg.history_retention():
            # How many days to keep?
            days_to_keep = int_conv(sabnzbd.cfg.history_retention().strip()[:-1])
            seconds_to_keep = int(time.time()) - days_to_keep*3600*24
            if days_to_keep > 0:
                logging.info('Removing completed jobs older than %s days from history', days_to_keep)
                return self.execute(""""""DELETE FROM history WHERE status = 'Completed' AND completed < ?"""""", (seconds_to_keep,), save=True)
        else:
            # How many to keep?
            to_keep = int_conv(sabnzbd.cfg.history_retention())
            if to_keep > 0:
                logging.info('Removing all but last %s completed jobs from history', to_keep)
                return self.execute(""""""DELETE FROM history WHERE id NOT IN ( SELECT id FROM history WHERE status = 'Completed' ORDER BY completed DESC LIMIT ? )"""""", (to_keep,), save=True)


    def add_history_db(self, nzo, storage, path, postproc_time, script_output, script_line):
        """""" Add a new job entry to the database """"""
        t = build_history_info(nzo, storage, path, postproc_time, script_output, script_line)

        if self.execute(""""""INSERT INTO history (completed, name, nzb_name, category, pp, script, report,
        url, status, nzo_id, storage, path, script_log, script_line, download_time, postproc_time, stage_log,
        downloaded, completeness, fail_message, url_info, bytes, series, md5sum, password)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)"""""", t):
            self.save()
        logging.info('Added job %s to history', nzo.final_name)

    def fetch_history(self, start=None, limit=None, search=None, failed_only=0, categories=None):
        """""" Return records for specified jobs """"""
        search = convert_search(search)

        post = ''
        if categories:
            categories = ['*' if c == 'Default' else c for c in categories]
            post = "" AND (CATEGORY = '""
            post += ""' OR CATEGORY = '"".join(categories)
            post += ""' )""
        if failed_only:
            post += ' AND STATUS = ""Failed""'

        cmd = 'SELECT COUNT(*) FROM history WHERE name LIKE ?'
        res = self.execute(cmd + post, (search,))
        total_items = -1
        if res:
            try:
                total_items = self.c.fetchone().get('COUNT(*)')
            except AttributeError:
                pass

        if not start:
            start = 0
        if not limit:
            limit = total_items

        t = (search, start, limit)
        cmd = 'SELECT * FROM history WHERE name LIKE ?'
        fetch_ok = self.execute(cmd + post + ' ORDER BY completed desc LIMIT ?, ?', t)

        if fetch_ok:
            items = self.c.fetchall()
        else:
            items = []

        fetched_items = len(items)

        # Unpack the single line stage log
        # Stage Name is separated by ::: stage lines by ; and stages by \r\n
        items = [unpack_history_info(item) for item in items]

        return (items, fetched_items, total_items)

    def have_episode(self, series, season, episode):
        """""" Check whether History contains this series episode """"""
        total = 0
        series = series.lower().replace('.', ' ').replace('_', ' ').replace('  ', ' ')
        if series and season and episode:
            pattern = '%s/%s/%s' % (series, season, episode)
            res = self.execute(""select count(*) from History WHERE series = ? AND STATUS != 'Failed'"", (pattern,))
            if res:
                try:
                    total = self.c.fetchone().get('count(*)')
                except AttributeError:
                    pass
        return total > 0

    def have_md5sum(self, md5sum):
        """""" Check whether this md5sum already in History """"""
        total = 0
        res = self.execute(""select count(*) from History WHERE md5sum = ? AND STATUS != 'Failed'"", (md5sum,))
        if res:
            try:
                total = self.c.fetchone().get('count(*)')
            except AttributeError:
                pass
        return total > 0

    def get_history_size(self):
        """""" Returns the total size of the history and
            amounts downloaded in the last month and week
        """"""
        # Total Size of the history
        total = 0
        if self.execute('''SELECT sum(bytes) FROM history'''):
            try:
                total = self.c.fetchone().get('sum(bytes)')
            except AttributeError:
                pass

        # Amount downloaded this month
        # r = time.gmtime(time.time())
        # month_timest = int(time.mktime((r.tm_year, r.tm_mon, 0, 0, 0, 1, r.tm_wday, r.tm_yday, r.tm_isdst)))
        month_timest = int(this_month(time.time()))

        month = 0
        if self.execute('''SELECT sum(bytes) FROM history WHERE ""completed"">?''', (month_timest,)):
            try:
                month = self.c.fetchone().get('sum(bytes)')
            except AttributeError:
                pass

        # Amount downloaded this week
        week_timest = int(this_week(time.time()))

        week = 0
        if self.execute('''SELECT sum(bytes) FROM history WHERE ""completed"">?''', (week_timest,)):
            try:
                week = self.c.fetchone().get('sum(bytes)')
            except AttributeError:
                pass

        return (total, month, week)

    def get_script_log(self, nzo_id):
        """""" Return decompressed log file """"""
        data = ''
        t = (nzo_id,)
        if self.execute('SELECT script_log FROM history WHERE nzo_id=?', t):
            try:
                data = zlib.decompress(self.c.fetchone().get('script_log'))
            except:
                pass
        return data

    def get_name(self, nzo_id):
        """""" Return name of the job `nzo_id` """"""
        t = (nzo_id,)
        name = ''
        if self.execute('SELECT name FROM history WHERE nzo_id=?', t):
            try:
                name = self.c.fetchone().get('name')
            except AttributeError:
                pass
        return name

    def get_path(self, nzo_id):
        """""" Return the `incomplete` path of the job `nzo_id` """"""
        t = (nzo_id,)
        path = ''
        if self.execute('SELECT path FROM history WHERE nzo_id=?', t):
            try:
                path = self.c.fetchone().get('path')
            except AttributeError:
                pass
        return path

    def get_other(self, nzo_id):
        """""" Return additional data for job `nzo_id` """"""
        t = (nzo_id,)
        if self.execute('SELECT * FROM history WHERE nzo_id=?', t):
            try:
                items = self.c.fetchall()[0]
                dtype = items.get('report')
                url = items.get('url')
                pp = items.get('pp')
                script = items.get('script')
                cat = items.get('category')
            except (AttributeError, IndexError):
                return '', '', '', '', ''
        return dtype, url, pp, script, cat


def dict_factory(cursor, row):
    """""" Return a dictionary for the current database position """"""
    d = {}
    for idx, col in enumerate(cursor.description):
        d[col[0]] = row[idx]
    return d


_PP_LOOKUP = {0: '', 1: 'R', 2: 'U', 3: 'D'}
def build_history_info(nzo, storage='', downpath='', postproc_time=0, script_output='', script_line=''):
    """""" Collects all the information needed for the database """"""

    if not downpath:
        downpath = nzo.downpath
    path = decode_factory(downpath)
    storage = decode_factory(storage)
    script_line = decode_factory(script_line)

    flagRepair, flagUnpack, flagDelete = nzo.repair_opts
    nzo_info = decode_factory(nzo.nzo_info)

    url = decode_factory(nzo.url)

    completed = int(time.time())
    name = decode_factory(nzo.final_name)

    nzb_name = decode_factory(nzo.filename)
    category = decode_factory(nzo.cat)
    pp = _PP_LOOKUP.get(sabnzbd.opts_to_pp(flagRepair, flagUnpack, flagDelete), 'X')
    script = decode_factory(nzo.script)
    status = decode_factory(nzo.status)
    nzo_id = nzo.nzo_id
    bytes = nzo.bytes_downloaded

    if script_output:
        # Compress the output of the script
        script_log = sqlite3.Binary(zlib.compress(script_output))
        #
    else:
        script_log = ''

    download_time = decode_factory(nzo_info.get('download_time', 0))

    downloaded = nzo.bytes_downloaded
    completeness = 0
    fail_message = decode_factory(nzo.fail_msg)
    url_info = nzo_info.get('details', '') or nzo_info.get('more_info', '')

    # Get the dictionary containing the stages and their unpack process
    stages = decode_factory(nzo.unpack_info)
    # Pack the dictionary up into a single string
    # Stage Name is separated by ::: stage lines by ; and stages by \r\n
    lines = []
    for key, results in stages.iteritems():
        lines.append('%s:::%s' % (key, ';'.join(results)))
    stage_log = '\r\n'.join(lines)

    # Reuse the old 'report' column to indicate a URL-fetch
    report = 'future' if nzo.futuretype else ''

    # Analyze series info only when job is finished
    series = u''
    if postproc_time:
        seriesname, season, episode, dummy = sabnzbd.newsunpack.analyse_show(nzo.final_name)
        if seriesname and season and episode:
            series = u'%s/%s/%s' % (seriesname.lower(), season, episode)

    # See whatever the first password was, for the Retry
    password = ''
    passwords = get_all_passwords(nzo)
    if passwords:
        password = passwords[0]

    return (completed, name, nzb_name, category, pp, script, report, url, status, nzo_id, storage, path,
            script_log, script_line, download_time, postproc_time, stage_log, downloaded, completeness,
            fail_message, url_info, bytes, series, nzo.md5sum, password)



def unpack_history_info(item):
    """""" Expands the single line stage_log from the DB
        into a python dictionary for use in the history display
    """"""
    # Stage Name is separated by ::: stage lines by ; and stages by \r\n
    lst = item['stage_log']
    if lst:
        try:
            lines = lst.split('\r\n')
        except:
            logging.error(T('Invalid stage logging in history for %s') + ' (\\r\\n)', unicoder(item['name']))
            logging.debug('Lines: %s', lst)
            lines = []
        lst = [None for x in STAGES]
        for line in lines:
            stage = {}
            try:
                key, logs = line.split(':::')
            except:
                logging.debug('Missing key:::logs ""%s""', line)
                key = line
                logs = ''
            stage['name'] = key
            stage['actions'] = []
            try:
                logs = logs.split(';')
            except:
                logging.error(T('Invalid stage logging in history for %s') + ' (;)', unicoder(item['name']))
                logging.debug('Logs: %s', logs)
                logs = []
            for log in logs:
                stage['actions'].append(log)
            try:
                lst[STAGES[key]] = stage
            except KeyError:
                lst.append(stage)
        # Remove unused stages
        item['stage_log'] = [x for x in lst if x is not None]

    if item['script_log']:
        item['script_log'] = ''
    # The action line is only available for items in the postproc queue
    if 'action_line' not in item:
        item['action_line'] = ''
    return item


def midnight_history_purge():
    logging.info('Scheduled history purge')
    history_db = HistoryDB()
    history_db.auto_history_purge()
    history_db.close()


def decode_factory(text):
    """""" Recursively looks through the supplied argument
        and converts and text to Unicode
    """"""
    if isinstance(text, str):
        return unicoder(text)

    elif isinstance(text, list):
        new_text = []
        for t in text:
            new_text.append(decode_factory(t))
        return new_text

    elif isinstance(text, dict):
        new_text = {}
        for key in text:
            new_text[key] = decode_factory(text[key])
        return new_text
    else:
        return text
/n/n/n",1
