,Unnamed: 0,id,code,label
194,194,9acb885e60f77cd4e9ea8c98bdc39c18abcac731,"erpnext/templates/utils.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors
# License: GNU General Public License v3. See license.txt

from __future__ import unicode_literals

import frappe, json
from frappe import _
from frappe.utils import cint, formatdate

@frappe.whitelist(allow_guest=True)
def send_message(subject=""Website Query"", message="""", sender="""", status=""Open""):
	from frappe.www.contact import send_message as website_send_message
	lead = customer = None

	website_send_message(subject, message, sender)

	customer = frappe.db.sql(""""""select distinct dl.link_name from `tabDynamic Link` dl
		left join `tabContact` c on dl.parent=c.name where dl.link_doctype='Customer'
		and c.email_id = %s"""""", sender)

	if not customer:
		lead = frappe.db.get_value('Lead', dict(email_id=sender))
		if not lead:
			new_lead = frappe.get_doc(dict(
				doctype='Lead',
				email_id = sender,
				lead_name = sender.split('@')[0].title()
			)).insert(ignore_permissions=True)

	opportunity = frappe.get_doc(dict(
		doctype ='Opportunity',
		enquiry_from = 'Customer' if customer else 'Lead',
		status = 'Open',
		title = subject,
		contact_email = sender,
		to_discuss = message
	))

	if customer:
		opportunity.customer = customer[0][0]
	elif lead:
		opportunity.lead = lead
	else:
		opportunity.lead = new_lead.name

	opportunity.insert(ignore_permissions=True)

	comm = frappe.get_doc({
		""doctype"":""Communication"",
		""subject"": subject,
		""content"": message,
		""sender"": sender,
		""sent_or_received"": ""Received"",
		'reference_doctype': 'Opportunity',
		'reference_name': opportunity.name
	})
	comm.insert(ignore_permissions=True)

	return ""okay""
/n/n/n",0
195,195,9acb885e60f77cd4e9ea8c98bdc39c18abcac731,"/erpnext/templates/utils.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors
# License: GNU General Public License v3. See license.txt

from __future__ import unicode_literals

import frappe, json
from frappe import _
from frappe.utils import cint, formatdate

@frappe.whitelist(allow_guest=True)
def send_message(subject=""Website Query"", message="""", sender="""", status=""Open""):
	from frappe.www.contact import send_message as website_send_message
	lead = customer = None

	website_send_message(subject, message, sender)

	customer = frappe.db.sql(""""""select distinct dl.link_name from `tabDynamic Link` dl
		left join `tabContact` c on dl.parent=c.name where dl.link_doctype='Customer'
		and c.email_id='{email_id}'"""""".format(email_id=sender))

	if not customer:
		lead = frappe.db.get_value('Lead', dict(email_id=sender))
		if not lead:
			new_lead = frappe.get_doc(dict(
				doctype='Lead',
				email_id = sender,
				lead_name = sender.split('@')[0].title()
			)).insert(ignore_permissions=True)

	opportunity = frappe.get_doc(dict(
		doctype ='Opportunity',
		enquiry_from = 'Customer' if customer else 'Lead',
		status = 'Open',
		title = subject,
		contact_email = sender,
		to_discuss = message
	))

	if customer:
		opportunity.customer = customer[0][0]
	elif lead:
		opportunity.lead = lead
	else:
		opportunity.lead = new_lead.name

	opportunity.insert(ignore_permissions=True)

	comm = frappe.get_doc({
		""doctype"":""Communication"",
		""subject"": subject,
		""content"": message,
		""sender"": sender,
		""sent_or_received"": ""Received"",
		'reference_doctype': 'Opportunity',
		'reference_name': opportunity.name
	})
	comm.insert(ignore_permissions=True)

	return ""okay""
/n/n/n",1
70,70,6096f43fd4b2d91211eec4614b7960c0816900da,"cgi/common.py/n/n# NOTE: I did *NOT* add a shebang here, intentionally, because
#       this is *NEVER* supposed to be a user-facing script!



class FormError(BaseException):
    def __init__(this, msg):
        this.msg = msg



def get_game_info(conn, game):
    # get the basic game properties
    cursor = conn.cursor()
    cursor.execute(""SELECT player1,player2,size,state FROM games WHERE id = %d;"", (game,))
    if cursor.rowcount != 1:
        raise FormError(""Invalid game ID"")

    row = cursor.fetchall()[0]
    players = [row[0],row[1]]
    size    =  row[2]
    state   =  row[3]

    if state is None:
         state = ""Active""

    cursor.close()

    return (players,size,state)



def build_board(conn, game,size):
    # we'll build the empty board, and then fill in with the move list that
    # we get from the DB.
    board = []
    for i in range(size):
        board.append([""""]*size)


    # search for all moves that have happenend during this game.
    cursor = conn.cursor()
    cursor.execute(""SELECT x,y,letter FROM moves WHERE gameID = %d;"", (game,))

    counts = {""X"":0, ""O"":0}
    for move in cursor.fetchall():
        (x,y,letter) = move

        x = int(x)
        y = int(y)
        assert x >= 0 and x < size
        assert y >= 0 and y < size

        assert letter in ""XO""

        assert board[x][y] == """"
        board[x][y] = letter

        counts[letter] += 1

    cursor.close()

    assert counts[""X""] >= counts[""O""]
    assert counts[""X""] <= counts[""O""]+1

    if counts[""X""] == counts[""O""]:
        nextPlayer = 0
    else:
        nextPlayer = 1
    letter = ""XO""[nextPlayer]

    return (board,nextPlayer,letter)

/n/n/ncgi/create_game.py/n/n#! /usr/bin/env python3

# taken from:
#    https://docs.python.org/3.4/howto/webservers.html

import cgi

# enable debugging.  Note that the Python docs recommend this for testing, but
# say that it's a very bad idea to leave enabled in production, as it can leak
# information about your internal implementation.
import cgitb
cgitb.enable(display=0, logdir=""/var/log/httpd/cgi_err/"")


import MySQLdb
import private_no_share_dangerous_passwords as pnsdp

from common import FormError



# this function handles the processing of the actual text of the HTML file.
# It writes everything from the HTML header, to the content in the body, to
# the closing tags at the bottom.
#
# Later, I ought to make this smarter, to handle cookies and such.  Or, just
# switch over to some framework which makes it all easier for me!

def process_form():
    # see https://docs.python.org/3.4/library/cgi.html for the basic usage
    # here.
    form = cgi.FieldStorage()


    if ""player1"" not in form or ""player2"" not in form or ""size"" not in form:
        raise FormError(""Invalid parameters."")

    player1 = form[""player1""].value
    player2 = form[""player2""].value
    for c in player1+player2:
        if c not in ""_-"" and not c.isdigit() and not c.isalpha():
            raise FormError(""Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens"")
            return

    try:
        size = int(form[""size""].value)
    except:
        raise FormError(""Invalid parameters: 'size' is not an integer."")
        return

    if size < 2 or size > 9:
        raise FormError(""The 'size' must be in the range 2-9, inclusive."")


    # connect to the database
    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,
                           user   = pnsdp.SQL_USER,
                           passwd = pnsdp.SQL_PASSWD,
                           db     = pnsdp.SQL_DB)
    cursor = conn.cursor()

    # insert the new row
    cursor.execute(""""""INSERT INTO games(player1,player2,size) VALUES(""%s"",""%s"",%d);"""""", (player1,player2,size))

    gameID = cursor.lastrowid


    # MySQLdb has been building a transaction as we run.  Commit them now, and
    # also clean up the other resources we've allocated.
    conn.commit()
    cursor.close()
    conn.close()

    return gameID



# this is what actually runs, each time that we are called...

try:
    #print(""Content-type: text/html"")
    #print()

    # this will not print out *ANYTHING* !!!
    gameID = process_form()

    # https://en.wikipedia.org/wiki/Post/Redirect/Get
    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python
    print(""Status: 303 See other"")
    print(""""""Location: http://%s/cgi-bin/list.py?new_game=%s"""""" % (pnsdp.WEB_HOST,gameID))
    print()

except FormError as e:
    print(""""""Content-Type: text/html;charset=utf-8

<html>

<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>

<body>

<p>ERROR: %s

<p><a href=""list.py"">Return to game list</a>

</body>
</html>

"""""" % e.msg, end="""")

except:
    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error


/n/n/ncgi/move.py/n/n#! /usr/bin/env python3

# taken from:
#    https://docs.python.org/3.4/howto/webservers.html

import cgi

# enable debugging.  Note that the Python docs recommend this for testing, but
# say that it's a very bad idea to leave enabled in production, as it can leak
# information about your internal implementation.
import cgitb
cgitb.enable(display=0, logdir=""/var/log/httpd/cgi_err/"")

import MySQLdb
import private_no_share_dangerous_passwords as pnsdp

from common import get_game_info,build_board,FormError



# this function handles the processing of the actual text of the HTML file.
# It writes everything from the HTML header, to the content in the body, to
# the closing tags at the bottom.
#
# Later, I ought to make this smarter, to handle cookies and such.  Or, just
# switch over to some framework which makes it all easier for me!

def process_form():
    # see https://docs.python.org/3.4/library/cgi.html for the basic usage
    # here.
    form = cgi.FieldStorage()


    # connect to the database
    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,
                           user   = pnsdp.SQL_USER,
                           passwd = pnsdp.SQL_PASSWD,
                           db     = pnsdp.SQL_DB)


    if ""user"" not in form or ""game"" not in form:
        raise FormError(""Invalid parameters."")
    if ""pos"" not in form and ""resign"" not in form:
        raise FormError(""Invalid parameters."")

    game = int(form[""game""].value)


    (players,size,state) = get_game_info(conn, game)

    user = form[""user""].value
    if user not in players:
        raise FormError(""Invalid player ID - player is not part of this game"")


    if ""resign"" in form:
        resign = True
    else:
        resign = False
        pos = form[""pos""].value.split("","")
        assert len(pos) == 2
        x = int(pos[0])
        y = int(pos[1])


    (board,nextPlayer,letter) = build_board(conn, game,size)

    if user != players[nextPlayer]:
        raise FormError(""Internal error, incorrect player is attempting to move."")


    if resign:
        # this user is choosing to resign.  Update the game state to reflect that.
        other_player_name = players[1-nextPlayer]

        cursor = conn.cursor()
        cursor.execute(""""""UPDATE games SET state=""%s:resignation"" WHERE id=%d;"""""", (other_player_name,game))
        cursor.close()

    else:
        assert x >= 0 and x < size
        assert y >= 0 and y < size

        assert board[x][y] == """"
        board[x][y] = ""XO""[nextPlayer]

        # we've done all of our sanity checks.  We now know enough to say that
        # it's safe to add a new move.
        cursor = conn.cursor()
        cursor.execute(""""""INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,""%s"",NOW());"""""", (game,x,y,letter))

        if cursor.rowcount != 1:
            raise FormError(""Could not make move, reason unknown."")

        cursor.close()

        result = analyze_board(board)
        if result != """":
            if result == ""win"":
                result = players[nextPlayer]+"":win""

            cursor = conn.cursor()
            cursor.execute(""""""UPDATE games SET state=""%s"" WHERE id=%d;"""""", (result,game))
            cursor.close()

    # we've made changes, make sure to commit them!
    conn.commit()
    conn.close()


    # return the parms to the caller, so that they can build a good redirect
    return (user,game)



def analyze_board(board):
    size = len(board)

    for x in range(size):
        # scan through the column 'x' to see if they are all the same.
        if board[x][0] == """":
            continue
        all_same = True
        for y in range(1,size):
            if board[x][y] != board[x][0]:
                all_same = False
                break
        if all_same:
            return ""win""

    for y in range(size):
        # scan through the row 'y' to see if they are all the same.
        if board[0][y] == """":
            continue
        all_same = True
        for x in range(1,size):
            if board[x][y] != board[0][y]:
                all_same = False
                break
        if all_same:
            return ""win""

    # check the NW/SE diagonal
    if board[0][0] != """":
        all_same = True
        for i in range(1,size):
            if board[i][i] != board[0][0]:
                all_same = False
                break
        if all_same:
            return ""win""

    # check the NE/SW diagonal
    if board[size-1][0] != """":
        all_same = True
        for i in range(1,size):
            if board[size-1-i][i] != board[size-1][0]:
                all_same = False
                break
        if all_same:
            return ""win""

    # check for stalemate
    for x in range(size):
        for y in range(size):
            if board[x][y] == """":
                return """"
    return ""stalemate""



# this is what actually runs, each time that we are called...

try:
#    print(""Content-type: text/html"")
#    print()

    # this will not print out *ANYTHING* !!!
    (user,game) = process_form()

    # https://en.wikipedia.org/wiki/Post/Redirect/Get
    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python
    print(""Status: 303 See other"")
    print(""""""Location: http://%s/cgi-bin/game.py?user=%s&game=%s"""""" % (pnsdp.WEB_HOST, user,game))
    print()

except FormError as e:
    print(""""""Content-Type: text/html;charset=utf-8

<html>

<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>

<body>

<p>ERROR: %s

<p><a href=""list.py"">Return to game list</a>

</body>
</html>

"""""" % e.msg, end="""")

except:
    print(""""""Content-Type: text/html;charset=utf-8\n\n"""""")

    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error


/n/n/n",0
71,71,6096f43fd4b2d91211eec4614b7960c0816900da,"/cgi/common.py/n/n# NOTE: I did *NOT* add a shebang here, intentionally, because
#       this is *NEVER* supposed to be a user-facing script!



class FormError(BaseException):
    def __init__(this, msg):
        this.msg = msg



def get_game_info(conn, game):
    # get the basic game properties
    cursor = conn.cursor()
    cursor.execute(""SELECT player1,player2,size,state FROM games WHERE id = %d;"" % game)
    if cursor.rowcount != 1:
        raise FormError(""Invalid game ID"")

    row = cursor.fetchall()[0]
    players = [row[0],row[1]]
    size    =  row[2]
    state   =  row[3]

    if state is None:
         state = ""Active""

    cursor.close()

    return (players,size,state)



def build_board(conn, game,size):
    # we'll build the empty board, and then fill in with the move list that
    # we get from the DB.
    board = []
    for i in range(size):
        board.append([""""]*size)


    # search for all moves that have happenend during this game.
    cursor = conn.cursor()
    cursor.execute(""SELECT x,y,letter FROM moves WHERE gameID = %d;"" % game)

    counts = {""X"":0, ""O"":0}
    for move in cursor.fetchall():
        (x,y,letter) = move

        x = int(x)
        y = int(y)
        assert x >= 0 and x < size
        assert y >= 0 and y < size

        assert letter in ""XO""

        assert board[x][y] == """"
        board[x][y] = letter

        counts[letter] += 1

    cursor.close()

    assert counts[""X""] >= counts[""O""]
    assert counts[""X""] <= counts[""O""]+1

    if counts[""X""] == counts[""O""]:
        nextPlayer = 0
    else:
        nextPlayer = 1
    letter = ""XO""[nextPlayer]

    return (board,nextPlayer,letter)

/n/n/n/cgi/create_game.py/n/n#! /usr/bin/env python3

# taken from:
#    https://docs.python.org/3.4/howto/webservers.html

import cgi

# enable debugging.  Note that the Python docs recommend this for testing, but
# say that it's a very bad idea to leave enabled in production, as it can leak
# information about your internal implementation.
import cgitb
cgitb.enable(display=0, logdir=""/var/log/httpd/cgi_err/"")


import MySQLdb
import private_no_share_dangerous_passwords as pnsdp

from common import FormError



# this function handles the processing of the actual text of the HTML file.
# It writes everything from the HTML header, to the content in the body, to
# the closing tags at the bottom.
#
# Later, I ought to make this smarter, to handle cookies and such.  Or, just
# switch over to some framework which makes it all easier for me!

def process_form():
    # see https://docs.python.org/3.4/library/cgi.html for the basic usage
    # here.
    form = cgi.FieldStorage()


    if ""player1"" not in form or ""player2"" not in form or ""size"" not in form:
        raise FormError(""Invalid parameters."")

    player1 = form[""player1""].value
    player2 = form[""player2""].value
    for c in player1+player2:
        if c not in ""_-"" and not c.isdigit() and not c.isalpha():
            raise FormError(""Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens"")
            return

    try:
        size = int(form[""size""].value)
    except:
        raise FormError(""Invalid parameters: 'size' is not an integer."")
        return

    if size < 2 or size > 9:
        raise FormError(""The 'size' must be in the range 2-9, inclusive."")


    # connect to the database
    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,
                           user   = pnsdp.SQL_USER,
                           passwd = pnsdp.SQL_PASSWD,
                           db     = pnsdp.SQL_DB)
    cursor = conn.cursor()

    # insert the new row
    cursor.execute(""""""INSERT INTO games(player1,player2,size) VALUES(""%s"",""%s"",%d);"""""" % (player1,player2,size))

    gameID = cursor.lastrowid


    # MySQLdb has been building a transaction as we run.  Commit them now, and
    # also clean up the other resources we've allocated.
    conn.commit()
    cursor.close()
    conn.close()

    return gameID



# this is what actually runs, each time that we are called...

try:
    #print(""Content-type: text/html"")
    #print()

    # this will not print out *ANYTHING* !!!
    gameID = process_form()

    # https://en.wikipedia.org/wiki/Post/Redirect/Get
    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python
    print(""Status: 303 See other"")
    print(""""""Location: http://%s/cgi-bin/list.py?new_game=%s"""""" % (pnsdp.WEB_HOST,gameID))
    print()

except FormError as e:
    print(""""""Content-Type: text/html;charset=utf-8

<html>

<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>

<body>

<p>ERROR: %s

<p><a href=""list.py"">Return to game list</a>

</body>
</html>

"""""" % e.msg, end="""")

except:
    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error


/n/n/n/cgi/move.py/n/n#! /usr/bin/env python3

# taken from:
#    https://docs.python.org/3.4/howto/webservers.html

import cgi

# enable debugging.  Note that the Python docs recommend this for testing, but
# say that it's a very bad idea to leave enabled in production, as it can leak
# information about your internal implementation.
import cgitb
cgitb.enable(display=0, logdir=""/var/log/httpd/cgi_err/"")

import MySQLdb
import private_no_share_dangerous_passwords as pnsdp

from common import get_game_info,build_board,FormError



# this function handles the processing of the actual text of the HTML file.
# It writes everything from the HTML header, to the content in the body, to
# the closing tags at the bottom.
#
# Later, I ought to make this smarter, to handle cookies and such.  Or, just
# switch over to some framework which makes it all easier for me!

def process_form():
    # see https://docs.python.org/3.4/library/cgi.html for the basic usage
    # here.
    form = cgi.FieldStorage()


    # connect to the database
    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,
                           user   = pnsdp.SQL_USER,
                           passwd = pnsdp.SQL_PASSWD,
                           db     = pnsdp.SQL_DB)


    if ""user"" not in form or ""game"" not in form:
        raise FormError(""Invalid parameters."")
    if ""pos"" not in form and ""resign"" not in form:
        raise FormError(""Invalid parameters."")

    game = int(form[""game""].value)


    (players,size,state) = get_game_info(conn, game)

    user = form[""user""].value
    if user not in players:
        raise FormError(""Invalid player ID - player is not part of this game"")


    if ""resign"" in form:
        resign = True
    else:
        resign = False
        pos = form[""pos""].value.split("","")
        assert len(pos) == 2
        x = int(pos[0])
        y = int(pos[1])


    (board,nextPlayer,letter) = build_board(conn, game,size)

    if user != players[nextPlayer]:
        raise FormError(""Internal error, incorrect player is attempting to move."")


    if resign:
        # this user is choosing to resign.  Update the game state to reflect that.
        other_player_name = players[1-nextPlayer]

        cursor = conn.cursor()
        cursor.execute(""""""UPDATE games SET state=""%s:resignation"" WHERE id=%d;"""""" % (other_player_name,game))
        cursor.close()

    else:
        assert x >= 0 and x < size
        assert y >= 0 and y < size

        assert board[x][y] == """"
        board[x][y] = ""XO""[nextPlayer]

        # we've done all of our sanity checks.  We now know enough to say that
        # it's safe to add a new move.
        cursor = conn.cursor()
        cursor.execute(""""""INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,""%s"",NOW());"""""" % (game,x,y,letter))

        if cursor.rowcount != 1:
            raise FormError(""Could not make move, reason unknown."")

        cursor.close()

        result = analyze_board(board)
        if result != """":
            if result == ""win"":
                result = players[nextPlayer]+"":win""

            cursor = conn.cursor()
            cursor.execute(""""""UPDATE games SET state=""%s"" WHERE id=%d;"""""" % (result,game))
            cursor.close()

    # we've made changes, make sure to commit them!
    conn.commit()
    conn.close()


    # return the parms to the caller, so that they can build a good redirect
    return (user,game)



def analyze_board(board):
    size = len(board)

    for x in range(size):
        # scan through the column 'x' to see if they are all the same.
        if board[x][0] == """":
            continue
        all_same = True
        for y in range(1,size):
            if board[x][y] != board[x][0]:
                all_same = False
                break
        if all_same:
            return ""win""

    for y in range(size):
        # scan through the row 'y' to see if they are all the same.
        if board[0][y] == """":
            continue
        all_same = True
        for x in range(1,size):
            if board[x][y] != board[0][y]:
                all_same = False
                break
        if all_same:
            return ""win""

    # check the NW/SE diagonal
    if board[0][0] != """":
        all_same = True
        for i in range(1,size):
            if board[i][i] != board[0][0]:
                all_same = False
                break
        if all_same:
            return ""win""

    # check the NE/SW diagonal
    if board[size-1][0] != """":
        all_same = True
        for i in range(1,size):
            if board[size-1-i][i] != board[size-1][0]:
                all_same = False
                break
        if all_same:
            return ""win""

    # check for stalemate
    for x in range(size):
        for y in range(size):
            if board[x][y] == """":
                return """"
    return ""stalemate""



# this is what actually runs, each time that we are called...

try:
#    print(""Content-type: text/html"")
#    print()

    # this will not print out *ANYTHING* !!!
    (user,game) = process_form()

    # https://en.wikipedia.org/wiki/Post/Redirect/Get
    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python
    print(""Status: 303 See other"")
    print(""""""Location: http://%s/cgi-bin/game.py?user=%s&game=%s"""""" % (pnsdp.WEB_HOST, user,game))
    print()

except FormError as e:
    print(""""""Content-Type: text/html;charset=utf-8

<html>

<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>

<body>

<p>ERROR: %s

<p><a href=""list.py"">Return to game list</a>

</body>
</html>

"""""" % e.msg, end="""")

except:
    print(""""""Content-Type: text/html;charset=utf-8\n\n"""""")

    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error


/n/n/n",1
200,200,3e4550f6dd019a97f62fb10937af5b7788c68c58,"crm_phonecall/models/crm_lead.py/n/n# -*- coding: utf-8 -*-
# Copyright (C) 2004-today OpenERP SA (<http://www.openerp.com>)
# Copyright (C) 2017 Tecnativa - Vicent Cubells
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).

from openerp import api, fields, models


class CrmLead(models.Model):
    _inherit = ""crm.lead""

    phonecall_ids = fields.One2many(
        comodel_name='crm.phonecall',
        inverse_name='opportunity_id',
        string='Phonecalls',
    )
    phonecall_count = fields.Integer(
        compute='_compute_phonecall_count',
        string=""Phonecalls"",
    )

    @api.multi
    def _compute_phonecall_count(self):
        for lead in self:
            lead.phonecall_count = self.env[
                'crm.phonecall'].search_count(
                [('opportunity_id', '=', lead.id)])
/n/n/ncrm_phonecall/report/crm_phonecall_report.py/n/n# -*- coding: utf-8 -*-
# Copyright 2004-2010 Tiny SPRL (<http://tiny.be>)
# Copyright 2017 Tecnativa - Vicent Cubells
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).
from psycopg2.extensions import AsIs

from odoo import tools
from odoo import api, fields, models

AVAILABLE_STATES = [
    ('draft', 'Draft'),
    ('open', 'Todo'),
    ('cancel', 'Cancelled'),
    ('done', 'Held'),
    ('pending', 'Pending')
]


class CrmPhonecallReport(models.Model):
    _name = ""crm.phonecall.report""
    _description = ""Phone calls by user""
    _auto = False

    user_id = fields.Many2one(
        comodel_name='res.users',
        string='User',
        readonly=True,
    )
    team_id = fields.Many2one(
        comodel_name='crm.team',
        string='Team',
        readonly=True,
    )
    priority = fields.Selection(
        selection=[
            ('0', 'Low'),
            ('1', 'Normal'),
            ('2', 'High')
        ],
        string='Priority',
    )
    nbr_cases = fields.Integer(
        string='# of Cases',
        readonly=True,
    )
    state = fields.Selection(
        AVAILABLE_STATES,
        string='Status',
        readonly=True,
    )
    create_date = fields.Datetime(
        string='Create Date',
        readonly=True,
        index=True,
    )
    delay_close = fields.Float(
        string='Delay to close',
        digits=(16, 2),
        readonly=True,
        group_operator=""avg"",
        help=""Number of Days to close the case"",
    )
    duration = fields.Float(
        string='Duration',
        digits=(16, 2),
        readonly=True,
        group_operator=""avg"",
    )
    delay_open = fields.Float(
        string='Delay to open',
        digits=(16, 2),
        readonly=True,
        group_operator=""avg"",
        help=""Number of Days to open the case"",
    )
    partner_id = fields.Many2one(
        comodel_name='res.partner',
        string='Partner',
        readonly=True,
    )
    company_id = fields.Many2one(
        comodel_name='res.company',
        string='Company',
        readonly=True,
    )
    opening_date = fields.Datetime(
        readonly=True,
        index=True,
    )
    date_closed = fields.Datetime(
        string='Close Date',
        readonly=True,
        index=True)

    def _select(self):
        select_str = """"""
            select
                id,
                c.date_open as opening_date,
                c.date_closed as date_closed,
                c.state,
                c.user_id,
                c.team_id,
                c.partner_id,
                c.duration,
                c.company_id,
                c.priority,
                1 as nbr_cases,
                c.create_date as create_date,
                extract(
                  'epoch' from (
                  c.date_closed-c.create_date))/(3600*24) as delay_close,
                extract(
                  'epoch' from (
                  c.date_open-c.create_date))/(3600*24) as delay_open
           """"""
        return select_str

    def _from(self):
        from_str = """"""
            from crm_phonecall c
        """"""
        return from_str

    @api.model_cr
    def init(self):

        tools.drop_view_if_exists(self._cr, self._table)
        self._cr.execute(
            """"""
            create or replace view %s as (
                %s
                %s
            )"""""", (
                AsIs(self._table), AsIs(self._select()), AsIs(self._from()))
            )
/n/n/n",0
201,201,3e4550f6dd019a97f62fb10937af5b7788c68c58,"/crm_phonecall/models/crm_lead.py/n/n# -*- coding: utf-8 -*-
# Copyright (C) 2004-today OpenERP SA (<http://www.openerp.com>)
# Copyright (C) 2017 Tecnativa - Vicent Cubells
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).

from openerp import api, fields, models


class CrmLead(models.Model):
    _inherit = ""crm.lead""

    phonecall_ids = fields.One2many(
        comodel_name='crm.phonecall',
        inverse_name='opportunity_id',
        string='Phonecalls',
    )
    phonecall_count = fields.Integer(
        compute='_phonecall_count',
        string=""Phonecalls"",
    )

    @api.multi
    def _phonecall_count(self):
        for lead in self:
            lead.phonecall_count = self.env[
                'crm.phonecall'].search_count(
                [('opportunity_id', '=', lead.id)])
/n/n/n/crm_phonecall/report/crm_phonecall_report.py/n/n# -*- coding: utf-8 -*-
# Copyright 2004-2010 Tiny SPRL (<http://tiny.be>)
# Copyright 2017 Tecnativa - Vicent Cubells
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).

from odoo import tools
from odoo import api, fields, models

AVAILABLE_STATES = [
    ('draft', 'Draft'),
    ('open', 'Todo'),
    ('cancel', 'Cancelled'),
    ('done', 'Held'),
    ('pending', 'Pending')
]


class CrmPhonecallReport(models.Model):
    _name = ""crm.phonecall.report""
    _description = ""Phone calls by user""
    _auto = False

    user_id = fields.Many2one(
        comodel_name='res.users',
        string='User',
        readonly=True,
    )
    team_id = fields.Many2one(
        comodel_name='crm.team',
        string='Team',
        readonly=True,
    )
    priority = fields.Selection(
        selection=[
            ('0', 'Low'),
            ('1', 'Normal'),
            ('2', 'High')
        ],
        string='Priority',
    )
    nbr_cases = fields.Integer(
        string='# of Cases',
        readonly=True,
    )
    state = fields.Selection(
        AVAILABLE_STATES,
        string='Status',
        readonly=True,
    )
    create_date = fields.Datetime(
        string='Create Date',
        readonly=True,
        index=True,
    )
    delay_close = fields.Float(
        string='Delay to close',
        digits=(16, 2),
        readonly=True,
        group_operator=""avg"",
        help=""Number of Days to close the case"",
    )
    duration = fields.Float(
        string='Duration',
        digits=(16, 2),
        readonly=True,
        group_operator=""avg"",
    )
    delay_open = fields.Float(
        string='Delay to open',
        digits=(16, 2),
        readonly=True,
        group_operator=""avg"",
        help=""Number of Days to open the case"",
    )
    partner_id = fields.Many2one(
        comodel_name='res.partner',
        string='Partner',
        readonly=True,
    )
    company_id = fields.Many2one(
        comodel_name='res.company',
        string='Company',
        readonly=True,
    )
    opening_date = fields.Datetime(
        readonly=True,
        index=True,
    )
    date_closed = fields.Datetime(
        string='Close Date',
        readonly=True,
        index=True)

    def _select(self):
        select_str = """"""
            select
                id,
                c.date_open as opening_date,
                c.date_closed as date_closed,
                c.state,
                c.user_id,
                c.team_id,
                c.partner_id,
                c.duration,
                c.company_id,
                c.priority,
                1 as nbr_cases,
                c.create_date as create_date,
                extract(
                  'epoch' from (
                  c.date_closed-c.create_date))/(3600*24) as delay_close,
                extract(
                  'epoch' from (
                  c.date_open-c.create_date))/(3600*24) as delay_open
           """"""
        return select_str

    def _from(self):
        from_str = """"""
            from crm_phonecall c
        """"""
        return from_str

    @api.model_cr
    def init(self):

        tools.drop_view_if_exists(self._cr, self._table)
        self._cr.execute(""""""
            create or replace view %s as (
                %s
                %s
            )"""""" % (self._table, self._select(), self._from()))
/n/n/n",1
138,138,48b00c7b7bb0b82bdc79167947fa9eda9f0ab8e0,"app/Data/Transform/controllers.py/n/nfrom flask import (
    Blueprint,
    request,
    jsonify,
    redirect,
    url_for,
    render_template,
    flash,
    Response
)
from flask_login import login_required, current_user
from app.Data.operations import create_action, get_dataset_with_id
from app.Data.helpers import table_name_to_object, escape_quotes
from app.Data.Transform.operations import (
    restore_original,
    change_attribute_type,
    delete_rows,
    fill_null_with,
    fill_null_with_average,
    fill_null_with_median,
    rename_attribute,
    delete_attribute,
    one_hot_encode,
    normalize_attribute,
    discretize_width,
    discretize_eq_freq,
    find_replace,
    regex_find_replace,
    substring_find_replace
)

_transform = Blueprint('transform_bp', __name__, url_prefix='/data/transform')


@_transform.route('/rename_column', methods=['POST'])
@login_required
def rename_column():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    col = request.form['column']
    new_name = request.form['new_name']
    try:
        rename_attribute(dataset.working_copy, col, new_name)
        create_action(
            'Renamed column {0} to {1}'.format(col, new_name),
            dataset.id,
            current_user.id
        )
    except:
        flash('An unexpected error occured while renaming the column', 'danger')
    else:
        flash('Column renamed successfully.', 'success')

    return redirect(request.referrer)


@_transform.route('/delete_column', methods=['POST'])
@login_required
def delete_column():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    col = request.form['column']
    try:
        delete_attribute(dataset.working_copy, col)
        create_action(
            'Deleted column {0}'.format(col),
            dataset.id,
            current_user.id
        )
    except:
        flash('An unexpected error occured while deleting the column', 'danger')
    else:
        flash('Column deleted successfully.', 'success')

    return redirect(request.referrer)


@_transform.route('one_hot_encode_column', methods=['POST'])
@login_required
def one_hot_encode_column():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    col = request.form['column']
    try:
        one_hot_encode(dataset.working_copy, col)
        create_action(
            'One-hot-encoded {0}'.format(col),
            dataset.id,
            current_user.id
        )
    except:
        flash('An unexpected error occured while one-hot-encoding the column',
              'danger'
              )
    else:
        flash('Column one-hot-encoded successfully.', 'success')

    return redirect(request.referrer)


@_transform.route('normalize_column', methods=['POST'])
@login_required
def normalize_column():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    col = request.form['column']
    try:
        normalize_attribute(dataset.working_copy, col)
        create_action(
            'Normalized {0}'.format(col),
            dataset.id,
            current_user.id
        )
    except:
        flash('An unexpected error occured while normalizing the column',
              'danger'
              )
    else:
        flash('Column normalized successfully.', 'success')

    return redirect(request.referrer)


@_transform.route('/discretize_column', methods=['POST'])
@login_required
def discretize_column():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    column = request.form['column']
    intervals = request.form['intervals']

    try:
        if intervals == 'equal-distance':
            amount = request.form['amount-dist']
            discretize_width(dataset.working_copy, column, int(amount))
        elif intervals == 'equal-frequency':
            amount = request.form['amount-freq']
            discretize_eq_freq(dataset.working_copy, column, int(amount))
        else:
            edges = str(request.form['custom-edges'])
            edges = edges.replace(' ', '')
            edge_list = edges.split(',')
            if len(edge_list) < 2:
                raise ValueError
            for i in range(len(edge_list)):
                edge_list[i] = float(edge_list[i])
            discretize_width(dataset.working_copy, column, edge_list)

    except ValueError:
        flash('Invalid list of edges provided.',
              'danger'
              )
    except:
        flash('An unexpected error occured while discretizing the column',
              'danger'
              )
    else:
        flash('Column discretized successfully.', 'success')

    return redirect(request.referrer)


@_transform.route('/delete_selection', methods=['POST'])
@login_required
def delete_selection():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    selected_data = request.form.getlist(""data_id"")
    table = table_name_to_object(dataset.working_copy)
    for data in selected_data:
        table.delete(table.c.index == data).execute()
    create_action(
        'deleted selected items',
        dataset.id,
        current_user.id
    )
    return redirect(request.referrer)


@_transform.route('/delete_predicate', methods=['POST'])
@login_required
def delete_predicate():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    table = table_name_to_object(dataset.working_copy)
    condition = ''
    columns = []
    conditions = []
    operators = []
    logics = []
    for i in request.form:
        if i.startswith('column'):
            columns.append(i)
        elif i.startswith('condition'):
            conditions.append(i)
        elif i.startswith('logical'):
            logics.append(i)
        elif i.startswith('operator'):
            operators.append(i)
    columns.sort()
    conditions.sort()
    logics.sort()
    operators.sort()
    for i in range(len(columns)):
        if i != len(columns) - 1:
            condition += '""' + request.form[columns[i + 1]] + '""'
            if request.form[operators[i + 1]] == 'CONTAINS':
                condition += ' ~ '
            elif request.form[operators[i + 1]] == 'NOT CONTIANS':
                condition += ' !~ '
            else:
                condition += request.form[operators[i + 1]]
            condition += '\'' + request.form[conditions[i + 1]] + '\''
            condition += ' ' + request.form[logics[i]] + ' '
        else:
            condition += '""' + request.form[columns[0]] + '""'
            if request.form[operators[0]] == 'CONTAINS':
                condition += ' ~ '
            elif request.form[operators[0]] == 'NOT CONTIANS':
                condition += ' !~ '
            else:
                condition += request.form[operators[0]]
            condition += '\'' + escape_quotes(request.form[conditions[0]]) + '\''

    try:
        if delete_rows(table.name, condition) is False:
            flash('no rows found with condition ""{0}""'.format(condition), 'warning')
        else:
            flash('successfully deleted rows using condition ""{0}""'.format(condition), 'success')
        create_action('rows deleted with condition ""{0}""'.format(condition), dataset.id, current_user.id)
    except Exception as e:
        print(e)
        flash('condition ""{0}"" not valid'.format(condition), 'danger')

    return redirect(request.referrer)


@_transform.route('/reset', methods=['GET'])
@login_required
def reset():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    restore_original(dataset.working_copy)
    create_action(
        'restored dataset to original state',
        dataset.id,
        current_user.id
    )
    return redirect(request.referrer)


@_transform.route('/change_type', methods=['POST'])
@login_required
def change_type():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    table = table_name_to_object(dataset.working_copy)
    col = request.form['column']
    col = col[:col.find('(')-1]
    new_type = request.form['type']
    if col != '' and new_type != '':
        try:
            change_attribute_type(table.name, col, new_type)
            create_action('type {0} changed to {1}'.format(col, new_type), dataset.id, current_user.id)
        except:
            flash('{0} could not be converted to {1}'.format(col, new_type), 'danger')
        else:
            flash('{0} successfully  converted to {1}'.format(col, new_type), 'success')

    return redirect(request.referrer)


@_transform.route('/find_and_replace', methods=['POST'])
@login_required
def find_and_replace():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    col = request.form['column']
    find = request.form['find']
    match_mode = request.form['match-mode']
    replace = request.form['replace']

    if match_mode == 'full-match':
        find_replace(dataset.working_copy, col, find, replace)
    elif match_mode == 'substring-match':
        replace_mode = request.form['replace-mode']
        if replace_mode == 'full-replace':
            substring_find_replace(dataset.working_copy,
                                   col,
                                   find,
                                   replace,
                                   full=True)
        elif replace_mode == 'substring-replace':
            substring_find_replace(dataset.working_copy,
                                   col,
                                   find,
                                   replace,
                                   full=False)
    elif match_mode == 'regex-match':
        regex_find_replace(dataset.working_copy, col, find, replace)

    return redirect(request.referrer)


@_transform.route('/fill_null', methods=['POST'])
@login_required
def fill_null():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    column_and_type = request.form['column']
    column_name = column_and_type[:column_and_type.find(' ')]
    column_type = column_and_type[column_and_type.find('(')+1:column_and_type.rfind(')')]
    fill_value = request.form['fill_value']

    try:
        if fill_value == '~option-average~':
            if column_type not in ['INTEGER', 'BIGINT', 'DOUBLE PRECISION']:
                flash('Operation not supported for this column type.', 'danger')
            else:
                fill_null_with_average(dataset.working_copy, column_name)
                create_action(
                    'Filled null values in {0} with average'.format(column_name),
                    dataset.id,
                    current_user.id
                )
        elif fill_value == '~option-median~':
            if column_type not in ['INTEGER', 'BIGINT', 'DOUBLE PRECISION']:
                flash('Operation not supported for this column type.', 'danger')
            else:
                fill_null_with_median(dataset.working_copy, column_name)
                create_action(
                    'Filled null values in {0} with median'.format(column_name),
                    dataset.id,
                    current_user.id
                )
        else:
            is_text_type = column_type in ['TEXT',
                                           'VARCHAR(10)',
                                           'VARCHAR(25)',
                                           'VARCHAR(255)']
            fill_null_with(
                dataset.working_copy,
                column_name,
                fill_value,
                is_text_type
            )
            create_action(
                'Filled null values in {0} with {1}'
                .format(column_name, fill_value),
                dataset.id,
                current_user.id
            )
    except:
        flash(
            'An unexpected error occured while performing the operation',
            'danger'
            )
    else:
        flash('Fill operation completed successfully', 'success')

    return redirect(request.referrer)
/n/n/napp/Data/Transform/operations.py/n/nfrom app import database as db
import pandas as pd
import re
import numpy as np


def rename_attribute(table_name, column, new_name):
    try:
        db.engine.execute(
            'ALTER TABLE {0} '
            'RENAME COLUMN ""{1}"" TO ""{2}""'
            .format(table_name, column, new_name)
        )
    except Exception as e:
        print(""RENAMING FAILED: ""+str(e))


def delete_attribute(table_name, column):
    try:
        db.engine.execute(
            'ALTER TABLE {0} '
            'DROP COLUMN ""{1}""'
            .format(table_name, column)
        )
    except:
        print(""DELETING FAILED"")


def restore_original(table_name):
    """"""
    Resets given table to its original state
    :param table_name: name of the the table to be reset
    """"""
    try:
        # Original tables are prepended with og
        # Thus we replace wc with og and have the name of the table
        # with the original data
        original = 'og' + table_name[2:]
        db.engine.execute(
            'DROP TABLE ""{0}""'.format(table_name)
        )
        db.engine.execute(
            'CREATE TABLE ""{0}"" AS SELECT * FROM ""{1}""'
            .format(table_name, original)
        )
    except:
        print(""FAILED TO RESTORE ORIGINAL"")


def change_attribute_type(table_name, table_col, new_type):
    """"""
    Changes the type of given attribute in given table to new_type
    :param table_name: table containing the attribute
    :param table_col: attribute to change type of
    :param new_type: new type
    """"""
    current_type = db.engine.execute(
        'SELECT data_type from information_schema.columns '
        'where table_name = \'{0}\' and column_name = \'{1}\';'
        .format(table_name, table_col)
    ).fetchall()[0][0]
    if new_type == 'INTEGER':
        db.engine.execute(
            'ALTER TABLE {0} '
            'ALTER COLUMN ""{1}"" '
            'TYPE BIGINT USING ""{1}""::bigint'
            .format(table_name, table_col))
    if new_type == 'DOUBLE':
        db.engine.execute(
            'ALTER TABLE {0} '
            'ALTER COLUMN ""{1}"" '
            'TYPE DOUBLE PRECISION USING ""{1}""::double precision'
            .format(table_name, table_col))
    if new_type == 'TEXT':
        if current_type == 'date':
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE TEXT USING to_char(""{1}"", \'DD/MM/YYYY\')'
                .format(table_name, table_col))
        elif current_type == 'timestamp without time zone':
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE TEXT USING to_char(""{1}"", \'DD/MM/YYYY HH24:MI:SS\')'
                .format(table_name, table_col))
        else:
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE TEXT'
                .format(table_name, table_col))
    if new_type == 'DATE':
        if current_type == 'timestamp without time zone':
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE DATE'
                .format(table_name, table_col))
        else:
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE DATE USING to_date(""{1}"", \'DD/MM/YYYY\')'
                .format(table_name, table_col))
    if new_type == 'TIMESTAMP':
        if current_type == 'date':
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE TIMESTAMP '
                .format(table_name, table_col))
        else:
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE TIMESTAMP '
                'USING to_timestamp(""{1}"", \'DD/MM/YYYY HH24:MI:SS\')'
                .format(table_name, table_col))


def drop_attribute(table_name, attr):
    """"""
    Drops given attribute from given table
    :param table_name: table to perform the operation on
    :param attr: attribute to drop
    """"""
    try:
        db.engine.execute(
            'ALTER TABLE ""{0}"" DROP COLUMN IF EXISTS ""{1}""'.
            format(table_name, attr)
        )
    except:
        print(""FAILED TO DROP ATTRIBUTE {0} FROM {1}"".format(attr, table_name))


def one_hot_encode(table_name, attr):
    """"""
    One hot encodes given attribute
    :param table_name: table on which to perform the operation
    :param attr: attribute to one hot encode
    :return:
    """"""
    try:
        dataframe = pd.read_sql_table(table_name, db.engine)
        one_hot = pd.get_dummies(dataframe[attr])
        print('OH', one_hot)
        dataframe = dataframe.join(one_hot)
        print('DF', dataframe)
        db.engine.execute(
            'DROP TABLE ""{0}""'.format(table_name)
        )
        dataframe.to_sql(
            name=table_name,
            con=db.engine,
            if_exists=""fail"",
            index=False
        )
    except:
        print('ONE-HOT ENCODING FAILED')


def fill_null_with(table_name, attr, value, text_type):
    """"""
    Fills all NULL values with provided value in table_name.attr
    :param table_name: table to perform the operation on
    :param attr: attribute containing NULL values
    :param text_type: indicates whether column is a text type
    :param value: value to insert
    """"""
    try:
        if text_type:
            db.engine.execute(
                'UPDATE ""{0}"" '
                'SET ""{1}"" = \'{2}\' '
                'WHERE (""{1}"" = \'\') IS NOT FALSE'
                .format(table_name, attr, value)
            )
        else:
            db.engine.execute(
                'UPDATE ""{0}"" '
                'SET ""{1}"" = {2} '
                'WHERE ""{1}"" IS NULL'
                .format(table_name, attr, value)
            )
    except Exception as e:
        print('FILL NULL FAILED WITH FOLLOWING MESSAGE:\n' + str(e))


def fill_null_with_average(table_name, attr):
    """"""
    Fills all NULL values with average value in table_name.attr
    :param table_name: table to perform the operation on
    :param attr: attribute containing NULL values
    """"""
    try:
        dataframe = pd.read_sql_table(table_name, db.engine, columns=[attr])
        average = dataframe[attr].mean()
        db.engine.execute(
            'UPDATE ""{0}"" '
            'SET ""{1}"" = {2} '
            'WHERE ""{1}"" IS NULL'
            .format(table_name, attr, average)
        )
    except:
        print('FILL AVERAGE FAILED')


def fill_null_with_median(table_name, attr):
    """"""
    Fills all NULL values with median value in table_name.attr
    :param table_name: table to perform the operation on
    :param attr: attribute containing NULL values
    """"""
    try:
        dataframe = pd.read_sql_table(table_name, db.engine, columns=[attr])
        median = dataframe[attr].median()
        db.engine.execute(
            'UPDATE ""{0}"" '
            'SET ""{1}"" = {2} '
            'WHERE ""{1}"" IS NULL'
            .format(table_name, attr, median)
        )
    except:
        print('FILL MEAN FAILED')


def find_replace(table_name, attr, find, replace):
    try:
        db.engine.execute(
            'UPDATE ""{0}"" '
            'SET ""{1}"" = \'{2}\' '
            'WHERE ""{1}"" = \'{3}\' '
            .format(table_name, attr, replace, find)
        )
    except:
        print('FIND-REPLACE FAILED')


def substring_find_replace(table_name, attr, find, replace, full=False):
    try:
        if full:
            db.engine.execute(
                'UPDATE ""{0}"" '
                'SET ""{1}"" = \'{2}\' '
                'WHERE ""{1}"" LIKE \'%%{3}%%\' '
                .format(table_name, attr, replace, find)
            )
        else:
            db.engine.execute(
                'UPDATE ""{0}"" '
                'SET ""{1}"" = REPLACE(""{1}"", \'{2}\', \'{3}\')'
                .format(table_name, attr, find, replace)
            )
    except Exception as e:
        print('FIND-REPLACE FAILED\n' + str(e))


def regex_find_replace(table_name, attr, regex, replace):
    try:
        is_valid = True
        try:
            re.compile(regex)
        except re.error:
            is_valid = False
        if is_valid:
            db.engine.execute(
                'UPDATE ""{0}"" '
                'SET ""{1}"" = REGEXP_REPLACE(""{1}"", \'{2}\', \'{3}\')'
                .format(table_name, attr, regex, replace)
            )
    except Exception as e:
        print('REGEX FIND-REPLACE FAILED:\n' + str(e))


def normalize_attribute(table_name, attr):
    """"""
    Normalizes table_name.attr using z-score method
    :param table_name: table to perform the operation on
    :param attr: attribute to normalize
    """"""
    try:
        df = pd.read_sql_table(table_name, db.engine)
        df[attr] = (df[attr] - df[attr].mean()) / df[attr].std(ddof=0)
        db.engine.execute(
            'DROP TABLE ""{0}""'.format(table_name)
        )
        df.to_sql(name=table_name, con=db.engine, if_exists=""fail"", index=False)
    except:
        print('NORMALIZATION FAILED')


def remove_outliers(table_name, attr, value, smaller_than=False):
    """"""
    Removes outliers based on provided value
    :param table_name: table to perform the operation on
    :param attr: attribute to search for outliers
    :param value: extrema value
    :param smaller_than:  if true values smaller than are filtered,
                          values greater than otherwise
    """"""
    try:
        if smaller_than:
            db.engine.execute(
                'DELETE FROM ""{0}"" '
                'WHERE ""{1}"" < {2}'
                .format(table_name, attr, value)
            )
        else:  # greater than
            db.engine.execute(
                'DELETE FROM ""{0}"" '
                'WHERE ""{1}"" > {2}'
                .format(table_name, attr, value)
            )
    except:
        print('REMOVE OUTLIERS FAILED')


def delete_rows(table_name, condition):

    result = db.engine.execute(
        'DELETE FROM ""{0}"" WHERE {1}'.format(table_name, condition)
    )
    if result.rowcount == 0:
        return False


def discretize_width(table_name, attr, intervals, dataframe=None, name=None):
    """"""
    Discretizes table_name.attr into a number of equal-width
    intervals equal to interval amount
    :param table_name: table to perform operation on
    :param attr: attribute to discretize
    :param intervals:
        - int: number of equal width intervals
        - [int]: non-uniform interval edges
    :param dataframe: Dataframe if data has already been read from sql
    """"""
    try:
        if dataframe is not None:
            df = dataframe
        else:
            df = pd.read_sql_table(table_name, db.engine)
        if name is not None:
            column_name = name
        elif isinstance(intervals, list):
            column_name = attr + '_custom_intervals'
        else:
            column_name = attr + '_' + str(intervals) + '_eq_intervals'

        df[column_name] = pd.cut(df[attr], intervals, precision=9).apply(str)
        db.engine.execute(
            'DROP TABLE ""{0}""'.format(table_name)
        )
        df.to_sql(name=table_name, con=db.engine, if_exists=""fail"", index=False)
    except Exception as e:
        print('WIDTH DISCRETIZATION FAILED:\n' + str(e))


def discretize_eq_freq(table_name, attr, intervals):
    """"""
    Discretizes table_name.attr into a number of equal-frequency
    intervals equal to intervals
    :param table_name: table to perform operation on
    :param attr: attribute to discretize
    :param intervals: number of equal frequency intervals
    """"""
    try:
        df = pd.read_sql_table(table_name, db.engine)
        attr_length = len(df[attr])
        elements_per_interval = attr_length//intervals
        sorted_data = list(df[attr].sort_values())
        selector = 0
        edge_list = []
        while selector < attr_length:
            try:
                edge_list.append(sorted_data[selector])
                selector += elements_per_interval
            except IndexError:
                pass
        if edge_list[-1] != sorted_data[-1] and len(edge_list) == intervals + 1:
            edge_list[-1] = sorted_data[-1]
        elif edge_list[-1] != sorted_data[-1] and len(edge_list) != intervals + 1:
            edge_list.append(sorted_data[-1])

        # Extend outer edges with 0.1% to include min and max values
        edge_list[0] = edge_list[0]-edge_list[0]*0.001
        edge_list[-1] = edge_list[-1]+edge_list[-1]*0.001

        column_name = attr + '_' + str(intervals) + '_eq_freq_intervals'

        discretize_width(table_name, attr, edge_list, df, column_name)
    except Exception as e:
        print('EQUAL FREQUENCY DISCRETIZATION FAILED:\n' + str(e))
/n/n/napp/Data/helpers.py/n/nfrom app import database as db


def table_name_to_object(sql_table_name):
    meta = db.MetaData(db.engine)
    table = db.Table(sql_table_name, meta, autoload=True)
    return table


def extract_columns_from_db(table):
    columns = []
    for column in table.columns:
        start = str(column).find('.') + 1
        col_name = str(column)[start:]
        if col_name != 'index':
            col_type = ''
            if str(column.type) == 'BIGINT':
                col_type = 'INTEGER'
            elif str(column.type) == 'DOUBLE PRECISION':
                col_type = 'DOUBLE'
            elif str(column.type) == 'TIMESTAMP WITHOUT TIME ZONE':
                col_type = 'TIMESTAMP'
            else:
                col_type = str(column.type)
            columns.append(
                (col_name, col_type)
            )
    return columns


def escape_quotes(string):
    return_string = ''
    for c in string:
        if c == '\'':
            return_string += '\''
        elif c == '""':
            return_string += '\""'
        return_string += c
    return return_string
/n/n/n",0
139,139,48b00c7b7bb0b82bdc79167947fa9eda9f0ab8e0,"/app/Data/Transform/controllers.py/n/nfrom flask import (
    Blueprint,
    request,
    jsonify,
    redirect,
    url_for,
    render_template,
    flash,
    Response
)
from flask_login import login_required, current_user
from app.Data.operations import create_action, get_dataset_with_id
from app.Data.helpers import table_name_to_object
from app.Data.Transform.operations import (
    restore_original,
    change_attribute_type,
    delete_rows,
    fill_null_with,
    fill_null_with_average,
    fill_null_with_median,
    rename_attribute,
    delete_attribute,
    one_hot_encode,
    normalize_attribute,
    discretize_width,
    discretize_eq_freq,
    find_replace,
    regex_find_replace,
    substring_find_replace
)

_transform = Blueprint('transform_bp', __name__, url_prefix='/data/transform')


@_transform.route('/rename_column', methods=['POST'])
@login_required
def rename_column():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    col = request.form['column']
    new_name = request.form['new_name']
    try:
        rename_attribute(dataset.working_copy, col, new_name)
        create_action(
            'Renamed column {0} to {1}'.format(col, new_name),
            dataset.id,
            current_user.id
        )
    except:
        flash('An unexpected error occured while renaming the column', 'danger')
    else:
        flash('Column renamed successfully.', 'success')

    return redirect(request.referrer)


@_transform.route('/delete_column', methods=['POST'])
@login_required
def delete_column():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    col = request.form['column']
    try:
        delete_attribute(dataset.working_copy, col)
        create_action(
            'Deleted column {0}'.format(col),
            dataset.id,
            current_user.id
        )
    except:
        flash('An unexpected error occured while deleting the column', 'danger')
    else:
        flash('Column deleted successfully.', 'success')

    return redirect(request.referrer)


@_transform.route('one_hot_encode_column', methods=['POST'])
@login_required
def one_hot_encode_column():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    col = request.form['column']
    try:
        one_hot_encode(dataset.working_copy, col)
        create_action(
            'One-hot-encoded {0}'.format(col),
            dataset.id,
            current_user.id
        )
    except:
        flash('An unexpected error occured while one-hot-encoding the column',
              'danger'
              )
    else:
        flash('Column one-hot-encoded successfully.', 'success')

    return redirect(request.referrer)


@_transform.route('normalize_column', methods=['POST'])
@login_required
def normalize_column():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    col = request.form['column']
    try:
        normalize_attribute(dataset.working_copy, col)
        create_action(
            'Normalized {0}'.format(col),
            dataset.id,
            current_user.id
        )
    except:
        flash('An unexpected error occured while normalizing the column',
              'danger'
              )
    else:
        flash('Column normalized successfully.', 'success')

    return redirect(request.referrer)


@_transform.route('/discretize_column', methods=['POST'])
@login_required
def discretize_column():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    column = request.form['column']
    intervals = request.form['intervals']

    try:
        if intervals == 'equal-distance':
            amount = request.form['amount-dist']
            discretize_width(dataset.working_copy, column, int(amount))
        elif intervals == 'equal-frequency':
            amount = request.form['amount-freq']
            discretize_eq_freq(dataset.working_copy, column, int(amount))
        else:
            edges = str(request.form['custom-edges'])
            edges = edges.replace(' ', '')
            edge_list = edges.split(',')
            if len(edge_list) < 2:
                raise ValueError
            for i in range(len(edge_list)):
                edge_list[i] = float(edge_list[i])
            discretize_width(dataset.working_copy, column, edge_list)

    except ValueError:
        flash('Invalid list of edges provided.',
              'danger'
              )
    except:
        flash('An unexpected error occured while discretizing the column',
              'danger'
              )
    else:
        flash('Column discretized successfully.', 'success')

    return redirect(request.referrer)


@_transform.route('/delete_selection', methods=['POST'])
@login_required
def delete_selection():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    selected_data = request.form.getlist(""data_id"")
    table = table_name_to_object(dataset.working_copy)
    for data in selected_data:
        table.delete(table.c.index == data).execute()
    create_action(
        'deleted selected items',
        dataset.id,
        current_user.id
    )
    return redirect(request.referrer)


@_transform.route('/delete_predicate', methods=['POST'])
@login_required
def delete_predicate():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    table = table_name_to_object(dataset.working_copy)
    condition = ''
    columns = []
    conditions = []
    operators = []
    logics = []
    for i in request.form:
        if i.startswith('column'):
            columns.append(i)
        elif i.startswith('condition'):
            conditions.append(i)
        elif i.startswith('logical'):
            logics.append(i)
        elif i.startswith('operator'):
            operators.append(i)
    columns.sort()
    conditions.sort()
    logics.sort()
    operators.sort()
    for i in range(len(columns)):
        if i != len(columns) - 1:
            condition += '""' + request.form[columns[i + 1]] + '""'
            if request.form[operators[i + 1]] == 'CONTAINS':
                condition += ' ~ '
            elif request.form[operators[i + 1]] == 'NOT CONTIANS':
                condition += ' !~ '
            else:
                condition += request.form[operators[i + 1]]
            condition += '\'' + request.form[conditions[i + 1]] + '\''
            condition += ' ' + request.form[logics[i]] + ' '
        else:
            condition += '""' + request.form[columns[0]] + '""'
            if request.form[operators[0]] == 'CONTAINS':
                condition += ' ~ '
            elif request.form[operators[0]] == 'NOT CONTIANS':
                condition += ' !~ '
            else:
                condition += request.form[operators[0]]
            condition += '\'' + request.form[conditions[0]] + '\''

    try:
        delete_rows(table.name, condition)
        create_action('rows deleted with condition ""{0}""'
                      .format(condition), dataset.id, current_user.id
                      )
    except:
        flash('condition ""{0}"" not valid'.format(condition), 'danger')
    else:
        flash('successfully deleted rows using condition ""{0}""'
              .format(condition), 'success'
              )
    return redirect(request.referrer)


@_transform.route('/reset', methods=['GET'])
@login_required
def reset():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    restore_original(dataset.working_copy)
    create_action(
        'restored dataset to original state',
        dataset.id,
        current_user.id
    )
    return redirect(request.referrer)


@_transform.route('/change_type', methods=['POST'])
@login_required
def change_type():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    table = table_name_to_object(dataset.working_copy)
    col = request.form['column']
    col = col[:col.find('(')-1]
    new_type = request.form['type']
    if col != '' and new_type != '':
        try:
            change_attribute_type(table.name, col, new_type)
            create_action('type {0} changed to {1}'.format(col, new_type), dataset.id, current_user.id)
        except:
            flash('{0} could not be converted to {1}'.format(col, new_type), 'danger')
        else:
            flash('{0} successfully  converted to {1}'.format(col, new_type), 'success')

    return redirect(request.referrer)


@_transform.route('/find_and_replace', methods=['POST'])
@login_required
def find_and_replace():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    col = request.form['column']
    find = request.form['find']
    match_mode = request.form['match-mode']
    replace = request.form['replace']

    if match_mode == 'full-match':
        find_replace(dataset.working_copy, col, find, replace)
    elif match_mode == 'substring-match':
        replace_mode = request.form['replace-mode']
        if replace_mode == 'full-replace':
            substring_find_replace(dataset.working_copy,
                                   col,
                                   find,
                                   replace,
                                   full=True)
        elif replace_mode == 'substring-replace':
            substring_find_replace(dataset.working_copy,
                                   col,
                                   find,
                                   replace,
                                   full=False)
    elif match_mode == 'regex-match':
        regex_find_replace(dataset.working_copy, col, find, replace)

    return redirect(request.referrer)


@_transform.route('/fill_null', methods=['POST'])
@login_required
def fill_null():
    dataset = get_dataset_with_id(request.args.get('dataset_id'))
    column_and_type = request.form['column']
    column_name = column_and_type[:column_and_type.find(' ')]
    column_type = column_and_type[column_and_type.find('(')+1:column_and_type.rfind(')')]
    fill_value = request.form['fill_value']

    try:
        if fill_value == '~option-average~':
            if column_type not in ['INTEGER', 'BIGINT', 'DOUBLE PRECISION']:
                flash('Operation not supported for this column type.', 'danger')
            else:
                fill_null_with_average(dataset.working_copy, column_name)
                create_action(
                    'Filled null values in {0} with average'.format(column_name),
                    dataset.id,
                    current_user.id
                )
        elif fill_value == '~option-median~':
            if column_type not in ['INTEGER', 'BIGINT', 'DOUBLE PRECISION']:
                flash('Operation not supported for this column type.', 'danger')
            else:
                fill_null_with_median(dataset.working_copy, column_name)
                create_action(
                    'Filled null values in {0} with median'.format(column_name),
                    dataset.id,
                    current_user.id
                )
        else:
            is_text_type = column_type in ['TEXT',
                                           'VARCHAR(10)',
                                           'VARCHAR(25)',
                                           'VARCHAR(255)']
            fill_null_with(
                dataset.working_copy,
                column_name,
                fill_value,
                is_text_type
            )
            create_action(
                'Filled null values in {0} with {1}'
                .format(column_name, fill_value),
                dataset.id,
                current_user.id
            )
    except:
        flash(
            'An unexpected error occured while performing the operation',
            'danger'
            )
    else:
        flash('Fill operation completed successfully', 'success')

    return redirect(request.referrer)
/n/n/n/app/Data/Transform/operations.py/n/nfrom app import database as db
import pandas as pd
import re
import numpy as np


def rename_attribute(table_name, column, new_name):
    try:
        db.engine.execute(
            'ALTER TABLE {0} '
            'RENAME COLUMN ""{1}"" TO ""{2}""'
            .format(table_name, column, new_name)
        )
    except Exception as e:
        print(""RENAMING FAILED: ""+str(e))


def delete_attribute(table_name, column):
    try:
        db.engine.execute(
            'ALTER TABLE {0} '
            'DROP COLUMN ""{1}""'
            .format(table_name, column)
        )
    except:
        print(""DELETING FAILED"")


def restore_original(table_name):
    """"""
    Resets given table to its original state
    :param table_name: name of the the table to be reset
    """"""
    try:
        # Original tables are prepended with og
        # Thus we replace wc with og and have the name of the table
        # with the original data
        original = 'og' + table_name[2:]
        db.engine.execute(
            'DROP TABLE ""{0}""'.format(table_name)
        )
        db.engine.execute(
            'CREATE TABLE ""{0}"" AS SELECT * FROM ""{1}""'
            .format(table_name, original)
        )
    except:
        print(""FAILED TO RESTORE ORIGINAL"")


def change_attribute_type(table_name, table_col, new_type):
    """"""
    Changes the type of given attribute in given table to new_type
    :param table_name: table containing the attribute
    :param table_col: attribute to change type of
    :param new_type: new type
    """"""
    current_type = db.engine.execute(
        'SELECT data_type from information_schema.columns '
        'where table_name = \'{0}\' and column_name = \'{1}\';'
        .format(table_name, table_col)
    ).fetchall()[0][0]
    if new_type == 'INTEGER':
        db.engine.execute(
            'ALTER TABLE {0} '
            'ALTER COLUMN ""{1}"" '
            'TYPE BIGINT USING ""{1}""::bigint'
            .format(table_name, table_col))
    if new_type == 'DOUBLE':
        db.engine.execute(
            'ALTER TABLE {0} '
            'ALTER COLUMN ""{1}"" '
            'TYPE DOUBLE PRECISION USING ""{1}""::double precision'
            .format(table_name, table_col))
    if new_type == 'TEXT':
        if current_type == 'date':
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE TEXT USING to_char(""{1}"", \'DD/MM/YYYY\')'
                .format(table_name, table_col))
        elif current_type == 'timestamp with time zone':
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE TEXT USING to_char(""{1}"", \'DD/MM/YYYY HH24:MI:SS\')'
                .format(table_name, table_col))
        else:
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE TEXT'
                .format(table_name, table_col))
    if new_type == 'DATE':
        if current_type == 'timestamp with time zone':
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE DATE'
                .format(table_name, table_col))
        else:
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE DATE USING to_date(""{1}"", \'DD/MM/YYYY\')'
                .format(table_name, table_col))
    if new_type == 'TIMESTAMP':
        if current_type == 'date':
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE TIMESTAMP WITH TIME ZONE'
                .format(table_name, table_col))
        else:
            db.engine.execute(
                'ALTER TABLE {0} '
                'ALTER COLUMN ""{1}"" '
                'TYPE TIMESTAMP WITH TIME ZONE '
                'USING to_timestamp(""{1}"", \'DD/MM/YYYY HH24:MI:SS\')'
                .format(table_name, table_col))


def drop_attribute(table_name, attr):
    """"""
    Drops given attribute from given table
    :param table_name: table to perform the operation on
    :param attr: attribute to drop
    """"""
    try:
        db.engine.execute(
            'ALTER TABLE ""{0}"" DROP COLUMN IF EXISTS ""{1}""'.
            format(table_name, attr)
        )
    except:
        print(""FAILED TO DROP ATTRIBUTE {0} FROM {1}"".format(attr, table_name))


def one_hot_encode(table_name, attr):
    """"""
    One hot encodes given attribute
    :param table_name: table on which to perform the operation
    :param attr: attribute to one hot encode
    :return:
    """"""
    try:
        dataframe = pd.read_sql_table(table_name, db.engine)
        one_hot = pd.get_dummies(dataframe[attr])
        print('OH', one_hot)
        dataframe = dataframe.join(one_hot)
        print('DF', dataframe)
        db.engine.execute(
            'DROP TABLE ""{0}""'.format(table_name)
        )
        dataframe.to_sql(
            name=table_name,
            con=db.engine,
            if_exists=""fail"",
            index=False
        )
    except:
        print('ONE-HOT ENCODING FAILED')


def fill_null_with(table_name, attr, value, text_type):
    """"""
    Fills all NULL values with provided value in table_name.attr
    :param table_name: table to perform the operation on
    :param attr: attribute containing NULL values
    :param text_type: indicates whether column is a text type
    :param value: value to insert
    """"""
    try:
        if text_type:
            db.engine.execute(
                'UPDATE ""{0}"" '
                'SET ""{1}"" = \'{2}\' '
                'WHERE (""{1}"" = \'\') IS NOT FALSE'
                .format(table_name, attr, value)
            )
        else:
            db.engine.execute(
                'UPDATE ""{0}"" '
                'SET ""{1}"" = {2} '
                'WHERE ""{1}"" IS NULL'
                .format(table_name, attr, value)
            )
    except Exception as e:
        print('FILL NULL FAILED WITH FOLLOWING MESSAGE:\n' + str(e))


def fill_null_with_average(table_name, attr):
    """"""
    Fills all NULL values with average value in table_name.attr
    :param table_name: table to perform the operation on
    :param attr: attribute containing NULL values
    """"""
    try:
        dataframe = pd.read_sql_table(table_name, db.engine, columns=[attr])
        average = dataframe[attr].mean()
        db.engine.execute(
            'UPDATE ""{0}"" '
            'SET ""{1}"" = {2} '
            'WHERE ""{1}"" IS NULL'
            .format(table_name, attr, average)
        )
    except:
        print('FILL AVERAGE FAILED')


def fill_null_with_median(table_name, attr):
    """"""
    Fills all NULL values with median value in table_name.attr
    :param table_name: table to perform the operation on
    :param attr: attribute containing NULL values
    """"""
    try:
        dataframe = pd.read_sql_table(table_name, db.engine, columns=[attr])
        median = dataframe[attr].median()
        db.engine.execute(
            'UPDATE ""{0}"" '
            'SET ""{1}"" = {2} '
            'WHERE ""{1}"" IS NULL'
            .format(table_name, attr, median)
        )
    except:
        print('FILL MEAN FAILED')


def find_replace(table_name, attr, find, replace):
    try:
        db.engine.execute(
            'UPDATE ""{0}"" '
            'SET ""{1}"" = \'{2}\' '
            'WHERE ""{1}"" = \'{3}\' '
            .format(table_name, attr, replace, find)
        )
    except:
        print('FIND-REPLACE FAILED')


def substring_find_replace(table_name, attr, find, replace, full=False):
    try:
        if full:
            db.engine.execute(
                'UPDATE ""{0}"" '
                'SET ""{1}"" = \'{2}\' '
                'WHERE ""{1}"" LIKE \'%%{3}%%\' '
                .format(table_name, attr, replace, find)
            )
        else:
            db.engine.execute(
                'UPDATE ""{0}"" '
                'SET ""{1}"" = REPLACE(""{1}"", \'{2}\', \'{3}\')'
                .format(table_name, attr, find, replace)
            )
    except Exception as e:
        print('FIND-REPLACE FAILED\n' + str(e))


def regex_find_replace(table_name, attr, regex, replace):
    try:
        is_valid = True
        try:
            re.compile(regex)
        except re.error:
            is_valid = False
        if is_valid:
            db.engine.execute(
                'UPDATE ""{0}"" '
                'SET ""{1}"" = REGEXP_REPLACE(""{1}"", \'{2}\', \'{3}\')'
                .format(table_name, attr, regex, replace)
            )
    except Exception as e:
        print('REGEX FIND-REPLACE FAILED:\n' + str(e))


def normalize_attribute(table_name, attr):
    """"""
    Normalizes table_name.attr using z-score method
    :param table_name: table to perform the operation on
    :param attr: attribute to normalize
    """"""
    try:
        df = pd.read_sql_table(table_name, db.engine)
        df[attr] = (df[attr] - df[attr].mean()) / df[attr].std(ddof=0)
        db.engine.execute(
            'DROP TABLE ""{0}""'.format(table_name)
        )
        df.to_sql(name=table_name, con=db.engine, if_exists=""fail"", index=False)
    except:
        print('NORMALIZATION FAILED')


def remove_outliers(table_name, attr, value, smaller_than=False):
    """"""
    Removes outliers based on provided value
    :param table_name: table to perform the operation on
    :param attr: attribute to search for outliers
    :param value: extrema value
    :param smaller_than:  if true values smaller than are filtered,
                          values greater than otherwise
    """"""
    try:
        if smaller_than:
            db.engine.execute(
                'DELETE FROM ""{0}"" '
                'WHERE ""{1}"" < {2}'
                .format(table_name, attr, value)
            )
        else:  # greater than
            db.engine.execute(
                'DELETE FROM ""{0}"" '
                'WHERE ""{1}"" > {2}'
                .format(table_name, attr, value)
            )
    except:
        print('REMOVE OUTLIERS FAILED')


def delete_rows(table_name, condition):

    db.engine.execute(
        'DELETE FROM ""{0}"" WHERE {1}'.format(table_name, condition)
    )


def discretize_width(table_name, attr, intervals, dataframe=None, name=None):
    """"""
    Discretizes table_name.attr into a number of equal-width
    intervals equal to interval amount
    :param table_name: table to perform operation on
    :param attr: attribute to discretize
    :param intervals:
        - int: number of equal width intervals
        - [int]: non-uniform interval edges
    :param dataframe: Dataframe if data has already been read from sql
    """"""
    try:
        if dataframe is not None:
            df = dataframe
        else:
            df = pd.read_sql_table(table_name, db.engine)
        if name is not None:
            column_name = name
        elif isinstance(intervals, list):
            column_name = attr + '_custom_intervals'
        else:
            column_name = attr + '_' + str(intervals) + '_eq_intervals'

        df[column_name] = pd.cut(df[attr], intervals, precision=9).apply(str)
        db.engine.execute(
            'DROP TABLE ""{0}""'.format(table_name)
        )
        df.to_sql(name=table_name, con=db.engine, if_exists=""fail"", index=False)
    except Exception as e:
        print('WIDTH DISCRETIZATION FAILED:\n' + str(e))


def discretize_eq_freq(table_name, attr, intervals):
    """"""
    Discretizes table_name.attr into a number of equal-frequency
    intervals equal to intervals
    :param table_name: table to perform operation on
    :param attr: attribute to discretize
    :param intervals: number of equal frequency intervals
    """"""
    try:
        df = pd.read_sql_table(table_name, db.engine)
        attr_length = len(df[attr])
        elements_per_interval = attr_length//intervals
        sorted_data = list(df[attr].sort_values())
        selector = 0
        edge_list = []
        while selector < attr_length:
            try:
                edge_list.append(sorted_data[selector])
                selector += elements_per_interval
            except IndexError:
                pass
        if edge_list[-1] != sorted_data[-1] and len(edge_list) == intervals + 1:
            edge_list[-1] = sorted_data[-1]
        elif edge_list[-1] != sorted_data[-1] and len(edge_list) != intervals + 1:
            edge_list.append(sorted_data[-1])

        # Extend outer edges with 0.1% to include min and max values
        edge_list[0] = edge_list[0]-edge_list[0]*0.001
        edge_list[-1] = edge_list[-1]+edge_list[-1]*0.001

        column_name = attr + '_' + str(intervals) + '_eq_freq_intervals'

        discretize_width(table_name, attr, edge_list, df, column_name)
    except Exception as e:
        print('EQUAL FREQUENCY DISCRETIZATION FAILED:\n' + str(e))
/n/n/n",1
142,142,f7e35633925d7f93d6ca09c635c5d85af5509f11,"comics-app/comics.py/n/nfrom flask import Flask, g, render_template, request, jsonify, abort
from utils import get_db, get_queries, ajax, execute_query, generic_search
import utils
import os
import atexit

app = Flask(__name__)
context = {}

# Set app configuration
app.config.update({'DB_USER': os.environ['IDBS_USER'],
                   'DB_PWD': os.environ['IDBS_PWD'],
                   'DB_SERVER': 'diassrv2.epfl.ch',
                   'DB_PORT': 1521,
                   'DB_SID': 'orcldias',
                   'DEBUG': True,
                   'QUERIES_PATH': 'queries.sql'})


@app.route('/')
def home():
    con = get_db(app)
    return render_template('index.html')


@app.route('/search', methods=['GET', 'POST'])
@ajax
def search():
    # If GET, return the form to render
    if request.method == 'GET':
        return render_template('search-form.html')

    # If POST, process the query and return data
    keywords = request.form['keywords']
    tables = list(request.form.keys())
    tables.remove('keywords')

    try:
        data = generic_search(get_db(app), keywords, tables)
        return jsonify(data)
    except ValueError:
        # Invalid user input
        return abort(401)


@app.route('/queries', methods=['GET', 'POST'])
@ajax
def queries():
    if request.method == 'GET':
        return render_template('queries-form.html', queries=get_queries(app, context))

    # Get query and execute it
    query_key = request.form['query-selector']
    query = get_queries(app, context)[query_key]
    (schema, data) = execute_query(get_db(app), query)

    return jsonify([('', schema, data)])


@app.route('/get_table_names', methods=['GET'])
@ajax
def get_table_names():
    return jsonify(utils.get_table_names(get_db(app)))


@app.teardown_appcontext
def close_db(error):
    """"""Closes the database again at the end of the request.""""""
    if hasattr(g, 'db'):
        g.db.close()
/n/n/ncomics-app/utils.py/n/nfrom flask import abort, request, g
from functools import wraps
import cx_Oracle
import re


def execute_query(con, query, **kwargs):
    """""" Execute a query and return corresponding data """"""
    # Execute query
    cur = con.cursor()
    cur.execute(query, kwargs)

    # Return data with description
    return (extract_schema(cur.description), cur.fetchall())


def generic_search(con, keywords, tables):
    """""" Perform a search in the given tables for containment of given keywords """"""
    # List of tuples (table_name, schema, tuples)
    result = []
    table_names = get_table_names(con)
    for table in tables:
        # Make sure user didn't cheat with table names
        if table not in table_names:
            raise ValueError('Invalid table name')

        # Build conditions
        conditions = []
        for col in get_column_names(con, table):
            conditions.append('{} LIKE \'%\'||:keywords||\'%\''.format(col))

        conditions = ' OR '.join(conditions)

        # Execute query
        query = 'SELECT * FROM {} WHERE {}'.format(table, conditions)
        (schema, data) = execute_query(con, query, keywords=keywords)

        if len(data) > 0:
            result.append((table, schema, data))

    return result


def extract_schema(description):
    """""" Extract column names from cursor description """"""
    names = []
    for col in description:
        names.append(col[0])

    return names


def ajax(f):
    """""" Custom decoractor to restrict acces to AJAX calls """"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not request.is_xhr:
            return abort(401)
        return f(*args, **kwargs)
    return decorated_function


def get_db(app):
    """""" Connect to the database and return connection """"""
    if not hasattr(g, 'db'):
        dsn_tns = cx_Oracle.makedsn(app.config['DB_SERVER'],
                                    app.config['DB_PORT'],
                                    app.config['DB_SID'])

        g.db = cx_Oracle.connect(app.config['DB_USER'],
                                 app.config['DB_PWD'],
                                 dsn_tns)

    return g.db


def get_queries(app, context):
    """""" Parse, cache and return predefined queries """"""
    if 'queries' not in context:
        with open(app.config['QUERIES_PATH'], 'r') as fd:
            sqlFile = fd.read()

        # all SQL commands (split on ';')
        sqlCommands = sqlFile.split(';')
        context['queries'] = {}
        for command in sqlCommands:
            command = re.sub(r'\s*--\s*|\s*\n\s*', ' ', command)
            query = command.split(':')
            context['queries'][query[0]] = query[1]

    return context['queries']


def get_table_names(con):
    """""" Return database tables names """"""
    query = 'SELECT table_name FROM user_tables'
    data = execute_query(con, query)[1]
    return list(map(lambda x: x[0], data))


def get_column_names(con, table):
    """""" Return table column names """"""
    query = 'SELECT * FROM {} WHERE 1=0'.format(table)
    return execute_query(con, query)[0]
/n/n/n",0
143,143,f7e35633925d7f93d6ca09c635c5d85af5509f11,"/comics-app/comics.py/n/nfrom flask import Flask, g, render_template, request, jsonify
from utils import get_db, get_queries, shutdown, ajax, execute_query, generic_search
import os
import atexit

app = Flask(__name__)

# Register clean up function
atexit.register(shutdown, app=app, context=g)

# Set app configuration
app.config.update({'DB_USER': os.environ['IDBS_USER'],
                   'DB_PWD': os.environ['IDBS_PWD'],
                   'DB_SERVER': 'diassrv2.epfl.ch',
                   'DB_PORT': 1521,
                   'DB_SID': 'orcldias',
                   'DEBUG': True,
                   'QUERIES_PATH': 'queries.sql'})


@app.route('/')
def home():
    con = get_db(app, g)
    return render_template('index.html')


@app.route('/search', methods=['GET', 'POST'])
@ajax
def search():
    # If GET, return the form to render
    if request.method == 'GET':
        return render_template('search-form.html')

    # If POST, process the query and return data
    keywords = request.form['keywords']
    tables = list(request.form.keys())
    tables.remove('keywords')

    data = generic_search(keywords, tables, app, g)
    return jsonify(data)


@app.route('/queries', methods=['GET', 'POST'])
@ajax
def queries():
    if request.method == 'GET':
        return render_template('queries-form.html', queries=get_queries(app, g))

    # Get query and execute it
    query_key = request.form['query-selector']
    query = get_queries(app, g)[query_key]
    (schema, data) = execute_query(app, g, query)

    return jsonify([('', schema, data)])


@app.route('/get_table_names', methods=['GET'])
@ajax
def get_table_names():
    query = 'SELECT table_name FROM user_tables'
    data = execute_query(app, g, query)[1]
    return jsonify(data)
/n/n/n/comics-app/utils.py/n/nfrom flask import abort, request
from functools import wraps
import cx_Oracle
import re


def get_db(app, context):
    """""" Connect to the database and return connection """"""
    if not hasattr(context, 'db'):
        dsn_tns = cx_Oracle.makedsn(app.config['DB_SERVER'],
                                    app.config['DB_PORT'],
                                    app.config['DB_SID'])

        context.db = cx_Oracle.connect(app.config['DB_USER'],
                                       app.config['DB_PWD'],
                                       dsn_tns)

    return context.db


def get_queries(app, context):
    """""" Parse and return predefined queries """"""
    if not hasattr(context, 'queries'):
        with open(app.config['QUERIES_PATH'], 'r') as fd:
            sqlFile = fd.read()

        # all SQL commands (split on ';')
        sqlCommands = sqlFile.split(';')
        context.queries = {}
        for command in sqlCommands:
            command = re.sub(r'\s*--\s*|\s*\n\s*', ' ', command)
            query = command.split(':')
            context.queries[query[0]] = query[1]

    return context.queries


def execute_query(app, context, query):
    """""" Execute a query and return corresponding data """"""
    # Execute query
    con = get_db(app, context)
    cur = con.cursor()
    cur.execute(query)

    # Return data with description
    return (extract_schema(cur.description), cur.fetchall())


def generic_search(keywords, tables, app, context):
    # List of tuples (table_name, schema, tuples)
    result = []
    for table in tables:
        # Get columns for the table
        query = 'SELECT * FROM {} WHERE 1=0'.format(table)
        description = execute_query(app, context, query)[0]

        # Build conditions
        conditions = []
        for col in description:
            conditions.append('{} LIKE \'%{}%\''.format(col, keywords))

        conditions = ' OR '.join(conditions)

        # Execute query
        query = 'SELECT * FROM {} WHERE {}'.format(table, conditions)
        (schema, data) = execute_query(app, context, query)
        result.append((table, schema, data))

    return result


def extract_schema(description):
    names = []
    for col in description:
        names.append(col[0])

    return names


def shutdown(app, context):
    """""" Clean-up application state before shutdown """"""
    with app.app_context():
        get_db(app, context).close()


def ajax(f):
    """""" Custom decoractor to restrict acces to AJAX calls """"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not request.is_xhr:
            return abort(401)
        return f(*args, **kwargs)
    return decorated_function
/n/n/n",1
84,84,3c56a5ab85df68f79ded480ad026f974bce7d48c,"server/functions/badWords.py/n/nimport mysql.connector

class BadWordsDB():
    from serverSetup import DBUSER,DBPASS

    def __init__(self,host,user,passwd,database,filterList=[]):
        self.host= host
        self.user = user
        self.passwd = passwd
        self.database = database
        self.filterList = filterList

    def connect(self):
        self.mydb = mysql.connector.connect(
            host=self.host,
            user=self.user,
            passwd=self.passwd,
            database=self.database
        )
        self.cursor = self.mydb.cursor()

    def close(self):
        self.cursor.close()
        self.mydb.close()

    def escapeString(self,sqlString):
        sqlString.replace('\'','')
        return sqlString

    def fetch(self):
        self.connect()

        sqlFormula = ""SELECT * FROM badwords""
        self.cursor.execute(sqlFormula)
        myresults = self.cursor.fetchall()

        # Format everything
        badWordArray = []
        for row in myresults:
            badWordArray.append(row[0])

        self.close()

        return badWordArray
    
    def insert(self,targetWord,badwordlist):
        if not targetWord.lower() in badwordlist:
            self.connect()

            sqlFormula = ""INSERT INTO badwords (word, badness) VALUE (%s,%s)""
            word = (self.escapeString(targetWord.lower()),1)
            
            self.cursor.execute(sqlFormula,word)
            self.close()
    
    def printAll(self):
        baddies = self.fetch()
        return ' '.join(baddies)

    def delete(self,targetWord):
        self.connect()

        sqlFormula = ""DELETE FROM badwords WHERE word='%s'"" % targetWord
        sqlFormula = self.escapeString(sqlFormula)

        self.cursor.execute(sqlFormula)
        self.close()
/n/n/n",0
85,85,3c56a5ab85df68f79ded480ad026f974bce7d48c,"/server/functions/badWords.py/n/nimport mysql.connector

class BadWordsDB():
    from serverSetup import DBUSER,DBPASS

    def __init__(self,host,user,passwd,database,filterList=[]):
        self.host= host
        self.user = user
        self.passwd = passwd
        self.database = database
        self.filterList = filterList

    def connect(self):
        self.mydb = mysql.connector.connect(
            host=self.host,
            user=self.user,
            passwd=self.passwd,
            database=self.database
        )
        self.cursor = self.mydb.cursor()

    def close(self):
        self.cursor.close()
        self.mydb.close()

    def fetch(self):
        self.connect()

        sqlFormula = ""SELECT * FROM badwords""
        self.cursor.execute(sqlFormula)
        myresults = self.cursor.fetchall()

        # Format everything
        badWordArray = []
        for row in myresults:
            badWordArray.append(row[0])

        self.close()

        return badWordArray
    
    def insert(self,targetWord,badwordlist):
        if not targetWord.lower() in badwordlist:
            self.connect()

            sqlFormula = ""INSERT INTO badwords (word, badness) VALUE (%s,%s)""
            word = (targetWord.lower(),1)

            self.cursor.execute(sqlFormula, word)
            self.close()
    
    def printAll(self):
        baddies = self.fetch()
        return ' '.join(baddies)

    def delete(self,targetWord):
        self.connect()

        sqlFormula = ""DELETE FROM badwords WHERE word='%s'"" % targetWord

        self.cursor.execute(sqlFormula)
        self.close()
/n/n/n",1
86,86,49c1e478193930ddc9f4cfb873cfab8d8f5653bc,"vagrant/4-project/boardgameclub/views.py/n/nfrom flask import (render_template, url_for, request, redirect, session, abort,
                   make_response, jsonify, flash)
import sqlalchemy
import sqlalchemy.orm.exc
import requests
from xml.etree import ElementTree
import json
import time
import string
import random
from decimal import Decimal
from oauth2client import client
from boardgameclub import app
from boardgameclub.database import db_session
from boardgameclub.models import (Club, Game, Post,  User, GameCategory,
                                  ClubAdmin, clubs_games_assoc,
                                  users_games_assoc)


###################
# Csrf protection #
###################

# Implemented as per:
# http://flask.pocoo.org/snippets/3/' posted by Dan Jacob on 2010-05-03
# but with only one token per session.

@app.before_request
def csrf_protect():
    """"""Abort create, update and delete requests without correct csrf tokens.""""""
    if request.method in ('POST', 'PATCH', 'DELETE'):
        print 'validating csrf token'
        token = session.get('_csrf_token')
        token_from_json = request.get_json().get(
            '_csrf_token') if request.get_json() else None
        if (
            not token or
            token not in (request.form.get('_csrf_token'), token_from_json)
        ):
            print 'failed csrf token test'
            abort(403)
        else:
            print 'csrf token ok'


def generate_csrf_token():
    """"""Add csrf token to the session and return the csrf token.""""""
    if '_csrf_token' not in session:
        print 'generating csrf token'
        session['_csrf_token'] = random_string()
    return session['_csrf_token']


def random_string():
    """"""Create a random string.""""""
    chars = string.ascii_letters + string.digits
    return ''.join([chars[random.randint(0, 61)] for i in range(20)])


app.jinja_env.globals['csrf_token'] = generate_csrf_token


###############################
# Database session management #
###############################

@app.teardown_appcontext
def remove_session(exception=None):
    """"""Remove database session at the end of each request.""""""
    db_session.remove()


####################################
# Authentication and authorisation #
####################################

@app.before_request
def ownership_required():
    """"""Prevent access to update and delete endpoints by
    non-authorized users.
    """"""
    if (
        request.endpoint in ('profile_game_add', 'club_game_add') or
        request.method in ('PATCH', 'DELETE')
    ):
        print 'checking ownership'
        if 'user_id' not in session or not check_ownership():
            abort(403)
        else:
            print 'ownership ok'


def check_ownership():
    """"""Verify if the user is the owner of the requested resource.""""""
    user_id = session.get('user_id')
    if not user_id:
        return False
    elif 'club_' in request.endpoint or 'home' in request.endpoint:
        admin = ClubAdmin.query.filter_by(user_id=user_id).scalar()
        return True if admin else False
    elif 'profile_' in request.endpoint:
        return request.view_args['user_id'] == user_id
    elif request.endpoint == 'post_':
        owned_post = Post.query.filter_by(
            id=request.view_args['post_id'], user_id=user_id).scalar()
        return True if owned_post else False
    else:
        print 'Unable to verify ownership'
        return False


@app.before_request
def login_required():
    """"""Prevent access to create endpoints by non-authenticated users.""""""
    if (
        (request.endpoint in ('post_add', 'profile_add', 'g_disconnect') or
         request.endpoint == 'game_' and request.method == 'POST') and
        'username' not in session
    ):
        abort(401)


def validate_id_token(token, token_jwt):
    """"""Validate id_token as per
    https://developers.google.com/identity/protocols/OpenIDConnect.
    """"""
    url = 'https://www.googleapis.com/oauth2/v3/tokeninfo'
    params = 'id_token={}'.format(token_jwt)
    r = requests.get(url, params=params)

    if (
        # Is the token properly signed by the issuer?
        r.status_code == 200 and r.json()['aud'] == token['aud'] and
        # Was it issued by google?
        token['iss'] in ('https://accounts.google.com',
                         'accounts.google.com') and
        # Is it intended for this app?
        token['aud'] == app.config['CLIENT_ID'] and
        # Is it still valid (not expired)?
        token['exp'] > int(time.time())
    ):
        return True


##################################################
# Miscellaneous functions used by view functions #
##################################################

def json_response(body, code):
    """"""Build a JSON response.""""""
    j_response = make_response(json.dumps(body), code)
    j_response.headers['Content-Type'] = 'application/json'
    return j_response


def error_response(err_msg, code):
    """"""Build a one-line JSON error response.""""""
    err_response = make_response(json.dumps({""error-msg"": err_msg}), code)
    err_response.headers['Content-Type'] = 'application/json'
    return err_response


def bgg_game_options(bg_name):
    """"""Search for games on bgg API by name and return all the matching options.

    Args:
        bg_name (str): game name.

    Returns:
        List of dictionaries. Each dictionary holds basic info about a game.
    """"""
    bgg_games = []
    url = 'https://boardgamegeek.com/xmlapi2/search'
    payload = {'query': bg_name, 'type': 'boardgame'}
    r = requests.get(url, params=payload)
    print r.url
    # Parse the xml response
    root = ElementTree.fromstring(r.content)
    for item in root.findall('item'):
        bgg_id = item.get('id')
        game_name = item.find('name').get('value')
        try:
            year = item.find('yearpublished').get('value')
        except AttributeError:
            year = ''
        bgg_games.append({'id': bgg_id, 'name': game_name, 'year': year})
    return bgg_games


def bgg_game_info(bgg_id):
    """"""Get game info from bgg API; return dictionary with game info and
    list of game category objects .
    """"""
    game_info = {'bgg_id': bgg_id}
    url = 'https://www.boardgamegeek.com/xmlapi2/thing'
    payload = {'id': bgg_id, 'stats': 1}
    r = requests.get(url, params=payload)
    # Parse the xml response
    root = ElementTree.fromstring(r.content)[0]
    # name
    for name in root.findall('name'):
        if name.get('type') == 'primary':
            game_info['name'] = name.get('value')
    # image
    game_info['image'] = root.find('image').text
    # complexity/weight
    game_info['weight'] = root.find('statistics').find('ratings').find(
        'averageweight').get('value')
    # bgg_rating
    game_info['bgg_rating'] = root.find('statistics').find('ratings').find(
        'average').get('value')
    # other properties
    properties = ['year_published', 'min_age', 'min_playtime', 'max_playtime',
                  'min_players', 'max_players']
    for bg_prop in properties:
        game_info[bg_prop] = root.find(bg_prop.replace('_', '')).get('value')

    game_info['bgg_link'] = 'https://boardgamegeek.com/boardgame/{}'.format(
        bgg_id)
    # categories
    categories = []
    for link in root.findall('link'):
        if link.get('type') == 'boardgamecategory':
            categories.append(check_game_category(link.get('value')))
    return game_info, categories


def check_user(email, name, picture):
    """"""Check if the user is already in the database;
    if not, make a new entry. Return user's id.
    """"""
    user = User.query.filter_by(email=email).scalar()
    new_user = False
    if not user:
        print 'adding new user to the db'
        user = User(email=email, name=name, picture=picture)
        db_session.add(user)
        db_session.commit()
        user = User.query.filter_by(email=email).scalar()
        new_user = True
    else:
        print 'user already exists'
    return user.id, new_user


def check_game_category(category_name):
    """"""Check if the game category is already in the database;
    if not, make a new entry. Return the category.
    """"""
    category = GameCategory.query.filter_by(name=category_name).scalar()
    if not category:
        new_category = GameCategory(name=category_name)
        db_session.add(new_category)
        db_session.commit()
        category = GameCategory.query.filter_by(name=category_name).scalar()
    return category


def check_game(bgg_id):
    """"""Check if the game is already in the database;
    if not, make a new entry. Return the game.
    """"""
    bgame = Game.query.filter_by(bgg_id=bgg_id).scalar()
    if not bgame:
        # Get the game info from bgg API
        game_info, bgg_categories = bgg_game_info(bgg_id)
        # Add the game to the database
        bgame = Game(**game_info)
        bgame.categories = bgg_categories
        db_session.add(bgame)
        db_session.commit()
        print 'Game added to the database!'
    else:
        print 'Game already in the database'
    return bgame


def make_posts_read(posts):
    """"""Prepare data on a set of posts for the template engine.

    Args:
        posts (list): list of Post objects.

    Returns:
         List of dictionaries. Each dictionary holds all the post data
         required by the template engine.
    """"""
    posts_read = []
    user_id = session.get('user_id')
    for post in posts:
        user = post.author
        post_dict = {
            'id': post.id,
            'subject': post.subject,
            'body': post.body,
            'author': user.name,
            'author_picture': user.picture,
            'posted': time.strftime(""%d/%m/%Y, %H:%M"",
                                    time.gmtime(post.posted)),
            'owner': post.user_id == user_id
        }
        if post.edited:
            post_dict['edited'] = time.strftime(""%d/%m/%Y, %H:%M"",
                                                time.gmtime(post.edited))
        posts_read.append(post_dict)
    return posts_read


def game_query_builder(key, value, query, param_dict):
    """"""Modify textual sql query in order take into account an additional
    WHERE condition.

    Args:
        key (str): condition name.
        value (str): condition value.
        query (str): textual SQL statement.
        param_dict (dict): dict with params for textual SQL statement.

    Returns:
        str: modified SQL query.
    """"""
    d = {'id': 'id in (:{val})',
         'name': 'name LIKE :{val}',
         'rating-min': 'bgg_rating>=:{val}',
         'players-from': 'min_players<=:{val}',
         'players-to': 'max_players>=:{val}',
         'time-from': 'max_playtime>=:{val}',
         'time-to': 'min_playtime<=:{val}',
         'weight-min': 'weight>=:{val}',
         'weight-max': 'weight<=:{val}',
         }
    if len(value) == 0 or value == 'any' or not d.get(key):
        # Do nothing
        return query, param_dict
    # Add condition value to param_dict
    param_key = 'val_{}'.format(len(param_dict) + 1)
    if key == 'name':
        value = '{}%'.format(value)
    param_dict[param_key] = value
    # Modify SQL statement
    if key == 'id' and 'id in' in query:
        pos = query.find(')', query.find('id in'))
        query = query[:pos] + ', :' + param_key + query[pos:]
    else:
        query = query + d[key].format(val=param_key) + ' AND '
    return query, param_dict


def clear_games(*games):
    """"""Remove orphaned games from the database.

    If any of the games is not owned by any user or the club,
    remove it from the database.
    """"""
    for game in games:
        if len(game.users) == 0 and len(game.clubs) == 0:
            categories = game.categories
            db_session.delete(game)
            db_session.commit()
            clear_categories(*categories)


def clear_categories(*categories):
    """"""Remove orphaned game categories from the database""""""
    for category in categories:
        if len(category.games) == 0:
            db_session.delete(category)
            db_session.commit()


def patch_resource(attributes, my_obj):
    """"""Patch database resource.

    Args:
        attributes (list): list of dictionaries;
            each dictionary is in the following format:
            {'name': attr_name, 'value': attr_value}.
        my_obj: instance of any of the models classes.
    """"""
    for attribute in attributes:
        setattr(my_obj, attribute['name'], attribute['value'])
    db_session.add(my_obj)
    db_session.commit()


def validate_api_game_query(query_dict):
    """"""Validate keys and values of the query.

    Args:
        query_dict (dict): dictionary where each key:value pair
            represents condition-name:condition-value pair of
            an SQL WHERE condition.

    Returns:
        bool: True if all keys and values are valid, False otherwise.
    """"""
    args_int = ['club', 'user', 'id', 'category', 'rating-min', 'players-from',
                'players-to', 'time-from', 'time-to', 'weight-min',
                'weight-max']
    args_other = ['name']
    args_dupl = ['user', 'id', 'category']
    for key, value in query_dict.iteritems(multi=True):
        if(
            # Check if any of the keys is invalid
            key not in args_int + args_other or
            # Check if any of the values is invalid
            key in args_int and not value.isdigit()
        ):
            return False
    # Check if there are any non-allowed key duplicates
    for key, values in query_dict.iterlists():
        if key not in args_dupl and len(values) > 1:
            return False
    # Validate players-to and players-from
    players = ['players-from', 'players-to']
    if not(
        # None of the two keys is present
        not any([x in query_dict for x in players]) or
        # Both keys are present and ...
        all([x in query_dict for x in players]) and
        # ... their values are valid
        int(query_dict['players-to']) >= int(query_dict['players-from'])
    ):
        return False
    return True


def dicts_purge(p_dicts, *keep_keys):
    """"""Purge dictionaries of unwanted key:value pairs.

    Args:
        p_dicts (list): list of dicts to be purged.
        *keep_keys: list of keys to be kept.

    Returns:
        List of purged dicts.
    """"""
    for p_dict in p_dicts:
        for key in p_dict.keys():
            if key not in keep_keys:
                del p_dict[key]
    return p_dicts


def sql_to_dicts(*games):
    """"""Convert Game objects to dictionaries.

    Each column-name:value pair in an object is converted to a
    key:value pair in the corresponding dictionary.

    Args:
        *games: list of Game objects.

    Returns:
        list of dictionaries.
    """"""
    sql_dicts = []
    for game in games:
        keys = game.__table__.columns.keys()
        values = [getattr(game, key) for key in keys]
        values = [float(value) if type(value) == Decimal
                  else value for value in values]
        sql_dicts.append(dict(zip(keys, values)))
    return sql_dicts


def sign_out():
    """"""Sign out a user.""""""
    try:
        # Revoke access token if possible
        r = requests.post(
            'https://accounts.google.com/o/oauth2/revoke',
            params={'token': session['access_token']},
            headers={'content-type': 'application/x-www-form-urlencoded'})
        if r.status_code != 200:
            print 'Failed to revoke access token'
            print r.text
        # Delete user info from session
        del session['email']
        del session['username']
        del session['access_token']
        del session['user_id']
        del session['_csrf_token']
        print 'Signed out'
    except KeyError:
        print 'Not signed in'
        abort(401)


##################
# View functions #
##################

@app.route('/')
def home():
    """"""Return the app's main page.""""""
    club = Club.query.filter_by(id=1).scalar()
    members = User.query.all()
    posts = Post.query.all()
    posts_read = make_posts_read(posts)
    return render_template('club.html', club=club, posts=posts_read,
                           members=members, games=club.games,
                           owner=check_ownership())


@app.route('/club', methods=['PATCH'])
def club_():
    """"""Update the Club.""""""
    club = Club.query.filter_by(id=1).scalar()
    attributes = request.get_json()['data']['attributes']
    patch_resource(attributes, club)
    flash('Club info updated!')
    return '', 204


@app.route('/club/games/add', methods=['GET', 'POST'])
def club_game_add():
    """"""Create ClubGame or return page with form to do so.

    Use POST and GET methods respectively.
    """"""
    if request.method == 'GET':
        # Show the game options matching the specified name
        bgg_options = bgg_game_options(request.args['name'])
        return render_template('game-options.html', games=bgg_options)
    else:
        # Add the chosen game to the database
        game = check_game(request.form['bgg-id'])
        club = Club.query.filter_by(id=1).scalar()
        club.games.append(game)
        db_session.add(club)
        db_session.commit()
        flash('Game added to the collection!')
        return redirect(url_for('home'))


@app.route('/club/games/<int:game_id>', methods=['DELETE'])
def club_game_(game_id):
    """"""Delete ClubGame.""""""
    club = Club.query.filter_by(id=1).scalar()
    try:
        game = Game.query.filter_by(id=game_id).one()
    except sqlalchemy.orm.exc.NoResultFound:
        abort(404)
    club.games.remove(game)
    db_session.commit()
    clear_games(game)
    flash('Game removed from the collection!')
    return '', 204


@app.route('/posts/add', methods=['GET', 'POST'])
def post_add():
    """"""Create Post or return page with form to do so.

    Use POST and GET methods respectively.
    """"""
    if request.method == 'GET':
        return render_template('post-new.html')
    else:
        # Add Post to the database
        post_data = {
            'user_id': session['user_id'],
            'subject': request.form['subject'],
            'body': request.form['body'],
            'posted': int(time.time())
        }
        post = Post(**post_data)
        db_session.add(post)
        db_session.commit()
        flash('Post created!')
        return redirect(url_for('home'))


@app.route('/posts/<int:post_id>', methods=['PATCH', 'DELETE'])
def post_(post_id):
    """"""Update or Delete Post.

    Use PATCH and DELETE methods respectively.
    """"""
    post = Post.query.filter_by(id=post_id).scalar()
    if request.method == 'PATCH':
        # Update Post
        attributes = request.get_json()['data']['attributes']
        attributes.append({'name': 'edited', 'value': int(time.time())})
        patch_resource(attributes, post)
        flash('Post edited!')
        return '', 204
    else:
        # Delete Post
        db_session.delete(post)
        db_session.commit()
        flash('Post deleted!')
        return '', 204


@app.route('/users/<int:user_id>/new')
def profile_add(user_id):
    """"""Return page with form letting the user update his/her new profile.""""""
    try:
        user = User.query.filter_by(id=user_id).one()
    except sqlalchemy.orm.exc.NoResultFound:
        abort(404)
    return render_template('profile-new.html', user=user)


@app.route('/users/<int:user_id>', methods=['GET', 'PATCH', 'DELETE'])
def profile_(user_id):
    """"""Return user's profile page or Update Profile or Delete Profile.

    Use GET, PATCH and DELETE methods respectively.
    """"""
    try:
        user = User.query.filter_by(id=user_id).one()
    except sqlalchemy.orm.exc.NoResultFound:
        abort(404)
    if request.method == 'GET':
        # Return user's profile page
        return render_template('profile.html', user=user, games=user.games,
                               owner=check_ownership())
    elif request.method == 'PATCH':
        # Update Profile
        attributes = request.get_json()['data']['attributes']
        patch_resource(attributes, user)
        flash('Profile updated!')
        return '', 204
    else:
        # Delete Profile
        games = user.games
        db_session.delete(user)
        db_session.commit()
        clear_games(*games)
        sign_out()
        flash('Profile deleted!')
        return '', 204


@app.route('/users/<int:user_id>/games/add', methods=['GET', 'POST'])
def profile_game_add(user_id):
    """"""Create UserGame or return page with form to do so.

    Use POST and GET methods respectively.
    """"""
    if request.method == 'GET':
        # Show the game options matching the specified name
        bgg_options = bgg_game_options(request.args['name'])
        return render_template('game-options.html', games=bgg_options)
    else:
        # Add the chosen game to the database
        game = check_game(request.form['bgg-id'])
        user = User.query.filter_by(id=user_id).scalar()
        user.games.append(game)
        db_session.add(user)
        db_session.commit()
        flash('Game added to the collection!')
        return redirect(url_for('profile_', user_id=user_id))


@app.route('/users/<int:user_id>/games/<int:game_id>', methods=['DELETE'])
def profile_game_(user_id, game_id):
    """"""Delete UserGame.""""""
    try:
        user = User.query.filter_by(id=user_id).one()
        game = Game.query.filter_by(id=game_id).one()
    except sqlalchemy.orm.exc.NoResultFound:
        abort(404)
    user.games.remove(game)
    db_session.commit()
    clear_games(game)
    flash('Game removed from the collection!')
    return '', 204


@app.route('/games/<int:game_id>', methods=['GET', 'POST'])
def game_(game_id):
    """"""Return game page or Update Game.

    Use GET and POST methods respectively.
    """"""
    try:
        bgame = Game.query.filter_by(id=game_id).one()
    except sqlalchemy.orm.exc.NoResultFound:
        abort(404)
    if request.method == 'GET':
        # Return game page
        return render_template('game.html', game=bgame)
    else:
        # Update game info from bgg API
        game_info, bgg_categories = bgg_game_info(bgame.bgg_id)
        for key, value in game_info.iteritems():
            setattr(bgame, key, value)
        bgame.categories = bgg_categories
        db_session.commit()
        flash('Game info updated!')
        return redirect(url_for('game_', game_id=game_id))


@app.route('/games/search')
def game_finder():
    """"""Return game-finder page.""""""
    all_categories = GameCategory.query.all()
    games = []
    if len(request.args) > 0:
        # Build SQL query
        query = ''
        param_dict = {}
        for key, value in request.args.iteritems():
            query, param_dict = game_query_builder(key, value, query,
                                                   param_dict)
        query = query[:-5]
        print query
        print param_dict
        # Get games satisfying the search criteria
        game_category = int(request.args['category'])
        if game_category == 0:
            games = Game.query.filter(sqlalchemy.text(query).params(
                param_dict)).all()
        else:
            # Consider game category
            games = (
                Game.query.filter(sqlalchemy.text(query).params(param_dict))
                .filter(Game.categories.any(GameCategory.id == game_category))
                .all()
            )
    return render_template('game-finder.html', games=games,
                           all_categories=all_categories)


@app.route('/api/games')
def api_games():
    """"""Return list of games, with all their attributes, satisfying
    the criteria provided in the request query string.

    Valid query args are of two types: ownership type and game-attribute type.
    The function first builds two sets of games, ownership set with
    games satisfying the ownership criteria and game-attribute set with
    games satisfying the game-attribute criteria; an intersection of
    these two sets is then returned to the user. Specifying no criteria
    of a given type will result in the corresponding set with all
    the games in the database.

    Valid arguments are as follows:
        ownership type:
            club=1: include all games owned by the club
            user=INTEGER: include all games owned by the user,
                value denotes user id,
                multiple args=YES
        game-attribute type:
            id=INTEGER: value denotes game id,
                multiple args=YES
            name=NAME
            category=INTEGER: value denotes category id,
                multiple args=YES
            rating-min=[1-10]
            players-from=INTEGER: query must also include players-to
            players-to=INTEGER: query must also include players-from
            time-from=INTEGER
            time-to=INTEGER
            weight-min=[1-5]
            weight-max=[1-5]

    The response is in JSON.
    """"""
    if not validate_api_game_query(request.args):
        return error_response(
            'One or more query parameters have invalid key and/or value', 400)
    # Club filter
    games_club = []
    if request.args.get('club') == '1':
        games_club = db_session.query(clubs_games_assoc).all()
        games_club = [club_game.game_id for club_game in games_club]
    print 'games_club', games_club
    # User filter
    users = [int(user_id) for user_id in request.args.getlist('user')]
    games_users = db_session.query(users_games_assoc).filter(
        users_games_assoc.c.user_id.in_(users)).all()
    games_users = [game.game_id for game in games_users]
    print 'games_user', games_users
    # Game attribute filter
    query = ''
    param_dict = {}
    for key, value in request.args.iteritems(multi=True):
        query, param_dict = game_query_builder(key, value, query, param_dict)
    query = query[:-5]
    categories = request.args.getlist('category')
    if len(categories) == 0:
        attr_games = Game.query.filter(sqlalchemy.text(query).params(
            param_dict)).all()
    else:
        # Consider game categories
        attr_games = (
            Game.query.filter(sqlalchemy.text(query).params(param_dict))
            .filter(Game.categories.any(GameCategory.id.in_(categories))).all()
        )
    attr_games = [game.id for game in attr_games]
    print 'games_query', attr_games
    # Union of club and user games
    owned_games = set(games_club) | set(games_users)
    print 'union', owned_games
    # Intersection of owned_games and attr_games
    games_id = ((set(attr_games) & owned_games)
                if len(owned_games) > 0 else set(attr_games))
    print 'intersection', games_id
    # Get all games satisfying the search criteria
    games = Game.query.filter(Game.id.in_(games_id)).all()
    games_dict = sql_to_dicts(*games)
    # Add category info to each game_dict
    games_categories = {}
    for game in games:
        games_categories[game.id] = [game_category.name for game_category in
                                     game.categories]
    for game_dict in games_dict:
        game_dict['category'] = games_categories[game_dict['id']]
    return jsonify(games=games_dict)


@app.route('/api/info')
def api_info():
    """"""Return basic information on all sql entries of chosen types.

    Valid query args:
        users=1
        categories=1
        games=1

    The response is in JSON.
    """"""
    d = {
        'users': User.query.all(),
        'categories': GameCategory.query.all(),
        'games': Game.query.all()
    }
    info = {}
    for key, value in request.args.iteritems():
        if d.get(key) and value == '1':
            sql_all_dict = sql_to_dicts(*d[key])
            info[key] = dicts_purge(sql_all_dict,
                                    *['id', 'name', 'year_published'])
    return jsonify(**info)


@app.route('/gconnect', methods=['POST'])
def g_connect():
    """"""Sign in user.""""""
    # Additional csrf check
    if not request.headers.get('X-Requested-With'):
        abort(403)
    # Get one-time code from the end-user
    auth_code = request.get_json().get('auth_code')
    # Exchange one-time code for id_token and access_token
    try:
        credentials = client.credentials_from_clientsecrets_and_code(
            app.config['CLIENT_SECRET_FILE'],
            ['https://www.googleapis.com/auth/drive.appdata', 'profile',
             'email'],
            auth_code)
    except client.FlowExchangeError:
        return error_response('Failed to upgrade one-time authorization code.',
                              401)
    # Validate id_token
    if not validate_id_token(credentials.id_token, credentials.id_token_jwt):
        return error_response('id token is not valid', 500)
    # Get user info from access token
    userinfo_url = ""https://www.googleapis.com/oauth2/v1/userinfo""
    params = {'access_token': credentials.access_token, 'alt': 'json'}
    answer = requests.get(userinfo_url, params=params)
    user_data = answer.json()
    # Store user info in the session for later use
    session['email'] = credentials.id_token['email']
    session['username'] = user_data['name']
    session['access_token'] = credentials.access_token
    # If the user does not exist, add him to the database
    session['user_id'], new_user = check_user(
        session['email'], session['username'],  user_data['picture'])
    # Response
    body = {'username': user_data['name'],
            'user_id': session['user_id'],
            'new_user': new_user}
    return json_response(body, 200)


@app.route('/gdisconnect', methods=['POST'])
def g_disconnect():
    """"""Sign out user.""""""
    sign_out()
    flash('Signed out!')
    return '', 204
/n/n/n",0
87,87,49c1e478193930ddc9f4cfb873cfab8d8f5653bc,"/vagrant/4-project/boardgameclub/views.py/n/nfrom flask import (render_template, url_for, request, redirect, session, abort,
                   make_response, jsonify, flash)
import sqlalchemy
import sqlalchemy.orm.exc
import requests
from xml.etree import ElementTree
import json
import time
import string
import random
from decimal import Decimal
from oauth2client import client
from boardgameclub import app
from boardgameclub.database import db_session
from boardgameclub.models import (Club, Game, Post,  User, GameCategory,
                                  ClubAdmin, clubs_games_assoc,
                                  users_games_assoc)


###################
# Csrf protection #
###################

# Implemented as per:
# http://flask.pocoo.org/snippets/3/' posted by Dan Jacob on 2010-05-03
# but with only one token per session.

@app.before_request
def csrf_protect():
    """"""Abort create, update and delete requests without correct csrf tokens.""""""
    if request.method in ('POST', 'PATCH', 'DELETE'):
        print 'validating csrf token'
        token = session.get('_csrf_token')
        token_from_json = request.get_json().get(
            '_csrf_token') if request.get_json() else None
        if (
            not token or
            token not in (request.form.get('_csrf_token'), token_from_json)
        ):
            print 'failed csrf token test'
            abort(403)
        else:
            print 'csrf token ok'


def generate_csrf_token():
    """"""Add csrf token to the session and return the csrf token.""""""
    if '_csrf_token' not in session:
        print 'generating csrf token'
        session['_csrf_token'] = random_string()
    return session['_csrf_token']


def random_string():
    """"""Create a random string.""""""
    chars = string.ascii_letters + string.digits
    return ''.join([chars[random.randint(0, 61)] for i in range(20)])


app.jinja_env.globals['csrf_token'] = generate_csrf_token


###############################
# Database session management #
###############################

@app.teardown_appcontext
def remove_session(exception=None):
    """"""Remove database session at the end of each request.""""""
    db_session.remove()


####################################
# Authentication and authorisation #
####################################

@app.before_request
def ownership_required():
    """"""Prevent access to update and delete endpoints by
    non-authorized users.
    """"""
    if (
        request.endpoint in ('profile_game_add', 'club_game_add') or
        request.method in ('PATCH', 'DELETE')
    ):
        print 'checking ownership'
        if 'user_id' not in session or not check_ownership():
            abort(403)
        else:
            print 'ownership ok'


def check_ownership():
    """"""Verify if the user is the owner of the requested resource.""""""
    user_id = session.get('user_id')
    if not user_id:
        return False
    elif 'club_' in request.endpoint or 'home' in request.endpoint:
        admin = ClubAdmin.query.filter_by(user_id=user_id).scalar()
        return True if admin else False
    elif 'profile_' in request.endpoint:
        return request.view_args['user_id'] == user_id
    elif request.endpoint == 'post_':
        owned_post = Post.query.filter_by(
            id=request.view_args['post_id'], user_id=user_id).scalar()
        return True if owned_post else False
    else:
        print 'Unable to verify ownership'
        return False


@app.before_request
def login_required():
    """"""Prevent access to create endpoints by non-authenticated users.""""""
    if (
        (request.endpoint in ('post_add', 'profile_add', 'g_disconnect') or
         request.endpoint == 'game_' and request.method == 'POST') and
        'username' not in session
    ):
        abort(401)


def validate_id_token(token, token_jwt):
    """"""Validate id_token as per
    https://developers.google.com/identity/protocols/OpenIDConnect.
    """"""
    url = 'https://www.googleapis.com/oauth2/v3/tokeninfo'
    params = 'id_token={}'.format(token_jwt)
    r = requests.get(url, params=params)

    if (
        # Is the token properly signed by the issuer?
        r.status_code == 200 and r.json()['aud'] == token['aud'] and
        # Was it issued by google?
        token['iss'] in ('https://accounts.google.com',
                         'accounts.google.com') and
        # Is it intended for this app?
        token['aud'] == app.config['CLIENT_ID'] and
        # Is it still valid (not expired)?
        token['exp'] > int(time.time())
    ):
        return True


##################################################
# Miscellaneous functions used by view functions #
##################################################

def json_response(body, code):
    """"""Build a JSON response.""""""
    j_response = make_response(json.dumps(body), code)
    j_response.headers['Content-Type'] = 'application/json'
    return j_response


def error_response(err_msg, code):
    """"""Build a one-line JSON error response.""""""
    err_response = make_response(json.dumps({""error-msg"": err_msg}), code)
    err_response.headers['Content-Type'] = 'application/json'
    return err_response


def bgg_game_options(bg_name):
    """"""Search for games on bgg API by name and return all the matching options.

    Args:
        bg_name (str): game name.

    Returns:
        List of dictionaries. Each dictionary holds basic info about a game.
    """"""
    bgg_games = []
    url = 'https://boardgamegeek.com/xmlapi2/search'
    payload = {'query': bg_name, 'type': 'boardgame'}
    r = requests.get(url, params=payload)
    print r.url
    # Parse the xml response
    root = ElementTree.fromstring(r.content)
    for item in root.findall('item'):
        bgg_id = item.get('id')
        game_name = item.find('name').get('value')
        try:
            year = item.find('yearpublished').get('value')
        except AttributeError:
            year = ''
        bgg_games.append({'id': bgg_id, 'name': game_name, 'year': year})
    return bgg_games


def bgg_game_info(bgg_id):
    """"""Get game info from bgg API; return dictionary with game info and
    list of game category objects .
    """"""
    game_info = {'bgg_id': bgg_id}
    url = 'https://www.boardgamegeek.com/xmlapi2/thing'
    payload = {'id': bgg_id, 'stats': 1}
    r = requests.get(url, params=payload)
    # Parse the xml response
    root = ElementTree.fromstring(r.content)[0]
    # name
    for name in root.findall('name'):
        if name.get('type') == 'primary':
            game_info['name'] = name.get('value')
    # image
    game_info['image'] = root.find('image').text
    # complexity/weight
    game_info['weight'] = root.find('statistics').find('ratings').find(
        'averageweight').get('value')
    # bgg_rating
    game_info['bgg_rating'] = root.find('statistics').find('ratings').find(
        'average').get('value')
    # other properties
    properties = ['year_published', 'min_age', 'min_playtime', 'max_playtime',
                  'min_players', 'max_players']
    for bg_prop in properties:
        game_info[bg_prop] = root.find(bg_prop.replace('_', '')).get('value')

    game_info['bgg_link'] = 'https://boardgamegeek.com/boardgame/{}'.format(
        bgg_id)
    # categories
    categories = []
    for link in root.findall('link'):
        if link.get('type') == 'boardgamecategory':
            categories.append(check_game_category(link.get('value')))
    return game_info, categories


def check_user(email, name, picture):
    """"""Check if the user is already in the database;
    if not, make a new entry. Return user's id.
    """"""
    user = User.query.filter_by(email=email).scalar()
    new_user = False
    if not user:
        print 'adding new user to the db'
        user = User(email=email, name=name, picture=picture)
        db_session.add(user)
        db_session.commit()
        user = User.query.filter_by(email=email).scalar()
        new_user = True
    else:
        print 'user already exists'
    return user.id, new_user


def check_game_category(category_name):
    """"""Check if the game category is already in the database;
    if not, make a new entry. Return the category.
    """"""
    category = GameCategory.query.filter_by(name=category_name).scalar()
    if not category:
        new_category = GameCategory(name=category_name)
        db_session.add(new_category)
        db_session.commit()
        category = GameCategory.query.filter_by(name=category_name).scalar()
    return category


def check_game(bgg_id):
    """"""Check if the game is already in the database;
    if not, make a new entry. Return the game.
    """"""
    bgame = Game.query.filter_by(bgg_id=bgg_id).scalar()
    if not bgame:
        # Get the game info from bgg API
        game_info, bgg_categories = bgg_game_info(bgg_id)
        # Add the game to the database
        bgame = Game(**game_info)
        bgame.categories = bgg_categories
        db_session.add(bgame)
        db_session.commit()
        print 'Game added to the database!'
    else:
        print 'Game already in the database'
    return bgame


def make_posts_read(posts):
    """"""Prepare data on a set of posts for the template engine.

    Args:
        posts (list): list of Post objects.

    Returns:
         List of dictionaries. Each dictionary holds all the post data
         required by the template engine.
    """"""
    posts_read = []
    user_id = session.get('user_id')
    for post in posts:
        user = post.author
        post_dict = {
            'id': post.id,
            'subject': post.subject,
            'body': post.body,
            'author': user.name,
            'author_picture': user.picture,
            'posted': time.strftime(""%d/%m/%Y, %H:%M"",
                                    time.gmtime(post.posted)),
            'owner': post.user_id == user_id
        }
        if post.edited:
            post_dict['edited'] = time.strftime(""%d/%m/%Y, %H:%M"",
                                                time.gmtime(post.edited))
        posts_read.append(post_dict)
    return posts_read


def game_query_builder(key, value, query):
    """"""Modify textual sql query in order take into account an additional
    WHERE condition.

    Args:
        key (str): condition name.
        value (str): condition value.
        query (str): SQL query.

    Returns:
        str: modified SQL query.
    """"""
    d = {'id': ""id in ({value})"",
         'name': ""name LIKE '{value}%'"",
         'rating-min': 'bgg_rating>={value}',
         'players-from': 'min_players<={value}',
         'players-to': 'max_players>={value}',
         'time-from': 'max_playtime>={value}',
         'time-to': 'min_playtime<={value}',
         'weight-min': 'weight>={value}',
         'weight-max': 'weight<={value}',
         }
    if len(value) == 0 or value == 'any' or not d.get(key):
        # do nothing
        return query
    elif key == 'id' and 'id in' in query:
        pos = query.find(')', query.find('id in'))
        return query[:pos] + ', ' + value + query[pos:]
    else:
        return query + d[key].format(value=value) + ' AND '


def clear_games(*games):
    """"""Remove orphaned games from the database.

    If any of the games is not owned by any user or the club,
    remove it from the database.
    """"""
    for game in games:
        if len(game.users) == 0 and len(game.clubs) == 0:
            categories = game.categories
            db_session.delete(game)
            db_session.commit()
            clear_categories(*categories)


def clear_categories(*categories):
    """"""Remove orphaned game categories from the database""""""
    for category in categories:
        if len(category.games) == 0:
            db_session.delete(category)
            db_session.commit()


def patch_resource(attributes, my_obj):
    """"""Patch database resource.

    Args:
        attributes (list): list of dictionaries;
            each dictionary is in the following format:
            {'name': attr_name, 'value': attr_value}.
        my_obj: instance of any of the models classes.
    """"""
    for attribute in attributes:
        setattr(my_obj, attribute['name'], attribute['value'])
    db_session.add(my_obj)
    db_session.commit()


def validate_api_game_query(query_dict):
    """"""Validate keys and values of the query.

    Args:
        query_dict (dict): dictionary where each key:value pair
            represents condition-name:condition-value pair of
            an SQL WHERE condition.

    Returns:
        bool: True if all keys and values are valid, False otherwise.
    """"""
    args_int = ['club', 'user', 'id', 'category', 'rating-min', 'players-from',
                'players-to', 'time-from', 'time-to', 'weight-min',
                'weight-max']
    args_other = ['name']
    args_dupl = ['user', 'id', 'category']
    for key, value in query_dict.iteritems(multi=True):
        if(
            # Check if any of the keys is invalid
            key not in args_int + args_other or
            # Check if any of the values is invalid
            key in args_int and not value.isdigit()
        ):
            return False
    # Check if there are any non-allowed key duplicates
    for key, values in query_dict.iterlists():
        if key not in args_dupl and len(values) > 1:
            return False
    # Validate players-to and players-from
    players = ['players-from', 'players-to']
    if not(
        # None of the two keys is present
        not any([x in query_dict for x in players]) or
        # Both keys are present and ...
        all([x in query_dict for x in players]) and
        # ... their values are valid
        int(query_dict['players-to']) >= int(query_dict['players-from'])
    ):
        return False
    return True


def dicts_purge(p_dicts, *keep_keys):
    """"""Purge dictionaries of unwanted key:value pairs.

    Args:
        p_dicts (list): list of dicts to be purged.
        *keep_keys: list of keys to be kept.

    Returns:
        List of purged dicts.
    """"""
    for p_dict in p_dicts:
        for key in p_dict.keys():
            if key not in keep_keys:
                del p_dict[key]
    return p_dicts


def sql_to_dicts(*games):
    """"""Convert Game objects to dictionaries.

    Each column-name:value pair in an object is converted to a
    key:value pair in the corresponding dictionary.

    Args:
        *games: list of Game objects.

    Returns:
        list of dictionaries.
    """"""
    sql_dicts = []
    for game in games:
        keys = game.__table__.columns.keys()
        values = [getattr(game, key) for key in keys]
        values = [float(value) if type(value) == Decimal
                  else value for value in values]
        sql_dicts.append(dict(zip(keys, values)))
    return sql_dicts


def sign_out():
    """"""Sign out a user.""""""
    try:
        # Revoke access token if possible
        r = requests.post(
            'https://accounts.google.com/o/oauth2/revoke',
            params={'token': session['access_token']},
            headers={'content-type': 'application/x-www-form-urlencoded'})
        if r.status_code != 200:
            print 'Failed to revoke access token'
            print r.text
        # Delete user info from session
        del session['email']
        del session['username']
        del session['access_token']
        del session['user_id']
        del session['_csrf_token']
        print 'Signed out'
    except KeyError:
        print 'Not signed in'
        abort(401)


##################
# View functions #
##################

@app.route('/')
def home():
    """"""Return the app's main page.""""""
    club = Club.query.filter_by(id=1).scalar()
    members = User.query.all()
    posts = Post.query.all()
    posts_read = make_posts_read(posts)
    return render_template('club.html', club=club, posts=posts_read,
                           members=members, games=club.games,
                           owner=check_ownership())


@app.route('/club', methods=['PATCH'])
def club_():
    """"""Update the Club.""""""
    club = Club.query.filter_by(id=1).scalar()
    attributes = request.get_json()['data']['attributes']
    patch_resource(attributes, club)
    flash('Club info updated!')
    return '', 204


@app.route('/club/games/add', methods=['GET', 'POST'])
def club_game_add():
    """"""Create ClubGame or return page with form to do so.

    Use POST and GET methods respectively.
    """"""
    if request.method == 'GET':
        # Show the game options matching the specified name
        bgg_options = bgg_game_options(request.args['name'])
        return render_template('game-options.html', games=bgg_options)
    else:
        # Add the chosen game to the database
        game = check_game(request.form['bgg-id'])
        club = Club.query.filter_by(id=1).scalar()
        club.games.append(game)
        db_session.add(club)
        db_session.commit()
        flash('Game added to the collection!')
        return redirect(url_for('home'))


@app.route('/club/games/<int:game_id>', methods=['DELETE'])
def club_game_(game_id):
    """"""Delete ClubGame.""""""
    club = Club.query.filter_by(id=1).scalar()
    try:
        game = Game.query.filter_by(id=game_id).one()
    except sqlalchemy.orm.exc.NoResultFound:
        abort(404)
    club.games.remove(game)
    db_session.commit()
    clear_games(game)
    flash('Game removed from the collection!')
    return '', 204


@app.route('/posts/add', methods=['GET', 'POST'])
def post_add():
    """"""Create Post or return page with form to do so.

    Use POST and GET methods respectively.
    """"""
    if request.method == 'GET':
        return render_template('post-new.html')
    else:
        # Add Post to the database
        post_data = {
            'user_id': session['user_id'],
            'subject': request.form['subject'],
            'body': request.form['body'],
            'posted': int(time.time())
        }
        post = Post(**post_data)
        db_session.add(post)
        db_session.commit()
        flash('Post created!')
        return redirect(url_for('home'))


@app.route('/posts/<int:post_id>', methods=['PATCH', 'DELETE'])
def post_(post_id):
    """"""Update or Delete Post.

    Use PATCH and DELETE methods respectively.
    """"""
    post = Post.query.filter_by(id=post_id).scalar()
    if request.method == 'PATCH':
        # Update Post
        attributes = request.get_json()['data']['attributes']
        attributes.append({'name': 'edited', 'value': int(time.time())})
        patch_resource(attributes, post)
        flash('Post edited!')
        return '', 204
    else:
        # Delete Post
        db_session.delete(post)
        db_session.commit()
        flash('Post deleted!')
        return '', 204


@app.route('/users/<int:user_id>/new')
def profile_add(user_id):
    """"""Return page with form letting the user update his/her new profile.""""""
    try:
        user = User.query.filter_by(id=user_id).one()
    except sqlalchemy.orm.exc.NoResultFound:
        abort(404)
    return render_template('profile-new.html', user=user)


@app.route('/users/<int:user_id>', methods=['GET', 'PATCH', 'DELETE'])
def profile_(user_id):
    """"""Return user's profile page or Update Profile or Delete Profile.

    Use GET, PATCH and DELETE methods respectively.
    """"""
    try:
        user = User.query.filter_by(id=user_id).one()
    except sqlalchemy.orm.exc.NoResultFound:
        abort(404)
    if request.method == 'GET':
        # Return user's profile page
        return render_template('profile.html', user=user, games=user.games,
                               owner=check_ownership())
    elif request.method == 'PATCH':
        # Update Profile
        attributes = request.get_json()['data']['attributes']
        patch_resource(attributes, user)
        flash('Profile updated!')
        return '', 204
    else:
        # Delete Profile
        games = user.games
        db_session.delete(user)
        db_session.commit()
        clear_games(*games)
        sign_out()
        flash('Profile deleted!')
        return '', 204


@app.route('/users/<int:user_id>/games/add', methods=['GET', 'POST'])
def profile_game_add(user_id):
    """"""Create UserGame or return page with form to do so.

    Use POST and GET methods respectively.
    """"""
    if request.method == 'GET':
        # Show the game options matching the specified name
        bgg_options = bgg_game_options(request.args['name'])
        return render_template('game-options.html', games=bgg_options)
    else:
        # Add the chosen game to the database
        game = check_game(request.form['bgg-id'])
        user = User.query.filter_by(id=user_id).scalar()
        user.games.append(game)
        db_session.add(user)
        db_session.commit()
        flash('Game added to the collection!')
        return redirect(url_for('profile_', user_id=user_id))


@app.route('/users/<int:user_id>/games/<int:game_id>', methods=['DELETE'])
def profile_game_(user_id, game_id):
    """"""Delete UserGame.""""""
    try:
        user = User.query.filter_by(id=user_id).one()
        game = Game.query.filter_by(id=game_id).one()
    except sqlalchemy.orm.exc.NoResultFound:
        abort(404)
    user.games.remove(game)
    db_session.commit()
    clear_games(game)
    flash('Game removed from the collection!')
    return '', 204


@app.route('/games/<int:game_id>', methods=['GET', 'POST'])
def game_(game_id):
    """"""Return game page or Update Game.

    Use GET and POST methods respectively.
    """"""
    try:
        bgame = Game.query.filter_by(id=game_id).one()
    except sqlalchemy.orm.exc.NoResultFound:
        abort(404)
    if request.method == 'GET':
        # Return game page
        return render_template('game.html', game=bgame)
    else:
        # Update game info from bgg API
        game_info, bgg_categories = bgg_game_info(bgame.bgg_id)
        for key, value in game_info.iteritems():
            setattr(bgame, key, value)
        bgame.categories = bgg_categories
        db_session.commit()
        flash('Game info updated!')
        return redirect(url_for('game_', game_id=game_id))


@app.route('/games/search')
def game_finder():
    """"""Return game-finder page.""""""
    all_categories = GameCategory.query.all()
    games = []
    if len(request.args) > 0:
        # Build SQL query
        query = ''
        for key, value in request.args.iteritems():
            query = game_query_builder(key, value, query)
        query = query[:-5]
        print query
        # Get games satisfying the search criteria
        game_category = int(request.args['category'])
        if game_category == 0:
            games = Game.query.filter(sqlalchemy.text(query)).all()
        else:
            # Consider game category
            games = (Game.query.filter(sqlalchemy.text(query)).filter(
                Game.categories.any(GameCategory.id == game_category)).all())
    return render_template('game-finder.html', games=games,
                           all_categories=all_categories)


@app.route('/api/games')
def api_games():
    """"""Return list of games, with all their attributes, satisfying
    the criteria provided in the request query string.

    Valid query args are of two types: ownership type and game-attribute type.
    The function first builds two sets of games, ownership set with
    games satisfying the ownership criteria and game-attribute set with
    games satisfying the game-attribute criteria; an intersection of
    these two sets is then returned to the user. Specifying no criteria
    of a given type will result in the corresponding set with all
    the games in the database.

    Valid arguments are as follows:
        ownership type:
            club=1: include all games owned by the club
            user=INTEGER: include all games owned by the user,
                value denotes user id,
                multiple args=YES
        game-attribute type:
            id=INTEGER: value denotes game id,
                multiple args=YES
            name=NAME
            category=INTEGER: value denotes category id,
                multiple args=YES
            rating-min=[1-10]
            players-from=INTEGER: query must also include players-to
            players-to=INTEGER: query must also include players-from
            time-from=INTEGER
            time-to=INTEGER
            weight-min=[1-5]
            weight-max=[1-5]

    The response is in JSON.
    """"""
    if not validate_api_game_query(request.args):
        return error_response(
            'One or more query parameters have invalid key and/or value', 400)
    # Club filter
    games_club = []
    if request.args.get('club') == '1':
        games_club = db_session.query(clubs_games_assoc).all()
        games_club = [club_game.game_id for club_game in games_club]
    print 'games_club', games_club
    # User filter
    users = [int(user_id) for user_id in request.args.getlist('user')]
    games_users = db_session.query(users_games_assoc).filter(
        users_games_assoc.c.user_id.in_(users)).all()
    games_users = [game.game_id for game in games_users]
    print 'games_user', games_users
    # Game attribute filter
    query = ''
    for key, value in request.args.iteritems(multi=True):
        query = game_query_builder(key, value, query)
    query = query[:-5]
    categories = request.args.getlist('category')
    if len(categories) == 0:
        attr_games = Game.query.filter(sqlalchemy.text(query)).all()
    else:
        # Consider game categories
        attr_games = (Game.query.filter(sqlalchemy.text(query)).filter(
            Game.categories.any(GameCategory.id.in_(categories))).all())
    attr_games = [game.id for game in attr_games]
    print 'games_query', attr_games
    # Union of club and user games
    owned_games = set(games_club) | set(games_users)
    print 'union', owned_games
    # Intersection of owned_games and attr_games
    games_id = ((set(attr_games) & owned_games)
                if len(owned_games) > 0 else set(attr_games))
    print 'intersection', games_id
    # Get all games satisfying the search criteria
    games = Game.query.filter(Game.id.in_(games_id)).all()
    games_dict = sql_to_dicts(*games)
    # Add category info to each game_dict
    games_categories = {}
    for game in games:
        games_categories[game.id] = [game_category.name for game_category in
                                     game.categories]
    for game_dict in games_dict:
        game_dict['category'] = games_categories[game_dict['id']]
    return jsonify(games=games_dict)


@app.route('/api/info')
def api_info():
    """"""Return basic information on all sql entries of chosen types.

    Valid query args:
        users=1
        categories=1
        games=1

    The response is in JSON.
    """"""
    d = {
        'users': User.query.all(),
        'categories': GameCategory.query.all(),
        'games': Game.query.all()
    }
    info = {}
    for key, value in request.args.iteritems():
        if d.get(key) and value == '1':
            sql_all_dict = sql_to_dicts(*d[key])
            info[key] = dicts_purge(sql_all_dict,
                                    *['id', 'name', 'year_published'])
    return jsonify(**info)


@app.route('/gconnect', methods=['POST'])
def g_connect():
    """"""Sign in user.""""""
    # Additional csrf check
    if not request.headers.get('X-Requested-With'):
        abort(403)
    # Get one-time code from the end-user
    auth_code = request.get_json().get('auth_code')
    # Exchange one-time code for id_token and access_token
    try:
        credentials = client.credentials_from_clientsecrets_and_code(
            app.config['CLIENT_SECRET_FILE'],
            ['https://www.googleapis.com/auth/drive.appdata', 'profile',
             'email'],
            auth_code)
    except client.FlowExchangeError:
        return error_response('Failed to upgrade one-time authorization code.',
                              401)
    # Validate id_token
    if not validate_id_token(credentials.id_token, credentials.id_token_jwt):
        return error_response('id token is not valid', 500)
    # Get user info from access token
    userinfo_url = ""https://www.googleapis.com/oauth2/v1/userinfo""
    params = {'access_token': credentials.access_token, 'alt': 'json'}
    answer = requests.get(userinfo_url, params=params)
    user_data = answer.json()
    # Store user info in the session for later use
    session['email'] = credentials.id_token['email']
    session['username'] = user_data['name']
    session['access_token'] = credentials.access_token
    # If the user does not exist, add him to the database
    session['user_id'], new_user = check_user(
        session['email'], session['username'],  user_data['picture'])
    # Response
    body = {'username': user_data['name'],
            'user_id': session['user_id'],
            'new_user': new_user}
    return json_response(body, 200)


@app.route('/gdisconnect', methods=['POST'])
def g_disconnect():
    """"""Sign out user.""""""
    sign_out()
    flash('Signed out!')
    return '', 204
/n/n/n",1
156,156,460d1d24a60ff733c6b060bfe956e46cb2984111,"public_html/cgi-bin/delete.py/n/n#!/usr/bin/python3

import cgi
import mysql.connector
from html import beghtml, endhtml

# getting all the values from the form
form = cgi.FieldStorage()
enzyme_name   = form.getvalue('enzyme_name')
process_name  = form.getvalue('process_name')
enzyme_name2  = form.getvalue('enzyme_name2')
process_name2 = form.getvalue('process_name2')
enzyme_name3  = form.getvalue('enzyme_name3')
conc          = form.getvalue(""conc"")
compound      = form.getvalue(""compound"")
intermediate  = form.getvalue(""inter"")
sub           = form.getvalue(""sub"")
organelle     = form.getvalue(""organelle"")
enzyme_name3  = form.getvalue(""enzyme_name3"")
process_name3 = form.getvalue(""process_name3"")
organelle2    = form.getvalue(""organelle2"")
conc2         = form.getvalue(""conc2"")
compound2     = form.getvalue(""compound2"")

# establishing connection, cursor
cnx = mysql.connector.connect(user='eapfelba', database='eapfelba2', host='localhost', password='chumash1000')
query = """"
cursor = cnx.cursor()

# depending on the user input- assign the query
# if multiple text boxes are filled, the last row to be filled in will be executed
if enzyme_name:
    query = ""delete from converts where enzyme_name = %s"" 
    v = (enzyme_name,)
    
if enzyme_name3:
    query = ""delete from enzyme where enzyme_name = %s""
    v = (enzyme_name3,)

if process_name:
    query = ""delete from process where process_name = %s""
    v = (process_name,)
    
if process_name2 and enzyme_name2:
    query = ""delete from uses where process_name = %s and enzyme_name = %s"" 
    v = (process_name2, enzyme_name2)
    
if conc and compound:
    query = ""delete from conds where concentration = %s and compound = %s""
    v = (conc, compound)
    
if intermediate:
    query = ""delete from intermediate where intermediate_name = %s""
    v = (intermediate,)
    
if organelle and sub:
    query = ""delete from location where organelle = %s and substructure = %s""
    v = (organelle, sub)

if enzyme_name3 and organelle2:
    query = ""delete from located_in where enzyme_name = %s and organelle = %s""
    v = (enzyme_name3, organelle2)
    
if process_name3 and conc2 and compound2:
    query = ""delete from operates_uner where process_name = %s and concentration = %s and compound = %s""
    v = (process_name3, conc2, compound2)

# if empty form - give the user an option to fill in something or go back to the home page
hasError = False
if not query:
    beghtml()
    print(""<h3>You didn't fill anything out! :/</h3>"")
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/delete.html"">Back</a></b>')
    print('<br><b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Home</a></b>')
    endhtml()
    hasError = True

# checking for errors - if there is an error, show it on the screen
try:
    cursor.execute(query, v)
    cnx.commit()
    
except mysql.connector.Error as err:
    beghtml()
    print(""Something went wrong: {}"".format(err) + ""<br><br>"")
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/delete.html"">Back</a></b>')
    endhtm()
    hasError = True

# otherwise print the repsonse to the screen
if hasError == False:
    # html with the response from the delete 
    beghtml()
    print(""<h3>Deleted!</h3>"")                                      
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/cgi-bin/showdb.py"">Current Database</a></b><br><br>')
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Try Something Else!</a></b><br><br>')
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/delete.html"">Back</a></b>')
    endhtml()
    
cursor.close()
cnx.close()
/n/n/npublic_html/cgi-bin/insert.py/n/n#!/usr/bin/python3                                     
                                
import cgi
import mysql.connector
from html import beghtml, endhtml

# getting the values from the html form
form = cgi.FieldStorage()
insert_table = form.getvalue('insert_table')
values       = form.getvalue('values')

# if values were inserted, split on the comma and concatenate the right amount of %s for the prepared statement
if values:
    values = values.split(', ')
    valueQuery = ""(""
    for value in values:
        valueQuery += ""%s, ""
    valueQuery = valueQuery[:-2] + "")""

# mysql connection
cnx = mysql.connector.connect(user='eapfelba', host = 'localhost', database='eapfelba2', password='chumash1000')
query=""""  # intialized as empty to prevent errors
cursor = cnx.cursor()

# creating the query based on the user input
# the insert_table cannot be inserted using prepared statements bc of the implicitly assigned quotes- this is vulnerable to SQL injection (even though only from the drop down)
if insert_table and values:
    query = ""insert into "" + insert_table + "" values "" + valueQuery    
    v = tuple(values)  # making a tuple of the values inputed from the form to put in the execute statement
    
# checking for errors
hasError = False
if not query:  # empty form
    beghtml()
    print(""<h3>You didn't fill anything out! :/</h3>"")
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/insert.html"">Back</a></b>')
    print('<br><b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Home</a></b>')
    endhtml()
    hasError = True
    
if query:
    try: # try to execute the query, otherwise print out the issue on an html page and give the user options to go back
        cursor.execute(query, v)
        cnx.commit()   
    except mysql.connector.Error as err:
        beghtml()
        print(""Something went wrong: {}"".format(err) + ""<br><br>"")
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/insert.html"">Back</a></b>')
        endhtml()
        hasError = True

# if there is no error, print out the results!
if hasError == False:
    beghtml()
    print(""<h3>"")
    # print them out in the right format for the results page
    for s in values:
        print(""<b> | %s"" % s)
    print("" | </b></h3>"")
    print(""<h3>is now in the table %s!</h3>"" % insert_table)
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/cgi-bin/showdb.py"">Current Database</a></b><br><br>')
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Try Something Else!</a></b><br><br>')
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/insert.html"">Back</a></b>')
    endhtml()
    
cursor.close()
cnx.close()
/n/n/npublic_html/cgi-bin/select.py/n/n#!/usr/bin/python3                                                                           
import cgi
import mysql.connector
from html import beghtml, endhtml

# getting values from the form
form = cgi.FieldStorage()
search_enzyme   = form.getvalue('search_enzyme')
search_process1 = form.getvalue('search_process1')
search_process2 = form.getvalue('search_process2')
search_enzyme2  = form.getvalue(""search_enzyme2"")
search_process3 = form.getvalue(""search_process3"")
sub             = form.getvalue(""sub"")
inter           = form.getvalue(""inter"")
search_process5 = form.getvalue(""search_process5"")
search_enzyme3  = form.getvalue(""search_enzyme3"")
reac            = form.getvalue(""reac"")
search_enzyme4  = form.getvalue(""search_enzyme4"")
inter2          = form.getvalue(""inter2"")

# establishing sql connection
cnx = mysql.connector.connect(user='eapfelba', database='eapfelba2', host='localhost', password='chumash1000')
cursor = cnx.cursor()
query = """"
key = """"

# different options to select- assign query based on input
# the last text box to be filled in on the form will be executed
# the title helps with printing the result to the html
if search_enzyme:
    query = ""select process_name from uses where enzyme_name = %s""
    title = ""Processes""
    v = (search_enzyme,)
    
if search_process1:
    query = ""select enzyme_name from uses where process_name = %s""
    title = ""Enzymes""
    v = (search_process1,)
    
if search_process2:
    query = ""select distinct organelle from uses natural join located_in where process_name = %s""
    title = ""Organelles""
    v = (search_process2,)
    
if search_enzyme2:
    query = ""select ligand_mechanism from enzyme where enzyme_name = %s""
    title = ""Ligand Mechanisms""
    v = (search_enzyme2,)
    
if search_process3:
    query = ""select goal_product from process where process_name = %s""
    title = ""Goal Products""
    v = (search_process3,) 
    
if sub:
    query = ""select organelle from location where substructure = %s""
    title = ""Organelles""
    v = (sub,)
    
if inter:
    query = ""select concentration from conds where compound = %s""
    title = ""Concentrations""
    v = (inter,)

# keep track of an extra variable so that it will know to print an extra line of results (onyl query with a tuple result)
if search_process5: 
    query = ""select concentration, compound from operates_under where process_name = %s""
    title = ""Conditions""
    key = 'one'
    v = (search_process5,)
    
if search_enzyme3 and reac:
    query = ""select product_name from converts where enzyme_name = %s and reactant_name = %s""
    title = ""Products""
    v = (search_enzyme3, reac)
    
if search_enzyme4:
    query = ""select organelle from located_in where enzyme_name = %s"" 
    title = ""Organelles""
    v = (search_enzyme4,)
    
if inter2:
    query = ""select concenration from intermediate where intermediate_name = %s""
    title = ""Concentrations""
    v = (inter2,)

# avoid error with empty form- give the user option to fill in information or go back to home page
if not query:
    beghtml()
    print(""<h3>You didn't fill anything out! :/</h3>"")
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/select.html"">Back</a></b>')
    print('<br><b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Home</a></b>')
    endhtml()
    
# catching errors- blank form, wrong syntax, etc
# try executing query and spit back error to the screen if there is a problem
hasError = False
if query:
    try:
        cursor.execute(query, v)        
    except mysql.connector.Error as err:
        print(""<b>Something went wrong:</b> {}"".format(err) + ""<br><br>"")
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/select.html"">Back</a></b>')
        endhtml()
        hasError = True

# otherwise, print out the response with links back and to home
if hasError == False:
    response = cursor.fetchall()
    beghtml()
    if not response:                                                                                     
        print(""<h3>no results found</h3>"")
    else:
        print(""<h3>Results!</h3>"")
        print(""<h3>%s</h3>"" % title) 
        for r in response:
            print(""<b> %s"" % r[0])
            if key:  # if there was a second value of the data like (concentration, compound)
                print(""%s</br>"" % r[1])
            print(""<br>"")
    print(""</b><br>"")
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Try Something Else!</a></b><br><br>')
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/select.html"">Back</a></b><br><br>')
    endhtml()

cursor.close()
cnx.close()
/n/n/npublic_html/cgi-bin/update.py/n/n#! /usr/bin/python3

import cgi
import mysql.connector
from html import beghtml, endhtml

# getting all the values from the html form
form = cgi.FieldStorage()
enzyme_name    = form.getvalue('enzyme_name')
product_name   = form.getvalue('product_name')
enzyme_name2   = form.getvalue('enzyme_name2')
mechanism_name = form.getvalue('mechanism_name')
process_name   = form.getvalue('process_name')
concentration  = form.getvalue('concentration')
compound_name  = form.getvalue('compound_name')
process_name2  = form.getvalue('process_name2')
goal           = form.getvalue('goal')
inter          = form.getvalue('inter')
conc           = form.getvalue('conc')
process_name3  = form.getvalue('process_name3')
enzyme_name3   = form.getvalue('enzyme_name3')
enzyme_name4   = form.getvalue('enzyme_name4')
organelle      = form.getvalue('organelle')
sub            = form.getvalue('sub')
organelle2     = form.getvalue('organelle2')
sub2           = form.getvalue('sub2')
conc2          = form.getvalue('conc2')
comp           = form.getvalue('comp')
loc            = form.getvalue('loc')
sub3           = form.getvalue('sub3')
sub4           = form.getvalue('sub4')

# establishing connection to the database
cnx = mysql.connector.connect(user='eapfelba', database='eapfelba2', host='localhost', password='chumash1000')
cursor = cnx.cursor(buffered=True)
query = """"  # initializing empty queries to avoid errors
query2 = """"

# depending on the user input assign the query
# the second query searches for the updated data in the database and shows the user what they inputed
# if multiple are filled in, the last one will be executed
if enzyme_name and product_name:
    query = ""update converts set product_name = %s where enzyme_name = %s""
    v1 = (product_name, enzyme_name)
    query2 = ""select * from converts where product_name = %s and enzyme_name = %s""
    v2 = (product_name, enzyme_name)
    
if enzyme_name2 and mechanism_name:
    query = ""update enzyme set ligand_mechanism = %s where enzyme_name = %s""
    v1 = (mechanism_name, enzyme_name2)
    query2 = ""select * from enzyme where enzyme_name = %s""
    v2 = (enzyme_name2,)
    
if process_name and concentration and compound_name:
    query = ""update operates_under set concentration = %s, compound = %s where process_name = %s""
    v1 = (concentration, compound_name, process_name)
    query2 = ""select * from operates_under where process_name = %s""
    v2 = (process_name,)
    
if process_name2 and goal:
    query = ""update process set goal_product = %s where process_name = %s""
    v1 = (goal, process_name2)
    query2 = ""select * from process where process_name = %s""
    v2 = (process_name2,)

if inter and conc:
    query = ""update intermediate set concenration = %s where intermediate_name = %s"" 
    v1 = (conc, inter)
    query2 = ""select * from intermediate where intermediate_name = %s"" 
    v2 = (inter,)
    
if process_name3 and enzyme_name3:
    query = ""update uses set enzyme_name = %s where process_name = %s""
    v1 = (enzyme_name3, process_name3)
    query2 = ""select * from uses where process_name = %s and enzyme_name = %s""
    v2 = (process_name3, enzyme_name3)
    
if enzyme_name4 and organelle and sub and sub4:
    query = ""update located_in set organelle = %s, substructure = %s where enzyme_name = %s and substructure = %s"" 
    v1 = (organelle, sub, enzyme_name4, sub4)
    query2 = ""select * from located_in where enzyme_name = %s""
    v2 = (enzyme_name4,)
    
if organelle2 and sub2:
    query = ""update location set substructure = %s where organelle = %s and substructure = %s""
    v1 = (sub2, organelle2, sub3)
    query2 = ""select * from location where organelle = %s and substructure = %s"" 
    v2 = (sub2, organelle2, sub3)
    
if conc2 and comp and loc:
    query = ""update conds set prime_location = %s where concentration = %s and compound = %s""
    v1 = (loc, conc2, comp)
    query2 = ""select * from conds where concentration = %s and compound = %s and prime_location = %s""
    v2 = (conc2, comp, loc)

hasError = False
if not query: # blank form - give the user option to go back or to the home page
    beghtml()
    print(""<h3>You didn't fill anything out! :/</h3>"")
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/update.html"">Back</a></b>')
    print('<br><b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Home</a></b>')
    endhtml()
    hasError = True

if query: # errors
    try:
        cursor.execute(query, v1)
        cnx.commit()

    except mysql.connector.Error as err:
        beghtml()
        print(""Something went wrong: {}"".format(err) + ""<br><br>"")
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/update.html"">Back</a></b>')
        print('<br><b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Home</a></b>')
        endhtml()
        hasError = True
        
# if there were no errors when executing the first query, continue executing the second
if hasError == False:
    cursor.execute(query2, v2)
    data = cursor.fetchall()
    
    # html with the response from the update           
    beghtml()
    
    # if the first query did not come up with an error but the second did (typo, value not in the table)
    # i.e. the select statement came up with nothing..
    # print that something went wrong and give an option to go back
    if not data:
        print(""<h3><b>Something went wrong </b></h3>"")
        print(""<b>Check your spelling!</b><br><br>"")
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/update.html"">Back</a></b>')
        print('<br><b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Home</a></b>')
    # otherwise, you want to print out what the database not reads
    else:
        print(""<h3>Updated!</h3>"")
        print(""The database now reads <br><br>"")
        for result in data[0]:
            print(""<b> | %s"" % result)
        print("" | </b>"")
        print(""<br><br>"")
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/cgi-bin/showdb.py"">Current Database</a></b><br><br>')
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Try Something Else!</a></b><br><br>')
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/update.html"">Back</a></b>')
    endhtml()


cursor.close()
cnx.close()
/n/n/n",0
157,157,460d1d24a60ff733c6b060bfe956e46cb2984111,"/public_html/cgi-bin/delete.py/n/n#!/usr/bin/python3

import cgi
import mysql.connector
from html import beghtml, endhtml

# getting all the values from the form
form = cgi.FieldStorage()
enzyme_name   = form.getvalue('enzyme_name')
process_name  = form.getvalue('process_name')
enzyme_name2  = form.getvalue('enzyme_name2')
process_name2 = form.getvalue('process_name2')
enzyme_name3  = form.getvalue('enzyme_name3')
conc          = form.getvalue(""conc"")
compound      = form.getvalue(""compound"")
intermediate  = form.getvalue(""inter"")
sub           = form.getvalue(""sub"")
organelle     = form.getvalue(""organelle"")
enzyme_name3  = form.getvalue(""enzyme_name3"")
process_name3 = form.getvalue(""process_name3"")
organelle2    = form.getvalue(""organelle2"")
conc2         = form.getvalue(""conc2"")
compound2     = form.getvalue(""compound2"")

# establishing connection, cursor
cnx = mysql.connector.connect(user='eapfelba', database='eapfelba2', host='localhost', password='chumash1000')
query = """"
cursor = cnx.cursor()

# depending on the user input- assign the query
# if multiple text boxes are filled, the last row to be filled in will be executed
if enzyme_name:
    query = ""delete from converts where enzyme_name = '%s'"" % enzyme_name

if enzyme_name3:
    query = ""delete from enzyme where enzyme_name = '%s'"" % enzyme_name3
    
if process_name:
    query = ""delete from process where process_name = '%s'"" % process_name

if process_name2 and enzyme_name2:
    query = ""delete from uses where process_name = '%s' and enzyme_name = '%s'"" % (process_name2, enzyme_name2)

if conc and compound:
    query = ""delete from conds where concentration = '%s' and compound = '%s'"" % (conc, compound)

if intermediate:
    query = ""delete from intermediate where intermediate_name = '%s'"" % intermediate

if organelle and sub:
    query = ""delete from location where organelle = '%s' and substructure = '%s'"" % (organelle, sub)

if enzyme_name3 and organelle2:
    query = ""delete from located_in where enzyme_name = '%s' and organelle = '%s'"" % (enzyme_name3, organelle2)

if process_name3 and conc2 and compound2:
    query = ""delete from operates_uner where process_name = '%s' and concentration = '%s' and compound = '%s'"" % (process_name3, conc2, compound2)


# if empty form - give the user an option to fill in something or go back to the home page
hasError = False
if not query:
    beghtml()
    print(""<h3>You didn't fill anything out! :/</h3>"")
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/delete.html"">Back</a></b>')
    print('<br><b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Home</a></b>')
    endhtml()
    hasError = True

# checking for errors - if there is an error, show it on the screen
try:
    cursor.execute(query)
    cnx.commit()
    
except mysql.connector.Error as err:
    beghtml()
    print(""Something went wrong: {}"".format(err) + ""<br><br>"")
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/delete.html"">Back</a></b>')
    endhtm()
    hasError = True

# otherwise print the repsonse to the screen
if hasError == False:
    # html with the response from the delete 
    beghtml()
    print(""<h3>Deleted!</h3>"")                                      
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/cgi-bin/showdb.py"">Current Database</a></b><br><br>')
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Try Something Else!</a></b><br><br>')
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/delete.html"">Back</a></b>')
    endhtml()
    
cursor.close()
cnx.close()
/n/n/n/public_html/cgi-bin/insert.py/n/n#!/usr/bin/python3                                     
                                
import cgi
import mysql.connector
from html import beghtml, endhtml

# getting the values from the html form
form = cgi.FieldStorage()
insert_table = form.getvalue('insert_table')
values       = form.getvalue('values')


if values:   # make sure not empty to split and then split on the comma
    values = values.split(', ')

svalues = """"
if values:
    for value in values:
        # concatenate them into the appropriate syntax, removing any unnecessary whitespace
        svalues += ""'%s', "" % value.strip()
    svalues = svalues[:-2]

# mysql connection
cnx = mysql.connector.connect(user='eapfelba', host = 'localhost', database='eapfelba2', password='chumash1000')
query=""""  # intialized as empty to prevent errors
cursor = cnx.cursor()

# creating the query based on the user input
if insert_table and values:
    query = ""insert into %s values (%s)"" % (insert_table, svalues)

# checking for errors
hasError = False
if not query:  # empty form
    beghtml()
    print(""<h3>You didn't fill anything out! :/</h3>"")
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/insert.html"">Back</a></b>')
    print('<br><b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Home</a></b>')
    endhtml()
    hasError = True
    
if query:
    try: # try to execute the query, otherwise print out the issue on an html page and give the user options to go back
        cursor.execute(query)
        cnx.commit()   
    except mysql.connector.Error as err:
        beghtml()
        print(""Something went wrong: {}"".format(err) + ""<br><br>"")
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/insert.html"">Back</a></b>')
        endhtml()
        hasError = True

# if there is no error, print out the results!
if hasError == False:
    beghtml()
    print(""<h3>"")
    # print them out in the right format for the results page
    temps = svalues.split("", "")
    for s in temps:
        print(""<b> | %s"" % s[1:-1])
    print("" | </b></h3>"")
    print(""<h3>is now in the table %s!</h3>"" % insert_table)
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/cgi-bin/showdb.py"">Current Database</a></b><br><br>')
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Try Something Else!</a></b><br><br>')
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/insert.html"">Back</a></b>')
    endhtml()
    
cursor.close()
cnx.close()
/n/n/n/public_html/cgi-bin/select.py/n/n#!/usr/bin/python3                                                                           
import cgi
import mysql.connector
from html import beghtml, endhtml

# getting values from the form
form = cgi.FieldStorage()
search_enzyme   = form.getvalue('search_enzyme')
search_process1 = form.getvalue('search_process1')
search_process2 = form.getvalue('search_process2')
search_enzyme2  = form.getvalue(""search_enzyme2"")
search_process3 = form.getvalue(""search_process3"")
sub             = form.getvalue(""sub"")
inter           = form.getvalue(""inter"")
search_process5 = form.getvalue(""search_process5"")
search_enzyme3  = form.getvalue(""search_enzyme3"")
reac            = form.getvalue(""reac"")
search_enzyme4  = form.getvalue(""search_enzyme4"")
inter2          = form.getvalue(""inter2"")

# establishing sql connection
cnx = mysql.connector.connect(user='eapfelba', database='eapfelba2', host='localhost', password='chumash1000')
cursor = cnx.cursor()
query = """"
key = """"

# different options to select- assign query based on input
# the last text box to be filled in on the form will be executed
# the title helps with printing the result to the html
if search_enzyme:
    query = ""select process_name from uses where enzyme_name = '%s'""  % search_enzyme
    title = ""Processes""
    
if search_process1:
    query = ""select enzyme_name from uses where process_name = '%s'"" % search_process1
    title = ""Enzymes""
    
if search_process2:
    query = ""select distinct organelle from uses natural join located_in where process_name = '%s'"" % search_process2
    title = ""Organelles""
    
if search_enzyme2:
    query = ""select ligand_mechanism from enzyme where enzyme_name = '%s'"" % search_enzyme2
    title = ""Ligand Mechanisms""
    
if search_process3:
    query = ""select goal_product from process where process_name = '%s'"" % search_process3
    title = ""Goal Products""
    
if sub:
    query = ""select organelle from location where substructure = '%s'"" % sub
    title = ""Organelles""
    
if inter:
    query = ""select concentration from conds where compound = '%s'"" % inter
    title = ""Concentrations""

# keep track of an extra variable so that it will know to print an extra line of results (onyl query with a tuple result)
if search_process5: 
    query = ""select concentration, compound from operates_under where process_name = '%s'"" % search_process5
    title = ""Conditions""
    key = 'one'
    
if search_enzyme3 and reac:
    query = ""select product_name from converts where enzyme_name = '%s' and reactant_name = '%s'"" % (search_enzyme3, reac)
    title = ""Products""
    
if search_enzyme4:
    query = ""select organelle from located_in where enzyme_name = '%s'"" % search_enzyme4
    title = ""Organelles""
    
if inter2:
    query = ""select concenration from intermediate where intermediate_name = '%s'"" % inter2
    title = ""Concentrations""

# avoid error with empty form- give the user option to fill in information or go back to home page
if not query:
    beghtml()
    print(""<h3>You didn't fill anything out! :/</h3>"")
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/select.html"">Back</a></b>')
    print('<br><b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Home</a></b>')
    endhtml()
    
# catching errors- blank form, wrong syntax, etc
# try executing query and spit back error to the screen if there is a problem
hasError = False
if query:
    try:
        cursor.execute(query)        
    except mysql.connector.Error as err:
        print(""<b>Something went wrong:</b> {}"".format(err) + ""<br><br>"")
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/select.html"">Back</a></b>')
        endhtml()
        hasError = True

# otherwise, print out the response with links back and to home
if hasError == False:
    response = cursor.fetchall()
    beghtml()
    if not response:                                                                                     
        print(""<h3>no results found</h3>"")
    else:
        print(""<h3>Results!</h3>"")
        print(""<h3>%s</h3>"" % title) 
        for r in response:
            print(""<b> %s"" % r[0])
            if key:  # if there was a second value of the data like (concentration, compound)
                print(""%s</br>"" % r[1])
            print(""<br>"")
    print(""</b><br>"")
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Try Something Else!</a></b><br><br>')
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/select.html"">Back</a></b><br><br>')
    endhtml()

cursor.close()
cnx.close()
/n/n/n/public_html/cgi-bin/update.py/n/n#! /usr/bin/python3

import cgi
import mysql.connector
from html import beghtml, endhtml

# getting all the values from the html form
form = cgi.FieldStorage()
enzyme_name    = form.getvalue('enzyme_name')
product_name   = form.getvalue('product_name')
enzyme_name2   = form.getvalue('enzyme_name2')
mechanism_name = form.getvalue('mechanism_name')
process_name   = form.getvalue('process_name')
concentration  = form.getvalue('concentration')
compound_name  = form.getvalue('compound_name')
process_name2  = form.getvalue('process_name2')
goal           = form.getvalue('goal')
inter          = form.getvalue('inter')
conc           = form.getvalue('conc')
process_name3  = form.getvalue('process_name3')
enzyme_name3   = form.getvalue('enzyme_name3')
enzyme_name4   = form.getvalue('enzyme_name4')
organelle      = form.getvalue('organelle')
sub            = form.getvalue('sub')
organelle2     = form.getvalue('organelle2')
sub2           = form.getvalue('sub2')
conc2          = form.getvalue('conc2')
comp           = form.getvalue('comp')
loc            = form.getvalue('loc')
sub3           = form.getvalue('sub3')
sub4           = form.getvalue('sub4')

# establishing connection to the database
cnx = mysql.connector.connect(user='eapfelba', database='eapfelba2', host='localhost', password='chumash1000')
cursor = cnx.cursor(buffered=True)
query = """"  # initializing empty queries to avoid errors
query2 = """"

# depending on the user input assign the query
# the second query searches for the updated data in the database and shows the user what they inputed
# if multiple are filled in, the last one will be executed
if enzyme_name and product_name:
    query = ""update converts set product_name = '%s' where enzyme_name = '%s'"" % (product_name, enzyme_name)
    query2 = ""select * from converts where product_name = '%s' and enzyme_name = '%s'"" % (product_name, enzyme_name)
    
if enzyme_name2 and mechanism_name:
    query = ""update enzyme set ligand_mechanism = '%s' where enzyme_name = '%s'"" % (mechanism_name, enzyme_name2)
    query2 = ""select * from enzyme where enzyme_name = '%s'"" % enzyme_name2
    
if process_name and concentration and compound_name:
    query = ""update operates_under set concentration = '%s', compound = '%s' where process_name = '%s'"" % (concentration, compound_name, process_name)
    query2 = ""select * from operates_under where process_name = '%s'"" % process_name

if process_name2 and goal:
    query = ""update process set goal_product = '%s' where process_name = '%s'"" % (goal, process_name2)
    query2 = ""select * from process where process_name = '%s'"" % process_name2

if inter and conc:
    query = ""update intermediate set concenration = '%s' where intermediate_name = '%s'"" % (conc, inter)
    query2 = ""select * from intermediate where intermediate_name = '%s'"" % inter

if process_name3 and enzyme_name3:
    query = ""update uses set enzyme_name = '%s' where process_name = '%s'"" % (enzyme_name3, process_name3)
    query2 = ""select * from uses where process_name = '%s' and enzyme_name = '%s'"" % (process_name3, enzyme_name3)

if enzyme_name4 and organelle and sub and sub4:
    query = ""update located_in set organelle = '%s', substructure = '%s' where enzyme_name = '%s' and substructure = '%s'"" % (organelle, sub, enzyme_name4, sub4)
    query2 = ""select * from located_in where enzyme_name = '%s'"" % enzyme_name4
    
if organelle2 and sub2:
    query = ""update location set substructure = '%s' where organelle = '%s' and substructure = '%s'"" % (sub2, organelle2, sub3)
    query2 = ""select * from location where organelle = '%s' and substructure = '%s'"" % (organelle2, sub2)

if conc2 and comp and loc:
    query = ""update conds set prime_location = '%s' where concentration = '%s' and compound = '%s'"" % (loc, conc2, comp)
    query2 = ""select * from conds where concentration = '%s' and compound = '%s' and prime_location = '%s'"" % (conc2, comp, loc)


hasError = False
if not query: # blank form - give the user option to go back or to the home page
    beghtml()
    print(""<h3>You didn't fill anything out! :/</h3>"")
    print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/update.html"">Back</a></b>')
    print('<br><b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Home</a></b>')
    endhtml()
    hasError = True

if query: # errors
    try:
        cursor.execute(query)
        cnx.commit()

    except mysql.connector.Error as err:
        beghtml()
        print(""Something went wrong: {}"".format(err) + ""<br><br>"")
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/update.html"">Back</a></b>')
        print('<br><b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Home</a></b>')
        endhtml()
        hasError = True
        
# if there were no errors when executing the first query, continue executing the second
if hasError == False:
    cursor.execute(query2)
    data = cursor.fetchall()
    
    # html with the response from the update           
    beghtml()
    
    # if the first query did not come up with an error but the second did (typo, value not in the table)
    # i.e. the select statement came up with nothing..
    # print that something went wrong and give an option to go back
    if not data:
        print(""<h3><b>Something went wrong </b></h3>"")
        print(""<b>Check your spelling!</b><br><br>"")
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/update.html"">Back</a></b>')
        print('<br><b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Home</a></b>')
    # otherwise, you want to print out what the database not reads
    else:
        print(""<h3>Updated!</h3>"")
        print(""The database now reads <br><br>"")
        for result in data[0]:
            print(""<b> | %s"" % result)
        print("" | </b>"")
        print(""<br><br>"")
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/cgi-bin/showdb.py"">Current Database</a></b><br><br>')
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/biobase.html"">Try Something Else!</a></b><br><br>')
        print('<b><a href = ""http://ada.sterncs.net/~eapfelbaum/update.html"">Back</a></b>')
    endhtml()


cursor.close()
cnx.close()
/n/n/n",1
94,94,dbe43f01fe4b4c170486b723de2ec61736ba02c8,"dbhelper.py/n/nimport pymysql
import dbconfig

class DBHelper:

	def connect(self, datbase=""crimemap""):
		return pymysql.connect(host='localhost',
							user=dbconfig.db_user,
							passwd=dbconfig.db_password,
							db=datbase)

	def get_all_inputs(self):
		connection = self.connect()
		try:
			query = ""SELECT description FROM crimes;""
			with connection.cursor() as cursor:
				cursor.execute(query)
			return cursor.fetchall()
		finally:
			connection.close()

	def add_input(self, data):
		connection = self.connect()
		try:
			query = ""INSERT INTO crimes (description) VALUES (%s);""
			with connection.cursor() as cursor:
				cursor.execute(query, data)
				connection.commit()
		finally:
			connection.close()

	def clear_all(self):
		connection = self.connect()
		try:
			query = ""DELETE FROM crimes;""
			with connection.cursor() as cursor:
				cursor.execute(query)
				connection.commit()
		finally:
			connection.close()
/n/n/n",0
95,95,dbe43f01fe4b4c170486b723de2ec61736ba02c8,"/dbhelper.py/n/nimport pymysql
import dbconfig

class DBHelper:

	def connect(self, datbase=""crimemap""):
		return pymysql.connect(host='localhost',
							user=dbconfig.db_user,
							passwd=dbconfig.db_password,
							db=datbase)

	def get_all_inputs(self):
	connection = self.connect()
		try:
			query = ""SELECT description FROM crimes;""
			with connection.cursor() as cursor:
				cursor.execute(query)
			return cursor.fetchall()
		finally:
			connection.close()

	def add_input(self, data):
		connection = self.connect()
		try:
			query = ""INSERT INTO crimes (description) VALUES ('{}');"".format(data) #i didn't understand this '.format(data)'
			with connection.cursor() as cursor:
				cursor.execute(query)
				connection.commit()
		finally:
			connection.close()

	def clear_all(self):
		connection.connect(self):
		try:
			query = ""DELETE FROM crimes;""
			with connection.cursor() as cursor:
				cursor.execute(query)
				connection.commit()
		finally:
			connection.close()
/n/n/n",1
40,40,b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c,"addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _

class pos_close_statement(osv.osv_memory):
    _name = 'pos.close.statement'
    _description = 'Close Statements'

    def close_statement(self, cr, uid, ids, context):
        """"""
             Close the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Dictionary
        """"""
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        statement_obj = self.pool.get('account.bank.statement')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if not ids:
                raise osv.except_osv(_('Message'), _('Journals are already closed'))
            else:
                list_statement.append(ids[0])
                if not journal.check_dtls:
                    statement_obj.button_confirm_cash(cr, uid, ids, context)

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id
        return {
                'domain': ""[('id','in',"" + str(list_statement) + "")]"",
                'name': 'Close Statements',
                'view_type': 'form',
                'view_mode': 'tree,form',
                'res_model': 'account.bank.statement',
                'views': [(id2, 'tree'),(id3, 'form')],
                'type': 'ir.actions.act_window'}

pos_close_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/naddons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _
import time

class pos_open_statement(osv.osv_memory):
    _name = 'pos.open.statement'
    _description = 'Open Statements'

    def open_statement(self, cr, uid, ids, context):
        """"""
             Open the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Directory
        """"""
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        statement_obj = self.pool.get('account.bank.statement')
        sequence_obj = self.pool.get('ir.sequence')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if len(ids):
                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for ""%s"". \n Please close the cashbox related to. ' %(journal.name)))
            
            number = ''
            if journal.sequence_id:
                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)
            else:
                number = sequence_obj.get(cr, uid, 'account.bank.statement')
            
            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,
                                                          'company_id': company_id,
                                                          'user_id': uid,
                                                          'state': 'open',
                                                          'name': number,
                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),
                                                      })
            statement_obj.button_open(cr, uid, [statement_id], context)

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id

        return {
            'domain': ""[('state','=','open')]"",
            'name': 'Open Statement',
            'view_type': 'form',
            'view_mode': 'tree,form',
            'res_model': 'account.bank.statement',
            'views': [(id2, 'tree'),(id3, 'form')],
            'type': 'ir.actions.act_window'
}
pos_open_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n",0
41,41,b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c,"/addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _

class pos_close_statement(osv.osv_memory):
    _name = 'pos.close.statement'
    _description = 'Close Statements'

    def close_statement(self, cr, uid, ids, context):
        """"""
             Close the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Dictionary
        """"""
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        statement_obj = self.pool.get('account.bank.statement')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        cr.execute("""""" select id from account_journal
                            where auto_cash='True' and type='cash'
                            and id in (%s)"""""" %(','.join(map(lambda x: ""'"" + str(x) + ""'"", j_ids))))
        journal_ids = map(lambda x1: x1[0], cr.fetchall())

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if not ids:
                raise osv.except_osv(_('Message'), _('Journals are already closed'))
            else:
                list_statement.append(ids[0])
                if not journal.check_dtls:
                    statement_obj.button_confirm_cash(cr, uid, ids, context)
    #        if not list_statement:
    #            return {}
    #        model_data_ids = mod_obj.search(cr, uid,[('model','=','ir.ui.view'),('name','=','view_bank_statement_tree')], context=context)
    #        resource_id = mod_obj.read(cr, uid, model_data_ids, fields=['res_id'], context=context)[0]['res_id']

        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id
        return {
                'domain': ""[('id','in',"" + str(list_statement) + "")]"",
                'name': 'Close Statements',
                'view_type': 'form',
                'view_mode': 'tree,form',
                'res_model': 'account.bank.statement',
                'views': [(id2, 'tree'),(id3, 'form')],
                'type': 'ir.actions.act_window'}

pos_close_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n/addons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-
##############################################################################
#
#    OpenERP, Open Source Management Solution
#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################

from osv import osv
from tools.translate import _
import time

class pos_open_statement(osv.osv_memory):
    _name = 'pos.open.statement'
    _description = 'Open Statements'

    def open_statement(self, cr, uid, ids, context):
        """"""
             Open the statements
             @param self: The object pointer.
             @param cr: A database cursor
             @param uid: ID of the user currently logged in
             @param context: A standard dictionary
             @return : Blank Directory
        """"""
        list_statement = []
        mod_obj = self.pool.get('ir.model.data')
        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id
        statement_obj = self.pool.get('account.bank.statement')
        sequence_obj = self.pool.get('ir.sequence')
        journal_obj = self.pool.get('account.journal')
        cr.execute(""""""select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id""""""%(uid))
        j_ids = map(lambda x1: x1[0], cr.fetchall())
        cr.execute("""""" select id from account_journal
                            where auto_cash='True' and type='cash'
                            and id in (%s)"""""" %(','.join(map(lambda x: ""'"" + str(x) + ""'"", j_ids))))
        journal_ids = map(lambda x1: x1[0], cr.fetchall())

        for journal in journal_obj.browse(cr, uid, journal_ids):
            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])
            if len(ids):
                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for ""%s"". \n Please close the cashbox related to. ' %(journal.name)))
            
#            cr.execute("""""" Select id from account_bank_statement
#                                    where journal_id =%d
#                                    and company_id =%d
#                                    order by id desc limit 1"""""" %(journal.id, company_id))
#            st_id = cr.fetchone()
            
            number = ''
            if journal.sequence_id:
                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)
            else:
                number = sequence_obj.get(cr, uid, 'account.bank.statement')
            
            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,
                                                          'company_id': company_id,
                                                          'user_id': uid,
                                                          'state': 'open',
                                                          'name': number,
                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),
                                                      })
            statement_obj.button_open(cr, uid, [statement_id], context)

    #            period = statement_obj._get_period(cr, uid, context) or None
    #            cr.execute(""INSERT INTO account_bank_statement(journal_id,company_id,user_id,state,name, period_id,date) VALUES(%d,%d,%d,'open','%s',%d,'%s')""%(journal.id, company_id, uid, number, period, time.strftime('%Y-%m-%d %H:%M:%S')))
    #            cr.commit()
    #            cr.execute(""select id from account_bank_statement where journal_id=%d and company_id=%d and user_id=%d and state='open' and name='%s'""%(journal.id, company_id, uid, number))
    #            statement_id = cr.fetchone()[0]
    #            print ""statement_id"",statement_id
    #            if st_id:
    #                statemt_id = statement_obj.browse(cr, uid, st_id[0])
    #                list_statement.append(statemt_id.id)
    #                if statemt_id and statemt_id.ending_details_ids:
    #                    statement_obj.write(cr, uid, [statement_id], {
    #                        'balance_start': statemt_id.balance_end,
    #                        'state': 'open',
    #                    })
    #                    if statemt_id.ending_details_ids:
    #                        for i in statemt_id.ending_details_ids:
    #                            c = statement_obj.create(cr, uid, {
    #                                'pieces': i.pieces,
    #                                'number': i.number,
    #                                'starting_id': statement_id,
    #                            })
        data_obj = self.pool.get('ir.model.data')
        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')
        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')
        if id2:
            id2 = data_obj.browse(cr, uid, id2, context=context).res_id
        if id3:
            id3 = data_obj.browse(cr, uid, id3, context=context).res_id

        return {
#           'domain': ""[('id','in', [""+','.join(map(str,list_statement))+""])]"",
            'domain': ""[('state','=','open')]"",
            'name': 'Open Statement',
            'view_type': 'form',
            'view_mode': 'tree,form',
            'res_model': 'account.bank.statement',
            'views': [(id2, 'tree'),(id3, 'form')],
            'type': 'ir.actions.act_window'
}
pos_open_statement()

# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:
/n/n/n",1
168,168,5ea8146ab38da79bad4daefdd0be9bb244dfff41,"crapo_tests/models/crm_stage.py/n/n""""""
©2019
License: AGPL-3

@author: C. Guychard (Article 714)

""""""

import logging

from odoo import models, api
from psycopg2.sql import Identifier, SQL
from odoo.addons.base_crapo_workflow.mixins import (
    crapo_automata_mixins,
)  # pylint: disable=odoo-addons-relative-import


class CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):
    _inherit = ""crm.stage""
    _state_for_model = ""crm.lead""

    def write(self, values):
        if len(self) == 1:
            if ""crapo_state"" not in values and not self.crapo_state:
                if ""name"" in values:
                    vals = {""name"": values[""name""]}
                else:
                    vals = {""name"": self.name}
                mystate = self._compute_related_state(vals)
                values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).write(values)

    @api.model
    def create(self, values):
        """""" Create a new crapo_stage for each crm_stage
        """"""
        if ""crapo_state"" not in values and not self.crapo_state:
            if ""name"" in values:
                vals = {""name"": values[""name""]}
            mystate = self._compute_related_state(vals)
            values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).create(values)

    @api.model_cr_context
    def _init_column(self, column_name):
        """""" Initialize the value of the given column for existing rows.
            Overridden here because we need to wrap existing stages in
            a new crapo_state for each stage (including a default automaton)
        """"""
        if column_name not in [""crapo_state""]:
            return super(CrmStageWithMixin, self)._init_column(column_name)
        else:
            default_compute = self._compute_related_state

            tname = Identifier(self._table.replace('""', """"))
            cname = Identifier(column_name.replace('""', """"))

            query = SQL(  # pylint: disable=sql-injection
                ""SELECT id, name FROM {} WHERE {} is NULL""
            ).format(tname, cname)

            self.env.cr.execute(query)
            stages = self.env.cr.fetchall()

            for stage in stages:
                query = SQL(  # pylint: disable=sql-injection
                    ""UPDATE {} SET {}=%s WHERE id = %s""
                ).format(tname, cname)

                default_value = default_compute(values={""name"": stage[1]})
                self.env.cr.execute(query, (default_value.id, stage[0]))
        return True
/n/n/n",0
169,169,5ea8146ab38da79bad4daefdd0be9bb244dfff41,"/crapo_tests/models/crm_stage.py/n/n""""""
©2019
License: AGPL-3

@author: C. Guychard (Article 714)

""""""

import logging

from odoo import models, api
from psycopg2.sql import Identifier
from odoo.addons.base_crapo_workflow.mixins import (
    crapo_automata_mixins,
)  # pylint: disable=odoo-addons-relative-import


class CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):
    _inherit = ""crm.stage""
    _state_for_model = ""crm.lead""

    def write(self, values):
        if len(self) == 1:
            if ""crapo_state"" not in values and not self.crapo_state:
                if ""name"" in values:
                    vals = {""name"": values[""name""]}
                else:
                    vals = {""name"": self.name}
                mystate = self._compute_related_state(vals)
                values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).write(values)

    @api.model
    def create(self, values):
        """""" Create a new crapo_stage for each crm_stage
        """"""
        if ""crapo_state"" not in values and not self.crapo_state:
            if ""name"" in values:
                vals = {""name"": values[""name""]}
            mystate = self._compute_related_state(vals)
            values[""crapo_state""] = mystate.id

        return super(CrmStageWithMixin, self).create(values)

    @api.model_cr_context
    def _init_column(self, column_name):
        """""" Initialize the value of the given column for existing rows.
            Overridden here because we need to wrap existing stages in
            a new crapo_state for each stage (including a default automaton)
        """"""
        if column_name not in [""crapo_state""]:
            return super(CrmStageWithMixin, self)._init_column(column_name)
        else:
            default_compute = self._compute_related_state

            tname = Identifier(self._table.replace('""', """")).as_string(
                self.env.cr._obj  # pylint: disable=protected-access
            )
            cname = Identifier(column_name.replace('""', """")).as_string(
                self.env.cr._obj  # pylint: disable=protected-access
            )

            logging.error(
                ""MMMMMAIS %s ==> %s (%s) -> %s"",
                self._table,
                tname,
                type(tname),
                str(tname),
            )

            self.env.cr.execute(
                ""SELECT id, name FROM %s WHERE %s is NULL"",
                (self._table, cname),
            )
            stages = self.env.cr.fetchall()

            for stage in stages:
                default_value = default_compute(values={""name"": stage[1]})
                self.env.cr.execute(
                    ""UPDATE %s SET %s=%s WHERE id = %s"",
                    (self._table, cname, default_value.id, stage[0]),
                )
        return True
/n/n/n",1
108,108,3f5079f53d8f259474885ff078bf96fdc08e02bd,"get_historical_data.py/n/n# LOAD LIBRARIES & FILES

# load libraries
from binance.client import Client
import configparser
import sqlite3


# load functions
def getlist(option, sep=',', chars=None):
    """"""Return a list from a ConfigParser option. By default,
       split on a comma and strip whitespaces.""""""
    return [ chunk.strip(chars) for chunk in option.split(sep) ]


# READ FILES

# read credentials
configParser = configparser.ConfigParser()
configParser.read(r'credentials/API-key')

api_key = configParser.get('credentials', 'api_key')
api_sec = configParser.get('credentials', 'api_secret')


# read config
configParser.read(r'config.txt')

db_path = configParser.get('config', 'db_path')
verbose = configParser.get('config', 'verbose')
symbols = getlist(configParser.get('symbols', 'symbol_list'))
intervals = getlist(configParser.get('intervals', 'interval_list'))
time_start = configParser.get('time', 'time_start')
time_end = configParser.get('time', 'time_end')


# create timestamps for beginning and now
if time_start == 'beginning':
    time_start = 'January 1, 2000'


# SET UP DATABASE CONNECTION AND BINANCE CLIENT

# connect to database
db_con = sqlite3.connect(db_path)

# cet up binance client
client = Client(api_key, api_sec)


# GET DATA FOR ALL SYMBOLS AND INTERVALS

# Loop over every symbol and every interval. Download historical data for each combination from binance.com which is not
# already in the database and write it to the database
for symbol in symbols:
    for interval in intervals:

        # check if table already exists
        with db_con:
            cur = db_con.cursor()
            cur.execute(""SELECT name FROM sqlite_master WHERE type='table' AND name='{}_{}'"".format(symbol, interval))
            if cur.fetchone() is None:
                table_exists = False
            else:
                table_exists = True

        # if table does not exist yet, create it and download all historical data.
        # Note: the SQL-command 'IF NOT EXISTS' has no use here since get_historical_klines()
        # cannot be used to update existing data
        if not table_exists:
            # create table
            with db_con:
                cur = db_con.cursor()
                cur.execute('CREATE TABLE IF NOT EXISTS {}_{}('.format(symbol, interval) +
                            't_open DATETIME, ' +
                            'open FLOAT, ' +
                            'high FLOAT, ' +
                            'low FLOAT, ' +
                            'close FLOAT, ' +
                            'vol FLOAT, ' +
                            't_close DATETIME, ' +
                            'u_vol FLOAT, ' +
                            'no_trds INT, ' +
                            'tbBav FLOAT, ' +
                            'tbQav FLOAT)')

            # download data
            output = client.get_historical_klines(symbol=symbol,
                                                  interval=interval,
                                                  start_str=time_start,
                                                  end_str=time_end)

            # write downloaded data to database
            with db_con:
                cur = db_con.cursor()
                for x in range(0, len(output)):
                    db_row = (output[x][0],
                              output[x][1],
                              output[x][2],
                              output[x][3],
                              output[x][4],
                              output[x][5],
                              output[x][6],
                              output[x][7],
                              output[x][8],
                              output[x][9],
                              output[x][10])

                    cur.execute('INSERT INTO {}_{} VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'.format(symbol, interval),
                                db_row)

            # print process to console if verbose mode is enabled
            if verbose:
                print('Symbol {}, interval {}: Historical data has been downloaded '
                      'and saved to database'.format(symbol, interval))

        # if table already exists and verbose mode is enabled print that to console
        elif table_exists & (verbose == 'True'):
            print('Symbol {}, interval {}: Table already exists in database. '
                  'No data has been downloaded.'.format(symbol, interval))
/n/n/n",0
109,109,3f5079f53d8f259474885ff078bf96fdc08e02bd,"/get_historical_data.py/n/n# LOAD LIBRARIES & FILES

# load libraries
from binance.client import Client
import configparser
import sqlite3


# load functions
def getlist(option, sep=',', chars=None):
    """"""Return a list from a ConfigParser option. By default,
       split on a comma and strip whitespaces.""""""
    return [ chunk.strip(chars) for chunk in option.split(sep) ]


# READ FILES

# read credentials
configParser = configparser.ConfigParser()
configParser.read(r'credentials/API-key')

api_key = configParser.get('credentials', 'api_key')
api_sec = configParser.get('credentials', 'api_secret')


# read config
configParser.read(r'config.txt')

db_path = configParser.get('config', 'db_path')
verbose = configParser.get('config', 'verbose')
symbols = getlist(configParser.get('symbols', 'symbol_list'))
intervals = getlist(configParser.get('intervals', 'interval_list'))
time_start = configParser.get('time', 'time_start')
time_end = configParser.get('time', 'time_end')


# create timestamps for beginning and now
if time_start == 'beginning':
    time_start = 'January 1, 2000'


# SET UP DATABASE CONNECTION AND BINANCE CLIENT

# connect to database
db_con = sqlite3.connect(db_path)

# cet up binance client
client = Client(api_key, api_sec)


# GET DATA FOR ALL SYMBOLS AND INTERVALS

# Loop over every symbol and every interval. Download historical data for each combination from binance.com which is not
# already in the database and write it to the database
for symbol in symbols:
    for interval in intervals:

        # define name of table in database
        table_name = (symbol + '_' + interval, )

        # check if table already exists
        with db_con:
            cur = db_con.cursor()
            cur.execute(""SELECT name FROM sqlite_master WHERE type='table' AND name=?"", table_name)
            if cur.fetchone() is None:
                table_exists = False
            else:
                table_exists = True

        # if table does not exist yet, create it and download all historical data.
        # Note: the SQL-command 'IF NOT EXISTS' has no use here since get_historical_klines()
        # cannot be used to update existing data
        if not table_exists:
            # create table
            with db_con:
                cur = db_con.cursor()
                cur.execute('CREATE TABLE {}_{}('.format(symbol, interval) +
                            't_open DATETIME, ' +
                            'open FLOAT, ' +
                            'high FLOAT, ' +
                            'low FLOAT, ' +
                            'close FLOAT, ' +
                            'vol FLOAT, ' +
                            't_close DATETIME, ' +
                            'u_vol FLOAT, ' +
                            'no_trds INT, ' +
                            'tbBav FLOAT, ' +
                            'tbQav FLOAT)')

            # download data
            output = client.get_historical_klines(symbol=symbol,
                                                  interval=interval,
                                                  start_str=time_start,
                                                  end_str=time_end)

            # write downloaded data to database
            with db_con:
                cur = db_con.cursor()
                for x in range(0, len(output)):
                    cur.execute('INSERT INTO {}_{} '.format(symbol, interval) +
                                'VALUES({}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {})'.format(output[x][0],
                                                                                            output[x][1],
                                                                                            output[x][2],
                                                                                            output[x][3],
                                                                                            output[x][4],
                                                                                            output[x][5],
                                                                                            output[x][6],
                                                                                            output[x][7],
                                                                                            output[x][8],
                                                                                            output[x][9],
                                                                                            output[x][10]))

            # print process to console if verbose mode is enabled
            if verbose:
                print('Symbol {}, interval {}: Historical data has been downloaded and saved to database'.format(symbol, interval))

        # if table already exists and verbose mode is enabled print that to console
        elif table_exists & (verbose == 'True'):
            print('Symbol {}, interval {}: Table already exists in database. No data has been downloaded.'.format(symbol, interval))
/n/n/n",1
172,172,6ceb5dc8ec38b4a3f1399e578ab970f7e3354922,"docker/app.py/n/nfrom flask import Flask, render_template, request, current_app, g
from indic_transliteration import sanscript
from indic_transliteration.sanscript import SchemeMap, SCHEMES, transliterate

import random
import sqlite3 as sql
import re

app = Flask(__name__, static_url_path='', static_folder='static')

@app.route('/')

def index():
    all_vargas = ['स्वर्गवर्गः','व्योमवर्गः','दिग्वर्गः','कालवर्गः','धीवर्गः','शब्दादिवर्गः','नाट्यवर्गः','पातालभोगिवर्गः','नरकवर्गः','वारिवर्गः','भूमिवर्गः','पुरवर्गः','शैलवर्गः','वनौषधिवर्गः','सिंहादिवर्गः','मनुष्यवर्गः','ब्रह्मवर्गः','क्षत्रियवर्गः','वैश्यवर्गः','शूद्रवर्गः','विशेष्यनिघ्नवर्गः','सङ्कीर्णवर्गः','विशेष्यनिघ्नवर्गः','सङ्कीर्णवर्गः','नानार्थवर्गः','अव्ययवर्गः']
    return render_template('index.html', all_vargas=all_vargas)

    # try:
    #     with sql.connect('amara.db') as con:
    #         con.row_factory = sql.Row
    #         cur = con.cursor()
    #         cur.execute(""select distinct varga from pada"")
    #         all_vargas = cur.fetchall();
    #         return render_template('index.html', all_vargas=all_vargas)
    # finally:
    #     con.close()

@app.route('/search')
def search():

    limit = 10
    offset = 0

    user_term = request.args.get('term')
    page = request.args.get('page')
    term = user_term

    if not page:
        page = 1

    offset = limit*(int(page) - 1)

    transliterate_regex = re.compile('.*[a-zA-Z].*')
    if (transliterate_regex.match(term)):
        term = transliterate(term, sanscript.ITRANS, sanscript.DEVANAGARI)

    term = term.replace(""*"", ""%"")
    term_words = term.split()

    try:
        with sql.connect('amara.db') as con:
            con.row_factory = sql.Row
            cur = con.cursor()

            if len(term_words) == 1:
                cur.execute(""select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada like ? or artha like ? order by id limit ? offset ?;"", [term, term, limit, offset])
                rows = cur.fetchall();
            else:
                query = ""select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada in (%s) order by pada limit 100;"" % ','.join('?' for i in term_words)
                rows = cur.execute(query, term_words)

            return render_template('search.html', rows=rows, user_term=user_term, term=term, page=page)
    finally:
        con.close()


@app.route('/sloka')
def sloka():

    sloka_number = request.args.get('sloka_number')

    sloka_number_parts = sloka_number.split('.')

    sloka_number_previous = ""%s.%s.%d"" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])-1)
    sloka_number_next = ""%s.%s.%d"" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])+1)

    try:
        with sql.connect('amara.db') as con:
            con.row_factory = sql.Row
            cur = con.cursor()
            cur.execute(""select * from mula where sloka_number = ? order by sloka_line;"", [sloka_number])
            mula = cur.fetchall();

            cur.execute(""select * from pada where sloka_number = ? order by id;"", [sloka_number])
            pada = cur.fetchall();

            varga = """"
            if len(pada) > 0:
                varga = pada[0][""varga""]

            return render_template('sloka.html', mula=mula, pada=pada, varga=varga, sloka_number=sloka_number, sloka_number_previous=sloka_number_previous, sloka_number_next=sloka_number_next)
    finally:
        con.close()

@app.route('/quiz')
def quiz():

    varga = request.args.get('varga')

    try:
        rows =[]

        with sql.connect('amara.db') as con:
            con.row_factory = sql.Row
            cur = con.cursor()
            cur.execute(""select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada.varga = ? order by random() limit 1;"", [varga])
            rows = cur.fetchall();

            artha = rows[0][""artha""];
            cur.execute(""select pada from pada where varga = ? and artha = ? order by id"", [varga, artha]);
            paryaya = cur.fetchall();

            return render_template('quiz.html', rows=rows, paryaya=paryaya, varga=varga)
    finally:
        con.close()

@app.route('/varga')
def varga():

    varga = request.args.get('varga')

    try:
        rows =[]

        with sql.connect('amara.db') as con:
            con.row_factory = sql.Row
            cur = con.cursor()

            if varga:
                cur.execute(""select * from mula where varga = ?;"", [varga])
                # cur.execute(""select * from mula where sloka_number in (select distinct sloka_number from pada where varga='%s');"" % varga)
            else:
                cur.execute(""select * from mula"")
            mula = cur.fetchall();

            return render_template('varga.html', mula=mula, varga=varga)
    finally:
        con.close()

if __name__ == ""__main__"":
    app.run(host=""0.0.0.0"")
/n/n/n",0
173,173,6ceb5dc8ec38b4a3f1399e578ab970f7e3354922,"/docker/app.py/n/nfrom flask import Flask, render_template, request, current_app, g
from indic_transliteration import sanscript
from indic_transliteration.sanscript import SchemeMap, SCHEMES, transliterate

import random
import sqlite3 as sql
import re

app = Flask(__name__, static_url_path='', static_folder='static')

@app.route('/')

def index():
    all_vargas = ['स्वर्गवर्गः','व्योमवर्गः','दिग्वर्गः','कालवर्गः','धीवर्गः','शब्दादिवर्गः','नाट्यवर्गः','पातालभोगिवर्गः','नरकवर्गः','वारिवर्गः','भूमिवर्गः','पुरवर्गः','शैलवर्गः','वनौषधिवर्गः','सिंहादिवर्गः','मनुष्यवर्गः','ब्रह्मवर्गः','क्षत्रियवर्गः','वैश्यवर्गः','शूद्रवर्गः','विशेष्यनिघ्नवर्गः','सङ्कीर्णवर्गः','विशेष्यनिघ्नवर्गः','सङ्कीर्णवर्गः','नानार्थवर्गः','अव्ययवर्गः']
    return render_template('index.html', all_vargas=all_vargas)

    # try:
    #     with sql.connect('amara.db') as con:
    #         con.row_factory = sql.Row
    #         cur = con.cursor()
    #         cur.execute(""select distinct varga from pada"")
    #         all_vargas = cur.fetchall();
    #         return render_template('index.html', all_vargas=all_vargas)
    # finally:
    #     con.close()

@app.route('/search')
def search():

    limit = 10
    offset = 0

    user_term = request.args.get('term')
    page = request.args.get('page')
    term = user_term

    if not page:
        page = 1

    offset = limit*(int(page) - 1)

    transliterate_regex = re.compile('.*[a-zA-Z].*')
    if (transliterate_regex.match(term)):
        term = transliterate(term, sanscript.ITRANS, sanscript.DEVANAGARI)

    term = term.replace(""*"", ""%"")
    term_words = term.split()

    try:
        with sql.connect('amara.db') as con:
            con.row_factory = sql.Row
            cur = con.cursor()

            if len(term_words) == 1:
                cur.execute(""select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada like '%s' or artha like '%s' order by id limit %d offset %d;"" % (term, term, limit, offset))
                rows = cur.fetchall();
            else:
                query = ""select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada in (%s) order by pada limit 100;"" % ','.join('?' for i in term_words)
                rows = cur.execute(query, term_words)

            return render_template('search.html', rows=rows, user_term=user_term, term=term, page=page)
    finally:
        con.close()


@app.route('/sloka')
def sloka():

    sloka_number = request.args.get('sloka_number')

    sloka_number_parts = sloka_number.split('.')

    sloka_number_previous = ""%s.%s.%d"" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])-1)
    sloka_number_next = ""%s.%s.%d"" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])+1)

    try:
        with sql.connect('amara.db') as con:
            con.row_factory = sql.Row
            cur = con.cursor()
            cur.execute(""select * from mula where sloka_number = '%s' order by sloka_line;"" % sloka_number)
            mula = cur.fetchall();

            cur.execute(""select * from pada where sloka_number = '%s' order by id;"" % sloka_number)
            pada = cur.fetchall();

            varga = """"
            if len(pada) > 0:
                varga = pada[0][""varga""]

            return render_template('sloka.html', mula=mula, pada=pada, varga=varga, sloka_number=sloka_number, sloka_number_previous=sloka_number_previous, sloka_number_next=sloka_number_next)
    finally:
        con.close()

@app.route('/quiz')
def quiz():

    varga = request.args.get('varga')

    try:
        rows =[]

        with sql.connect('amara.db') as con:
            con.row_factory = sql.Row
            cur = con.cursor()
            cur.execute(""select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada.varga = '%s' order by random() limit 1;"" % varga)
            rows = cur.fetchall();

            artha = rows[0][""artha""];
            cur.execute(""select pada from pada where varga = '%s' and artha = '%s' order by id"" % (varga, artha));
            paryaya = cur.fetchall();

            return render_template('quiz.html', rows=rows, paryaya=paryaya, varga=varga)
    finally:
        con.close()

@app.route('/varga')
def varga():

    varga = request.args.get('varga')

    try:
        rows =[]

        with sql.connect('amara.db') as con:
            con.row_factory = sql.Row
            cur = con.cursor()
            cur.execute(""select * from mula where varga = '%s';"" % varga)
            # cur.execute(""select * from mula where sloka_number in (select distinct sloka_number from pada where varga='%s');"" % varga)
            mula = cur.fetchall();



            return render_template('varga.html', mula=mula, varga=varga)
    finally:
        con.close()

if __name__ == ""__main__"":
    app.run(host=""0.0.0.0"")
/n/n/n",1
112,112,4db98f3521592f17550d2b723336f33fec5e112a,"scripts/createMockDatabase.py/n/nimport sqlite3

mock_database_filename = 'sdow.sqlite'

print '[INFO] Creating mock database: {0}'.format(mock_database_filename)

conn = sqlite3.connect(mock_database_filename)

conn.execute('DROP TABLE IF EXISTS pages')
conn.execute('CREATE TABLE pages(id INTEGER PRIMARY KEY, name TEXT)')

for page_id in range(1, 101):
  page_name = '*{0}_{1}*'.format(page_id, page_id)
  conn.execute('INSERT INTO pages VALUES ({0}, ""{1}"")'.format(page_id, page_name))

conn.execute('DROP TABLE IF EXISTS redirects')
conn.execute('CREATE TABLE redirects(from_id INTEGER PRIMARY KEY, to_id INTEGER)')

for page_id in range(50, 60):
  conn.execute('INSERT INTO redirects VALUES ({0}, {1})'.format(page_id, page_id + 10))

conn.execute('DROP TABLE IF EXISTS links')
conn.execute('CREATE TABLE links(from_id INTEGER, to_id INTEGER, PRIMARY KEY (from_id, to_id)) WITHOUT ROWID;')

conn.execute('INSERT INTO links VALUES (1, 2)')
conn.execute('INSERT INTO links VALUES (1, 4)')
conn.execute('INSERT INTO links VALUES (1, 5)')
conn.execute('INSERT INTO links VALUES (1, 10)')
conn.execute('INSERT INTO links VALUES (2, 1)')
conn.execute('INSERT INTO links VALUES (2, 3)')
conn.execute('INSERT INTO links VALUES (2, 10)')
conn.execute('INSERT INTO links VALUES (3, 4)')
conn.execute('INSERT INTO links VALUES (3, 11)')
conn.execute('INSERT INTO links VALUES (4, 1)')
conn.execute('INSERT INTO links VALUES (4, 6)')
conn.execute('INSERT INTO links VALUES (4, 9)')
conn.execute('INSERT INTO links VALUES (5, 6)')
conn.execute('INSERT INTO links VALUES (7, 8)')
conn.execute('INSERT INTO links VALUES (8, 7)')
conn.execute('INSERT INTO links VALUES (9, 3)')
conn.execute('INSERT INTO links VALUES (11, 12)')
conn.execute('INSERT INTO links VALUES (13, 12)')
conn.execute('INSERT INTO links VALUES (15, 16)')
conn.execute('INSERT INTO links VALUES (15, 17)')
conn.execute('INSERT INTO links VALUES (16, 17)')
conn.execute('INSERT INTO links VALUES (16, 18)')
conn.execute('INSERT INTO links VALUES (17, 18)')
conn.execute('INSERT INTO links VALUES (18, 19)')
conn.execute('INSERT INTO links VALUES (19, 20)')
conn.execute('INSERT INTO links VALUES (21, 20)')
conn.execute('INSERT INTO links VALUES (22, 20)')

conn.commit()

print '[INFO] Successfully created mock database: {0}'.format(mock_database_filename)
/n/n/nsdow/database.py/n/n'''
Wrapper for connecting to the SDOW database.
'''

import os.path
import sqlite3
import sdow.helpers as helpers
from sdow.breadth_first_search import breadth_first_search


class Database():
  '''
  Wrapper for connecting to the SDOW database.
  '''
  def __init__(self, sqlite_filename):
    if not os.path.isfile(sqlite_filename):
      raise IOError('Specified SQLite file ""{0}"" does not exist.'.format(sqlite_filename))

    self.conn = sqlite3.connect(sqlite_filename)
    self.cursor = self.conn.cursor()

    # TODO: measure the performance impact of this
    self.cursor.arraysize = 1000

  def __del__(self):
    self.conn.close()

  def fetch_page_id(self, page_name):
    '''
    Returns the page ID corresponding to the provided page name.

    Args:
      page_name: The page name whose ID to fetch.

    Returns:
      int: The page ID corresponding to the provided page name.

    Raises:
      ValueError: If the provided page name is invalid or does not exist.
    '''
    helpers.validate_page_name(page_name)

    sanitized_page_name = page_name.replace(' ', '_')

    query = 'SELECT id FROM pages WHERE name = ?;'
    query_bindings = (sanitized_page_name,)
    self.cursor.execute(query, query_bindings)

    page_id = self.cursor.fetchone()

    if not page_id:
      raise ValueError('Invalid page name {0} provided. Page name does not exist.'.format(page_name))

    return page_id[0]


  def fetch_page_name(self, page_id):
    '''
    Returns the page name corresponding to the provided page ID.

    Args:
      page_id: The page ID whose ID to fetch.

    Returns:
      str: The page name corresponding to the provided page ID.

    Raises:
      ValueError: If the provided page ID is invalid or does not exist.
    '''
    helpers.validate_page_id(page_id)

    query = 'SELECT name FROM pages WHERE id = ?;'
    query_bindings = (page_id,)
    self.cursor.execute(query, query_bindings)

    page_name = self.cursor.fetchone()

    if not page_name:
      raise ValueError('Invalid page ID ""{0}"" provided. Page ID does not exist.'.format(page_id))

    return page_name[0].encode('utf-8').replace('_', ' ')


  def fetch_redirected_page_id(self, from_page_id):
    '''
    If the provided page ID is a redirect, returns the ID of the page to which it redirects.
    Otherwise, returns None.

    Args:
      from_page_id: The page ID whose redirected page ID to fetch.

    Returns:
      int: The ID of the page to which the provided page ID redirects.
      OR
      None: If the provided page ID is not a redirect.

    Raises:
      ValueError: If the provided page ID is invalid.
    '''
    helpers.validate_page_id(from_page_id)

    query = 'SELECT to_id FROM redirects WHERE from_id = ?'
    query_bindings = (from_page_id,)
    self.cursor.execute(query, query_bindings)

    to_page_id = self.cursor.fetchone()

    return to_page_id and to_page_id[0]

  def compute_shortest_paths(self, from_page_id, to_page_id):
    '''
    Returns a list of page IDs indicating the shortest path between the from and to page IDs.

    Args:
      from_page_id: The ID corresponding to the page at which to start the search.
      to_page_id: The ID corresponding to the page at which to end the search.

    Returns:
      [[int]]: A list of integer lists corresponding to the page IDs indicating the shortest path
               between the from and to page IDs.

    Raises:
      ValueError: If either of the provided page IDs are invalid.
    '''
    helpers.validate_page_id(from_page_id)
    helpers.validate_page_id(to_page_id)

    return breadth_first_search(from_page_id, to_page_id, self)

  def fetch_forwards_links(self, page_ids):
    '''
    Returns a list of tuples of page IDs representing forwards links from the list of provided page
    IDs to other pages.

    Args:
      page_ids: The page IDs whose forwards links to fetch.

    Returns:
      [(int, int)]: A lists of integer tuples representing forwards links from the list of provided
                    page IDs to other pages.
    '''
    return self.fetch_links_helper(page_ids, 'from_id')

  def fetch_backwards_links(self, page_ids):
    '''
    Returns a list of tuples of page IDs representing backwards links from the list of provided page
    IDs to other pages.

    Args:
      page_ids: The page IDs whose backwards links to fetch.

    Returns:
      [(int, int)]: A lists of integer tuples representing backwards links from the list of provided
                    page IDs to other pages.
    '''
    return self.fetch_links_helper(page_ids, 'to_id')

  def fetch_links_helper(self, page_ids, to_id_or_from_id):
    '''
    Helper function which handles duplicate logic for fetch_forwards_links() and
    fetch_backwards_links().

    Args:
      page_ids: The page IDs whose links to fetch.
      to_id_or_from_id: String which indicates whether to fetch forwards (""from_id"") or backwards
                        (""to_id"") links.

    Returns:
      [(int, int)]: A lists of integer tuples representing links from the list of provided page IDs
                    to other pages.
    '''
    #results = []
    #for row in self.cursor.execute(query):
    #  results.append(row)

    # TODO: measure the performance impact of this versus just appending to an array (above) or
    # just returning the cursor (not yet implemented)
    # There is no need to escape the query parameters here since they are never user-defined
    query = 'SELECT * FROM links WHERE {0} IN {1}'.format(to_id_or_from_id, page_ids)
    self.cursor.execute(query)

    return self.cursor.fetchall()
/n/n/n",0
113,113,4db98f3521592f17550d2b723336f33fec5e112a,"/scripts/createMockDatabase.py/n/nimport sqlite3

mock_database_filename = 'sdow.sqlite'

print '[INFO] Creating mock database: {0}'.format(mock_database_filename)

conn = sqlite3.connect(mock_database_filename)

conn.execute('DROP TABLE IF EXISTS pages')
conn.execute('CREATE TABLE pages(id INTEGER PRIMARY KEY, name TEXT)')

for page_id in range(1, 101):
  page_name = '{0}_{1}'.format(page_id, page_id)
  conn.execute('INSERT INTO pages VALUES ({0}, ""{1}"")'.format(page_id, page_name))

conn.execute('DROP TABLE IF EXISTS redirects')
conn.execute('CREATE TABLE redirects(from_id INTEGER PRIMARY KEY, to_id INTEGER)')

for page_id in range(50, 60):
  conn.execute('INSERT INTO redirects VALUES ({0}, {1})'.format(page_id, page_id + 10))

conn.execute('DROP TABLE IF EXISTS links')
conn.execute('CREATE TABLE links(from_id INTEGER, to_id INTEGER, PRIMARY KEY (from_id, to_id)) WITHOUT ROWID;')

conn.execute('INSERT INTO links VALUES (1, 2)')
conn.execute('INSERT INTO links VALUES (1, 4)')
conn.execute('INSERT INTO links VALUES (1, 5)')
conn.execute('INSERT INTO links VALUES (1, 10)')
conn.execute('INSERT INTO links VALUES (2, 1)')
conn.execute('INSERT INTO links VALUES (2, 3)')
conn.execute('INSERT INTO links VALUES (2, 10)')
conn.execute('INSERT INTO links VALUES (3, 4)')
conn.execute('INSERT INTO links VALUES (3, 11)')
conn.execute('INSERT INTO links VALUES (4, 1)')
conn.execute('INSERT INTO links VALUES (4, 6)')
conn.execute('INSERT INTO links VALUES (4, 9)')
conn.execute('INSERT INTO links VALUES (5, 6)')
conn.execute('INSERT INTO links VALUES (7, 8)')
conn.execute('INSERT INTO links VALUES (8, 7)')
conn.execute('INSERT INTO links VALUES (9, 3)')
conn.execute('INSERT INTO links VALUES (11, 12)')
conn.execute('INSERT INTO links VALUES (13, 12)')
conn.execute('INSERT INTO links VALUES (15, 16)')
conn.execute('INSERT INTO links VALUES (15, 17)')
conn.execute('INSERT INTO links VALUES (16, 17)')
conn.execute('INSERT INTO links VALUES (16, 18)')
conn.execute('INSERT INTO links VALUES (17, 18)')
conn.execute('INSERT INTO links VALUES (18, 19)')
conn.execute('INSERT INTO links VALUES (19, 20)')
conn.execute('INSERT INTO links VALUES (21, 20)')
conn.execute('INSERT INTO links VALUES (22, 20)')

conn.commit()

print '[INFO] Successfully created mock database: {0}'.format(mock_database_filename)
/n/n/n/sdow/database.py/n/n'''
Wrapper for connecting to the SDOW database.
'''

import os.path
import sqlite3
import sdow.helpers as helpers
from sdow.breadth_first_search import breadth_first_search


class Database():
  '''
  Wrapper for connecting to the SDOW database.
  '''
  def __init__(self, sqlite_filename):
    if not os.path.isfile(sqlite_filename):
      raise IOError('Specified SQLite file ""{0}"" does not exist.'.format(sqlite_filename))

    self.conn = sqlite3.connect(sqlite_filename)
    self.cursor = self.conn.cursor()

    # TODO: measure the performance impact of this
    self.cursor.arraysize = 1000

  def __del__(self):
    self.conn.close()

  def fetch_page_id(self, page_name):
    '''
    Returns the page ID corresponding to the provided page name.

    Args:
      page_name: The page name whose ID to fetch.

    Returns:
      int: The page ID corresponding to the provided page name.

    Raises:
      ValueError: If the provided page name is invalid or does not exist.
    '''
    helpers.validate_page_name(page_name)

    sanitized_page_name = page_name.replace(' ', '_')

    print 'sanitized_page_name: {0}'.format(sanitized_page_name)

    query = 'SELECT id FROM pages WHERE name=""{0}""'.format(sanitized_page_name)
    self.cursor.execute(query)

    page_id = self.cursor.fetchone()

    if not page_id:
      raise ValueError('Invalid page name {0} provided. Page name does not exist.'.format(page_name))

    return page_id[0]


  def fetch_page_name(self, page_id):
    '''
    Returns the page name corresponding to the provided page ID.

    Args:
      page_id: The page ID whose ID to fetch.

    Returns:
      str: The page name corresponding to the provided page ID.

    Raises:
      ValueError: If the provided page ID is invalid or does not exist.
    '''
    helpers.validate_page_id(page_id)

    query = 'SELECT name FROM pages WHERE id=""{0}""'.format(page_id)
    self.cursor.execute(query)

    page_name = self.cursor.fetchone()

    if not page_name:
      raise ValueError('Invalid page ID ""{0}"" provided. Page ID does not exist.'.format(page_id))

    return page_name[0].encode('utf-8').replace('_', ' ')


  def fetch_redirected_page_id(self, from_page_id):
    '''
    If the provided page ID is a redirect, returns the ID of the page to which it redirects.
    Otherwise, returns None.

    Args:
      from_page_id: The page ID whose redirected page ID to fetch.

    Returns:
      int: The ID of the page to which the provided page ID redirects.
      OR
      None: If the provided page ID is not a redirect.

    Raises:
      ValueError: If the provided page ID is invalid.
    '''
    helpers.validate_page_id(from_page_id)

    query = 'SELECT to_id FROM redirects WHERE from_id=""{0}""'.format(from_page_id)
    self.cursor.execute(query)

    to_page_id = self.cursor.fetchone()

    return to_page_id and to_page_id[0]

  def compute_shortest_paths(self, from_page_id, to_page_id):
    '''
    Returns a list of page IDs indicating the shortest path between the from and to page IDs.

    Args:
      from_page_id: The ID corresponding to the page at which to start the search.
      to_page_id: The ID corresponding to the page at which to end the search.

    Returns:
      [[int]]: A list of integer lists corresponding to the page IDs indicating the shortest path
               between the from and to page IDs.

    Raises:
      ValueError: If either of the provided page IDs are invalid.
    '''
    helpers.validate_page_id(from_page_id)
    helpers.validate_page_id(to_page_id)

    return breadth_first_search(from_page_id, to_page_id, self)

  def fetch_forwards_links(self, page_ids):
    '''
    Returns a list of tuples of page IDs representing forwards links from the list of provided page
    IDs to other pages.

    Args:
      page_ids: The page IDs whose forwards links to fetch.

    Returns:
      [(int, int)]: A lists of integer tuples representing forwards links from the list of provided
                    page IDs to other pages.
    '''
    return self.fetch_links_helper(page_ids, 'from_id')

  def fetch_backwards_links(self, page_ids):
    '''
    Returns a list of tuples of page IDs representing backwards links from the list of provided page
    IDs to other pages.

    Args:
      page_ids: The page IDs whose backwards links to fetch.

    Returns:
      [(int, int)]: A lists of integer tuples representing backwards links from the list of provided
                    page IDs to other pages.
    '''
    return self.fetch_links_helper(page_ids, 'to_id')

  def fetch_links_helper(self, page_ids, to_id_or_from_id):
    '''
    Helper function which handles duplicate logic for fetch_forwards_links() and
    fetch_backwards_links().

    Args:
      page_ids: The page IDs whose links to fetch.
      to_id_or_from_id: String which indicates whether to fetch forwards (""from_id"") or backwards
                        (""to_id"") links.

    Returns:
      [(int, int)]: A lists of integer tuples representing links from the list of provided page IDs
                    to other pages.
    '''

    query = 'SELECT from_id, to_id FROM links WHERE {0} IN {1}'.format(to_id_or_from_id, page_ids)

    #results = []
    #for row in self.cursor.execute(query):
    #  results.append(row)

    # TODO: measure the performance impact of this versus just appending to an array (above) or
    # just returning the cursor (not yet implemented)
    self.cursor.execute(query)

    return self.cursor.fetchall()
/n/n/n",1
122,122,650b26c48bcb7824775ff269d4badf27666b611e,"app/run.py/n/nimport json
import os
import mysql.connector
from flask import Flask, render_template, url_for, redirect, request, session, jsonify, g

app = Flask(__name__)
app.config.from_object('config')


def get_db():
    if not hasattr(g, 'db'):
        g.db = mysql.connector.connect(user=os.getenv('SAMWISE_USERNAME'), password=os.getenv('SAMWISE_PASSWORD'),
                                       host=os.getenv('SAMWISE_DB'))
    return g.db


@app.teardown_appcontext
def close_db(error):
    if hasattr(g, 'db'):
        g.db.close()


@app.route(""/"")
def index():
    if 'netid' in session:
        app.logger.debug('NetID: ' + session['netid'])
        return redirect(url_for('calData', userid=session['netid']))
    return render_template(""index.html"")


@app.route(""/calendar"")
def calendar():
    return render_template(""calendar.html"")


@app.route(""/<userid>"")
def calData(userid):
    if 'netid' in session:
        app.logger.debug('User ID Data For ' + session['netid'])
        return render_template(""index.html"", netid=userid)
    return redirect(url_for('index'))


@app.route('/getUserExams/<netId>')
def getUserExams(netId):
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('SELECT courseId FROM samwisedb.User WHERE netId = %s', (netId,))
    courses = [item[0] for item in cursor.fetchall()]
    data = []
    for courseId in courses:
        cursor.execute('SELECT sections, time FROM samwisedb.Exam WHERE courseId = %s', (courseId,))
        exam = [{'courseId': courseId, 'section': item[0], 'start': item[1]} for item in cursor.fetchall()]
        data.append(exam)
    return jsonify(data)


@app.route('/getAllCourses')
def getAllCourses():
    # Open the connection to database
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('SELECT DISTINCT courseId FROM samwisedb.Course ORDER BY courseId')
    data = [item[0] for item in cursor.fetchall()]
    return jsonify(data)


@app.route('/getUserCourses/<netId>')
def getUserCourses(netId):
    # Open the connection to database
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('SELECT DISTINCT courseId FROM samwisedb.User WHERE netId = %s', (netId,))
    data = [item[0] for item in cursor.fetchall()]
    return jsonify(data)


@app.route('/addCourse/', methods=['POST'])
def addCourse():
    data = request.get_json(force=True)
    courseId = data['courseId']
    user = data['user']
    connection = get_db()
    cursor = connection.cursor()
    # TODO: Make sure course exists and use does not already have course
    cursor.execute('INSERT INTO samwisedb.User(netId, courseId) VALUES (%s, %s)', (user, courseId))
    connection.commit()
    return jsonify([])


@app.route('/removeCourse/', methods=['POST'])
def removeCourse():
    data = request.get_json(force=True)
    courseId = data['courseId']
    userId = data['userId']
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('DELETE FROM samwisedb.User WHERE (userId, courseId) = (%s, %s)', (userId, courseId))
    connection.commit()
    return jsonify([])


@app.route('/getProjects/<userId>')
def getProjects(userId):
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('SELECT DISTINCT * FROM samwisedb.Project WHERE user = %s', (userId,))
    data = [{'projectId': item[1], 'projectName': item[2], 'date': item[3], 'courseId': item[4]} for item in
            cursor.fetchall()]
    for d in data:
        cursor.execute('SELECT subtaskName FROM samwisedb.Subtask WHERE projectId = %s', (d['projectId'],))
        subtasks = [item[0] for item in cursor.fetchall()]
        d['subtasks'] = subtasks
    return jsonify(data)


@app.route('/removeProject/', methods=['POST'])
def removeProject():
    data = request.get_json(force=True)
    projectId = data['projectId']
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('DELETE FROM samwisedb.Project WHERE projectId = %s', (projectId,))
    cursor.execute('DELETE FROM samwisedb.Subtask WHERE projectId = %s', (projectId,))
    connection.commit()
    return jsonify([])


@app.route('/updateProject/', methods=['POST'])
def updateProject():
    data = request.get_json(force=True)
    projectId = data['projectid']
    projectName = data['projectname']
    dueDate = data['duedate']
    courseId = data['course']

    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('''
       UPDATE samwisedb.Project
       SET projectName=%s, dueDate=%s, courseId=%s
       WHERE projectId=%s
    ''', (projectName, dueDate, courseId, projectId))
    connection.commit()
    return jsonify(data)


@app.route('/addProject/', methods=['POST'])
def addProject():
    data = request.get_json(force=True)
    userId = data['userId']
    projectName = data['projectName']
    courseId = data['courseId']
    dueDate = data['dueDate']
    subtasks = data['subtasks']

    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('INSERT INTO samwisedb.Project(userId, projectName, dueDate, courseId) VALUES (%s, %s, %s, %s)',
                   (userId, projectName, dueDate, courseId))
    projectId = cursor.lastrowid
    for subtask in subtasks:
        cursor.execute('INSERT INTO samwisedb.Subtask(projectId, subtaskName) VALUES (%s, %s)', (projectId, subtask))
    connection.commit()
    return jsonify([projectId])


@app.route('/getEvents/<userid>')
def getEvents(userid):
    connection = get_db()

    cursor = connection.cursor()
    cursor.execute('SELECT DISTINCT * FROM samwisedb.Event WHERE user = %s', userid)
    data = [{""eventName"": str(item[2]), ""startTime"": str(item[3]), ""endTime"": str(item[4]), ""tagId"": str(item[5])} for
            item in cursor.fetchall()]

    return jsonify(data)


-


@app.route('/removeEvent/', methods=['POST'])
def removeEvent():
    if request.method == 'POST':
        data = request.get_json(force=True)
        eventId = data['eventId']

        connection = get_db()

        try:
            cursor = connection.cursor()
            cursor.execute('DELETE FROM samwisedb.Event WHERE eventId = %s', eventId)
            connection.commit()
        finally:
            print (""DONE"")

    return jsonify([])


@app.route('/addEvent/', methods=['POST'])
def addEvent():
    event_id = -1
    if request.method == 'POST':
        data = request.get_json(force=True)
        user = data['user']
        eventName = data['eventName']
        startTime = data['startTime']
        endTime = data['endTime']
        tagId = data['tagId']

        connection = get_db()

        try:
            cursor = connection.cursor()
            cursor.execute(
                'INSERT INTO samwisedb.Event(user, eventName, startTime, endTime, tagId) values (%s, %s, %s, %s, %s)',
                (user, eventName, startTime, endTime, tagId))
            connection.commit()
            event_id = cursor.lastrowid
        finally:
            print (""DONE"")
    return jsonify([event_id])


@app.route('/updateEvent/', methods=['POST'])
def updateEvent():
    if request.method == 'POST':
        data = request.get_json(force=True)
        eventId = data['eventId']
        eventName = data['eventName']
        startTime = data['startTime']
        endTime = data['endTime']
        tagId = data['tagId']

        connection = get_db()

        try:
            cursor = connection.cursor()
            cursor.execute(
                'UPDATE samwisedb.Event SET eventName=%s, startTime=%s, endTime=%s, tagId=%s WHERE eventId=%s',
                (eventName, startTime, endTime, tagId, eventId))
            connection.commit()
        finally:
            print (""DONE"")

    return jsonify([])


@app.route('/getTasks/<userId>', methods=['GET'])
def getTasks(userId):
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('SELECT DISTINCT * FROM samwisedb.Task WHERE user = %s', (userId,))
    data = [{
        'user': item[0],
        'taskId': item[1],
        'taskName': item[2],
        'courseId': item[3],
        'tag': item[4],
        'dueDate': item[5],
        'details': item[6]
    } for item in cursor.fetchall()]

    return jsonify(data)


@app.route('/removeTask/', methods=['POST'])
def removeTask():
    data = request.get_json(force=True)
    taskId = data['taskid']

    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('DELETE FROM samwisedb.Task WHERE taskId = %s', taskId)
    connection.commit()

    return jsonify([])


@app.route('/addTask/', methods=['POST'])
def addTaskCourse():
    task_id = -1
    if request.method == 'POST':
        data = request.get_json(force=True)
        userid = data['userid']
        taskname = data['taskname']
        course = data['course']
        duedate = data['duedate']
        details = data['details']

        connection = get_db()

        try:
            cursor = connection.cursor()
            cursor.execute('INSERT INTO samwisedb.Task(user, taskName, courseId, dueDate, details) values (%s, %s, %s, %s, %s)', (userid, taskname, course, duedate, details))
            connection.commit()
            task_id = cursor.lastrowid
        finally:
            print (""DONE"")
    return jsonify([task_id])


@app.route('/updateTask/', methods=['POST'])
def updateTask():
    if request.method == 'POST':
        data = request.get_json(force=True)
        taskid = data['taskid']
        taskname = data['taskname']
        details = data['details']
        duedate = data['duedate']
        course = data['course']

        taskid = int(taskid)

        connection = get_db()

        try:
            cursor = connection.cursor()
            cursor.execute(""""""
               UPDATE samwisedb.Task
               SET taskName=%s, dueDate=%s, courseId=%s, details=%s
               WHERE taskId=%s
            """""", (taskname, duedate, course, details, taskid))
            connection.commit()
        finally:
            print (""DONE"")

    return jsonify([])


@app.route('/exams/<course_id>')
def getExams(course_id):
    # Open the connection to database
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('SELECT time FROM samwisedb.Exam WHERE courseId = %s', (course_id,))
    data = [{'course_id': course_id, 'start': item[0]} for item in cursor.fetchall()]
    return jsonify(data)


@app.route('/courses/<courseId>')
def getClassInfo(courseId):
    # Open the connection to database
    connection = get_db()

    cursor = connection.cursor()
    cursor.execute('SELECT startTime FROM samwisedb.Course WHERE courseId = %s', courseId)
    data = [{""course"": courseId + "" Class"", ""start"": str(item[0])} for item in cursor.fetchall()]
    return jsonify(data)


@app.route('/addSubtask/', methods=['POST'])
def addSubtask():
    data = request.get_json(force=True)
    projectId = data['projectId']
    subtask = data['subtask']
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('INSERT INTO samwisedb.Subtask(projectId, subtask) VALUES (%s, %s)', (projectId, subtask))
    subtaskId = cursor.lastrowid
    connection.commit()
    return jsonify([subtaskId])


@app.route('/removeSubtask/', methods=['POST'])
def removeSubtask():
    data = request.get_json(force=True)
    subtaskId = data['subtaskId']
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('DELETE FROM samwisedb.Subtask WHERE subtaskId = %s', (subtaskId,))
    connection.commit()
    return jsonify([subtaskId])


@app.route('/updateSubtask/', methods=['POST'])
def updateSubtask():
    data = request.get_json(force=True)
    subtaskId = data['subtaskId']
    subtaskName = data['subtaskName']
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('UPDATE samwisedb.Subtask SET subtaskName = %s WHERE subtaskId = %s', (subtaskName, subtaskId))
    connection.commit()
    return jsonify([subtaskName])


@app.route('/getColor/<name>')
def getColor(name):
    return app.config['COLORS'][hash(name) % len(app.config['COLORS'])]


if __name__ == ""__main__"":
    app.run(debug=True)
/n/n/n",0
123,123,650b26c48bcb7824775ff269d4badf27666b611e,"/app/run.py/n/nimport json
import os
import mysql.connector
from flask import Flask, render_template, url_for, redirect, request, session, jsonify, g

app = Flask(__name__)
app.config.from_object('config')

def get_db():
    if not hasattr(g, 'db'):
        g.db = mysql.connector.connect(user=os.getenv('SAMWISE_USERNAME'), password=os.getenv('SAMWISE_PASSWORD'),
                                       host=os.getenv('SAMWISE_DB'))
    return g.db


@app.teardown_appcontext
def close_db(error):
    if hasattr(g, 'db'):
        g.db.close()


@app.route(""/"")
def index():
    if 'netid' in session:
        app.logger.debug('NetID: ' + session['netid'])
        return redirect(url_for('calData', userid=session['netid']))
    return render_template(""index.html"")


@app.route(""/calendar"")
def calendar():
    return render_template(""calendar.html"")


@app.route(""/<userid>"")
def calData(userid):
    if 'netid' in session:
        app.logger.debug('User ID Data For ' + session['netid'])
        return render_template(""index.html"", netid=userid)
    return redirect(url_for('index'))


@app.route('/getUserExams/<netId>')
def getUserExams(netId):
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('SELECT courseId FROM samwisedb.User WHERE netId = %s', (netId,))
    courses = [item[0] for item in cursor.fetchall()]
    data = []
    for courseId in courses:
        cursor.execute('SELECT sections, time FROM samwisedb.Exam WHERE courseId = %s', (courseId,))
        exam = [{'courseId': courseId, 'section': item[0], 'start': item[1]} for item in cursor.fetchall()]
        data.append(exam)
    return jsonify(data)


@app.route('/getAllCourses')
def getAllCourses():
    # Open the connection to database
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('SELECT DISTINCT courseId FROM samwisedb.Course ORDER BY courseId')
    data = [item[0] for item in cursor.fetchall()]
    return jsonify(data)


@app.route('/getUserCourses/<netId>')
def getUserCourses(netId):
    # Open the connection to database
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('SELECT DISTINCT courseId FROM samwisedb.User WHERE netId = %s', (netId,))
    data = [item[0] for item in cursor.fetchall()]
    return jsonify(data)


@app.route('/addCourse/', methods=['POST'])
def addCourse():
    data = request.get_json(force=True)
    courseId = data['courseId']
    user = data['user']
    connection = get_db()
    cursor = connection.cursor()
    # TODO: Make sure course exists and use does not already have course
    cursor.execute('INSERT INTO samwisedb.User(netId, courseId) VALUES (%s, %s)', (user, courseId))
    connection.commit()
    return jsonify([])


@app.route('/removeCourse/', methods=['POST'])
def removeCourse():
    data = request.get_json(force=True)
    courseId = data['courseId']
    userId = data['userId']
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('DELETE FROM samwisedb.User WHERE (userId, courseId) = (%s, %s)', (userId, courseId))
    connection.commit()
    return jsonify([])


@app.route('/getProjects/<userId>')
def getProjects(userId):
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('SELECT DISTINCT * FROM samwisedb.Project WHERE user = %s', (userId,))
    data = [{'projectId': item[1], 'projectName': item[2], 'date': item[3], 'courseId': item[4]} for item in
            cursor.fetchall()]
    for d in data:
        cursor.execute('SELECT subtaskName FROM samwisedb.Subtask WHERE projectId = %s', (d['projectId'],))
        subtasks = [item[0] for item in cursor.fetchall()]
        d['subtasks'] = subtasks
    return jsonify(data)


@app.route('/removeProject/', methods=['POST'])
def removeProject():
    data = request.get_json(force=True)
    projectId = data['projectId']
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('DELETE FROM samwisedb.Project WHERE projectId = %s', (projectId,))
    cursor.execute('DELETE FROM samwisedb.Subtask WHERE projectId = %s', (projectId,))
    connection.commit()
    return jsonify([])


@app.route('/updateProject/', methods=['POST'])
def updateProject():
    data = request.get_json(force=True)
    projectId = data['projectid']
    projectName = data['projectname']
    dueDate = data['duedate']
    courseId = data['course']

    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('''
       UPDATE samwisedb.Project
       SET projectName=%s, dueDate=%s, courseId=%s
       WHERE projectId=%s
    ''', (projectName, dueDate, courseId, projectId))
    connection.commit()
    return jsonify(data)


@app.route('/addProject/', methods=['POST'])
def addProject():
    data = request.get_json(force=True)
    userId = data['userId']
    projectName = data['projectName']
    courseId = data['courseId']
    dueDate = data['dueDate']
    subtasks = data['subtasks']

    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('INSERT INTO samwisedb.Project(userId, projectName, dueDate, courseId) VALUES (%s, %s, %s, %s)',
                   (userId, projectName, dueDate, courseId))
    projectId = cursor.lastrowid
    for subtask in subtasks:
        cursor.execute('INSERT INTO samwisedb.Subtask(projectId, subtaskName) VALUES (%s, %s)', (projectId, subtask))
    connection.commit()
    return jsonify([projectId])


@app.route('/getEvents/<userid>')
def getEvents(userid):
    connection = get_db()

    cursor = connection.cursor()

    query = ""SELECT DISTINCT * FROM samwisedb.Event WHERE user = \"""" + userid + ""\"";""
    cursor.execute(query)

    data = [{""eventName"": str(item[2]), ""startTime"": str(item[3]), ""endTime"": str(item[4]), ""tagId"": str(item[5])} for
            item in cursor.fetchall()]

    return json.dumps(data)


@app.route('/removeEvent/', methods=['POST'])
def removeEvent():
    if request.method == 'POST':
        data = request.get_json(force=True)
        eventId = data['eventId']

        connection = get_db()

        try:
            cursor = connection.cursor()
            query = ""DELETE FROM samwisedb.Event WHERE eventId = \"""" + eventId + ""\"";""
            print(query)
            cursor.execute(query)
            connection.commit()
        finally:
            print (""DONE"")

    return json.dumps([])


@app.route('/addEvent/', methods=['POST'])
def addEvent():
    event_id = -1
    if request.method == 'POST':
        data = request.get_json(force=True)
        user = data['user']
        eventName = data['eventName']
        startTime = data['startTime']
        endTime = data['endTime']
        tagId = data['tagId']

        connection = get_db()

        try:
            cursor = connection.cursor()
            query = ""insert into samwisedb.Event(user, eventName, startTime, endTime, tagId) values (\"""" + user + ""\"", \"""" + eventName + ""\"", \"""" + startTime + ""\"", \"""" + endTime + ""\"", \"""" + tagId + ""\"");""
            print(query)
            cursor.execute(query)
            connection.commit()
            event_id = cursor.lastrowid
        finally:
            print (""DONE"")
    return json.dumps([event_id])


@app.route('/updateEvent/', methods=['POST'])
def updateEvent():
    if request.method == 'POST':
        data = request.get_json(force=True)
        eventId = data['eventId']
        eventName = data['eventName']
        startTime = data['startTime']
        endTime = data['endTime']
        tagId = data['tagId']

        connection = get_db()

        try:
            cursor = connection.cursor()
            cursor.execute(""""""
               UPDATE samwisedb.Event
               SET eventName=%s, startTime=%s, endTime=%s, tagId=%s
               WHERE eventId=%s
            """""", (eventName, startTime, endTime, tagId, eventId))
            connection.commit()
        finally:
            print (""DONE"")

    return json.dumps([])


@app.route('/getTasks/<userId>', methods=['GET'])
def getTasks(userId):
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('SELECT DISTINCT * FROM samwisedb.Task WHERE user = %s', (userId,))
    data = [{
        'user': item[0],
        'taskId': item[1],
        'taskName': item[2],
        'courseId': item[3],
        'tag': item[4],
        'dueDate': item[5],
        'details': item[6]
    } for item in cursor.fetchall()]

    return jsonify(data)


@app.route('/removeTask/', methods=['POST'])
def removeTask():
    data = request.get_json(force=True)
    taskId = data['taskid']

    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('DELETE FROM samwisedb.Task WHERE taskId = %s', taskId)
    connection.commit()

    return json.dumps([])


@app.route('/addTask/', methods=['POST'])
def addTaskCourse():
    task_id = -1
    if request.method == 'POST':
        data = request.get_json(force=True)
        userid = data['userid']
        taskname = data['taskname']
        course = data['course']
        duedate = data['duedate']
        details = data['details']

        connection = get_db()

        try:
            cursor = connection.cursor()
            query = ""INSERT into samwisedb.Task(user, taskName, courseId, dueDate, details) values (\"""" + userid + ""\"", \"""" + taskname + ""\"", \"""" + course + ""\"", \"""" + duedate + ""\"", \"""" + details + ""\"");""
            print(query)
            cursor.execute(query)
            connection.commit()
            task_id = cursor.lastrowid
        finally:
            print (""DONE"")
    return json.dumps([task_id])


@app.route('/updateTask/', methods=['POST'])
def updateTask():
    if request.method == 'POST':
        data = request.get_json(force=True)
        taskid = data['taskid']
        taskname = data['taskname']
        details = data['details']
        duedate = data['duedate']
        course = data['course']

        taskid = int(taskid)

        connection = get_db()

        try:
            cursor = connection.cursor()
            cursor.execute(""""""
               UPDATE samwisedb.Task
               SET taskName=%s, dueDate=%s, courseId=%s, details=%s
               WHERE taskId=%s
            """""", (taskname, duedate, course, details, taskid))
            connection.commit()
        finally:
            print (""DONE"")

    return json.dumps([])


@app.route('/exams/<course_id>')
def getExams(course_id):
    # Open the connection to database
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('SELECT time FROM samwisedb.Exam WHERE courseId = %s', (course_id,))
    data = [{'course_id': course_id, 'start': item[0]} for item in cursor.fetchall()]
    return jsonify(data)


@app.route('/courses/<courseId>')
def getClassInfo(courseId):
    # Open the connection to database
    connection = get_db()

    cursor = connection.cursor()
    cursor.execute('SELECT startTime FROM samwisedb.Course WHERE courseId = %s', courseId)
    data = [{""course"": courseId + "" Class"", ""start"": str(item[0])} for item in cursor.fetchall()]
    return json.dumps(data)


@app.route('/addSubtask/', methods=['POST'])
def addSubtask():
    data = request.get_json(force=True)
    projectId = data['projectId']
    subtask = data['subtask']
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('INSERT INTO samwisedb.Subtask(projectId, subtask) VALUES (%s, %s)', (projectId, subtask))
    subtaskId = cursor.lastrowid
    connection.commit()
    return jsonify([subtaskId])


@app.route('/removeSubtask/', methods=['POST'])
def removeSubtask():
    data = request.get_json(force=True)
    subtaskId = data['subtaskId']
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('DELETE FROM samwisedb.Subtask WHERE subtaskId = %s', (subtaskId,))
    connection.commit()
    return jsonify([subtaskId])


@app.route('/updateSubtask/', methods=['POST'])
def updateSubtask():
    data = request.get_json(force=True)
    subtaskId = data['subtaskId']
    subtaskName = data['subtaskName']
    connection = get_db()
    cursor = connection.cursor()
    cursor.execute('UPDATE samwisedb.Subtask SET subtaskName = %s WHERE subtaskId = %s', (subtaskName, subtaskId))
    connection.commit()
    return jsonify([subtaskName])


@app.route('/getColor/<name>')
def getColor(name):
    return app.config['COLORS'][hash(name) % len(app.config['COLORS'])]


if __name__ == ""__main__"":
    app.run(debug=True)
/n/n/n",1
190,190,abd763746d7ff1d40571fed8ed46fce2211f3deb,"gfui/backends/Mysql/mysql.py/n/nfrom gfui.backends.default import Backend
import mysql.connector
from gfui.chartgraph import Graph, Table
import re
import ipaddress
import os

class Mysql_backend(Backend):
    def __init__(self, OPTIONS):
        super().__init__()
        self.required_opts = ['SQL_SERVER', 'SQL_USERNAME', 'SQL_DB']
        self.parse_options(OPTIONS)
        self.columns = {}

        pw = os.environ.get(""SQL_PASSWORD"")
        if not pw:
            pw = self.OPTIONS['SQL_PASSWORD']

        self.db = mysql.connector.connect(
            host=self.OPTIONS['SQL_SERVER'],
            user=self.OPTIONS['SQL_USERNAME'],
            passwd=pw,
            database=self.OPTIONS['SQL_DB']


        )

        self.schema = Schema()

        self.filters = []

    def get_columns(self):
        return self.schema.get_columns()

    def add_filter(self, op, value):
        self.schema.add_filter(value, op)

    def get_int_columns(self):
        return self.schema.get_int_columns()

    def flow_table(self, limit=10):
        db = self.db
        self.schema.limit = limit

        FLOWS = self.schema.flows()
        cursor = self.schema.query(db, FLOWS)
        r = cursor.fetchall()
        t = Table()
        t = t.table_from_rows(r, self.schema.column_order)
        return t

    def topn_sum_graph(self, field, sum_by, limit=10):
        db = self.db
        self.schema.limit = limit
        FLOWS_PER_IP = self.schema.topn_sum(field, sum_by)

        cursor = db.cursor()
        cursor.execute(""USE testgoflow"")
        cursor.execute(FLOWS_PER_IP)
        r = cursor.fetchall()
        g = Graph()
        g.name = ""TopN {0}"".format(field)
        g.set_headers([
            field,
            ""Total""
        ])
        g.graph_from_rows(r, 0)
        return g

class Column:
    """"""
    Column

    Column handling class.
    Governs how query strings are built and helper functons for returned data.
    """"""
    def __init__(self, name, display_name=None):
        self.name = name
        self.display_name = display_name
        self.type = 'text'
        self.filter_string = None

    def get_display_name(self):
        return self.display_name

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        if self.filter_string:
            self.filter_string = self.filter_string + ""AND {2} {0} \""{1}\"""".format(op, value, self.name)
        else:
            self.filter_string = ""{2} {0} \""{1}\"""".format(op, value, self.name)

class IP4Column(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = ""ip""

    def select(self):
        return ""inet_ntoa({0})"".format(self.name)

    def filter(self, value, op=None):
        s = value.split(""/"")
        if len(s) > 1:
            ip = ipaddress.ip_network(value, strict=False)
            start_ip = ip.network_address
            end_ip = ip.broadcast_address
            self.filter_string = ""({0} > {1} AND {0} < {2})"".format(self.name, int(start_ip), int(end_ip))
        else:
            ip = ipaddress.ip_address(value)
            self.filter_string = ""{0} = {1}"".format(self.name, int(ip))

        return self.filter_string

class IP6Column(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = ""ip6""

    def select(self):
        return ""inet6_ntoa({0})"".format(self.name)

    def filter(self, value, op=None):
        s = value.split(""/"")
        if len(s) > 1:
            ip = ipaddress.ip_network(value, strict=False)
            start_ip = ip.network_address
            end_ip = ip.broadcast_address
            self.filter_string = ""({0} > {1} AND {0} < {2})"".format(self.name, int(start_ip), int(end_ip))
        else:
            ip = ipaddress.ip_address(value)
            self.filter_string = ""{0} = {1}"".format(self.name, int(ip))

        return self.filter_string

class IntColumn(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = 'int'

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        self.filter_string = ""{0} = %s"".format(self.name)
        return self.filter_string

class PortColumn(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = 'port'

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        self.filter_string = ""{0} = %s"".format(self.name)
        return self.filter_string

class Coalesce:
    def __init__(self, name, columns, filter_func, display_name):
        """"""
        Coalesce
        Select from a list of columns whatever is not null
        :param columns (List): Column objects
        """"""
        self.name = name
        self.columns = columns
        # We assume that the passed columns are of roughly the same type
        self.type = columns[0].type
        self.column_selects = []
        for c in columns:
            self.column_selects.append(c.select())

        self.filter_string = None
        self.filter_func = filter_func
        self.display_name = display_name

    def get_display_name(self):
        return self.display_name

    def select(self):
        fields = "", "".join(self.column_selects)
        return ""COALESCE({0}) AS {1}"".format(fields, self.name)

    def filter(self, value, op=None):
        self.filter_string = self.filter_func(value, op)

class Schema:
    """"""
    Schema

    Defines the backend schema
    Changes to the backend (naming, etc.) should be reflected here.
    """"""
    def __init__(self):
        # Default
        self.limit = 10

        self.column_order = [
            ""last_switched"",
            ""src_ip"",
            ""src_port"",
            ""dst_ip"",
            ""dst_port"",
            ""in_bytes"",
        ]
        src_ip_col = IP4Column(""src_ip"", ""Source IP"")
        src_ipv6_col = IP6Column(""src_ipv6"", ""Source IPv6"")
        dst_ip_col = IP4Column(""dst_ip"", ""Destination IP"")
        dst_ipv6_col = IP6Column(""dst_ipv6"", ""DestinationIPv6"")

        self.filter_val_list = []

        # Columns
        self.columns = {
            ""last_switched"": Column(""last_switched"", ""Last Switched""),
            ""src_ip"": Coalesce(""src_c_ip"", [src_ip_col, src_ipv6_col], src_ip_col.filter, ""Source IP""),
            ""src_port"": PortColumn(""src_port"", ""Source Port""),
            ""dst_ip"": Coalesce(""dst_c_ip"", [dst_ip_col, dst_ipv6_col], dst_ip_col.filter, ""Destination IP""),
            ""dst_port"": PortColumn(""dst_port"", ""Destination Port""),
            ""in_bytes"": IntColumn(""in_bytes"", ""Input bytes""),
            ""in_pkts"": IntColumn(""in_pkts"", ""Input Packets""),
        }

        # Supported queries
        self.QUERIES = {
            ""TOPN"": self.topn
        }

        self.filters = []

        self.filter_map = {
            ""(\d+\-\d+\-\d+)"": ""last_switched"",
            ""src (\d+\.\d+\.\d+\.\d+\/\d+|\d+\.\d+\.\d+\.\d+)"": ""src_ip"",
            ""dst (\d+\.\d+\.\d+\.\d+\/\d+|\d+\.\d+\.\d+\.\d+)"": ""dst_ip"",
            ""src ([0-9]+)($|\s)"": ""src_port"",
            ""dst ([0-9]+)($|\s)"": ""dst_port"",
        }

    def add_filter(self, value, op=""=""):
        for regex, column in self.filter_map.items():
            if re.search(regex, value):
                m = re.search(regex, value)
                v = m.group(1)
                self.columns[column].filter(v, op)
                self.filter_val_list.append(v)


    def build_filter_string(self):
        s = 'WHERE '
        l = []
        for c in self.columns.values():
            if c.filter_string:
                l.append(c.filter_string)

        if len(l) > 0:
            return s + "" AND "".join(l)
        else:
            return ''

    def get_columns(self):
        result = {}
        for col_name, col in self.columns.items():
            result[col_name] = col.get_display_name()

        return result

    def get_int_columns(self):
        result = {}
        for col_name, col in self.columns.items():
            if col.type is ""int"":
                result[col_name] = col.get_display_name()

        return result

    def topn(self, column):
        count = ""last_switched""
        q = """"""
        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC
        """""".format(self.columns[column].select(), count, self.build_filter_string())
        return self.query_boilerplate(q)

    def topn_sum(self, column, sum_by):
        q = """"""
        SELECT {0}, sum({1}) AS c FROM test_goflow_records {2} GROUP BY {3} ORDER BY c DESC
        """""".format(self.columns[column].select(), sum_by, self.build_filter_string(), self.columns[column].name)
        return self.query_boilerplate(q)

    def flows(self):
        c = []
        for col in self.column_order:
            c.append(self.columns[col].select())
        q = """"""
        SELECT {1} FROM goflow_records {0} ORDER BY last_switched DESC
        """""".format(self.build_filter_string(), "", "".join(c))
        return self.query_boilerplate(q)

    def query_boilerplate(self, q):
        q = q + """"""LIMIT {0}"""""".format(self.limit)
        return q

    def query(self, db, q):
        cursor = db.cursor()
        if len(self.filter_val_list) > 0:
            print(self.filter_val_list)
            cursor.execute(q, self.filter_val_list)
        else:
            cursor.execute(q)
        return cursor/n/n/ngfui/backends/Timescaledb/timescaledb.py/n/nfrom gfui.backends.default import Backend
import psycopg2
from gfui.chartgraph import Graph, Table
import re
import ipaddress
import os

class Timescaledb_backend(Backend):
    def __init__(self, OPTIONS):
        super().__init__()
        self.required_opts = ['SQL_SERVER', 'SQL_USERNAME', 'SQL_DB']
        self.parse_options(OPTIONS)
        self.columns = {}

        pw = os.environ.get(""SQL_PASSWORD"")
        if not pw:
            pw = self.OPTIONS['SQL_PASSWORD']

        self.db = psycopg2.connect(
            ""dbname={0} user={1} password={2} host={3}"".format(
                self.OPTIONS['SQL_DB'],
                self.OPTIONS['SQL_USERNAME'],
                pw,
                self.OPTIONS['SQL_SERVER']
            )
        )

        self.schema = Schema()

        self.filters = []

    def get_columns(self):
        return self.schema.get_columns()

    def add_filter(self, op, value):
        self.schema.add_filter(value, op)

    def get_int_columns(self):
        return self.schema.get_int_columns()

    def flow_table(self, limit=10):
        db = self.db
        self.schema.limit = limit
        FLOWS = self.schema.flows()

        cursor = self.schema.query(db, FLOWS)
        r = cursor.fetchall()
        t = Table()
        t = t.table_from_rows(r, self.schema.column_order)
        return t

    def topn_sum_graph(self, field, sum_by, limit=10):
        db = self.db
        self.schema.limit = limit
        FLOWS_PER_IP = self.schema.topn_sum(field, sum_by)

        cursor = self.schema.query(db, FLOWS_PER_IP)
        r = cursor.fetchall()
        g = Graph()
        g.name = ""TopN {0}"".format(field)
        g.set_headers([
            field,
            ""Total""
        ])
        g.graph_from_rows(r, 0)
        return g

class Column:
    """"""
    Column

    Column handling class.
    Governs how query strings are built and helper functons for returned data.
    """"""
    def __init__(self, name, display_name=None):
        self.name = name
        self.display_name = display_name
        self.type = 'text'
        self.filter_string = None

    def get_display_name(self):
        return self.display_name

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        if self.filter_string:
            self.filter_string = self.filter_string + ""AND {2} {0} \""{1}\"""".format(op, value, self.name)
        else:
            self.filter_string = ""{2} {0} \""{1}\"""".format(op, value, self.name)

class IP4Column(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = ""ip""

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        s = value.split(""/"")
        if len(s) > 1:
            self.filter_string = ""{0} << %s"".format(self.name, value)
        else:
            self.filter_string = ""{0} = %s"".format(self.name, value)

        return self.filter_string

class IP6Column(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = ""ip6""

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        s = value.split(""/"")
        if len(s) > 1:
            self.filter_string = ""{0} << %s"".format(self.name, value)
        else:
            self.filter_string = ""{0} = %s"".format(self.name, value)

        return self.filter_string

class IntColumn(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = 'int'

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        self.filter_string = ""{0} = {1}"".format(self.name, value)
        return self.filter_string

class PortColumn(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = 'port'

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        self.filter_string = ""{0} = %s"".format(self.name, value)
        return self.filter_string

class Coalesce:
    def __init__(self, name, columns, filter_func, display_name):
        """"""
        Coalesce
        Select from a list of columns whatever is not null
        :param columns (List): Column objects
        """"""
        self.name = name
        self.columns = columns
        # We assume that the passed columns are of roughly the same type
        self.type = columns[0].type
        self.column_selects = []
        for c in columns:
            self.column_selects.append(c.select())

        self.filter_string = None
        self.filter_func = filter_func
        self.display_name = display_name

    def get_display_name(self):
        return self.display_name

    def select(self):
        fields = "", "".join(self.column_selects)
        return ""COALESCE({0}) AS {1}"".format(fields, self.name)

    def filter(self, value, op=None):
        self.filter_string = self.filter_func(value, op)

class Schema:
    """"""
    Schema

    Defines the backend schema
    Changes to the backend (naming, etc.) should be reflected here.
    """"""
    def __init__(self):
        # Default
        self.limit = 10

        self.column_order = [
            ""last_switched"",
            ""src_ip"",
            ""src_port"",
            ""dst_ip"",
            ""dst_port"",
            ""in_bytes"",
        ]
        src_ip_col = IP4Column(""src_ip"", ""Source IP"")
        src_ipv6_col = IP6Column(""src_ipv6"", ""Source IPv6"")
        dst_ip_col = IP4Column(""dst_ip"", ""Destination IP"")
        dst_ipv6_col = IP6Column(""dst_ipv6"", ""DestinationIPv6"")

        self.filter_val_list = []

        # Columns
        self.columns = {
            ""last_switched"": Column(""last_switched"", ""Last Switched""),
            ""src_ip"": Coalesce(""src_c_ip"", [src_ip_col, src_ipv6_col], src_ip_col.filter, ""Source IP""),
            ""src_port"": PortColumn(""src_port"", ""Source Port""),
            ""dst_ip"": Coalesce(""dst_c_ip"", [dst_ip_col, dst_ipv6_col], dst_ip_col.filter, ""Destination IP""),
            ""dst_port"": PortColumn(""dst_port"", ""Destination Port""),
            ""in_bytes"": IntColumn(""in_bytes"", ""Input bytes""),
            ""in_pkts"": IntColumn(""in_pkts"", ""Input Packets""),
        }

        # Supported queries
        self.QUERIES = {
            ""TOPN"": self.topn
        }

        self.filters = []

        self.filter_map = {
            ""(\d+\-\d+\-\d+)"": ""last_switched"",
            ""src (\d+\.\d+\.\d+\.\d+\/\d+|\d+\.\d+\.\d+\.\d+)"": ""src_ip"",
            ""dst (\d+\.\d+\.\d+\.\d+\/\d+|\d+\.\d+\.\d+\.\d+)"": ""dst_ip"",
            ""src ([0-9]+)($|\s)"": ""src_port"",
            ""dst ([0-9]+)($|\s)"": ""dst_port"",
        }

    def add_filter(self, value, op=""=""):
        for regex, column in self.filter_map.items():
            if re.search(regex, value):
                m = re.search(regex, value)
                v = m.group(1)
                self.columns[column].filter(v, op)
                self.filter_val_list.append(v)

    def build_filter_string(self):
        s = 'WHERE '
        l = []
        for c in self.columns.values():
            if c.filter_string:
                l.append(c.filter_string)

        if len(l) > 0:
            return s + "" AND "".join(l)
        else:
            return ''

    def get_columns(self):
        result = {}
        for col_name, col in self.columns.items():
            result[col_name] = col.get_display_name()

        return result

    def get_int_columns(self):
        result = {}
        for col_name, col in self.columns.items():
            if col.type is ""int"":
                result[col_name] = col.get_display_name()

        return result

    def topn(self, column):
        count = ""last_switched""
        q = """"""
        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC
        """""".format(self.columns[column].select(), count, self.build_filter_string())
        return self.query_boilerplate(q)

    def topn_sum(self, column, sum_by):
        q = """"""
        SELECT {0}, sum({1}) AS c FROM goflow_records {2} GROUP BY {3} ORDER BY c DESC
        """""".format(self.columns[column].select(), sum_by, self.build_filter_string(), self.columns[column].name)
        return self.query_boilerplate(q)

    def flows(self):
        c = []
        for col in self.column_order:
            c.append(self.columns[col].select())
        q = """"""
        SELECT {1} FROM goflow_records {0} ORDER BY last_switched DESC
        """""".format(self.build_filter_string(), "", "".join(c))
        return self.query_boilerplate(q)

    def query_boilerplate(self, q):
        q = q + """"""LIMIT {0}"""""".format(self.limit)
        return q

    def query(self, db, q):
        cursor = db.cursor()
        cursor.execute(q, self.filter_val_list)
        return cursor/n/n/n",0
191,191,abd763746d7ff1d40571fed8ed46fce2211f3deb,"/gfui/backends/Mysql/mysql.py/n/nfrom gfui.backends.default import Backend
import mysql.connector
from gfui.chartgraph import Graph, Table
import re
import ipaddress
import os

class Mysql_backend(Backend):
    def __init__(self, OPTIONS):
        super().__init__()
        self.required_opts = ['SQL_SERVER', 'SQL_USERNAME', 'SQL_DB']
        self.parse_options(OPTIONS)
        self.columns = {}

        pw = os.environ.get(""SQL_PASSWORD"")
        if not pw:
            pw = self.OPTIONS['SQL_PASSWORD']

        self.db = mysql.connector.connect(
            host=self.OPTIONS['SQL_SERVER'],
            user=self.OPTIONS['SQL_USERNAME'],
            passwd=pw
        )

        self.schema = Schema()

        self.filters = []

    def get_columns(self):
        return self.schema.get_columns()

    def add_filter(self, op, value):
        self.schema.add_filter(value, op)

    def get_int_columns(self):
        return self.schema.get_int_columns()

    def flow_table(self, limit=10):
        db = self.db
        self.schema.limit = limit
        FLOWS = self.schema.flows()

        cursor = db.cursor()
        cursor.execute(""USE testgoflow"")
        cursor.execute(FLOWS)
        r = cursor.fetchall()
        t = Table()
        t = t.table_from_rows(r, self.schema.column_order)
        return t

    def topn_sum_graph(self, field, sum_by, limit=10):
        db = self.db
        self.schema.limit = limit
        FLOWS_PER_IP = self.schema.topn_sum(field, sum_by)

        cursor = db.cursor()
        cursor.execute(""USE testgoflow"")
        cursor.execute(FLOWS_PER_IP)
        r = cursor.fetchall()
        g = Graph()
        g.name = ""TopN {0}"".format(field)
        g.set_headers([
            field,
            ""Total""
        ])
        g.graph_from_rows(r, 0)
        return g

class Column:
    """"""
    Column

    Column handling class.
    Governs how query strings are built and helper functons for returned data.
    """"""
    def __init__(self, name, display_name=None):
        self.name = name
        self.display_name = display_name
        self.type = 'text'
        self.filter_string = None

    def get_display_name(self):
        return self.display_name

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        if self.filter_string:
            self.filter_string = self.filter_string + ""AND {2} {0} \""{1}\"""".format(op, value, self.name)
        else:
            self.filter_string = ""{2} {0} \""{1}\"""".format(op, value, self.name)

class IP4Column(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = ""ip""

    def select(self):
        return ""inet_ntoa({0})"".format(self.name)

    def filter(self, value, op=None):
        s = value.split(""/"")
        if len(s) > 1:
            ip = ipaddress.ip_network(value, strict=False)
            start_ip = ip.network_address
            end_ip = ip.broadcast_address
            self.filter_string = ""({0} > {1} AND {0} < {2})"".format(self.name, int(start_ip), int(end_ip))
        else:
            ip = ipaddress.ip_address(value)
            self.filter_string = ""{0} = {1}"".format(self.name, int(ip))

        return self.filter_string

class IP6Column(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = ""ip6""

    def select(self):
        return ""inet6_ntoa({0})"".format(self.name)

    def filter(self, value, op=None):
        s = value.split(""/"")
        if len(s) > 1:
            ip = ipaddress.ip_network(value, strict=False)
            start_ip = ip.network_address
            end_ip = ip.broadcast_address
            self.filter_string = ""({0} > {1} AND {0} < {2})"".format(self.name, int(start_ip), int(end_ip))
        else:
            ip = ipaddress.ip_address(value)
            self.filter_string = ""{0} = {1}"".format(self.name, int(ip))

        return self.filter_string

class IntColumn(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = 'int'

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        self.filter_string = ""{0} = {1}"".format(self.name, value)
        return self.filter_string

class PortColumn(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = 'port'

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        self.filter_string = ""{0} = {1}"".format(self.name, value)
        return self.filter_string

class Coalesce:
    def __init__(self, name, columns, filter_func, display_name):
        """"""
        Coalesce
        Select from a list of columns whatever is not null
        :param columns (List): Column objects
        """"""
        self.name = name
        self.columns = columns
        # We assume that the passed columns are of roughly the same type
        self.type = columns[0].type
        self.column_selects = []
        for c in columns:
            self.column_selects.append(c.select())

        self.filter_string = None
        self.filter_func = filter_func
        self.display_name = display_name

    def get_display_name(self):
        return self.display_name

    def select(self):
        fields = "", "".join(self.column_selects)
        return ""COALESCE({0}) AS {1}"".format(fields, self.name)

    def filter(self, value, op=None):
        self.filter_string = self.filter_func(value, op)
        print(self.filter_string)

class Schema:
    """"""
    Schema

    Defines the backend schema
    Changes to the backend (naming, etc.) should be reflected here.
    """"""
    def __init__(self):
        # Default
        self.limit = 10

        self.column_order = [
            ""last_switched"",
            ""src_ip"",
            ""src_port"",
            ""dst_ip"",
            ""dst_port"",
            ""in_bytes"",
        ]
        src_ip_col = IP4Column(""src_ip"", ""Source IP"")
        src_ipv6_col = IP6Column(""src_ipv6"", ""Source IPv6"")
        dst_ip_col = IP4Column(""dst_ip"", ""Destination IP"")
        dst_ipv6_col = IP6Column(""dst_ipv6"", ""DestinationIPv6"")

        # Columns
        self.columns = {
            ""last_switched"": Column(""last_switched"", ""Last Switched""),
            ""src_ip"": Coalesce(""src_c_ip"", [src_ip_col, src_ipv6_col], src_ip_col.filter, ""Source IP""),
            ""src_port"": PortColumn(""src_port"", ""Source Port""),
            ""dst_ip"": Coalesce(""dst_c_ip"", [dst_ip_col, dst_ipv6_col], dst_ip_col.filter, ""Destination IP""),
            ""dst_port"": PortColumn(""dst_port"", ""Destination Port""),
            ""in_bytes"": IntColumn(""in_bytes"", ""Input bytes""),
            ""in_pkts"": IntColumn(""in_pkts"", ""Input Packets""),
        }

        # Supported queries
        self.QUERIES = {
            ""TOPN"": self.topn
        }

        self.filters = []

        self.filter_map = {
            ""(\d+\-\d+\-\d+)"": ""last_switched"",
            ""src (\d+\.\d+\.\d+\.\d+\/\d+|\d+\.\d+\.\d+\.\d+)"": ""src_ip"",
            ""dst (\d+\.\d+\.\d+\.\d+\/\d+|\d+\.\d+\.\d+\.\d+)"": ""dst_ip"",
            ""src ([0-9]+)($|\s)"": ""src_port"",
            ""dst ([0-9]+)($|\s)"": ""dst_port"",
        }

    def add_filter(self, value, op=""=""):
        for regex, column in self.filter_map.items():
            if re.search(regex, value):
                m = re.search(regex, value)
                v = m.group(1)
                self.columns[column].filter(v, op)

    def build_filter_string(self):
        s = 'WHERE '
        l = []
        for c in self.columns.values():
            if c.filter_string:
                l.append(c.filter_string)

        if len(l) > 0:
            return s + "" AND "".join(l)
        else:
            return ''

    def get_columns(self):
        result = {}
        for col_name, col in self.columns.items():
            result[col_name] = col.get_display_name()

        return result

    def get_int_columns(self):
        result = {}
        for col_name, col in self.columns.items():
            if col.type is ""int"":
                result[col_name] = col.get_display_name()

        return result

    def topn(self, column):
        count = ""last_switched""
        q = """"""
        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC
        """""".format(self.columns[column].select(), count, self.build_filter_string())
        return self.query_boilerplate(q)

    def topn_sum(self, column, sum_by):
        q = """"""
        SELECT {0}, sum({1}) AS c FROM test_goflow_records {2} GROUP BY {3} ORDER BY c DESC
        """""".format(self.columns[column].select(), sum_by, self.build_filter_string(), self.columns[column].name)
        print(q)
        return self.query_boilerplate(q)

    def flows(self):
        c = []
        for col in self.column_order:
            c.append(self.columns[col].select())
        q = """"""
        SELECT {1} FROM goflow_records {0} ORDER BY last_switched DESC
        """""".format(self.build_filter_string(), "", "".join(c))
        print(q)
        return self.query_boilerplate(q)

    def query_boilerplate(self, q):
        q = q + """"""LIMIT {0}"""""".format(self.limit)
        return q
/n/n/n/gfui/backends/Timescaledb/timescaledb.py/n/nfrom gfui.backends.default import Backend
import psycopg2
from gfui.chartgraph import Graph, Table
import re
import ipaddress
import os

class Timescaledb_backend(Backend):
    def __init__(self, OPTIONS):
        super().__init__()
        self.required_opts = ['SQL_SERVER', 'SQL_USERNAME', 'SQL_DB']
        self.parse_options(OPTIONS)
        self.columns = {}

        pw = os.environ.get(""SQL_PASSWORD"")
        if not pw:
            pw = self.OPTIONS['SQL_PASSWORD']

        self.db = psycopg2.connect(
            ""dbname={0} user={1} password={2} host={3}"".format(
                self.OPTIONS['SQL_DB'],
                self.OPTIONS['SQL_USERNAME'],
                pw,
                self.OPTIONS['SQL_SERVER']
            )
        )

        self.schema = Schema()

        self.filters = []

    def get_columns(self):
        return self.schema.get_columns()

    def add_filter(self, op, value):
        self.schema.add_filter(value, op)

    def get_int_columns(self):
        return self.schema.get_int_columns()

    def flow_table(self, limit=10):
        db = self.db
        self.schema.limit = limit
        FLOWS = self.schema.flows()

        cursor = self.schema.query(db, FLOWS)
        r = cursor.fetchall()
        t = Table()
        t = t.table_from_rows(r, self.schema.column_order)
        return t

    def topn_sum_graph(self, field, sum_by, limit=10):
        db = self.db
        self.schema.limit = limit
        FLOWS_PER_IP = self.schema.topn_sum(field, sum_by)

        cursor = db.cursor()
        cursor.execute(FLOWS_PER_IP)
        r = cursor.fetchall()
        g = Graph()
        g.name = ""TopN {0}"".format(field)
        g.set_headers([
            field,
            ""Total""
        ])
        g.graph_from_rows(r, 0)
        return g

class Column:
    """"""
    Column

    Column handling class.
    Governs how query strings are built and helper functons for returned data.
    """"""
    def __init__(self, name, display_name=None):
        self.name = name
        self.display_name = display_name
        self.type = 'text'
        self.filter_string = None

    def get_display_name(self):
        return self.display_name

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        if self.filter_string:
            self.filter_string = self.filter_string + ""AND {2} {0} \""{1}\"""".format(op, value, self.name)
        else:
            self.filter_string = ""{2} {0} \""{1}\"""".format(op, value, self.name)

class IP4Column(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = ""ip""

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        s = value.split(""/"")
        if len(s) > 1:
            self.filter_string = ""({0} << '{1}'"".format(self.name, value)
        else:
            self.filter_string = ""{0} = '{1}'"".format(self.name, value)

        return self.filter_string

class IP6Column(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = ""ip6""

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        s = value.split(""/"")
        if len(s) > 1:
            ip = ipaddress.ip_network(value, strict=False)
            start_ip = ip.network_address
            end_ip = ip.broadcast_address
            self.filter_string = ""({0} > {1} AND {0} < {2})"".format(self.name, int(start_ip), int(end_ip))
        else:
            ip = ipaddress.ip_address(value)
            self.filter_string = ""{0} = {1}"".format(self.name, int(ip))

        return self.filter_string

class IntColumn(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = 'int'

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        self.filter_string = ""{0} = {1}"".format(self.name, value)
        return self.filter_string

class PortColumn(Column):
    def __init__(self, name, display_name=None):
        super().__init__(name, display_name)
        self.type = 'port'

    def select(self):
        return ""{0}"".format(self.name)

    def filter(self, value, op=None):
        self.filter_string = ""{0} = %s"".format(self.name, value)
        return self.filter_string

class Coalesce:
    def __init__(self, name, columns, filter_func, display_name):
        """"""
        Coalesce
        Select from a list of columns whatever is not null
        :param columns (List): Column objects
        """"""
        self.name = name
        self.columns = columns
        # We assume that the passed columns are of roughly the same type
        self.type = columns[0].type
        self.column_selects = []
        for c in columns:
            self.column_selects.append(c.select())

        self.filter_string = None
        self.filter_func = filter_func
        self.display_name = display_name

    def get_display_name(self):
        return self.display_name

    def select(self):
        fields = "", "".join(self.column_selects)
        return ""COALESCE({0}) AS {1}"".format(fields, self.name)

    def filter(self, value, op=None):
        self.filter_string = self.filter_func(value, op)

class Schema:
    """"""
    Schema

    Defines the backend schema
    Changes to the backend (naming, etc.) should be reflected here.
    """"""
    def __init__(self):
        # Default
        self.limit = 10

        self.column_order = [
            ""last_switched"",
            ""src_ip"",
            ""src_port"",
            ""dst_ip"",
            ""dst_port"",
            ""in_bytes"",
        ]
        src_ip_col = IP4Column(""src_ip"", ""Source IP"")
        src_ipv6_col = IP6Column(""src_ipv6"", ""Source IPv6"")
        dst_ip_col = IP4Column(""dst_ip"", ""Destination IP"")
        dst_ipv6_col = IP6Column(""dst_ipv6"", ""DestinationIPv6"")

        self.filter_val_list = []

        # Columns
        self.columns = {
            ""last_switched"": Column(""last_switched"", ""Last Switched""),
            ""src_ip"": Coalesce(""src_c_ip"", [src_ip_col, src_ipv6_col], src_ip_col.filter, ""Source IP""),
            ""src_port"": PortColumn(""src_port"", ""Source Port""),
            ""dst_ip"": Coalesce(""dst_c_ip"", [dst_ip_col, dst_ipv6_col], dst_ip_col.filter, ""Destination IP""),
            ""dst_port"": PortColumn(""dst_port"", ""Destination Port""),
            ""in_bytes"": IntColumn(""in_bytes"", ""Input bytes""),
            ""in_pkts"": IntColumn(""in_pkts"", ""Input Packets""),
        }

        # Supported queries
        self.QUERIES = {
            ""TOPN"": self.topn
        }

        self.filters = []

        self.filter_map = {
            ""(\d+\-\d+\-\d+)"": ""last_switched"",
            ""src (\d+\.\d+\.\d+\.\d+\/\d+|\d+\.\d+\.\d+\.\d+)"": ""src_ip"",
            ""dst (\d+\.\d+\.\d+\.\d+\/\d+|\d+\.\d+\.\d+\.\d+)"": ""dst_ip"",
            ""src ([0-9]+)($|\s)"": ""src_port"",
            ""dst ([0-9]+)($|\s)"": ""dst_port"",
        }

    def add_filter(self, value, op=""=""):
        for regex, column in self.filter_map.items():
            if re.search(regex, value):
                m = re.search(regex, value)
                v = m.group(1)
                self.columns[column].filter(v, op)
                self.filter_val_list.append(v)

    def build_filter_string(self):
        s = 'WHERE '
        l = []
        for c in self.columns.values():
            if c.filter_string:
                l.append(c.filter_string)

        if len(l) > 0:
            return s + "" AND "".join(l)
        else:
            return ''

    def get_columns(self):
        result = {}
        for col_name, col in self.columns.items():
            result[col_name] = col.get_display_name()

        return result

    def get_int_columns(self):
        result = {}
        for col_name, col in self.columns.items():
            if col.type is ""int"":
                result[col_name] = col.get_display_name()

        return result

    def topn(self, column):
        count = ""last_switched""
        q = """"""
        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC
        """""".format(self.columns[column].select(), count, self.build_filter_string())
        return self.query_boilerplate(q)

    def topn_sum(self, column, sum_by):
        q = """"""
        SELECT {0}, sum({1}) AS c FROM goflow_records {2} GROUP BY {3} ORDER BY c DESC
        """""".format(self.columns[column].select(), sum_by, self.build_filter_string(), self.columns[column].name)
        return self.query_boilerplate(q)

    def flows(self):
        c = []
        for col in self.column_order:
            c.append(self.columns[col].select())
        q = """"""
        SELECT {1} FROM goflow_records {0} ORDER BY last_switched DESC
        """""".format(self.build_filter_string(), "", "".join(c))
        return self.query_boilerplate(q)

    def query_boilerplate(self, q):
        q = q + """"""LIMIT {0}"""""".format(self.limit)
        return q

    def query(self, db, q):
        cursor = db.cursor()
        cursor.execute(q, self.filter_val_list)
        return cursor/n/n/n",1
